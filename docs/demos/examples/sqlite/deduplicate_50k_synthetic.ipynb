{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking a dataset of real historical persons \n",
    "\n",
    "In this example, we deduplicate a more realistic dataset.  The data is based on historical persons scraped from wikidata.  Duplicate records are introduced with a variety of errors introduced.\n",
    "\n",
    "Note, as explained in the [backends topic guide](https://moj-analytical-services.github.io/splink/topic_guides/backends.html#sqlite), SQLite does not natively support string fuzzy matching functions such as `damareau-levenshtein` and `jaro-winkler` (as used in this example). Instead, these have been imported as python User Defined Functions (UDFs). One drawback of python UDFs is that they are considerably slower than native-SQL comparisons. As such, if you are hitting issues with large run times, consider switching to DuckDB (or some other backend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.sqlite.linker import SQLiteLinker\n",
    "import altair as alt\n",
    "\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 1000\n",
    "df = splink_datasets.historical_50k.sample(10000) # reduce size of dataset to reduce CI runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1cf459ce3fb44cab8eb0e53a6852445b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1cf459ce3fb44cab8eb0e53a6852445b.vega-embed details,\n",
       "  #altair-viz-1cf459ce3fb44cab8eb0e53a6852445b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1cf459ce3fb44cab8eb0e53a6852445b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1cf459ce3fb44cab8eb0e53a6852445b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1cf459ce3fb44cab8eb0e53a6852445b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.947400060114217, \"percentile_inc_nulls\": 0.9475, \"value_count\": 525, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 525, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.895802023845306, \"percentile_inc_nulls\": 0.896, \"value_count\": 515, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 515, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.8677487225728885, \"percentile_inc_nulls\": 0.868, \"value_count\": 280, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 280, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.8399959923855325, \"percentile_inc_nulls\": 0.8403, \"value_count\": 277, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 277, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.8131449754533614, \"percentile_inc_nulls\": 0.8135, \"value_count\": 268, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 268, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.7871956717763751, \"percentile_inc_nulls\": 0.7876, \"value_count\": 259, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 259, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.7616471295461377, \"percentile_inc_nulls\": 0.7621, \"value_count\": 255, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 255, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.7376014427412083, \"percentile_inc_nulls\": 0.7381, \"value_count\": 240, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 240, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.7191664161907625, \"percentile_inc_nulls\": 0.7197, \"value_count\": 184, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 184, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.7011321510870654, \"percentile_inc_nulls\": 0.7017, \"value_count\": 180, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 180, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6865043582807334, \"percentile_inc_nulls\": 0.6871, \"value_count\": 146, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 146, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6734796112613967, \"percentile_inc_nulls\": 0.6740999999999999, \"value_count\": 130, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 130, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6610560064121831, \"percentile_inc_nulls\": 0.6617, \"value_count\": 124, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 124, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6495341148181545, \"percentile_inc_nulls\": 0.6502, \"value_count\": 115, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 115, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6385131750325619, \"percentile_inc_nulls\": 0.6392, \"value_count\": 110, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 110, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6281935677787797, \"percentile_inc_nulls\": 0.6289, \"value_count\": 103, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 103, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6194770063119928, \"percentile_inc_nulls\": 0.6202, \"value_count\": 87, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 87, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6111612062919547, \"percentile_inc_nulls\": 0.6119, \"value_count\": 83, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 83, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.6029455966336039, \"percentile_inc_nulls\": 0.6037, \"value_count\": 82, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 82, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5948301773369402, \"percentile_inc_nulls\": 0.5956, \"value_count\": 81, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 81, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5873159002103998, \"percentile_inc_nulls\": 0.5881000000000001, \"value_count\": 75, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 75, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5800020038072338, \"percentile_inc_nulls\": 0.5808, \"value_count\": 73, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 73, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5729886784891294, \"percentile_inc_nulls\": 0.5738, \"value_count\": 70, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 70, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5662759242560866, \"percentile_inc_nulls\": 0.5670999999999999, \"value_count\": 67, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 67, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5600641218314798, \"percentile_inc_nulls\": 0.5609, \"value_count\": 62, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5549544133854323, \"percentile_inc_nulls\": 0.5558000000000001, \"value_count\": 51, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 51, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.549944895301072, \"percentile_inc_nulls\": 0.5508, \"value_count\": 50, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 50, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5405270013024748, \"percentile_inc_nulls\": 0.5414, \"value_count\": 47, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 94, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5359182446648633, \"percentile_inc_nulls\": 0.5367999999999999, \"value_count\": 46, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 46, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5271014928363891, \"percentile_inc_nulls\": 0.528, \"value_count\": 44, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 88, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5228934976455265, \"percentile_inc_nulls\": 0.5238, \"value_count\": 42, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 42, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5146778879871756, \"percentile_inc_nulls\": 0.5156000000000001, \"value_count\": 41, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 82, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5106702735196874, \"percentile_inc_nulls\": 0.5116, \"value_count\": 40, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 40, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5070634204989479, \"percentile_inc_nulls\": 0.508, \"value_count\": 36, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.5000500951808435, \"percentile_inc_nulls\": 0.501, \"value_count\": 35, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 70, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.49664362288347863, \"percentile_inc_nulls\": 0.49760000000000004, \"value_count\": 34, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 34, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4933373409478008, \"percentile_inc_nulls\": 0.49429999999999996, \"value_count\": 33, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 33, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.49013124937381025, \"percentile_inc_nulls\": 0.4911, \"value_count\": 32, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 32, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4839194469492035, \"percentile_inc_nulls\": 0.4849, \"value_count\": 31, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.474902314397355, \"percentile_inc_nulls\": 0.4759, \"value_count\": 30, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 90, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.47199679390842597, \"percentile_inc_nulls\": 0.473, \"value_count\": 29, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 29, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.46638613365394244, \"percentile_inc_nulls\": 0.46740000000000004, \"value_count\": 28, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 56, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4609758541228334, \"percentile_inc_nulls\": 0.46199999999999997, \"value_count\": 27, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 54, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4531610059112313, \"percentile_inc_nulls\": 0.45420000000000005, \"value_count\": 26, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 78, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.45075643723073844, \"percentile_inc_nulls\": 0.4518, \"value_count\": 24, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 24, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4415389239555155, \"percentile_inc_nulls\": 0.4426, \"value_count\": 23, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 92, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.43272217212704134, \"percentile_inc_nulls\": 0.43379999999999996, \"value_count\": 22, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 88, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.42851417693617877, \"percentile_inc_nulls\": 0.4296, \"value_count\": 21, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 42, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.42049894800120224, \"percentile_inc_nulls\": 0.4216, \"value_count\": 20, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 80, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.4090772467688608, \"percentile_inc_nulls\": 0.4102, \"value_count\": 19, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 114, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3946498346859032, \"percentile_inc_nulls\": 0.39580000000000004, \"value_count\": 18, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 144, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3878368900911733, \"percentile_inc_nulls\": 0.389, \"value_count\": 17, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 68, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.37180643222122034, \"percentile_inc_nulls\": 0.373, \"value_count\": 16, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 160, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.365795010519988, \"percentile_inc_nulls\": 0.367, \"value_count\": 15, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 60, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.35597635507464187, \"percentile_inc_nulls\": 0.35719999999999996, \"value_count\": 14, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 98, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3494639815649735, \"percentile_inc_nulls\": 0.3507, \"value_count\": 13, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 65, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3350365694820159, \"percentile_inc_nulls\": 0.33630000000000004, \"value_count\": 12, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 144, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.327321911632101, \"percentile_inc_nulls\": 0.3286, \"value_count\": 11, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 77, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3163009718465084, \"percentile_inc_nulls\": 0.3176, \"value_count\": 10, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 110, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.3036769862739205, \"percentile_inc_nulls\": 0.30500000000000005, \"value_count\": 9, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 126, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.29005109708446053, \"percentile_inc_nulls\": 0.2914, \"value_count\": 8, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 136, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.27251778378919944, \"percentile_inc_nulls\": 0.27390000000000003, \"value_count\": 7, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 175, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.25448351868550245, \"percentile_inc_nulls\": 0.2559, \"value_count\": 6, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 180, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.22893497645526495, \"percentile_inc_nulls\": 0.23040000000000005, \"value_count\": 5, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 255, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.19767558360885684, \"percentile_inc_nulls\": 0.19920000000000004, \"value_count\": 4, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 312, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.15800020038072338, \"percentile_inc_nulls\": 0.15959999999999996, \"value_count\": 3, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 396, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.10710349664362284, \"percentile_inc_nulls\": 0.10880000000000001, \"value_count\": 2, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 508, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0019000000000000128, \"value_count\": 1, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1069, \"distinct_value_count\": 1814}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 525, \"group_name\": \"first_name\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 525, \"distinct_value_count\": 1814}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column first_name\", \"subtitle\": \"In this col, 19 values (0.2%) are null and there are 1814 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 525, \"group_name\": \"first_name\", \"value\": \"william\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 515, \"group_name\": \"first_name\", \"value\": \"john\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 280, \"group_name\": \"first_name\", \"value\": \"thomas\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 277, \"group_name\": \"first_name\", \"value\": \"george\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 268, \"group_name\": \"first_name\", \"value\": \"charles\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 259, \"group_name\": \"first_name\", \"value\": \"james\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 255, \"group_name\": \"first_name\", \"value\": \"sir\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 240, \"group_name\": \"first_name\", \"value\": \"henry\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 184, \"group_name\": \"first_name\", \"value\": \"edward\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 180, \"group_name\": \"first_name\", \"value\": \"robert\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6tyelburh\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6thelfroth\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6lfric\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6ldfl\\u00e6d,\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6kfgifu\", \"total_non_null_rows\": 9981, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1814}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 525]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.997686672664182, \"percentile_inc_nulls\": 0.9982, \"value_count\": 9, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 18, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.9966585271815962, \"percentile_inc_nulls\": 0.9974, \"value_count\": 8, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 8, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.9912607633980208, \"percentile_inc_nulls\": 0.9932, \"value_count\": 7, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 42, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.9766096902711734, \"percentile_inc_nulls\": 0.9818, \"value_count\": 6, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 114, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.9361264618943581, \"percentile_inc_nulls\": 0.9503, \"value_count\": 5, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 315, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.8477059503919805, \"percentile_inc_nulls\": 0.8815, \"value_count\": 4, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 688, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.6738208456496595, \"percentile_inc_nulls\": 0.7462, \"value_count\": 3, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1353, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.42423852975195986, \"percentile_inc_nulls\": 0.552, \"value_count\": 2, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1942, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.2219, \"value_count\": 1, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 3301, \"distinct_value_count\": 4986}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 9, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 18, \"distinct_value_count\": 4986}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column postcode_fake\", \"subtitle\": \"In this col, 2,219 values (22.2%) are null and there are 4986 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 9, \"group_name\": \"postcode_fake\", \"value\": \"se1 7eh\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 9, \"group_name\": \"postcode_fake\", \"value\": \"l3 0ah\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 8, \"group_name\": \"postcode_fake\", \"value\": \"pl1 3dq\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"tr18 4py\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"se1 7pb\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"m18 7hq\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"hu6 8rf\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"ch1 4bj\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"ca10 2qy\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"wn6 8ta\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"ze1 0px\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yow5 9as\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo7 3nn\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo7 3hz\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo62 6hj\", \"total_non_null_rows\": 7781, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 4986}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 9]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9397559075564789, \"percentile_inc_nulls\": 0.9536, \"value_count\": 464, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 464, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.8944430018177096, \"percentile_inc_nulls\": 0.9187, \"value_count\": 349, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 349, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.8504284601402233, \"percentile_inc_nulls\": 0.8848, \"value_count\": 339, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 339, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.8070631004933784, \"percentile_inc_nulls\": 0.8513999999999999, \"value_count\": 334, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 334, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.7642170864710465, \"percentile_inc_nulls\": 0.8184, \"value_count\": 330, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 330, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.7227992729161257, \"percentile_inc_nulls\": 0.7865, \"value_count\": 319, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 319, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.6876136068553622, \"percentile_inc_nulls\": 0.7594, \"value_count\": 271, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 271, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.6556738509478057, \"percentile_inc_nulls\": 0.7348, \"value_count\": 246, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 246, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.6241236042586341, \"percentile_inc_nulls\": 0.7105, \"value_count\": 243, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 243, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.5936120488184887, \"percentile_inc_nulls\": 0.687, \"value_count\": 235, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 235, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.5647883666580109, \"percentile_inc_nulls\": 0.6648000000000001, \"value_count\": 222, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 222, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.514411841080239, \"percentile_inc_nulls\": 0.626, \"value_count\": 194, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 388, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.49636458062840816, \"percentile_inc_nulls\": 0.6121, \"value_count\": 139, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 139, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.48013502986237344, \"percentile_inc_nulls\": 0.5996, \"value_count\": 125, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 125, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.4652038431576214, \"percentile_inc_nulls\": 0.5881000000000001, \"value_count\": 115, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 115, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.4514411841080239, \"percentile_inc_nulls\": 0.5775, \"value_count\": 106, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 106, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.43819787068293947, \"percentile_inc_nulls\": 0.5673, \"value_count\": 102, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 102, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.4266424305375227, \"percentile_inc_nulls\": 0.5584, \"value_count\": 89, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 89, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.41625551804726046, \"percentile_inc_nulls\": 0.5504, \"value_count\": 80, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 80, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.40664762399376786, \"percentile_inc_nulls\": 0.5429999999999999, \"value_count\": 74, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 74, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.39742923915866013, \"percentile_inc_nulls\": 0.5359, \"value_count\": 71, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 71, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.3883406907296806, \"percentile_inc_nulls\": 0.5288999999999999, \"value_count\": 70, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 70, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.37938197870682944, \"percentile_inc_nulls\": 0.522, \"value_count\": 69, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 69, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.3719813035575176, \"percentile_inc_nulls\": 0.5163, \"value_count\": 57, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 57, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.36535964684497535, \"percentile_inc_nulls\": 0.5112, \"value_count\": 51, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 51, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.3588678265385614, \"percentile_inc_nulls\": 0.5062, \"value_count\": 50, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 50, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.35289535185666066, \"percentile_inc_nulls\": 0.5016, \"value_count\": 46, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 46, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.3470527135808881, \"percentile_inc_nulls\": 0.4971, \"value_count\": 45, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 45, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.33614645546611266, \"percentile_inc_nulls\": 0.4887, \"value_count\": 42, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 84, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.32549987016359383, \"percentile_inc_nulls\": 0.48050000000000004, \"value_count\": 41, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 82, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.320436250324591, \"percentile_inc_nulls\": 0.4766, \"value_count\": 39, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 39, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.3158919761101012, \"percentile_inc_nulls\": 0.47309999999999997, \"value_count\": 35, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 35, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.31147753830173985, \"percentile_inc_nulls\": 0.4697, \"value_count\": 34, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 34, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.30719293689950666, \"percentile_inc_nulls\": 0.46640000000000004, \"value_count\": 33, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 33, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.30303817190340177, \"percentile_inc_nulls\": 0.46319999999999995, \"value_count\": 32, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 32, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.295247987535705, \"percentile_inc_nulls\": 0.45720000000000005, \"value_count\": 30, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 60, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.2914827317579849, \"percentile_inc_nulls\": 0.45430000000000004, \"value_count\": 29, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 29, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.28096598286159435, \"percentile_inc_nulls\": 0.44620000000000004, \"value_count\": 27, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 81, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.2775902363022592, \"percentile_inc_nulls\": 0.4436, \"value_count\": 26, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 26, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.27434432614905224, \"percentile_inc_nulls\": 0.44110000000000005, \"value_count\": 25, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 25, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.2681121786548948, \"percentile_inc_nulls\": 0.4363, \"value_count\": 24, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 48, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.262139703972994, \"percentile_inc_nulls\": 0.4317, \"value_count\": 23, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 46, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.25357050116852764, \"percentile_inc_nulls\": 0.42510000000000003, \"value_count\": 22, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 66, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.23993767852505843, \"percentile_inc_nulls\": 0.41459999999999997, \"value_count\": 21, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 105, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.2373409504024928, \"percentile_inc_nulls\": 0.41259999999999997, \"value_count\": 20, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 20, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.22747338353674373, \"percentile_inc_nulls\": 0.405, \"value_count\": 19, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 76, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.2181251622955077, \"percentile_inc_nulls\": 0.39780000000000004, \"value_count\": 18, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 72, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.20929628667878475, \"percentile_inc_nulls\": 0.391, \"value_count\": 17, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 68, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.1989093741885225, \"percentile_inc_nulls\": 0.383, \"value_count\": 16, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 80, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.19306673591274992, \"percentile_inc_nulls\": 0.37849999999999995, \"value_count\": 15, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 45, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.1821604777979745, \"percentile_inc_nulls\": 0.3701, \"value_count\": 14, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 84, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.17372111139963642, \"percentile_inc_nulls\": 0.36360000000000003, \"value_count\": 13, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 65, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.16904700077901846, \"percentile_inc_nulls\": 0.36, \"value_count\": 12, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.1547649961049078, \"percentile_inc_nulls\": 0.349, \"value_count\": 11, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 110, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.14178135549207993, \"percentile_inc_nulls\": 0.33899999999999997, \"value_count\": 10, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 100, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.1324331342508439, \"percentile_inc_nulls\": 0.3318, \"value_count\": 9, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 72, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.12204622176058166, \"percentile_inc_nulls\": 0.3238, \"value_count\": 8, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 80, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.10296027005972475, \"percentile_inc_nulls\": 0.30910000000000004, \"value_count\": 7, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 147, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.08582186445079198, \"percentile_inc_nulls\": 0.29590000000000005, \"value_count\": 6, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 132, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.06439885743962603, \"percentile_inc_nulls\": 0.2794, \"value_count\": 5, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 165, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.04466372370812777, \"percentile_inc_nulls\": 0.2642, \"value_count\": 4, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 152, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.02479875357050121, \"percentile_inc_nulls\": 0.2489, \"value_count\": 3, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 153, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.00999740327187748, \"percentile_inc_nulls\": 0.23750000000000004, \"value_count\": 2, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 114, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.2298, \"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 77, \"distinct_value_count\": 430}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 464, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 464, \"distinct_value_count\": 430}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column substr(dob, 1,4)\", \"subtitle\": \"In this col, 2,298 values (23.0%) are null and there are 430 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 464, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1862\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 349, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1857\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 339, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1858\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 334, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1861\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 330, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1859\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 319, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1860\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 271, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1856\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 246, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1855\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 243, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1850\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 235, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1854\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1884\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1875\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1756\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1739\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1731\", \"total_non_null_rows\": 7702, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 430}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 464]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple settings dictionary will be used for exploratory analysis\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname\",\n",
    "        \"l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"l.first_name = r.first_name and l.dob = r.dob\",\n",
    "        \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\",\n",
    "    ],\n",
    "}\n",
    "linker = SQLiteLinker(df, settings)\n",
    "\n",
    "linker.profile_columns(\n",
    "    [\"first_name\", \"postcode_fake\", \"substr(dob, 1,4)\"], top_n=10, bottom_n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-baf6a4569123495e9747b15e928d6cce.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-baf6a4569123495e9747b15e928d6cce.vega-embed details,\n",
       "  #altair-viz-baf6a4569123495e9747b15e928d6cce.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-baf6a4569123495e9747b15e928d6cce\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-baf6a4569123495e9747b15e928d6cce\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-baf6a4569123495e9747b15e928d6cce\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b5b299d9b4b0549022bc8714c7f92866\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"rule\", \"legend\": null, \"scale\": {\"scheme\": \"category20c\"}}, \"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Cartesian Product of Input Data\", \"type\": \"quantitative\"}, {\"field\": \"reduction_ratio\", \"title\": \"Reduction Ratio (cumulative rows/cartesian product)\", \"type\": \"nominal\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-b5b299d9b4b0549022bc8714c7f92866\": [{\"row_count\": 10971, \"rule\": \"l.first_name = r.first_name and l.surname = r.surname\", \"cumulative_rows\": 10971, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999781. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 0}, {\"row_count\": 1031, \"rule\": \"l.surname = r.surname and l.dob = r.dob\", \"cumulative_rows\": 12002, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.99976. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 10971}, {\"row_count\": 1083, \"rule\": \"l.first_name = r.first_name and l.dob = r.dob\", \"cumulative_rows\": 13085, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999738. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 12002}, {\"row_count\": 352, \"rule\": \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\", \"cumulative_rows\": 13437, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999731. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 13085}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.cumulative_num_comparisons_from_blocking_rules_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splink.sqlite.comparison_template_library as ctl\n",
    "import splink.sqlite.comparison_library as cl\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname\",\n",
    "        \"l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"l.first_name = r.first_name and l.dob = r.dob\",\n",
    "        \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\",\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\", jaro_winkler_thresholds=[0.9], term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"surname\", jaro_winkler_thresholds=[0.9], term_frequency_adjustments=True),\n",
    "        cl.damerau_levenshtein_at_thresholds(\"dob\", [1, 2], term_frequency_adjustments=True),\n",
    "        cl.damerau_levenshtein_at_thresholds(\"postcode_fake\", [1,2]),\n",
    "        cl.exact_match(\"birth_place\", term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"occupation\",  term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n",
    "\n",
    "linker = SQLiteLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000144.\n",
      "This means that amongst all possible pairwise record comparisons, one in 6,955.02 are expected to match.  With 49,995,000 total possible comparisons, we expect a total of around 7,188.33 matching pairs\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_probability_two_random_records_match(\n",
    "    [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"substr(l.first_name,1,2) = substr(r.first_name,1,2) and l.surname = r.surname and substr(l.postcode_fake,1,2) = substr(r.postcode_fake,1,2)\",\n",
    "        \"l.dob = r.dob and l.postcode_fake = r.postcode_fake\",\n",
    "    ],\n",
    "    recall=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - postcode_fake (no m values are trained).\n",
      "    - birth_place (no m values are trained).\n",
      "    - occupation (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=5e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.first_name = r.first_name and l.surname = r.surname\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - dob\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n",
      "\n",
      "Iteration 1: Largest change in params was -0.533 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was -0.047 in probability_two_random_records_match\n",
      "Iteration 3: Largest change in params was 0.0181 in the m_probability of birth_place, level `Exact match`\n",
      "Iteration 4: Largest change in params was 0.00608 in the m_probability of birth_place, level `Exact match`\n",
      "\n",
      "EM converged after 4 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_names = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.dob = r.dob\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n",
      "\n",
      "Iteration 1: Largest change in params was -0.353 in the m_probability of first_name, level `Exact match first_name`\n",
      "Iteration 2: Largest change in params was 0.0376 in the m_probability of first_name, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was 0.00562 in the m_probability of postcode_fake, level `All other comparisons`\n",
      "\n",
      "EM converged after 3 iterations\n",
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final match weights can be viewed in the match weights chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-65d88c7beebe4d90a1874e658030d009.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-65d88c7beebe4d90a1874e658030d009.vega-embed details,\n",
       "  #altair-viz-65d88c7beebe4d90a1874e658030d009.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-65d88c7beebe4d90a1874e658030d009\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-65d88c7beebe4d90a1874e658030d009\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-65d88c7beebe4d90a1874e658030d009\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-07422e65de1bbd766a022cadbdeff57f\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-07422e65de1bbd766a022cadbdeff57f\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.00014380172073279066, \"log2_bayes_factor\": -12.763631440366042, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.000 or one in  6,955.0 records.This is equivalent to a starting match weight of -12.764.\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match first_name\", \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"m_probability_description\": \"Amongst matching record comparisons, 55.46% of records are in the exact match first_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.20% of records are in the exact match first_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 46.376175616965774, \"log2_bayes_factor\": 5.535311948809896, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"damerau_levenshtein(\\\"first_name_l\\\", \\\"first_name_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.08024152976681312, \"u_probability\": 0.0029957179623490205, \"m_probability_description\": \"Amongst matching record comparisons, 8.02% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.30% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 26.785408631690295, \"log2_bayes_factor\": 4.743375400518043, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 26.79 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler >= 0.9\", \"m_probability\": 0.039940575558038253, \"u_probability\": 0.3021836281651755, \"m_probability_description\": \"Amongst matching record comparisons, 3.99% of records are in the jaro_winkler >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 30.22% of records are in the jaro_winkler >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.13217319482379924, \"log2_bayes_factor\": -2.919498471868429, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro_winkler >= 0.9` then comparison is  7.57 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.3252259699421662, \"u_probability\": 0.6828621015046925, \"m_probability_description\": \"Amongst matching record comparisons, 32.52% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 68.29% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4762688824369195, \"log2_bayes_factor\": -1.0701518032093222, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.10 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match surname\", \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"m_probability_description\": \"Amongst matching record comparisons, 79.05% of records are in the exact match surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.08% of records are in the exact match surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 992.9327003879175, \"log2_bayes_factor\": 9.955552126957437, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"damerau_levenshtein(\\\"surname_l\\\", \\\"surname_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.12320231560472998, \"u_probability\": 0.0004085065481196684, \"m_probability_description\": \"Amongst matching record comparisons, 12.32% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 301.5920214053434, \"log2_bayes_factor\": 8.23645445249536, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 301.59 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler >= 0.9\", \"m_probability\": 0.010763102961497512, \"u_probability\": 0.20626498069727675, \"m_probability_description\": \"Amongst matching record comparisons, 1.08% of records are in the jaro_winkler >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 20.63% of records are in the jaro_winkler >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.052180951536770555, \"log2_bayes_factor\": -4.260332937362106, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro_winkler >= 0.9` then comparison is  19.16 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.07552240517827755, \"u_probability\": 0.7925303740274304, \"m_probability_description\": \"Amongst matching record comparisons, 7.55% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 79.25% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.09529275804849295, \"log2_bayes_factor\": -3.3914896117834785, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  10.49 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.623315558644858, \"u_probability\": 0.001872316324648982, \"m_probability_description\": \"Amongst matching record comparisons, 62.33% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.19% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"dob\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 332.9114586242343, \"log2_bayes_factor\": 8.378994717855353, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 332.91 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"m_probability_description\": \"Amongst matching record comparisons, 34.00% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.99% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 17.120448415261805, \"log2_bayes_factor\": 4.097648583892912, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"m_probability_description\": \"Amongst matching record comparisons, 3.64% of records are in the damerau_levenshtein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 7.72% of records are in the damerau_levenshtein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.47109091074943404, \"log2_bayes_factor\": -1.0859225980401308, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0002821895512075107, \"u_probability\": 0.9010626037248756, \"m_probability_description\": \"Amongst matching record comparisons, 0.03% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 90.11% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.0003131741901627876, \"log2_bayes_factor\": -11.64074705982751, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3,193.11 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 2}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.6869574386653682, \"u_probability\": 0.00014872260799965388, \"m_probability_description\": \"Amongst matching record comparisons, 68.70% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 4619.051857044942, \"log2_bayes_factor\": 12.173381027749148, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,619.05 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"damerau_levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.07773939909138543, \"u_probability\": 8.990957665433622e-05, \"m_probability_description\": \"Amongst matching record comparisons, 7.77% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 864.6398079512719, \"log2_bayes_factor\": 9.755955449108026, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 864.64 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"damerau_levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"m_probability\": 0.054240764701006354, \"u_probability\": 0.0005391194539987453, \"m_probability_description\": \"Amongst matching record comparisons, 5.42% of records are in the damerau_levenshtein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the damerau_levenshtein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 100.60991919080811, \"log2_bayes_factor\": 6.652628738078518, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is 100.61 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"m_probability_description\": \"Amongst matching record comparisons, 18.11% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.92% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.18120332872808764, \"log2_bayes_factor\": -2.4643186367692493, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 3}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.8305787965393059, \"u_probability\": 0.005164739750845969, \"m_probability_description\": \"Amongst matching record comparisons, 83.06% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.52% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"birth_place\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 160.8171634211113, \"log2_bayes_factor\": 7.329277578014943, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 160.82 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 4}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"m_probability_description\": \"Amongst matching record comparisons, 16.94% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.48% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.1703007625787842, \"log2_bayes_factor\": -2.55384319970551, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 4}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.9139268395242015, \"u_probability\": 0.04253387488711016, \"m_probability_description\": \"Amongst matching record comparisons, 91.39% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 4.25% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"occupation\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 21.487034556570954, \"log2_bayes_factor\": 4.42539448385424, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 21.49 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 5}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"m_probability_description\": \"Amongst matching record comparisons, 8.61% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 95.75% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.08989682059576795, \"log2_bayes_factor\": -3.4755860973034207, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001437810447711438, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e7c3e4aed6994de18b4b8ed6651e9577.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e7c3e4aed6994de18b4b8ed6651e9577.vega-embed details,\n",
       "  #altair-viz-e7c3e4aed6994de18b4b8ed6651e9577.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e7c3e4aed6994de18b4b8ed6651e9577\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e7c3e4aed6994de18b4b8ed6651e9577\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e7c3e4aed6994de18b4b8ed6651e9577\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"axis\": {\"format\": \"+\", \"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"point\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"match_weight\", \"format\": \"+.5\", \"title\": \"Match weight\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".5\", \"title\": \"Match probability\", \"type\": \"quantitative\"}, {\"field\": \"cum_prop\", \"format\": \".3%\", \"title\": \"Proportion of unlinkable records\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"name\": \"mouse_coords\"}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"match_weight\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"y\": {\"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}], \"data\": {\"name\": \"data-080302785871e05d07c553dccc1e165f\"}, \"height\": 400, \"params\": [{\"name\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"select\": {\"type\": \"point\", \"fields\": [\"match_weight\", \"cum_prop\"], \"nearest\": true, \"on\": \"mouseover\"}, \"views\": [\"mouse_coords\"]}], \"title\": {\"text\": \"Unlinkable records\", \"subtitle\": \"Records with insufficient information to exceed a given match threshold\"}, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-080302785871e05d07c553dccc1e165f\": [{\"match_weight\": -9.34, \"match_probability\": 0.00154, \"prop\": 0.0001, \"cum_prop\": 0.0001}, {\"match_weight\": -7.82, \"match_probability\": 0.0044, \"prop\": 0.0001, \"cum_prop\": 0.0002}, {\"match_weight\": -6.46, \"match_probability\": 0.01124, \"prop\": 0.0001, \"cum_prop\": 0.00030000000000000003}, {\"match_weight\": -6.03, \"match_probability\": 0.01511, \"prop\": 0.0001, \"cum_prop\": 0.0004}, {\"match_weight\": -5.08, \"match_probability\": 0.02864, \"prop\": 0.0002, \"cum_prop\": 0.0006000000000000001}, {\"match_weight\": -4.95, \"match_probability\": 0.03125, \"prop\": 0.0001, \"cum_prop\": 0.0007000000000000001}, {\"match_weight\": -4.76, \"match_probability\": 0.03556, \"prop\": 0.0001, \"cum_prop\": 0.0008000000000000001}, {\"match_weight\": -4.54, \"match_probability\": 0.04124, \"prop\": 0.0001, \"cum_prop\": 0.0009000000000000002}, {\"match_weight\": -4.12, \"match_probability\": 0.05424, \"prop\": 0.0001, \"cum_prop\": 0.0010000000000000002}, {\"match_weight\": -3.62, \"match_probability\": 0.07539, \"prop\": 0.0001, \"cum_prop\": 0.0011000000000000003}, {\"match_weight\": -3.5, \"match_probability\": 0.08126, \"prop\": 0.0001, \"cum_prop\": 0.0012000000000000003}, {\"match_weight\": -3.14, \"match_probability\": 0.1021, \"prop\": 0.0001, \"cum_prop\": 0.0013000000000000004}, {\"match_weight\": -2.97, \"match_probability\": 0.11311, \"prop\": 0.0001, \"cum_prop\": 0.0014000000000000004}, {\"match_weight\": -2.84, \"match_probability\": 0.12282, \"prop\": 0.0001, \"cum_prop\": 0.0015000000000000005}, {\"match_weight\": -2.6, \"match_probability\": 0.14125, \"prop\": 0.0001, \"cum_prop\": 0.0016000000000000005}, {\"match_weight\": -2.34, \"match_probability\": 0.16479, \"prop\": 0.0001, \"cum_prop\": 0.0017000000000000006}, {\"match_weight\": -1.54, \"match_probability\": 0.25601, \"prop\": 0.0001, \"cum_prop\": 0.0018000000000000006}, {\"match_weight\": -1.33, \"match_probability\": 0.28469, \"prop\": 0.0001, \"cum_prop\": 0.0019000000000000006}, {\"match_weight\": -0.95, \"match_probability\": 0.34044, \"prop\": 0.0001, \"cum_prop\": 0.0020000000000000005}, {\"match_weight\": -0.87, \"match_probability\": 0.35305, \"prop\": 0.0001, \"cum_prop\": 0.0021000000000000003}, {\"match_weight\": -0.59, \"match_probability\": 0.39912, \"prop\": 0.0001, \"cum_prop\": 0.0022}, {\"match_weight\": -0.41, \"match_probability\": 0.43004, \"prop\": 0.0001, \"cum_prop\": 0.0023}, {\"match_weight\": -0.33, \"match_probability\": 0.44321, \"prop\": 0.0012, \"cum_prop\": 0.0034999999999999996}, {\"match_weight\": -0.2, \"match_probability\": 0.46486, \"prop\": 0.0001, \"cum_prop\": 0.0035999999999999995}, {\"match_weight\": -0.14, \"match_probability\": 0.47518, \"prop\": 0.0001, \"cum_prop\": 0.0036999999999999993}, {\"match_weight\": -0.06, \"match_probability\": 0.48903, \"prop\": 0.0001, \"cum_prop\": 0.003799999999999999}, {\"match_weight\": 0.71, \"match_probability\": 0.61988, \"prop\": 0.0002, \"cum_prop\": 0.003999999999999999}, {\"match_weight\": 1.15, \"match_probability\": 0.68898, \"prop\": 0.0001, \"cum_prop\": 0.0040999999999999995}, {\"match_weight\": 1.78, \"match_probability\": 0.77437, \"prop\": 0.0001, \"cum_prop\": 0.0042}, {\"match_weight\": 1.78, \"match_probability\": 0.775, \"prop\": 0.0001, \"cum_prop\": 0.0043}, {\"match_weight\": 1.86, \"match_probability\": 0.78363, \"prop\": 0.0001, \"cum_prop\": 0.0044}, {\"match_weight\": 1.89, \"match_probability\": 0.78769, \"prop\": 0.0001, \"cum_prop\": 0.0045000000000000005}, {\"match_weight\": 1.97, \"match_probability\": 0.79621, \"prop\": 0.0001, \"cum_prop\": 0.004600000000000001}, {\"match_weight\": 2.28, \"match_probability\": 0.82883, \"prop\": 0.0001, \"cum_prop\": 0.004700000000000001}, {\"match_weight\": 2.3, \"match_probability\": 0.83086, \"prop\": 0.0001, \"cum_prop\": 0.004800000000000001}, {\"match_weight\": 2.35, \"match_probability\": 0.83588, \"prop\": 0.0001, \"cum_prop\": 0.004900000000000002}, {\"match_weight\": 2.36, \"match_probability\": 0.83735, \"prop\": 0.0001, \"cum_prop\": 0.005000000000000002}, {\"match_weight\": 2.38, \"match_probability\": 0.83895, \"prop\": 0.0001, \"cum_prop\": 0.005100000000000002}, {\"match_weight\": 2.48, \"match_probability\": 0.84831, \"prop\": 0.0001, \"cum_prop\": 0.005200000000000002}, {\"match_weight\": 2.51, \"match_probability\": 0.85027, \"prop\": 0.0001, \"cum_prop\": 0.005300000000000003}, {\"match_weight\": 2.57, \"match_probability\": 0.85616, \"prop\": 0.0001, \"cum_prop\": 0.005400000000000003}, {\"match_weight\": 2.78, \"match_probability\": 0.87284, \"prop\": 0.0001, \"cum_prop\": 0.005500000000000003}, {\"match_weight\": 2.83, \"match_probability\": 0.87652, \"prop\": 0.0001, \"cum_prop\": 0.005600000000000003}, {\"match_weight\": 2.84, \"match_probability\": 0.87746, \"prop\": 0.0001, \"cum_prop\": 0.005700000000000004}, {\"match_weight\": 2.87, \"match_probability\": 0.87934, \"prop\": 0.0001, \"cum_prop\": 0.005800000000000004}, {\"match_weight\": 2.87, \"match_probability\": 0.8795, \"prop\": 0.0002, \"cum_prop\": 0.006000000000000004}, {\"match_weight\": 2.88, \"match_probability\": 0.88011, \"prop\": 0.0001, \"cum_prop\": 0.006100000000000004}, {\"match_weight\": 2.91, \"match_probability\": 0.88243, \"prop\": 0.0001, \"cum_prop\": 0.006200000000000004}, {\"match_weight\": 3.05, \"match_probability\": 0.89197, \"prop\": 0.0001, \"cum_prop\": 0.006300000000000004}, {\"match_weight\": 3.18, \"match_probability\": 0.9007, \"prop\": 0.0001, \"cum_prop\": 0.006400000000000005}, {\"match_weight\": 3.36, \"match_probability\": 0.91147, \"prop\": 0.0002, \"cum_prop\": 0.006600000000000004}, {\"match_weight\": 3.37, \"match_probability\": 0.91206, \"prop\": 0.0001, \"cum_prop\": 0.0067000000000000046}, {\"match_weight\": 3.4, \"match_probability\": 0.91366, \"prop\": 0.0001, \"cum_prop\": 0.006800000000000005}, {\"match_weight\": 3.44, \"match_probability\": 0.91572, \"prop\": 0.0001, \"cum_prop\": 0.006900000000000005}, {\"match_weight\": 3.44, \"match_probability\": 0.91585, \"prop\": 0.0001, \"cum_prop\": 0.007000000000000005}, {\"match_weight\": 3.46, \"match_probability\": 0.91645, \"prop\": 0.0001, \"cum_prop\": 0.007100000000000006}, {\"match_weight\": 3.47, \"match_probability\": 0.91719, \"prop\": 0.0002, \"cum_prop\": 0.007300000000000005}, {\"match_weight\": 3.52, \"match_probability\": 0.92, \"prop\": 0.0001, \"cum_prop\": 0.0074000000000000055}, {\"match_weight\": 3.7, \"match_probability\": 0.92839, \"prop\": 0.0002, \"cum_prop\": 0.007600000000000005}, {\"match_weight\": 3.83, \"match_probability\": 0.93446, \"prop\": 0.0001, \"cum_prop\": 0.0077000000000000055}, {\"match_weight\": 3.85, \"match_probability\": 0.93515, \"prop\": 0.0001, \"cum_prop\": 0.007800000000000006}, {\"match_weight\": 3.94, \"match_probability\": 0.93878, \"prop\": 0.0001, \"cum_prop\": 0.007900000000000006}, {\"match_weight\": 3.94, \"match_probability\": 0.93888, \"prop\": 0.0001, \"cum_prop\": 0.008000000000000005}, {\"match_weight\": 3.95, \"match_probability\": 0.9394, \"prop\": 0.0001, \"cum_prop\": 0.008100000000000005}, {\"match_weight\": 3.97, \"match_probability\": 0.93986, \"prop\": 0.0001, \"cum_prop\": 0.008200000000000004}, {\"match_weight\": 4.12, \"match_probability\": 0.94547, \"prop\": 0.0001, \"cum_prop\": 0.008300000000000004}, {\"match_weight\": 4.12, \"match_probability\": 0.94556, \"prop\": 0.0001, \"cum_prop\": 0.008400000000000003}, {\"match_weight\": 4.15, \"match_probability\": 0.94651, \"prop\": 0.0001, \"cum_prop\": 0.008500000000000002}, {\"match_weight\": 4.25, \"match_probability\": 0.95003, \"prop\": 0.0001, \"cum_prop\": 0.008600000000000002}, {\"match_weight\": 4.29, \"match_probability\": 0.9513, \"prop\": 0.0001, \"cum_prop\": 0.008700000000000001}, {\"match_weight\": 4.35, \"match_probability\": 0.95318, \"prop\": 0.0001, \"cum_prop\": 0.0088}, {\"match_weight\": 4.35, \"match_probability\": 0.95321, \"prop\": 0.0002, \"cum_prop\": 0.009000000000000001}, {\"match_weight\": 4.36, \"match_probability\": 0.9536, \"prop\": 0.0001, \"cum_prop\": 0.0091}, {\"match_weight\": 4.36, \"match_probability\": 0.95369, \"prop\": 0.0001, \"cum_prop\": 0.0092}, {\"match_weight\": 4.53, \"match_probability\": 0.95857, \"prop\": 0.0001, \"cum_prop\": 0.0093}, {\"match_weight\": 4.57, \"match_probability\": 0.95969, \"prop\": 0.0001, \"cum_prop\": 0.009399999999999999}, {\"match_weight\": 4.61, \"match_probability\": 0.96056, \"prop\": 0.0001, \"cum_prop\": 0.009499999999999998}, {\"match_weight\": 4.61, \"match_probability\": 0.96059, \"prop\": 0.0001, \"cum_prop\": 0.009599999999999997}, {\"match_weight\": 4.77, \"match_probability\": 0.96463, \"prop\": 0.0001, \"cum_prop\": 0.009699999999999997}, {\"match_weight\": 4.92, \"match_probability\": 0.96809, \"prop\": 0.0001, \"cum_prop\": 0.009799999999999996}, {\"match_weight\": 4.95, \"match_probability\": 0.96858, \"prop\": 0.0001, \"cum_prop\": 0.009899999999999996}, {\"match_weight\": 5.03, \"match_probability\": 0.9704, \"prop\": 0.0001, \"cum_prop\": 0.009999999999999995}, {\"match_weight\": 5.05, \"match_probability\": 0.97079, \"prop\": 0.0001, \"cum_prop\": 0.010099999999999994}, {\"match_weight\": 5.16, \"match_probability\": 0.97272, \"prop\": 0.0001, \"cum_prop\": 0.010199999999999994}, {\"match_weight\": 5.21, \"match_probability\": 0.97361, \"prop\": 0.0001, \"cum_prop\": 0.010299999999999993}, {\"match_weight\": 5.21, \"match_probability\": 0.97366, \"prop\": 0.0001, \"cum_prop\": 0.010399999999999993}, {\"match_weight\": 5.22, \"match_probability\": 0.97388, \"prop\": 0.0001, \"cum_prop\": 0.010499999999999992}, {\"match_weight\": 5.24, \"match_probability\": 0.97423, \"prop\": 0.0001, \"cum_prop\": 0.010599999999999991}, {\"match_weight\": 5.29, \"match_probability\": 0.97504, \"prop\": 0.0001, \"cum_prop\": 0.01069999999999999}, {\"match_weight\": 5.31, \"match_probability\": 0.97538, \"prop\": 0.0001, \"cum_prop\": 0.01079999999999999}, {\"match_weight\": 5.38, \"match_probability\": 0.97648, \"prop\": 0.0001, \"cum_prop\": 0.01089999999999999}, {\"match_weight\": 5.41, \"match_probability\": 0.97705, \"prop\": 0.0001, \"cum_prop\": 0.010999999999999989}, {\"match_weight\": 5.46, \"match_probability\": 0.97772, \"prop\": 0.0001, \"cum_prop\": 0.011099999999999988}, {\"match_weight\": 5.47, \"match_probability\": 0.97792, \"prop\": 0.0001, \"cum_prop\": 0.011199999999999988}, {\"match_weight\": 5.47, \"match_probability\": 0.97795, \"prop\": 0.0001, \"cum_prop\": 0.011299999999999987}, {\"match_weight\": 5.48, \"match_probability\": 0.97805, \"prop\": 0.0001, \"cum_prop\": 0.011399999999999987}, {\"match_weight\": 5.52, \"match_probability\": 0.97872, \"prop\": 0.0001, \"cum_prop\": 0.011499999999999986}, {\"match_weight\": 5.56, \"match_probability\": 0.97918, \"prop\": 0.0001, \"cum_prop\": 0.011599999999999985}, {\"match_weight\": 5.63, \"match_probability\": 0.98024, \"prop\": 0.0001, \"cum_prop\": 0.011699999999999985}, {\"match_weight\": 5.65, \"match_probability\": 0.9805, \"prop\": 0.0001, \"cum_prop\": 0.011799999999999984}, {\"match_weight\": 5.67, \"match_probability\": 0.98074, \"prop\": 0.0001, \"cum_prop\": 0.011899999999999984}, {\"match_weight\": 5.71, \"match_probability\": 0.9812, \"prop\": 0.0001, \"cum_prop\": 0.011999999999999983}, {\"match_weight\": 5.72, \"match_probability\": 0.98142, \"prop\": 0.0001, \"cum_prop\": 0.012099999999999982}, {\"match_weight\": 5.77, \"match_probability\": 0.98196, \"prop\": 0.0001, \"cum_prop\": 0.012199999999999982}, {\"match_weight\": 5.77, \"match_probability\": 0.98201, \"prop\": 0.0001, \"cum_prop\": 0.012299999999999981}, {\"match_weight\": 5.83, \"match_probability\": 0.98277, \"prop\": 0.0001, \"cum_prop\": 0.01239999999999998}, {\"match_weight\": 5.85, \"match_probability\": 0.98294, \"prop\": 0.0001, \"cum_prop\": 0.01249999999999998}, {\"match_weight\": 5.91, \"match_probability\": 0.98362, \"prop\": 0.0001, \"cum_prop\": 0.01259999999999998}, {\"match_weight\": 5.95, \"match_probability\": 0.98413, \"prop\": 0.0002, \"cum_prop\": 0.01279999999999998}, {\"match_weight\": 5.99, \"match_probability\": 0.98447, \"prop\": 0.0001, \"cum_prop\": 0.01289999999999998}, {\"match_weight\": 6.04, \"match_probability\": 0.98498, \"prop\": 0.0002, \"cum_prop\": 0.01309999999999998}, {\"match_weight\": 6.05, \"match_probability\": 0.98511, \"prop\": 0.0001, \"cum_prop\": 0.013199999999999979}, {\"match_weight\": 6.06, \"match_probability\": 0.98518, \"prop\": 0.0001, \"cum_prop\": 0.013299999999999979}, {\"match_weight\": 6.1, \"match_probability\": 0.98558, \"prop\": 0.0001, \"cum_prop\": 0.013399999999999978}, {\"match_weight\": 6.11, \"match_probability\": 0.98568, \"prop\": 0.0001, \"cum_prop\": 0.013499999999999977}, {\"match_weight\": 6.12, \"match_probability\": 0.98581, \"prop\": 0.0001, \"cum_prop\": 0.013599999999999977}, {\"match_weight\": 6.14, \"match_probability\": 0.98602, \"prop\": 0.0001, \"cum_prop\": 0.013699999999999976}, {\"match_weight\": 6.16, \"match_probability\": 0.98617, \"prop\": 0.0001, \"cum_prop\": 0.013799999999999975}, {\"match_weight\": 6.2, \"match_probability\": 0.98658, \"prop\": 0.0001, \"cum_prop\": 0.013899999999999975}, {\"match_weight\": 6.25, \"match_probability\": 0.98702, \"prop\": 0.0001, \"cum_prop\": 0.013999999999999974}, {\"match_weight\": 6.29, \"match_probability\": 0.98738, \"prop\": 0.0001, \"cum_prop\": 0.014099999999999974}, {\"match_weight\": 6.31, \"match_probability\": 0.98756, \"prop\": 0.0001, \"cum_prop\": 0.014199999999999973}, {\"match_weight\": 6.35, \"match_probability\": 0.98788, \"prop\": 0.0001, \"cum_prop\": 0.014299999999999972}, {\"match_weight\": 6.38, \"match_probability\": 0.98811, \"prop\": 0.0001, \"cum_prop\": 0.014399999999999972}, {\"match_weight\": 6.43, \"match_probability\": 0.98856, \"prop\": 0.0001, \"cum_prop\": 0.014499999999999971}, {\"match_weight\": 6.44, \"match_probability\": 0.98862, \"prop\": 0.0001, \"cum_prop\": 0.01459999999999997}, {\"match_weight\": 6.48, \"match_probability\": 0.9889, \"prop\": 0.0001, \"cum_prop\": 0.01469999999999997}, {\"match_weight\": 6.5, \"match_probability\": 0.98908, \"prop\": 0.0001, \"cum_prop\": 0.01479999999999997}, {\"match_weight\": 6.52, \"match_probability\": 0.98925, \"prop\": 0.0001, \"cum_prop\": 0.014899999999999969}, {\"match_weight\": 6.53, \"match_probability\": 0.98927, \"prop\": 0.0001, \"cum_prop\": 0.014999999999999968}, {\"match_weight\": 6.57, \"match_probability\": 0.98961, \"prop\": 0.0002, \"cum_prop\": 0.015199999999999969}, {\"match_weight\": 6.61, \"match_probability\": 0.98986, \"prop\": 0.0001, \"cum_prop\": 0.015299999999999968}, {\"match_weight\": 6.62, \"match_probability\": 0.98993, \"prop\": 0.0001, \"cum_prop\": 0.015399999999999968}, {\"match_weight\": 6.72, \"match_probability\": 0.99061, \"prop\": 0.0001, \"cum_prop\": 0.015499999999999967}, {\"match_weight\": 6.72, \"match_probability\": 0.99062, \"prop\": 0.0003, \"cum_prop\": 0.015799999999999967}, {\"match_weight\": 6.73, \"match_probability\": 0.99067, \"prop\": 0.0001, \"cum_prop\": 0.015899999999999966}, {\"match_weight\": 6.75, \"match_probability\": 0.9908, \"prop\": 0.0001, \"cum_prop\": 0.015999999999999966}, {\"match_weight\": 6.78, \"match_probability\": 0.99098, \"prop\": 0.0001, \"cum_prop\": 0.016099999999999965}, {\"match_weight\": 6.81, \"match_probability\": 0.99115, \"prop\": 0.0001, \"cum_prop\": 0.016199999999999964}, {\"match_weight\": 6.91, \"match_probability\": 0.99174, \"prop\": 0.0001, \"cum_prop\": 0.016299999999999964}, {\"match_weight\": 7.02, \"match_probability\": 0.99234, \"prop\": 0.0001, \"cum_prop\": 0.016399999999999963}, {\"match_weight\": 7.09, \"match_probability\": 0.99269, \"prop\": 0.0002, \"cum_prop\": 0.016599999999999962}, {\"match_weight\": 7.12, \"match_probability\": 0.99288, \"prop\": 0.0001, \"cum_prop\": 0.01669999999999996}, {\"match_weight\": 7.16, \"match_probability\": 0.99304, \"prop\": 0.0003, \"cum_prop\": 0.016999999999999963}, {\"match_weight\": 7.17, \"match_probability\": 0.99313, \"prop\": 0.0001, \"cum_prop\": 0.017099999999999962}, {\"match_weight\": 7.33, \"match_probability\": 0.99383, \"prop\": 0.0001, \"cum_prop\": 0.017199999999999962}, {\"match_weight\": 7.35, \"match_probability\": 0.9939, \"prop\": 0.0002, \"cum_prop\": 0.01739999999999996}, {\"match_weight\": 7.36, \"match_probability\": 0.99395, \"prop\": 0.0001, \"cum_prop\": 0.01749999999999996}, {\"match_weight\": 7.39, \"match_probability\": 0.99408, \"prop\": 0.0001, \"cum_prop\": 0.01759999999999996}, {\"match_weight\": 7.4, \"match_probability\": 0.99413, \"prop\": 0.0001, \"cum_prop\": 0.01769999999999996}, {\"match_weight\": 7.41, \"match_probability\": 0.99416, \"prop\": 0.0001, \"cum_prop\": 0.017799999999999958}, {\"match_weight\": 7.44, \"match_probability\": 0.99428, \"prop\": 0.0001, \"cum_prop\": 0.017899999999999958}, {\"match_weight\": 7.51, \"match_probability\": 0.99453, \"prop\": 0.0002, \"cum_prop\": 0.018099999999999956}, {\"match_weight\": 7.51, \"match_probability\": 0.99456, \"prop\": 0.0001, \"cum_prop\": 0.018199999999999956}, {\"match_weight\": 7.52, \"match_probability\": 0.99459, \"prop\": 0.0001, \"cum_prop\": 0.018299999999999955}, {\"match_weight\": 7.57, \"match_probability\": 0.99477, \"prop\": 0.0002, \"cum_prop\": 0.018499999999999954}, {\"match_weight\": 7.58, \"match_probability\": 0.99479, \"prop\": 0.0001, \"cum_prop\": 0.018599999999999953}, {\"match_weight\": 7.65, \"match_probability\": 0.99505, \"prop\": 0.0001, \"cum_prop\": 0.018699999999999953}, {\"match_weight\": 7.72, \"match_probability\": 0.99529, \"prop\": 0.0001, \"cum_prop\": 0.018799999999999952}, {\"match_weight\": 7.78, \"match_probability\": 0.99547, \"prop\": 0.0001, \"cum_prop\": 0.01889999999999995}, {\"match_weight\": 7.89, \"match_probability\": 0.99581, \"prop\": 0.0003, \"cum_prop\": 0.019199999999999953}, {\"match_weight\": 7.92, \"match_probability\": 0.99588, \"prop\": 0.0001, \"cum_prop\": 0.019299999999999953}, {\"match_weight\": 7.93, \"match_probability\": 0.99593, \"prop\": 0.0001, \"cum_prop\": 0.019399999999999952}, {\"match_weight\": 7.95, \"match_probability\": 0.99597, \"prop\": 0.0002, \"cum_prop\": 0.01959999999999995}, {\"match_weight\": 7.96, \"match_probability\": 0.99599, \"prop\": 0.0002, \"cum_prop\": 0.01979999999999995}, {\"match_weight\": 7.96, \"match_probability\": 0.99601, \"prop\": 0.0001, \"cum_prop\": 0.01989999999999995}, {\"match_weight\": 7.97, \"match_probability\": 0.99603, \"prop\": 0.0001, \"cum_prop\": 0.01999999999999995}, {\"match_weight\": 8.02, \"match_probability\": 0.99616, \"prop\": 0.0002, \"cum_prop\": 0.020199999999999947}, {\"match_weight\": 8.02, \"match_probability\": 0.99617, \"prop\": 0.0001, \"cum_prop\": 0.020299999999999947}, {\"match_weight\": 8.1, \"match_probability\": 0.99636, \"prop\": 0.0001, \"cum_prop\": 0.020399999999999946}, {\"match_weight\": 8.11, \"match_probability\": 0.9964, \"prop\": 0.0001, \"cum_prop\": 0.020499999999999945}, {\"match_weight\": 8.16, \"match_probability\": 0.99651, \"prop\": 0.0001, \"cum_prop\": 0.020599999999999945}, {\"match_weight\": 8.2, \"match_probability\": 0.99661, \"prop\": 0.0001, \"cum_prop\": 0.020699999999999944}, {\"match_weight\": 8.23, \"match_probability\": 0.99668, \"prop\": 0.0002, \"cum_prop\": 0.020899999999999943}, {\"match_weight\": 8.23, \"match_probability\": 0.99669, \"prop\": 0.0001, \"cum_prop\": 0.020999999999999942}, {\"match_weight\": 8.31, \"match_probability\": 0.99685, \"prop\": 0.0001, \"cum_prop\": 0.02109999999999994}, {\"match_weight\": 8.32, \"match_probability\": 0.99689, \"prop\": 0.0001, \"cum_prop\": 0.02119999999999994}, {\"match_weight\": 8.39, \"match_probability\": 0.99703, \"prop\": 0.0001, \"cum_prop\": 0.02129999999999994}, {\"match_weight\": 8.4, \"match_probability\": 0.99704, \"prop\": 0.0001, \"cum_prop\": 0.02139999999999994}, {\"match_weight\": 8.47, \"match_probability\": 0.99718, \"prop\": 0.0001, \"cum_prop\": 0.02149999999999994}, {\"match_weight\": 8.47, \"match_probability\": 0.99719, \"prop\": 0.0001, \"cum_prop\": 0.02159999999999994}, {\"match_weight\": 8.48, \"match_probability\": 0.99721, \"prop\": 0.0002, \"cum_prop\": 0.021799999999999937}, {\"match_weight\": 8.51, \"match_probability\": 0.99727, \"prop\": 0.0001, \"cum_prop\": 0.021899999999999937}, {\"match_weight\": 8.57, \"match_probability\": 0.99737, \"prop\": 0.0001, \"cum_prop\": 0.021999999999999936}, {\"match_weight\": 8.57, \"match_probability\": 0.99738, \"prop\": 0.0002, \"cum_prop\": 0.022199999999999935}, {\"match_weight\": 8.58, \"match_probability\": 0.99739, \"prop\": 0.0001, \"cum_prop\": 0.022299999999999934}, {\"match_weight\": 8.67, \"match_probability\": 0.99755, \"prop\": 0.0002, \"cum_prop\": 0.022499999999999933}, {\"match_weight\": 8.67, \"match_probability\": 0.99756, \"prop\": 0.0001, \"cum_prop\": 0.022599999999999933}, {\"match_weight\": 8.73, \"match_probability\": 0.99765, \"prop\": 0.0001, \"cum_prop\": 0.022699999999999932}, {\"match_weight\": 8.84, \"match_probability\": 0.99783, \"prop\": 0.0001, \"cum_prop\": 0.02279999999999993}, {\"match_weight\": 8.86, \"match_probability\": 0.99786, \"prop\": 0.0001, \"cum_prop\": 0.02289999999999993}, {\"match_weight\": 8.9, \"match_probability\": 0.9979, \"prop\": 0.0003, \"cum_prop\": 0.023199999999999932}, {\"match_weight\": 8.9, \"match_probability\": 0.99791, \"prop\": 0.0001, \"cum_prop\": 0.023299999999999932}, {\"match_weight\": 8.98, \"match_probability\": 0.99802, \"prop\": 0.0001, \"cum_prop\": 0.02339999999999993}, {\"match_weight\": 9.04, \"match_probability\": 0.9981, \"prop\": 0.0001, \"cum_prop\": 0.02349999999999993}, {\"match_weight\": 9.06, \"match_probability\": 0.99812, \"prop\": 0.0001, \"cum_prop\": 0.02359999999999993}, {\"match_weight\": 9.09, \"match_probability\": 0.99817, \"prop\": 0.0001, \"cum_prop\": 0.02369999999999993}, {\"match_weight\": 9.13, \"match_probability\": 0.99822, \"prop\": 0.0001, \"cum_prop\": 0.02379999999999993}, {\"match_weight\": 9.15, \"match_probability\": 0.99825, \"prop\": 0.0001, \"cum_prop\": 0.023899999999999928}, {\"match_weight\": 9.18, \"match_probability\": 0.99828, \"prop\": 0.0001, \"cum_prop\": 0.023999999999999928}, {\"match_weight\": 9.19, \"match_probability\": 0.99829, \"prop\": 0.0001, \"cum_prop\": 0.024099999999999927}, {\"match_weight\": 9.26, \"match_probability\": 0.99838, \"prop\": 0.0001, \"cum_prop\": 0.024199999999999926}, {\"match_weight\": 9.31, \"match_probability\": 0.99843, \"prop\": 0.0004, \"cum_prop\": 0.024599999999999927}, {\"match_weight\": 9.36, \"match_probability\": 0.99848, \"prop\": 0.0001, \"cum_prop\": 0.024699999999999927}, {\"match_weight\": 9.38, \"match_probability\": 0.9985, \"prop\": 0.0002, \"cum_prop\": 0.024899999999999926}, {\"match_weight\": 9.41, \"match_probability\": 0.99853, \"prop\": 0.0002, \"cum_prop\": 0.025099999999999924}, {\"match_weight\": 9.42, \"match_probability\": 0.99854, \"prop\": 0.0001, \"cum_prop\": 0.025199999999999924}, {\"match_weight\": 9.48, \"match_probability\": 0.9986, \"prop\": 0.0001, \"cum_prop\": 0.025299999999999923}, {\"match_weight\": 9.49, \"match_probability\": 0.99861, \"prop\": 0.0001, \"cum_prop\": 0.025399999999999923}, {\"match_weight\": 9.5, \"match_probability\": 0.99862, \"prop\": 0.0001, \"cum_prop\": 0.025499999999999922}, {\"match_weight\": 9.52, \"match_probability\": 0.99864, \"prop\": 0.0002, \"cum_prop\": 0.02569999999999992}, {\"match_weight\": 9.58, \"match_probability\": 0.99869, \"prop\": 0.0002, \"cum_prop\": 0.02589999999999992}, {\"match_weight\": 9.58, \"match_probability\": 0.9987, \"prop\": 0.0001, \"cum_prop\": 0.02599999999999992}, {\"match_weight\": 9.66, \"match_probability\": 0.99876, \"prop\": 0.0001, \"cum_prop\": 0.02609999999999992}, {\"match_weight\": 9.67, \"match_probability\": 0.99877, \"prop\": 0.0001, \"cum_prop\": 0.026199999999999918}, {\"match_weight\": 9.67, \"match_probability\": 0.99878, \"prop\": 0.0001, \"cum_prop\": 0.026299999999999917}, {\"match_weight\": 9.7, \"match_probability\": 0.9988, \"prop\": 0.0001, \"cum_prop\": 0.026399999999999917}, {\"match_weight\": 9.71, \"match_probability\": 0.99881, \"prop\": 0.0001, \"cum_prop\": 0.026499999999999916}, {\"match_weight\": 9.74, \"match_probability\": 0.99883, \"prop\": 0.0002, \"cum_prop\": 0.026699999999999915}, {\"match_weight\": 9.78, \"match_probability\": 0.99887, \"prop\": 0.0001, \"cum_prop\": 0.026799999999999914}, {\"match_weight\": 9.84, \"match_probability\": 0.99891, \"prop\": 0.0001, \"cum_prop\": 0.026899999999999914}, {\"match_weight\": 9.86, \"match_probability\": 0.99893, \"prop\": 0.0001, \"cum_prop\": 0.026999999999999913}, {\"match_weight\": 9.88, \"match_probability\": 0.99894, \"prop\": 0.0001, \"cum_prop\": 0.027099999999999912}, {\"match_weight\": 9.9, \"match_probability\": 0.99895, \"prop\": 0.0003, \"cum_prop\": 0.027399999999999914}, {\"match_weight\": 9.91, \"match_probability\": 0.99896, \"prop\": 0.0001, \"cum_prop\": 0.027499999999999913}, {\"match_weight\": 9.95, \"match_probability\": 0.99899, \"prop\": 0.0001, \"cum_prop\": 0.027599999999999913}, {\"match_weight\": 10.0, \"match_probability\": 0.99902, \"prop\": 0.0001, \"cum_prop\": 0.027699999999999912}, {\"match_weight\": 10.05, \"match_probability\": 0.99906, \"prop\": 0.0001, \"cum_prop\": 0.02779999999999991}, {\"match_weight\": 10.09, \"match_probability\": 0.99908, \"prop\": 0.0002, \"cum_prop\": 0.02799999999999991}, {\"match_weight\": 10.11, \"match_probability\": 0.9991, \"prop\": 0.0001, \"cum_prop\": 0.02809999999999991}, {\"match_weight\": 10.13, \"match_probability\": 0.99911, \"prop\": 0.0002, \"cum_prop\": 0.02829999999999991}, {\"match_weight\": 10.16, \"match_probability\": 0.99912, \"prop\": 0.0003, \"cum_prop\": 0.02859999999999991}, {\"match_weight\": 10.16, \"match_probability\": 0.99913, \"prop\": 0.0001, \"cum_prop\": 0.02869999999999991}, {\"match_weight\": 10.26, \"match_probability\": 0.99918, \"prop\": 0.0002, \"cum_prop\": 0.02889999999999991}, {\"match_weight\": 10.28, \"match_probability\": 0.9992, \"prop\": 0.0001, \"cum_prop\": 0.028999999999999908}, {\"match_weight\": 10.31, \"match_probability\": 0.99922, \"prop\": 0.0001, \"cum_prop\": 0.029099999999999907}, {\"match_weight\": 10.37, \"match_probability\": 0.99925, \"prop\": 0.0001, \"cum_prop\": 0.029199999999999907}, {\"match_weight\": 10.41, \"match_probability\": 0.99927, \"prop\": 0.0001, \"cum_prop\": 0.029299999999999906}, {\"match_weight\": 10.44, \"match_probability\": 0.99928, \"prop\": 0.0001, \"cum_prop\": 0.029399999999999905}, {\"match_weight\": 10.47, \"match_probability\": 0.99929, \"prop\": 0.0001, \"cum_prop\": 0.029499999999999905}, {\"match_weight\": 10.48, \"match_probability\": 0.9993, \"prop\": 0.0011, \"cum_prop\": 0.030599999999999905}, {\"match_weight\": 10.54, \"match_probability\": 0.99933, \"prop\": 0.0003, \"cum_prop\": 0.030899999999999907}, {\"match_weight\": 10.56, \"match_probability\": 0.99934, \"prop\": 0.0003, \"cum_prop\": 0.03119999999999991}, {\"match_weight\": 10.6, \"match_probability\": 0.99936, \"prop\": 0.0001, \"cum_prop\": 0.03129999999999991}, {\"match_weight\": 10.63, \"match_probability\": 0.99937, \"prop\": 0.0001, \"cum_prop\": 0.031399999999999914}, {\"match_weight\": 10.69, \"match_probability\": 0.99939, \"prop\": 0.0002, \"cum_prop\": 0.03159999999999991}, {\"match_weight\": 10.72, \"match_probability\": 0.99941, \"prop\": 0.0002, \"cum_prop\": 0.03179999999999991}, {\"match_weight\": 10.76, \"match_probability\": 0.99942, \"prop\": 0.0001, \"cum_prop\": 0.031899999999999915}, {\"match_weight\": 10.79, \"match_probability\": 0.99943, \"prop\": 0.0001, \"cum_prop\": 0.03199999999999992}, {\"match_weight\": 10.79, \"match_probability\": 0.99944, \"prop\": 0.0001, \"cum_prop\": 0.03209999999999992}, {\"match_weight\": 10.84, \"match_probability\": 0.99945, \"prop\": 0.0001, \"cum_prop\": 0.03219999999999992}, {\"match_weight\": 10.84, \"match_probability\": 0.99946, \"prop\": 0.0001, \"cum_prop\": 0.032299999999999926}, {\"match_weight\": 10.89, \"match_probability\": 0.99947, \"prop\": 0.0003, \"cum_prop\": 0.03259999999999993}, {\"match_weight\": 10.9, \"match_probability\": 0.99948, \"prop\": 0.0002, \"cum_prop\": 0.032799999999999926}, {\"match_weight\": 10.93, \"match_probability\": 0.99949, \"prop\": 0.0001, \"cum_prop\": 0.03289999999999993}, {\"match_weight\": 10.98, \"match_probability\": 0.9995, \"prop\": 0.0001, \"cum_prop\": 0.03299999999999993}, {\"match_weight\": 10.98, \"match_probability\": 0.99951, \"prop\": 0.0001, \"cum_prop\": 0.033099999999999935}, {\"match_weight\": 11.01, \"match_probability\": 0.99952, \"prop\": 0.0002, \"cum_prop\": 0.033299999999999934}, {\"match_weight\": 11.04, \"match_probability\": 0.99953, \"prop\": 0.0001, \"cum_prop\": 0.03339999999999994}, {\"match_weight\": 11.09, \"match_probability\": 0.99954, \"prop\": 0.0001, \"cum_prop\": 0.03349999999999994}, {\"match_weight\": 11.11, \"match_probability\": 0.99955, \"prop\": 0.0001, \"cum_prop\": 0.03359999999999994}, {\"match_weight\": 11.22, \"match_probability\": 0.99958, \"prop\": 0.0001, \"cum_prop\": 0.033699999999999945}, {\"match_weight\": 11.29, \"match_probability\": 0.9996, \"prop\": 0.0002, \"cum_prop\": 0.033899999999999944}, {\"match_weight\": 11.34, \"match_probability\": 0.99961, \"prop\": 0.0001, \"cum_prop\": 0.03399999999999995}, {\"match_weight\": 11.37, \"match_probability\": 0.99962, \"prop\": 0.0004, \"cum_prop\": 0.034399999999999945}, {\"match_weight\": 11.42, \"match_probability\": 0.99963, \"prop\": 0.0002, \"cum_prop\": 0.03459999999999994}, {\"match_weight\": 11.49, \"match_probability\": 0.99965, \"prop\": 0.001, \"cum_prop\": 0.035599999999999944}, {\"match_weight\": 11.59, \"match_probability\": 0.99967, \"prop\": 0.0008, \"cum_prop\": 0.036399999999999946}, {\"match_weight\": 11.68, \"match_probability\": 0.99969, \"prop\": 0.0005, \"cum_prop\": 0.03689999999999995}, {\"match_weight\": 11.71, \"match_probability\": 0.9997, \"prop\": 0.0004, \"cum_prop\": 0.037299999999999944}, {\"match_weight\": 11.77, \"match_probability\": 0.99971, \"prop\": 0.0002, \"cum_prop\": 0.03749999999999994}, {\"match_weight\": 11.78, \"match_probability\": 0.99972, \"prop\": 0.0002, \"cum_prop\": 0.03769999999999994}, {\"match_weight\": 11.87, \"match_probability\": 0.99973, \"prop\": 0.002, \"cum_prop\": 0.039699999999999944}, {\"match_weight\": 11.92, \"match_probability\": 0.99974, \"prop\": 0.0007, \"cum_prop\": 0.04039999999999994}, {\"match_weight\": 11.99, \"match_probability\": 0.99975, \"prop\": 0.0003, \"cum_prop\": 0.040699999999999945}, {\"match_weight\": 12.03, \"match_probability\": 0.99976, \"prop\": 0.0004, \"cum_prop\": 0.04109999999999994}, {\"match_weight\": 12.11, \"match_probability\": 0.99977, \"prop\": 0.0002, \"cum_prop\": 0.04129999999999994}, {\"match_weight\": 12.17, \"match_probability\": 0.99978, \"prop\": 0.0004, \"cum_prop\": 0.04169999999999994}, {\"match_weight\": 12.22, \"match_probability\": 0.99979, \"prop\": 0.0006, \"cum_prop\": 0.04229999999999994}, {\"match_weight\": 12.32, \"match_probability\": 0.9998, \"prop\": 0.0005, \"cum_prop\": 0.04279999999999994}, {\"match_weight\": 12.39, \"match_probability\": 0.99981, \"prop\": 0.0004, \"cum_prop\": 0.04319999999999994}, {\"match_weight\": 12.48, \"match_probability\": 0.99982, \"prop\": 0.0007, \"cum_prop\": 0.04389999999999994}, {\"match_weight\": 12.55, \"match_probability\": 0.99983, \"prop\": 0.0007, \"cum_prop\": 0.04459999999999994}, {\"match_weight\": 12.64, \"match_probability\": 0.99984, \"prop\": 0.001, \"cum_prop\": 0.04559999999999994}, {\"match_weight\": 12.75, \"match_probability\": 0.99985, \"prop\": 0.0007, \"cum_prop\": 0.04629999999999994}, {\"match_weight\": 12.85, \"match_probability\": 0.99986, \"prop\": 0.001, \"cum_prop\": 0.04729999999999994}, {\"match_weight\": 12.96, \"match_probability\": 0.99987, \"prop\": 0.0007, \"cum_prop\": 0.04799999999999994}, {\"match_weight\": 13.09, \"match_probability\": 0.99988, \"prop\": 0.0009, \"cum_prop\": 0.04889999999999994}, {\"match_weight\": 13.21, \"match_probability\": 0.99989, \"prop\": 0.0015, \"cum_prop\": 0.05039999999999994}, {\"match_weight\": 13.35, \"match_probability\": 0.9999, \"prop\": 0.0008, \"cum_prop\": 0.05119999999999994}, {\"match_weight\": 13.51, \"match_probability\": 0.99991, \"prop\": 0.0015, \"cum_prop\": 0.05269999999999994}, {\"match_weight\": 13.67, \"match_probability\": 0.99992, \"prop\": 0.0018, \"cum_prop\": 0.054499999999999944}, {\"match_weight\": 13.89, \"match_probability\": 0.99993, \"prop\": 0.0015, \"cum_prop\": 0.055999999999999946}, {\"match_weight\": 14.14, \"match_probability\": 0.99994, \"prop\": 0.0027, \"cum_prop\": 0.05869999999999995}, {\"match_weight\": 14.44, \"match_probability\": 0.99995, \"prop\": 0.0027, \"cum_prop\": 0.06139999999999995}, {\"match_weight\": 14.8, \"match_probability\": 0.99996, \"prop\": 0.0042, \"cum_prop\": 0.06559999999999995}, {\"match_weight\": 15.28, \"match_probability\": 0.99997, \"prop\": 0.0057, \"cum_prop\": 0.07129999999999995}, {\"match_weight\": 16.02, \"match_probability\": 0.99998, \"prop\": 0.0084, \"cum_prop\": 0.07969999999999995}, {\"match_weight\": 17.61, \"match_probability\": 0.99999, \"prop\": 0.022, \"cum_prop\": 0.10169999999999996}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.unlinkables_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_name_l</th>\n",
       "      <th>first_name_r</th>\n",
       "      <th>gamma_first_name</th>\n",
       "      <th>tf_first_name_l</th>\n",
       "      <th>tf_first_name_r</th>\n",
       "      <th>bf_first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>bf_birth_place</th>\n",
       "      <th>bf_tf_adj_birth_place</th>\n",
       "      <th>occupation_l</th>\n",
       "      <th>occupation_r</th>\n",
       "      <th>gamma_occupation</th>\n",
       "      <th>tf_occupation_l</th>\n",
       "      <th>tf_occupation_r</th>\n",
       "      <th>bf_occupation</th>\n",
       "      <th>bf_tf_adj_occupation</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.908286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Q7422529-2</td>\n",
       "      <td>Q7422529-3</td>\n",
       "      <td>sarah</td>\n",
       "      <td>sarah</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>46.376176</td>\n",
       "      <td>...</td>\n",
       "      <td>160.817163</td>\n",
       "      <td>3.188489</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.815419</td>\n",
       "      <td>0.875610</td>\n",
       "      <td>Q334210-11</td>\n",
       "      <td>Q334210-13</td>\n",
       "      <td>reginald</td>\n",
       "      <td>reginald</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>46.376176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.086449</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>Q334210-11</td>\n",
       "      <td>Q334210-2</td>\n",
       "      <td>reginald</td>\n",
       "      <td>reginald</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>46.376176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.895924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Q334210-11</td>\n",
       "      <td>Q334210-9</td>\n",
       "      <td>reginald</td>\n",
       "      <td>reginald</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>46.376176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.088896</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>Q6233309-3</td>\n",
       "      <td>Q6233309-4</td>\n",
       "      <td>john</td>\n",
       "      <td>john</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>46.376176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>politician</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.09218</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_weight  match_probability unique_id_l unique_id_r first_name_l  \\\n",
       "0     25.908286           1.000000  Q7422529-2  Q7422529-3        sarah   \n",
       "1      2.815419           0.875610  Q334210-11  Q334210-13     reginald   \n",
       "2     19.086449           0.999998  Q334210-11   Q334210-2     reginald   \n",
       "3     24.895924           1.000000  Q334210-11   Q334210-9     reginald   \n",
       "4     11.088896           0.999541  Q6233309-3  Q6233309-4         john   \n",
       "\n",
       "  first_name_r  gamma_first_name  tf_first_name_l  tf_first_name_r  \\\n",
       "0        sarah                 3         0.001603         0.001603   \n",
       "1     reginald                 3         0.002304         0.002304   \n",
       "2     reginald                 3         0.002304         0.002304   \n",
       "3     reginald                 3         0.002304         0.002304   \n",
       "4         john                 3         0.051598         0.051598   \n",
       "\n",
       "   bf_first_name  ...  bf_birth_place bf_tf_adj_birth_place occupation_l  \\\n",
       "0      46.376176  ...      160.817163              3.188489         None   \n",
       "1      46.376176  ...        0.170301              1.000000         None   \n",
       "2      46.376176  ...        0.170301              1.000000         None   \n",
       "3      46.376176  ...        0.170301              1.000000         None   \n",
       "4      46.376176  ...        0.170301              1.000000   politician   \n",
       "\n",
       "   occupation_r  gamma_occupation  tf_occupation_l  tf_occupation_r  \\\n",
       "0          None                -1              NaN             None   \n",
       "1          None                -1              NaN             None   \n",
       "2          None                -1              NaN             None   \n",
       "3          None                -1              NaN             None   \n",
       "4          None                -1          0.09218             None   \n",
       "\n",
       "   bf_occupation bf_tf_adj_occupation match_key  \n",
       "0            1.0                  1.0         0  \n",
       "1            1.0                  1.0         0  \n",
       "2            1.0                  1.0         0  \n",
       "3            1.0                  1.0         0  \n",
       "4            1.0                  1.0         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = linker.predict()\n",
    "df_e = df_predict.as_pandas_dataframe(limit=5)\n",
    "df_e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view rows in this dataset as a waterfall chart as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26.vega-embed details,\n",
       "  #altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3fe2286aaabb4fccb9f1bd71a03fdb26\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-d0333f7bb862de3e6c1ee947a27e1684\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 4, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-d0333f7bb862de3e6c1ee947a27e1684\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sarah\", \"value_r\": \"sarah\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.8991552177343958, \"bayes_factor\": 7.459894448927582, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 7.46 times more likely to be a match\", \"value_l\": \"sarah\", \"value_r\": \"sarah\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"leonard\", \"value_r\": \"leonard\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5294706724793722, \"bayes_factor\": 1.4433995123650296, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.44 times more likely to be a match\", \"value_l\": \"leonard\", \"value_r\": \"leonard\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 4.097648583892912, \"bayes_factor\": 17.120448415261805, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"1861-01-01\", \"value_r\": \"1862-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"log2_bayes_factor\": 6.652628738078518, \"bayes_factor\": 100.60991919080811, \"comparison_vector_value\": 1, \"m_probability\": 0.054240764701006354, \"u_probability\": 0.0005391194539987453, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is 100.61 times more likely to be a match\", \"value_l\": \"po9 2eq\", \"value_r\": \"po9 5ew\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 7.329277578014943, \"bayes_factor\": 160.8171634211113, \"comparison_vector_value\": 1, \"m_probability\": 0.8305787965393059, \"u_probability\": 0.005164739750845969, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 160.82 times more likely to be a match\", \"value_l\": \"havant\", \"value_r\": \"havant\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 1.6728728932616606, \"bayes_factor\": 3.1884889761829793, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.19 times more likely to be a match\", \"value_l\": \"havant\", \"value_r\": \"havant\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 25.90828631886309, \"bayes_factor\": 62975455.61675563, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.3755932616773827, \"bayes_factor\": 5.189491790558317, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.19 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.2664362666455783, \"bayes_factor\": 1.202832926970858, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.20 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1852-06-30\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"w1t 4bg\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 2.8154189640187415, \"bayes_factor\": 7.039236531116934, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.3755932616773827, \"bayes_factor\": 5.189491790558317, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.19 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.2664362666455783, \"bayes_factor\": 1.202832926970858, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.20 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 4.097648583892912, \"bayes_factor\": 17.120448415261805, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"1852-06-30\", \"value_r\": \"1852-08-30\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"log2_bayes_factor\": 12.173381027749148, \"bayes_factor\": 4619.051857044942, \"comparison_vector_value\": 3, \"m_probability\": 0.6869574386653682, \"u_probability\": 0.00014872260799965388, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,619.05 times more likely to be a match\", \"value_l\": \"w1t 4bg\", \"value_r\": \"w1t 4bg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 2}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 2}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 19.0864485756608, \"bayes_factor\": 556664.507581761, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.3755932616773827, \"bayes_factor\": 5.189491790558317, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.19 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.2664362666455783, \"bayes_factor\": 1.202832926970858, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.20 times more likely to be a match\", \"value_l\": \"esher\", \"value_r\": \"esher\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"column_name\": \"dob\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 8.378994717855353, \"bayes_factor\": 332.9114586242343, \"comparison_vector_value\": 3, \"m_probability\": 0.623315558644858, \"u_probability\": 0.001872316324648982, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 332.91 times more likely to be a match\", \"value_l\": \"1852-06-30\", \"value_r\": \"1852-06-30\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Term freq adjustment on dob with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 1.5281292246269753, \"bayes_factor\": 2.8841160664892915, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on dob makes comparison 2.88 times more likely to be a match\", \"value_l\": \"1852-06-30\", \"value_r\": \"1852-06-30\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"log2_bayes_factor\": 12.173381027749148, \"bayes_factor\": 4619.051857044942, \"comparison_vector_value\": 3, \"m_probability\": 0.6869574386653682, \"u_probability\": 0.00014872260799965388, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,619.05 times more likely to be a match\", \"value_l\": \"w1t 4bg\", \"value_r\": \"w1t 4bg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 3}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 3}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.895923934250217, \"bayes_factor\": 31219063.707783993, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"fitzgerald\", \"value_r\": \"fitzgerald\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"fitzgerald\", \"value_r\": \"fitzgerald\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1857-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"log2_bayes_factor\": 12.173381027749148, \"bayes_factor\": 4619.051857044942, \"comparison_vector_value\": 3, \"m_probability\": 0.6869574386653682, \"u_probability\": 0.00014872260799965388, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,619.05 times more likely to be a match\", \"value_l\": \"s18 1ps\", \"value_r\": \"s18 1ps\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"dronfield\", \"value_r\": \"north east derbyshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 4}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 4}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.088895826475477, \"bayes_factor\": 2178.162428558412, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.charts import waterfall_chart\n",
    "records_to_plot = df_e.to_dict(orient=\"records\")\n",
    "linker.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 1, root rows count 27\n",
      "Completed iteration 2, root rows count 1\n",
      "Completed iteration 3, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "clusters = linker.cluster_pairwise_predictions_at_threshold(df_predict, threshold_match_probability=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"./dashboards/50k_cluster.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbf323558e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.cluster_studio_dashboard(df_predict, clusters, \"dashboards/50k_cluster.html\", sampling_method='by_cluster_size', overwrite=True)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\n",
    "    src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b4e4a071b6db42c38ffd58372b18438b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b4e4a071b6db42c38ffd58372b18438b.vega-embed details,\n",
       "  #altair-viz-b4e4a071b6db42c38ffd58372b18438b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b4e4a071b6db42c38ffd58372b18438b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b4e4a071b6db42c38ffd58372b18438b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b4e4a071b6db42c38ffd58372b18438b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-8111401b5c4a621e9cf914562571809e\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-8111401b5c4a621e9cf914562571809e\": [{\"truth_threshold\": -25.02, \"match_probability\": 2.939202414470863e-08, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12024, \"tn\": 0, \"fp\": 8049, \"fn\": 0, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 1.0, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0, \"precision\": 0.5990136003586908, \"recall\": 1.0, \"specificity\": 0.0, \"npv\": 1, \"accuracy\": 0.5990136003586908, \"f1\": 0.7492288998971867, \"f2\": 0.8819258020507855, \"f0_5\": 0.6512413882750553, \"p4\": 0.0, \"phi\": 0}, {\"truth_threshold\": -24.18, \"match_probability\": 5.261319576792893e-08, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12023, \"tn\": 0, \"fp\": 8049, \"fn\": 1, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9999168330006654, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 8.316699933466401e-05, \"precision\": 0.5989936229573535, \"recall\": 0.9999168330006654, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5989637821949882, \"f1\": 0.7491899302093719, \"f2\": 0.8818653913859875, \"f0_5\": 0.6512154432793136, \"p4\": 0.0, \"phi\": -0.0057749889257644295}, {\"truth_threshold\": -24.1, \"match_probability\": 5.561309693145467e-08, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12022, \"tn\": 0, \"fp\": 8049, \"fn\": 2, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9998336660013307, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.00016633399866932801, \"precision\": 0.598973643565343, \"recall\": 0.9998336660013307, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5989139640312858, \"f1\": 0.7491509580931609, \"f2\": 0.8818049789487582, \"f0_5\": 0.6511894960350132, \"p4\": 0.0, \"phi\": -0.008167271113264681}, {\"truth_threshold\": -23.42, \"match_probability\": 8.909995051884308e-08, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12021, \"tn\": 0, \"fp\": 8049, \"fn\": 3, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.999750499001996, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.000249500998003992, \"precision\": 0.5989536621823617, \"recall\": 0.999750499001996, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5988641458675833, \"f1\": 0.7491119835483268, \"f2\": 0.8817445647390194, \"f0_5\": 0.6511635465418617, \"p4\": 0.0, \"phi\": -0.010003072604522417}, {\"truth_threshold\": -23.16, \"match_probability\": 1.0669529145157474e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12020, \"tn\": 0, \"fp\": 8049, \"fn\": 4, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9996673320026613, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.00033266799733865603, \"precision\": 0.598933678808112, \"recall\": 0.9996673320026613, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5988143277038809, \"f1\": 0.7490730065746425, \"f2\": 0.8816841487566933, \"f0_5\": 0.6511375947995667, \"p4\": 0.0, \"phi\": -0.011550841089327113}, {\"truth_threshold\": -23.12, \"match_probability\": 1.096949040514205e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12019, \"tn\": 0, \"fp\": 8049, \"fn\": 5, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9995841650033267, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.00041583499667332, \"precision\": 0.5989136934422962, \"recall\": 0.9995841650033267, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5987645095401783, \"f1\": 0.7490340271718808, \"f2\": 0.8816237310017018, \"f0_5\": 0.6511116408078357, \"p4\": 0.0, \"phi\": -0.012914554694341458}, {\"truth_threshold\": -22.740000000000002, \"match_probability\": 1.4275056525208533e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12016, \"tn\": 0, \"fp\": 8049, \"fn\": 8, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9993346640053227, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0006653359946773121, \"precision\": 0.5988537253924745, \"recall\": 0.9993346640053227, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.5986150550490709, \"f1\": 0.7489170743868615, \"f2\": 0.8814424670999546, \"f0_5\": 0.6510337653331022, \"p4\": 0.0, \"phi\": -0.016336984288022566}, {\"truth_threshold\": -22.72, \"match_probability\": 1.44743288594304e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12016, \"tn\": 1078, \"fp\": 6971, \"fn\": 8, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9993346640053227, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.0006653359946773121, \"precision\": 0.6328540580397114, \"recall\": 0.9993346640053227, \"specificity\": 0.13392968070567773, \"npv\": 0.992633517495396, \"accuracy\": 0.6523190355203508, \"f1\": 0.7749508239011963, \"f2\": 0.8956069346928432, \"f0_5\": 0.6829445732733143, \"p4\": 0.36183263140739014, \"phi\": 0.28871299222334706}, {\"truth_threshold\": -22.56, \"match_probability\": 1.6171981192325074e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12015, \"tn\": 1078, \"fp\": 6971, \"fn\": 9, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.999251497005988, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.0007485029940119761, \"precision\": 0.6328347203202359, \"recall\": 0.999251497005988, \"specificity\": 0.13392968070567773, \"npv\": 0.9917203311867525, \"accuracy\": 0.6522692173566482, \"f1\": 0.7749113189293776, \"f2\": 0.8955457499776394, \"f0_5\": 0.6829187886504183, \"p4\": 0.3617979659187549, \"phi\": 0.2884076581949078}, {\"truth_threshold\": -22.32, \"match_probability\": 1.9098990549882926e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12013, \"tn\": 1078, \"fp\": 6971, \"fn\": 11, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9990851630073186, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.000914836992681304, \"precision\": 0.6327960387694901, \"recall\": 0.9990851630073186, \"specificity\": 0.13392968070567773, \"npv\": 0.98989898989899, \"accuracy\": 0.6521695810292433, \"f1\": 0.7748323013415893, \"f2\": 0.8954233750745378, \"f0_5\": 0.6828672123692587, \"p4\": 0.3617286527148774, \"phi\": 0.28779798803882856}, {\"truth_threshold\": -22.240000000000002, \"match_probability\": 2.01879773478931e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12012, \"tn\": 1078, \"fp\": 6971, \"fn\": 12, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.999001996007984, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.000998003992015968, \"precision\": 0.6327766949375757, \"recall\": 0.999001996007984, \"specificity\": 0.13392968070567773, \"npv\": 0.9889908256880734, \"accuracy\": 0.6521197628655407, \"f1\": 0.7747927887251266, \"f2\": 0.8953621848864771, \"f0_5\": 0.6828414207103551, \"p4\": 0.3616940049962845, \"phi\": 0.287493650439212}, {\"truth_threshold\": -21.72, \"match_probability\": 2.894865352873749e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12011, \"tn\": 1078, \"fp\": 6971, \"fn\": 13, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9989188290086494, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.001081170991350632, \"precision\": 0.6327573490675377, \"recall\": 0.9989188290086494, \"specificity\": 0.13392968070567773, \"npv\": 0.9880843263061412, \"accuracy\": 0.6520699447018383, \"f1\": 0.7747532735599562, \"f2\": 0.8953009928739676, \"f0_5\": 0.6828156267054757, \"p4\": 0.36165936319768927, \"phi\": 0.2871896435144194}, {\"truth_threshold\": -21.62, \"match_probability\": 3.1026397983608945e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12009, \"tn\": 1078, \"fp\": 6971, \"fn\": 15, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9987524950099801, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.00124750499001996, \"precision\": 0.6327186512118019, \"recall\": 0.9987524950099801, \"specificity\": 0.13392968070567773, \"npv\": 0.9862763037511436, \"accuracy\": 0.6519703083744334, \"f1\": 0.7746742355825055, \"f2\": 0.8951786033752758, \"f0_5\": 0.6827640316565087, \"p4\": 0.361590097353797, \"phi\": 0.2865826187707468}, {\"truth_threshold\": -21.56, \"match_probability\": 3.2343957153991476e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12006, \"tn\": 1078, \"fp\": 6971, \"fn\": 18, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9985029940119761, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.0014970059880239522, \"precision\": 0.6326605891342151, \"recall\": 0.9985029940119761, \"specificity\": 0.13392968070567773, \"npv\": 0.9835766423357665, \"accuracy\": 0.6518208538833259, \"f1\": 0.774555659494855, \"f2\": 0.8949950054418321, \"f0_5\": 0.6826866214802347, \"p4\": 0.36148624294611303, \"phi\": 0.28567454353542177}, {\"truth_threshold\": -21.54, \"match_probability\": 3.279546182213909e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12005, \"tn\": 1078, \"fp\": 6971, \"fn\": 19, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9984198270126414, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.001580172987358616, \"precision\": 0.6326412310286678, \"recall\": 0.9984198270126414, \"specificity\": 0.13392968070567773, \"npv\": 0.9826800364630811, \"accuracy\": 0.6517710357196234, \"f1\": 0.7745161290322581, \"f2\": 0.894933802480916, \"f0_5\": 0.682660813392776, \"p4\": 0.36145163663237273, \"phi\": 0.2853725054050322}, {\"truth_threshold\": -21.36, \"match_probability\": 3.715344858999198e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12001, \"tn\": 1078, \"fp\": 6971, \"fn\": 23, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9980871590153028, \"tn_rate\": 0.13392968070567773, \"fp_rate\": 0.8660703192943223, \"fn_rate\": 0.0019128409846972721, \"precision\": 0.6325637781994519, \"recall\": 0.9980871590153028, \"specificity\": 0.13392968070567773, \"npv\": 0.9791099000908265, \"accuracy\": 0.6515717630648135, \"f1\": 0.7743579816750549, \"f2\": 0.8946889723862349, \"f0_5\": 0.6825575575575575, \"p4\": 0.36131327044364253, \"phi\": 0.28416760186268636}, {\"truth_threshold\": -21.18, \"match_probability\": 4.2090541112717983e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12001, \"tn\": 1079, \"fp\": 6970, \"fn\": 23, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9980871590153028, \"tn_rate\": 0.13405391974158282, \"fp_rate\": 0.8659460802584172, \"fn_rate\": 0.0019128409846972721, \"precision\": 0.632597121922935, \"recall\": 0.9980871590153028, \"specificity\": 0.13405391974158282, \"npv\": 0.9791288566243194, \"accuracy\": 0.6516215812285159, \"f1\": 0.7743829649943539, \"f2\": 0.8947023126127603, \"f0_5\": 0.6825886153706148, \"p4\": 0.3615426253195168, \"phi\": 0.2843134374398186}, {\"truth_threshold\": -20.94, \"match_probability\": 4.970861638287614e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12001, \"tn\": 1080, \"fp\": 6969, \"fn\": 23, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9980871590153028, \"tn_rate\": 0.1341781587774879, \"fp_rate\": 0.8658218412225122, \"fn_rate\": 0.0019128409846972721, \"precision\": 0.6326304691618345, \"recall\": 0.9980871590153028, \"specificity\": 0.1341781587774879, \"npv\": 0.9791477787851315, \"accuracy\": 0.6516713993922184, \"f1\": 0.7744079499257921, \"f2\": 0.8947156532371097, \"f0_5\": 0.6826196760101929, \"p4\": 0.36177185106915327, \"phi\": 0.28445921391901174}, {\"truth_threshold\": -20.86, \"match_probability\": 5.254290279882799e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12001, \"tn\": 1084, \"fp\": 6965, \"fn\": 23, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9980871590153028, \"tn_rate\": 0.1346751149211082, \"fp_rate\": 0.8653248850788918, \"fn_rate\": 0.0019128409846972721, \"precision\": 0.6327638932827164, \"recall\": 0.9980871590153028, \"specificity\": 0.1346751149211082, \"npv\": 0.979223125564589, \"accuracy\": 0.6518706720470283, \"f1\": 0.7745079057760568, \"f2\": 0.8947690197131013, \"f0_5\": 0.6827439468414346, \"p4\": 0.36268746526033274, \"phi\": 0.285041730702249}, {\"truth_threshold\": -20.78, \"match_probability\": 5.553879449794111e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11999, \"tn\": 1084, \"fp\": 6965, \"fn\": 25, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9979208250166334, \"tn_rate\": 0.1346751149211082, \"fp_rate\": 0.8653248850788918, \"fn_rate\": 0.0020791749833666, \"precision\": 0.6327251634676229, \"recall\": 0.9979208250166334, \"specificity\": 0.1346751149211082, \"npv\": 0.9774571686203787, \"accuracy\": 0.6517710357196234, \"f1\": 0.7744288111527042, \"f2\": 0.894646585147629, \"f0_5\": 0.6826923076923077, \"p4\": 0.3626181309650939, \"phi\": 0.28444278837160164}, {\"truth_threshold\": -20.7, \"match_probability\": 5.870550587631993e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11998, \"tn\": 1084, \"fp\": 6965, \"fn\": 26, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9978376580172987, \"tn_rate\": 0.1346751149211082, \"fp_rate\": 0.8653248850788918, \"fn_rate\": 0.002162341982701264, \"precision\": 0.6327057954964932, \"recall\": 0.9978376580172987, \"specificity\": 0.1346751149211082, \"npv\": 0.9765765765765766, \"accuracy\": 0.6517212175559209, \"f1\": 0.7743892600122632, \"f2\": 0.8945853651262321, \"f0_5\": 0.682666484591925, \"p4\": 0.3625834726737092, \"phi\": 0.28414379568432013}, {\"truth_threshold\": -20.66, \"match_probability\": 6.0355941296147e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11994, \"tn\": 1084, \"fp\": 6965, \"fn\": 30, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9975049900199601, \"tn_rate\": 0.1346751149211082, \"fp_rate\": 0.8653248850788918, \"fn_rate\": 0.00249500998003992, \"precision\": 0.6326283031805475, \"recall\": 0.9975049900199601, \"specificity\": 0.1346751149211082, \"npv\": 0.9730700179533214, \"accuracy\": 0.6515219449011109, \"f1\": 0.7742310299196333, \"f2\": 0.8943404667810007, \"f0_5\": 0.6825631686774414, \"p4\": 0.36244489851086714, \"phi\": 0.2829509986730983}, {\"truth_threshold\": -20.64, \"match_probability\": 6.119847832325859e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11994, \"tn\": 1095, \"fp\": 6954, \"fn\": 30, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9975049900199601, \"tn_rate\": 0.1360417443160641, \"fp_rate\": 0.8639582556839359, \"fn_rate\": 0.00249500998003992, \"precision\": 0.6329955668144395, \"recall\": 0.9975049900199601, \"specificity\": 0.1360417443160641, \"npv\": 0.9733333333333334, \"accuracy\": 0.6520699447018383, \"f1\": 0.7745060054242542, \"f2\": 0.8944872024342223, \"f0_5\": 0.6829051653457229, \"p4\": 0.3649510720923858, \"phi\": 0.28455798099559315}, {\"truth_threshold\": -20.28, \"match_probability\": 7.854369834792407e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11990, \"tn\": 1095, \"fp\": 6954, \"fn\": 34, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9971723220226214, \"tn_rate\": 0.1360417443160641, \"fp_rate\": 0.8639582556839359, \"fn_rate\": 0.0028276779773785763, \"precision\": 0.6329180743243243, \"recall\": 0.9971723220226214, \"specificity\": 0.1360417443160641, \"npv\": 0.9698848538529672, \"accuracy\": 0.6518706720470283, \"f1\": 0.7743477137690519, \"f2\": 0.8942422434367542, \"f0_5\": 0.6828018223234624, \"p4\": 0.36481191445778094, \"phi\": 0.2833757739528268}, {\"truth_threshold\": -20.26, \"match_probability\": 7.964012664444846e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11990, \"tn\": 1198, \"fp\": 6851, \"fn\": 34, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9971723220226214, \"tn_rate\": 0.1488383650142875, \"fp_rate\": 0.8511616349857125, \"fn_rate\": 0.0028276779773785763, \"precision\": 0.6363781115652035, \"recall\": 0.9971723220226214, \"specificity\": 0.1488383650142875, \"npv\": 0.9724025974025974, \"accuracy\": 0.6570019429083844, \"f1\": 0.7769317997732059, \"f2\": 0.8956182679235699, \"f0_5\": 0.6860209639767474, \"p4\": 0.3875478178004372, \"phi\": 0.29814172732310573}, {\"truth_threshold\": -20.18, \"match_probability\": 8.418104679317787e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11990, \"tn\": 1201, \"fp\": 6848, \"fn\": 34, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9971723220226214, \"tn_rate\": 0.14921108212200274, \"fp_rate\": 0.8507889178779973, \"fn_rate\": 0.0028276779773785763, \"precision\": 0.6364794564178787, \"recall\": 0.9971723220226214, \"specificity\": 0.14921108212200274, \"npv\": 0.9724696356275304, \"accuracy\": 0.6571513973994919, \"f1\": 0.777007322921392, \"f2\": 0.895658409776795, \"f0_5\": 0.6861151803698956, \"p4\": 0.3881911051580646, \"phi\": 0.29856329487126354}, {\"truth_threshold\": -20.16, \"match_probability\": 8.535616941155019e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11990, \"tn\": 1252, \"fp\": 6797, \"fn\": 34, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9971723220226214, \"tn_rate\": 0.1555472729531619, \"fp_rate\": 0.8444527270468382, \"fn_rate\": 0.0028276779773785763, \"precision\": 0.6382072709852558, \"recall\": 0.9971723220226214, \"specificity\": 0.1555472729531619, \"npv\": 0.973561430793157, \"accuracy\": 0.6596921237483186, \"f1\": 0.7782934666190646, \"f2\": 0.8963413722470583, \"f0_5\": 0.6877208277887396, \"p4\": 0.3989708523650267, \"phi\": 0.30566168937971266}, {\"truth_threshold\": -20.04, \"match_probability\": 9.275951816389499e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11989, \"tn\": 1252, \"fp\": 6797, \"fn\": 35, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9970891550232868, \"tn_rate\": 0.1555472729531619, \"fp_rate\": 0.8444527270468382, \"fn_rate\": 0.0029108449767132403, \"precision\": 0.6381880123496221, \"recall\": 0.9970891550232868, \"specificity\": 0.1555472729531619, \"npv\": 0.9728049728049728, \"accuracy\": 0.6596423055846161, \"f1\": 0.7782538136968516, \"f2\": 0.8962800155497742, \"f0_5\": 0.6876950256975036, \"p4\": 0.3989338608004028, \"phi\": 0.30538465379364543}, {\"truth_threshold\": -19.94, \"match_probability\": 9.941718334684598e-07, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11989, \"tn\": 1253, \"fp\": 6796, \"fn\": 35, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9970891550232868, \"tn_rate\": 0.15567151198906695, \"fp_rate\": 0.8443284880109331, \"fn_rate\": 0.0029108449767132403, \"precision\": 0.63822198562683, \"recall\": 0.9970891550232868, \"specificity\": 0.15567151198906695, \"npv\": 0.9728260869565217, \"accuracy\": 0.6596921237483186, \"f1\": 0.7782790742964718, \"f2\": 0.8962934166654207, \"f0_5\": 0.6877265843696939, \"p4\": 0.3991423160800391, \"phi\": 0.30552268515520403}, {\"truth_threshold\": -19.92, \"match_probability\": 1.0080499410957392e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11987, \"tn\": 1253, \"fp\": 6796, \"fn\": 37, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9969228210246174, \"tn_rate\": 0.15567151198906695, \"fp_rate\": 0.8443284880109331, \"fn_rate\": 0.0030771789753825684, \"precision\": 0.6381834637704307, \"recall\": 0.9969228210246174, \"specificity\": 0.15567151198906695, \"npv\": 0.9713178294573643, \"accuracy\": 0.6595924874209137, \"f1\": 0.7781997597948518, \"f2\": 0.896170696332182, \"f0_5\": 0.6876749736105374, \"p4\": 0.39906832492045513, \"phi\": 0.3049695776812393}, {\"truth_threshold\": -19.88, \"match_probability\": 1.036390053028924e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11986, \"tn\": 1253, \"fp\": 6796, \"fn\": 38, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9968396540252827, \"tn_rate\": 0.15567151198906695, \"fp_rate\": 0.8443284880109331, \"fn_rate\": 0.003160345974717232, \"precision\": 0.6381641997657331, \"recall\": 0.9968396540252827, \"specificity\": 0.15567151198906695, \"npv\": 0.9705654531371031, \"accuracy\": 0.6595426692572112, \"f1\": 0.7781600986820749, \"f2\": 0.8961093334130805, \"f0_5\": 0.6876491646778043, \"p4\": 0.3990313383220649, \"phi\": 0.3046934018841267}, {\"truth_threshold\": -19.86, \"match_probability\": 1.050857503825523e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11986, \"tn\": 1254, \"fp\": 6795, \"fn\": 38, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9968396540252827, \"tn_rate\": 0.15579575102497203, \"fp_rate\": 0.844204248975028, \"fn_rate\": 0.003160345974717232, \"precision\": 0.6381981790107023, \"recall\": 0.9968396540252827, \"specificity\": 0.15579575102497203, \"npv\": 0.9705882352941176, \"accuracy\": 0.6595924874209137, \"f1\": 0.7781853595195585, \"f2\": 0.8961227327780852, \"f0_5\": 0.68768072703906, \"p4\": 0.3992396449246772, \"phi\": 0.3048316928019599}, {\"truth_threshold\": -19.84, \"match_probability\": 1.0655269122817094e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11985, \"tn\": 1258, \"fp\": 6791, \"fn\": 39, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9967564870259481, \"tn_rate\": 0.15629270716859237, \"fp_rate\": 0.8437072928314077, \"fn_rate\": 0.003243512974051896, \"precision\": 0.6383148700468684, \"recall\": 0.9967564870259481, \"specificity\": 0.15629270716859237, \"npv\": 0.9699306090979183, \"accuracy\": 0.6597419419120211, \"f1\": 0.7782467532467533, \"f2\": 0.8961149659050126, \"f0_5\": 0.6877811954825085, \"p4\": 0.4000347311101664, \"phi\": 0.30510896488890943}, {\"truth_threshold\": -19.78, \"match_probability\": 1.1107752730476261e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11985, \"tn\": 1260, \"fp\": 6789, \"fn\": 39, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9967564870259481, \"tn_rate\": 0.15654118524040253, \"fp_rate\": 0.8434588147595975, \"fn_rate\": 0.003243512974051896, \"precision\": 0.6383828699264941, \"recall\": 0.9967564870259481, \"specificity\": 0.15654118524040253, \"npv\": 0.9699769053117783, \"accuracy\": 0.6598415782394261, \"f1\": 0.7782972920319501, \"f2\": 0.8961417676087932, \"f0_5\": 0.6878443526170799, \"p4\": 0.40045011557182697, \"phi\": 0.30538522794088685}, {\"truth_threshold\": -19.68, \"match_probability\": 1.190499365582357e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11980, \"tn\": 1260, \"fp\": 6789, \"fn\": 44, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9963406520292748, \"tn_rate\": 0.15654118524040253, \"fp_rate\": 0.8434588147595975, \"fn_rate\": 0.003659347970725216, \"precision\": 0.6382865363098726, \"recall\": 0.9963406520292748, \"specificity\": 0.15654118524040253, \"npv\": 0.9662576687116564, \"accuracy\": 0.6595924874209137, \"f1\": 0.7780989185853928, \"f2\": 0.8958348911986839, \"f0_5\": 0.687715269804822, \"p4\": 0.40026484917412297, \"phi\": 0.3040128760010468}, {\"truth_threshold\": -19.62, \"match_probability\": 1.241054764180587e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11971, \"tn\": 1260, \"fp\": 6789, \"fn\": 53, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9955921490352628, \"tn_rate\": 0.15654118524040253, \"fp_rate\": 0.8434588147595975, \"fn_rate\": 0.0044078509647371925, \"precision\": 0.6381130063965885, \"recall\": 0.9955921490352628, \"specificity\": 0.15654118524040253, \"npv\": 0.9596344249809596, \"accuracy\": 0.6591441239475913, \"f1\": 0.777741683991684, \"f2\": 0.8952823979897092, \"f0_5\": 0.6874827712946798, \"p4\": 0.399931746144391, \"phi\": 0.30155813666717873}, {\"truth_threshold\": -19.48, \"match_probability\": 1.3675244207830495e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11967, \"tn\": 1260, \"fp\": 6789, \"fn\": 57, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9952594810379242, \"tn_rate\": 0.15654118524040253, \"fp_rate\": 0.8434588147595975, \"fn_rate\": 0.004740518962075849, \"precision\": 0.6380358285348688, \"recall\": 0.9952594810379242, \"specificity\": 0.15654118524040253, \"npv\": 0.9567198177676538, \"accuracy\": 0.6589448512927814, \"f1\": 0.7775828460038986, \"f2\": 0.8950367977023873, \"f0_5\": 0.6873793768955059, \"p4\": 0.39978385547381, \"phi\": 0.3004734653534647}, {\"truth_threshold\": -19.38, \"match_probability\": 1.4656762397065895e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11967, \"tn\": 1261, \"fp\": 6788, \"fn\": 57, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9952594810379242, \"tn_rate\": 0.1566654242763076, \"fp_rate\": 0.8433345757236924, \"fn_rate\": 0.004740518962075849, \"precision\": 0.6380698480405226, \"recall\": 0.9952594810379242, \"specificity\": 0.1566654242763076, \"npv\": 0.956752655538695, \"accuracy\": 0.6589946694564839, \"f1\": 0.7776081094252575, \"f2\": 0.89505018623506, \"f0_5\": 0.6874109645696429, \"p4\": 0.3999911521787614, \"phi\": 0.30061329400917536}, {\"truth_threshold\": -19.26, \"match_probability\": 1.592801264380025e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11967, \"tn\": 1263, \"fp\": 6786, \"fn\": 57, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9952594810379242, \"tn_rate\": 0.15691390234811778, \"fp_rate\": 0.8430860976518822, \"fn_rate\": 0.004740518962075849, \"precision\": 0.6381378979363301, \"recall\": 0.9952594810379242, \"specificity\": 0.15691390234811778, \"npv\": 0.9568181818181818, \"accuracy\": 0.6590943057838888, \"f1\": 0.7776586411930987, \"f2\": 0.8950769645020868, \"f0_5\": 0.6874741486281538, \"p4\": 0.40040541975930166, \"phi\": 0.30089280420498576}, {\"truth_threshold\": -19.080000000000002, \"match_probability\": 1.8044585029675095e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11967, \"tn\": 2401, \"fp\": 5648, \"fn\": 57, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9952594810379242, \"tn_rate\": 0.2982979252081004, \"fp_rate\": 0.7017020747918996, \"fn_rate\": 0.004740518962075849, \"precision\": 0.6793641782571672, \"recall\": 0.9952594810379242, \"specificity\": 0.2982979252081004, \"npv\": 0.9768104149715215, \"accuracy\": 0.7157873760773178, \"f1\": 0.807517122709943, \"f2\": 0.9105781376025323, \"f0_5\": 0.725413413510499, \"p4\": 0.5837012264082122, \"phi\": 0.43889054630141455}, {\"truth_threshold\": -19.02, \"match_probability\": 1.8810860620589545e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11953, \"tn\": 2401, \"fp\": 5648, \"fn\": 71, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9940951430472389, \"tn_rate\": 0.2982979252081004, \"fp_rate\": 0.7017020747918996, \"fn_rate\": 0.005904856952761144, \"precision\": 0.6791091415260496, \"recall\": 0.9940951430472389, \"specificity\": 0.2982979252081004, \"npv\": 0.9712783171521036, \"accuracy\": 0.715089921785483, \"f1\": 0.8069535864978903, \"f2\": 0.9097066837146293, \"f0_5\": 0.725057019459407, \"p4\": 0.583057954755785, \"phi\": 0.4360834605871884}, {\"truth_threshold\": -18.98, \"match_probability\": 1.9339704872557063e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11952, \"tn\": 2401, \"fp\": 5648, \"fn\": 72, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9940119760479041, \"tn_rate\": 0.2982979252081004, \"fp_rate\": 0.7017020747918996, \"fn_rate\": 0.005988023952095809, \"precision\": 0.6790909090909091, \"recall\": 0.9940119760479041, \"specificity\": 0.2982979252081004, \"npv\": 0.9708855640921957, \"accuracy\": 0.7150401036217805, \"f1\": 0.8069133135295706, \"f2\": 0.9096444227959084, \"f0_5\": 0.7250315442104242, \"p4\": 0.5830120478549818, \"phi\": 0.43588365270434204}, {\"truth_threshold\": -18.900000000000002, \"match_probability\": 2.044241469521586e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11952, \"tn\": 2404, \"fp\": 5645, \"fn\": 72, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9940119760479041, \"tn_rate\": 0.29867064231581564, \"fp_rate\": 0.7013293576841844, \"fn_rate\": 0.005988023952095809, \"precision\": 0.6792066829573222, \"recall\": 0.9940119760479041, \"specificity\": 0.29867064231581564, \"npv\": 0.9709208400646203, \"accuracy\": 0.715189558112888, \"f1\": 0.806995037304615, \"f2\": 0.9096859634968718, \"f0_5\": 0.7251371159539873, \"p4\": 0.5833922983897093, \"phi\": 0.4362121338390092}, {\"truth_threshold\": -18.86, \"match_probability\": 2.1017127990503803e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11951, \"tn\": 2404, \"fp\": 5645, \"fn\": 73, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9939288090485695, \"tn_rate\": 0.29867064231581564, \"fp_rate\": 0.7013293576841844, \"fn_rate\": 0.006071190951430472, \"precision\": 0.6791884519208911, \"recall\": 0.9939288090485695, \"specificity\": 0.29867064231581564, \"npv\": 0.9705288655631813, \"accuracy\": 0.7151397399491854, \"f1\": 0.8069547602970966, \"f2\": 0.9096236984716556, \"f0_5\": 0.7251116396466363, \"p4\": 0.5833463830694793, \"phi\": 0.43601253495487907}, {\"truth_threshold\": -18.78, \"match_probability\": 2.2215480784545784e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11941, \"tn\": 2404, \"fp\": 5645, \"fn\": 83, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9930971390552229, \"tn_rate\": 0.29867064231581564, \"fp_rate\": 0.7013293576841844, \"fn_rate\": 0.006902860944777113, \"precision\": 0.6790060275218924, \"recall\": 0.9930971390552229, \"specificity\": 0.29867064231581564, \"npv\": 0.9666264575794129, \"accuracy\": 0.7146415583121606, \"f1\": 0.8065518405943938, \"f2\": 0.9090009439420237, \"f0_5\": 0.7248567404817405, \"p4\": 0.5828875302742005, \"phi\": 0.43402160978351984}, {\"truth_threshold\": -18.740000000000002, \"match_probability\": 2.2840041533901063e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11940, \"tn\": 2404, \"fp\": 5645, \"fn\": 84, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9930139720558883, \"tn_rate\": 0.29867064231581564, \"fp_rate\": 0.7013293576841844, \"fn_rate\": 0.006986027944111776, \"precision\": 0.6789877736707421, \"recall\": 0.9930139720558883, \"specificity\": 0.29867064231581564, \"npv\": 0.9662379421221865, \"accuracy\": 0.7145917401484582, \"f1\": 0.8065115336553075, \"f2\": 0.9089386580594083, \"f0_5\": 0.7248312369481812, \"p4\": 0.5828416750064378, \"phi\": 0.4338230216272149}, {\"truth_threshold\": -18.64, \"match_probability\": 2.4479346386340956e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11940, \"tn\": 2406, \"fp\": 5643, \"fn\": 84, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9930139720558883, \"tn_rate\": 0.2989191203876258, \"fp_rate\": 0.7010808796123742, \"fn_rate\": 0.006986027944111776, \"precision\": 0.6790650059716772, \"recall\": 0.9930139720558883, \"specificity\": 0.2989191203876258, \"npv\": 0.9662650602409638, \"accuracy\": 0.7146913764758631, \"f1\": 0.8065660147937987, \"f2\": 0.9089663362718677, \"f0_5\": 0.7249016465102724, \"p4\": 0.583094842057777, \"phi\": 0.4340428571883587}, {\"truth_threshold\": -18.48, \"match_probability\": 2.735045101325131e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11940, \"tn\": 2407, \"fp\": 5642, \"fn\": 84, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9930139720558883, \"tn_rate\": 0.2990433594235309, \"fp_rate\": 0.7009566405764691, \"fn_rate\": 0.006986027944111776, \"precision\": 0.6791036287111819, \"recall\": 0.9930139720558883, \"specificity\": 0.2990433594235309, \"npv\": 0.9662786029706945, \"accuracy\": 0.7147411946395655, \"f1\": 0.8065932581233534, \"f2\": 0.9089801760102317, \"f0_5\": 0.7249368564212162, \"p4\": 0.5832213590471825, \"phi\": 0.43415275234557826}, {\"truth_threshold\": -18.400000000000002, \"match_probability\": 2.8909915630084804e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11940, \"tn\": 2413, \"fp\": 5636, \"fn\": 84, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9930139720558883, \"tn_rate\": 0.2997887936389614, \"fp_rate\": 0.7002112063610386, \"fn_rate\": 0.006986027944111776, \"precision\": 0.6793354574419663, \"recall\": 0.9930139720558883, \"specificity\": 0.2997887936389614, \"npv\": 0.9663596315578694, \"accuracy\": 0.7150401036217805, \"f1\": 0.8067567567567567, \"f2\": 0.9090632232915093, \"f0_5\": 0.7251481877368574, \"p4\": 0.5839795313808311, \"phi\": 0.43481180740032116}, {\"truth_threshold\": -18.38, \"match_probability\": 2.9313481830057973e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11939, \"tn\": 2413, \"fp\": 5636, \"fn\": 85, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9929308050565535, \"tn_rate\": 0.2997887936389614, \"fp_rate\": 0.7002112063610386, \"fn_rate\": 0.007069194943446441, \"precision\": 0.6793172119487909, \"recall\": 0.9929308050565535, \"specificity\": 0.2997887936389614, \"npv\": 0.9659727782225781, \"accuracy\": 0.714990285458078, \"f1\": 0.8067164431230784, \"f2\": 0.909000928872714, \"f0_5\": 0.725122685972499, \"p4\": 0.583933640014225, \"phi\": 0.4346136525296875}, {\"truth_threshold\": -18.36, \"match_probability\": 2.9722681570985064e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11939, \"tn\": 2415, \"fp\": 5634, \"fn\": 85, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9929308050565535, \"tn_rate\": 0.30003727171077155, \"fp_rate\": 0.6999627282892285, \"fn_rate\": 0.007069194943446441, \"precision\": 0.6793945256928242, \"recall\": 0.9929308050565535, \"specificity\": 0.30003727171077155, \"npv\": 0.966, \"accuracy\": 0.715089921785483, \"f1\": 0.8067709565158631, \"f2\": 0.9090286131964854, \"f0_5\": 0.7251931580737645, \"p4\": 0.5841860015222473, \"phi\": 0.4348332932842041}, {\"truth_threshold\": -18.32, \"match_probability\": 3.0558297334917884e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11939, \"tn\": 2416, \"fp\": 5633, \"fn\": 85, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9929308050565535, \"tn_rate\": 0.30016151074667663, \"fp_rate\": 0.6998384892533234, \"fn_rate\": 0.007069194943446441, \"precision\": 0.6794331891645801, \"recall\": 0.9929308050565535, \"specificity\": 0.30016151074667663, \"npv\": 0.9660135945621752, \"accuracy\": 0.7151397399491854, \"f1\": 0.8067982159751318, \"f2\": 0.9090424559907413, \"f0_5\": 0.7252283992613471, \"p4\": 0.5843121161527558, \"phi\": 0.4349430911857565}, {\"truth_threshold\": -18.240000000000002, \"match_probability\": 3.2300665943862097e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11937, \"tn\": 2416, \"fp\": 5633, \"fn\": 87, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9927644710578842, \"tn_rate\": 0.30016151074667663, \"fp_rate\": 0.6998384892533234, \"fn_rate\": 0.007235528942115769, \"precision\": 0.6793966989186113, \"recall\": 0.9927644710578842, \"specificity\": 0.30016151074667663, \"npv\": 0.9652417099480624, \"accuracy\": 0.7150401036217805, \"f1\": 0.8067175778874096, \"f2\": 0.9089178570340816, \"f0_5\": 0.7251773911353032, \"p4\": 0.5842203221734967, \"phi\": 0.4345472803115908}, {\"truth_threshold\": -18.14, \"match_probability\": 3.4618988555055063e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11918, \"tn\": 2416, \"fp\": 5633, \"fn\": 106, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9911842980705257, \"tn_rate\": 0.30016151074667663, \"fp_rate\": 0.6998384892533234, \"fn_rate\": 0.008815701929474385, \"precision\": 0.6790496268018916, \"recall\": 0.9911842980705257, \"specificity\": 0.30016151074667663, \"npv\": 0.9579698651863601, \"accuracy\": 0.7140935585114333, \"f1\": 0.8059509721048183, \"f2\": 0.907733788291925, \"f0_5\": 0.7246923189181301, \"p4\": 0.5833493628072653, \"phi\": 0.43080501288360196}, {\"truth_threshold\": -18.1, \"match_probability\": 3.5592257334204593e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11915, \"tn\": 2416, \"fp\": 5633, \"fn\": 109, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9909347970725216, \"tn_rate\": 0.30016151074667663, \"fp_rate\": 0.6998384892533234, \"fn_rate\": 0.009065202927478377, \"precision\": 0.678994757237292, \"recall\": 0.9909347970725216, \"specificity\": 0.30016151074667663, \"npv\": 0.9568316831683168, \"accuracy\": 0.7139441040203258, \"f1\": 0.8058298390369268, \"f2\": 0.9075467674121016, \"f0_5\": 0.7246156465894716, \"p4\": 0.5832120217775596, \"phi\": 0.430217072204133}, {\"truth_threshold\": -18.0, \"match_probability\": 3.8146827137652828e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2416, \"fp\": 5633, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.30016151074667663, \"fp_rate\": 0.6998384892533234, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6788666552648082, \"recall\": 0.9903526280771789, \"specificity\": 0.30016151074667663, \"npv\": 0.9541864139020537, \"accuracy\": 0.7135953768744084, \"f1\": 0.8055470996110266, \"f2\": 0.9071103188750248, \"f0_5\": 0.7244366574195746, \"p4\": 0.5828917486445714, \"phi\": 0.42884830327145934}, {\"truth_threshold\": -17.92, \"match_probability\": 4.032187570443627e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2417, \"fp\": 5632, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.3002857497825817, \"fp_rate\": 0.6997142502174183, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6789053591790194, \"recall\": 0.9903526280771789, \"specificity\": 0.3002857497825817, \"npv\": 0.9542045005921832, \"accuracy\": 0.7136451950381109, \"f1\": 0.8055743471790014, \"f2\": 0.9071241391919069, \"f0_5\": 0.7244719166747785, \"p4\": 0.5830176766461884, \"phi\": 0.4289592319217793}, {\"truth_threshold\": -17.900000000000002, \"match_probability\": 4.088474581213888e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2423, \"fp\": 5626, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.30103118399801215, \"fp_rate\": 0.6989688160019878, \"fn_rate\": 0.009647371922821025, \"precision\": 0.67913767537356, \"recall\": 0.9903526280771789, \"specificity\": 0.30103118399801215, \"npv\": 0.9543127215439149, \"accuracy\": 0.7139441040203258, \"f1\": 0.8057378713038771, \"f2\": 0.9072070699375285, \"f0_5\": 0.7246835443037974, \"p4\": 0.5837723238318677, \"phi\": 0.42962447720579977}, {\"truth_threshold\": -17.78, \"match_probability\": 4.443086286379355e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2424, \"fp\": 5625, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.30115542303391724, \"fp_rate\": 0.6988445769660827, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6791764101979125, \"recall\": 0.9903526280771789, \"specificity\": 0.30115542303391724, \"npv\": 0.9543307086614173, \"accuracy\": 0.7139939221840284, \"f1\": 0.8057651317792739, \"f2\": 0.9072208932027, \"f0_5\": 0.7247188275962803, \"p4\": 0.583897945170218, \"phi\": 0.42973529711170905}, {\"truth_threshold\": -17.72, \"match_probability\": 4.631764452096345e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2425, \"fp\": 5624, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.3012796620698223, \"fp_rate\": 0.6987203379301776, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6792151494410221, \"recall\": 0.9903526280771789, \"specificity\": 0.3012796620698223, \"npv\": 0.9543486816214088, \"accuracy\": 0.7140437403477308, \"f1\": 0.8057923940993369, \"f2\": 0.9072347168891327, \"f0_5\": 0.7247541143246665, \"p4\": 0.5840235228185476, \"phi\": 0.4298461015375673}, {\"truth_threshold\": -17.7, \"match_probability\": 4.69642117070095e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2498, \"fp\": 5551, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.3103491116908933, \"fp_rate\": 0.6896508883091067, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6820551005212211, \"recall\": 0.9903526280771789, \"specificity\": 0.3103491116908933, \"npv\": 0.9556235654169855, \"accuracy\": 0.7176804662980123, \"f1\": 0.8077875385815555, \"f2\": 0.9082449851269926, \"f0_5\": 0.7273393598827266, \"p4\": 0.5930746570723919, \"phi\": 0.43789391895823593}, {\"truth_threshold\": -17.62, \"match_probability\": 4.964200574188029e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11908, \"tn\": 2499, \"fp\": 5550, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9903526280771789, \"tn_rate\": 0.3104733507267984, \"fp_rate\": 0.6895266492732016, \"fn_rate\": 0.009647371922821025, \"precision\": 0.6820941688624127, \"recall\": 0.9903526280771789, \"specificity\": 0.3104733507267984, \"npv\": 0.955640535372849, \"accuracy\": 0.7177302844617147, \"f1\": 0.8078149379282273, \"f2\": 0.9082588400402721, \"f0_5\": 0.7273749022673964, \"p4\": 0.5931970822839133, \"phi\": 0.4380036148467699}, {\"truth_threshold\": -17.6, \"match_probability\": 5.033497882967444e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11907, \"tn\": 2499, \"fp\": 5550, \"fn\": 117, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9902694610778443, \"tn_rate\": 0.3104733507267984, \"fp_rate\": 0.6895266492732016, \"fn_rate\": 0.009730538922155689, \"precision\": 0.6820759580683966, \"recall\": 0.9902694610778443, \"specificity\": 0.3104733507267984, \"npv\": 0.9552752293577982, \"accuracy\": 0.7176804662980123, \"f1\": 0.8077744988297547, \"f2\": 0.9081964212164203, \"f0_5\": 0.7273493622635977, \"p4\": 0.5931509799698471, \"phi\": 0.43781136144871985}, {\"truth_threshold\": -17.580000000000002, \"match_probability\": 5.103762536321944e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11906, \"tn\": 2499, \"fp\": 5550, \"fn\": 118, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9901862940785097, \"tn_rate\": 0.3104733507267984, \"fp_rate\": 0.6895266492732016, \"fn_rate\": 0.009813705921490353, \"precision\": 0.682057745187901, \"recall\": 0.9901862940785097, \"specificity\": 0.3104733507267984, \"npv\": 0.9549102025219717, \"accuracy\": 0.7176306481343098, \"f1\": 0.8077340569877883, \"f2\": 0.9081340004881621, \"f0_5\": 0.7273238197634639, \"p4\": 0.5931048829901833, \"phi\": 0.43761919166190183}, {\"truth_threshold\": -17.56, \"match_probability\": 5.1750080376029e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11906, \"tn\": 2501, \"fp\": 5548, \"fn\": 118, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9901862940785097, \"tn_rate\": 0.31072182879860855, \"fp_rate\": 0.6892781712013915, \"fn_rate\": 0.009813705921490353, \"precision\": 0.6821359000802109, \"recall\": 0.9901862940785097, \"specificity\": 0.31072182879860855, \"npv\": 0.9549446353570065, \"accuracy\": 0.7177302844617147, \"f1\": 0.807788859488432, \"f2\": 0.9081617086193745, \"f0_5\": 0.727394916911046, \"p4\": 0.5933495915659803, \"phi\": 0.43783867809955124}, {\"truth_threshold\": -17.54, \"match_probability\": 5.247248078653649e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11905, \"tn\": 2501, \"fp\": 5548, \"fn\": 119, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.990103127079175, \"tn_rate\": 0.31072182879860855, \"fp_rate\": 0.6892781712013915, \"fn_rate\": 0.009896872920825016, \"precision\": 0.682117687503581, \"recall\": 0.990103127079175, \"specificity\": 0.31072182879860855, \"npv\": 0.9545801526717558, \"accuracy\": 0.7176804662980123, \"f1\": 0.8077484140177087, \"f2\": 0.9080992845047217, \"f0_5\": 0.7273693728921257, \"p4\": 0.5933034912817167, \"phi\": 0.43764666076439535}, {\"truth_threshold\": -17.48, \"match_probability\": 5.470075241747767e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11904, \"tn\": 2501, \"fp\": 5548, \"fn\": 120, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9900199600798403, \"tn_rate\": 0.31072182879860855, \"fp_rate\": 0.6892781712013915, \"fn_rate\": 0.00998003992015968, \"precision\": 0.6820994728397891, \"recall\": 0.9900199600798403, \"specificity\": 0.31072182879860855, \"npv\": 0.9542159481114079, \"accuracy\": 0.7176306481343098, \"f1\": 0.8077079658026869, \"f2\": 0.9080368584853847, \"f0_5\": 0.7273438263759898, \"p4\": 0.5932573963277264, \"phi\": 0.43745472678644837}, {\"truth_threshold\": -17.46, \"match_probability\": 5.546434223012468e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11899, \"tn\": 2501, \"fp\": 5548, \"fn\": 125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.989604125083167, \"tn_rate\": 0.31072182879860855, \"fp_rate\": 0.6892781712013915, \"fn_rate\": 0.010395874916833001, \"precision\": 0.6820083682008368, \"recall\": 0.989604125083167, \"specificity\": 0.31072182879860855, \"npv\": 0.9523990860624524, \"accuracy\": 0.7173815573157973, \"f1\": 0.8075056835533236, \"f2\": 0.9077246998153884, \"f0_5\": 0.7272160563242556, \"p4\": 0.5930270014671936, \"phi\": 0.43649630451050925}, {\"truth_threshold\": -17.44, \"match_probability\": 5.62385912402615e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11899, \"tn\": 2503, \"fp\": 5546, \"fn\": 125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.989604125083167, \"tn_rate\": 0.3109703068704187, \"fp_rate\": 0.6890296931295813, \"fn_rate\": 0.010395874916833001, \"precision\": 0.6820865577529378, \"recall\": 0.989604125083167, \"specificity\": 0.3109703068704187, \"npv\": 0.9524353120243532, \"accuracy\": 0.7174811936432023, \"f1\": 0.8075604872917302, \"f2\": 0.907752399261531, \"f0_5\": 0.7272871742213095, \"p4\": 0.5932714837510513, \"phi\": 0.4367162128550259}, {\"truth_threshold\": -17.38, \"match_probability\": 5.862679180457631e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11896, \"tn\": 2506, \"fp\": 5543, \"fn\": 128, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9893546240851631, \"tn_rate\": 0.3113430239781339, \"fp_rate\": 0.688656976021866, \"fn_rate\": 0.010645375914836993, \"precision\": 0.682149205803085, \"recall\": 0.9893546240851631, \"specificity\": 0.3113430239781339, \"npv\": 0.9514047076689446, \"accuracy\": 0.7174811936432023, \"f1\": 0.8075212978990598, \"f2\": 0.9076066224155032, \"f0_5\": 0.727317192467596, \"p4\": 0.5934996590620293, \"phi\": 0.4364724180315829}, {\"truth_threshold\": -17.3, \"match_probability\": 6.196955588258426e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11893, \"tn\": 2506, \"fp\": 5543, \"fn\": 131, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.989105123087159, \"tn_rate\": 0.3113430239781339, \"fp_rate\": 0.688656976021866, \"fn_rate\": 0.010894876912840985, \"precision\": 0.6820945170910759, \"recall\": 0.989105123087159, \"specificity\": 0.3113430239781339, \"npv\": 0.950322335987865, \"accuracy\": 0.7173317391520948, \"f1\": 0.8073998642226748, \"f2\": 0.9074192760788622, \"f0_5\": 0.7272404852754134, \"p4\": 0.5933614691615561, \"phi\": 0.4358996119296637}, {\"truth_threshold\": -17.22, \"match_probability\": 6.550291538878178e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11891, \"tn\": 2506, \"fp\": 5543, \"fn\": 133, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9889387890884896, \"tn_rate\": 0.3113430239781339, \"fp_rate\": 0.688656976021866, \"fn_rate\": 0.011061210911510314, \"precision\": 0.6820580474934037, \"recall\": 0.9889387890884896, \"specificity\": 0.3113430239781339, \"npv\": 0.9496021220159151, \"accuracy\": 0.7172321028246899, \"f1\": 0.8073188946975355, \"f2\": 0.9072943689913017, \"f0_5\": 0.7271893346379648, \"p4\": 0.593269369118604, \"phi\": 0.43551815225341534}, {\"truth_threshold\": -17.18, \"match_probability\": 6.734444059575694e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11857, \"tn\": 2506, \"fp\": 5543, \"fn\": 167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9861111111111112, \"tn_rate\": 0.3113430239781339, \"fp_rate\": 0.688656976021866, \"fn_rate\": 0.013888888888888888, \"precision\": 0.6814367816091954, \"recall\": 0.9861111111111112, \"specificity\": 0.3113430239781339, \"npv\": 0.9375233819678264, \"accuracy\": 0.7155382852588054, \"f1\": 0.8059407286568787, \"f2\": 0.9051697813606938, \"f0_5\": 0.7263182397334117, \"p4\": 0.5917069089065956, \"phi\": 0.4290830457050251}, {\"truth_threshold\": -17.16, \"match_probability\": 6.8284527533841125e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11857, \"tn\": 2510, \"fp\": 5539, \"fn\": 167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9861111111111112, \"tn_rate\": 0.31183998012175423, \"fp_rate\": 0.6881600198782457, \"fn_rate\": 0.013888888888888888, \"precision\": 0.6815934697631639, \"recall\": 0.9861111111111112, \"specificity\": 0.31183998012175423, \"npv\": 0.9376167351512887, \"accuracy\": 0.7157375579136153, \"f1\": 0.806050305914344, \"f2\": 0.9052250656568741, \"f0_5\": 0.7264606411136163, \"p4\": 0.5921941567680757, \"phi\": 0.42952806224598106}, {\"truth_threshold\": -17.080000000000002, \"match_probability\": 7.217794939235686e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11857, \"tn\": 2511, \"fp\": 5538, \"fn\": 167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9861111111111112, \"tn_rate\": 0.3119642191576593, \"fp_rate\": 0.6880357808423406, \"fn_rate\": 0.013888888888888888, \"precision\": 0.6816326530612244, \"recall\": 0.9861111111111112, \"specificity\": 0.3119642191576593, \"npv\": 0.9376400298730396, \"accuracy\": 0.7157873760773178, \"f1\": 0.8060777048845984, \"f2\": 0.9052388877861081, \"f0_5\": 0.7264962501838145, \"p4\": 0.5923158660170388, \"phi\": 0.42963927833946736}, {\"truth_threshold\": -17.0, \"match_probability\": 7.629336324033172e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11857, \"tn\": 2512, \"fp\": 5537, \"fn\": 167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9861111111111112, \"tn_rate\": 0.3120884581935644, \"fp_rate\": 0.6879115418064355, \"fn_rate\": 0.013888888888888888, \"precision\": 0.6816718408646659, \"recall\": 0.9861111111111112, \"specificity\": 0.3120884581935644, \"npv\": 0.9376633072041807, \"accuracy\": 0.7158371942410203, \"f1\": 0.8061051057175879, \"f2\": 0.9052527103374561, \"f0_5\": 0.7265318627450981, \"p4\": 0.5924375342342268, \"phi\": 0.4297504792427549}, {\"truth_threshold\": -16.98, \"match_probability\": 7.735837066381084e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11857, \"tn\": 2513, \"fp\": 5536, \"fn\": 167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9861111111111112, \"tn_rate\": 0.3122126972294695, \"fp_rate\": 0.6877873027705305, \"fn_rate\": 0.013888888888888888, \"precision\": 0.6817110331742655, \"recall\": 0.9861111111111112, \"specificity\": 0.3122126972294695, \"npv\": 0.9376865671641791, \"accuracy\": 0.7158870124047227, \"f1\": 0.8061325084135024, \"f2\": 0.9052665333109378, \"f0_5\": 0.7265674787979803, \"p4\": 0.5925591614469925, \"phi\": 0.4298616649690708}, {\"truth_threshold\": -16.92, \"match_probability\": 8.064342623945162e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11856, \"tn\": 2513, \"fp\": 5536, \"fn\": 168, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9860279441117764, \"tn_rate\": 0.3122126972294695, \"fp_rate\": 0.6877873027705305, \"fn_rate\": 0.013972055888223553, \"precision\": 0.6816927322907084, \"recall\": 0.9860279441117764, \"specificity\": 0.3122126972294695, \"npv\": 0.9373368146214099, \"accuracy\": 0.7158371942410203, \"f1\": 0.8060919227631221, \"f2\": 0.9052040068409479, \"f0_5\": 0.7265418178252769, \"p4\": 0.5925132688474949, \"phi\": 0.4296740265366887}, {\"truth_threshold\": -16.82, \"match_probability\": 8.643143414443251e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11856, \"tn\": 2514, \"fp\": 5535, \"fn\": 168, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9860279441117764, \"tn_rate\": 0.31233693626537457, \"fp_rate\": 0.6876630637346254, \"fn_rate\": 0.013972055888223553, \"precision\": 0.6817319303087804, \"recall\": 0.9860279441117764, \"specificity\": 0.31233693626537457, \"npv\": 0.9373601789709173, \"accuracy\": 0.7158870124047227, \"f1\": 0.8061193268740439, \"f2\": 0.9052178294928764, \"f0_5\": 0.7265774378585086, \"p4\": 0.5926348507714482, \"phi\": 0.42978522907107347}, {\"truth_threshold\": -16.8, \"match_probability\": 8.76379614287431e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11856, \"tn\": 2516, \"fp\": 5533, \"fn\": 168, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9860279441117764, \"tn_rate\": 0.31258541433718473, \"fp_rate\": 0.6874145856628152, \"fn_rate\": 0.013972055888223553, \"precision\": 0.6818103398700328, \"recall\": 0.9860279441117764, \"specificity\": 0.31258541433718473, \"npv\": 0.9374068554396423, \"accuracy\": 0.7159866487321277, \"f1\": 0.8061741406860912, \"f2\": 0.9052454760632206, \"f0_5\": 0.7266486884040206, \"p4\": 0.5928778918072881, \"phi\": 0.4300075886548613}, {\"truth_threshold\": -16.76, \"match_probability\": 9.01017776852193e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11855, \"tn\": 3201, \"fp\": 4848, \"fn\": 169, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9859447771124418, \"tn_rate\": 0.3976891539321655, \"fp_rate\": 0.6023108460678345, \"fn_rate\": 0.014055222887558217, \"precision\": 0.709752739028917, \"recall\": 0.9859447771124418, \"specificity\": 0.3976891539321655, \"npv\": 0.9498516320474777, \"accuracy\": 0.7500622727046281, \"f1\": 0.8253559369234518, \"f2\": 0.9147517708606614, \"f0_5\": 0.7518773149322644, \"p4\": 0.6677217031304088, \"phi\": 0.5030373920597186}, {\"truth_threshold\": -16.7, \"match_probability\": 9.392798228865447e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11852, \"tn\": 3203, \"fp\": 4846, \"fn\": 172, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9856952761144377, \"tn_rate\": 0.39793763200397564, \"fp_rate\": 0.6020623679960243, \"fn_rate\": 0.014304723885562209, \"precision\": 0.7097856030662355, \"recall\": 0.9856952761144377, \"specificity\": 0.39793763200397564, \"npv\": 0.949037037037037, \"accuracy\": 0.7500124545409256, \"f1\": 0.8252907179165796, \"f2\": 0.9145908571781338, \"f0_5\": 0.7518777913114089, \"p4\": 0.6677746475548363, \"phi\": 0.5027385457243848}, {\"truth_threshold\": -16.68, \"match_probability\": 9.523915557150856e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11852, \"tn\": 3369, \"fp\": 4680, \"fn\": 172, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9856952761144377, \"tn_rate\": 0.41856131196421914, \"fp_rate\": 0.5814386880357808, \"fn_rate\": 0.014304723885562209, \"precision\": 0.7169126542463102, \"recall\": 0.9856952761144377, \"specificity\": 0.41856131196421914, \"npv\": 0.9514261508048574, \"accuracy\": 0.7582822697155382, \"f1\": 0.830088247653733, \"f2\": 0.9169400259949247, \"f0_5\": 0.758265943289999, \"p4\": 0.6838106720660395, \"phi\": 0.519788769607955}, {\"truth_threshold\": -16.66, \"match_probability\": 9.656863180023442e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11850, \"tn\": 3374, \"fp\": 4675, \"fn\": 174, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9855289421157685, \"tn_rate\": 0.41918250714374455, \"fp_rate\": 0.5808174928562554, \"fn_rate\": 0.014471057884231538, \"precision\": 0.7170953101361573, \"recall\": 0.9855289421157685, \"specificity\": 0.41918250714374455, \"npv\": 0.9509582863585119, \"accuracy\": 0.7584317242066457, \"f1\": 0.8301516690602123, \"f2\": 0.9168846040760743, \"f0_5\": 0.7584097076442579, \"p4\": 0.6841858286350984, \"phi\": 0.5199701330080291}, {\"truth_threshold\": -16.64, \"match_probability\": 9.791666646456521e-06, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11850, \"tn\": 3375, \"fp\": 4674, \"fn\": 174, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9855289421157685, \"tn_rate\": 0.41930674617964964, \"fp_rate\": 0.5806932538203503, \"fn_rate\": 0.014471057884231538, \"precision\": 0.7171387073347858, \"recall\": 0.9855289421157685, \"specificity\": 0.41930674617964964, \"npv\": 0.9509721048182587, \"accuracy\": 0.7584815423703483, \"f1\": 0.830180748213535, \"f2\": 0.9168987929433612, \"f0_5\": 0.7584485407066052, \"p4\": 0.6842802257451052, \"phi\": 0.5200722070016706}, {\"truth_threshold\": -16.6, \"match_probability\": 1.0066945093988067e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11848, \"tn\": 3379, \"fp\": 4670, \"fn\": 176, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9853626081170991, \"tn_rate\": 0.41980370232326997, \"fp_rate\": 0.58019629767673, \"fn_rate\": 0.014637391882900865, \"precision\": 0.7172781208378738, \"recall\": 0.9853626081170991, \"specificity\": 0.41980370232326997, \"npv\": 0.9504922644163151, \"accuracy\": 0.7585811786977532, \"f1\": 0.8302151215752225, \"f2\": 0.9168291701488841, \"f0_5\": 0.7585535750870723, \"p4\": 0.6845603560862269, \"phi\": 0.520151961656191}, {\"truth_threshold\": -16.56, \"match_probability\": 1.0349962514066602e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11846, \"tn\": 3379, \"fp\": 4670, \"fn\": 178, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9851962741184298, \"tn_rate\": 0.41980370232326997, \"fp_rate\": 0.58019629767673, \"fn_rate\": 0.014803725881570194, \"precision\": 0.7172438847178494, \"recall\": 0.9851962741184298, \"specificity\": 0.41980370232326997, \"npv\": 0.9499578296317122, \"accuracy\": 0.7584815423703483, \"f1\": 0.8301331464611073, \"f2\": 0.9167027796694113, \"f0_5\": 0.758503227128368, \"p4\": 0.6844631564518766, \"phi\": 0.5198236995303639}, {\"truth_threshold\": -16.5, \"match_probability\": 1.0789476804723106e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11843, \"tn\": 3380, \"fp\": 4669, \"fn\": 181, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9849467731204258, \"tn_rate\": 0.41992794135917505, \"fp_rate\": 0.5800720586408249, \"fn_rate\": 0.015053226879574185, \"precision\": 0.7172359496124031, \"recall\": 0.9849467731204258, \"specificity\": 0.41992794135917505, \"npv\": 0.9491715810165684, \"accuracy\": 0.7583819060429433, \"f1\": 0.8300392486683488, \"f2\": 0.9165273650321941, \"f0_5\": 0.7584665437032483, \"p4\": 0.6844116520995973, \"phi\": 0.5194338828864177}, {\"truth_threshold\": -16.46, \"match_probability\": 1.1092806920501003e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11842, \"tn\": 3384, \"fp\": 4665, \"fn\": 182, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9848636061210911, \"tn_rate\": 0.4204248975027954, \"fp_rate\": 0.5795751024972047, \"fn_rate\": 0.015136393878908848, \"precision\": 0.7173926213121706, \"recall\": 0.9848636061210911, \"specificity\": 0.4204248975027954, \"npv\": 0.9489624228827819, \"accuracy\": 0.7585313605340507, \"f1\": 0.8301146121762294, \"f2\": 0.9165209046019535, \"f0_5\": 0.7585968328806437, \"p4\": 0.6847398657838488, \"phi\": 0.5196787841965468}, {\"truth_threshold\": -16.44, \"match_probability\": 1.1247654992825144e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11841, \"tn\": 3384, \"fp\": 4665, \"fn\": 183, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9847804391217565, \"tn_rate\": 0.4204248975027954, \"fp_rate\": 0.5795751024972047, \"fn_rate\": 0.015219560878243513, \"precision\": 0.7173754998182479, \"recall\": 0.9847804391217565, \"specificity\": 0.4204248975027954, \"npv\": 0.9486963835155593, \"accuracy\": 0.7584815423703483, \"f1\": 0.8300736067297582, \"f2\": 0.9164576948082103, \"f0_5\": 0.7585716482164822, \"p4\": 0.6846912794985818, \"phi\": 0.5195150447315502}, {\"truth_threshold\": -16.42, \"match_probability\": 1.1404664614720203e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11841, \"tn\": 3386, \"fp\": 4663, \"fn\": 183, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9847804391217565, \"tn_rate\": 0.42067337557460555, \"fp_rate\": 0.5793266244253945, \"fn_rate\": 0.015219560878243513, \"precision\": 0.717462433349491, \"recall\": 0.9847804391217565, \"specificity\": 0.42067337557460555, \"npv\": 0.9487251330905015, \"accuracy\": 0.7585811786977532, \"f1\": 0.8301318003365115, \"f2\": 0.916486068111455, \"f0_5\": 0.7586494105586878, \"p4\": 0.684879529115394, \"phi\": 0.5197194340376171}, {\"truth_threshold\": -16.4, \"match_probability\": 1.156386595891718e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11840, \"tn\": 3386, \"fp\": 4663, \"fn\": 184, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9846972721224219, \"tn_rate\": 0.42067337557460555, \"fp_rate\": 0.5793266244253945, \"fn_rate\": 0.015302727877578177, \"precision\": 0.7174453129733988, \"recall\": 0.9846972721224219, \"specificity\": 0.42067337557460555, \"npv\": 0.9484593837535014, \"accuracy\": 0.7585313605340507, \"f1\": 0.8300907911802854, \"f2\": 0.9164228548429543, \"f0_5\": 0.7586242247167974, \"p4\": 0.6848309427897039, \"phi\": 0.5195557893207197}, {\"truth_threshold\": -16.38, \"match_probability\": 1.1725289619303927e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11840, \"tn\": 3395, \"fp\": 4654, \"fn\": 184, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9846972721224219, \"tn_rate\": 0.4217915268977513, \"fp_rate\": 0.5782084731022488, \"fn_rate\": 0.015302727877578177, \"precision\": 0.7178367891354432, \"recall\": 0.9846972721224219, \"specificity\": 0.4217915268977513, \"npv\": 0.9485889913383627, \"accuracy\": 0.7589797240073731, \"f1\": 0.8303527596605652, \"f2\": 0.9165505496206843, \"f0_5\": 0.7589743589743589, \"p4\": 0.6856768653441346, \"phi\": 0.5204753741925537}, {\"truth_threshold\": -16.36, \"match_probability\": 1.1888966616803339e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11794, \"tn\": 3396, \"fp\": 4653, \"fn\": 230, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9808715901530273, \"tn_rate\": 0.4219157659336564, \"fp_rate\": 0.5780842340663437, \"fn_rate\": 0.01912840984697272, \"precision\": 0.7170912628442877, \"recall\": 0.9808715901530273, \"specificity\": 0.4219157659336564, \"npv\": 0.936569222283508, \"accuracy\": 0.7567379066407612, \"f1\": 0.8284921499069229, \"f2\": 0.9136544629161955, \"f0_5\": 0.7578522592916259, \"p4\": 0.6835395954917549, \"phi\": 0.5131141964348324}, {\"truth_threshold\": -16.3, \"match_probability\": 1.2393834372475679e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11794, \"tn\": 3398, \"fp\": 4651, \"fn\": 230, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9808715901530273, \"tn_rate\": 0.42216424400546654, \"fp_rate\": 0.5778357559945335, \"fn_rate\": 0.01912840984697272, \"precision\": 0.7171784737002128, \"recall\": 0.9808715901530273, \"specificity\": 0.42216424400546654, \"npv\": 0.9366041896361632, \"accuracy\": 0.7568375429681662, \"f1\": 0.8285503530155608, \"f2\": 0.9136827752901256, \"f0_5\": 0.7579301835381215, \"p4\": 0.683727058614786, \"phi\": 0.5133204078118636}, {\"truth_threshold\": -16.26, \"match_probability\": 1.274226804373564e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11764, \"tn\": 3398, \"fp\": 4651, \"fn\": 260, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9783765801729873, \"tn_rate\": 0.42216424400546654, \"fp_rate\": 0.5778357559945335, \"fn_rate\": 0.02162341982701264, \"precision\": 0.716661590009138, \"recall\": 0.9783765801729873, \"specificity\": 0.42216424400546654, \"npv\": 0.928922908693275, \"accuracy\": 0.7553429980570916, \"f1\": 0.827314603185766, \"f2\": 0.9117824867076932, \"f0_5\": 0.7571700736316359, \"p4\": 0.6822769394385579, \"phi\": 0.5085105182659435}, {\"truth_threshold\": -16.14, \"match_probability\": 1.384745160659142e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11762, \"tn\": 3398, \"fp\": 4651, \"fn\": 262, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9782102461743181, \"tn_rate\": 0.42216424400546654, \"fp_rate\": 0.5778357559945335, \"fn_rate\": 0.02178975382568197, \"precision\": 0.7166270639127521, \"recall\": 0.9782102461743181, \"specificity\": 0.42216424400546654, \"npv\": 0.928415300546448, \"accuracy\": 0.7552433617296866, \"f1\": 0.8272321271582797, \"f2\": 0.9116557379590444, \"f0_5\": 0.7571193161336836, \"p4\": 0.6821804074196929, \"phi\": 0.5081914086392203}, {\"truth_threshold\": -16.02, \"match_probability\": 1.5048490343933547e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11760, \"tn\": 3398, \"fp\": 4651, \"fn\": 264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9780439121756487, \"tn_rate\": 0.42216424400546654, \"fp_rate\": 0.5778357559945335, \"fn_rate\": 0.021956087824351298, \"precision\": 0.7165925294010115, \"recall\": 0.9780439121756487, \"specificity\": 0.42216424400546654, \"npv\": 0.9279082468596396, \"accuracy\": 0.7551437254022817, \"f1\": 0.8271496395287498, \"f2\": 0.9115289813508611, \"f0_5\": 0.7570685481794304, \"p4\": 0.6820838931774892, \"phi\": 0.5078724912067719}, {\"truth_threshold\": -16.0, \"match_probability\": 1.5258556235409006e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11760, \"tn\": 3400, \"fp\": 4649, \"fn\": 264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9780439121756487, \"tn_rate\": 0.4224127220772767, \"fp_rate\": 0.5775872779227234, \"fn_rate\": 0.021956087824351298, \"precision\": 0.7166798708026083, \"recall\": 0.9780439121756487, \"specificity\": 0.4224127220772767, \"npv\": 0.9279475982532751, \"accuracy\": 0.7552433617296866, \"f1\": 0.8272078218970914, \"f2\": 0.9115572436245253, \"f0_5\": 0.7571465361833634, \"p4\": 0.6822711041362686, \"phi\": 0.5080800592476552}, {\"truth_threshold\": -15.96, \"match_probability\": 1.5687525910854657e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11759, \"tn\": 3400, \"fp\": 4649, \"fn\": 265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.977960745176314, \"tn_rate\": 0.4224127220772767, \"fp_rate\": 0.5775872779227234, \"fn_rate\": 0.02203925482368596, \"precision\": 0.716662603607996, \"recall\": 0.977960745176314, \"specificity\": 0.4224127220772767, \"npv\": 0.927694406548431, \"accuracy\": 0.7551935435659841, \"f1\": 0.8271665728756331, \"f2\": 0.911493860845839, \"f0_5\": 0.7571211496857938, \"p4\": 0.6822228490152492, \"phi\": 0.5079207126171229}, {\"truth_threshold\": -15.94, \"match_probability\": 1.5906512128400478e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11759, \"tn\": 3838, \"fp\": 4211, \"fn\": 265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.977960745176314, \"tn_rate\": 0.4768294198037023, \"fp_rate\": 0.5231705801962977, \"fn_rate\": 0.02203925482368596, \"precision\": 0.7363180964308078, \"recall\": 0.977960745176314, \"specificity\": 0.4768294198037023, \"npv\": 0.9354131123568121, \"accuracy\": 0.777013899267673, \"f1\": 0.840108594698864, \"f2\": 0.917725470608435, \"f0_5\": 0.7745968591905565, \"p4\": 0.7211264972556521, \"phi\": 0.5527176017341473}, {\"truth_threshold\": -15.92, \"match_probability\": 1.612855518169533e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11759, \"tn\": 3841, \"fp\": 4208, \"fn\": 265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.977960745176314, \"tn_rate\": 0.47720213691141755, \"fp_rate\": 0.5227978630885824, \"fn_rate\": 0.02203925482368596, \"precision\": 0.736456441410409, \"recall\": 0.977960745176314, \"specificity\": 0.47720213691141755, \"npv\": 0.9354603019970774, \"accuracy\": 0.7771633537587804, \"f1\": 0.8401986352756243, \"f2\": 0.9177684466852941, \"f0_5\": 0.7747193380066411, \"p4\": 0.7213797143279205, \"phi\": 0.5530203987669482}, {\"truth_threshold\": -15.9, \"match_probability\": 1.6353697739823012e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11759, \"tn\": 3842, \"fp\": 4207, \"fn\": 265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.977960745176314, \"tn_rate\": 0.47732637594732263, \"fp_rate\": 0.5226736240526774, \"fn_rate\": 0.02203925482368596, \"precision\": 0.7365025679569084, \"recall\": 0.977960745176314, \"specificity\": 0.47732637594732263, \"npv\": 0.9354760165570977, \"accuracy\": 0.777213171922483, \"f1\": 0.8402286530903894, \"f2\": 0.9177827729387156, \"f0_5\": 0.7747601728863589, \"p4\": 0.7214640831340838, \"phi\": 0.5531213205076426}, {\"truth_threshold\": -15.860000000000001, \"match_probability\": 1.6813455033027547e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11759, \"tn\": 3844, \"fp\": 4205, \"fn\": 265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.977960745176314, \"tn_rate\": 0.4775748540191328, \"fp_rate\": 0.5224251459808672, \"fn_rate\": 0.02203925482368596, \"precision\": 0.7365948383863693, \"recall\": 0.977960745176314, \"specificity\": 0.4775748540191328, \"npv\": 0.9355074227305914, \"accuracy\": 0.7773128082498879, \"f1\": 0.8402886951550664, \"f2\": 0.9178114267873868, \"f0_5\": 0.7748418555614127, \"p4\": 0.7216327654792206, \"phi\": 0.5533231481137667}, {\"truth_threshold\": -15.84, \"match_probability\": 1.7048158117438166e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11758, \"tn\": 3844, \"fp\": 4205, \"fn\": 266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9778775781769794, \"tn_rate\": 0.4775748540191328, \"fp_rate\": 0.5224251459808672, \"fn_rate\": 0.022122421823020627, \"precision\": 0.7365783374052497, \"recall\": 0.9778775781769794, \"specificity\": 0.4775748540191328, \"npv\": 0.9352798053527981, \"accuracy\": 0.7772629900861854, \"f1\": 0.84024725765534, \"f2\": 0.9177477013378292, \"f0_5\": 0.7748168063682851, \"p4\": 0.7215836195564475, \"phi\": 0.5531721478978452}, {\"truth_threshold\": -15.82, \"match_probability\": 1.728613742232168e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11758, \"tn\": 3845, \"fp\": 4204, \"fn\": 266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9778775781769794, \"tn_rate\": 0.4776990930550379, \"fp_rate\": 0.5223009069449621, \"fn_rate\": 0.022122421823020627, \"precision\": 0.7366244831474753, \"recall\": 0.9778775781769794, \"specificity\": 0.4776990930550379, \"npv\": 0.9352955485283386, \"accuracy\": 0.7773128082498879, \"f1\": 0.8402772814978918, \"f2\": 0.9177620281619782, \"f0_5\": 0.7748576549978912, \"p4\": 0.7216679313817413, \"phi\": 0.553273071245094}, {\"truth_threshold\": -15.8, \"match_probability\": 1.7527438678849133e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11758, \"tn\": 3846, \"fp\": 4203, \"fn\": 266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9778775781769794, \"tn_rate\": 0.47782333209094296, \"fp_rate\": 0.522176667909057, \"fn_rate\": 0.022122421823020627, \"precision\": 0.736670634672013, \"recall\": 0.9778775781769794, \"specificity\": 0.47782333209094296, \"npv\": 0.9353112840466926, \"accuracy\": 0.7773626264135904, \"f1\": 0.8403073074861533, \"f2\": 0.917776355433442, \"f0_5\": 0.7748985079348342, \"p4\": 0.7217522248122679, \"phi\": 0.5533739893089475}, {\"truth_threshold\": -15.780000000000001, \"match_probability\": 1.7772108256485995e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11757, \"tn\": 3848, \"fp\": 4201, \"fn\": 267, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9777944111776448, \"tn_rate\": 0.47807181016275313, \"fp_rate\": 0.5219281898372469, \"fn_rate\": 0.02220558882235529, \"precision\": 0.7367464594560722, \"recall\": 0.9777944111776448, \"specificity\": 0.47807181016275313, \"npv\": 0.9351154313487242, \"accuracy\": 0.7774124445772929, \"f1\": 0.8403259238081624, \"f2\": 0.9177412807943298, \"f0_5\": 0.7749551782324404, \"p4\": 0.7218716077702733, \"phi\": 0.5534249194098486}, {\"truth_threshold\": -15.76, \"match_probability\": 1.802019317189998e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11757, \"tn\": 3850, \"fp\": 4199, \"fn\": 267, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9777944111776448, \"tn_rate\": 0.4783202882345633, \"fp_rate\": 0.5216797117654367, \"fn_rate\": 0.02220558882235529, \"precision\": 0.7368388067184758, \"recall\": 0.9777944111776448, \"specificity\": 0.4783202882345633, \"npv\": 0.9351469516638329, \"accuracy\": 0.7775120809046978, \"f1\": 0.8403859899928521, \"f2\": 0.9177699369262474, \"f0_5\": 0.7750369159371374, \"p4\": 0.7220400625682075, \"phi\": 0.5536267535026025}, {\"truth_threshold\": -15.74, \"match_probability\": 1.8271741097992973e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11754, \"tn\": 3850, \"fp\": 4199, \"fn\": 270, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9775449101796407, \"tn_rate\": 0.4783202882345633, \"fp_rate\": 0.5216797117654367, \"fn_rate\": 0.02245508982035928, \"precision\": 0.7367893186234564, \"recall\": 0.9775449101796407, \"specificity\": 0.4783202882345633, \"npv\": 0.9344660194174758, \"accuracy\": 0.7773626264135904, \"f1\": 0.8402616434928691, \"f2\": 0.9175787287857734, \"f0_5\": 0.7749617595864761, \"p4\": 0.7218926304494835, \"phi\": 0.5531744280628156}, {\"truth_threshold\": -15.68, \"match_probability\": 1.904764970609435e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11754, \"tn\": 3855, \"fp\": 4194, \"fn\": 270, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9775449101796407, \"tn_rate\": 0.4789414834140887, \"fp_rate\": 0.5210585165859113, \"fn_rate\": 0.02245508982035928, \"precision\": 0.7370203160270881, \"recall\": 0.9775449101796407, \"specificity\": 0.4789414834140887, \"npv\": 0.9345454545454546, \"accuracy\": 0.7776117172321029, \"f1\": 0.8404118404118404, \"f2\": 0.9176503653738055, \"f0_5\": 0.7751661918328585, \"p4\": 0.7223134206944876, \"phi\": 0.5536791820807911}, {\"truth_threshold\": -15.66, \"match_probability\": 1.931353985183501e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11717, \"tn\": 3855, \"fp\": 4194, \"fn\": 307, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9744677312042581, \"tn_rate\": 0.4789414834140887, \"fp_rate\": 0.5210585165859113, \"fn_rate\": 0.02553226879574185, \"precision\": 0.7364087738042864, \"recall\": 0.9744677312042581, \"specificity\": 0.4789414834140887, \"npv\": 0.9262373858721769, \"accuracy\": 0.7757684451751109, \"f1\": 0.83887596205477, \"f2\": 0.915290515099911, \"f0_5\": 0.7742374583707776, \"p4\": 0.7204977848008184, \"phi\": 0.5481330813121653}, {\"truth_threshold\": -15.6, \"match_probability\": 2.013368750324953e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11716, \"tn\": 3855, \"fp\": 4194, \"fn\": 308, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9743845642049235, \"tn_rate\": 0.4789414834140887, \"fp_rate\": 0.5210585165859113, \"fn_rate\": 0.025615435795076514, \"precision\": 0.7363922061596481, \"recall\": 0.9743845642049235, \"specificity\": 0.4789414834140887, \"npv\": 0.9260148931059332, \"accuracy\": 0.7757186270114084, \"f1\": 0.8388343953604925, \"f2\": 0.9152266974971096, \"f0_5\": 0.7742123070416579, \"p4\": 0.7204487906713475, \"phi\": 0.5479839342762163}, {\"truth_threshold\": -15.58, \"match_probability\": 2.0414737569369415e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3859, \"fp\": 4190, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.47943843955770904, \"fp_rate\": 0.520561560442291, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7364945600905604, \"recall\": 0.9739687292082502, \"specificity\": 0.47943843955770904, \"npv\": 0.9249760306807286, \"accuracy\": 0.7756688088477058, \"f1\": 0.8387466427931961, \"f2\": 0.9149647639733113, \"f0_5\": 0.7742502776749353, \"p4\": 0.7205398844829105, \"phi\": 0.5476454215854968}, {\"truth_threshold\": -15.5, \"match_probability\": 2.1578720786338814e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3867, \"fp\": 4182, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.4804323518449497, \"fp_rate\": 0.5195676481550503, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7368652866041654, \"recall\": 0.9739687292082502, \"specificity\": 0.4804323518449497, \"npv\": 0.9251196172248803, \"accuracy\": 0.7760673541573258, \"f1\": 0.838986997170183, \"f2\": 0.9150791542296333, \"f0_5\": 0.7745780200010582, \"p4\": 0.721211018923373, \"phi\": 0.5484584359282086}, {\"truth_threshold\": -15.48, \"match_probability\": 2.187994191220544e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3870, \"fp\": 4179, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.48080506895266495, \"fp_rate\": 0.519194931047335, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7370044052863436, \"recall\": 0.9739687292082502, \"specificity\": 0.48080506895266495, \"npv\": 0.9251733205833134, \"accuracy\": 0.7762168086484332, \"f1\": 0.8390771655799957, \"f2\": 0.9151220579501766, \"f0_5\": 0.7747009949195597, \"p4\": 0.7214623950037563, \"phi\": 0.5487632271310653}, {\"truth_threshold\": -15.38, \"match_probability\": 2.345030427699851e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3872, \"fp\": 4177, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.4810535470244751, \"fp_rate\": 0.5189464529755249, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7370971802618328, \"recall\": 0.9739687292082502, \"specificity\": 0.4810535470244751, \"npv\": 0.9252090800477897, \"accuracy\": 0.7763164449758382, \"f1\": 0.8391372886213815, \"f2\": 0.9151506626656665, \"f0_5\": 0.7747829998941463, \"p4\": 0.721629888560958, \"phi\": 0.548966394353305}, {\"truth_threshold\": -15.36, \"match_probability\": 2.3777650541913158e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3876, \"fp\": 4173, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.4815505031680954, \"fp_rate\": 0.5184494968319046, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7372828003021908, \"recall\": 0.9739687292082502, \"specificity\": 0.4815505031680954, \"npv\": 0.9252804965385534, \"accuracy\": 0.7765157176306481, \"f1\": 0.8392575605561129, \"f2\": 0.9152078774617067, \"f0_5\": 0.774947061937533, \"p4\": 0.7219646588338445, \"phi\": 0.5493726643887886}, {\"truth_threshold\": -15.34, \"match_probability\": 2.410956617157259e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3880, \"fp\": 4169, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.4820474593117157, \"fp_rate\": 0.5179525406882842, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7374685138539043, \"recall\": 0.9739687292082502, \"specificity\": 0.4820474593117157, \"npv\": 0.9253517767708085, \"accuracy\": 0.7767149902854581, \"f1\": 0.8393778669724771, \"f2\": 0.9152650994122796, \"f0_5\": 0.7751111934766494, \"p4\": 0.7222991405018429, \"phi\": 0.5497788488150283}, {\"truth_threshold\": -15.32, \"match_probability\": 2.4446114945779867e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11711, \"tn\": 3882, \"fp\": 4167, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9739687292082502, \"tn_rate\": 0.4822959373835259, \"fp_rate\": 0.5177040626164741, \"fn_rate\": 0.026031270791749835, \"precision\": 0.7375614057186044, \"recall\": 0.9739687292082502, \"specificity\": 0.4822959373835259, \"npv\": 0.9253873659117997, \"accuracy\": 0.776814626612863, \"f1\": 0.8394380331159057, \"f2\": 0.9152937130709351, \"f0_5\": 0.7751932853209066, \"p4\": 0.7224662733025521, \"phi\": 0.5499819090255368}, {\"truth_threshold\": -15.280000000000001, \"match_probability\": 2.5133371510271085e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11709, \"tn\": 3882, \"fp\": 4167, \"fn\": 315, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9738023952095808, \"tn_rate\": 0.4822959373835259, \"fp_rate\": 0.5177040626164741, \"fn_rate\": 0.02619760479041916, \"precision\": 0.7375283446712018, \"recall\": 0.9738023952095808, \"specificity\": 0.4822959373835259, \"npv\": 0.9249463902787706, \"accuracy\": 0.7767149902854581, \"f1\": 0.8393548387096774, \"f2\": 0.9151660101294317, \"f0_5\": 0.7751429933269781, \"p4\": 0.7223682434889545, \"phi\": 0.5496850207125374}, {\"truth_threshold\": -15.26, \"match_probability\": 2.5484211360819274e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11709, \"tn\": 3883, \"fp\": 4166, \"fn\": 315, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9738023952095808, \"tn_rate\": 0.48242017641943097, \"fp_rate\": 0.517579823580569, \"fn_rate\": 0.02619760479041916, \"precision\": 0.7375748031496063, \"recall\": 0.9738023952095808, \"specificity\": 0.48242017641943097, \"npv\": 0.9249642686993806, \"accuracy\": 0.7767648084491605, \"f1\": 0.8393849241908312, \"f2\": 0.915180316080724, \"f0_5\": 0.7751840474551136, \"p4\": 0.7224517794603259, \"phi\": 0.5497865760125864}, {\"truth_threshold\": -15.22, \"match_probability\": 2.6200651289799313e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11706, \"tn\": 3885, \"fp\": 4164, \"fn\": 318, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9735528942115769, \"tn_rate\": 0.48266865449124113, \"fp_rate\": 0.5173313455087588, \"fn_rate\": 0.026447105788423155, \"precision\": 0.7376181474480151, \"recall\": 0.9735528942115769, \"specificity\": 0.48266865449124113, \"npv\": 0.9243397573162027, \"accuracy\": 0.7767149902854581, \"f1\": 0.8393202839320284, \"f2\": 0.9150173529687646, \"f0_5\": 0.7751907183725365, \"p4\": 0.7224717673770988, \"phi\": 0.5495447756894828}, {\"truth_threshold\": -15.16, \"match_probability\": 2.7313251491794388e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11705, \"tn\": 3885, \"fp\": 4164, \"fn\": 319, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9734697272122422, \"tn_rate\": 0.48266865449124113, \"fp_rate\": 0.5173313455087588, \"fn_rate\": 0.026530272787757818, \"precision\": 0.7376016132081417, \"recall\": 0.9734697272122422, \"specificity\": 0.48266865449124113, \"npv\": 0.9241198858230257, \"accuracy\": 0.7766651721217556, \"f1\": 0.8392786720682609, \"f2\": 0.9149534901899476, \"f0_5\": 0.7751655629139073, \"p4\": 0.722422765362302, \"phi\": 0.5493965541450727}, {\"truth_threshold\": -15.14, \"match_probability\": 2.7694519714661317e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11703, \"tn\": 3889, \"fp\": 4160, \"fn\": 321, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9733033932135728, \"tn_rate\": 0.48316561063486146, \"fp_rate\": 0.5168343893651385, \"fn_rate\": 0.026696606786427147, \"precision\": 0.7377545231040786, \"recall\": 0.9733033932135728, \"specificity\": 0.48316561063486146, \"npv\": 0.9237529691211401, \"accuracy\": 0.7767648084491605, \"f1\": 0.8393158102341592, \"f2\": 0.9148829719038759, \"f0_5\": 0.7752795590651332, \"p4\": 0.7226585527558353, \"phi\": 0.549506747924283}, {\"truth_threshold\": -15.1, \"match_probability\": 2.8473096472119992e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11701, \"tn\": 3891, \"fp\": 4158, \"fn\": 323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9731370592149036, \"tn_rate\": 0.48341408870667163, \"fp_rate\": 0.5165859112933283, \"fn_rate\": 0.026862940785096472, \"precision\": 0.737814490194842, \"recall\": 0.9731370592149036, \"specificity\": 0.48341408870667163, \"npv\": 0.9233507356430944, \"accuracy\": 0.7767648084491605, \"f1\": 0.839292759028799, \"f2\": 0.9147838323821437, \"f0_5\": 0.775311423270607, \"p4\": 0.7227273383163431, \"phi\": 0.5494139994777503}, {\"truth_threshold\": -15.02, \"match_probability\": 3.0096527780559407e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11701, \"tn\": 3895, \"fp\": 4154, \"fn\": 323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9731370592149036, \"tn_rate\": 0.48391104485029196, \"fp_rate\": 0.516088955149708, \"fn_rate\": 0.026862940785096472, \"precision\": 0.7380006307158625, \"recall\": 0.9731370592149036, \"specificity\": 0.48391104485029196, \"npv\": 0.9234234234234234, \"accuracy\": 0.7769640811039705, \"f1\": 0.8394131783779906, \"f2\": 0.9148410501790434, \"f0_5\": 0.7754758496368167, \"p4\": 0.723060674474036, \"phi\": 0.5498205251966097}, {\"truth_threshold\": -15.0, \"match_probability\": 3.0516646830846227e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11701, \"tn\": 3900, \"fp\": 4149, \"fn\": 323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9731370592149036, \"tn_rate\": 0.4845322400298174, \"fp_rate\": 0.5154677599701827, \"fn_rate\": 0.026862940785096472, \"precision\": 0.7382334384858045, \"recall\": 0.9731370592149036, \"specificity\": 0.4845322400298174, \"npv\": 0.9235140895098272, \"accuracy\": 0.777213171922483, \"f1\": 0.8395637511659612, \"f2\": 0.9149125824914772, \"f0_5\": 0.7756814806957998, \"p4\": 0.7234769432558131, \"phi\": 0.5503285631463145}, {\"truth_threshold\": -14.98, \"match_probability\": 3.094263016408827e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11701, \"tn\": 3902, \"fp\": 4147, \"fn\": 323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9731370592149036, \"tn_rate\": 0.48478071810162754, \"fp_rate\": 0.5152192818983725, \"fn_rate\": 0.026862940785096472, \"precision\": 0.738326602725896, \"recall\": 0.9731370592149036, \"specificity\": 0.48478071810162754, \"npv\": 0.9235502958579882, \"accuracy\": 0.7773128082498879, \"f1\": 0.8396239954075775, \"f2\": 0.9149411985487301, \"f0_5\": 0.7757637636575793, \"p4\": 0.7236433261287789, \"phi\": 0.5505317413707327}, {\"truth_threshold\": -14.94, \"match_probability\": 3.181251823059389e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11698, \"tn\": 3902, \"fp\": 4147, \"fn\": 326, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9728875582168995, \"tn_rate\": 0.48478071810162754, \"fp_rate\": 0.5152192818983725, \"fn_rate\": 0.027112441783100467, \"precision\": 0.7382770590091512, \"recall\": 0.9728875582168995, \"specificity\": 0.48478071810162754, \"npv\": 0.9228949858088931, \"accuracy\": 0.7771633537587804, \"f1\": 0.839499085004844, \"f2\": 0.9147495347273268, \"f0_5\": 0.7756882923982813, \"p4\": 0.7234963044078918, \"phi\": 0.5500886020468614}, {\"truth_threshold\": -14.92, \"match_probability\": 3.225659011119708e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11698, \"tn\": 3906, \"fp\": 4143, \"fn\": 326, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9728875582168995, \"tn_rate\": 0.48527767424524787, \"fp_rate\": 0.5147223257547522, \"fn_rate\": 0.027112441783100467, \"precision\": 0.738463480840856, \"recall\": 0.9728875582168995, \"specificity\": 0.48527767424524787, \"npv\": 0.9229678638941399, \"accuracy\": 0.7773626264135904, \"f1\": 0.8396195944733537, \"f2\": 0.9148067629072368, \"f0_5\": 0.7758529208892662, \"p4\": 0.7238288363691658, \"phi\": 0.5504950915478358}, {\"truth_threshold\": -14.88, \"match_probability\": 3.316341621965e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11694, \"tn\": 3908, \"fp\": 4141, \"fn\": 330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9725548902195609, \"tn_rate\": 0.48552615231705804, \"fp_rate\": 0.514473847682942, \"fn_rate\": 0.027445109780439122, \"precision\": 0.7384906851910326, \"recall\": 0.9725548902195609, \"specificity\": 0.48552615231705804, \"npv\": 0.9221330816422841, \"accuracy\": 0.7772629900861854, \"f1\": 0.8395132632183495, \"f2\": 0.9145797813267429, \"f0_5\": 0.7758346159970277, \"p4\": 0.7237989817354211, \"phi\": 0.550108374627649}, {\"truth_threshold\": -14.84, \"match_probability\": 3.4095734965395514e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11694, \"tn\": 3913, \"fp\": 4136, \"fn\": 330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9725548902195609, \"tn_rate\": 0.48614734749658345, \"fp_rate\": 0.5138526525034166, \"fn_rate\": 0.027445109780439122, \"precision\": 0.7387239418825016, \"recall\": 0.9725548902195609, \"specificity\": 0.48614734749658345, \"npv\": 0.9222248409144473, \"accuracy\": 0.7775120809046978, \"f1\": 0.8396639620880304, \"f2\": 0.9146513155836435, \"f0_5\": 0.7760405606285835, \"p4\": 0.7242140365405947, \"phi\": 0.5506166413074729}, {\"truth_threshold\": -14.82, \"match_probability\": 3.457167723387977e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11694, \"tn\": 3915, \"fp\": 4134, \"fn\": 330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9725548902195609, \"tn_rate\": 0.4863958255683936, \"fp_rate\": 0.5136041744316064, \"fn_rate\": 0.027445109780439122, \"precision\": 0.7388172858225929, \"recall\": 0.9725548902195609, \"specificity\": 0.4863958255683936, \"npv\": 0.9222614840989399, \"accuracy\": 0.7776117172321029, \"f1\": 0.8397242567858682, \"f2\": 0.9146799324197484, \"f0_5\": 0.776122969098439, \"p4\": 0.7243799347403155, \"phi\": 0.5508199112665663}, {\"truth_threshold\": -14.8, \"match_probability\": 3.505426294625404e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11694, \"tn\": 3918, \"fp\": 4131, \"fn\": 330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9725548902195609, \"tn_rate\": 0.4867685426761088, \"fp_rate\": 0.5132314573238912, \"fn_rate\": 0.027445109780439122, \"precision\": 0.7389573459715639, \"recall\": 0.9725548902195609, \"specificity\": 0.4867685426761088, \"npv\": 0.922316384180791, \"accuracy\": 0.7777611717232102, \"f1\": 0.839814715070559, \"f2\": 0.9147228610315858, \"f0_5\": 0.7762466146248208, \"p4\": 0.7246286497162073, \"phi\": 0.5511247769945607}, {\"truth_threshold\": -14.76, \"match_probability\": 3.603973690077914e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11694, \"tn\": 3920, \"fp\": 4129, \"fn\": 330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9725548902195609, \"tn_rate\": 0.48701702074791897, \"fp_rate\": 0.512982979252081, \"fn_rate\": 0.027445109780439122, \"precision\": 0.7390507489098148, \"recall\": 0.9725548902195609, \"specificity\": 0.48701702074791897, \"npv\": 0.9223529411764706, \"accuracy\": 0.7778608080506153, \"f1\": 0.8398750314216972, \"f2\": 0.9147514823448427, \"f0_5\": 0.7763290668649424, \"p4\": 0.7247943715942462, \"phi\": 0.5513279947308108}, {\"truth_threshold\": -14.74, \"match_probability\": 3.65428144951405e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11693, \"tn\": 3920, \"fp\": 4129, \"fn\": 331, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9724717232202262, \"tn_rate\": 0.48701702074791897, \"fp_rate\": 0.512982979252081, \"fn_rate\": 0.027528276779773785, \"precision\": 0.7390342560991026, \"recall\": 0.9724717232202262, \"specificity\": 0.48701702074791897, \"npv\": 0.9221359680075276, \"accuracy\": 0.7778109898869128, \"f1\": 0.839833369245134, \"f2\": 0.9146875684470728, \"f0_5\": 0.7763039090715955, \"p4\": 0.7247453575619469, \"phi\": 0.5511808013926941}, {\"truth_threshold\": -14.72, \"match_probability\": 3.7052914274172446e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3920, \"fp\": 4129, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.48701702074791897, \"fp_rate\": 0.512982979252081, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7390177612034637, \"recall\": 0.9723885562208916, \"specificity\": 0.48701702074791897, \"npv\": 0.9219190968955786, \"accuracy\": 0.7777611717232102, \"f1\": 0.8397917040761358, \"f2\": 0.9146236525494, \"f0_5\": 0.7762787486057258, \"p4\": 0.7246963475051983, \"phi\": 0.5510336456469273}, {\"truth_threshold\": -14.68, \"match_probability\": 3.809457380009125e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3921, \"fp\": 4128, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.48714125978382405, \"fp_rate\": 0.512858740216176, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7390644753476612, \"recall\": 0.9723885562208916, \"specificity\": 0.48714125978382405, \"npv\": 0.9219374559134729, \"accuracy\": 0.7778109898869128, \"f1\": 0.8398218646746157, \"f2\": 0.9146379623255523, \"f0_5\": 0.7763199830022309, \"p4\": 0.7247791786444581, \"phi\": 0.5511352790841741}, {\"truth_threshold\": -14.6, \"match_probability\": 4.026656429207677e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3928, \"fp\": 4121, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.48801093303515963, \"fp_rate\": 0.5119890669648404, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7393916397900462, \"recall\": 0.9723885562208916, \"specificity\": 0.48801093303515963, \"npv\": 0.9220657276995305, \"accuracy\": 0.7781597170328302, \"f1\": 0.8400330495383842, \"f2\": 0.9147381432975011, \"f0_5\": 0.7766087464796216, \"p4\": 0.7253585046900551, \"phi\": 0.5518465675863657}, {\"truth_threshold\": -14.540000000000001, \"match_probability\": 4.197644280356719e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3930, \"fp\": 4119, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.4882594111069698, \"fp_rate\": 0.5117405888930302, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7394851685535386, \"recall\": 0.9723885562208916, \"specificity\": 0.4882594111069698, \"npv\": 0.9221022993899578, \"accuracy\": 0.7782593533602351, \"f1\": 0.8400934075803844, \"f2\": 0.9147667704633295, \"f0_5\": 0.7766912897911463, \"p4\": 0.7255238685783112, \"phi\": 0.5520497462346653}, {\"truth_threshold\": -14.52, \"match_probability\": 4.2562387168288515e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3931, \"fp\": 4118, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.4883836501428749, \"fp_rate\": 0.5116163498571251, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7395319418089816, \"recall\": 0.9723885562208916, \"specificity\": 0.4883836501428749, \"npv\": 0.9221205723668778, \"accuracy\": 0.7783091715239376, \"f1\": 0.8401235898541353, \"f2\": 0.9147810847181799, \"f0_5\": 0.7767325680272109, \"p4\": 0.7256065242626873, \"phi\": 0.5521513278105414}, {\"truth_threshold\": -14.48, \"match_probability\": 4.3758926381643505e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3932, \"fp\": 4117, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.48850788917877996, \"fp_rate\": 0.51149211082122, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7395787209817193, \"recall\": 0.9723885562208916, \"specificity\": 0.48850788917877996, \"npv\": 0.9221388367729831, \"accuracy\": 0.7783589896876402, \"f1\": 0.8401537742966981, \"f2\": 0.9147953994210156, \"f0_5\": 0.7767738506510763, \"p4\": 0.7256891624530089, \"phi\": 0.5522529042274873}, {\"truth_threshold\": -14.46, \"match_probability\": 4.4369751126756925e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11692, \"tn\": 3933, \"fp\": 4116, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723885562208916, \"tn_rate\": 0.48863212821468505, \"fp_rate\": 0.511367871785315, \"fn_rate\": 0.02761144377910845, \"precision\": 0.7396255060728745, \"recall\": 0.9723885562208916, \"specificity\": 0.48863212821468505, \"npv\": 0.9221570926143025, \"accuracy\": 0.7784088078513426, \"f1\": 0.8401839609083069, \"f2\": 0.9148097145718578, \"f0_5\": 0.7768151376634421, \"p4\": 0.7257717831586027, \"phi\": 0.552354475490438}, {\"truth_threshold\": -14.38, \"match_probability\": 4.6899508746246485e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11691, \"tn\": 3935, \"fp\": 4114, \"fn\": 333, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723053892215568, \"tn_rate\": 0.4888806062864952, \"fp_rate\": 0.5111193937135048, \"fn_rate\": 0.027694610778443114, \"precision\": 0.7397026257513445, \"recall\": 0.9723053892215568, \"specificity\": 0.4888806062864952, \"npv\": 0.9219775070290535, \"accuracy\": 0.7784586260150451, \"f1\": 0.8402026662833735, \"f2\": 0.9147744166757954, \"f0_5\": 0.7768725745574397, \"p4\": 0.7258879406960558, \"phi\": 0.5524107264927319}, {\"truth_threshold\": -14.32, \"match_probability\": 4.8891034695705744e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11691, \"tn\": 3936, \"fp\": 4113, \"fn\": 333, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9723053892215568, \"tn_rate\": 0.4890048453224003, \"fp_rate\": 0.5109951546775997, \"fn_rate\": 0.027694610778443114, \"precision\": 0.739749430523918, \"recall\": 0.9723053892215568, \"specificity\": 0.4890048453224003, \"npv\": 0.9219957835558679, \"accuracy\": 0.7785084441787475, \"f1\": 0.8402328589909444, \"f2\": 0.9147887323943662, \"f0_5\": 0.7769138755980861, \"p4\": 0.72597050732035, \"phi\": 0.5525122984291727}, {\"truth_threshold\": -14.3, \"match_probability\": 4.9573494272870864e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11690, \"tn\": 3936, \"fp\": 4113, \"fn\": 334, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9722222222222222, \"tn_rate\": 0.4890048453224003, \"fp_rate\": 0.5109951546775997, \"fn_rate\": 0.027777777777777776, \"precision\": 0.7397329620958046, \"recall\": 0.9722222222222222, \"specificity\": 0.4890048453224003, \"npv\": 0.9217798594847775, \"accuracy\": 0.7784586260150451, \"f1\": 0.840191181226866, \"f2\": 0.9147248000751186, \"f0_5\": 0.7768887234834387, \"p4\": 0.725921478142319, \"phi\": 0.5523654757864407}, {\"truth_threshold\": -14.280000000000001, \"match_probability\": 5.026547967956725e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11689, \"tn\": 3937, \"fp\": 4112, \"fn\": 335, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9721390552228876, \"tn_rate\": 0.4891290843583054, \"fp_rate\": 0.5108709156416946, \"fn_rate\": 0.027860944777112442, \"precision\": 0.7397633061198658, \"recall\": 0.9721390552228876, \"specificity\": 0.4891290843583054, \"npv\": 0.9215823970037453, \"accuracy\": 0.7784586260150451, \"f1\": 0.8401796945193172, \"f2\": 0.9146751803684054, \"f0_5\": 0.7769048758441006, \"p4\": 0.7259549987369422, \"phi\": 0.5523202894153392}, {\"truth_threshold\": -14.26, \"match_probability\": 5.096712386468152e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11688, \"tn\": 3937, \"fp\": 4112, \"fn\": 336, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9720558882235529, \"tn_rate\": 0.4891290843583054, \"fp_rate\": 0.5108709156416946, \"fn_rate\": 0.027944111776447105, \"precision\": 0.739746835443038, \"recall\": 0.9720558882235529, \"specificity\": 0.4891290843583054, \"npv\": 0.9213667212731103, \"accuracy\": 0.7784088078513426, \"f1\": 0.8401380103507763, \"f2\": 0.9146112432703143, \"f0_5\": 0.7768797192385409, \"p4\": 0.7259059757955494, \"phi\": 0.5521735574324722}, {\"truth_threshold\": -14.24, \"match_probability\": 5.1678561632245805e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11687, \"tn\": 3937, \"fp\": 4112, \"fn\": 337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9719727212242182, \"tn_rate\": 0.4891290843583054, \"fp_rate\": 0.5108709156416946, \"fn_rate\": 0.02802727877578177, \"precision\": 0.7397303626811823, \"recall\": 0.9719727212242182, \"specificity\": 0.4891290843583054, \"npv\": 0.9211511464670098, \"accuracy\": 0.7783589896876402, \"f1\": 0.8400963231858535, \"f2\": 0.9145473041709054, \"f0_5\": 0.7768545599574581, \"p4\": 0.7258569568123989, \"phi\": 0.5520268627017481}, {\"truth_threshold\": -14.22, \"match_probability\": 5.2399929667313805e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11687, \"tn\": 3994, \"fp\": 4055, \"fn\": 337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9719727212242182, \"tn_rate\": 0.49621070940489503, \"fp_rate\": 0.503789290595105, \"fn_rate\": 0.02802727877578177, \"precision\": 0.7424088425867107, \"recall\": 0.9719727212242182, \"specificity\": 0.49621070940489503, \"npv\": 0.9221888709305011, \"accuracy\": 0.7811986250186818, \"f1\": 0.8418209320751999, \"f2\": 0.9153638898461731, \"f0_5\": 0.7792164497546405, \"p4\": 0.7305333436334662, \"phi\": 0.5578114712900344}, {\"truth_threshold\": -14.200000000000001, \"match_probability\": 5.31313665621969e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11687, \"tn\": 3996, \"fp\": 4053, \"fn\": 337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9719727212242182, \"tn_rate\": 0.4964591874767052, \"fp_rate\": 0.5035408125232949, \"fn_rate\": 0.02802727877578177, \"precision\": 0.7425031766200763, \"recall\": 0.9719727212242182, \"specificity\": 0.4964591874767052, \"npv\": 0.9222247865220402, \"accuracy\": 0.7812982613460868, \"f1\": 0.8418815732603371, \"f2\": 0.9153925684566702, \"f0_5\": 0.7792995839112344, \"p4\": 0.7306964197437673, \"phi\": 0.5580141472593133}, {\"truth_threshold\": -14.18, \"match_probability\": 5.3873012843066357e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11686, \"tn\": 3996, \"fp\": 4053, \"fn\": 338, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9718895542248835, \"tn_rate\": 0.4964591874767052, \"fp_rate\": 0.5035408125232949, \"fn_rate\": 0.028110445775116434, \"precision\": 0.7424868161890844, \"recall\": 0.9718895542248835, \"specificity\": 0.4964591874767052, \"npv\": 0.9220119981541302, \"accuracy\": 0.7812484431823843, \"f1\": 0.8418398588048842, \"f2\": 0.9153285814991776, \"f0_5\": 0.7792744731928515, \"p4\": 0.7306473071408628, \"phi\": 0.5578684285383447}, {\"truth_threshold\": -14.16, \"match_probability\": 5.462501099692568e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11684, \"tn\": 4004, \"fp\": 4045, \"fn\": 340, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9717232202262143, \"tn_rate\": 0.4974530997639458, \"fp_rate\": 0.5025469002360542, \"fn_rate\": 0.028276779773785763, \"precision\": 0.7428317121241019, \"recall\": 0.9717232202262143, \"specificity\": 0.4974530997639458, \"npv\": 0.921731123388582, \"accuracy\": 0.7815473521645993, \"f1\": 0.8419990631643426, \"f2\": 0.9153153153153153, \"f0_5\": 0.7795569789164665, \"p4\": 0.7312006841562517, \"phi\": 0.5583879883808991}, {\"truth_threshold\": -14.14, \"match_probability\": 5.538750549895966e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11682, \"tn\": 4011, \"fp\": 4038, \"fn\": 342, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9715568862275449, \"tn_rate\": 0.4983227730152814, \"fp_rate\": 0.5016772269847186, \"fn_rate\": 0.02844311377245509, \"precision\": 0.7431297709923664, \"recall\": 0.9715568862275449, \"specificity\": 0.4983227730152814, \"npv\": 0.9214334941419711, \"accuracy\": 0.7817964429831117, \"f1\": 0.842128027681661, \"f2\": 0.9152877021436631, \"f0_5\": 0.7797981416212753, \"p4\": 0.7316716962310801, \"phi\": 0.5588065502180719}, {\"truth_threshold\": -14.120000000000001, \"match_probability\": 5.616064284026378e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11672, \"tn\": 4012, \"fp\": 4037, \"fn\": 352, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9707252162341983, \"tn_rate\": 0.49844701205118647, \"fp_rate\": 0.5015529879488135, \"fn_rate\": 0.02927478376580173, \"precision\": 0.7430135591062448, \"recall\": 0.9707252162341983, \"specificity\": 0.49844701205118647, \"npv\": 0.919340054995417, \"accuracy\": 0.7813480795097892, \"f1\": 0.8417408863087297, \"f2\": 0.9146618603557715, \"f0_5\": 0.7795885653219343, \"p4\": 0.7312619343469535, \"phi\": 0.5574566539570179}, {\"truth_threshold\": -14.1, \"match_probability\": 5.6944571555960515e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11672, \"tn\": 4013, \"fp\": 4036, \"fn\": 352, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9707252162341983, \"tn_rate\": 0.49857125108709155, \"fp_rate\": 0.5014287489129085, \"fn_rate\": 0.02927478376580173, \"precision\": 0.7430608607079195, \"recall\": 0.9707252162341983, \"specificity\": 0.49857125108709155, \"npv\": 0.9193585337915234, \"accuracy\": 0.7813978976734918, \"f1\": 0.8417712390018751, \"f2\": 0.91467619584979, \"f0_5\": 0.7796302233621888, \"p4\": 0.731343153778365, \"phi\": 0.5575581420118412}, {\"truth_threshold\": -14.040000000000001, \"match_probability\": 5.936262256248524e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11672, \"tn\": 4015, \"fp\": 4034, \"fn\": 352, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9707252162341983, \"tn_rate\": 0.4988197291589017, \"fp_rate\": 0.5011802708410983, \"fn_rate\": 0.02927478376580173, \"precision\": 0.7431554819814084, \"recall\": 0.9707252162341983, \"specificity\": 0.4988197291589017, \"npv\": 0.9193954659949622, \"accuracy\": 0.7814975340008967, \"f1\": 0.8418319509556437, \"f2\": 0.9147048681859503, \"f0_5\": 0.779713552800342, \"p4\": 0.7315055424644111, \"phi\": 0.5577611035987643}, {\"truth_threshold\": -14.02, \"match_probability\": 6.01912440136712e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11658, \"tn\": 4015, \"fp\": 4034, \"fn\": 366, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.969560878243513, \"tn_rate\": 0.4988197291589017, \"fp_rate\": 0.5011802708410983, \"fn_rate\": 0.030439121756487025, \"precision\": 0.7429263318888606, \"recall\": 0.969560878243513, \"specificity\": 0.4988197291589017, \"npv\": 0.9164574298105456, \"accuracy\": 0.780800079709062, \"f1\": 0.8412469331793909, \"f2\": 0.9138082397943187, \"f0_5\": 0.7793614290298427, \"p4\": 0.7308187075244699, \"phi\": 0.5557360585890184}, {\"truth_threshold\": -14.0, \"match_probability\": 6.1031431187061336e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11657, \"tn\": 4019, \"fp\": 4030, \"fn\": 367, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9694777112441784, \"tn_rate\": 0.49931668530252205, \"fp_rate\": 0.500683314697478, \"fn_rate\": 0.03052228875582169, \"precision\": 0.7430993816535986, \"recall\": 0.9694777112441784, \"specificity\": 0.49931668530252205, \"npv\": 0.9163246694026448, \"accuracy\": 0.7809495342001693, \"f1\": 0.8413265490238534, \"f2\": 0.9138014831538184, \"f0_5\": 0.7795030225217996, \"p4\": 0.7310941568219109, \"phi\": 0.555998471295823}, {\"truth_threshold\": -13.96, \"match_probability\": 6.274715060076599e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11657, \"tn\": 4020, \"fp\": 4029, \"fn\": 367, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9694777112441784, \"tn_rate\": 0.49944092433842713, \"fp_rate\": 0.5005590756615729, \"fn_rate\": 0.03052228875582169, \"precision\": 0.7431467550682137, \"recall\": 0.9694777112441784, \"specificity\": 0.49944092433842713, \"npv\": 0.9163437428766811, \"accuracy\": 0.7809993523638719, \"f1\": 0.8413569108625045, \"f2\": 0.9138158101031639, \"f0_5\": 0.7795447250160497, \"p4\": 0.7311752351136944, \"phi\": 0.5561001568746525}, {\"truth_threshold\": -13.94, \"match_probability\": 6.362301245294422e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11656, \"tn\": 4024, \"fp\": 4025, \"fn\": 368, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9693945442448436, \"tn_rate\": 0.49993788048204746, \"fp_rate\": 0.5000621195179525, \"fn_rate\": 0.030605455755156354, \"precision\": 0.7433199413302723, \"recall\": 0.9693945442448436, \"specificity\": 0.49993788048204746, \"npv\": 0.9162112932604736, \"accuracy\": 0.7811488068549793, \"f1\": 0.8414365637971485, \"f2\": 0.9138090534205121, \"f0_5\": 0.779686413014395, \"p4\": 0.7314503405760162, \"phi\": 0.5563626456849837}, {\"truth_threshold\": -13.92, \"match_probability\": 6.451109931430596e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11655, \"tn\": 4024, \"fp\": 4025, \"fn\": 369, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.969311377245509, \"tn_rate\": 0.49993788048204746, \"fp_rate\": 0.5000621195179525, \"fn_rate\": 0.030688622754491017, \"precision\": 0.7433035714285714, \"recall\": 0.969311377245509, \"specificity\": 0.49993788048204746, \"npv\": 0.916002731618484, \"accuracy\": 0.7810989886912768, \"f1\": 0.841394744441236, \"f2\": 0.9137449824385349, \"f0_5\": 0.7796612437118698, \"p4\": 0.731401303163728, \"phi\": 0.5562184762482546}, {\"truth_threshold\": -13.84, \"match_probability\": 6.818914497177655e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11651, \"tn\": 4024, \"fp\": 4025, \"fn\": 373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9689787092481703, \"tn_rate\": 0.49993788048204746, \"fp_rate\": 0.5000621195179525, \"fn_rate\": 0.031021290751829675, \"precision\": 0.7432380709364634, \"recall\": 0.9689787092481703, \"specificity\": 0.49993788048204746, \"npv\": 0.9151694337047988, \"accuracy\": 0.7808997160364669, \"f1\": 0.8412274368231047, \"f2\": 0.9134886784168601, \"f0_5\": 0.7795605395567926, \"p4\": 0.7312051921412467, \"phi\": 0.5556421525848837}, {\"truth_threshold\": -13.82, \"match_probability\": 6.914096414866335e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11580, \"tn\": 4029, \"fp\": 4020, \"fn\": 444, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9630738522954092, \"tn_rate\": 0.5005590756615729, \"fp_rate\": 0.49944092433842713, \"fn_rate\": 0.036926147704590816, \"precision\": 0.7423076923076923, \"recall\": 0.9630738522954092, \"specificity\": 0.5005590756615729, \"npv\": 0.9007377598926894, \"accuracy\": 0.7776117172321029, \"f1\": 0.838401390095569, \"f2\": 0.9090052750565185, \"f0_5\": 0.7779748468236053, \"p4\": 0.7281386210484563, \"phi\": 0.5460192723824723}, {\"truth_threshold\": -13.8, \"match_probability\": 7.01060683759531e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11579, \"tn\": 4029, \"fp\": 4020, \"fn\": 445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9629906852960746, \"tn_rate\": 0.5005590756615729, \"fp_rate\": 0.49944092433842713, \"fn_rate\": 0.03700931470392548, \"precision\": 0.7422911725110584, \"recall\": 0.9629906852960746, \"specificity\": 0.5005590756615729, \"npv\": 0.900536432722396, \"accuracy\": 0.7775618990684003, \"f1\": 0.8383593382326322, \"f2\": 0.9089410471779574, \"f0_5\": 0.777949475947326, \"p4\": 0.7280898662817922, \"phi\": 0.5458778093520058}, {\"truth_threshold\": -13.780000000000001, \"match_probability\": 7.10846430540288e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11577, \"tn\": 4029, \"fp\": 4020, \"fn\": 447, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9628243512974052, \"tn_rate\": 0.5005590756615729, \"fp_rate\": 0.49944092433842713, \"fn_rate\": 0.03717564870259481, \"precision\": 0.7422581265628005, \"recall\": 0.9628243512974052, \"specificity\": 0.5005590756615729, \"npv\": 0.9001340482573726, \"accuracy\": 0.7774622627409954, \"f1\": 0.8382752253719996, \"f2\": 0.9088125853704488, \"f0_5\": 0.7778987260119336, \"p4\": 0.7279923681165892, \"phi\": 0.5455949847824875}, {\"truth_threshold\": -13.76, \"match_probability\": 7.207687616990448e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11576, \"tn\": 4030, \"fp\": 4019, \"fn\": 448, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9627411842980705, \"tn_rate\": 0.500683314697478, \"fp_rate\": 0.49931668530252205, \"fn_rate\": 0.037258815701929474, \"precision\": 0.7422891952548893, \"recall\": 0.9627411842980705, \"specificity\": 0.500683314697478, \"npv\": 0.899955337204109, \"accuracy\": 0.7774622627409954, \"f1\": 0.8382635142474384, \"f2\": 0.9087626195223815, \"f0_5\": 0.7779151658512983, \"p4\": 0.7280244040817531, \"phi\": 0.5455564596697958}, {\"truth_threshold\": -13.72, \"match_probability\": 7.410308281316996e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11575, \"tn\": 4030, \"fp\": 4019, \"fn\": 449, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9626580172987359, \"tn_rate\": 0.500683314697478, \"fp_rate\": 0.49931668530252205, \"fn_rate\": 0.03734198270126414, \"precision\": 0.7422726689752469, \"recall\": 0.9626580172987359, \"specificity\": 0.500683314697478, \"npv\": 0.8997544094663987, \"accuracy\": 0.7774124445772929, \"f1\": 0.8382214497791296, \"f2\": 0.908698382791647, \"f0_5\": 0.7778897849462365, \"p4\": 0.7279756627992728, \"phi\": 0.5454151461985537}, {\"truth_threshold\": -13.68, \"match_probability\": 7.61862453176377e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11575, \"tn\": 4032, \"fp\": 4017, \"fn\": 449, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9626580172987359, \"tn_rate\": 0.5009317927692881, \"fp_rate\": 0.4990682072307119, \"fn_rate\": 0.03734198270126414, \"precision\": 0.7423678809645973, \"recall\": 0.9626580172987359, \"specificity\": 0.5009317927692881, \"npv\": 0.8997991519750056, \"accuracy\": 0.7775120809046978, \"f1\": 0.8382821552723059, \"f2\": 0.908726918728803, \"f0_5\": 0.7779734380040865, \"p4\": 0.7281371687584465, \"phi\": 0.5456208324765623}, {\"truth_threshold\": -13.66, \"match_probability\": 7.724968351281685e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11572, \"tn\": 4033, \"fp\": 4016, \"fn\": 452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9624085163007319, \"tn_rate\": 0.5010560318051932, \"fp_rate\": 0.4989439681948068, \"fn_rate\": 0.03759148369926813, \"precision\": 0.7423659225044906, \"recall\": 0.9624085163007319, \"specificity\": 0.5010560318051932, \"npv\": 0.8992196209587514, \"accuracy\": 0.7774124445772929, \"f1\": 0.8381862958134144, \"f2\": 0.9085484580114315, \"f0_5\": 0.7779391201462837, \"p4\": 0.7280716808832908, \"phi\": 0.545300058658062}, {\"truth_threshold\": -13.64, \"match_probability\": 7.832796444243376e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11572, \"tn\": 4037, \"fp\": 4012, \"fn\": 452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9624085163007319, \"tn_rate\": 0.5015529879488135, \"fp_rate\": 0.49844701205118647, \"fn_rate\": 0.03759148369926813, \"precision\": 0.7425564681724846, \"recall\": 0.9624085163007319, \"specificity\": 0.5015529879488135, \"npv\": 0.8993094230340833, \"accuracy\": 0.7776117172321029, \"f1\": 0.8383077368878586, \"f2\": 0.9086055276381909, \"f0_5\": 0.7781065088757396, \"p4\": 0.7283944095629075, \"phi\": 0.5457115212368843}, {\"truth_threshold\": -13.6, \"match_probability\": 8.052988592232462e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11572, \"tn\": 4048, \"fp\": 4001, \"fn\": 452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9624085163007319, \"tn_rate\": 0.5029196173437694, \"fp_rate\": 0.4970803826562306, \"fn_rate\": 0.03759148369926813, \"precision\": 0.7430809734797406, \"recall\": 0.9624085163007319, \"specificity\": 0.5029196173437694, \"npv\": 0.8995555555555556, \"accuracy\": 0.7781597170328302, \"f1\": 0.8386418813639164, \"f2\": 0.9087625060861644, \"f0_5\": 0.7785671995263469, \"p4\": 0.7292805606688871, \"phi\": 0.5468426251379593}, {\"truth_threshold\": -13.56, \"match_probability\": 8.279370173056753e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11572, \"tn\": 4052, \"fp\": 3997, \"fn\": 452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9624085163007319, \"tn_rate\": 0.5034165734873898, \"fp_rate\": 0.4965834265126103, \"fn_rate\": 0.03759148369926813, \"precision\": 0.7432718864410046, \"recall\": 0.9624085163007319, \"specificity\": 0.5034165734873898, \"npv\": 0.8996447602131439, \"accuracy\": 0.7783589896876402, \"f1\": 0.8387634544993295, \"f2\": 0.9088196026073981, \"f0_5\": 0.7787348586810229, \"p4\": 0.7296023071554414, \"phi\": 0.5472537845039965}, {\"truth_threshold\": -13.540000000000001, \"match_probability\": 8.39493617115541e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11571, \"tn\": 4052, \"fp\": 3997, \"fn\": 453, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9623253493013972, \"tn_rate\": 0.5034165734873898, \"fp_rate\": 0.4965834265126103, \"fn_rate\": 0.0376746506986028, \"precision\": 0.7432553956834532, \"recall\": 0.9623253493013972, \"specificity\": 0.5034165734873898, \"npv\": 0.8994450610432853, \"accuracy\": 0.7783091715239376, \"f1\": 0.8387213685126124, \"f2\": 0.9087553405378236, \"f0_5\": 0.7787094863788091, \"p4\": 0.7295535444836199, \"phi\": 0.5471129193257482}, {\"truth_threshold\": -13.5, \"match_probability\": 8.630929581276842e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11570, \"tn\": 4057, \"fp\": 3992, \"fn\": 454, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9622421823020625, \"tn_rate\": 0.5040377686669152, \"fp_rate\": 0.49596223133308487, \"fn_rate\": 0.03775781769793746, \"precision\": 0.7434777020948464, \"recall\": 0.9622421823020625, \"specificity\": 0.5040377686669152, \"npv\": 0.8993571270228331, \"accuracy\": 0.7785084441787475, \"f1\": 0.8388312912346843, \"f2\": 0.9087624493386535, \"f0_5\": 0.778893795777682, \"p4\": 0.7299065857921175, \"phi\": 0.5474860661260181}, {\"truth_threshold\": -13.48, \"match_probability\": 8.751402324358653e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11566, \"tn\": 4059, \"fp\": 3990, \"fn\": 458, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9619095143047239, \"tn_rate\": 0.5042862467387254, \"fp_rate\": 0.4957137532612747, \"fn_rate\": 0.038090485695276115, \"precision\": 0.7435073283620468, \"recall\": 0.9619095143047239, \"specificity\": 0.5042862467387254, \"npv\": 0.8986052689838389, \"accuracy\": 0.7784088078513426, \"f1\": 0.8387237128353879, \"f2\": 0.9085339030980959, \"f0_5\": 0.7788761986854865, \"p4\": 0.7298721479823649, \"phi\": 0.5471290259118511}, {\"truth_threshold\": -13.46, \"match_probability\": 8.873556507857524e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11566, \"tn\": 4115, \"fp\": 3934, \"fn\": 458, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9619095143047239, \"tn_rate\": 0.5112436327494099, \"fp_rate\": 0.48875636725059013, \"fn_rate\": 0.038090485695276115, \"precision\": 0.7461935483870967, \"recall\": 0.9619095143047239, \"specificity\": 0.5112436327494099, \"npv\": 0.899846927618631, \"accuracy\": 0.7811986250186818, \"f1\": 0.8404301700334253, \"f2\": 0.9093339203723505, \"f0_5\": 0.7812331135847833, \"p4\": 0.7343426573310045, \"phi\": 0.55287981003692}, {\"truth_threshold\": -13.44, \"match_probability\": 8.997415595475012e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11563, \"tn\": 4116, \"fp\": 3933, \"fn\": 461, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9616600133067199, \"tn_rate\": 0.511367871785315, \"fp_rate\": 0.48863212821468505, \"fn_rate\": 0.038339986693280106, \"precision\": 0.7461925658234383, \"recall\": 0.9616600133067199, \"specificity\": 0.511367871785315, \"npv\": 0.8992790037142233, \"accuracy\": 0.7810989886912768, \"f1\": 0.8403343023255814, \"f2\": 0.9091552396527866, \"f0_5\": 0.7811993298021835, \"p4\": 0.7342755140248254, \"phi\": 0.5525631651000964}, {\"truth_threshold\": -13.38, \"match_probability\": 9.379461857095894e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11563, \"tn\": 4122, \"fp\": 3927, \"fn\": 461, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9616600133067199, \"tn_rate\": 0.5121133060007454, \"fp_rate\": 0.48788669399925455, \"fn_rate\": 0.038339986693280106, \"precision\": 0.7464816010329245, \"recall\": 0.9616600133067199, \"specificity\": 0.5121133060007454, \"npv\": 0.8994108662448178, \"accuracy\": 0.7813978976734918, \"f1\": 0.8405175546994258, \"f2\": 0.9092410278992231, \"f0_5\": 0.7814527465397924, \"p4\": 0.734751418205371, \"phi\": 0.553178649387216}, {\"truth_threshold\": -13.34, \"match_probability\": 9.643128993659314e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11562, \"tn\": 4122, \"fp\": 3927, \"fn\": 462, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9615768463073853, \"tn_rate\": 0.5121133060007454, \"fp_rate\": 0.48788669399925455, \"fn_rate\": 0.03842315369261477, \"precision\": 0.7464652333914391, \"recall\": 0.9615768463073853, \"specificity\": 0.5121133060007454, \"npv\": 0.8992146596858639, \"accuracy\": 0.7813480795097892, \"f1\": 0.8404754116235961, \"f2\": 0.9091766926161831, \"f0_5\": 0.7814274128142741, \"p4\": 0.7347025759285037, \"phi\": 0.5530390645280722}, {\"truth_threshold\": -13.32, \"match_probability\": 9.777728895858458e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11561, \"tn\": 4124, \"fp\": 3925, \"fn\": 463, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9614936793080505, \"tn_rate\": 0.5123617840725556, \"fp_rate\": 0.4876382159274444, \"fn_rate\": 0.03850632069194943, \"precision\": 0.7465452666924964, \"recall\": 0.9614936793080505, \"specificity\": 0.5123617840725556, \"npv\": 0.8990625681273163, \"accuracy\": 0.7813978976734918, \"f1\": 0.8404943656852054, \"f2\": 0.9091409518417162, \"f0_5\": 0.7814865887951546, \"p4\": 0.7348122401006386, \"phi\": 0.5531046914741298}, {\"truth_threshold\": -13.3, \"match_probability\": 9.914207372671765e-05, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11560, \"tn\": 4125, \"fp\": 3924, \"fn\": 464, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9614105123087159, \"tn_rate\": 0.5124860231084607, \"fp_rate\": 0.4875139768915393, \"fn_rate\": 0.0385894876912841, \"precision\": 0.7465771118574012, \"recall\": 0.9614105123087159, \"specificity\": 0.5124860231084607, \"npv\": 0.8988886467640008, \"accuracy\": 0.7813978976734918, \"f1\": 0.8404827686491203, \"f2\": 0.9090909090909091, \"f0_5\": 0.7815035154137372, \"p4\": 0.7348426283310535, \"phi\": 0.553067795790988}, {\"truth_threshold\": -13.280000000000001, \"match_probability\": 0.00010052590637623026, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11559, \"tn\": 4126, \"fp\": 3923, \"fn\": 465, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9613273453093812, \"tn_rate\": 0.5126102621443658, \"fp_rate\": 0.4873897378556342, \"fn_rate\": 0.038672654690618764, \"precision\": 0.7466089652499677, \"recall\": 0.9613273453093812, \"specificity\": 0.5126102621443658, \"npv\": 0.89871487693313, \"accuracy\": 0.7813978976734918, \"f1\": 0.8404711699265615, \"f2\": 0.9090408631916701, \"f0_5\": 0.7815204456945045, \"p4\": 0.7348730014273436, \"phi\": 0.553030955550516}, {\"truth_threshold\": -13.26, \"match_probability\": 0.00010192905269870875, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11557, \"tn\": 4132, \"fp\": 3917, \"fn\": 467, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9611610113107119, \"tn_rate\": 0.5133556963597963, \"fp_rate\": 0.4866443036402038, \"fn_rate\": 0.03883898868928809, \"precision\": 0.7468657102236009, \"recall\": 0.9611610113107119, \"specificity\": 0.5133556963597963, \"npv\": 0.898456186127419, \"accuracy\": 0.7815971703283017, \"f1\": 0.8405702232889665, \"f2\": 0.908997955010225, \"f0_5\": 0.7817234848484849, \"p4\": 0.7352502440850673, \"phi\": 0.5533678899648722}, {\"truth_threshold\": -13.24, \"match_probability\": 0.00010335178219304575, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11557, \"tn\": 4133, \"fp\": 3916, \"fn\": 467, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9611610113107119, \"tn_rate\": 0.5134799353957014, \"fp_rate\": 0.4865200646042987, \"fn_rate\": 0.03883898868928809, \"precision\": 0.746913979189556, \"recall\": 0.9611610113107119, \"specificity\": 0.5134799353957014, \"npv\": 0.8984782608695652, \"accuracy\": 0.7816469884920042, \"f1\": 0.8406007928137615, \"f2\": 0.90901225440073, \"f0_5\": 0.7817657881920017, \"p4\": 0.7353293405061473, \"phi\": 0.5534704904677701}, {\"truth_threshold\": -13.22, \"match_probability\": 0.00010479436811710874, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11557, \"tn\": 4134, \"fp\": 3915, \"fn\": 467, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9611610113107119, \"tn_rate\": 0.5136041744316064, \"fp_rate\": 0.4863958255683936, \"fn_rate\": 0.03883898868928809, \"precision\": 0.7469622543950362, \"recall\": 0.9611610113107119, \"specificity\": 0.5136041744316064, \"npv\": 0.8985003260160834, \"accuracy\": 0.7816968066557066, \"f1\": 0.8406313645621182, \"f2\": 0.9090265542411277, \"f0_5\": 0.7818080961142981, \"p4\": 0.7354084213283542, \"phi\": 0.5535730863026139}, {\"truth_threshold\": -13.200000000000001, \"match_probability\": 0.00010625708754012587, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11556, \"tn\": 4134, \"fp\": 3915, \"fn\": 468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9610778443113772, \"tn_rate\": 0.5136041744316064, \"fp_rate\": 0.4863958255683936, \"fn_rate\": 0.038922155688622756, \"precision\": 0.7469458987783595, \"recall\": 0.9610778443113772, \"specificity\": 0.5136041744316064, \"npv\": 0.8983050847457628, \"accuracy\": 0.7816469884920042, \"f1\": 0.8405891980360065, \"f2\": 0.9089621973665581, \"f0_5\": 0.7817827569410618, \"p4\": 0.7353595822625326, \"phi\": 0.5534338618616736}, {\"truth_threshold\": -13.18, \"match_probability\": 0.00010774022139580177, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11556, \"tn\": 4135, \"fp\": 3914, \"fn\": 468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9610778443113772, \"tn_rate\": 0.5137284134675115, \"fp_rate\": 0.48627158653248853, \"fn_rate\": 0.038922155688622756, \"precision\": 0.7469941822883, \"recall\": 0.9610778443113772, \"specificity\": 0.5137284134675115, \"npv\": 0.8983271779274387, \"accuracy\": 0.7816968066557066, \"f1\": 0.840619771586528, \"f2\": 0.9089764968693956, \"f0_5\": 0.7818250703615501, \"p4\": 0.7354386459148481, \"phi\": 0.5535364668283537}, {\"truth_threshold\": -13.16, \"match_probability\": 0.00010924405453617098, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11556, \"tn\": 4138, \"fp\": 3911, \"fn\": 468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9610778443113772, \"tn_rate\": 0.5141011305752268, \"fp_rate\": 0.4858988694247733, \"fn_rate\": 0.038922155688622756, \"precision\": 0.7471390702786578, \"recall\": 0.9610778443113772, \"specificity\": 0.5141011305752268, \"npv\": 0.8983933999131567, \"accuracy\": 0.7818462611468141, \"f1\": 0.8407115055836456, \"f2\": 0.9090193980774979, \"f0_5\": 0.7819520381096736, \"p4\": 0.7356757434139981, \"phi\": 0.5538442537769653}, {\"truth_threshold\": -13.14, \"match_probability\": 0.0001107688757862026, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11556, \"tn\": 4146, \"fp\": 3903, \"fn\": 468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9610778443113772, \"tn_rate\": 0.5150950428624674, \"fp_rate\": 0.4849049571375326, \"fn_rate\": 0.038922155688622756, \"precision\": 0.7475257131767902, \"recall\": 0.9610778443113772, \"specificity\": 0.5150950428624674, \"npv\": 0.8985695708712613, \"accuracy\": 0.782244806456434, \"f1\": 0.8409562274860823, \"f2\": 0.9091338210998348, \"f0_5\": 0.7822908204711616, \"p4\": 0.7363073194781401, \"phi\": 0.554664814815728}, {\"truth_threshold\": -13.120000000000001, \"match_probability\": 0.00011231497799916251, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11555, \"tn\": 4148, \"fp\": 3901, \"fn\": 469, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9609946773120426, \"tn_rate\": 0.5153435209342776, \"fp_rate\": 0.48465647906572246, \"fn_rate\": 0.039005322687957415, \"precision\": 0.7476061076604554, \"recall\": 0.9609946773120426, \"specificity\": 0.5153435209342776, \"npv\": 0.8984188867229803, \"accuracy\": 0.7822946246201365, \"f1\": 0.8409752547307132, \"f2\": 0.90909806143001, \"f0_5\": 0.7823502329108439, \"p4\": 0.7364162010015493, \"phi\": 0.5547309094026535}, {\"truth_threshold\": -13.1, \"match_probability\": 0.00011388265811274712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11541, \"tn\": 4148, \"fp\": 3901, \"fn\": 483, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9598303393213573, \"tn_rate\": 0.5153435209342776, \"fp_rate\": 0.48465647906572246, \"fn_rate\": 0.040169660678642714, \"precision\": 0.7473772827353969, \"recall\": 0.9598303393213573, \"specificity\": 0.5153435209342776, \"npv\": 0.8957028719499028, \"accuracy\": 0.7815971703283017, \"f1\": 0.8403844753513435, \"f2\": 0.9081966697094652, \"f0_5\": 0.7819953382480486, \"p4\": 0.7357325837166652, \"phi\": 0.5527882773319317}, {\"truth_threshold\": -13.08, \"match_probability\": 0.00011547221720599655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11539, \"tn\": 4148, \"fp\": 3901, \"fn\": 485, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9596640053226879, \"tn_rate\": 0.5153435209342776, \"fp_rate\": 0.48465647906572246, \"fn_rate\": 0.04033599467731204, \"precision\": 0.7473445595854922, \"recall\": 0.9596640053226879, \"specificity\": 0.5153435209342776, \"npv\": 0.8953162097992662, \"accuracy\": 0.7814975340008967, \"f1\": 0.8403000291290417, \"f2\": 0.9080678670360111, \"f0_5\": 0.7819445950341537, \"p4\": 0.7356349828960286, \"phi\": 0.5525112689238585}, {\"truth_threshold\": -13.06, \"match_probability\": 0.00011708396055700113, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11538, \"tn\": 4148, \"fp\": 3901, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9595808383233533, \"tn_rate\": 0.5153435209342776, \"fp_rate\": 0.48465647906572246, \"fn_rate\": 0.040419161676646706, \"precision\": 0.7473281948312714, \"recall\": 0.9595808383233533, \"specificity\": 0.5153435209342776, \"npv\": 0.8951230038843332, \"accuracy\": 0.7814477158371942, \"f1\": 0.8402578014055274, \"f2\": 0.9080034626583773, \"f0_5\": 0.7819192193006235, \"p4\": 0.735586187989749, \"phi\": 0.5523728124231906}, {\"truth_threshold\": -13.040000000000001, \"match_probability\": 0.00011871819770140902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11538, \"tn\": 4149, \"fp\": 3900, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9595808383233533, \"tn_rate\": 0.5154677599701827, \"fp_rate\": 0.4845322400298174, \"fn_rate\": 0.040419161676646706, \"precision\": 0.7473766031869413, \"recall\": 0.9595808383233533, \"specificity\": 0.5154677599701827, \"npv\": 0.8951456310679612, \"accuracy\": 0.7814975340008967, \"f1\": 0.8402883985143107, \"f2\": 0.9080177542733024, \"f0_5\": 0.7819616135328562, \"p4\": 0.7356650059282449, \"phi\": 0.5524755983346435}, {\"truth_threshold\": -13.02, \"match_probability\": 0.00012037524249174837, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11537, \"tn\": 4151, \"fp\": 3898, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9594976713240186, \"tn_rate\": 0.5157162380419928, \"fp_rate\": 0.4842837619580072, \"fn_rate\": 0.04050232867598137, \"precision\": 0.7474570780693229, \"recall\": 0.9594976713240186, \"specificity\": 0.5157162380419928, \"npv\": 0.894997843898232, \"accuracy\": 0.7815473521645993, \"f1\": 0.840307367347682, \"f2\": 0.9079819300813776, \"f0_5\": 0.7820210400737487, \"p4\": 0.7357737994852113, \"phi\": 0.5525427721540095}, {\"truth_threshold\": -13.0, \"match_probability\": 0.00012205541315757354, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11537, \"tn\": 4152, \"fp\": 3897, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9594976713240186, \"tn_rate\": 0.5158404770778979, \"fp_rate\": 0.4841595229221021, \"fn_rate\": 0.04050232867598137, \"precision\": 0.747505507321498, \"recall\": 0.9594976713240186, \"specificity\": 0.5158404770778979, \"npv\": 0.895020478551412, \"accuracy\": 0.7815971703283017, \"f1\": 0.8403379707189161, \"f2\": 0.9079962222572013, \"f0_5\": 0.7820634490238612, \"p4\": 0.7358525695162008, \"phi\": 0.5526455576813633}, {\"truth_threshold\": -12.98, \"match_probability\": 0.00012375903236644915, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11537, \"tn\": 4155, \"fp\": 3894, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9594976713240186, \"tn_rate\": 0.5162131941856131, \"fp_rate\": 0.4837868058143869, \"fn_rate\": 0.04050232867598137, \"precision\": 0.747650832739291, \"recall\": 0.9594976713240186, \"specificity\": 0.5162131941856131, \"npv\": 0.8950883239982766, \"accuracy\": 0.7817466248194092, \"f1\": 0.8404297942087051, \"f2\": 0.9080391014844083, \"f0_5\": 0.7821907034767045, \"p4\": 0.7360887870806978, \"phi\": 0.5529538864575952}, {\"truth_threshold\": -12.96, \"match_probability\": 0.00012548642728578072, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11537, \"tn\": 4160, \"fp\": 3889, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9594976713240186, \"tn_rate\": 0.5168343893651385, \"fp_rate\": 0.48316561063486146, \"fn_rate\": 0.04050232867598137, \"precision\": 0.7478931673797484, \"recall\": 0.9594976713240186, \"specificity\": 0.5168343893651385, \"npv\": 0.8952012050785453, \"accuracy\": 0.7819957156379216, \"f1\": 0.8405828779599271, \"f2\": 0.9081105758634803, \"f0_5\": 0.7824028862847222, \"p4\": 0.7364821750730031, \"phi\": 0.5534676753439711}, {\"truth_threshold\": -12.94, \"match_probability\": 0.0001272379296455061, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11536, \"tn\": 4167, \"fp\": 3882, \"fn\": 488, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.959414504324684, \"tn_rate\": 0.5177040626164741, \"fp_rate\": 0.4822959373835259, \"fn_rate\": 0.04058549567531603, \"precision\": 0.7482163704760669, \"recall\": 0.959414504324684, \"specificity\": 0.5177040626164741, \"npv\": 0.8951664876476907, \"accuracy\": 0.7822946246201365, \"f1\": 0.8407550470082356, \"f2\": 0.9081462354756432, \"f0_5\": 0.7826747720364742, \"p4\": 0.736983455817519, \"phi\": 0.5540486506278249}, {\"truth_threshold\": -12.9, \"match_probability\": 0.0001308146068008071, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11536, \"tn\": 4168, \"fp\": 3881, \"fn\": 488, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.959414504324684, \"tn_rate\": 0.5178283016523791, \"fp_rate\": 0.4821716983476208, \"fn_rate\": 0.04058549567531603, \"precision\": 0.748264902380489, \"recall\": 0.959414504324684, \"specificity\": 0.5178283016523791, \"npv\": 0.8951890034364262, \"accuracy\": 0.782344442783839, \"f1\": 0.8407856856528552, \"f2\": 0.9081605340638924, \"f0_5\": 0.7827172556044075, \"p4\": 0.7370619784163476, \"phi\": 0.5541513760056592}, {\"truth_threshold\": -12.88, \"match_probability\": 0.00013264046844541213, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11535, \"tn\": 4168, \"fp\": 3881, \"fn\": 489, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9593313373253493, \"tn_rate\": 0.5178283016523791, \"fp_rate\": 0.4821716983476208, \"fn_rate\": 0.0406686626746507, \"precision\": 0.748248572911261, \"recall\": 0.9593313373253493, \"specificity\": 0.5178283016523791, \"npv\": 0.8949967790423019, \"accuracy\": 0.7822946246201365, \"f1\": 0.8407434402332361, \"f2\": 0.9080961078221439, \"f0_5\": 0.7826918901313646, \"p4\": 0.7370131630790557, \"phi\": 0.5540132849600846}, {\"truth_threshold\": -12.86, \"match_probability\": 0.00013449181136006226, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11534, \"tn\": 4168, \"fp\": 3881, \"fn\": 490, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9592481703260146, \"tn_rate\": 0.5178283016523791, \"fp_rate\": 0.4821716983476208, \"fn_rate\": 0.040751829673985364, \"precision\": 0.7482322413233863, \"recall\": 0.9592481703260146, \"specificity\": 0.5178283016523791, \"npv\": 0.8948046371833405, \"accuracy\": 0.782244806456434, \"f1\": 0.8407011917343926, \"f2\": 0.9080316795515737, \"f0_5\": 0.7826665219043483, \"p4\": 0.7369643513932506, \"phi\": 0.5538752254343827}, {\"truth_threshold\": -12.82, \"match_probability\": 0.00013827236801248723, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11534, \"tn\": 4170, \"fp\": 3879, \"fn\": 490, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9592481703260146, \"tn_rate\": 0.5180767797241893, \"fp_rate\": 0.48192322027581064, \"fn_rate\": 0.040751829673985364, \"precision\": 0.7483293323817557, \"recall\": 0.9592481703260146, \"specificity\": 0.5180767797241893, \"npv\": 0.8948497854077253, \"accuracy\": 0.782344442783839, \"f1\": 0.8407624740314175, \"f2\": 0.9080602749216646, \"f0_5\": 0.7827515065964493, \"p4\": 0.7371213444571216, \"phi\": 0.5540807163872411}, {\"truth_threshold\": -12.8, \"match_probability\": 0.00014020230771933477, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11534, \"tn\": 4174, \"fp\": 3875, \"fn\": 490, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9592481703260146, \"tn_rate\": 0.5185737358678096, \"fp_rate\": 0.4814262641321903, \"fn_rate\": 0.040751829673985364, \"precision\": 0.7485235901096762, \"recall\": 0.9592481703260146, \"specificity\": 0.5185737358678096, \"npv\": 0.8949399656946827, \"accuracy\": 0.782543715438649, \"f1\": 0.8408850654321438, \"f2\": 0.9081174710652704, \"f0_5\": 0.7829215313603041, \"p4\": 0.7374351472807286, \"phi\": 0.5544916435805818}, {\"truth_threshold\": -12.76, \"match_probability\": 0.0001441433629364879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11532, \"tn\": 4174, \"fp\": 3875, \"fn\": 492, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9590818363273453, \"tn_rate\": 0.5185737358678096, \"fp_rate\": 0.4814262641321903, \"fn_rate\": 0.04091816367265469, \"precision\": 0.7484909456740443, \"recall\": 0.9590818363273453, \"specificity\": 0.5185737358678096, \"npv\": 0.8945563651950279, \"accuracy\": 0.7824440791112439, \"f1\": 0.8408005541176041, \"f2\": 0.9079885989638284, \"f0_5\": 0.782870797805898, \"p4\": 0.7373375161254297, \"phi\": 0.5542157803795579}, {\"truth_threshold\": -12.74, \"match_probability\": 0.00014615523520961874, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11526, \"tn\": 4176, \"fp\": 3873, \"fn\": 498, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9585828343313373, \"tn_rate\": 0.5188222139396198, \"fp_rate\": 0.4811777860603802, \"fn_rate\": 0.04141716566866267, \"precision\": 0.7484901616988117, \"recall\": 0.9585828343313373, \"specificity\": 0.5188222139396198, \"npv\": 0.8934531450577664, \"accuracy\": 0.782244806456434, \"f1\": 0.8406082485504868, \"f2\": 0.9076305220883534, \"f0_5\": 0.7828035859820701, \"p4\": 0.7372014950344601, \"phi\": 0.5535945947616739}, {\"truth_threshold\": -12.72, \"match_probability\": 0.00014819518390635442, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11525, \"tn\": 4181, \"fp\": 3868, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9584996673320026, \"tn_rate\": 0.5194434091191452, \"fp_rate\": 0.4805565908808548, \"fn_rate\": 0.04150033266799734, \"precision\": 0.7487169492626519, \"recall\": 0.9584996673320026, \"specificity\": 0.5194434091191452, \"npv\": 0.8933760683760684, \"accuracy\": 0.7824440791112439, \"f1\": 0.8407192617718934, \"f2\": 0.9076375435114744, \"f0_5\": 0.7829909234197511, \"p4\": 0.737544391869472, \"phi\": 0.5539710391510111}, {\"truth_threshold\": -12.66, \"match_probability\": 0.0001544874329203339, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11522, \"tn\": 4185, \"fp\": 3864, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9582501663339986, \"tn_rate\": 0.5199403652627655, \"fp_rate\": 0.48005963473723445, \"fn_rate\": 0.04174983366600133, \"precision\": 0.7488626023657871, \"recall\": 0.9582501663339986, \"specificity\": 0.5199403652627655, \"npv\": 0.8928952421591636, \"accuracy\": 0.7824938972749464, \"f1\": 0.8407150674936155, \"f2\": 0.9075013389622255, \"f0_5\": 0.7830850369725968, \"p4\": 0.7377110746252122, \"phi\": 0.5539697869286553}, {\"truth_threshold\": -12.64, \"match_probability\": 0.00015664365930589128, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11519, \"tn\": 4186, \"fp\": 3863, \"fn\": 505, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9580006653359947, \"tn_rate\": 0.5200646042986706, \"fp_rate\": 0.47993539570132937, \"fn_rate\": 0.04199933466400532, \"precision\": 0.7488623065921206, \"recall\": 0.9580006653359947, \"specificity\": 0.5200646042986706, \"npv\": 0.8923470475378384, \"accuracy\": 0.7823942609475415, \"f1\": 0.840618842589214, \"f2\": 0.9073222218721447, \"f0_5\": 0.7830514465956059, \"p4\": 0.7376429349021486, \"phi\": 0.5536604760811525}, {\"truth_threshold\": -12.6, \"match_probability\": 0.00016104680276399447, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11519, \"tn\": 4188, \"fp\": 3861, \"fn\": 505, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9580006653359947, \"tn_rate\": 0.5203130823704808, \"fp_rate\": 0.4796869176295192, \"fn_rate\": 0.04199933466400532, \"precision\": 0.7489596879063719, \"recall\": 0.9580006653359947, \"specificity\": 0.5203130823704808, \"npv\": 0.8923929256339229, \"accuracy\": 0.7824938972749464, \"f1\": 0.8406801926726025, \"f2\": 0.9073508097548679, \"f0_5\": 0.7831366256934624, \"p4\": 0.73779933360875, \"phi\": 0.5538662042260759}, {\"truth_threshold\": -12.540000000000001, \"match_probability\": 0.0001678846296156108, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11519, \"tn\": 4190, \"fp\": 3859, \"fn\": 505, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9580006653359947, \"tn_rate\": 0.520561560442291, \"fp_rate\": 0.47943843955770904, \"fn_rate\": 0.04199933466400532, \"precision\": 0.7490570945506568, \"recall\": 0.9580006653359947, \"specificity\": 0.520561560442291, \"npv\": 0.8924387646432375, \"accuracy\": 0.7825935336023514, \"f1\": 0.8407415517115538, \"f2\": 0.9073793994391405, \"f0_5\": 0.7832218233246301, \"p4\": 0.7379556718150289, \"phi\": 0.554071914288555}, {\"truth_threshold\": -12.5, \"match_probability\": 0.00017260369432222522, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11516, \"tn\": 4191, \"fp\": 3858, \"fn\": 508, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9577511643379907, \"tn_rate\": 0.520685799478196, \"fp_rate\": 0.47931420052180396, \"fn_rate\": 0.042248835662009314, \"precision\": 0.7490568492259659, \"recall\": 0.9577511643379907, \"specificity\": 0.520685799478196, \"npv\": 0.8918918918918919, \"accuracy\": 0.7824938972749464, \"f1\": 0.8406453025768305, \"f2\": 0.9072002520876005, \"f0_5\": 0.7831882480957563, \"p4\": 0.7378874610823046, \"phi\": 0.5537630988628938}, {\"truth_threshold\": -12.48, \"match_probability\": 0.00017501273041901525, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11513, \"tn\": 4191, \"fp\": 3858, \"fn\": 511, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9575016633399867, \"tn_rate\": 0.520685799478196, \"fp_rate\": 0.47931420052180396, \"fn_rate\": 0.042498336660013306, \"precision\": 0.7490078719666905, \"recall\": 0.9575016633399867, \"specificity\": 0.520685799478196, \"npv\": 0.8913228413441089, \"accuracy\": 0.782344442783839, \"f1\": 0.840518342763278, \"f2\": 0.9070067909307199, \"f0_5\": 0.7831120422266964, \"p4\": 0.7377411364807517, \"phi\": 0.5533517137975162}, {\"truth_threshold\": -12.46, \"match_probability\": 0.00017745538355341462, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11510, \"tn\": 4195, \"fp\": 3854, \"fn\": 514, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9572521623419827, \"tn_rate\": 0.5211827556218164, \"fp_rate\": 0.4788172443781836, \"fn_rate\": 0.0427478376580173, \"precision\": 0.7491538661806821, \"recall\": 0.9572521623419827, \"specificity\": 0.5211827556218164, \"npv\": 0.8908473136547037, \"accuracy\": 0.7823942609475415, \"f1\": 0.8405140937636921, \"f2\": 0.9068704695871415, \"f0_5\": 0.7832063146434404, \"p4\": 0.7379072232900447, \"phi\": 0.553352430166596}, {\"truth_threshold\": -12.42, \"match_probability\": 0.00018244342324472447, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11509, \"tn\": 4195, \"fp\": 3854, \"fn\": 515, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.957168995342648, \"tn_rate\": 0.5211827556218164, \"fp_rate\": 0.4788172443781836, \"fn_rate\": 0.04283100465735196, \"precision\": 0.749137538241229, \"recall\": 0.957168995342648, \"specificity\": 0.5211827556218164, \"npv\": 0.8906581740976646, \"accuracy\": 0.782344442783839, \"f1\": 0.840471756672874, \"f2\": 0.9068059692084653, \"f0_5\": 0.7831809026076542, \"p4\": 0.7378584602689999, \"phi\": 0.5532155088723258}, {\"truth_threshold\": -12.38, \"match_probability\": 0.00018757164393112065, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11507, \"tn\": 4196, \"fp\": 3853, \"fn\": 517, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9570026613439787, \"tn_rate\": 0.5213069946577215, \"fp_rate\": 0.47869300534227854, \"fn_rate\": 0.04299733865602129, \"precision\": 0.7491536458333333, \"recall\": 0.9570026613439787, \"specificity\": 0.5213069946577215, \"npv\": 0.8903034160831742, \"accuracy\": 0.7822946246201365, \"f1\": 0.8404177621969033, \"f2\": 0.906691250630358, \"f0_5\": 0.7831727104432102, \"p4\": 0.7378389974299614, \"phi\": 0.5530447425960603}, {\"truth_threshold\": -12.36, \"match_probability\": 0.00019018954851095674, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11506, \"tn\": 4197, \"fp\": 3852, \"fn\": 518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9569194943446441, \"tn_rate\": 0.5214312336936265, \"fp_rate\": 0.47856876630637346, \"fn_rate\": 0.043080505655355955, \"precision\": 0.7491860919390546, \"recall\": 0.9569194943446441, \"specificity\": 0.5214312336936265, \"npv\": 0.8901378579003182, \"accuracy\": 0.7822946246201365, \"f1\": 0.8404061062011541, \"f2\": 0.9066410312982633, \"f0_5\": 0.783189936832934, \"p4\": 0.7378682794455804, \"phi\": 0.5530109192936128}, {\"truth_threshold\": -12.34, \"match_probability\": 0.0001928439836790836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11506, \"tn\": 4199, \"fp\": 3850, \"fn\": 518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9569194943446441, \"tn_rate\": 0.5216797117654367, \"fp_rate\": 0.4783202882345633, \"fn_rate\": 0.043080505655355955, \"precision\": 0.7492836676217765, \"recall\": 0.9569194943446441, \"specificity\": 0.5216797117654367, \"npv\": 0.890184439262243, \"accuracy\": 0.7823942609475415, \"f1\": 0.8404674945215486, \"f2\": 0.906669608522978, \"f0_5\": 0.783275242348328, \"p4\": 0.7380243058603265, \"phi\": 0.5532168908189699}, {\"truth_threshold\": -12.32, \"match_probability\": 0.0001955354589900938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11506, \"tn\": 4200, \"fp\": 3849, \"fn\": 518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9569194943446441, \"tn_rate\": 0.5218039508013418, \"fp_rate\": 0.4781960491986582, \"fn_rate\": 0.043080505655355955, \"precision\": 0.7493324649951156, \"recall\": 0.9569194943446441, \"specificity\": 0.5218039508013418, \"npv\": 0.8902077151335311, \"accuracy\": 0.7824440791112439, \"f1\": 0.840498192044998, \"f2\": 0.9066838978109092, \"f0_5\": 0.7833179020750504, \"p4\": 0.7381022965226682, \"phi\": 0.5533198698225739}, {\"truth_threshold\": -12.280000000000001, \"match_probability\": 0.00020103160386827137, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11504, \"tn\": 4200, \"fp\": 3849, \"fn\": 520, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9567531603459747, \"tn_rate\": 0.5218039508013418, \"fp_rate\": 0.4781960491986582, \"fn_rate\": 0.04324683965402528, \"precision\": 0.7492998111118349, \"recall\": 0.9567531603459747, \"specificity\": 0.5218039508013418, \"npv\": 0.8898305084745762, \"accuracy\": 0.782344442783839, \"f1\": 0.8404134857727289, \"f2\": 0.906554870841148, \"f0_5\": 0.7832670624761697, \"p4\": 0.7380047873899865, \"phi\": 0.5530464351100494}, {\"truth_threshold\": -12.26, \"match_probability\": 0.00020383732845162376, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11489, \"tn\": 4206, \"fp\": 3843, \"fn\": 535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9555056553559548, \"tn_rate\": 0.5225493850167723, \"fp_rate\": 0.4774506149832277, \"fn_rate\": 0.044494344644045246, \"precision\": 0.7493477693712497, \"recall\": 0.9555056553559548, \"specificity\": 0.5225493850167723, \"npv\": 0.887154608732335, \"accuracy\": 0.7818960793105166, \"f1\": 0.8399619827460155, \"f2\": 0.9056725736267894, \"f0_5\": 0.783141563965536, \"p4\": 0.7377413976903207, \"phi\": 0.5516186817554731}, {\"truth_threshold\": -12.22, \"match_probability\": 0.00020956677481647222, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11489, \"tn\": 4210, \"fp\": 3839, \"fn\": 535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9555056553559548, \"tn_rate\": 0.5230463411603926, \"fp_rate\": 0.4769536588396074, \"fn_rate\": 0.044494344644045246, \"precision\": 0.7495433194154488, \"recall\": 0.9555056553559548, \"specificity\": 0.5230463411603926, \"npv\": 0.8872497365648051, \"accuracy\": 0.7820953519653265, \"f1\": 0.8400848201228429, \"f2\": 0.9057296922300706, \"f0_5\": 0.7833124250027271, \"p4\": 0.7380527451617421, \"phi\": 0.552031329099261}, {\"truth_threshold\": -12.200000000000001, \"match_probability\": 0.0002124915963420977, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11489, \"tn\": 4211, \"fp\": 3838, \"fn\": 535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9555056553559548, \"tn_rate\": 0.5231705801962977, \"fp_rate\": 0.4768294198037023, \"fn_rate\": 0.044494344644045246, \"precision\": 0.7495922228746656, \"recall\": 0.9555056553559548, \"specificity\": 0.5231705801962977, \"npv\": 0.8872734934681837, \"accuracy\": 0.7821451701290291, \"f1\": 0.8401155350809842, \"f2\": 0.905743973006638, \"f0_5\": 0.7833551519118529, \"p4\": 0.7381305446931662, \"phi\": 0.5521344796798002}, {\"truth_threshold\": -12.18, \"match_probability\": 0.0002154572293820086, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11480, \"tn\": 4211, \"fp\": 3838, \"fn\": 544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9547571523619428, \"tn_rate\": 0.5231705801962977, \"fp_rate\": 0.4768294198037023, \"fn_rate\": 0.04524284763805722, \"precision\": 0.7494450972711842, \"recall\": 0.9547571523619428, \"specificity\": 0.5231705801962977, \"npv\": 0.8855941114616194, \"accuracy\": 0.7816968066557066, \"f1\": 0.8397337429595494, \"f2\": 0.905162897782824, \"f0_5\": 0.7831259550316525, \"p4\": 0.7376922618014723, \"phi\": 0.5509109266616954}, {\"truth_threshold\": -12.16, \"match_probability\": 0.00021846424315264881, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11480, \"tn\": 4228, \"fp\": 3821, \"fn\": 544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9547571523619428, \"tn_rate\": 0.5252826438066841, \"fp_rate\": 0.47471735619331595, \"fn_rate\": 0.04524284763805722, \"precision\": 0.750277759623554, \"recall\": 0.9547571523619428, \"specificity\": 0.5252826438066841, \"npv\": 0.8860016764459346, \"accuracy\": 0.782543715438649, \"f1\": 0.840256175663312, \"f2\": 0.9054056185623925, \"f0_5\": 0.783853170918228, \"p4\": 0.7390123402842577, \"phi\": 0.5526657677087357}, {\"truth_threshold\": -12.14, \"match_probability\": 0.00022151321480262968, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11480, \"tn\": 4230, \"fp\": 3819, \"fn\": 544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9547571523619428, \"tn_rate\": 0.5255311218784943, \"fp_rate\": 0.4744688781215058, \"fn_rate\": 0.04524284763805722, \"precision\": 0.7503758415582718, \"recall\": 0.9547571523619428, \"specificity\": 0.5255311218784943, \"npv\": 0.8860494344365312, \"accuracy\": 0.7826433517660539, \"f1\": 0.8403176810745526, \"f2\": 0.9054341825065069, \"f0_5\": 0.7839388145315488, \"p4\": 0.73916736207216, \"phi\": 0.5528721348472336}, {\"truth_threshold\": -12.120000000000001, \"match_probability\": 0.00022460472952307015, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11480, \"tn\": 4248, \"fp\": 3801, \"fn\": 544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9547571523619428, \"tn_rate\": 0.5277674245247856, \"fp_rate\": 0.4722325754752143, \"fn_rate\": 0.04524284763805722, \"precision\": 0.7512597343105818, \"recall\": 0.9547571523619428, \"specificity\": 0.5277674245247856, \"npv\": 0.8864774624373957, \"accuracy\": 0.7835400787126986, \"f1\": 0.8408716352316425, \"f2\": 0.9056913391293372, \"f0_5\": 0.7847104500464811, \"p4\": 0.7405599075982687, \"phi\": 0.5547286462999239}, {\"truth_threshold\": -12.1, \"match_probability\": 0.00022773938065946784, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11479, \"tn\": 4250, \"fp\": 3799, \"fn\": 545, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9546739853626082, \"tn_rate\": 0.5280159025965958, \"fp_rate\": 0.47198409740340413, \"fn_rate\": 0.04532601463739188, \"precision\": 0.7513417986647467, \"recall\": 0.9546739853626082, \"specificity\": 0.5280159025965958, \"npv\": 0.886339937434828, \"accuracy\": 0.7835898968764011, \"f1\": 0.8408907772324372, \"f2\": 0.905655316060214, \"f0_5\": 0.7847708378910523, \"p4\": 0.7406656010517123, \"phi\": 0.5547995365458901}, {\"truth_threshold\": -12.08, \"match_probability\": 0.00023091776982511915, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11478, \"tn\": 4262, \"fp\": 3787, \"fn\": 546, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9545908183632734, \"tn_rate\": 0.5295067710274568, \"fp_rate\": 0.4704932289725432, \"fn_rate\": 0.045409181636726546, \"precision\": 0.7519161480510973, \"recall\": 0.9545908183632734, \"specificity\": 0.5295067710274568, \"npv\": 0.8864392678868552, \"accuracy\": 0.7841378966771285, \"f1\": 0.8412180732163143, \"f2\": 0.9057622196619372, \"f0_5\": 0.7852607957966176, \"p4\": 0.7415422054079431, \"phi\": 0.5559013563844576}, {\"truth_threshold\": -12.06, \"match_probability\": 0.000234140507016114, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11477, \"tn\": 4265, \"fp\": 3784, \"fn\": 547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9545076513639388, \"tn_rate\": 0.529879488135172, \"fp_rate\": 0.47012051186482795, \"fn_rate\": 0.04549234863606121, \"precision\": 0.7520477032959832, \"recall\": 0.9545076513639388, \"specificity\": 0.529879488135172, \"npv\": 0.8863258520365752, \"accuracy\": 0.7842375330045335, \"f1\": 0.8412680960234561, \"f2\": 0.9057404864498003, \"f0_5\": 0.7853643181693765, \"p4\": 0.7417244572884295, \"phi\": 0.5560754808471736}, {\"truth_threshold\": -12.02, \"match_probability\": 0.00024072150807358944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11477, \"tn\": 4266, \"fp\": 3783, \"fn\": 547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9545076513639388, \"tn_rate\": 0.5300037271710771, \"fp_rate\": 0.46999627282892287, \"fn_rate\": 0.04549234863606121, \"precision\": 0.7520969855832241, \"recall\": 0.9545076513639388, \"specificity\": 0.5300037271710771, \"npv\": 0.8863494701849158, \"accuracy\": 0.7842873511682359, \"f1\": 0.8412989297756928, \"f2\": 0.9057547824988952, \"f0_5\": 0.7854073141355524, \"p4\": 0.7418014294404517, \"phi\": 0.5561785436395552}, {\"truth_threshold\": -11.98, \"match_probability\": 0.00024748743592730506, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11476, \"tn\": 4270, \"fp\": 3779, \"fn\": 548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9544244843646041, \"tn_rate\": 0.5305006833146975, \"fp_rate\": 0.46949931668530254, \"fn_rate\": 0.04557551563539587, \"precision\": 0.7522779416584726, \"recall\": 0.9544244843646041, \"specificity\": 0.5305006833146975, \"npv\": 0.8862598588625986, \"accuracy\": 0.7844368056593434, \"f1\": 0.8413798159756589, \"f2\": 0.9057473441618917, \"f0_5\": 0.7855539127101473, \"p4\": 0.7420604130136741, \"phi\": 0.5564557933809773}, {\"truth_threshold\": -11.96, \"match_probability\": 0.00025094136483622993, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11475, \"tn\": 4270, \"fp\": 3779, \"fn\": 549, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9543413173652695, \"tn_rate\": 0.5305006833146975, \"fp_rate\": 0.46949931668530254, \"fn_rate\": 0.04565868263473054, \"precision\": 0.7522617018486955, \"recall\": 0.9543413173652695, \"specificity\": 0.5305006833146975, \"npv\": 0.8860759493670886, \"accuracy\": 0.784386987495641, \"f1\": 0.8413373414473202, \"f2\": 0.9056827150749802, \"f0_5\": 0.7855284775465499, \"p4\": 0.7420116563594034, \"phi\": 0.5563208641825432}, {\"truth_threshold\": -11.92, \"match_probability\": 0.00025799446673722515, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11474, \"tn\": 4273, \"fp\": 3776, \"fn\": 550, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9542581503659348, \"tn_rate\": 0.5308734004224127, \"fp_rate\": 0.4691265995775873, \"fn_rate\": 0.045741849634065204, \"precision\": 0.7523934426229508, \"recall\": 0.9542581503659348, \"specificity\": 0.5308734004224127, \"npv\": 0.8859630935102634, \"accuracy\": 0.7844866238230459, \"f1\": 0.8413874019212437, \"f2\": 0.9056609730685442, \"f0_5\": 0.7856321209465381, \"p4\": 0.7421935455743527, \"phi\": 0.5564951898535907}, {\"truth_threshold\": -11.9, \"match_probability\": 0.0002615949931554435, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11473, \"tn\": 4273, \"fp\": 3776, \"fn\": 551, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9541749833666001, \"tn_rate\": 0.5308734004224127, \"fp_rate\": 0.4691265995775873, \"fn_rate\": 0.045825016633399863, \"precision\": 0.7523772050626271, \"recall\": 0.9541749833666001, \"specificity\": 0.5308734004224127, \"npv\": 0.8857794361525705, \"accuracy\": 0.7844368056593434, \"f1\": 0.8413449198841345, \"f2\": 0.9055963375167733, \"f0_5\": 0.7856066831005204, \"p4\": 0.7421447914410815, \"phi\": 0.5563603575252792}, {\"truth_threshold\": -11.88, \"match_probability\": 0.00026524575456968495, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11472, \"tn\": 4278, \"fp\": 3771, \"fn\": 552, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9540918163672655, \"tn_rate\": 0.5314945956019381, \"fp_rate\": 0.4685054043980619, \"fn_rate\": 0.04590818363273453, \"precision\": 0.7526077543790592, \"recall\": 0.9540918163672655, \"specificity\": 0.5314945956019381, \"npv\": 0.8857142857142857, \"accuracy\": 0.7846360783141534, \"f1\": 0.8414567059082407, \"f2\": 0.9056031828731114, \"f0_5\": 0.7857964819990136, \"p4\": 0.7424801409902719, \"phi\": 0.5567409713051389}, {\"truth_threshold\": -11.86, \"match_probability\": 0.0002689474514902129, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11468, \"tn\": 4293, \"fp\": 3756, \"fn\": 556, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9537591483699268, \"tn_rate\": 0.5333581811405144, \"fp_rate\": 0.46664181885948564, \"fn_rate\": 0.04624085163007319, \"precision\": 0.7532842879663689, \"recall\": 0.9537591483699268, \"specificity\": 0.5333581811405144, \"npv\": 0.8853371829243143, \"accuracy\": 0.7851840781148807, \"f1\": 0.8417498532002349, \"f2\": 0.9055590650663298, \"f0_5\": 0.7863411958310478, \"p4\": 0.7434351977323955, \"phi\": 0.5577486759000864}, {\"truth_threshold\": -11.84, \"match_probability\": 0.00027270079418514036, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11467, \"tn\": 4294, \"fp\": 3755, \"fn\": 557, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9536759813705922, \"tn_rate\": 0.5334824201764194, \"fp_rate\": 0.46651757982358055, \"fn_rate\": 0.046324018629407854, \"precision\": 0.7533175666798055, \"recall\": 0.9536759813705922, \"specificity\": 0.5334824201764194, \"npv\": 0.8851783137497423, \"accuracy\": 0.7851840781148807, \"f1\": 0.8417382368054026, \"f2\": 0.9055087021068259, \"f0_5\": 0.7863588983980689, \"p4\": 0.7434629888459635, \"phi\": 0.5577173410468876}, {\"truth_threshold\": -11.8, \"match_probability\": 0.00028036530757554303, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11464, \"tn\": 4298, \"fp\": 3751, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9534264803725881, \"tn_rate\": 0.5339793763200398, \"fp_rate\": 0.4660206236799602, \"fn_rate\": 0.046573519627411845, \"precision\": 0.7534669733815313, \"recall\": 0.9534264803725881, \"specificity\": 0.5339793763200398, \"npv\": 0.8847262247838616, \"accuracy\": 0.7852338962785832, \"f1\": 0.8417342780571974, \"f2\": 0.9053718942995688, \"f0_5\": 0.7864551890675594, \"p4\": 0.7436227722954204, \"phi\": 0.5577267274276995}, {\"truth_threshold\": -11.78, \"match_probability\": 0.0002842779488265541, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11464, \"tn\": 4301, \"fp\": 3748, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9534264803725881, \"tn_rate\": 0.534352093427755, \"fp_rate\": 0.465647906572245, \"fn_rate\": 0.046573519627411845, \"precision\": 0.7536155666579016, \"recall\": 0.9534264803725881, \"specificity\": 0.534352093427755, \"npv\": 0.8847973667969553, \"accuracy\": 0.7853833507696907, \"f1\": 0.8418269936848289, \"f2\": 0.9054147974979465, \"f0_5\": 0.7865846964540564, \"p4\": 0.7438521648656286, \"phi\": 0.5580359757007639}, {\"truth_threshold\": -11.76, \"match_probability\": 0.0002882451772437776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11464, \"tn\": 4303, \"fp\": 3746, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9534264803725881, \"tn_rate\": 0.5346005714995652, \"fp_rate\": 0.46539942850043486, \"fn_rate\": 0.046573519627411845, \"precision\": 0.7537146614069691, \"recall\": 0.9534264803725881, \"specificity\": 0.5346005714995652, \"npv\": 0.8848447460415382, \"accuracy\": 0.7854829870970956, \"f1\": 0.8418888154512741, \"f2\": 0.9054434018892364, \"f0_5\": 0.7866710584101888, \"p4\": 0.7440050221131418, \"phi\": 0.5582421204659535}, {\"truth_threshold\": -11.74, \"match_probability\": 0.00029226775395691364, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11464, \"tn\": 4304, \"fp\": 3745, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9534264803725881, \"tn_rate\": 0.5347248105354703, \"fp_rate\": 0.4652751894645298, \"fn_rate\": 0.046573519627411845, \"precision\": 0.753764218554803, \"recall\": 0.9534264803725881, \"specificity\": 0.5347248105354703, \"npv\": 0.8848684210526315, \"accuracy\": 0.785532805260798, \"f1\": 0.8419197297396541, \"f2\": 0.905457704762657, \"f0_5\": 0.7867142465001372, \"p4\": 0.7440814294189023, \"phi\": 0.5583451866367167}, {\"truth_threshold\": -11.72, \"match_probability\": 0.00029634645069594797, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11463, \"tn\": 4304, \"fp\": 3745, \"fn\": 561, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9533433133732535, \"tn_rate\": 0.5347248105354703, \"fp_rate\": 0.4652751894645298, \"fn_rate\": 0.046656686626746505, \"precision\": 0.7537480273540242, \"recall\": 0.9533433133732535, \"specificity\": 0.5347248105354703, \"npv\": 0.8846865364850977, \"accuracy\": 0.7854829870970956, \"f1\": 0.8418772032902467, \"f2\": 0.9053930241374952, \"f0_5\": 0.7866888108048754, \"p4\": 0.7440326638873191, \"phi\": 0.5582110351931825}, {\"truth_threshold\": -11.700000000000001, \"match_probability\": 0.0003004820499384334, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11460, \"tn\": 4304, \"fp\": 3745, \"fn\": 564, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9530938123752495, \"tn_rate\": 0.5347248105354703, \"fp_rate\": 0.4652751894645298, \"fn_rate\": 0.046906187624750496, \"precision\": 0.753699440973364, \"recall\": 0.9530938123752495, \"specificity\": 0.5347248105354703, \"npv\": 0.8841413311421529, \"accuracy\": 0.7853335326059881, \"f1\": 0.8417496052003379, \"f2\": 0.9051989700004739, \"f0_5\": 0.7866124869584317, \"p4\": 0.7438863882541219, \"phi\": 0.5578087549417826}, {\"truth_threshold\": -11.68, \"match_probability\": 0.00030467534505880815, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11459, \"tn\": 4314, \"fp\": 3735, \"fn\": 565, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9530106453759148, \"tn_rate\": 0.5359672008945211, \"fp_rate\": 0.46403279910547895, \"fn_rate\": 0.04698935462408516, \"precision\": 0.7541792812952481, \"recall\": 0.9530106453759148, \"specificity\": 0.5359672008945211, \"npv\": 0.884197581471613, \"accuracy\": 0.7857818960793105, \"f1\": 0.84201631273422, \"f2\": 0.9052772949913098, \"f0_5\": 0.7870192307692307, \"p4\": 0.7446008554799457, \"phi\": 0.5587057753993755}, {\"truth_threshold\": -11.66, \"match_probability\": 0.00030892714047977567, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11459, \"tn\": 4315, \"fp\": 3734, \"fn\": 565, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9530106453759148, \"tn_rate\": 0.5360914399304262, \"fp_rate\": 0.46390856006957387, \"fn_rate\": 0.04698935462408516, \"precision\": 0.7542289212137169, \"recall\": 0.9530106453759148, \"specificity\": 0.5360914399304262, \"npv\": 0.8842213114754098, \"accuracy\": 0.785831714243013, \"f1\": 0.8420472498805893, \"f2\": 0.9052915988560414, \"f0_5\": 0.7870624759602176, \"p4\": 0.7446770995479632, \"phi\": 0.5588088583519149}, {\"truth_threshold\": -11.64, \"match_probability\": 0.00031323825182578204, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11458, \"tn\": 4319, \"fp\": 3730, \"fn\": 566, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9529274783765802, \"tn_rate\": 0.5365883960740465, \"fp_rate\": 0.46341160392595354, \"fn_rate\": 0.04707252162341983, \"precision\": 0.7544113774032131, \"recall\": 0.9529274783765802, \"specificity\": 0.5365883960740465, \"npv\": 0.8841351074718526, \"accuracy\": 0.7859811687341205, \"f1\": 0.8421284727326179, \"f2\": 0.9052841160482903, \"f0_5\": 0.7872100692536, \"p4\": 0.7449331643374538, \"phi\": 0.5590873285283718}, {\"truth_threshold\": -11.620000000000001, \"match_probability\": 0.00031760950607860996, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11456, \"tn\": 4331, \"fp\": 3718, \"fn\": 568, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9527611443779108, \"tn_rate\": 0.5380792645049074, \"fp_rate\": 0.46192073549509255, \"fn_rate\": 0.047238855622089154, \"precision\": 0.7549756161855806, \"recall\": 0.9527611443779108, \"specificity\": 0.5380792645049074, \"npv\": 0.8840579710144928, \"accuracy\": 0.7864793503711454, \"f1\": 0.8424148834473123, \"f2\": 0.9053263790105895, \"f0_5\": 0.7876787678767877, \"p4\": 0.7457487356047301, \"phi\": 0.5600567000145058}, {\"truth_threshold\": -11.6, \"match_probability\": 0.000322041741735126, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11454, \"tn\": 4335, \"fp\": 3714, \"fn\": 570, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9525948103792415, \"tn_rate\": 0.5385762206485277, \"fp_rate\": 0.4614237793514722, \"fn_rate\": 0.04740518962075848, \"precision\": 0.7551424050632911, \"recall\": 0.9525948103792415, \"specificity\": 0.5385762206485277, \"npv\": 0.8837920489296636, \"accuracy\": 0.7865789866985503, \"f1\": 0.8424536628420124, \"f2\": 0.9052541729893778, \"f0_5\": 0.7878012545394519, \"p4\": 0.7459550905291998, \"phi\": 0.5602018337410941}, {\"truth_threshold\": -11.58, \"match_probability\": 0.0003265358089672047, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11453, \"tn\": 4335, \"fp\": 3714, \"fn\": 571, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9525116433799069, \"tn_rate\": 0.5385762206485277, \"fp_rate\": 0.4614237793514722, \"fn_rate\": 0.047488356620093146, \"precision\": 0.7551262609612975, \"recall\": 0.9525116433799069, \"specificity\": 0.5385762206485277, \"npv\": 0.883611903791276, \"accuracy\": 0.7865291685348478, \"f1\": 0.8424110919054099, \"f2\": 0.9051894472282377, \"f0_5\": 0.7877758212733176, \"p4\": 0.745906313921004, \"phi\": 0.5600683538656542}, {\"truth_threshold\": -11.56, \"match_probability\": 0.0003310925697838664, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11441, \"tn\": 4336, \"fp\": 3713, \"fn\": 583, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9515136393878909, \"tn_rate\": 0.5387004596844328, \"fp_rate\": 0.46129954031556714, \"fn_rate\": 0.04848636061210911, \"precision\": 0.7549821829220008, \"recall\": 0.9515136393878909, \"specificity\": 0.5387004596844328, \"npv\": 0.8814799756047977, \"accuracy\": 0.7859811687341205, \"f1\": 0.8419309735815733, \"f2\": 0.9044268774703558, \"f0_5\": 0.7875137665198237, \"p4\": 0.7453971871964152, \"phi\": 0.5585720397906084}, {\"truth_threshold\": -11.540000000000001, \"match_probability\": 0.0003357128981956508, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11439, \"tn\": 4337, \"fp\": 3712, \"fn\": 585, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9513473053892215, \"tn_rate\": 0.5388246987203379, \"fp_rate\": 0.46117530127966205, \"fn_rate\": 0.048652694610778445, \"precision\": 0.7549996699887797, \"recall\": 0.9513473053892215, \"specificity\": 0.5388246987203379, \"npv\": 0.8811458756603007, \"accuracy\": 0.785931350570418, \"f1\": 0.8418767249310027, \"f2\": 0.9043116669565355, \"f0_5\": 0.787506195957482, \"p4\": 0.7453756300997482, \"phi\": 0.5584091125833988}, {\"truth_threshold\": -11.5, \"match_probability\": 0.0003451478148565189, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11437, \"tn\": 4337, \"fp\": 3712, \"fn\": 587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9511809713905522, \"tn_rate\": 0.5388246987203379, \"fp_rate\": 0.46117530127966205, \"fn_rate\": 0.04881902860944777, \"precision\": 0.7549673245758796, \"recall\": 0.9511809713905522, \"specificity\": 0.5388246987203379, \"npv\": 0.8807879772542648, \"accuracy\": 0.785831714243013, \"f1\": 0.841791484193869, \"f2\": 0.9041821487864653, \"f0_5\": 0.7874552464885707, \"p4\": 0.7452781781690947, \"phi\": 0.5581430844325056}, {\"truth_threshold\": -11.46, \"match_probability\": 0.00035484779745482883, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11436, \"tn\": 4338, \"fp\": 3711, \"fn\": 588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9510978043912176, \"tn_rate\": 0.538948937756243, \"fp_rate\": 0.46105106224375697, \"fn_rate\": 0.04890219560878244, \"precision\": 0.7550009902951079, \"recall\": 0.9510978043912176, \"specificity\": 0.538948937756243, \"npv\": 0.8806333739342266, \"accuracy\": 0.785831714243013, \"f1\": 0.8417798387987192, \"f2\": 0.9041316825577534, \"f0_5\": 0.7874731449347215, \"p4\": 0.7453053446803574, \"phi\": 0.5581133839889146}, {\"truth_threshold\": -11.44, \"match_probability\": 0.00035979950584844554, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11435, \"tn\": 4338, \"fp\": 3711, \"fn\": 589, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9510146373918829, \"tn_rate\": 0.538948937756243, \"fp_rate\": 0.46105106224375697, \"fn_rate\": 0.048985362608117096, \"precision\": 0.754984814472468, \"recall\": 0.9510146373918829, \"specificity\": 0.538948937756243, \"npv\": 0.8804546377105744, \"accuracy\": 0.7857818960793105, \"f1\": 0.8417372101582627, \"f2\": 0.9040669175547895, \"f0_5\": 0.7874476641692375, \"p4\": 0.7452566258577376, \"phi\": 0.5579804528670964}, {\"truth_threshold\": -11.42, \"match_probability\": 0.00036482028742734155, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11435, \"tn\": 4339, \"fp\": 3710, \"fn\": 589, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9510146373918829, \"tn_rate\": 0.5390731767921481, \"fp_rate\": 0.4609268232078519, \"fn_rate\": 0.048985362608117096, \"precision\": 0.7550346649059095, \"recall\": 0.9510146373918829, \"specificity\": 0.5390731767921481, \"npv\": 0.8804788961038961, \"accuracy\": 0.785831714243013, \"f1\": 0.8417681916890574, \"f2\": 0.9040812131370471, \"f0_5\": 0.7874910473252162, \"p4\": 0.7453324977463615, \"phi\": 0.5580837320685897}, {\"truth_threshold\": -11.4, \"match_probability\": 0.00036991110500986284, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11429, \"tn\": 4353, \"fp\": 3696, \"fn\": 595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9505156353958749, \"tn_rate\": 0.5408125232948192, \"fp_rate\": 0.4591874767051808, \"fn_rate\": 0.049484364604125086, \"precision\": 0.7556363636363637, \"recall\": 0.9505156353958749, \"specificity\": 0.5408125232948192, \"npv\": 0.879749393694422, \"accuracy\": 0.7862302595526329, \"f1\": 0.841946296364507, \"f2\": 0.9038926938833616, \"f0_5\": 0.7879460592355634, \"p4\": 0.7461008717268532, \"phi\": 0.5587333122408464}, {\"truth_threshold\": -11.38, \"match_probability\": 0.0003750729348152639, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11429, \"tn\": 4365, \"fp\": 3684, \"fn\": 595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9505156353958749, \"tn_rate\": 0.5423033917256802, \"fp_rate\": 0.4576966082743198, \"fn_rate\": 0.049484364604125086, \"precision\": 0.75623635280884, \"recall\": 0.9505156353958749, \"specificity\": 0.5423033917256802, \"npv\": 0.8800403225806451, \"accuracy\": 0.7868280775170627, \"f1\": 0.8423186055938386, \"f2\": 0.9040642946415859, \"f0_5\": 0.788467906617363, \"p4\": 0.7470078204454258, \"phi\": 0.5599725458855851}, {\"truth_threshold\": -11.36, \"match_probability\": 0.0003803067666496687, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11429, \"tn\": 4368, \"fp\": 3681, \"fn\": 595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9505156353958749, \"tn_rate\": 0.5426761088333955, \"fp_rate\": 0.45732389116660455, \"fn_rate\": 0.049484364604125086, \"precision\": 0.7563864990072799, \"recall\": 0.9505156353958749, \"specificity\": 0.5426761088333955, \"npv\": 0.8801128349788434, \"accuracy\": 0.7869775320081702, \"f1\": 0.8424117343554213, \"f2\": 0.9041072050121823, \"f0_5\": 0.7885984764848752, \"p4\": 0.7472342480298086, \"phi\": 0.5602822652283267}, {\"truth_threshold\": -11.3, \"match_probability\": 0.00039645038016841163, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11429, \"tn\": 4370, \"fp\": 3679, \"fn\": 595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9505156353958749, \"tn_rate\": 0.5429245869052056, \"fp_rate\": 0.4570754130947944, \"fn_rate\": 0.049484364604125086, \"precision\": 0.7564866296002118, \"recall\": 0.9505156353958749, \"specificity\": 0.5429245869052056, \"npv\": 0.8801611278952669, \"accuracy\": 0.7870771683355752, \"f1\": 0.8424738316379183, \"f2\": 0.9041358141889754, \"f0_5\": 0.7886855470906481, \"p4\": 0.7473851311514612, \"phi\": 0.5604887251194741}, {\"truth_threshold\": -11.28, \"match_probability\": 0.00040198239657063386, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11428, \"tn\": 4370, \"fp\": 3679, \"fn\": 596, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9504324683965403, \"tn_rate\": 0.5429245869052056, \"fp_rate\": 0.4570754130947944, \"fn_rate\": 0.049567531603459745, \"precision\": 0.756470510359436, \"recall\": 0.9504324683965403, \"specificity\": 0.5429245869052056, \"npv\": 0.8799838904550946, \"accuracy\": 0.7870273501718726, \"f1\": 0.8424311672993993, \"f2\": 0.9040710092875338, \"f0_5\": 0.7886600783967316, \"p4\": 0.7473363893744167, \"phi\": 0.560356376799349}, {\"truth_threshold\": -11.26, \"match_probability\": 0.0004075915745255968, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11427, \"tn\": 4373, \"fp\": 3676, \"fn\": 597, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9503493013972056, \"tn_rate\": 0.5432973040129209, \"fp_rate\": 0.45670269598707913, \"fn_rate\": 0.04965069860279441, \"precision\": 0.7566046480831623, \"recall\": 0.9503493013972056, \"specificity\": 0.5432973040129209, \"npv\": 0.8798792756539235, \"accuracy\": 0.7871269864992776, \"f1\": 0.8424816603384082, \"f2\": 0.904049114701182, \"f0_5\": 0.7887652548456568, \"p4\": 0.7475138641977371, \"phi\": 0.5605337887682866}, {\"truth_threshold\": -11.22, \"match_probability\": 0.0004190457315704786, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11426, \"tn\": 4373, \"fp\": 3676, \"fn\": 598, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9502661343978709, \"tn_rate\": 0.5432973040129209, \"fp_rate\": 0.45670269598707913, \"fn_rate\": 0.04973386560212908, \"precision\": 0.756588531320355, \"recall\": 0.9502661343978709, \"specificity\": 0.5432973040129209, \"npv\": 0.8797022731844699, \"accuracy\": 0.7870771683355752, \"f1\": 0.8424389884243899, \"f2\": 0.9039843033007373, \"f0_5\": 0.7887397835210956, \"p4\": 0.7474651248861778, \"phi\": 0.5604015322075505}, {\"truth_threshold\": -11.200000000000001, \"match_probability\": 0.00042489290651221616, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11423, \"tn\": 4374, \"fp\": 3675, \"fn\": 601, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.950016633399867, \"tn_rate\": 0.543421543048826, \"fp_rate\": 0.45657845695117405, \"fn_rate\": 0.04998336660013307, \"precision\": 0.756590276857862, \"recall\": 0.950016633399867, \"specificity\": 0.543421543048826, \"npv\": 0.8791959798994975, \"accuracy\": 0.7869775320081702, \"f1\": 0.8423420101762407, \"f2\": 0.9038041586226541, \"f0_5\": 0.7887069155987627, \"p4\": 0.7473942986359481, \"phi\": 0.5601082137814904}, {\"truth_threshold\": -11.18, \"match_probability\": 0.00043082163512815456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11422, \"tn\": 4381, \"fp\": 3668, \"fn\": 602, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9499334664005322, \"tn_rate\": 0.5442912163001615, \"fp_rate\": 0.45570878369983847, \"fn_rate\": 0.05006653359946773, \"precision\": 0.7569251159708417, \"recall\": 0.9499334664005322, \"specificity\": 0.5442912163001615, \"npv\": 0.879189243427654, \"accuracy\": 0.7872764409903851, \"f1\": 0.842516780998746, \"f2\": 0.9038394581078087, \"f0_5\": 0.788986516357206, \"p4\": 0.747872777289145, \"phi\": 0.5606990435474958}, {\"truth_threshold\": -11.16, \"match_probability\": 0.0004368330539027926, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11422, \"tn\": 4390, \"fp\": 3659, \"fn\": 602, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9499334664005322, \"tn_rate\": 0.5454093676233073, \"fp_rate\": 0.4545906323766928, \"fn_rate\": 0.05006653359946773, \"precision\": 0.7573768317750812, \"recall\": 0.9499334664005322, \"specificity\": 0.5454093676233073, \"npv\": 0.8794070512820513, \"accuracy\": 0.7877248044637075, \"f1\": 0.8427965320051651, \"f2\": 0.9039682162812416, \"f0_5\": 0.7893791120694421, \"p4\": 0.7485496328182744, \"phi\": 0.5616282874768909}, {\"truth_threshold\": -11.120000000000001, \"match_probability\": 0.0004491085871334007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11421, \"tn\": 4390, \"fp\": 3659, \"fn\": 603, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9498502994011976, \"tn_rate\": 0.5454093676233073, \"fp_rate\": 0.4545906323766928, \"fn_rate\": 0.050149700598802395, \"precision\": 0.7573607427055703, \"recall\": 0.9498502994011976, \"specificity\": 0.5454093676233073, \"npv\": 0.8792309232926097, \"accuracy\": 0.787674986300005, \"f1\": 0.8427538370720189, \"f2\": 0.9039033810307712, \"f0_5\": 0.7893536437023112, \"p4\": 0.7485008858836736, \"phi\": 0.561496372680032}, {\"truth_threshold\": -11.1, \"match_probability\": 0.00045537505448605916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11419, \"tn\": 4391, \"fp\": 3658, \"fn\": 605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9496839654025283, \"tn_rate\": 0.5455336066592124, \"fp_rate\": 0.4544663933407877, \"fn_rate\": 0.05031603459747172, \"precision\": 0.7573787888837302, \"recall\": 0.9496839654025283, \"specificity\": 0.5455336066592124, \"npv\": 0.8789031224979984, \"accuracy\": 0.7876251681363025, \"f1\": 0.8426995313826058, \"f2\": 0.9037880107007741, \"f0_5\": 0.7893463473981087, \"p4\": 0.7484785361542406, \"phi\": 0.5613358916916531}, {\"truth_threshold\": -11.08, \"match_probability\": 0.000461728918238175, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11418, \"tn\": 4958, \"fp\": 3091, \"fn\": 606, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9496007984031936, \"tn_rate\": 0.6159771400173935, \"fp_rate\": 0.38402285998260655, \"fn_rate\": 0.05039920159680639, \"precision\": 0.7869598180439727, \"recall\": 0.9496007984031936, \"specificity\": 0.6159771400173935, \"npv\": 0.8910855499640546, \"accuracy\": 0.8158222487919096, \"f1\": 0.8606640786944559, \"f2\": 0.9119079945691239, \"f0_5\": 0.8148729660291179, \"p4\": 0.7890401413810578, \"phi\": 0.6192636767917269}, {\"truth_threshold\": -11.040000000000001, \"match_probability\": 0.0004747037228943636, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11417, \"tn\": 4961, \"fp\": 3088, \"fn\": 607, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9495176314038589, \"tn_rate\": 0.6163498571251087, \"fp_rate\": 0.3836501428748913, \"fn_rate\": 0.05048236859614105, \"precision\": 0.7871078938297139, \"recall\": 0.9495176314038589, \"specificity\": 0.6163498571251087, \"npv\": 0.8909841954022989, \"accuracy\": 0.8159218851193145, \"f1\": 0.8607184590448189, \"f2\": 0.9118863915911887, \"f0_5\": 0.8149877220033122, \"p4\": 0.7891959547472325, \"phi\": 0.6194435143942342}, {\"truth_threshold\": -11.0, \"match_probability\": 0.0004880429477794046, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11417, \"tn\": 4966, \"fp\": 3083, \"fn\": 607, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9495176314038589, \"tn_rate\": 0.6169710523046341, \"fp_rate\": 0.3830289476953659, \"fn_rate\": 0.05048236859614105, \"precision\": 0.7873793103448276, \"recall\": 0.9495176314038589, \"specificity\": 0.6169710523046341, \"npv\": 0.891082002512112, \"accuracy\": 0.816170975937827, \"f1\": 0.8608807118081737, \"f2\": 0.911959230621765, \"f0_5\": 0.8152204958300011, \"p4\": 0.7895378339990552, \"phi\": 0.6199521401426595}, {\"truth_threshold\": -10.98, \"match_probability\": 0.0004948524021024512, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11415, \"tn\": 4967, \"fp\": 3082, \"fn\": 609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9493512974051896, \"tn_rate\": 0.6170952913405392, \"fp_rate\": 0.3829047086594608, \"fn_rate\": 0.05064870259481038, \"precision\": 0.787404290542871, \"recall\": 0.9493512974051896, \"specificity\": 0.6170952913405392, \"npv\": 0.8907819225251076, \"accuracy\": 0.8161211577741244, \"f1\": 0.8608272689566758, \"f2\": 0.9118431773521001, \"f0_5\": 0.8152173913043478, \"p4\": 0.7895072958886307, \"phi\": 0.6198034099024791}, {\"truth_threshold\": -10.96, \"match_probability\": 0.000501756818131702, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11415, \"tn\": 4968, \"fp\": 3081, \"fn\": 609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9493512974051896, \"tn_rate\": 0.6172195303764443, \"fp_rate\": 0.3827804696235557, \"fn_rate\": 0.05064870259481038, \"precision\": 0.7874586092715232, \"recall\": 0.9493512974051896, \"specificity\": 0.6172195303764443, \"npv\": 0.8908015061861215, \"accuracy\": 0.816170975937827, \"f1\": 0.8608597285067874, \"f2\": 0.911857745398773, \"f0_5\": 0.8152639698320192, \"p4\": 0.7895756288502835, \"phi\": 0.619905150056123}, {\"truth_threshold\": -10.94, \"match_probability\": 0.0005087575188218651, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11411, \"tn\": 4968, \"fp\": 3081, \"fn\": 613, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.949018629407851, \"tn_rate\": 0.6172195303764443, \"fp_rate\": 0.3827804696235557, \"fn_rate\": 0.050981370592149036, \"precision\": 0.7873999447971295, \"recall\": 0.949018629407851, \"specificity\": 0.6172195303764443, \"npv\": 0.8901630532162695, \"accuracy\": 0.8159717032830169, \"f1\": 0.8606878865590587, \"f2\": 0.9115964721671886, \"f0_5\": 0.8151645902388844, \"p4\": 0.7893778942642812, \"phi\": 0.6194045730643559}, {\"truth_threshold\": -10.9, \"match_probability\": 0.0005230531582235416, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11409, \"tn\": 4968, \"fp\": 3081, \"fn\": 615, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9488522954091816, \"tn_rate\": 0.6172195303764443, \"fp_rate\": 0.3827804696235557, \"fn_rate\": 0.05114770459081836, \"precision\": 0.7873706004140787, \"recall\": 0.9488522954091816, \"specificity\": 0.6172195303764443, \"npv\": 0.8898441698011822, \"accuracy\": 0.815872066955612, \"f1\": 0.860601946141661, \"f2\": 0.9114658230275141, \"f0_5\": 0.8151148834019204, \"p4\": 0.7892790451101247, \"phi\": 0.6191544245378093}, {\"truth_threshold\": -10.88, \"match_probability\": 0.0005303508358317331, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11408, \"tn\": 4971, \"fp\": 3078, \"fn\": 616, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.948769128409847, \"tn_rate\": 0.6175922474841595, \"fp_rate\": 0.38240775251584047, \"fn_rate\": 0.05123087159015303, \"precision\": 0.7875189838464725, \"recall\": 0.948769128409847, \"specificity\": 0.6175922474841595, \"npv\": 0.889744048684446, \"accuracy\": 0.8159717032830169, \"f1\": 0.8606563560920407, \"f2\": 0.9114441852289796, \"f0_5\": 0.8152298193459867, \"p4\": 0.7894345408738445, \"phi\": 0.6193348229724842}, {\"truth_threshold\": -10.86, \"match_probability\": 0.0005377502764140461, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11407, \"tn\": 4971, \"fp\": 3078, \"fn\": 617, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9486859614105123, \"tn_rate\": 0.6175922474841595, \"fp_rate\": 0.38240775251584047, \"fn_rate\": 0.051314038589487694, \"precision\": 0.7875043148084225, \"recall\": 0.9486859614105123, \"specificity\": 0.6175922474841595, \"npv\": 0.8895848246241947, \"accuracy\": 0.8159218851193145, \"f1\": 0.860613376589083, \"f2\": 0.9113788530065036, \"f0_5\": 0.8152049625521697, \"p4\": 0.7893851207004065, \"phi\": 0.6192098393436083}, {\"truth_threshold\": -10.84, \"match_probability\": 0.0005452528974721083, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11405, \"tn\": 4975, \"fp\": 3074, \"fn\": 619, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.948519627411843, \"tn_rate\": 0.6180892036277799, \"fp_rate\": 0.38191079637222014, \"fn_rate\": 0.05148037258815702, \"precision\": 0.7876925202016714, \"recall\": 0.948519627411843, \"specificity\": 0.6180892036277799, \"npv\": 0.8893457275652484, \"accuracy\": 0.8160215214467195, \"f1\": 0.8606572840810475, \"f2\": 0.9113064322812625, \"f0_5\": 0.8153417214755505, \"p4\": 0.7895593556101628, \"phi\": 0.619367298245822}, {\"truth_threshold\": -10.82, \"match_probability\": 0.0005528601362093087, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11405, \"tn\": 4976, \"fp\": 3073, \"fn\": 619, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.948519627411843, \"tn_rate\": 0.6182134426636849, \"fp_rate\": 0.38178655733631506, \"fn_rate\": 0.05148037258815702, \"precision\": 0.7877469263710457, \"recall\": 0.948519627411843, \"specificity\": 0.6182134426636849, \"npv\": 0.8893655049151028, \"accuracy\": 0.816071339610422, \"f1\": 0.8606897592634518, \"f2\": 0.9113209959408061, \"f0_5\": 0.8153883550674903, \"p4\": 0.7896275967883154, \"phi\": 0.6194691331851038}, {\"truth_threshold\": -10.8, \"match_probability\": 0.0005605734498034131, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11403, \"tn\": 4976, \"fp\": 3073, \"fn\": 621, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9483532934131736, \"tn_rate\": 0.6182134426636849, \"fp_rate\": 0.38178655733631506, \"fn_rate\": 0.051646706586826345, \"precision\": 0.7877176015473888, \"recall\": 0.9483532934131736, \"specificity\": 0.6182134426636849, \"npv\": 0.889047704127211, \"accuracy\": 0.8159717032830169, \"f1\": 0.8606037735849057, \"f2\": 0.9111903087643035, \"f0_5\": 0.8153386340235671, \"p4\": 0.7895287670645417, \"phi\": 0.6192194363277976}, {\"truth_threshold\": -10.74, \"match_probability\": 0.0005843647169505126, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11401, \"tn\": 4976, \"fp\": 3073, \"fn\": 623, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9481869594145044, \"tn_rate\": 0.6182134426636849, \"fp_rate\": 0.38178655733631506, \"fn_rate\": 0.05181304058549568, \"precision\": 0.7876882686195937, \"recall\": 0.9481869594145044, \"specificity\": 0.6182134426636849, \"npv\": 0.888730130380425, \"accuracy\": 0.815872066955612, \"f1\": 0.8605177749264096, \"f2\": 0.9110596132331789, \"f0_5\": 0.8152889016018307, \"p4\": 0.7894299493858682, \"phi\": 0.6189698321943451}, {\"truth_threshold\": -10.72, \"match_probability\": 0.0005925173109898081, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11401, \"tn\": 4978, \"fp\": 3071, \"fn\": 623, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9481869594145044, \"tn_rate\": 0.6184619207354951, \"fp_rate\": 0.3815380792645049, \"fn_rate\": 0.05181304058549568, \"precision\": 0.7877971254836926, \"recall\": 0.9481869594145044, \"specificity\": 0.6184619207354951, \"npv\": 0.8887698625245491, \"accuracy\": 0.8159717032830169, \"f1\": 0.860582729468599, \"f2\": 0.911088735455824, \"f0_5\": 0.8153821947591258, \"p4\": 0.7895663929465846, \"phi\": 0.6191735831746444}, {\"truth_threshold\": -10.700000000000001, \"match_probability\": 0.0006007835751966225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11400, \"tn\": 4979, \"fp\": 3070, \"fn\": 624, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9481037924151696, \"tn_rate\": 0.6185861597714002, \"fp_rate\": 0.3814138402285998, \"fn_rate\": 0.05189620758483034, \"precision\": 0.7878369039391845, \"recall\": 0.9481037924151696, \"specificity\": 0.6185861597714002, \"npv\": 0.888631090487239, \"accuracy\": 0.8159717032830169, \"f1\": 0.8605722050275534, \"f2\": 0.9110379439312086, \"f0_5\": 0.815403982604715, \"p4\": 0.789585192062168, \"phi\": 0.6191507210827221}, {\"truth_threshold\": -10.68, \"match_probability\": 0.000609165092532851, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11398, \"tn\": 4980, \"fp\": 3069, \"fn\": 626, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9479374584165003, \"tn_rate\": 0.6187103988073053, \"fp_rate\": 0.3812896011926947, \"fn_rate\": 0.05206254158349967, \"precision\": 0.7878620308287827, \"recall\": 0.9479374584165003, \"specificity\": 0.6187103988073053, \"npv\": 0.8883339279343561, \"accuracy\": 0.8159218851193145, \"f1\": 0.8605186667169982, \"f2\": 0.9109217908348385, \"f0_5\": 0.815400904252275, \"p4\": 0.7895545794588887, \"phi\": 0.6190032238175577}, {\"truth_threshold\": -10.66, \"match_probability\": 0.0006176634679506185, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11394, \"tn\": 4980, \"fp\": 3069, \"fn\": 630, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9476047904191617, \"tn_rate\": 0.6187103988073053, \"fp_rate\": 0.3812896011926947, \"fn_rate\": 0.05239520958083832, \"precision\": 0.7878033602986932, \"recall\": 0.9476047904191617, \"specificity\": 0.6187103988073053, \"npv\": 0.8877005347593583, \"accuracy\": 0.8157226124645045, \"f1\": 0.8603465851172273, \"f2\": 0.9106603366422098, \"f0_5\": 0.8153013910355487, \"p4\": 0.7893569994698332, \"phi\": 0.6185047422235466}, {\"truth_threshold\": -10.64, \"match_probability\": 0.0006262803286962502, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11392, \"tn\": 4982, \"fp\": 3067, \"fn\": 632, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9474384564204924, \"tn_rate\": 0.6189588768791154, \"fp_rate\": 0.38104112312088456, \"fn_rate\": 0.05256154357950765, \"precision\": 0.7878829794591604, \"recall\": 0.9474384564204924, \"specificity\": 0.6189588768791154, \"npv\": 0.8874242964018525, \"accuracy\": 0.8157226124645045, \"f1\": 0.8603254918249443, \"f2\": 0.9105587083366637, \"f0_5\": 0.8153449756656169, \"p4\": 0.7893945711812308, \"phi\": 0.618459570388801}, {\"truth_threshold\": -10.620000000000001, \"match_probability\": 0.0006350173246183965, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11387, \"tn\": 4982, \"fp\": 3067, \"fn\": 637, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.947022621423819, \"tn_rate\": 0.6189588768791154, \"fp_rate\": 0.38104112312088456, \"fn_rate\": 0.05297737857618097, \"precision\": 0.787809602878096, \"recall\": 0.947022621423819, \"specificity\": 0.6189588768791154, \"npv\": 0.8866346324968856, \"accuracy\": 0.8154735216459922, \"f1\": 0.860110280232646, \"f2\": 0.9102318145483613, \"f0_5\": 0.8152205040091638, \"p4\": 0.7891476831761883, \"phi\": 0.6178373239448303}, {\"truth_threshold\": -10.58, \"match_probability\": 0.0006528584362767788, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11382, \"tn\": 4982, \"fp\": 3067, \"fn\": 642, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9466067864271457, \"tn_rate\": 0.6189588768791154, \"fp_rate\": 0.38104112312088456, \"fn_rate\": 0.053393213572854294, \"precision\": 0.7877361755138764, \"recall\": 0.9466067864271457, \"specificity\": 0.6189588768791154, \"npv\": 0.885846372688478, \"accuracy\": 0.8152244308274798, \"f1\": 0.8598949873455974, \"f2\": 0.9099048684946839, \"f0_5\": 0.8150959610426812, \"p4\": 0.7889008700400757, \"phi\": 0.6172156516693222}, {\"truth_threshold\": -10.56, \"match_probability\": 0.0006619659675544257, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11376, \"tn\": 4983, \"fp\": 3066, \"fn\": 648, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9461077844311377, \"tn_rate\": 0.6190831159150205, \"fp_rate\": 0.3809168840849795, \"fn_rate\": 0.05389221556886228, \"precision\": 0.7877025342750311, \"recall\": 0.9461077844311377, \"specificity\": 0.6190831159150205, \"npv\": 0.8849227490676611, \"accuracy\": 0.8149753400089673, \"f1\": 0.8596690092949445, \"f2\": 0.9095270075793918, \"f0_5\": 0.8149931224209078, \"p4\": 0.7886729327551955, \"phi\": 0.6165725338417581}, {\"truth_threshold\": -10.540000000000001, \"match_probability\": 0.0006712004657376785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11375, \"tn\": 4983, \"fp\": 3066, \"fn\": 649, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9460246174318031, \"tn_rate\": 0.6190831159150205, \"fp_rate\": 0.3809168840849795, \"fn_rate\": 0.053975382568196936, \"precision\": 0.7876878332525449, \"recall\": 0.9460246174318031, \"specificity\": 0.6190831159150205, \"npv\": 0.884765625, \"accuracy\": 0.8149255218452648, \"f1\": 0.8596259210277726, \"f2\": 0.9094615987335497, \"f0_5\": 0.8149681893735312, \"p4\": 0.7886235959697174, \"phi\": 0.6164484159881737}, {\"truth_threshold\": -10.52, \"match_probability\": 0.0006805636984582193, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11374, \"tn\": 4987, \"fp\": 3062, \"fn\": 650, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9459414504324684, \"tn_rate\": 0.6195800720586409, \"fp_rate\": 0.38041992794135915, \"fn_rate\": 0.0540585495675316, \"precision\": 0.7878913826544749, \"recall\": 0.9459414504324684, \"specificity\": 0.6195800720586409, \"npv\": 0.884690438176335, \"accuracy\": 0.8150749763363723, \"f1\": 0.8597127739984883, \"f2\": 0.9094543593680036, \"f0_5\": 0.8151301456255017, \"p4\": 0.7888467120280932, \"phi\": 0.6167329205710378}, {\"truth_threshold\": -10.5, \"match_probability\": 0.000690057457889322, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11373, \"tn\": 4987, \"fp\": 3062, \"fn\": 651, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9458582834331337, \"tn_rate\": 0.6195800720586409, \"fp_rate\": 0.38041992794135915, \"fn_rate\": 0.05414171656686627, \"precision\": 0.7878766886040873, \"recall\": 0.9458582834331337, \"specificity\": 0.6195800720586409, \"npv\": 0.8845335225257184, \"accuracy\": 0.8150251581726697, \"f1\": 0.8596696776144224, \"f2\": 0.9093889430842302, \"f0_5\": 0.8151052118571183, \"p4\": 0.7887973769667745, \"phi\": 0.6166088906244495}, {\"truth_threshold\": -10.48, \"match_probability\": 0.0006996835610846967, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11373, \"tn\": 4989, \"fp\": 3060, \"fn\": 651, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9458582834331337, \"tn_rate\": 0.619828550130451, \"fp_rate\": 0.38017144986954904, \"fn_rate\": 0.05414171656686627, \"precision\": 0.7879858657243817, \"recall\": 0.9458582834331337, \"specificity\": 0.619828550130451, \"npv\": 0.8845744680851064, \"accuracy\": 0.8151247945000747, \"f1\": 0.8597346637940809, \"f2\": 0.9094180300340642, \"f0_5\": 0.8151986925855841, \"p4\": 0.7889335393546494, \"phi\": 0.6168132015555089}, {\"truth_threshold\": -10.46, \"match_probability\": 0.000709443850321953, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11365, \"tn\": 4993, \"fp\": 3056, \"fn\": 659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9451929474384564, \"tn_rate\": 0.6203255062740713, \"fp_rate\": 0.3796744937259287, \"fn_rate\": 0.05480705256154358, \"precision\": 0.7880868178351016, \"recall\": 0.9451929474384564, \"specificity\": 0.6203255062740713, \"npv\": 0.8834041047416844, \"accuracy\": 0.8149255218452648, \"f1\": 0.8595197579882775, \"f2\": 0.9089527648479614, \"f0_5\": 0.8151862053135939, \"p4\": 0.788811119306833, \"phi\": 0.616230888724042}, {\"truth_threshold\": -10.42, \"match_probability\": 0.0007293744842456983, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11365, \"tn\": 4994, \"fp\": 3055, \"fn\": 659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9451929474384564, \"tn_rate\": 0.6204497453099764, \"fp_rate\": 0.3795502546900236, \"fn_rate\": 0.05480705256154358, \"precision\": 0.7881414701803051, \"recall\": 0.9451929474384564, \"specificity\": 0.6204497453099764, \"npv\": 0.8834247302317354, \"accuracy\": 0.8149753400089673, \"f1\": 0.8595522613825443, \"f2\": 0.9089673043700812, \"f0_5\": 0.8152329851945369, \"p4\": 0.7888791367637137, \"phi\": 0.6163331193112214}, {\"truth_threshold\": -10.4, \"match_probability\": 0.0007395486427640722, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11364, \"tn\": 4994, \"fp\": 3055, \"fn\": 660, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9451097804391217, \"tn_rate\": 0.6204497453099764, \"fp_rate\": 0.3795502546900236, \"fn_rate\": 0.054890219560878244, \"precision\": 0.7881267771690131, \"recall\": 0.9451097804391217, \"specificity\": 0.6204497453099764, \"npv\": 0.8832684824902723, \"accuracy\": 0.8149255218452648, \"f1\": 0.8595091328517944, \"f2\": 0.9089018635527474, \"f0_5\": 0.8152080344332855, \"p4\": 0.788829821055268, \"phi\": 0.6162093675392302}, {\"truth_threshold\": -10.38, \"match_probability\": 0.0007498646157084, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11363, \"tn\": 4994, \"fp\": 3055, \"fn\": 661, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9450266134397871, \"tn_rate\": 0.6204497453099764, \"fp_rate\": 0.3795502546900236, \"fn_rate\": 0.05497338656021291, \"precision\": 0.7881120821195727, \"recall\": 0.9450266134397871, \"specificity\": 0.6204497453099764, \"npv\": 0.8831122900088417, \"accuracy\": 0.8148757036815623, \"f1\": 0.8594660010589215, \"f2\": 0.9088364206417763, \"f0_5\": 0.8151830808080808, \"p4\": 0.7887805083158455, \"phi\": 0.6160856384101744}, {\"truth_threshold\": -10.36, \"match_probability\": 0.0007603243767939938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11362, \"tn\": 4994, \"fp\": 3055, \"fn\": 662, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9449434464404525, \"tn_rate\": 0.6204497453099764, \"fp_rate\": 0.3795502546900236, \"fn_rate\": 0.05505655355954757, \"precision\": 0.78809738503156, \"recall\": 0.9449434464404525, \"specificity\": 0.6204497453099764, \"npv\": 0.882956152758133, \"accuracy\": 0.8148258855178598, \"f1\": 0.8594228660035551, \"f2\": 0.9087709756370674, \"f0_5\": 0.8151581243184297, \"p4\": 0.7887311985446446, \"phi\": 0.6159619319132729}, {\"truth_threshold\": -10.34, \"match_probability\": 0.0007709299271214838, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11362, \"tn\": 4996, \"fp\": 3053, \"fn\": 662, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9449434464404525, \"tn_rate\": 0.6206982233817866, \"fp_rate\": 0.37930177661821346, \"fn_rate\": 0.05505655355954757, \"precision\": 0.7882067291016303, \"recall\": 0.9449434464404525, \"specificity\": 0.6206982233817866, \"npv\": 0.8829975256274302, \"accuracy\": 0.8149255218452648, \"f1\": 0.8594878777563448, \"f2\": 0.9088000511909904, \"f0_5\": 0.8152517077090867, \"p4\": 0.7888671970122397, \"phi\": 0.6161664510801745}, {\"truth_threshold\": -10.32, \"match_probability\": 0.0007816832955544318, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11361, \"tn\": 4996, \"fp\": 3053, \"fn\": 663, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9448602794411177, \"tn_rate\": 0.6206982233817866, \"fp_rate\": 0.37930177661821346, \"fn_rate\": 0.055139720558882235, \"precision\": 0.7881920355210212, \"recall\": 0.9448602794411177, \"specificity\": 0.6206982233817866, \"npv\": 0.8828414914295812, \"accuracy\": 0.8148757036815623, \"f1\": 0.8594447386337847, \"f2\": 0.9087346024636058, \"f0_5\": 0.8152267508610792, \"p4\": 0.7888178880836827, \"phi\": 0.6160427881617929}, {\"truth_threshold\": -10.3, \"match_probability\": 0.0007925865391020799, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11359, \"tn\": 4998, \"fp\": 3051, \"fn\": 665, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9446939454424484, \"tn_rate\": 0.6209467014535968, \"fp_rate\": 0.3790532985464033, \"fn_rate\": 0.05530605455755156, \"precision\": 0.7882720333102012, \"recall\": 0.9446939454424484, \"specificity\": 0.6209467014535968, \"npv\": 0.8825710754017305, \"accuracy\": 0.8148757036815623, \"f1\": 0.8594234697737761, \"f2\": 0.9086327712539596, \"f0_5\": 0.8152704409738172, \"p4\": 0.7888552311525959, \"phi\": 0.6160001055012662}, {\"truth_threshold\": -10.28, \"match_probability\": 0.0008036417433073089, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11355, \"tn\": 5001, \"fp\": 3048, \"fn\": 669, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9443612774451098, \"tn_rate\": 0.621319418561312, \"fp_rate\": 0.37868058143868805, \"fn_rate\": 0.05563872255489022, \"precision\": 0.7883774213705478, \"recall\": 0.9443612774451098, \"specificity\": 0.621319418561312, \"npv\": 0.882010582010582, \"accuracy\": 0.8148258855178598, \"f1\": 0.8593483936882733, \"f2\": 0.9084145346325542, \"f0_5\": 0.8153110460106842, \"p4\": 0.7888618805473928, \"phi\": 0.615812919925356}, {\"truth_threshold\": -10.26, \"match_probability\": 0.0008148510226398721, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11354, \"tn\": 5001, \"fp\": 3048, \"fn\": 670, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9442781104457751, \"tn_rate\": 0.621319418561312, \"fp_rate\": 0.37868058143868805, \"fn_rate\": 0.055721889554224885, \"precision\": 0.7883627273989724, \"recall\": 0.9442781104457751, \"specificity\": 0.621319418561312, \"npv\": 0.8818550520190442, \"accuracy\": 0.8147760673541573, \"f1\": 0.8593052296980247, \"f2\": 0.9083490671701494, \"f0_5\": 0.8152860753676471, \"p4\": 0.7888125870370828, \"phi\": 0.6156894671305067}, {\"truth_threshold\": -10.24, \"match_probability\": 0.0008262165208949831, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11350, \"tn\": 5001, \"fp\": 3048, \"fn\": 674, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9439454424484365, \"tn_rate\": 0.621319418561312, \"fp_rate\": 0.37868058143868805, \"fn_rate\": 0.05605455755156354, \"precision\": 0.7883039311015418, \"recall\": 0.9439454424484365, \"specificity\": 0.621319418561312, \"npv\": 0.8812334801762115, \"accuracy\": 0.8145767946993474, \"f1\": 0.8591325410642646, \"f2\": 0.9080871763689314, \"f0_5\": 0.8151861641002068, \"p4\": 0.7886154425556741, \"phi\": 0.6151958807784282}, {\"truth_threshold\": -10.200000000000001, \"match_probability\": 0.0008494248984104829, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11350, \"tn\": 5003, \"fp\": 3046, \"fn\": 674, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9439454424484365, \"tn_rate\": 0.6215678966331222, \"fp_rate\": 0.3784321033668779, \"fn_rate\": 0.05605455755156354, \"precision\": 0.78841344818005, \"recall\": 0.9439454424484365, \"specificity\": 0.6215678966331222, \"npv\": 0.8812753214726088, \"accuracy\": 0.8146764310267524, \"f1\": 0.8591975775927327, \"f2\": 0.9081162388785765, \"f0_5\": 0.8152798528904723, \"p4\": 0.7887512754829195, \"phi\": 0.6154006274547467}, {\"truth_threshold\": -10.18, \"match_probability\": 0.0008612722155521146, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11350, \"tn\": 5009, \"fp\": 3040, \"fn\": 674, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9439454424484365, \"tn_rate\": 0.6223133308485527, \"fp_rate\": 0.3776866691514474, \"fn_rate\": 0.05605455755156354, \"precision\": 0.7887421820708825, \"recall\": 0.9439454424484365, \"specificity\": 0.6223133308485527, \"npv\": 0.8814006686609185, \"accuracy\": 0.8149753400089673, \"f1\": 0.8593927462709169, \"f2\": 0.9082034375700156, \"f0_5\": 0.8155610485169005, \"p4\": 0.7891585350031981, \"phi\": 0.6160148282218026}, {\"truth_threshold\": -10.16, \"match_probability\": 0.000873284628214516, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11347, \"tn\": 5011, \"fp\": 3038, \"fn\": 677, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9436959414504325, \"tn_rate\": 0.6225618089203627, \"fp_rate\": 0.3774381910796372, \"fn_rate\": 0.056304058549567534, \"precision\": 0.7888077858880779, \"recall\": 0.9436959414504325, \"specificity\": 0.6225618089203627, \"npv\": 0.8809774964838256, \"accuracy\": 0.8149255218452648, \"f1\": 0.8593282593055398, \"f2\": 0.908036042957059, \"f0_5\": 0.8155798976482088, \"p4\": 0.7891463492922458, \"phi\": 0.6158499064117667}, {\"truth_threshold\": -10.14, \"match_probability\": 0.0008854644329910831, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11345, \"tn\": 5011, \"fp\": 3038, \"fn\": 679, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9435296074517632, \"tn_rate\": 0.6225618089203627, \"fp_rate\": 0.3774381910796372, \"fn_rate\": 0.05647039254823686, \"precision\": 0.7887784189668359, \"recall\": 0.9435296074517632, \"specificity\": 0.6225618089203627, \"npv\": 0.8806678383128296, \"accuracy\": 0.8148258855178598, \"f1\": 0.8592418676865983, \"f2\": 0.9079050560988492, \"f0_5\": 0.8155299327160849, \"p4\": 0.7890477911800877, \"phi\": 0.6156035899574209}, {\"truth_threshold\": -10.1, \"match_probability\": 0.0009103355648646677, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11343, \"tn\": 5017, \"fp\": 3032, \"fn\": 681, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9433632734530938, \"tn_rate\": 0.6233072431357932, \"fp_rate\": 0.3766927568642067, \"fn_rate\": 0.056636726546906185, \"precision\": 0.7890782608695652, \"recall\": 0.9433632734530938, \"specificity\": 0.6233072431357932, \"npv\": 0.8804843804843805, \"accuracy\": 0.8150251581726697, \"f1\": 0.8593507329823099, \"f2\": 0.9078612476188952, \"f0_5\": 0.8157614636672228, \"p4\": 0.7893559826149751, \"phi\": 0.6159719213281236}, {\"truth_threshold\": -10.08, \"match_probability\": 0.0009230316460729091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11341, \"tn\": 5017, \"fp\": 3032, \"fn\": 683, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9431969394544245, \"tn_rate\": 0.6233072431357932, \"fp_rate\": 0.3766927568642067, \"fn_rate\": 0.05680306054557552, \"precision\": 0.789048911152856, \"recall\": 0.9431969394544245, \"specificity\": 0.6233072431357932, \"npv\": 0.8801754385964913, \"accuracy\": 0.8149255218452648, \"f1\": 0.859264310338296, \"f2\": 0.9077302341961613, \"f0_5\": 0.8157114908797974, \"p4\": 0.7892574352888401, \"phi\": 0.6157259075467135}, {\"truth_threshold\": -10.06, \"match_probability\": 0.0009359046285117405, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11339, \"tn\": 5017, \"fp\": 3032, \"fn\": 685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9430306054557551, \"tn_rate\": 0.6233072431357932, \"fp_rate\": 0.3766927568642067, \"fn_rate\": 0.05696939454424484, \"precision\": 0.789019553266996, \"recall\": 0.9430306054557551, \"specificity\": 0.6233072431357932, \"npv\": 0.8798667134338829, \"accuracy\": 0.8148258855178598, \"f1\": 0.8591778745974616, \"f2\": 0.9075992123841389, \"f0_5\": 0.8156615065891696, \"p4\": 0.7891588997097047, \"phi\": 0.6154799828067591}, {\"truth_threshold\": -10.040000000000001, \"match_probability\": 0.0009489569723810712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11337, \"tn\": 5017, \"fp\": 3032, \"fn\": 687, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9428642714570858, \"tn_rate\": 0.6233072431357932, \"fp_rate\": 0.3766927568642067, \"fn_rate\": 0.05713572854291417, \"precision\": 0.7889901872085741, \"recall\": 0.9428642714570858, \"specificity\": 0.6233072431357932, \"npv\": 0.8795582047685835, \"accuracy\": 0.8147262491904549, \"f1\": 0.8590914257568295, \"f2\": 0.907468182182022, \"f0_5\": 0.815611510791367, \"p4\": 0.7890603758711823, \"phi\": 0.6152341470239937}, {\"truth_threshold\": -10.02, \"match_probability\": 0.0009621911719644465, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11336, \"tn\": 5022, \"fp\": 3027, \"fn\": 688, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9427811044577512, \"tn_rate\": 0.6239284383153186, \"fp_rate\": 0.3760715616846813, \"fn_rate\": 0.057218895542248835, \"precision\": 0.78925015665251, \"recall\": 0.9427811044577512, \"specificity\": 0.6239284383153186, \"npv\": 0.8795096322241681, \"accuracy\": 0.8149255218452648, \"f1\": 0.8592109751013757, \"f2\": 0.9074753037992923, \"f0_5\": 0.815821290805458, \"p4\": 0.7893497569382009, \"phi\": 0.6156237115148481}, {\"truth_threshold\": -10.0, \"match_probability\": 0.000975609756097561, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11335, \"tn\": 5022, \"fp\": 3027, \"fn\": 689, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9426979374584165, \"tn_rate\": 0.6239284383153186, \"fp_rate\": 0.3760715616846813, \"fn_rate\": 0.0573020625415835, \"precision\": 0.7892354825233254, \"recall\": 0.9426979374584165, \"specificity\": 0.6239284383153186, \"npv\": 0.879355629486955, \"accuracy\": 0.8148757036815623, \"f1\": 0.8591677404684303, \"f2\": 0.9074097793717378, \"f0_5\": 0.815796292031322, \"p4\": 0.7893004970339513, \"phi\": 0.6155009006272182}, {\"truth_threshold\": -9.98, \"match_probability\": 0.0009892152886431212, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11334, \"tn\": 5022, \"fp\": 3027, \"fn\": 690, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9426147704590818, \"tn_rate\": 0.6239284383153186, \"fp_rate\": 0.3760715616846813, \"fn_rate\": 0.05738522954091816, \"precision\": 0.7892208063505327, \"recall\": 0.9426147704590818, \"specificity\": 0.6239284383153186, \"npv\": 0.8792016806722689, \"accuracy\": 0.8148258855178598, \"f1\": 0.8591245025582718, \"f2\": 0.907344252845958, \"f0_5\": 0.8157712903783036, \"p4\": 0.7892512400586588, \"phi\": 0.615378111907519}, {\"truth_threshold\": -9.96, \"match_probability\": 0.0010030103689721156, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11333, \"tn\": 5026, \"fp\": 3023, \"fn\": 691, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9425316034597472, \"tn_rate\": 0.624425394458939, \"fp_rate\": 0.375574605541061, \"fn_rate\": 0.05746839654025283, \"precision\": 0.7894260239621065, \"recall\": 0.9425316034597472, \"specificity\": 0.624425394458939, \"npv\": 0.8791324121042505, \"accuracy\": 0.8149753400089673, \"f1\": 0.8592115238817286, \"f2\": 0.9073368346890411, \"f0_5\": 0.8159342241677227, \"p4\": 0.7894727063363791, \"phi\": 0.6156653992595277}, {\"truth_threshold\": -9.94, \"match_probability\": 0.0010169976324515963, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11325, \"tn\": 5027, \"fp\": 3022, \"fn\": 699, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9418662674650699, \"tn_rate\": 0.624549633494844, \"fp_rate\": 0.3754503665051559, \"fn_rate\": 0.05813373253493014, \"precision\": 0.7893636300271833, \"recall\": 0.9418662674650699, \"specificity\": 0.624549633494844, \"npv\": 0.8779252532308767, \"accuracy\": 0.8146266128630498, \"f1\": 0.8588980319290129, \"f2\": 0.9068270262479381, \"f0_5\": 0.8157811329453121, \"p4\": 0.7891463921204646, \"phi\": 0.6147869826298773}, {\"truth_threshold\": -9.92, \"match_probability\": 0.0010311797509390394, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11324, \"tn\": 5028, \"fp\": 3021, \"fn\": 700, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9417831004657352, \"tn_rate\": 0.6246738725307491, \"fp_rate\": 0.3753261274692508, \"fn_rate\": 0.0582168995342648, \"precision\": 0.7894039735099337, \"recall\": 0.9417831004657352, \"specificity\": 0.6246738725307491, \"npv\": 0.8777932960893855, \"accuracy\": 0.8146266128630498, \"f1\": 0.8588873298191058, \"f2\": 0.9067759965407345, \"f0_5\": 0.8158031237392658, \"p4\": 0.7891647950644033, \"phi\": 0.6147670662362694}, {\"truth_threshold\": -9.9, \"match_probability\": 0.0010455594332833937, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11322, \"tn\": 5028, \"fp\": 3021, \"fn\": 702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9416167664670658, \"tn_rate\": 0.6246738725307491, \"fp_rate\": 0.3753261274692508, \"fn_rate\": 0.058383233532934134, \"precision\": 0.7893746078226312, \"recall\": 0.9416167664670658, \"specificity\": 0.6246738725307491, \"npv\": 0.8774869109947644, \"accuracy\": 0.8145269765356449, \"f1\": 0.8588007736943907, \"f2\": 0.9066448854081584, \"f0_5\": 0.8157530693411724, \"p4\": 0.7890663355491486, \"phi\": 0.6145221197110454}, {\"truth_threshold\": -9.86, \"match_probability\": 0.00107492251294963, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11320, \"tn\": 5028, \"fp\": 3021, \"fn\": 704, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9414504324683965, \"tn_rate\": 0.6246738725307491, \"fp_rate\": 0.3753261274692508, \"fn_rate\": 0.05854956753160346, \"precision\": 0.7893452339446343, \"recall\": 0.9414504324683965, \"specificity\": 0.6246738725307491, \"npv\": 0.8771807397069086, \"accuracy\": 0.8144273402082399, \"f1\": 0.8587142044377015, \"f2\": 0.906513765876003, \"f0_5\": 0.8157030034011644, \"p4\": 0.7889678876938763, \"phi\": 0.6142772611755692}, {\"truth_threshold\": -9.84, \"match_probability\": 0.0010899115175312943, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11317, \"tn\": 5035, \"fp\": 3014, \"fn\": 707, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9412009314703925, \"tn_rate\": 0.6255435457820847, \"fp_rate\": 0.3744564542179153, \"fn_rate\": 0.05879906852960745, \"precision\": 0.7896866931826111, \"recall\": 0.9412009314703925, \"specificity\": 0.6255435457820847, \"npv\": 0.8768721699756182, \"accuracy\": 0.8146266128630498, \"f1\": 0.8588123695693417, \"f2\": 0.9064186970381406, \"f0_5\": 0.8159572013612505, \"p4\": 0.7892933623352207, \"phi\": 0.6146287940363812}, {\"truth_threshold\": -9.82, \"match_probability\": 0.0011051093015396422, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11316, \"tn\": 5037, \"fp\": 3012, \"fn\": 708, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9411177644710579, \"tn_rate\": 0.6257920238538949, \"fp_rate\": 0.3742079761461051, \"fn_rate\": 0.05888223552894212, \"precision\": 0.7897822445561139, \"recall\": 0.9411177644710579, \"specificity\": 0.6257920238538949, \"npv\": 0.8767624020887729, \"accuracy\": 0.8146764310267524, \"f1\": 0.8588342440801457, \"f2\": 0.9063821607074202, \"f0_5\": 0.8160263066805122, \"p4\": 0.7893792320526566, \"phi\": 0.6147118711547576}, {\"truth_threshold\": -9.8, \"match_probability\": 0.0011205187665362995, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11315, \"tn\": 5040, \"fp\": 3009, \"fn\": 709, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9410345974717232, \"tn_rate\": 0.6261647409616101, \"fp_rate\": 0.3738352590383899, \"fn_rate\": 0.05896540252827678, \"precision\": 0.7899329796146328, \"recall\": 0.9410345974717232, \"specificity\": 0.6261647409616101, \"npv\": 0.8766742042094278, \"accuracy\": 0.8147760673541573, \"f1\": 0.8588887202064673, \"f2\": 0.906360140980455, \"f0_5\": 0.8161425274091172, \"p4\": 0.7895325699179515, \"phi\": 0.6148976773902424}, {\"truth_threshold\": -9.78, \"match_probability\": 0.0011361428542256968, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11314, \"tn\": 5048, \"fp\": 3001, \"fn\": 710, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9409514304723886, \"tn_rate\": 0.6271586532488508, \"fp_rate\": 0.3728413467511492, \"fn_rate\": 0.05904856952761144, \"precision\": 0.7903597624869019, \"recall\": 0.9409514304723886, \"specificity\": 0.6271586532488508, \"npv\": 0.8766932962834317, \"accuracy\": 0.8151247945000747, \"f1\": 0.8591062682713846, \"f2\": 0.9064107288779222, \"f0_5\": 0.8164944287281335, \"p4\": 0.7900230613877217, \"phi\": 0.6155969209348947}, {\"truth_threshold\": -9.74, \"match_probability\": 0.0011680468685233154, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11312, \"tn\": 5048, \"fp\": 3001, \"fn\": 712, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9407850964737192, \"tn_rate\": 0.6271586532488508, \"fp_rate\": 0.3728413467511492, \"fn_rate\": 0.059214903526280775, \"precision\": 0.7903304688045832, \"recall\": 0.9407850964737192, \"specificity\": 0.6271586532488508, \"npv\": 0.8763888888888889, \"accuracy\": 0.8150251581726697, \"f1\": 0.8590196301780765, \"f2\": 0.9062795430146293, \"f0_5\": 0.8164443674577054, \"p4\": 0.7899246174522521, \"phi\": 0.6153528191379756}, {\"truth_threshold\": -9.72, \"match_probability\": 0.0011843328842437272, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11277, \"tn\": 5054, \"fp\": 2995, \"fn\": 747, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.937874251497006, \"tn_rate\": 0.6279040874642813, \"fp_rate\": 0.3720959125357187, \"fn_rate\": 0.06212574850299401, \"precision\": 0.7901485426008968, \"recall\": 0.937874251497006, \"specificity\": 0.6279040874642813, \"npv\": 0.8712290984313049, \"accuracy\": 0.8135804314252977, \"f1\": 0.8576969881350776, \"f2\": 0.9040693945613135, \"f0_5\": 0.8158496353744646, \"p4\": 0.7886078528333847, \"phi\": 0.6117132851012258}, {\"truth_threshold\": -9.700000000000001, \"match_probability\": 0.0012008457020191263, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11276, \"tn\": 5059, \"fp\": 2990, \"fn\": 748, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9377910844976713, \"tn_rate\": 0.6285252826438067, \"fp_rate\": 0.3714747173561933, \"fn_rate\": 0.062208915502328675, \"precision\": 0.7904107668582644, \"recall\": 0.9377910844976713, \"specificity\": 0.6285252826438067, \"npv\": 0.8711899431720338, \"accuracy\": 0.8137797040801076, \"f1\": 0.8578166603271206, \"f2\": 0.9040762002501523, \"f0_5\": 0.8160606762389996, \"p4\": 0.7888952370664714, \"phi\": 0.6121072705029575}, {\"truth_threshold\": -9.68, \"match_probability\": 0.0012175884726710806, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11275, \"tn\": 5059, \"fp\": 2990, \"fn\": 749, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9377079174983367, \"tn_rate\": 0.6285252826438067, \"fp_rate\": 0.3714747173561933, \"fn_rate\": 0.06229208250166334, \"precision\": 0.7903960743077463, \"recall\": 0.9377079174983367, \"specificity\": 0.6285252826438067, \"npv\": 0.8710399449035813, \"accuracy\": 0.8137298859164052, \"f1\": 0.8577732131309673, \"f2\": 0.9040105193951348, \"f0_5\": 0.8160355509235134, \"p4\": 0.7888461112588232, \"phi\": 0.6119861386071667}, {\"truth_threshold\": -9.66, \"match_probability\": 0.001234564390578344, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11272, \"tn\": 5059, \"fp\": 2990, \"fn\": 752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9374584165003327, \"tn_rate\": 0.6285252826438067, \"fp_rate\": 0.3714747173561933, \"fn_rate\": 0.06254158349966733, \"precision\": 0.790351984293928, \"recall\": 0.9374584165003327, \"specificity\": 0.6285252826438067, \"npv\": 0.8705902598520048, \"accuracy\": 0.8135804314252977, \"f1\": 0.8576428517081336, \"f2\": 0.9038134641906411, \"f0_5\": 0.8159601575167941, \"p4\": 0.7886987509878348, \"phi\": 0.6116228709444603}, {\"truth_threshold\": -9.64, \"match_probability\": 0.001251776694272957, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11270, \"tn\": 5066, \"fp\": 2983, \"fn\": 754, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9372920825016633, \"tn_rate\": 0.6293949558951423, \"fp_rate\": 0.37060504410485773, \"fn_rate\": 0.06270791749833667, \"precision\": 0.7907107275661265, \"recall\": 0.9372920825016633, \"specificity\": 0.6293949558951423, \"npv\": 0.870446735395189, \"accuracy\": 0.8138295222438101, \"f1\": 0.857784374167523, \"f2\": 0.9037835410351409, \"f0_5\": 0.8162408019004578, \"p4\": 0.7890711845232211, \"phi\": 0.6121024134893551}, {\"truth_threshold\": -9.620000000000001, \"match_probability\": 0.0012692286670443176, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11270, \"tn\": 5070, \"fp\": 2979, \"fn\": 754, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9372920825016633, \"tn_rate\": 0.6298919120387626, \"fp_rate\": 0.3701080879612374, \"fn_rate\": 0.06270791749833667, \"precision\": 0.7909326970313706, \"recall\": 0.9372920825016633, \"specificity\": 0.6298919120387626, \"npv\": 0.8705357142857143, \"accuracy\": 0.81402879489862, \"f1\": 0.8579149697407985, \"f2\": 0.9038415269869275, \"f0_5\": 0.8164300202839757, \"p4\": 0.7893399207785301, \"phi\": 0.6125147310825542}, {\"truth_threshold\": -9.6, \"match_probability\": 0.0012869236375513526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11270, \"tn\": 5077, \"fp\": 2972, \"fn\": 754, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9372920825016633, \"tn_rate\": 0.6307615852900982, \"fp_rate\": 0.3692384147099019, \"fn_rate\": 0.06270791749833667, \"precision\": 0.7913214436174695, \"recall\": 0.9372920825016633, \"specificity\": 0.6307615852900982, \"npv\": 0.8706911335962957, \"accuracy\": 0.8143775220445374, \"f1\": 0.8581436077057794, \"f2\": 0.90394302030864, \"f0_5\": 0.8167613636363636, \"p4\": 0.7898098393111781, \"phi\": 0.6132362290427369}, {\"truth_threshold\": -9.58, \"match_probability\": 0.0013048649804428731, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11269, \"tn\": 5077, \"fp\": 2972, \"fn\": 755, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9372089155023287, \"tn_rate\": 0.6307615852900982, \"fp_rate\": 0.3692384147099019, \"fn_rate\": 0.06279108449767132, \"precision\": 0.7913067902534935, \"recall\": 0.9372089155023287, \"specificity\": 0.6307615852900982, \"npv\": 0.8705418381344308, \"accuracy\": 0.814327703880835, \"f1\": 0.8581001332571864, \"f2\": 0.9038773120297736, \"f0_5\": 0.8167362439844611, \"p4\": 0.7897607112981232, \"phi\": 0.6131154026072662}, {\"truth_threshold\": -9.56, \"match_probability\": 0.0013230561169862418, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11269, \"tn\": 5078, \"fp\": 2971, \"fn\": 755, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9372089155023287, \"tn_rate\": 0.6308858243260033, \"fp_rate\": 0.3691141756739968, \"fn_rate\": 0.06279108449767132, \"precision\": 0.7913623595505618, \"recall\": 0.9372089155023287, \"specificity\": 0.6308858243260033, \"npv\": 0.8705640322304131, \"accuracy\": 0.8143775220445374, \"f1\": 0.8581328053609504, \"f2\": 0.9038918121149897, \"f0_5\": 0.8167836019946654, \"p4\": 0.7898278030888717, \"phi\": 0.6132184776442402}, {\"truth_threshold\": -9.540000000000001, \"match_probability\": 0.001341500515704429, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11268, \"tn\": 5079, \"fp\": 2970, \"fn\": 756, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.937125748502994, \"tn_rate\": 0.6310100633619083, \"fp_rate\": 0.3689899366380917, \"fn_rate\": 0.06287425149700598, \"precision\": 0.7914032869785083, \"recall\": 0.937125748502994, \"specificity\": 0.6310100633619083, \"npv\": 0.8704370179948586, \"accuracy\": 0.8143775220445374, \"f1\": 0.858122001370802, \"f2\": 0.9038406006352874, \"f0_5\": 0.8168058455114823, \"p4\": 0.789845757995534, \"phi\": 0.6132007656477267}, {\"truth_threshold\": -9.52, \"match_probability\": 0.0013602016930215866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11267, \"tn\": 5080, \"fp\": 2969, \"fn\": 757, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9370425815036594, \"tn_rate\": 0.6311343023978134, \"fp_rate\": 0.3688656976021866, \"fn_rate\": 0.06295741849634065, \"precision\": 0.7914442259061534, \"recall\": 0.9370425815036594, \"specificity\": 0.6311343023978134, \"npv\": 0.8703100908000685, \"accuracy\": 0.8143775220445374, \"f1\": 0.8581111957349581, \"f2\": 0.9037893858692164, \"f0_5\": 0.8168280941886092, \"p4\": 0.789863704034925, \"phi\": 0.6131830930272699}, {\"truth_threshold\": -9.48, \"match_probability\": 0.0013983886925891824, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11266, \"tn\": 5082, \"fp\": 2967, \"fn\": 758, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9369594145043247, \"tn_rate\": 0.6313827804696236, \"fp_rate\": 0.36861721953037646, \"fn_rate\": 0.06304058549567532, \"precision\": 0.7915407854984894, \"recall\": 0.9369594145043247, \"specificity\": 0.6313827804696236, \"npv\": 0.8702054794520548, \"accuracy\": 0.8144273402082399, \"f1\": 0.8581330692767642, \"f2\": 0.9037526672977266, \"f0_5\": 0.8168977318870004, \"p4\": 0.7899486915229744, \"phi\": 0.6132685584128736}, {\"truth_threshold\": -9.46, \"match_probability\": 0.0014178817931252896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11266, \"tn\": 5083, \"fp\": 2966, \"fn\": 758, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9369594145043247, \"tn_rate\": 0.6315070195055287, \"fp_rate\": 0.3684929804944714, \"fn_rate\": 0.06304058549567532, \"precision\": 0.7915964024732997, \"recall\": 0.9369594145043247, \"specificity\": 0.6315070195055287, \"npv\": 0.8702277007361753, \"accuracy\": 0.8144771583719425, \"f1\": 0.8581657525898843, \"f2\": 0.9037671672442562, \"f0_5\": 0.8169451212437637, \"p4\": 0.7900157322799878, \"phi\": 0.613371655599816}, {\"truth_threshold\": -9.44, \"match_probability\": 0.0014376462301841668, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11261, \"tn\": 5083, \"fp\": 2966, \"fn\": 763, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9365435795076513, \"tn_rate\": 0.6315070195055287, \"fp_rate\": 0.3684929804944714, \"fn_rate\": 0.06345642049234863, \"precision\": 0.7915231601883742, \"recall\": 0.9365435795076513, \"specificity\": 0.6315070195055287, \"npv\": 0.869483407458091, \"accuracy\": 0.81422806755343, \"f1\": 0.8579482686373853, \"f2\": 0.9034385379394445, \"f0_5\": 0.8168194742644925, \"p4\": 0.7897701453178724, \"phi\": 0.6127684527643542}, {\"truth_threshold\": -9.42, \"match_probability\": 0.0014576857696849406, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11257, \"tn\": 5083, \"fp\": 2966, \"fn\": 767, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9362109115103127, \"tn_rate\": 0.6315070195055287, \"fp_rate\": 0.3684929804944714, \"fn_rate\": 0.0637890884896873, \"precision\": 0.7914645292835548, \"recall\": 0.9362109115103127, \"specificity\": 0.6315070195055287, \"npv\": 0.8688888888888889, \"accuracy\": 0.81402879489862, \"f1\": 0.8577742218158265, \"f2\": 0.9031755965275438, \"f0_5\": 0.8167189041731964, \"p4\": 0.789573726763672, \"phi\": 0.6122862698967685}, {\"truth_threshold\": -9.4, \"match_probability\": 0.0014780042295062135, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11253, \"tn\": 5084, \"fp\": 2965, \"fn\": 771, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9358782435129741, \"tn_rate\": 0.6316312585414338, \"fp_rate\": 0.3683687414585663, \"fn_rate\": 0.06412175648702595, \"precision\": 0.7914615276410184, \"recall\": 0.9358782435129741, \"specificity\": 0.6316312585414338, \"npv\": 0.8683176771989752, \"accuracy\": 0.8138793404075125, \"f1\": 0.8576328023778675, \"f2\": 0.9029271110825817, \"f0_5\": 0.8166656990246168, \"p4\": 0.789444370773107, \"phi\": 0.6119076466302721}, {\"truth_threshold\": -9.38, \"match_probability\": 0.0014986054801942956, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11250, \"tn\": 5089, \"fp\": 2960, \"fn\": 774, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9356287425149701, \"tn_rate\": 0.6322524537209592, \"fp_rate\": 0.3677475462790409, \"fn_rate\": 0.06437125748502993, \"precision\": 0.7916959887403238, \"recall\": 0.9356287425149701, \"specificity\": 0.6322524537209592, \"npv\": 0.8679856728637216, \"accuracy\": 0.8139789767349176, \"f1\": 0.8576656247617596, \"f2\": 0.9028022983340288, \"f0_5\": 0.8168273698884758, \"p4\": 0.7896320445355438, \"phi\": 0.612062750971345}, {\"truth_threshold\": -9.36, \"match_probability\": 0.0015194934456808581, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11249, \"tn\": 5089, \"fp\": 2960, \"fn\": 775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9355455755156354, \"tn_rate\": 0.6322524537209592, \"fp_rate\": 0.3677475462790409, \"fn_rate\": 0.0644544244843646, \"precision\": 0.7916813287353086, \"recall\": 0.9355455755156354, \"specificity\": 0.6322524537209592, \"npv\": 0.867837653478854, \"accuracy\": 0.8139291585712151, \"f1\": 0.8576220790607251, \"f2\": 0.9027365379985555, \"f0_5\": 0.8168022073772873, \"p4\": 0.7895829603108233, \"phi\": 0.6119424632637664}, {\"truth_threshold\": -9.34, \"match_probability\": 0.0015406721040101049, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11249, \"tn\": 5090, \"fp\": 2959, \"fn\": 775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9355455755156354, \"tn_rate\": 0.6323766927568643, \"fp_rate\": 0.3676233072431358, \"fn_rate\": 0.0644544244843646, \"precision\": 0.7917370495495496, \"recall\": 0.9355455755156354, \"specificity\": 0.6323766927568643, \"npv\": 0.8678601875532822, \"accuracy\": 0.8139789767349176, \"f1\": 0.8576547727965843, \"f2\": 0.9027510272213662, \"f0_5\": 0.8168496572557221, \"p4\": 0.7896499161255524, \"phi\": 0.6120457164638227}, {\"truth_threshold\": -9.32, \"match_probability\": 0.0015621454880756095, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11248, \"tn\": 5090, \"fp\": 2959, \"fn\": 776, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9354624085163007, \"tn_rate\": 0.6323766927568643, \"fp_rate\": 0.3676233072431358, \"fn_rate\": 0.06453759148369927, \"precision\": 0.7917223903709439, \"recall\": 0.9354624085163007, \"specificity\": 0.6323766927568643, \"npv\": 0.8677122400272759, \"accuracy\": 0.8139291585712151, \"f1\": 0.8576112233616713, \"f2\": 0.9026852639519767, \"f0_5\": 0.8168244931156684, \"p4\": 0.789600833646776, \"phi\": 0.6119254594096627}, {\"truth_threshold\": -9.3, \"match_probability\": 0.0015839176863668995, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11245, \"tn\": 5094, \"fp\": 2955, \"fn\": 779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9352129075182968, \"tn_rate\": 0.6328736489004846, \"fp_rate\": 0.36712635109951547, \"fn_rate\": 0.06478709248170327, \"precision\": 0.7919014084507042, \"recall\": 0.9352129075182968, \"specificity\": 0.6328736489004846, \"npv\": 0.8673591009705431, \"accuracy\": 0.8139789767349176, \"f1\": 0.8576113483831604, \"f2\": 0.9025459098497496, \"f0_5\": 0.8169388585377194, \"p4\": 0.7897213141503386, \"phi\": 0.6119779673975264}, {\"truth_threshold\": -9.28, \"match_probability\": 0.0016059928437259468, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11245, \"tn\": 5096, \"fp\": 2953, \"fn\": 779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9352129075182968, \"tn_rate\": 0.6331221269722946, \"fp_rate\": 0.3668778730277053, \"fn_rate\": 0.06478709248170327, \"precision\": 0.7920129595717706, \"recall\": 0.9352129075182968, \"specificity\": 0.6331221269722946, \"npv\": 0.8674042553191489, \"accuracy\": 0.8140786130623225, \"f1\": 0.8576767599725421, \"f2\": 0.9025748868269817, \"f0_5\": 0.8170338293420135, \"p4\": 0.7898551127154947, \"phi\": 0.6121845355517571}, {\"truth_threshold\": -9.24, \"match_probability\": 0.001651068901386505, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11244, \"tn\": 5097, \"fp\": 2952, \"fn\": 780, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.935129740518962, \"tn_rate\": 0.6332463660081997, \"fp_rate\": 0.3667536339918002, \"fn_rate\": 0.06487025948103792, \"precision\": 0.7920540997464074, \"recall\": 0.935129740518962, \"specificity\": 0.6332463660081997, \"npv\": 0.8672792240939254, \"accuracy\": 0.8140786130623225, \"f1\": 0.8576659038901602, \"f2\": 0.9025235985359276, \"f0_5\": 0.8170561562608999, \"p4\": 0.7898729190464395, \"phi\": 0.6121677119123327}, {\"truth_threshold\": -9.22, \"match_probability\": 0.0016740783800834494, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11243, \"tn\": 5099, \"fp\": 2950, \"fn\": 781, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9350465735196274, \"tn_rate\": 0.6334948440800099, \"fp_rate\": 0.36650515591999006, \"fn_rate\": 0.06495342648037258, \"precision\": 0.7921510603818784, \"recall\": 0.9350465735196274, \"specificity\": 0.6334948440800099, \"npv\": 0.8671768707482993, \"accuracy\": 0.814128431226025, \"f1\": 0.8576877598504787, \"f2\": 0.9024867954213425, \"f0_5\": 0.8171259956974243, \"p4\": 0.7899575805409753, \"phi\": 0.6122542254878992}, {\"truth_threshold\": -9.200000000000001, \"match_probability\": 0.0016974079762232014, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11243, \"tn\": 5102, \"fp\": 2947, \"fn\": 781, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9350465735196274, \"tn_rate\": 0.6338675611877251, \"fp_rate\": 0.3661324388122748, \"fn_rate\": 0.06495342648037258, \"precision\": 0.7923185341789993, \"recall\": 0.9350465735196274, \"specificity\": 0.6338675611877251, \"npv\": 0.8672446030936597, \"accuracy\": 0.8142778857171324, \"f1\": 0.8577859159227893, \"f2\": 0.9025302636226439, \"f0_5\": 0.8172685508257734, \"p4\": 0.7901581156891561, \"phi\": 0.6125641121763025}, {\"truth_threshold\": -9.18, \"match_probability\": 0.0017210621281120474, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11242, \"tn\": 5102, \"fp\": 2947, \"fn\": 782, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9349634065202928, \"tn_rate\": 0.6338675611877251, \"fp_rate\": 0.3661324388122748, \"fn_rate\": 0.06503659347970725, \"precision\": 0.7923038973852985, \"recall\": 0.9349634065202928, \"specificity\": 0.6338675611877251, \"npv\": 0.8670972127804215, \"accuracy\": 0.81422806755343, \"f1\": 0.8577423415862359, \"f2\": 0.9024644778036446, \"f0_5\": 0.817243384704856, \"p4\": 0.7901090372182432, \"phi\": 0.6124440967168414}, {\"truth_threshold\": -9.16, \"match_probability\": 0.0017450453351622972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11237, \"tn\": 5103, \"fp\": 2946, \"fn\": 787, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9345475715236194, \"tn_rate\": 0.6339918002236302, \"fp_rate\": 0.3660081997763697, \"fn_rate\": 0.06545242847638057, \"precision\": 0.7922865402242121, \"recall\": 0.9345475715236194, \"specificity\": 0.6339918002236302, \"npv\": 0.866383701188455, \"accuracy\": 0.81402879489862, \"f1\": 0.8575571412218109, \"f2\": 0.9021500024085165, \"f0_5\": 0.8171650474140438, \"p4\": 0.7899305066710367, \"phi\": 0.6119476817844538}, {\"truth_threshold\": -9.14, \"match_probability\": 0.001769362158721538, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11236, \"tn\": 5107, \"fp\": 2942, \"fn\": 788, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9344644045242848, \"tn_rate\": 0.6344887563672506, \"fp_rate\": 0.3655112436327494, \"fn_rate\": 0.06553559547571523, \"precision\": 0.79249541543236, \"recall\": 0.9344644045242848, \"specificity\": 0.6344887563672506, \"npv\": 0.8663273960983885, \"accuracy\": 0.8141782493897275, \"f1\": 0.8576444546217846, \"f2\": 0.9021421459999358, \"f0_5\": 0.8173300744878957, \"p4\": 0.7901486241113148, \"phi\": 0.6122412278570167}, {\"truth_threshold\": -9.120000000000001, \"match_probability\": 0.001794017222912777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11234, \"tn\": 5111, \"fp\": 2938, \"fn\": 790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9342980705256154, \"tn_rate\": 0.6349857125108709, \"fp_rate\": 0.36501428748912906, \"fn_rate\": 0.06570192947438457, \"precision\": 0.792689810894722, \"recall\": 0.9342980705256154, \"specificity\": 0.6349857125108709, \"npv\": 0.8661243856973394, \"accuracy\": 0.8142778857171324, \"f1\": 0.8576881966712475, \"f2\": 0.9020684781910452, \"f0_5\": 0.8174700197927581, \"p4\": 0.7903175192951836, \"phi\": 0.6124150864847078}, {\"truth_threshold\": -9.1, \"match_probability\": 0.0018190152154856484, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11232, \"tn\": 5111, \"fp\": 2938, \"fn\": 792, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9341317365269461, \"tn_rate\": 0.6349857125108709, \"fp_rate\": 0.36501428748912906, \"fn_rate\": 0.0658682634730539, \"precision\": 0.7926605504587156, \"recall\": 0.9341317365269461, \"specificity\": 0.6349857125108709, \"npv\": 0.8658309334236829, \"accuracy\": 0.8141782493897275, \"f1\": 0.8576009773230511, \"f2\": 0.9019368515722866, \"f0_5\": 0.8174196553330229, \"p4\": 0.790219396298102, \"phi\": 0.6121756231019636}, {\"truth_threshold\": -9.08, \"match_probability\": 0.0018443608886787883, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11229, \"tn\": 5116, \"fp\": 2933, \"fn\": 795, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9338822355289421, \"tn_rate\": 0.6356069076903963, \"fp_rate\": 0.36439309230960365, \"fn_rate\": 0.06611776447105788, \"precision\": 0.7928964835475215, \"recall\": 0.9338822355289421, \"specificity\": 0.6356069076903963, \"npv\": 0.8655049906953138, \"accuracy\": 0.8142778857171324, \"f1\": 0.8576338501489346, \"f2\": 0.9018118153490314, \"f0_5\": 0.8175821295433364, \"p4\": 0.7904057703911597, \"phi\": 0.6123336439073894}, {\"truth_threshold\": -9.040000000000001, \"match_probability\": 0.0018961146135791532, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11228, \"tn\": 5116, \"fp\": 2933, \"fn\": 796, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9337990685296075, \"tn_rate\": 0.6356069076903963, \"fp_rate\": 0.36439309230960365, \"fn_rate\": 0.06620093147039255, \"precision\": 0.7928818586258033, \"recall\": 0.9337990685296075, \"specificity\": 0.6356069076903963, \"npv\": 0.8653585926928281, \"accuracy\": 0.81422806755343, \"f1\": 0.8575902234103494, \"f2\": 0.9017459884029105, \"f0_5\": 0.8175569406419293, \"p4\": 0.7903567160988224, \"phi\": 0.6122140530652503}, {\"truth_threshold\": -9.02, \"match_probability\": 0.001922532500129454, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11224, \"tn\": 5117, \"fp\": 2932, \"fn\": 800, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9334664005322688, \"tn_rate\": 0.6357311467263014, \"fp_rate\": 0.3642688532736986, \"fn_rate\": 0.0665335994677312, \"precision\": 0.792879344447584, \"recall\": 0.9334664005322688, \"specificity\": 0.6357311467263014, \"npv\": 0.8647963495014366, \"accuracy\": 0.8140786130623225, \"f1\": 0.8574484339190221, \"f2\": 0.9014971406541156, \"f0_5\": 0.8175037874373616, \"p4\": 0.7902272008142724, \"phi\": 0.6118393513720416}, {\"truth_threshold\": -8.98, \"match_probability\": 0.001976475417585539, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11222, \"tn\": 5117, \"fp\": 2932, \"fn\": 802, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9333000665335994, \"tn_rate\": 0.6357311467263014, \"fp_rate\": 0.3642688532736986, \"fn_rate\": 0.06669993346640053, \"precision\": 0.7928500777165466, \"recall\": 0.9333000665335994, \"specificity\": 0.6357311467263014, \"npv\": 0.8645041392127049, \"accuracy\": 0.8139789767349176, \"f1\": 0.8573611429444572, \"f2\": 0.9013654618473895, \"f0_5\": 0.81745337995338, \"p4\": 0.7901291207349642, \"phi\": 0.611600414977593}, {\"truth_threshold\": -8.96, \"match_probability\": 0.0020040106944381785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11220, \"tn\": 5118, \"fp\": 2931, \"fn\": 804, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9331337325349301, \"tn_rate\": 0.6358553857622065, \"fp_rate\": 0.36414461423779354, \"fn_rate\": 0.06686626746506986, \"precision\": 0.792876828492686, \"recall\": 0.9331337325349301, \"specificity\": 0.6358553857622065, \"npv\": 0.8642350557244174, \"accuracy\": 0.8139291585712151, \"f1\": 0.8573065902578797, \"f2\": 0.9012482529278519, \"f0_5\": 0.8174506032523169, \"p4\": 0.7900977121252132, \"phi\": 0.6114650534766969}, {\"truth_threshold\": -8.92, \"match_probability\": 0.0020602350292337574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11219, \"tn\": 5119, \"fp\": 2930, \"fn\": 805, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9330505655355955, \"tn_rate\": 0.6359796247981115, \"fp_rate\": 0.36402037520188846, \"fn_rate\": 0.06694943446440453, \"precision\": 0.7929182274365679, \"recall\": 0.9330505655355955, \"specificity\": 0.6359796247981115, \"npv\": 0.8641120864280891, \"accuracy\": 0.8139291585712151, \"f1\": 0.8572956863943759, \"f2\": 0.9011968832837979, \"f0_5\": 0.8174730399300495, \"p4\": 0.7901153306445823, \"phi\": 0.6114491675956564}, {\"truth_threshold\": -8.9, \"match_probability\": 0.0020889347611217834, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11217, \"tn\": 5119, \"fp\": 2930, \"fn\": 807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9328842315369261, \"tn_rate\": 0.6359796247981115, \"fp_rate\": 0.36402037520188846, \"fn_rate\": 0.06711576846307385, \"precision\": 0.792888951721213, \"recall\": 0.9328842315369261, \"specificity\": 0.6359796247981115, \"npv\": 0.8638204522443469, \"accuracy\": 0.8138295222438101, \"f1\": 0.8572083603989148, \"f2\": 0.9010651800202433, \"f0_5\": 0.817422608290095, \"p4\": 0.790017274079507, \"phi\": 0.6112104744123195}, {\"truth_threshold\": -8.88, \"match_probability\": 0.002118033440909814, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11216, \"tn\": 5120, \"fp\": 2929, \"fn\": 808, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9328010645375915, \"tn_rate\": 0.6361038638340166, \"fp_rate\": 0.3638961361659834, \"fn_rate\": 0.06719893546240852, \"precision\": 0.7929303640862495, \"recall\": 0.9328010645375915, \"specificity\": 0.6361038638340166, \"npv\": 0.863697705802969, \"accuracy\": 0.8138295222438101, \"f1\": 0.8571974473613818, \"f2\": 0.9010138011921403, \"f0_5\": 0.8174450469360387, \"p4\": 0.7900348872716351, \"phi\": 0.6111946867137452}, {\"truth_threshold\": -8.86, \"match_probability\": 0.0021475365904707793, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11214, \"tn\": 5120, \"fp\": 2929, \"fn\": 810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9326347305389222, \"tn_rate\": 0.6361038638340166, \"fp_rate\": 0.3638961361659834, \"fn_rate\": 0.06736526946107785, \"precision\": 0.7929010818072545, \"recall\": 0.9326347305389222, \"specificity\": 0.6361038638340166, \"npv\": 0.863406408094435, \"accuracy\": 0.8137298859164052, \"f1\": 0.8571101005082737, \"f2\": 0.9008820835810344, \"f0_5\": 0.8173946002682372, \"p4\": 0.7899368452180938, \"phi\": 0.6109561353183374}, {\"truth_threshold\": -8.84, \"match_probability\": 0.0021774498074386152, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11212, \"tn\": 5121, \"fp\": 2928, \"fn\": 812, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9324683965402528, \"tn_rate\": 0.6362281028699217, \"fp_rate\": 0.3637718971300783, \"fn_rate\": 0.06753160345974717, \"precision\": 0.792927864214993, \"recall\": 0.9324683965402528, \"specificity\": 0.6362281028699217, \"npv\": 0.8631383785605933, \"accuracy\": 0.8136800677527026, \"f1\": 0.8570554961015135, \"f2\": 0.900764830644643, \"f0_5\": 0.8173918115012248, \"p4\": 0.789905437908072, \"phi\": 0.6108212305148386}, {\"truth_threshold\": -8.82, \"match_probability\": 0.002207778766228983, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11211, \"tn\": 5121, \"fp\": 2928, \"fn\": 813, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9323852295409182, \"tn_rate\": 0.6362281028699217, \"fp_rate\": 0.3637718971300783, \"fn_rate\": 0.06761477045908183, \"precision\": 0.7929132187566306, \"recall\": 0.9323852295409182, \"specificity\": 0.6362281028699217, \"npv\": 0.8629929221435794, \"accuracy\": 0.8136302495890001, \"f1\": 0.8570118105721821, \"f2\": 0.9006989636056881, \"f0_5\": 0.8173665791776028, \"p4\": 0.7898564255136, \"phi\": 0.6107020357965104}, {\"truth_threshold\": -8.8, \"match_probability\": 0.002238529219073188, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11207, \"tn\": 5125, \"fp\": 2924, \"fn\": 817, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9320525615435795, \"tn_rate\": 0.636725059013542, \"fp_rate\": 0.36327494098645796, \"fn_rate\": 0.0679474384564205, \"precision\": 0.7930790460689264, \"recall\": 0.9320525615435795, \"specificity\": 0.636725059013542, \"npv\": 0.8625042073375968, \"accuracy\": 0.8136302495890001, \"f1\": 0.8569680749378704, \"f2\": 0.9004933549745288, \"f0_5\": 0.8174563809301512, \"p4\": 0.7899267832165582, \"phi\": 0.6106398962970392}, {\"truth_threshold\": -8.78, \"match_probability\": 0.0022697069970654916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11206, \"tn\": 5125, \"fp\": 2924, \"fn\": 818, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9319693945442449, \"tn_rate\": 0.636725059013542, \"fp_rate\": 0.36327494098645796, \"fn_rate\": 0.06803060545575515, \"precision\": 0.7930644019815994, \"recall\": 0.9319693945442449, \"specificity\": 0.636725059013542, \"npv\": 0.8623590779067811, \"accuracy\": 0.8135804314252977, \"f1\": 0.8569243710331116, \"f2\": 0.9004274740462186, \"f0_5\": 0.8174311391223156, \"p4\": 0.789877780353592, \"phi\": 0.6105208413674882}, {\"truth_threshold\": -8.74, \"match_probability\": 0.002333368253564943, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11201, \"tn\": 5125, \"fp\": 2924, \"fn\": 823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9315535595475716, \"tn_rate\": 0.636725059013542, \"fp_rate\": 0.36327494098645796, \"fn_rate\": 0.06844644045242848, \"precision\": 0.7929911504424779, \"recall\": 0.9315535595475716, \"specificity\": 0.636725059013542, \"npv\": 0.8616341627437795, \"accuracy\": 0.8133313406067852, \"f1\": 0.8567058013690773, \"f2\": 0.900098037640025, \"f0_5\": 0.8173048858793999, \"p4\": 0.7896328075134914, \"phi\": 0.6099258714406388}, {\"truth_threshold\": -8.72, \"match_probability\": 0.0023658637981916145, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11199, \"tn\": 5125, \"fp\": 2924, \"fn\": 825, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9313872255489022, \"tn_rate\": 0.636725059013542, \"fp_rate\": 0.36327494098645796, \"fn_rate\": 0.0686127744510978, \"precision\": 0.7929618353041139, \"recall\": 0.9313872255489022, \"specificity\": 0.636725059013542, \"npv\": 0.8613445378151261, \"accuracy\": 0.8132317042793803, \"f1\": 0.8566183500975255, \"f2\": 0.8999662482521417, \"f0_5\": 0.8172543639441883, \"p4\": 0.7895348377176697, \"phi\": 0.6096880254987287}, {\"truth_threshold\": -8.700000000000001, \"match_probability\": 0.002398810802396238, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11196, \"tn\": 5128, \"fp\": 2921, \"fn\": 828, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9311377245508982, \"tn_rate\": 0.6370977761212573, \"fp_rate\": 0.3629022238787427, \"fn_rate\": 0.0688622754491018, \"precision\": 0.7930863497910321, \"recall\": 0.9311377245508982, \"specificity\": 0.6370977761212573, \"npv\": 0.8609805238415044, \"accuracy\": 0.8132317042793803, \"f1\": 0.8565854404957729, \"f2\": 0.899811936412004, \"f0_5\": 0.8173217310050809, \"p4\": 0.7895875547670403, \"phi\": 0.6096425324824833}, {\"truth_threshold\": -8.68, \"match_probability\": 0.00243221550777684, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11193, \"tn\": 5150, \"fp\": 2899, \"fn\": 831, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9308882235528942, \"tn_rate\": 0.6398310349111691, \"fp_rate\": 0.3601689650888309, \"fn_rate\": 0.06911177644710578, \"precision\": 0.794280442804428, \"recall\": 0.9308882235528942, \"specificity\": 0.6398310349111691, \"npv\": 0.8610600234074569, \"accuracy\": 0.8141782493897275, \"f1\": 0.8571756777454435, \"f2\": 0.89993246285457, \"f0_5\": 0.8182974616914259, \"p4\": 0.7909021205982029, \"phi\": 0.6115680051457406}, {\"truth_threshold\": -8.66, \"match_probability\": 0.0024660842413681285, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11190, \"tn\": 5151, \"fp\": 2898, \"fn\": 834, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9306387225548902, \"tn_rate\": 0.6399552739470742, \"fp_rate\": 0.3600447260529258, \"fn_rate\": 0.06936127744510978, \"precision\": 0.7942930153321976, \"recall\": 0.9306387225548902, \"specificity\": 0.6399552739470742, \"npv\": 0.8606516290726817, \"accuracy\": 0.8140786130623225, \"f1\": 0.8570772058823529, \"f2\": 0.8997491316094172, \"f0_5\": 0.8182695682695683, \"p4\": 0.7908214768127193, \"phi\": 0.611316188349808}, {\"truth_threshold\": -8.64, \"match_probability\": 0.002500423416786966, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11187, \"tn\": 5152, \"fp\": 2897, \"fn\": 837, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9303892215568862, \"tn_rate\": 0.6400795129829793, \"fp_rate\": 0.35992048701702073, \"fn_rate\": 0.06961077844311377, \"precision\": 0.7943055950014201, \"recall\": 0.9303892215568862, \"specificity\": 0.6400795129829793, \"npv\": 0.860243780263817, \"accuracy\": 0.8139789767349176, \"f1\": 0.8569787038455646, \"f2\": 0.8995657767770987, \"f0_5\": 0.8182416617905208, \"p4\": 0.7907408420251705, \"phi\": 0.6110646068963733}, {\"truth_threshold\": -8.620000000000001, \"match_probability\": 0.0025352395353924907, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11187, \"tn\": 5280, \"fp\": 2769, \"fn\": 837, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9303892215568862, \"tn_rate\": 0.6559821095788296, \"fp_rate\": 0.3440178904211703, \"fn_rate\": 0.06961077844311377, \"precision\": 0.8015907136715391, \"recall\": 0.9303892215568862, \"specificity\": 0.6559821095788296, \"npv\": 0.8631682197155468, \"accuracy\": 0.8203557016888358, \"f1\": 0.8612009237875289, \"f2\": 0.9014213885128601, \"f0_5\": 0.8244163424124513, \"p4\": 0.799154019712305, \"phi\": 0.6243361119257352}, {\"truth_threshold\": -8.6, \"match_probability\": 0.0025705391874611093, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11183, \"tn\": 5283, \"fp\": 2766, \"fn\": 841, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9300565535595475, \"tn_rate\": 0.6563548266865449, \"fp_rate\": 0.34364517331345507, \"fn_rate\": 0.06994344644045243, \"precision\": 0.801706215499319, \"recall\": 0.9300565535595475, \"specificity\": 0.6563548266865449, \"npv\": 0.8626714565643371, \"accuracy\": 0.8203058835251332, \"f1\": 0.8611250144380703, \"f2\": 0.9012007413973728, \"f0_5\": 0.824461810675317, \"p4\": 0.7991530327320008, \"phi\": 0.6241783620725204}, {\"truth_threshold\": -8.58, \"match_probability\": 0.0026063290533764843, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11183, \"tn\": 5284, \"fp\": 2765, \"fn\": 841, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9300565535595475, \"tn_rate\": 0.65647906572245, \"fp_rate\": 0.34352093427755, \"fn_rate\": 0.06994344644045243, \"precision\": 0.8017636937195297, \"recall\": 0.9300565535595475, \"specificity\": 0.65647906572245, \"npv\": 0.8626938775510204, \"accuracy\": 0.8203557016888358, \"f1\": 0.8611581703372863, \"f2\": 0.9012152665850042, \"f0_5\": 0.824510440014156, \"p4\": 0.7992181613625221, \"phi\": 0.6242820140383544}, {\"truth_threshold\": -8.56, \"match_probability\": 0.0026426159048347467, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11182, \"tn\": 5284, \"fp\": 2765, \"fn\": 842, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9299733865602129, \"tn_rate\": 0.65647906572245, \"fp_rate\": 0.34352093427755, \"fn_rate\": 0.0700266134397871, \"precision\": 0.8017494801749481, \"recall\": 0.9299733865602129, \"specificity\": 0.65647906572245, \"npv\": 0.8625530525628469, \"accuracy\": 0.8203058835251332, \"f1\": 0.8611143198182588, \"f2\": 0.9011492029721322, \"f0_5\": 0.8244853418274052, \"p4\": 0.7991690578058008, \"phi\": 0.6241649216206113}, {\"truth_threshold\": -8.540000000000001, \"match_probability\": 0.0026794066060650402, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11181, \"tn\": 5284, \"fp\": 2765, \"fn\": 843, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9298902195608783, \"tn_rate\": 0.65647906572245, \"fp_rate\": 0.34352093427755, \"fn_rate\": 0.07010978043912176, \"precision\": 0.8017352645919977, \"recall\": 0.9298902195608783, \"specificity\": 0.65647906572245, \"npv\": 0.8624122735433328, \"accuracy\": 0.8202560653614308, \"f1\": 0.8610704659222179, \"f2\": 0.9010831372296186, \"f0_5\": 0.8244602406795658, \"p4\": 0.7991199569051676, \"phi\": 0.6240478485333442}, {\"truth_threshold\": -8.52, \"match_probability\": 0.0027167081150656154, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11179, \"tn\": 5401, \"fp\": 2648, \"fn\": 845, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9297238855622089, \"tn_rate\": 0.6710150329233445, \"fp_rate\": 0.3289849670766555, \"fn_rate\": 0.07027611443779108, \"precision\": 0.8084906342662906, \"recall\": 0.9297238855622089, \"specificity\": 0.6710150329233445, \"npv\": 0.8647134165866154, \"accuracy\": 0.8259851541872166, \"f1\": 0.8648795017600867, \"f2\": 0.9026532952214847, \"f0_5\": 0.8301402007960553, \"p4\": 0.8065828532399105, \"phi\": 0.6359401492510661}, {\"truth_threshold\": -8.5, \"match_probability\": 0.0027545274848556306, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11175, \"tn\": 5404, \"fp\": 2645, \"fn\": 849, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9293912175648703, \"tn_rate\": 0.6713877500310598, \"fp_rate\": 0.32861224996894023, \"fn_rate\": 0.07060878243512975, \"precision\": 0.8086107091172214, \"recall\": 0.9293912175648703, \"specificity\": 0.6713877500310598, \"npv\": 0.8642251719174796, \"accuracy\": 0.8259353360235142, \"f1\": 0.8648042098746324, \"f2\": 0.9024323276697461, \"f0_5\": 0.8301883989064544, \"p4\": 0.806578405483537, \"phi\": 0.6357874219969484}, {\"truth_threshold\": -8.48, \"match_probability\": 0.0027928718647428573, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11168, \"tn\": 5404, \"fp\": 2645, \"fn\": 856, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9288090485695276, \"tn_rate\": 0.6713877500310598, \"fp_rate\": 0.32861224996894023, \"fn_rate\": 0.07119095143047238, \"precision\": 0.8085137189603996, \"recall\": 0.9288090485695276, \"specificity\": 0.6713877500310598, \"npv\": 0.8632587859424921, \"accuracy\": 0.8255866088775967, \"f1\": 0.8644966520880907, \"f2\": 0.9019690190440808, \"f0_5\": 0.8300136750104049, \"p4\": 0.8062340599211705, \"phi\": 0.6349769340933676}, {\"truth_threshold\": -8.46, \"match_probability\": 0.0028317485016074407, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11161, \"tn\": 5404, \"fp\": 2645, \"fn\": 863, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9282268795741849, \"tn_rate\": 0.6713877500310598, \"fp_rate\": 0.32861224996894023, \"fn_rate\": 0.07177312042581503, \"precision\": 0.8084166304505288, \"recall\": 0.9282268795741849, \"specificity\": 0.6713877500310598, \"npv\": 0.8622945588000638, \"accuracy\": 0.8252378817316793, \"f1\": 0.8641889276035617, \"f2\": 0.9015056056347129, \"f0_5\": 0.8298388056150369, \"p4\": 0.8058898406819452, \"phi\": 0.6341673606506308}, {\"truth_threshold\": -8.42, \"match_probability\": 0.002911128029467595, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11161, \"tn\": 5406, \"fp\": 2643, \"fn\": 863, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9282268795741849, \"tn_rate\": 0.6716362281028699, \"fp_rate\": 0.32836377189713006, \"fn_rate\": 0.07177312042581503, \"precision\": 0.8085337583309186, \"recall\": 0.9282268795741849, \"specificity\": 0.6716362281028699, \"npv\": 0.8623384909873983, \"accuracy\": 0.8253375180590844, \"f1\": 0.8642558463682825, \"f2\": 0.901534733441034, \"f0_5\": 0.8299375371802499, \"p4\": 0.8060180176182186, \"phi\": 0.6343748988810808}, {\"truth_threshold\": -8.4, \"match_probability\": 0.002951645913867726, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11159, \"tn\": 5406, \"fp\": 2643, \"fn\": 865, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9280605455755156, \"tn_rate\": 0.6716362281028699, \"fp_rate\": 0.32836377189713006, \"fn_rate\": 0.07193945442448436, \"precision\": 0.8085060136212143, \"recall\": 0.9280605455755156, \"specificity\": 0.6716362281028699, \"npv\": 0.8620634667517142, \"accuracy\": 0.8252378817316793, \"f1\": 0.864167892821188, \"f2\": 0.9014023070212285, \"f0_5\": 0.8298875535459305, \"p4\": 0.8059196885995, \"phi\": 0.6341437959223734}, {\"truth_threshold\": -8.38, \"match_probability\": 0.0029927260447372276, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11158, \"tn\": 5413, \"fp\": 2636, \"fn\": 866, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.927977378576181, \"tn_rate\": 0.6725059013542055, \"fp_rate\": 0.3274940986457945, \"fn_rate\": 0.07202262142381903, \"precision\": 0.8089024213426127, \"recall\": 0.927977378576181, \"specificity\": 0.6725059013542055, \"npv\": 0.8620799490364708, \"accuracy\": 0.8255367907138943, \"f1\": 0.8643581997056318, \"f2\": 0.9014380352237842, \"f0_5\": 0.8302083333333333, \"p4\": 0.8063188711257536, \"phi\": 0.6347548302618086}, {\"truth_threshold\": -8.36, \"match_probability\": 0.0030343761766495666, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11158, \"tn\": 5415, \"fp\": 2634, \"fn\": 866, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.927977378576181, \"tn_rate\": 0.6727543794260157, \"fp_rate\": 0.3272456205739843, \"fn_rate\": 0.07202262142381903, \"precision\": 0.8090197215777262, \"recall\": 0.927977378576181, \"specificity\": 0.6727543794260157, \"npv\": 0.8621238656264926, \"accuracy\": 0.8256364270412992, \"f1\": 0.8644251626898047, \"f2\": 0.9014671664943124, \"f0_5\": 0.8303071794261222, \"p4\": 0.8064468961664035, \"phi\": 0.6349624138585613}, {\"truth_threshold\": -8.34, \"match_probability\": 0.003076604169800717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11154, \"tn\": 5415, \"fp\": 2634, \"fn\": 870, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9276447105788423, \"tn_rate\": 0.6727543794260157, \"fp_rate\": 0.3272456205739843, \"fn_rate\": 0.07235528942115768, \"precision\": 0.8089643167972149, \"recall\": 0.9276447105788423, \"specificity\": 0.6727543794260157, \"npv\": 0.8615751789976134, \"accuracy\": 0.8254371543864893, \"f1\": 0.8642491864249187, \"f2\": 0.9012022493697887, \"f0_5\": 0.8302072168631655, \"p4\": 0.8062502447827926, \"phi\": 0.6345008298556678}, {\"truth_threshold\": -8.3, \"match_probability\": 0.0031628257171415226, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11146, \"tn\": 5420, \"fp\": 2629, \"fn\": 878, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.926979374584165, \"tn_rate\": 0.6733755746055411, \"fp_rate\": 0.32662442539445896, \"fn_rate\": 0.073020625415835, \"precision\": 0.8091470054446461, \"recall\": 0.926979374584165, \"specificity\": 0.6733755746055411, \"npv\": 0.8605906637027628, \"accuracy\": 0.8252876998953819, \"f1\": 0.8640644986239777, \"f2\": 0.9007450986730455, \"f0_5\": 0.8302544544425243, \"p4\": 0.8061769285091288, \"phi\": 0.6340980399996714}, {\"truth_threshold\": -8.28, \"match_probability\": 0.0032068355325356353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11146, \"tn\": 5427, \"fp\": 2622, \"fn\": 878, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.926979374584165, \"tn_rate\": 0.6742452478568767, \"fp_rate\": 0.3257547521431234, \"fn_rate\": 0.073020625415835, \"precision\": 0.8095583962812318, \"recall\": 0.926979374584165, \"specificity\": 0.6742452478568767, \"npv\": 0.8607454401268835, \"accuracy\": 0.8256364270412992, \"f1\": 0.8642990074441688, \"f2\": 0.9008470192680719, \"f0_5\": 0.8306009300107309, \"p4\": 0.8066243985905616, \"phi\": 0.6348253074391812}, {\"truth_threshold\": -8.26, \"match_probability\": 0.0032514557344685887, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11144, \"tn\": 5427, \"fp\": 2622, \"fn\": 880, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9268130405854956, \"tn_rate\": 0.6742452478568767, \"fp_rate\": 0.3257547521431234, \"fn_rate\": 0.07318695941450433, \"precision\": 0.8095307278802848, \"recall\": 0.9268130405854956, \"specificity\": 0.6742452478568767, \"npv\": 0.8604724908831457, \"accuracy\": 0.8255367907138943, \"f1\": 0.8642109344707251, \"f2\": 0.9007144935501601, \"f0_5\": 0.830550918196995, \"p4\": 0.8065261061977793, \"phi\": 0.6345951370132203}, {\"truth_threshold\": -8.24, \"match_probability\": 0.0032966947326226116, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11141, \"tn\": 5429, \"fp\": 2620, \"fn\": 883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9265635395874917, \"tn_rate\": 0.6744937259286868, \"fp_rate\": 0.3255062740713132, \"fn_rate\": 0.07343646041250831, \"precision\": 0.8096068599665722, \"recall\": 0.9265635395874917, \"specificity\": 0.6744937259286868, \"npv\": 0.8601077313054499, \"accuracy\": 0.8254869725501918, \"f1\": 0.8641458212138841, \"f2\": 0.9005448049533602, \"f0_5\": 0.8305749388680146, \"p4\": 0.8065064532762036, \"phi\": 0.6344578952982197}, {\"truth_threshold\": -8.22, \"match_probability\": 0.0033425610509773486, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11141, \"tn\": 5436, \"fp\": 2613, \"fn\": 883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9265635395874917, \"tn_rate\": 0.6753633991800224, \"fp_rate\": 0.32463660081997764, \"fn_rate\": 0.07343646041250831, \"precision\": 0.8100189035916824, \"recall\": 0.9265635395874917, \"specificity\": 0.6753633991800224, \"npv\": 0.8602626997942713, \"accuracy\": 0.8258356996961091, \"f1\": 0.8643804794786252, \"f2\": 0.9006467259498787, \"f0_5\": 0.8309218377088305, \"p4\": 0.8069533833188716, \"phi\": 0.635185448226176}, {\"truth_threshold\": -8.2, \"match_probability\": 0.0033890633293192944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11141, \"tn\": 5441, \"fp\": 2608, \"fn\": 883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9265635395874917, \"tn_rate\": 0.6759845943595477, \"fp_rate\": 0.3240154056404522, \"fn_rate\": 0.07343646041250831, \"precision\": 0.8103134773438069, \"recall\": 0.9265635395874917, \"specificity\": 0.6759845943595477, \"npv\": 0.8603731815306768, \"accuracy\": 0.8260847905146216, \"f1\": 0.8645481705660963, \"f2\": 0.9007195407874525, \"f0_5\": 0.8311698000596837, \"p4\": 0.8072723786976427, \"phi\": 0.6357051162040421}, {\"truth_threshold\": -8.18, \"match_probability\": 0.0034362103247699053, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11141, \"tn\": 5445, \"fp\": 2604, \"fn\": 883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9265635395874917, \"tn_rate\": 0.676481550503168, \"fp_rate\": 0.3235184494968319, \"fn_rate\": 0.07343646041250831, \"precision\": 0.8105492906511459, \"recall\": 0.9265635395874917, \"specificity\": 0.676481550503168, \"npv\": 0.8604614412136536, \"accuracy\": 0.8262840631694316, \"f1\": 0.8646823702898832, \"f2\": 0.9007778011351693, \"f0_5\": 0.8313682765208047, \"p4\": 0.8075274311451114, \"phi\": 0.636120843275244}, {\"truth_threshold\": -8.16, \"match_probability\": 0.0034840109133326283, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11136, \"tn\": 5447, \"fp\": 2602, \"fn\": 888, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9261477045908184, \"tn_rate\": 0.6767300285749782, \"fp_rate\": 0.32326997142502173, \"fn_rate\": 0.07385229540918163, \"precision\": 0.8105983403697773, \"recall\": 0.9261477045908184, \"specificity\": 0.6767300285749782, \"npv\": 0.8598263614838201, \"accuracy\": 0.8261346086783241, \"f1\": 0.8645291514633957, \"f2\": 0.900475466571789, \"f0_5\": 0.8313425704730053, \"p4\": 0.807409165874508, \"phi\": 0.6357547675887707}, {\"truth_threshold\": -8.14, \"match_probability\": 0.003532474091458984, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11121, \"tn\": 5447, \"fp\": 2602, \"fn\": 903, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9249001996007984, \"tn_rate\": 0.6767300285749782, \"fp_rate\": 0.32326997142502173, \"fn_rate\": 0.0750998003992016, \"precision\": 0.8103913138526562, \"recall\": 0.9249001996007984, \"specificity\": 0.6767300285749782, \"npv\": 0.8577952755905511, \"accuracy\": 0.8253873362227868, \"f1\": 0.8638676350642793, \"f2\": 0.8994807421666478, \"f0_5\": 0.8309671827365652, \"p4\": 0.8066723140927339, \"phi\": 0.6340356853290758}, {\"truth_threshold\": -8.120000000000001, \"match_probability\": 0.003581608977633939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11120, \"tn\": 5447, \"fp\": 2602, \"fn\": 904, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9248170326014638, \"tn_rate\": 0.6767300285749782, \"fp_rate\": 0.32326997142502173, \"fn_rate\": 0.07518296739853626, \"precision\": 0.810377495991838, \"recall\": 0.9248170326014638, \"specificity\": 0.6767300285749782, \"npv\": 0.8576602109903952, \"accuracy\": 0.8253375180590844, \"f1\": 0.8638235065641264, \"f2\": 0.8994144100423824, \"f0_5\": 0.8309421329507413, \"p4\": 0.8066232108163927, \"phi\": 0.6339212249090667}, {\"truth_threshold\": -8.1, \"match_probability\": 0.0036314248139807737, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11118, \"tn\": 5447, \"fp\": 2602, \"fn\": 906, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9246506986027944, \"tn_rate\": 0.6767300285749782, \"fp_rate\": 0.32326997142502173, \"fn_rate\": 0.0753493013972056, \"precision\": 0.8103498542274052, \"recall\": 0.9246506986027944, \"specificity\": 0.6767300285749782, \"npv\": 0.8573902093499134, \"accuracy\": 0.8252378817316793, \"f1\": 0.8637352392790553, \"f2\": 0.8992817393555067, \"f0_5\": 0.8308920243931603, \"p4\": 0.8065250118159206, \"phi\": 0.6336923583252839}, {\"truth_threshold\": -8.06, \"match_probability\": 0.0037331369336417713, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11117, \"tn\": 5447, \"fp\": 2602, \"fn\": 907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9245675316034597, \"tn_rate\": 0.6767300285749782, \"fp_rate\": 0.32326997142502173, \"fn_rate\": 0.07543246839654025, \"precision\": 0.8103360303229098, \"recall\": 0.9245675316034597, \"specificity\": 0.6767300285749782, \"npv\": 0.8572552722694365, \"accuracy\": 0.8251880635679769, \"f1\": 0.863691100493338, \"f2\": 0.8992154007926879, \"f0_5\": 0.8308669656203288, \"p4\": 0.8064759160902671, \"phi\": 0.6335779521456876}, {\"truth_threshold\": -8.040000000000001, \"match_probability\": 0.0037850523341144294, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11101, \"tn\": 5448, \"fp\": 2601, \"fn\": 923, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9232368596141052, \"tn_rate\": 0.6768542676108833, \"fp_rate\": 0.32314573238911665, \"fn_rate\": 0.07676314038589488, \"precision\": 0.8101736972704715, \"recall\": 0.9232368596141052, \"specificity\": 0.6768542676108833, \"npv\": 0.855124784178308, \"accuracy\": 0.8244407911124396, \"f1\": 0.8630179584855788, \"f2\": 0.8981682255089162, \"f0_5\": 0.8305153220014364, \"p4\": 0.8057544149539881, \"phi\": 0.6318541886176519}, {\"truth_threshold\": -8.02, \"match_probability\": 0.0038376869224252233, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11092, \"tn\": 5451, \"fp\": 2598, \"fn\": 932, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9224883566200931, \"tn_rate\": 0.6772269847185985, \"fp_rate\": 0.3227730152814014, \"fn_rate\": 0.07751164337990685, \"precision\": 0.8102264426588751, \"recall\": 0.9224883566200931, \"specificity\": 0.6772269847185985, \"npv\": 0.8539871533761554, \"accuracy\": 0.8241418821302247, \"f1\": 0.8627206968966322, \"f2\": 0.8976143462920403, \"f0_5\": 0.8304384283660757, \"p4\": 0.8055040114704586, \"phi\": 0.6311410963231188}, {\"truth_threshold\": -8.0, \"match_probability\": 0.0038910505836575876, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11080, \"tn\": 5451, \"fp\": 2598, \"fn\": 944, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9214903526280772, \"tn_rate\": 0.6772269847185985, \"fp_rate\": 0.3227730152814014, \"fn_rate\": 0.07850964737192283, \"precision\": 0.8100599502851294, \"recall\": 0.9214903526280772, \"specificity\": 0.6772269847185985, \"npv\": 0.8523846755277561, \"accuracy\": 0.8235440641657948, \"f1\": 0.8621897128628122, \"f2\": 0.896817431281769, \"f0_5\": 0.8301366578758091, \"p4\": 0.8049157622593281, \"phi\": 0.6297754222786927}, {\"truth_threshold\": -7.98, \"match_probability\": 0.003945153336582717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11076, \"tn\": 5452, \"fp\": 2597, \"fn\": 948, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9211576846307385, \"tn_rate\": 0.6773512237545036, \"fp_rate\": 0.3226487762454963, \"fn_rate\": 0.07884231536926148, \"precision\": 0.8100636290499524, \"recall\": 0.9211576846307385, \"specificity\": 0.6773512237545036, \"npv\": 0.851875, \"accuracy\": 0.8233946096746874, \"f1\": 0.8620461532474608, \"f2\": 0.8965662387281647, \"f0_5\": 0.8300857365549493, \"p4\": 0.8047833915724826, \"phi\": 0.6294252666446676}, {\"truth_threshold\": -7.96, \"match_probability\": 0.004000005335406395, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11074, \"tn\": 5455, \"fp\": 2594, \"fn\": 950, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9209913506320692, \"tn_rate\": 0.6777239408622189, \"fp_rate\": 0.32227605913778107, \"fn_rate\": 0.07900864936793081, \"precision\": 0.8102136376938835, \"recall\": 0.9209913506320692, \"specificity\": 0.6777239408622189, \"npv\": 0.8516783762685401, \"accuracy\": 0.8234444278383899, \"f1\": 0.8620582282422544, \"f2\": 0.8964769121170909, \"f0_5\": 0.8301847187237615, \"p4\": 0.804876247785509, \"phi\": 0.6295116123450416}, {\"truth_threshold\": -7.92, \"match_probability\": 0.004111998375374417, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11071, \"tn\": 5457, \"fp\": 2592, \"fn\": 953, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9207418496340652, \"tn_rate\": 0.677972418934029, \"fp_rate\": 0.3220275810659709, \"fn_rate\": 0.0792581503659348, \"precision\": 0.8102905657615458, \"recall\": 0.9207418496340652, \"specificity\": 0.677972418934029, \"npv\": 0.8513260530421217, \"accuracy\": 0.8233946096746874, \"f1\": 0.861992447541558, \"f2\": 0.8963066111821759, \"f0_5\": 0.8302087707720919, \"p4\": 0.8048564589346193, \"phi\": 0.629380099780358}, {\"truth_threshold\": -7.9, \"match_probability\": 0.00416916041812146, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11069, \"tn\": 5457, \"fp\": 2592, \"fn\": 955, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9205755156353959, \"tn_rate\": 0.677972418934029, \"fp_rate\": 0.3220275810659709, \"fn_rate\": 0.07942448436460413, \"precision\": 0.8102627918893199, \"recall\": 0.9205755156353959, \"specificity\": 0.677972418934029, \"npv\": 0.8510605115408609, \"accuracy\": 0.8232949733472824, \"f1\": 0.8619038349231068, \"f2\": 0.8961737131013489, \"f0_5\": 0.8301583968320634, \"p4\": 0.8047584850873285, \"phi\": 0.6291531588975484}, {\"truth_threshold\": -7.88, \"match_probability\": 0.004227113713615665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11061, \"tn\": 5458, \"fp\": 2591, \"fn\": 963, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9199101796407185, \"tn_rate\": 0.6780966579699341, \"fp_rate\": 0.3219033420300658, \"fn_rate\": 0.08008982035928144, \"precision\": 0.8102109581013771, \"recall\": 0.9199101796407185, \"specificity\": 0.6780966579699341, \"npv\": 0.8500233608472201, \"accuracy\": 0.822946246201365, \"f1\": 0.861582801059355, \"f2\": 0.8956565394830602, \"f0_5\": 0.8300066034337855, \"p4\": 0.8044302591954081, \"phi\": 0.6283507278236204}, {\"truth_threshold\": -7.86, \"match_probability\": 0.004285869120183992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11060, \"tn\": 5458, \"fp\": 2591, \"fn\": 964, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9198270126413839, \"tn_rate\": 0.6780966579699341, \"fp_rate\": 0.3219033420300658, \"fn_rate\": 0.0801729873586161, \"precision\": 0.8101970551607941, \"recall\": 0.9198270126413839, \"specificity\": 0.6780966579699341, \"npv\": 0.8498909996885705, \"accuracy\": 0.8228964280376625, \"f1\": 0.8615384615384616, \"f2\": 0.8955900691531572, \"f0_5\": 0.8299813892057394, \"p4\": 0.8043812947557628, \"phi\": 0.6282374333659346}, {\"truth_threshold\": -7.84, \"match_probability\": 0.00434543764251929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11056, \"tn\": 5461, \"fp\": 2588, \"fn\": 968, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9194943446440452, \"tn_rate\": 0.6784693750776494, \"fp_rate\": 0.3215306249223506, \"fn_rate\": 0.08050565535595476, \"precision\": 0.810319554382879, \"recall\": 0.9194943446440452, \"specificity\": 0.6784693750776494, \"npv\": 0.8494322600715508, \"accuracy\": 0.8228466098739601, \"f1\": 0.861461742247156, \"f2\": 0.8953676708778749, \"f0_5\": 0.8300300300300301, \"p4\": 0.8043761114128458, \"phi\": 0.6280984389920963}, {\"truth_threshold\": -7.82, \"match_probability\": 0.004405830433579104, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11055, \"tn\": 5461, \"fp\": 2588, \"fn\": 969, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9194111776447106, \"tn_rate\": 0.6784693750776494, \"fp_rate\": 0.3215306249223506, \"fn_rate\": 0.08058882235528943, \"precision\": 0.8103056512497251, \"recall\": 0.9194111776447106, \"specificity\": 0.6784693750776494, \"npv\": 0.8493001555209954, \"accuracy\": 0.8227967917102575, \"f1\": 0.8614173841898157, \"f2\": 0.8953011872560294, \"f0_5\": 0.830004805093399, \"p4\": 0.8043271563317899, \"phi\": 0.6279852580522544}, {\"truth_threshold\": -7.8, \"match_probability\": 0.00446705879650708, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11051, \"tn\": 5462, \"fp\": 2587, \"fn\": 973, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9190785096473719, \"tn_rate\": 0.6785936141135545, \"fp_rate\": 0.32140638588644554, \"fn_rate\": 0.08092149035262808, \"precision\": 0.8103094295351224, \"recall\": 0.9190785096473719, \"specificity\": 0.6785936141135545, \"npv\": 0.8487956487956488, \"accuracy\": 0.8226473372191501, \"f1\": 0.8612734782947549, \"f2\": 0.8950497294845629, \"f0_5\": 0.8299537370824321, \"p4\": 0.8041948898340533, \"phi\": 0.6276374207674076}, {\"truth_threshold\": -7.78, \"match_probability\": 0.004529134186577057, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11051, \"tn\": 5468, \"fp\": 2581, \"fn\": 973, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9190785096473719, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.08092149035262808, \"precision\": 0.8106660798122066, \"recall\": 0.9190785096473719, \"specificity\": 0.679339048328985, \"npv\": 0.8489365005433939, \"accuracy\": 0.822946246201365, \"f1\": 0.861474898659183, \"f2\": 0.8951367288750648, \"f0_5\": 0.8302530352205794, \"p4\": 0.8045759001156789, \"phi\": 0.6282656805614183}, {\"truth_threshold\": -7.76, \"match_probability\": 0.004592068213160174, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11047, \"tn\": 5468, \"fp\": 2581, \"fn\": 977, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9187458416500333, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.08125415834996673, \"precision\": 0.810610507778104, \"recall\": 0.9187458416500333, \"specificity\": 0.679339048328985, \"npv\": 0.8484096198603569, \"accuracy\": 0.8227469735465551, \"f1\": 0.8612973647278964, \"f2\": 0.8948707147948934, \"f0_5\": 0.8301520981123001, \"p4\": 0.8043801160178405, \"phi\": 0.6278136511199859}, {\"truth_threshold\": -7.74, \"match_probability\": 0.004655872641715067, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11044, \"tn\": 5468, \"fp\": 2581, \"fn\": 980, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9184963406520292, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.08150365934797073, \"precision\": 0.8105688073394496, \"recall\": 0.9184963406520292, \"specificity\": 0.679339048328985, \"npv\": 0.848014888337469, \"accuracy\": 0.8225975190554476, \"f1\": 0.8611641779406605, \"f2\": 0.8946711816075565, \"f0_5\": 0.830076363417714, \"p4\": 0.8042333036793966, \"phi\": 0.6274748121491129}, {\"truth_threshold\": -7.68, \"match_probability\": 0.0048526283775603, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11040, \"tn\": 5468, \"fp\": 2581, \"fn\": 984, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9181636726546906, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.08183632734530938, \"precision\": 0.8105131781807503, \"recall\": 0.9181636726546906, \"specificity\": 0.679339048328985, \"npv\": 0.847489150650961, \"accuracy\": 0.8223982464006376, \"f1\": 0.8609865470852018, \"f2\": 0.894405107182786, \"f0_5\": 0.8299753413123233, \"p4\": 0.8040375881690702, \"phi\": 0.6270232706132547}, {\"truth_threshold\": -7.66, \"match_probability\": 0.004920035261311362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11038, \"tn\": 5468, \"fp\": 2581, \"fn\": 986, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9179973386560213, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.08200266134397871, \"precision\": 0.8104853513473823, \"recall\": 0.9179973386560213, \"specificity\": 0.679339048328985, \"npv\": 0.8472265261853115, \"accuracy\": 0.8222986100732327, \"f1\": 0.8608977108762625, \"f2\": 0.8942720570363769, \"f0_5\": 0.8299248120300752, \"p4\": 0.8039397450892097, \"phi\": 0.6267976041773806}, {\"truth_threshold\": -7.640000000000001, \"match_probability\": 0.004988373786945367, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11035, \"tn\": 5468, \"fp\": 2581, \"fn\": 989, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9177478376580173, \"tn_rate\": 0.679339048328985, \"fp_rate\": 0.32066095167101505, \"fn_rate\": 0.0822521623419827, \"precision\": 0.8104435957696827, \"recall\": 0.9177478376580173, \"specificity\": 0.679339048328985, \"npv\": 0.8468328945330649, \"accuracy\": 0.8221491555821252, \"f1\": 0.8607644305772231, \"f2\": 0.8940724656468758, \"f0_5\": 0.8298489953074238, \"p4\": 0.8037929987964628, \"phi\": 0.6264592347689781}, {\"truth_threshold\": -7.62, \"match_probability\": 0.005057656699563808, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11030, \"tn\": 5469, \"fp\": 2580, \"fn\": 994, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.917332002661344, \"tn_rate\": 0.67946328736489, \"fp_rate\": 0.32053671263510997, \"fn_rate\": 0.08266799733865603, \"precision\": 0.8104335047759, \"recall\": 0.917332002661344, \"specificity\": 0.67946328736489, \"npv\": 0.8462014544329259, \"accuracy\": 0.8219498829273153, \"f1\": 0.8605757977685886, \"f2\": 0.893754254043367, \"f0_5\": 0.8297725084256139, \"p4\": 0.8036119238723294, \"phi\": 0.6260005199058509}, {\"truth_threshold\": -7.6000000000000005, \"match_probability\": 0.005127896914953068, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11026, \"tn\": 5944, \"fp\": 2105, \"fn\": 998, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9169993346640053, \"tn_rate\": 0.7384768294198037, \"fp_rate\": 0.2615231705801963, \"fn_rate\": 0.08300066533599468, \"precision\": 0.8396923311248191, \"recall\": 0.9169993346640053, \"specificity\": 0.7384768294198037, \"npv\": 0.8562373955632383, \"accuracy\": 0.8454142380311862, \"f1\": 0.8766448022261976, \"f2\": 0.9004197494569389, \"f0_5\": 0.8540930780194584, \"p4\": 0.8327322477701825, \"phi\": 0.675400138970508}, {\"truth_threshold\": -7.58, \"match_probability\": 0.005199107521767358, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11022, \"tn\": 5944, \"fp\": 2105, \"fn\": 1002, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9166666666666666, \"tn_rate\": 0.7384768294198037, \"fp_rate\": 0.2615231705801963, \"fn_rate\": 0.08333333333333333, \"precision\": 0.8396434828978442, \"recall\": 0.9166666666666666, \"specificity\": 0.7384768294198037, \"npv\": 0.8557443132738267, \"accuracy\": 0.8452149653763762, \"f1\": 0.8764661444872968, \"f2\": 0.9001519036963233, \"f0_5\": 0.8539949172503564, \"p4\": 0.8325350116268441, \"phi\": 0.6749657709245516}, {\"truth_threshold\": -7.5600000000000005, \"match_probability\": 0.0052713017837366085, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11019, \"tn\": 5944, \"fp\": 2105, \"fn\": 1005, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9164171656686627, \"tn_rate\": 0.7384768294198037, \"fp_rate\": 0.2615231705801963, \"fn_rate\": 0.08358283433133733, \"precision\": 0.8396068271868333, \"recall\": 0.9164171656686627, \"specificity\": 0.7384768294198037, \"npv\": 0.8553748740826018, \"accuracy\": 0.8450655108852688, \"f1\": 0.8763321138857961, \"f2\": 0.8999509964064031, \"f0_5\": 0.8539212647241166, \"p4\": 0.8323871074438416, \"phi\": 0.6746401580529574}, {\"truth_threshold\": -7.5200000000000005, \"match_probability\": 0.005418695216862511, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11016, \"tn\": 5951, \"fp\": 2098, \"fn\": 1008, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9161676646706587, \"tn_rate\": 0.7393465026711393, \"fp_rate\": 0.26065349732886073, \"fn_rate\": 0.08383233532934131, \"precision\": 0.8400183010523105, \"recall\": 0.9161676646706587, \"specificity\": 0.7393465026711393, \"npv\": 0.8551516022417014, \"accuracy\": 0.8452647835400787, \"f1\": 0.8764420399395337, \"f2\": 0.8998529652017644, \"f0_5\": 0.8542183622828784, \"p4\": 0.8326598139440249, \"phi\": 0.6750509020206198}, {\"truth_threshold\": -7.5, \"match_probability\": 0.005493921811082985, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11015, \"tn\": 5954, \"fp\": 2095, \"fn\": 1009, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.916084497671324, \"tn_rate\": 0.7397192197788545, \"fp_rate\": 0.2602807802211455, \"fn_rate\": 0.08391550232867598, \"precision\": 0.8401983218916858, \"recall\": 0.916084497671324, \"specificity\": 0.7397192197788545, \"npv\": 0.8550911963234238, \"accuracy\": 0.8453644198674837, \"f1\": 0.8765019495504098, \"f2\": 0.8998300820181028, \"f0_5\": 0.8543528170761976, \"p4\": 0.8327906753078497, \"phi\": 0.6752580623358839}, {\"truth_threshold\": -7.48, \"match_probability\": 0.005570186911180121, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11015, \"tn\": 5955, \"fp\": 2094, \"fn\": 1009, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.916084497671324, \"tn_rate\": 0.7398434588147595, \"fp_rate\": 0.2601565411852404, \"fn_rate\": 0.08391550232867598, \"precision\": 0.8402624151346403, \"recall\": 0.916084497671324, \"specificity\": 0.7398434588147595, \"npv\": 0.8551120045950603, \"accuracy\": 0.8454142380311862, \"f1\": 0.8765368240958102, \"f2\": 0.8998447839228821, \"f0_5\": 0.854405833074775, \"p4\": 0.8328507153216302, \"phi\": 0.6753632519807388}, {\"truth_threshold\": -7.46, \"match_probability\": 0.00564750469027039, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11011, \"tn\": 5959, \"fp\": 2090, \"fn\": 1013, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9157518296739854, \"tn_rate\": 0.7403404149583799, \"fp_rate\": 0.25965958504162007, \"fn_rate\": 0.08424817032601464, \"precision\": 0.8404701931150294, \"recall\": 0.9157518296739854, \"specificity\": 0.7403404149583799, \"npv\": 0.8547045324153758, \"accuracy\": 0.8454142380311862, \"f1\": 0.8764975124378109, \"f2\": 0.8996356030524372, \"f0_5\": 0.8545197740112994, \"p4\": 0.8328936255641595, \"phi\": 0.6753508318532908}, {\"truth_threshold\": -7.44, \"match_probability\": 0.005725889510329732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11001, \"tn\": 5959, \"fp\": 2090, \"fn\": 1023, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9149201596806387, \"tn_rate\": 0.7403404149583799, \"fp_rate\": 0.25965958504162007, \"fn_rate\": 0.08507984031936128, \"precision\": 0.8403483309143687, \"recall\": 0.9149201596806387, \"specificity\": 0.7403404149583799, \"npv\": 0.8534803781151532, \"accuracy\": 0.8449160563941613, \"f1\": 0.8760501692215807, \"f2\": 0.8989654665206661, \"f0_5\": 0.8542740883394422, \"p4\": 0.832400808090207, \"phi\": 0.6742689363894299}, {\"truth_threshold\": -7.42, \"match_probability\": 0.005805355924582104, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10996, \"tn\": 5959, \"fp\": 2090, \"fn\": 1028, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9145043246839654, \"tn_rate\": 0.7403404149583799, \"fp_rate\": 0.25965958504162007, \"fn_rate\": 0.0854956753160346, \"precision\": 0.8402873299709613, \"recall\": 0.9145043246839654, \"specificity\": 0.7403404149583799, \"npv\": 0.8528696149992844, \"accuracy\": 0.8446669655756489, \"f1\": 0.875826363998407, \"f2\": 0.8986303161060443, \"f0_5\": 0.8541511309967685, \"p4\": 0.8321544804028047, \"phi\": 0.6737285648985978}, {\"truth_threshold\": -7.4, \"match_probability\": 0.005885918679914525, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10995, \"tn\": 5962, \"fp\": 2087, \"fn\": 1029, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9144211576846307, \"tn_rate\": 0.7407131320660951, \"fp_rate\": 0.2592868679339048, \"fn_rate\": 0.08557884231536926, \"precision\": 0.8404678183763951, \"recall\": 0.9144211576846307, \"specificity\": 0.7407131320660951, \"npv\": 0.8528107566871692, \"accuracy\": 0.8447666019030539, \"f1\": 0.8758862423325101, \"f2\": 0.898607342508745, \"f0_5\": 0.8542858030830432, \"p4\": 0.8322851820871855, \"phi\": 0.673936619329788}, {\"truth_threshold\": -7.38, \"match_probability\": 0.005967592719318969, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10989, \"tn\": 5962, \"fp\": 2087, \"fn\": 1035, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9139221556886228, \"tn_rate\": 0.7407131320660951, \"fp_rate\": 0.2592868679339048, \"fn_rate\": 0.08607784431137724, \"precision\": 0.8403946160905476, \"recall\": 0.9139221556886228, \"specificity\": 0.7407131320660951, \"npv\": 0.8520794626268401, \"accuracy\": 0.8444676929208389, \"f1\": 0.8756175298804781, \"f2\": 0.8982050611390833, \"f0_5\": 0.8541381668946648, \"p4\": 0.8319896585853878, \"phi\": 0.6732889185066395}, {\"truth_threshold\": -7.36, \"match_probability\": 0.006050393184361143, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10988, \"tn\": 5962, \"fp\": 2087, \"fn\": 1036, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9138389886892881, \"tn_rate\": 0.7407131320660951, \"fp_rate\": 0.2592868679339048, \"fn_rate\": 0.08616101131071191, \"precision\": 0.8403824091778203, \"recall\": 0.9138389886892881, \"specificity\": 0.7407131320660951, \"npv\": 0.8519577022006287, \"accuracy\": 0.8444178747571365, \"f1\": 0.8755727319813539, \"f2\": 0.8981380065717415, \"f0_5\": 0.8541135501523537, \"p4\": 0.8319404121969997, \"phi\": 0.6731810218557726}, {\"truth_threshold\": -7.34, \"match_probability\": 0.0061343354176764545, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10986, \"tn\": 5962, \"fp\": 2087, \"fn\": 1038, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9136726546906188, \"tn_rate\": 0.7407131320660951, \"fp_rate\": 0.2592868679339048, \"fn_rate\": 0.08632734530938124, \"precision\": 0.8403579897498661, \"recall\": 0.9136726546906188, \"specificity\": 0.7407131320660951, \"npv\": 0.8517142857142858, \"accuracy\": 0.8443182384297315, \"f1\": 0.8754831254731641, \"f2\": 0.8980038908597492, \"f0_5\": 0.8540643074818086, \"p4\": 0.8318419258666943, \"phi\": 0.6729652743434228}, {\"truth_threshold\": -7.3, \"match_probability\": 0.00630570758018367, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10979, \"tn\": 5964, \"fp\": 2085, \"fn\": 1045, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9130904856952761, \"tn_rate\": 0.7409616101379053, \"fp_rate\": 0.25903838986209465, \"fn_rate\": 0.08690951430472389, \"precision\": 0.8404011022657685, \"recall\": 0.9130904856952761, \"specificity\": 0.7409616101379053, \"npv\": 0.8509059780282494, \"accuracy\": 0.8440691476112191, \"f1\": 0.8752391581632653, \"f2\": 0.8975637671680837, \"f0_5\": 0.8539981331673927, \"p4\": 0.8316172086231732, \"phi\": 0.6724216272032153}, {\"truth_threshold\": -7.28, \"match_probability\": 0.006393169222841944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10977, \"tn\": 5965, \"fp\": 2084, \"fn\": 1047, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9129241516966068, \"tn_rate\": 0.7410858491738104, \"fp_rate\": 0.25891415082618957, \"fn_rate\": 0.08707584830339321, \"precision\": 0.8404410075798178, \"recall\": 0.9129241516966068, \"specificity\": 0.7410858491738104, \"npv\": 0.8506845407872219, \"accuracy\": 0.8440193294475166, \"f1\": 0.8751843731313534, \"f2\": 0.8974442827476822, \"f0_5\": 0.8540019916599241, \"p4\": 0.8315787054637638, \"phi\": 0.672311698908397}, {\"truth_threshold\": -7.22, \"match_probability\": 0.006662851115328145, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10972, \"tn\": 5965, \"fp\": 2084, \"fn\": 1052, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9125083166999335, \"tn_rate\": 0.7410858491738104, \"fp_rate\": 0.25891415082618957, \"fn_rate\": 0.08749168330006653, \"precision\": 0.8403799019607843, \"recall\": 0.9125083166999335, \"specificity\": 0.7410858491738104, \"npv\": 0.8500783810745333, \"accuracy\": 0.8437702386290041, \"f1\": 0.8749601275917065, \"f2\": 0.8971088435374149, \"f0_5\": 0.8538787199601544, \"p4\": 0.8313326115441456, \"phi\": 0.6717734034412838}, {\"truth_threshold\": -7.2, \"match_probability\": 0.006755232747054526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10972, \"tn\": 5966, \"fp\": 2083, \"fn\": 1052, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9125083166999335, \"tn_rate\": 0.7412100882097155, \"fp_rate\": 0.2587899117902845, \"fn_rate\": 0.08749168330006653, \"precision\": 0.8404442742244351, \"recall\": 0.9125083166999335, \"specificity\": 0.7412100882097155, \"npv\": 0.8500997435166714, \"accuracy\": 0.8438200567927067, \"f1\": 0.8749950157502293, \"f2\": 0.8971235139245475, \"f0_5\": 0.8539318846896208, \"p4\": 0.8313925491212929, \"phi\": 0.6718789576981977}, {\"truth_threshold\": -7.18, \"match_probability\": 0.006848886435257802, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10970, \"tn\": 5969, \"fp\": 2080, \"fn\": 1054, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9123419827012641, \"tn_rate\": 0.7415828053174307, \"fp_rate\": 0.25841719468256924, \"fn_rate\": 0.08765801729873586, \"precision\": 0.8406130268199233, \"recall\": 0.9123419827012641, \"specificity\": 0.7415828053174307, \"npv\": 0.8499216858892211, \"accuracy\": 0.8438698749564091, \"f1\": 0.8750099704873574, \"f2\": 0.8970333300624734, \"f0_5\": 0.8540421026407573, \"p4\": 0.8314738957837403, \"phi\": 0.6719804800943832}, {\"truth_threshold\": -7.16, \"match_probability\": 0.006943829449084327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10962, \"tn\": 5969, \"fp\": 2080, \"fn\": 1062, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9116766467065869, \"tn_rate\": 0.7415828053174307, \"fp_rate\": 0.25841719468256924, \"fn_rate\": 0.08832335329341318, \"precision\": 0.8405152583959515, \"recall\": 0.9116766467065869, \"specificity\": 0.7415828053174307, \"npv\": 0.8489546294979377, \"accuracy\": 0.8434713296467892, \"f1\": 0.8746509215670629, \"f2\": 0.896496450652622, \"f0_5\": 0.8538447158524427, \"p4\": 0.8310802648015813, \"phi\": 0.6711204967460187}, {\"truth_threshold\": -7.12, \"match_probability\": 0.0071376536708013, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10959, \"tn\": 5969, \"fp\": 2080, \"fn\": 1065, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9114271457085829, \"tn_rate\": 0.7415828053174307, \"fp_rate\": 0.25841719468256924, \"fn_rate\": 0.08857285429141716, \"precision\": 0.8404785643070788, \"recall\": 0.9114271457085829, \"specificity\": 0.7415828053174307, \"npv\": 0.8485925504691498, \"accuracy\": 0.8433218751556818, \"f1\": 0.874516219127798, \"f2\": 0.8962950846487282, \"f0_5\": 0.8537706450607666, \"p4\": 0.8309326882908549, \"phi\": 0.670798252020282}, {\"truth_threshold\": -7.1000000000000005, \"match_probability\": 0.007236570566039904, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10953, \"tn\": 5976, \"fp\": 2073, \"fn\": 1071, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9109281437125748, \"tn_rate\": 0.7424524785687663, \"fp_rate\": 0.2575475214312337, \"fn_rate\": 0.08907185628742514, \"precision\": 0.8408567480423768, \"recall\": 0.9109281437125748, \"specificity\": 0.7424524785687663, \"npv\": 0.8480204342273308, \"accuracy\": 0.8433716933193842, \"f1\": 0.8744910179640718, \"f2\": 0.8959948954549917, \"f0_5\": 0.8539951347305389, \"p4\": 0.8310567463557811, \"phi\": 0.6708941809456976}, {\"truth_threshold\": -7.08, \"match_probability\": 0.007336848167297341, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10951, \"tn\": 5976, \"fp\": 2073, \"fn\": 1073, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9107618097139055, \"tn_rate\": 0.7424524785687663, \"fp_rate\": 0.2575475214312337, \"fn_rate\": 0.08923819028609448, \"precision\": 0.8408323095823096, \"recall\": 0.9107618097139055, \"specificity\": 0.7424524785687663, \"npv\": 0.8477798269258051, \"accuracy\": 0.8432720569919793, \"f1\": 0.8744011497923986, \"f2\": 0.8958606020942408, \"f0_5\": 0.8539457267623206, \"p4\": 0.8309583867182421, \"phi\": 0.6706797198752608}, {\"truth_threshold\": -7.0600000000000005, \"match_probability\": 0.007438504909873419, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10950, \"tn\": 5976, \"fp\": 2073, \"fn\": 1074, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9106786427145709, \"tn_rate\": 0.7424524785687663, \"fp_rate\": 0.2575475214312337, \"fn_rate\": 0.08932135728542914, \"precision\": 0.8408200875374338, \"recall\": 0.9106786427145709, \"specificity\": 0.7424524785687663, \"npv\": 0.8476595744680852, \"accuracy\": 0.8432222388282767, \"f1\": 0.8743562103245898, \"f2\": 0.8957934521179993, \"f0_5\": 0.8539210181545948, \"p4\": 0.8309092100722771, \"phi\": 0.6705725118333121}, {\"truth_threshold\": -7.04, \"match_probability\": 0.0075415594709504815, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10949, \"tn\": 5976, \"fp\": 2073, \"fn\": 1075, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9105954757152362, \"tn_rate\": 0.7424524785687663, \"fp_rate\": 0.2575475214312337, \"fn_rate\": 0.08940452428476381, \"precision\": 0.84080786361542, \"recall\": 0.9105954757152362, \"specificity\": 0.7424524785687663, \"npv\": 0.8475393561196993, \"accuracy\": 0.8431724206645743, \"f1\": 0.8743112672682265, \"f2\": 0.8957262999443699, \"f0_5\": 0.8538963064636885, \"p4\": 0.8308600355405382, \"phi\": 0.6704653187787571}, {\"truth_threshold\": -7.0, \"match_probability\": 0.007751937984496124, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10942, \"tn\": 5976, \"fp\": 2073, \"fn\": 1082, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9100133067198936, \"tn_rate\": 0.7424524785687663, \"fp_rate\": 0.2575475214312337, \"fn_rate\": 0.08998669328010646, \"precision\": 0.8407222435651172, \"recall\": 0.9100133067198936, \"specificity\": 0.7424524785687663, \"npv\": 0.8466987815245112, \"accuracy\": 0.8428236935186569, \"f1\": 0.8739965653580415, \"f2\": 0.8952561731930422, \"f0_5\": 0.8537232382497971, \"p4\": 0.8305158729551397, \"phi\": 0.6697153865329958}, {\"truth_threshold\": -6.98, \"match_probability\": 0.007859300527466294, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10940, \"tn\": 5982, \"fp\": 2067, \"fn\": 1084, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9098469727212242, \"tn_rate\": 0.7431979127841968, \"fp_rate\": 0.2568020872158032, \"fn_rate\": 0.09015302727877578, \"precision\": 0.8410855693088337, \"recall\": 0.9098469727212242, \"specificity\": 0.7431979127841968, \"npv\": 0.8465893008774412, \"accuracy\": 0.8430229661734668, \"f1\": 0.8741160960409092, \"f2\": 0.8952097278366038, \"f0_5\": 0.8539936301754825, \"p4\": 0.8307765317513236, \"phi\": 0.6701362226187682}, {\"truth_threshold\": -6.96, \"match_probability\": 0.007968138075995553, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10938, \"tn\": 5983, \"fp\": 2066, \"fn\": 1086, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9096806387225549, \"tn_rate\": 0.7433221518201019, \"fp_rate\": 0.25667784817989814, \"fn_rate\": 0.09031936127744511, \"precision\": 0.8411258074438634, \"recall\": 0.9096806387225549, \"specificity\": 0.7433221518201019, \"npv\": 0.8463714811147263, \"accuracy\": 0.8429731480097643, \"f1\": 0.8740610516221832, \"f2\": 0.8950900163666121, \"f0_5\": 0.8539975015615241, \"p4\": 0.8307380228258419, \"phi\": 0.670028094873095}, {\"truth_threshold\": -6.94, \"match_probability\": 0.008078470561568152, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10936, \"tn\": 5983, \"fp\": 2066, \"fn\": 1088, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9095143047238856, \"tn_rate\": 0.7433221518201019, \"fp_rate\": 0.25667784817989814, \"fn_rate\": 0.09048569527611444, \"precision\": 0.8411013690201508, \"recall\": 0.9095143047238856, \"specificity\": 0.7433221518201019, \"npv\": 0.8461320888134635, \"accuracy\": 0.8428735116823594, \"f1\": 0.8739710700871094, \"f2\": 0.8949556450292971, \"f0_5\": 0.8539480259870065, \"p4\": 0.8306397150530026, \"phi\": 0.6698141947066877}, {\"truth_threshold\": -6.92, \"match_probability\": 0.008190318175716487, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10932, \"tn\": 5983, \"fp\": 2066, \"fn\": 1092, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.909181636726547, \"tn_rate\": 0.7433221518201019, \"fp_rate\": 0.25667784817989814, \"fn_rate\": 0.09081836327345309, \"precision\": 0.8410524696107093, \"recall\": 0.909181636726547, \"specificity\": 0.7433221518201019, \"npv\": 0.8456537102473498, \"accuracy\": 0.8426742390275495, \"f1\": 0.8737910638637999, \"f2\": 0.8946868759616329, \"f0_5\": 0.8538490377405649, \"p4\": 0.8304431247072892, \"phi\": 0.669386572897739}, {\"truth_threshold\": -6.9, \"match_probability\": 0.008303701373154063, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10927, \"tn\": 5983, \"fp\": 2066, \"fn\": 1097, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9087658017298735, \"tn_rate\": 0.7433221518201019, \"fp_rate\": 0.25667784817989814, \"fn_rate\": 0.09123419827012641, \"precision\": 0.8409913030093127, \"recall\": 0.9087658017298735, \"specificity\": 0.7433221518201019, \"npv\": 0.8450564971751412, \"accuracy\": 0.842425148209037, \"f1\": 0.8735659751369069, \"f2\": 0.894350865131202, \"f0_5\": 0.8537252328270517, \"p4\": 0.8301974339646352, \"phi\": 0.6688523798714804}, {\"truth_threshold\": -6.88, \"match_probability\": 0.008418640874938868, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10914, \"tn\": 5983, \"fp\": 2066, \"fn\": 1110, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9076846307385229, \"tn_rate\": 0.7433221518201019, \"fp_rate\": 0.25667784817989814, \"fn_rate\": 0.09231536926147704, \"precision\": 0.8408320493066256, \"recall\": 0.9076846307385229, \"specificity\": 0.7433221518201019, \"npv\": 0.8435076836317497, \"accuracy\": 0.8417775120809047, \"f1\": 0.8729803231482963, \"f2\": 0.8934769795009496, \"f0_5\": 0.8534029776054047, \"p4\": 0.8295588827903512, \"phi\": 0.667465210866634}, {\"truth_threshold\": -6.86, \"match_probability\": 0.008535157671667086, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10912, \"tn\": 5984, \"fp\": 2065, \"fn\": 1112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9075182967398536, \"tn_rate\": 0.743446390856007, \"fp_rate\": 0.25655360914399306, \"fn_rate\": 0.09248170326014638, \"precision\": 0.8408723125529783, \"recall\": 0.9075182967398536, \"specificity\": 0.743446390856007, \"npv\": 0.8432919954904171, \"accuracy\": 0.8417276939172023, \"f1\": 0.8729250829966801, \"f2\": 0.8933571299919768, \"f0_5\": 0.8534067446662078, \"p4\": 0.8295204536104602, \"phi\": 0.6673580785827854}, {\"truth_threshold\": -6.84, \"match_probability\": 0.008653273026697373, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10910, \"tn\": 5986, \"fp\": 2063, \"fn\": 1114, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9073519627411843, \"tn_rate\": 0.7436948689278171, \"fp_rate\": 0.2563051310721829, \"fn_rate\": 0.09264803725881571, \"precision\": 0.8409774146303862, \"recall\": 0.9073519627411843, \"specificity\": 0.7436948689278171, \"npv\": 0.8430985915492958, \"accuracy\": 0.8417276939172023, \"f1\": 0.8729047485698284, \"f2\": 0.8932518953970099, \"f0_5\": 0.8534639213968334, \"p4\": 0.8295417876693443, \"phi\": 0.6673571131291448}, {\"truth_threshold\": -6.82, \"match_probability\": 0.008773008479405596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10908, \"tn\": 5986, \"fp\": 2063, \"fn\": 1116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.907185628742515, \"tn_rate\": 0.7436948689278171, \"fp_rate\": 0.2563051310721829, \"fn_rate\": 0.09281437125748503, \"precision\": 0.8409528949194357, \"recall\": 0.907185628742515, \"specificity\": 0.7436948689278171, \"npv\": 0.8428611658687694, \"accuracy\": 0.8416280575897972, \"f1\": 0.8728145629125825, \"f2\": 0.8931173956474037, \"f0_5\": 0.8534142830318583, \"p4\": 0.8294435920156774, \"phi\": 0.667144089533736}, {\"truth_threshold\": -6.8, \"match_probability\": 0.008894385848470222, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10900, \"tn\": 5986, \"fp\": 2063, \"fn\": 1124, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9065202927478376, \"tn_rate\": 0.7436948689278171, \"fp_rate\": 0.2563051310721829, \"fn_rate\": 0.09347970725216234, \"precision\": 0.8408547404150274, \"recall\": 0.9065202927478376, \"specificity\": 0.7436948689278171, \"npv\": 0.8419127988748242, \"accuracy\": 0.8412295122801774, \"f1\": 0.8724536759114739, \"f2\": 0.8925793085376439, \"f0_5\": 0.8532156052351431, \"p4\": 0.8290508924815309, \"phi\": 0.6662925828389806}, {\"truth_threshold\": -6.78, \"match_probability\": 0.009017427235188254, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10900, \"tn\": 5990, \"fp\": 2059, \"fn\": 1124, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9065202927478376, \"tn_rate\": 0.7441918250714374, \"fp_rate\": 0.25580817492856256, \"fn_rate\": 0.09347970725216234, \"precision\": 0.8411142835095301, \"recall\": 0.9065202927478376, \"specificity\": 0.7441918250714374, \"npv\": 0.8420016868147315, \"accuracy\": 0.8414287849349873, \"f1\": 0.8725933634871713, \"f2\": 0.8926377856031447, \"f0_5\": 0.8534293767616662, \"p4\": 0.8292898557043145, \"phi\": 0.6667172112416697}, {\"truth_threshold\": -6.76, \"match_probability\": 0.009142155026821896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10899, \"tn\": 5990, \"fp\": 2059, \"fn\": 1125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.906437125748503, \"tn_rate\": 0.7441918250714374, \"fp_rate\": 0.25580817492856256, \"fn_rate\": 0.09356287425149701, \"precision\": 0.8411020219169625, \"recall\": 0.906437125748503, \"specificity\": 0.7441918250714374, \"npv\": 0.8418833450456782, \"accuracy\": 0.8413789667712848, \"f1\": 0.8725482347290049, \"f2\": 0.8925705113506076, \"f0_5\": 0.8534045352042094, \"p4\": 0.829240774267524, \"phi\": 0.6666108705476343}, {\"truth_threshold\": -6.74, \"match_probability\": 0.009268591899975812, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10894, \"tn\": 5990, \"fp\": 2059, \"fn\": 1130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9060212907518297, \"tn_rate\": 0.7441918250714374, \"fp_rate\": 0.25580817492856256, \"fn_rate\": 0.09397870924817033, \"precision\": 0.8410406855554697, \"recall\": 0.9060212907518297, \"specificity\": 0.7441918250714374, \"npv\": 0.8412921348314607, \"accuracy\": 0.8411298759527723, \"f1\": 0.8723225367337951, \"f2\": 0.8922341070287801, \"f0_5\": 0.8532802807193434, \"p4\": 0.8289953981174485, \"phi\": 0.6660793865390698}, {\"truth_threshold\": -6.72, \"match_probability\": 0.009396760824005125, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10892, \"tn\": 5990, \"fp\": 2059, \"fn\": 1132, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9058549567531603, \"tn_rate\": 0.7441918250714374, \"fp_rate\": 0.25580817492856256, \"fn_rate\": 0.09414504324683966, \"precision\": 0.8410161377499807, \"recall\": 0.9058549567531603, \"specificity\": 0.7441918250714374, \"npv\": 0.8410558831788824, \"accuracy\": 0.8410302396253674, \"f1\": 0.8722322322322322, \"f2\": 0.8920995298704277, \"f0_5\": 0.8532305571222661, \"p4\": 0.8288972621262126, \"phi\": 0.6658668952406382}, {\"truth_threshold\": -6.7, \"match_probability\": 0.00952668506445404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10887, \"tn\": 5991, \"fp\": 2058, \"fn\": 1137, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.905439121756487, \"tn_rate\": 0.7443160641073425, \"fp_rate\": 0.2556839358926575, \"fn_rate\": 0.09456087824351297, \"precision\": 0.8410196987253766, \"recall\": 0.905439121756487, \"specificity\": 0.7443160641073425, \"npv\": 0.8404882154882155, \"accuracy\": 0.8408309669705575, \"f1\": 0.8720413312507509, \"f2\": 0.8917776576399469, \"f0_5\": 0.8531596765093098, \"p4\": 0.8287116730400923, \"phi\": 0.6654421849173099}, {\"truth_threshold\": -6.68, \"match_probability\": 0.009658388186525174, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10883, \"tn\": 5992, \"fp\": 2057, \"fn\": 1141, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9051064537591483, \"tn_rate\": 0.7444403031432476, \"fp_rate\": 0.2555596968567524, \"fn_rate\": 0.09489354624085163, \"precision\": 0.8410355486862442, \"recall\": 0.9051064537591483, \"specificity\": 0.7444403031432476, \"npv\": 0.8400392541707556, \"accuracy\": 0.84068151247945, \"f1\": 0.8718955295625701, \"f2\": 0.891523035585556, \"f0_5\": 0.8531136335131068, \"p4\": 0.8285751690589594, \"phi\": 0.6651239955103883}, {\"truth_threshold\": -6.66, \"match_probability\": 0.009791894058579487, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10878, \"tn\": 5992, \"fp\": 2057, \"fn\": 1146, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.904690618762475, \"tn_rate\": 0.7444403031432476, \"fp_rate\": 0.2555596968567524, \"fn_rate\": 0.09530938123752496, \"precision\": 0.8409741012756088, \"recall\": 0.904690618762475, \"specificity\": 0.7444403031432476, \"npv\": 0.8394508265620622, \"accuracy\": 0.8404324216609376, \"f1\": 0.8716695380423896, \"f2\": 0.8911864462322426, \"f0_5\": 0.8529891474813375, \"p4\": 0.8283299494799369, \"phi\": 0.6645937561359588}, {\"truth_threshold\": -6.640000000000001, \"match_probability\": 0.009927226855666866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10873, \"tn\": 5992, \"fp\": 2057, \"fn\": 1151, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9042747837658017, \"tn_rate\": 0.7444403031432476, \"fp_rate\": 0.2555596968567524, \"fn_rate\": 0.09572521623419827, \"precision\": 0.8409126063418407, \"recall\": 0.9042747837658017, \"specificity\": 0.7444403031432476, \"npv\": 0.8388632227355453, \"accuracy\": 0.8401833308424251, \"f1\": 0.8714434559589644, \"f2\": 0.8908498017238554, \"f0_5\": 0.8528645833333334, \"p4\": 0.828084781238919, \"phi\": 0.6640638794864598}, {\"truth_threshold\": -6.62, \"match_probability\": 0.010064411063087227, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10868, \"tn\": 5992, \"fp\": 2057, \"fn\": 1156, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9038589487691284, \"tn_rate\": 0.7444403031432476, \"fp_rate\": 0.2555596968567524, \"fn_rate\": 0.09614105123087159, \"precision\": 0.8408510638297872, \"recall\": 0.9038589487691284, \"specificity\": 0.7444403031432476, \"npv\": 0.838276440962507, \"accuracy\": 0.8399342400239127, \"f1\": 0.871217283257846, \"f2\": 0.8905131020468363, \"f0_5\": 0.8527399409955433, \"p4\": 0.8278396642442537, \"phi\": 0.6635343648297072}, {\"truth_threshold\": -6.6000000000000005, \"match_probability\": 0.010203471479982122, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10866, \"tn\": 5994, \"fp\": 2055, \"fn\": 1158, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.903692614770459, \"tn_rate\": 0.7446887812150578, \"fp_rate\": 0.25531121878494223, \"fn_rate\": 0.09630738522954092, \"precision\": 0.840956582307871, \"recall\": 0.903692614770459, \"specificity\": 0.7446887812150578, \"npv\": 0.8380872483221476, \"accuracy\": 0.8399342400239127, \"f1\": 0.8711966325917018, \"f2\": 0.8904075913270072, \"f0_5\": 0.8527971369372763, \"p4\": 0.8278609956562429, \"phi\": 0.663535520405083}, {\"truth_threshold\": -6.58, \"match_probability\": 0.010344433222956822, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10863, \"tn\": 5994, \"fp\": 2055, \"fn\": 1161, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9034431137724551, \"tn_rate\": 0.7446887812150578, \"fp_rate\": 0.25531121878494223, \"fn_rate\": 0.09655688622754491, \"precision\": 0.8409196470041802, \"recall\": 0.9034431137724551, \"specificity\": 0.7446887812150578, \"npv\": 0.8377358490566038, \"accuracy\": 0.8397847855328052, \"f1\": 0.8710608611979793, \"f2\": 0.8902055266004524, \"f0_5\": 0.852722305953278, \"p4\": 0.8277139571999794, \"phi\": 0.6632181184991606}, {\"truth_threshold\": -6.5600000000000005, \"match_probability\": 0.010487321729732655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10847, \"tn\": 5994, \"fp\": 2055, \"fn\": 1177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9021124417831005, \"tn_rate\": 0.7446887812150578, \"fp_rate\": 0.25531121878494223, \"fn_rate\": 0.09788755821689954, \"precision\": 0.8407223686250194, \"recall\": 0.9021124417831005, \"specificity\": 0.7446887812150578, \"npv\": 0.8358666852600753, \"accuracy\": 0.8389876949135655, \"f1\": 0.8703361951376073, \"f2\": 0.889127512377455, \"f0_5\": 0.8523227307015339, \"p4\": 0.8269300619301025, \"phi\": 0.6615274956644251}, {\"truth_threshold\": -6.54, \"match_probability\": 0.010632162762829713, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10846, \"tn\": 5998, \"fp\": 2051, \"fn\": 1178, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9020292747837658, \"tn_rate\": 0.7451857373586781, \"fp_rate\": 0.2548142626413219, \"fn_rate\": 0.09797072521623419, \"precision\": 0.8409707683957509, \"recall\": 0.9020292747837658, \"specificity\": 0.7451857373586781, \"npv\": 0.8358416945373467, \"accuracy\": 0.839137149404673, \"f1\": 0.8704305605714057, \"f2\": 0.889118423425639, \"f0_5\": 0.8525121046343457, \"p4\": 0.82711967293442, \"phi\": 0.6618483107294316}, {\"truth_threshold\": -6.5200000000000005, \"match_probability\": 0.010778982413279539, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10843, \"tn\": 6000, \"fp\": 2049, \"fn\": 1181, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9017797737857618, \"tn_rate\": 0.7454342154304883, \"fp_rate\": 0.25456578456951173, \"fn_rate\": 0.09822022621423819, \"precision\": 0.8410642258765125, \"recall\": 0.9017797737857618, \"specificity\": 0.7454342154304883, \"npv\": 0.8355382258738338, \"accuracy\": 0.8390873312409705, \"f1\": 0.8703644244662064, \"f2\": 0.8889453663015675, \"f0_5\": 0.8525443452006541, \"p4\": 0.827091998601935, \"phi\": 0.661745095872147}, {\"truth_threshold\": -6.5, \"match_probability\": 0.010927807104367976, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10828, \"tn\": 6001, \"fp\": 2048, \"fn\": 1196, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9005322687957419, \"tn_rate\": 0.7455584544663933, \"fp_rate\": 0.25444154553360665, \"fn_rate\": 0.09946773120425816, \"precision\": 0.8409443926685306, \"recall\": 0.9005322687957419, \"specificity\": 0.7455584544663933, \"npv\": 0.8338196470751702, \"accuracy\": 0.8383898769491357, \"f1\": 0.869718875502008, \"f2\": 0.8879485665551401, \"f0_5\": 0.8522226419846367, \"p4\": 0.8264172169441681, \"phi\": 0.6602717519849594}, {\"truth_threshold\": -6.48, \"match_probability\": 0.011078663595407736, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10826, \"tn\": 6002, \"fp\": 2047, \"fn\": 1198, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9003659347970725, \"tn_rate\": 0.7456826935022984, \"fp_rate\": 0.25431730649770157, \"fn_rate\": 0.09963406520292747, \"precision\": 0.8409850073797871, \"recall\": 0.9003659347970725, \"specificity\": 0.7456826935022984, \"npv\": 0.8336111111111111, \"accuracy\": 0.8383400587854332, \"f1\": 0.8696630116078242, \"f2\": 0.887828240581279, \"f0_5\": 0.8522262107185591, \"p4\": 0.8263789278629192, \"phi\": 0.6601680823904809}, {\"truth_threshold\": -6.46, \"match_probability\": 0.011231578985540796, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10822, \"tn\": 6002, \"fp\": 2047, \"fn\": 1202, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.9000332667997338, \"tn_rate\": 0.7456826935022984, \"fp_rate\": 0.25431730649770157, \"fn_rate\": 0.09996673320026614, \"precision\": 0.8409355816302743, \"recall\": 0.9000332667997338, \"specificity\": 0.7456826935022984, \"npv\": 0.8331482509716824, \"accuracy\": 0.8381407861306233, \"f1\": 0.869481380307717, \"f2\": 0.8875584351677192, \"f0_5\": 0.8521259842519685, \"p4\": 0.8261831773916865, \"phi\": 0.6597474435665869}, {\"truth_threshold\": -6.44, \"match_probability\": 0.011386580717570208, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10820, \"tn\": 6002, \"fp\": 2047, \"fn\": 1204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8998669328010646, \"tn_rate\": 0.7456826935022984, \"fp_rate\": 0.25431730649770157, \"fn_rate\": 0.10013306719893546, \"precision\": 0.8409108572316779, \"recall\": 0.8998669328010646, \"specificity\": 0.7456826935022984, \"npv\": 0.832917013599778, \"accuracy\": 0.8380411498032182, \"f1\": 0.8693905427664618, \"f2\": 0.8874235191837672, \"f0_5\": 0.8520758520758521, \"p4\": 0.8260853142041534, \"phi\": 0.6595372091156321}, {\"truth_threshold\": -6.42, \"match_probability\": 0.011543696581821352, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10820, \"tn\": 6003, \"fp\": 2046, \"fn\": 1204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8998669328010646, \"tn_rate\": 0.7458069325382035, \"fp_rate\": 0.2541930674617965, \"fn_rate\": 0.10013306719893546, \"precision\": 0.8409762163842686, \"recall\": 0.8998669328010646, \"specificity\": 0.7458069325382035, \"npv\": 0.8329401970306647, \"accuracy\": 0.8380909679669207, \"f1\": 0.8694254720771394, \"f2\": 0.887438076178603, \"f0_5\": 0.8521295362903226, \"p4\": 0.8261448995004811, \"phi\": 0.6596440066923946}, {\"truth_threshold\": -6.4, \"match_probability\": 0.011702954720032218, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10819, \"tn\": 6003, \"fp\": 2046, \"fn\": 1205, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8997837658017299, \"tn_rate\": 0.7458069325382035, \"fp_rate\": 0.2541930674617965, \"fn_rate\": 0.10021623419827012, \"precision\": 0.8409638554216867, \"recall\": 0.8997837658017299, \"specificity\": 0.7458069325382035, \"npv\": 0.8328246392896781, \"accuracy\": 0.8380411498032182, \"f1\": 0.8693800474105027, \"f2\": 0.8873706139991142, \"f0_5\": 0.8521044672673429, \"p4\": 0.8260959700503205, \"phi\": 0.6595389183620043}, {\"truth_threshold\": -6.38, \"match_probability\": 0.011864383629272682, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10819, \"tn\": 6004, \"fp\": 2045, \"fn\": 1205, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8997837658017299, \"tn_rate\": 0.7459311715741086, \"fp_rate\": 0.2540688284258914, \"fn_rate\": 0.10021623419827012, \"precision\": 0.8410292288557214, \"recall\": 0.8997837658017299, \"specificity\": 0.7459311715741086, \"npv\": 0.8328478291025108, \"accuracy\": 0.8380909679669207, \"f1\": 0.8694149791063966, \"f2\": 0.8873851706036745, \"f0_5\": 0.8521581600504096, \"p4\": 0.8261555484785887, \"phi\": 0.6596457248239498}, {\"truth_threshold\": -6.36, \"match_probability\": 0.012028012165892355, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10805, \"tn\": 6007, \"fp\": 2042, \"fn\": 1219, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8986194278110445, \"tn_rate\": 0.7463038886818238, \"fp_rate\": 0.25369611131817615, \"fn_rate\": 0.10138057218895542, \"precision\": 0.8410523857709972, \"recall\": 0.8986194278110445, \"specificity\": 0.7463038886818238, \"npv\": 0.8313036257957376, \"accuracy\": 0.8375429681661934, \"f1\": 0.8688834385428813, \"f2\": 0.886484091692237, \"f0_5\": 0.8519680817510881, \"p4\": 0.8256493970140648, \"phi\": 0.6584968252342117}, {\"truth_threshold\": -6.34, \"match_probability\": 0.012193869549496904, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10805, \"tn\": 6008, \"fp\": 2041, \"fn\": 1219, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8986194278110445, \"tn_rate\": 0.7464281277177289, \"fp_rate\": 0.25357187228227107, \"fn_rate\": 0.10138057218895542, \"precision\": 0.8411178576988946, \"recall\": 0.8986194278110445, \"specificity\": 0.7464281277177289, \"npv\": 0.8313269683132697, \"accuracy\": 0.8375927863298959, \"f1\": 0.868918375552875, \"f2\": 0.8864986380492927, \"f0_5\": 0.852021826898814, \"p4\": 0.825708939317304, \"phi\": 0.658603743723886}, {\"truth_threshold\": -6.3, \"match_probability\": 0.01253238957641751, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10801, \"tn\": 6010, \"fp\": 2039, \"fn\": 1223, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8982867598137059, \"tn_rate\": 0.7466766057895391, \"fp_rate\": 0.2533233942104609, \"fn_rate\": 0.10171324018629407, \"precision\": 0.8411993769470405, \"recall\": 0.8982867598137059, \"specificity\": 0.7466766057895391, \"npv\": 0.8309138669984792, \"accuracy\": 0.8374931500024909, \"f1\": 0.8688063063063063, \"f2\": 0.8862577130103715, \"f0_5\": 0.8520289031932349, \"p4\": 0.82563239569685, \"phi\": 0.6583983747562089}, {\"truth_threshold\": -6.28, \"match_probability\": 0.01270511251140324, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10789, \"tn\": 6010, \"fp\": 2039, \"fn\": 1235, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.89728875582169, \"tn_rate\": 0.7466766057895391, \"fp_rate\": 0.2533233942104609, \"fn_rate\": 0.10271124417831004, \"precision\": 0.8410508263174307, \"recall\": 0.89728875582169, \"specificity\": 0.7466766057895391, \"npv\": 0.8295376121463078, \"accuracy\": 0.8368953320380611, \"f1\": 0.8682600997907614, \"f2\": 0.8854474427155145, \"f0_5\": 0.8517272956928129, \"p4\": 0.8250457555270204, \"phi\": 0.657142089861554}, {\"truth_threshold\": -6.24, \"match_probability\": 0.013057637793289553, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10788, \"tn\": 6014, \"fp\": 2035, \"fn\": 1236, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8972055888223552, \"tn_rate\": 0.7471735619331594, \"fp_rate\": 0.2528264380668406, \"fn_rate\": 0.1027944111776447, \"precision\": 0.8413007876471964, \"recall\": 0.8972055888223552, \"specificity\": 0.7471735619331594, \"npv\": 0.8295172413793104, \"accuracy\": 0.8370447865291686, \"f1\": 0.868354328490361, \"f2\": 0.8854380406769645, \"f0_5\": 0.8519173668582981, \"p4\": 0.825234883979981, \"phi\": 0.6574657039386835}, {\"truth_threshold\": -6.22, \"match_probability\": 0.013237502720888259, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10787, \"tn\": 6022, \"fp\": 2027, \"fn\": 1237, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8971224218230206, \"tn_rate\": 0.7481674742204001, \"fp_rate\": 0.25183252577959997, \"fn_rate\": 0.10287757817697937, \"precision\": 0.8418136413297955, \"recall\": 0.8971224218230206, \"specificity\": 0.7481674742204001, \"npv\": 0.8295908527345365, \"accuracy\": 0.837393513675086, \"f1\": 0.8685884531765843, \"f2\": 0.8854867837793465, \"f0_5\": 0.8523230088495575, \"p4\": 0.8256617203296103, \"phi\": 0.6582176966459184}, {\"truth_threshold\": -6.2, \"match_probability\": 0.013419811543709683, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10786, \"tn\": 6024, \"fp\": 2025, \"fn\": 1238, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.897039254823686, \"tn_rate\": 0.7484159522922103, \"fp_rate\": 0.2515840477077898, \"fn_rate\": 0.10296074517631404, \"precision\": 0.8419327140738427, \"recall\": 0.897039254823686, \"specificity\": 0.7484159522922103, \"npv\": 0.8295235472321675, \"accuracy\": 0.8374433318387884, \"f1\": 0.8686128447755184, \"f2\": 0.8854483064344, \"f0_5\": 0.8524056395018018, \"p4\": 0.825731706733568, \"phi\": 0.6583273807237067}, {\"truth_threshold\": -6.18, \"match_probability\": 0.013604596533857708, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10785, \"tn\": 6026, \"fp\": 2023, \"fn\": 1239, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8969560878243513, \"tn_rate\": 0.7486644303640204, \"fp_rate\": 0.25133556963597964, \"fn_rate\": 0.1030439121756487, \"precision\": 0.8420518425983761, \"recall\": 0.8969560878243513, \"specificity\": 0.7486644303640204, \"npv\": 0.8294562973158981, \"accuracy\": 0.8374931500024909, \"f1\": 0.8686372422680413, \"f2\": 0.8854098252988309, \"f0_5\": 0.8524883015049955, \"p4\": 0.8258016678966468, \"phi\": 0.6584371141264467}, {\"truth_threshold\": -6.16, \"match_probability\": 0.013791890363702633, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10784, \"tn\": 6026, \"fp\": 2023, \"fn\": 1240, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8968729208250167, \"tn_rate\": 0.7486644303640204, \"fp_rate\": 0.25133556963597964, \"fn_rate\": 0.10312707917498337, \"precision\": 0.8420395096431639, \"recall\": 0.8968729208250167, \"specificity\": 0.7486644303640204, \"npv\": 0.8293421414808698, \"accuracy\": 0.8374433318387884, \"f1\": 0.8685916797551447, \"f2\": 0.8853422655698405, \"f0_5\": 0.8524631632201354, \"p4\": 0.8257527879840464, \"phi\": 0.6583326915044785}, {\"truth_threshold\": -6.140000000000001, \"match_probability\": 0.013981726110122288, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10768, \"tn\": 6028, \"fp\": 2021, \"fn\": 1256, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.895542248835662, \"tn_rate\": 0.7489129084358306, \"fp_rate\": 0.2510870915641695, \"fn_rate\": 0.10445775116433799, \"precision\": 0.8419735710376104, \"recall\": 0.895542248835662, \"specificity\": 0.7489129084358306, \"npv\": 0.827567270730368, \"accuracy\": 0.8367458775469536, \"f1\": 0.8679321323499778, \"f2\": 0.8842900550217624, \"f0_5\": 0.8521684077239633, \"p4\": 0.8250897643127252, \"phi\": 0.6568782600157126}, {\"truth_threshold\": -6.12, \"match_probability\": 0.01417413725876712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10767, \"tn\": 6028, \"fp\": 2021, \"fn\": 1257, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8954590818363274, \"tn_rate\": 0.7489129084358306, \"fp_rate\": 0.2510870915641695, \"fn_rate\": 0.10454091816367266, \"precision\": 0.8419612136377854, \"recall\": 0.8954590818363274, \"specificity\": 0.7489129084358306, \"npv\": 0.8274536719286204, \"accuracy\": 0.8366960593832511, \"f1\": 0.8678865065290988, \"f2\": 0.8842224558176204, \"f0_5\": 0.8521432189439028, \"p4\": 0.8250409159924708, \"phi\": 0.6567740875904239}, {\"truth_threshold\": -6.1000000000000005, \"match_probability\": 0.014369157708348785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10766, \"tn\": 6028, \"fp\": 2021, \"fn\": 1258, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8953759148369926, \"tn_rate\": 0.7489129084358306, \"fp_rate\": 0.2510870915641695, \"fn_rate\": 0.10462408516300732, \"precision\": 0.8419488543051536, \"recall\": 0.8953759148369926, \"specificity\": 0.7489129084358306, \"npv\": 0.8273401043096349, \"accuracy\": 0.8366462412195487, \"f1\": 0.8678408770303494, \"f2\": 0.8841548543928519, \"f0_5\": 0.8521180269739758, \"p4\": 0.8249920696266788, \"phi\": 0.6566699289410285}, {\"truth_threshold\": -6.08, \"match_probability\": 0.01456682177495178, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10765, \"tn\": 6030, \"fp\": 2019, \"fn\": 1259, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.895292747837658, \"tn_rate\": 0.7491613865076407, \"fp_rate\": 0.2508386134923593, \"fn_rate\": 0.10470725216234199, \"precision\": 0.8420682102628285, \"recall\": 0.895292747837658, \"specificity\": 0.7491613865076407, \"npv\": 0.8272739744820963, \"accuracy\": 0.8366960593832511, \"f1\": 0.8678652047726539, \"f2\": 0.8841162943495401, \"f0_5\": 0.8522007599746675, \"p4\": 0.8250619840796711, \"phi\": 0.6567802815634629}, {\"truth_threshold\": -6.0600000000000005, \"match_probability\": 0.014767164196367252, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10760, \"tn\": 6215, \"fp\": 1834, \"fn\": 1264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8948769128409847, \"tn_rate\": 0.7721456081500807, \"fp_rate\": 0.22785439184991924, \"fn_rate\": 0.1051230871590153, \"precision\": 0.8543750992536129, \"recall\": 0.8948769128409847, \"specificity\": 0.7721456081500807, \"npv\": 0.8309934483219682, \"accuracy\": 0.8456633288496986, \"f1\": 0.8741571208059143, \"f2\": 0.8864722359532048, \"f0_5\": 0.8621794871794872, \"p4\": 0.8357029593808964, \"phi\": 0.6761333126032536}, {\"truth_threshold\": -6.04, \"match_probability\": 0.014970220136448715, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10754, \"tn\": 6220, \"fp\": 1829, \"fn\": 1270, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8943779108449768, \"tn_rate\": 0.7727668033296061, \"fp_rate\": 0.22723319667039385, \"fn_rate\": 0.10562208915502329, \"precision\": 0.8546451561630771, \"recall\": 0.8943779108449768, \"specificity\": 0.7727668033296061, \"npv\": 0.8304405874499332, \"accuracy\": 0.8456135106859961, \"f1\": 0.8740602267647417, \"f2\": 0.8861385322764054, \"f0_5\": 0.8623067547629739, \"p4\": 0.8357005676121172, \"phi\": 0.6760557170883058}, {\"truth_threshold\": -6.0200000000000005, \"match_probability\": 0.015176025189488596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10748, \"tn\": 6220, \"fp\": 1829, \"fn\": 1276, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8938789088489687, \"tn_rate\": 0.7727668033296061, \"fp_rate\": 0.22723319667039385, \"fn_rate\": 0.10612109115103127, \"precision\": 0.8545758129919695, \"recall\": 0.8938789088489687, \"specificity\": 0.7727668033296061, \"npv\": 0.8297758804695837, \"accuracy\": 0.8453146017037811, \"f1\": 0.8737856184707938, \"f2\": 0.8857317093270483, \"f0_5\": 0.8621574793043701, \"p4\": 0.8354066912701282, \"phi\": 0.675440687305918}, {\"truth_threshold\": -6.0, \"match_probability\": 0.015384615384615385, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10746, \"tn\": 6220, \"fp\": 1829, \"fn\": 1278, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8937125748502994, \"tn_rate\": 0.7727668033296061, \"fp_rate\": 0.22723319667039385, \"fn_rate\": 0.1062874251497006, \"precision\": 0.8545526838966203, \"recall\": 0.8937125748502994, \"specificity\": 0.7727668033296061, \"npv\": 0.8295545478794345, \"accuracy\": 0.8452149653763762, \"f1\": 0.8736940526037644, \"f2\": 0.8855960837962124, \"f0_5\": 0.86210769526988, \"p4\": 0.8353087472858841, \"phi\": 0.6752357828510583}, {\"truth_threshold\": -5.98, \"match_probability\": 0.01559602719021019, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10746, \"tn\": 6223, \"fp\": 1826, \"fn\": 1278, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8937125748502994, \"tn_rate\": 0.7731395204373214, \"fp_rate\": 0.2268604795626786, \"fn_rate\": 0.1062874251497006, \"precision\": 0.8547566019726376, \"recall\": 0.8937125748502994, \"specificity\": 0.7731395204373214, \"npv\": 0.8296227169710705, \"accuracy\": 0.8453644198674837, \"f1\": 0.8738006179866645, \"f2\": 0.8856398760466803, \"f0_5\": 0.8622737193477982, \"p4\": 0.8354835792598584, \"phi\": 0.6755588670198377}, {\"truth_threshold\": -5.96, \"match_probability\": 0.015810297518342384, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10744, \"tn\": 6223, \"fp\": 1826, \"fn\": 1280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.89354624085163, \"tn_rate\": 0.7731395204373214, \"fp_rate\": 0.2268604795626786, \"fn_rate\": 0.10645375914836992, \"precision\": 0.854733492442323, \"recall\": 0.89354624085163, \"specificity\": 0.7731395204373214, \"npv\": 0.8294015727042516, \"accuracy\": 0.8452647835400787, \"f1\": 0.8737090347239164, \"f2\": 0.8855042363102891, \"f0_5\": 0.8622239342578326, \"p4\": 0.835385637776573, \"phi\": 0.6753540602763195}, {\"truth_threshold\": -5.94, \"match_probability\": 0.016027463729223174, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10743, \"tn\": 6230, \"fp\": 1819, \"fn\": 1281, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8934630738522954, \"tn_rate\": 0.774009193688657, \"fp_rate\": 0.22599080631134302, \"fn_rate\": 0.10653692614770459, \"precision\": 0.8551982168444515, \"recall\": 0.8934630738522954, \"specificity\": 0.774009193688657, \"npv\": 0.8294501397949674, \"accuracy\": 0.8455636925222936, \"f1\": 0.8739119824290247, \"f2\": 0.8855385934254344, \"f0_5\": 0.8625867163412128, \"p4\": 0.8357444058171423, \"phi\": 0.676005762604358}, {\"truth_threshold\": -5.92, \"match_probability\": 0.016247563635676584, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10743, \"tn\": 6231, \"fp\": 1818, \"fn\": 1281, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8934630738522954, \"tn_rate\": 0.774133432724562, \"fp_rate\": 0.22586656727543794, \"fn_rate\": 0.10653692614770459, \"precision\": 0.8552663004537855, \"recall\": 0.8934630738522954, \"specificity\": 0.774133432724562, \"npv\": 0.8294728434504792, \"accuracy\": 0.8456135106859961, \"f1\": 0.8739475289810861, \"f2\": 0.8855531925416688, \"f0_5\": 0.862642127577568, \"p4\": 0.8358026323544706, \"phi\": 0.6761134966756064}, {\"truth_threshold\": -5.9, \"match_probability\": 0.016470635507626726, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10737, \"tn\": 6231, \"fp\": 1818, \"fn\": 1287, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8929640718562875, \"tn_rate\": 0.774133432724562, \"fp_rate\": 0.22586656727543794, \"fn_rate\": 0.10703592814371257, \"precision\": 0.8551971326164874, \"recall\": 0.8929640718562875, \"specificity\": 0.774133432724562, \"npv\": 0.8288108539505188, \"accuracy\": 0.8453146017037811, \"f1\": 0.8736726473819114, \"f2\": 0.8851461641193056, \"f0_5\": 0.8624927703875073, \"p4\": 0.8355088240818076, \"phi\": 0.6754998304605421}, {\"truth_threshold\": -5.88, \"match_probability\": 0.016696718076600735, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10721, \"tn\": 6231, \"fp\": 1818, \"fn\": 1303, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8916333998669328, \"tn_rate\": 0.774133432724562, \"fp_rate\": 0.22586656727543794, \"fn_rate\": 0.1083666001330672, \"precision\": 0.8550123614323312, \"recall\": 0.8916333998669328, \"specificity\": 0.774133432724562, \"npv\": 0.8270507034775684, \"accuracy\": 0.8445175110845414, \"f1\": 0.8729389732524528, \"f2\": 0.8840603611775377, \"f0_5\": 0.8620939208748793, \"p4\": 0.8347256579583072, \"phi\": 0.6738656886596252}, {\"truth_threshold\": -5.86, \"match_probability\": 0.0169258505402461, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10714, \"tn\": 6231, \"fp\": 1818, \"fn\": 1310, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8910512308715901, \"tn_rate\": 0.774133432724562, \"fp_rate\": 0.22586656727543794, \"fn_rate\": 0.10894876912840985, \"precision\": 0.8549313756782636, \"recall\": 0.8910512308715901, \"specificity\": 0.774133432724562, \"npv\": 0.826282986341334, \"accuracy\": 0.844168783938624, \"f1\": 0.8726176901775533, \"f2\": 0.8835851421785313, \"f0_5\": 0.8619191659158193, \"p4\": 0.8343831697677903, \"phi\": 0.673151800292381}, {\"truth_threshold\": -5.84, \"match_probability\": 0.017158072566861807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10713, \"tn\": 6231, \"fp\": 1818, \"fn\": 1311, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8909680638722555, \"tn_rate\": 0.774133432724562, \"fp_rate\": 0.22586656727543794, \"fn_rate\": 0.1090319361277445, \"precision\": 0.8549197988987312, \"recall\": 0.8909680638722555, \"specificity\": 0.774133432724562, \"npv\": 0.8261734287987271, \"accuracy\": 0.8441189657749215, \"f1\": 0.8725717776420281, \"f2\": 0.8835172447919244, \"f0_5\": 0.8618941880671944, \"p4\": 0.8343342501639259, \"phi\": 0.6730498681847702}, {\"truth_threshold\": -5.82, \"match_probability\": 0.017393424299941902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10713, \"tn\": 6239, \"fp\": 1810, \"fn\": 1311, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8909680638722555, \"tn_rate\": 0.7751273450118027, \"fp_rate\": 0.22487265498819728, \"fn_rate\": 0.1090319361277445, \"precision\": 0.8554659426654955, \"recall\": 0.8909680638722555, \"specificity\": 0.7751273450118027, \"npv\": 0.8263576158940398, \"accuracy\": 0.8445175110845414, \"f1\": 0.8728561535014462, \"f2\": 0.8836338441742688, \"f0_5\": 0.8623382059372786, \"p4\": 0.8347996735910437, \"phi\": 0.6739136013062039}, {\"truth_threshold\": -5.8, \"match_probability\": 0.017631946362730785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10703, \"tn\": 6241, \"fp\": 1808, \"fn\": 1321, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8901363938789089, \"tn_rate\": 0.7753758230836129, \"fp_rate\": 0.22462417691638714, \"fn_rate\": 0.10986360612109115, \"precision\": 0.8554871712892654, \"recall\": 0.8901363938789089, \"specificity\": 0.7753758230836129, \"npv\": 0.8253107643480561, \"accuracy\": 0.8441189657749215, \"f1\": 0.8724679029957204, \"f2\": 0.8829838137508869, \"f0_5\": 0.8621995231036927, \"p4\": 0.834426797316295, \"phi\": 0.6731116872031729}, {\"truth_threshold\": -5.78, \"match_probability\": 0.01787367986278876, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10701, \"tn\": 6241, \"fp\": 1808, \"fn\": 1323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8899700598802395, \"tn_rate\": 0.7753758230836129, \"fp_rate\": 0.22462417691638714, \"fn_rate\": 0.11002994011976049, \"precision\": 0.8554640658725717, \"recall\": 0.8899700598802395, \"specificity\": 0.7753758230836129, \"npv\": 0.8250925436277102, \"accuracy\": 0.8440193294475166, \"f1\": 0.8723759833693393, \"f2\": 0.8828479498391222, \"f0_5\": 0.8621495327102804, \"p4\": 0.8343289832483994, \"phi\": 0.6729082688263318}, {\"truth_threshold\": -5.76, \"match_probability\": 0.018118666396567108, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10701, \"tn\": 6242, \"fp\": 1807, \"fn\": 1323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8899700598802395, \"tn_rate\": 0.7755000621195179, \"fp_rate\": 0.22449993788048206, \"fn_rate\": 0.11002994011976049, \"precision\": 0.8555324592260953, \"recall\": 0.8899700598802395, \"specificity\": 0.7755000621195179, \"npv\": 0.8251156642432254, \"accuracy\": 0.8440691476112191, \"f1\": 0.8724115441056579, \"f2\": 0.8828625173255891, \"f0_5\": 0.8622051050663917, \"p4\": 0.8343871166371101, \"phi\": 0.673016336922095}, {\"truth_threshold\": -5.74, \"match_probability\": 0.018366948053991125, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10699, \"tn\": 6242, \"fp\": 1807, \"fn\": 1325, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8898037258815702, \"tn_rate\": 0.7755000621195179, \"fp_rate\": 0.22449993788048206, \"fn_rate\": 0.1101962741184298, \"precision\": 0.8555093555093555, \"recall\": 0.8898037258815702, \"specificity\": 0.7755000621195179, \"npv\": 0.8248975816043346, \"accuracy\": 0.843969511283814, \"f1\": 0.8723196086424786, \"f2\": 0.8827266426850598, \"f0_5\": 0.8621551057246003, \"p4\": 0.834289308131159, \"phi\": 0.6728129848954731}, {\"truth_threshold\": -5.72, \"match_probability\": 0.018618567423050236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10695, \"tn\": 6246, \"fp\": 1803, \"fn\": 1329, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8894710578842315, \"tn_rate\": 0.7759970182631383, \"fp_rate\": 0.22400298173686173, \"fn_rate\": 0.11052894211576847, \"precision\": 0.8557369179068651, \"recall\": 0.8894710578842315, \"specificity\": 0.7759970182631383, \"npv\": 0.8245544554455445, \"accuracy\": 0.843969511283814, \"f1\": 0.8722779544898459, \"f2\": 0.8825131201109021, \"f0_5\": 0.8622774767801857, \"p4\": 0.834326173307538, \"phi\": 0.6728389045265443}, {\"truth_threshold\": -5.7, \"match_probability\": 0.018873567594393605, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10693, \"tn\": 6246, \"fp\": 1803, \"fn\": 1331, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8893047238855623, \"tn_rate\": 0.7759970182631383, \"fp_rate\": 0.22400298173686173, \"fn_rate\": 0.11069527611443779, \"precision\": 0.855713828425096, \"recall\": 0.8893047238855623, \"specificity\": 0.7759970182631383, \"npv\": 0.8243368087633628, \"accuracy\": 0.8438698749564091, \"f1\": 0.8721859706362153, \"f2\": 0.882377211513071, \"f0_5\": 0.8622274545219971, \"p4\": 0.8342283797759672, \"phi\": 0.6726357659765168}, {\"truth_threshold\": -5.68, \"match_probability\": 0.01913199216593024, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10689, \"tn\": 6248, \"fp\": 1801, \"fn\": 1335, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8889720558882236, \"tn_rate\": 0.7762454963349484, \"fp_rate\": 0.22375450366505156, \"fn_rate\": 0.11102794411177645, \"precision\": 0.855804643714972, \"recall\": 0.8889720558882236, \"specificity\": 0.7762454963349484, \"npv\": 0.8239483054200185, \"accuracy\": 0.8437702386290041, \"f1\": 0.8720731010850943, \"f2\": 0.8821344865150365, \"f0_5\": 0.8622386422302529, \"p4\": 0.834149002766305, \"phi\": 0.6724459777112661}, {\"truth_threshold\": -5.66, \"match_probability\": 0.019393885247431873, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10685, \"tn\": 6252, \"fp\": 1797, \"fn\": 1339, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8886393878908849, \"tn_rate\": 0.7767424524785688, \"fp_rate\": 0.22325754752143123, \"fn_rate\": 0.1113606121091151, \"precision\": 0.85603268706938, \"recall\": 0.8886393878908849, \"specificity\": 0.7767424524785688, \"npv\": 0.8236069029113424, \"accuracy\": 0.8437702386290041, \"f1\": 0.8720313392638538, \"f2\": 0.8819208293439863, \"f0_5\": 0.8623611828512396, \"p4\": 0.8341857594891028, \"phi\": 0.6724729296925743}, {\"truth_threshold\": -5.64, \"match_probability\": 0.019659291465137646, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10679, \"tn\": 6252, \"fp\": 1797, \"fn\": 1345, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8881403858948769, \"tn_rate\": 0.7767424524785688, \"fp_rate\": 0.22325754752143123, \"fn_rate\": 0.11185961410512309, \"precision\": 0.8559634498236615, \"recall\": 0.8881403858948769, \"specificity\": 0.7767424524785688, \"npv\": 0.8229564301698039, \"accuracy\": 0.8434713296467892, \"f1\": 0.8717551020408163, \"f2\": 0.8815129102555637, \"f0_5\": 0.862210954657021, \"p4\": 0.8338924779541711, \"phi\": 0.6718647012890425}, {\"truth_threshold\": -5.62, \"match_probability\": 0.019928255966358603, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10671, \"tn\": 6257, \"fp\": 1792, \"fn\": 1353, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8874750499001997, \"tn_rate\": 0.7773636476580942, \"fp_rate\": 0.22263635234190582, \"fn_rate\": 0.1125249500998004, \"precision\": 0.8562143946080398, \"recall\": 0.8874750499001997, \"specificity\": 0.7773636476580942, \"npv\": 0.8222076215505913, \"accuracy\": 0.8433218751556818, \"f1\": 0.8715645036141626, \"f2\": 0.8810416288247824, \"f0_5\": 0.8622890943176676, \"p4\": 0.8337917338110238, \"phi\": 0.6715960166780146}, {\"truth_threshold\": -5.6000000000000005, \"match_probability\": 0.02020082442408101, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10671, \"tn\": 6259, \"fp\": 1790, \"fn\": 1353, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8874750499001997, \"tn_rate\": 0.7776121257299043, \"fp_rate\": 0.22238787427009565, \"fn_rate\": 0.1125249500998004, \"precision\": 0.8563518176711339, \"recall\": 0.8874750499001997, \"specificity\": 0.7776121257299043, \"npv\": 0.8222543352601156, \"accuracy\": 0.8434215114830867, \"f1\": 0.8716356953236676, \"f2\": 0.8810707267533068, \"f0_5\": 0.8624005948147669, \"p4\": 0.8339077761633882, \"phi\": 0.6718126596144607}, {\"truth_threshold\": -5.58, \"match_probability\": 0.02047704304156655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10617, \"tn\": 6259, \"fp\": 1790, \"fn\": 1407, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8829840319361277, \"tn_rate\": 0.7776121257299043, \"fp_rate\": 0.22238787427009565, \"fn_rate\": 0.11701596806387225, \"precision\": 0.855726605948255, \"recall\": 0.8829840319361277, \"specificity\": 0.7776121257299043, \"npv\": 0.8164623010696582, \"accuracy\": 0.8407313306431525, \"f1\": 0.8691416642789898, \"f2\": 0.8773945093631721, \"f0_5\": 0.8610426263543762, \"p4\": 0.8312715522725022, \"phi\": 0.666367323029696}, {\"truth_threshold\": -5.5600000000000005, \"match_probability\": 0.020756958556947872, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10608, \"tn\": 6259, \"fp\": 1790, \"fn\": 1416, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8822355289421158, \"tn_rate\": 0.7776121257299043, \"fp_rate\": 0.22238787427009565, \"fn_rate\": 0.11776447105788423, \"precision\": 0.8556218744958864, \"recall\": 0.8822355289421158, \"specificity\": 0.7776121257299043, \"npv\": 0.8155048859934854, \"accuracy\": 0.8402829671698301, \"f1\": 0.8687249201539595, \"f2\": 0.8767811683803353, \"f0_5\": 0.8608153726304856, \"p4\": 0.8308326765626546, \"phi\": 0.6654633114579214}, {\"truth_threshold\": -5.54, \"match_probability\": 0.02104061824781806, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10599, \"tn\": 6259, \"fp\": 1790, \"fn\": 1425, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8814870259481038, \"tn_rate\": 0.7776121257299043, \"fp_rate\": 0.22238787427009565, \"fn_rate\": 0.1185129740518962, \"precision\": 0.8555169908790056, \"recall\": 0.8814870259481038, \"specificity\": 0.7776121257299043, \"npv\": 0.8145497136907861, \"accuracy\": 0.8398346036965078, \"f1\": 0.8683078687584483, \"f2\": 0.876167644870629, \"f0_5\": 0.8605878531990906, \"p4\": 0.8303939408446308, \"phi\": 0.6645603031701699}, {\"truth_threshold\": -5.5200000000000005, \"match_probability\": 0.021328069935811763, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10593, \"tn\": 6259, \"fp\": 1790, \"fn\": 1431, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8809880239520959, \"tn_rate\": 0.7776121257299043, \"fp_rate\": 0.22238787427009565, \"fn_rate\": 0.11901197604790419, \"precision\": 0.8554469837680692, \"recall\": 0.8809880239520959, \"specificity\": 0.7776121257299043, \"npv\": 0.8139141742522756, \"accuracy\": 0.8395356947142928, \"f1\": 0.8680296636210924, \"f2\": 0.8757585277534351, \"f0_5\": 0.8604360257326662, \"p4\": 0.8301015278760953, \"phi\": 0.6639588532910123}, {\"truth_threshold\": -5.5, \"match_probability\": 0.021619361991176866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10592, \"tn\": 6260, \"fp\": 1789, \"fn\": 1432, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8809048569527611, \"tn_rate\": 0.7777363647658094, \"fp_rate\": 0.22226363523419057, \"fn_rate\": 0.11909514304723885, \"precision\": 0.8555044019061465, \"recall\": 0.8809048569527611, \"specificity\": 0.7777363647658094, \"npv\": 0.8138325533021321, \"accuracy\": 0.8395356947142928, \"f1\": 0.8680188485965991, \"f2\": 0.8757048134001356, \"f0_5\": 0.8604666276727108, \"p4\": 0.8301107442883371, \"phi\": 0.6639675518575955}, {\"truth_threshold\": -5.48, \"match_probability\": 0.021914543337334162, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10585, \"tn\": 6261, \"fp\": 1788, \"fn\": 1439, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8803226879574185, \"tn_rate\": 0.7778606038017145, \"fp_rate\": 0.2221393961982855, \"fn_rate\": 0.1196773120425815, \"precision\": 0.8554917966540047, \"recall\": 0.8803226879574185, \"specificity\": 0.7778606038017145, \"npv\": 0.8131168831168831, \"accuracy\": 0.8392367857320779, \"f1\": 0.8677296388900274, \"f2\": 0.8752418594651805, \"f0_5\": 0.8603452760257494, \"p4\": 0.8298276143984246, \"phi\": 0.6633755058413981}, {\"truth_threshold\": -5.46, \"match_probability\": 0.02221366345542378, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10581, \"tn\": 6261, \"fp\": 1788, \"fn\": 1443, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8799900199600799, \"tn_rate\": 0.7778606038017145, \"fp_rate\": 0.2221393961982855, \"fn_rate\": 0.12000998003992017, \"precision\": 0.8554450642735872, \"recall\": 0.8799900199600799, \"specificity\": 0.7778606038017145, \"npv\": 0.8126947040498442, \"accuracy\": 0.8390375130772679, \"f1\": 0.867543967531669, \"f2\": 0.8749689903249814, \"f0_5\": 0.8602439024390244, \"p4\": 0.8296327545865876, \"phi\": 0.6629752358509555}, {\"truth_threshold\": -5.44, \"match_probability\": 0.02251677238883578, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10579, \"tn\": 6261, \"fp\": 1788, \"fn\": 1445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8798236859614105, \"tn_rate\": 0.7778606038017145, \"fp_rate\": 0.2221393961982855, \"fn_rate\": 0.12017631403858949, \"precision\": 0.8554216867469879, \"recall\": 0.8798236859614105, \"specificity\": 0.7778606038017145, \"npv\": 0.812483778873605, \"accuracy\": 0.838937876749863, \"f1\": 0.8674511090156205, \"f2\": 0.8748325422159007, \"f0_5\": 0.8601931958628765, \"p4\": 0.8295353349293464, \"phi\": 0.6627751743884113}, {\"truth_threshold\": -5.42, \"match_probability\": 0.02282392074772345, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10577, \"tn\": 6261, \"fp\": 1788, \"fn\": 1447, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8796573519627412, \"tn_rate\": 0.7778606038017145, \"fp_rate\": 0.2221393961982855, \"fn_rate\": 0.12034264803725882, \"precision\": 0.8553983016579054, \"recall\": 0.8796573519627412, \"specificity\": 0.7778606038017145, \"npv\": 0.8122729631551635, \"accuracy\": 0.838838240422458, \"f1\": 0.8673582352699988, \"f2\": 0.8746960850796381, \"f0_5\": 0.8601424760913409, \"p4\": 0.8294379220967518, \"phi\": 0.6625751618967901}, {\"truth_threshold\": -5.4, \"match_probability\": 0.023135159713496674, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10575, \"tn\": 6262, \"fp\": 1787, \"fn\": 1449, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8794910179640718, \"tn_rate\": 0.7779848428376196, \"fp_rate\": 0.22201515716238043, \"fn_rate\": 0.12050898203592815, \"precision\": 0.8554441028959715, \"recall\": 0.8794910179640718, \"specificity\": 0.7779848428376196, \"npv\": 0.8120866294903385, \"accuracy\": 0.8387884222587555, \"f1\": 0.8673009103584024, \"f2\": 0.8745740844884051, \"f0_5\": 0.8601477095262884, \"p4\": 0.8293984366556544, \"phi\": 0.6624842208590879}, {\"truth_threshold\": -5.38, \"match_probability\": 0.023450541043293725, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10567, \"tn\": 6280, \"fp\": 1769, \"fn\": 1457, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8788256819693946, \"tn_rate\": 0.7802211454839111, \"fp_rate\": 0.21977885451608895, \"fn_rate\": 0.12117431803060545, \"precision\": 0.8565985732814526, \"recall\": 0.8788256819693946, \"specificity\": 0.7802211454839111, \"npv\": 0.8116841152901642, \"accuracy\": 0.8392866038957804, \"f1\": 0.8675697865353038, \"f2\": 0.8742884564469156, \"f0_5\": 0.8609535914483119, \"p4\": 0.830050428300678, \"phi\": 0.6636486915116231}, {\"truth_threshold\": -5.36, \"match_probability\": 0.023770117074428793, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10566, \"tn\": 6281, \"fp\": 1768, \"fn\": 1458, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8787425149700598, \"tn_rate\": 0.7803453845198162, \"fp_rate\": 0.21965461548018386, \"fn_rate\": 0.12125748502994012, \"precision\": 0.8566563969515162, \"recall\": 0.8787425149700598, \"specificity\": 0.7803453845198162, \"npv\": 0.8116035663522418, \"accuracy\": 0.8392866038957804, \"f1\": 0.8675589128828312, \"f2\": 0.8742346516630812, \"f0_5\": 0.8609843546284224, \"p4\": 0.8300595387980272, \"phi\": 0.6636580863118112}, {\"truth_threshold\": -5.34, \"match_probability\": 0.024093940728813348, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10565, \"tn\": 6282, \"fp\": 1767, \"fn\": 1459, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8786593479707252, \"tn_rate\": 0.7804696235557212, \"fp_rate\": 0.21953037644427878, \"fn_rate\": 0.12134065202927478, \"precision\": 0.85671423937723, \"recall\": 0.8786593479707252, \"specificity\": 0.7804696235557212, \"npv\": 0.8115230590363002, \"accuracy\": 0.8392866038957804, \"f1\": 0.8675480374445722, \"f2\": 0.8741808433176673, \"f0_5\": 0.8610151258312687, \"p4\": 0.8300686440680562, \"phi\": 0.6636675095549889}, {\"truth_threshold\": -5.3, \"match_probability\": 0.024754545544286844, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10559, \"tn\": 6283, \"fp\": 1766, \"fn\": 1465, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8781603459747173, \"tn_rate\": 0.7805938625916263, \"fp_rate\": 0.21940613740837372, \"fn_rate\": 0.12183965402528277, \"precision\": 0.8567139959432049, \"recall\": 0.8781603459747173, \"specificity\": 0.7805938625916263, \"npv\": 0.8109189468249871, \"accuracy\": 0.8390375130772679, \"f1\": 0.8673046120990595, \"f2\": 0.8737856043428609, \"f0_5\": 0.8609190528993542, \"p4\": 0.8298342553530214, \"phi\": 0.6631787171088042}, {\"truth_threshold\": -5.28, \"match_probability\": 0.0250914355115595, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10547, \"tn\": 6285, \"fp\": 1764, \"fn\": 1477, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8771623419827013, \"tn_rate\": 0.7808423406634365, \"fp_rate\": 0.21915765933656356, \"fn_rate\": 0.12283765801729873, \"precision\": 0.8567135082446592, \"recall\": 0.8771623419827013, \"specificity\": 0.7808423406634365, \"npv\": 0.8097139912393713, \"accuracy\": 0.8385393314402431, \"f1\": 0.8668173412779947, \"f2\": 0.8729948515900475, \"f0_5\": 0.860726643598616, \"p4\": 0.8293656122487165, \"phi\": 0.6622026995600733}, {\"truth_threshold\": -5.26, \"match_probability\": 0.02543279072306829, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10528, \"tn\": 6285, \"fp\": 1764, \"fn\": 1496, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8755821689953427, \"tn_rate\": 0.7808423406634365, \"fp_rate\": 0.21915765933656356, \"fn_rate\": 0.12441783100465735, \"precision\": 0.856492027334852, \"recall\": 0.8755821689953427, \"specificity\": 0.7808423406634365, \"npv\": 0.807736794756458, \"accuracy\": 0.8375927863298959, \"f1\": 0.8659318966935351, \"f2\": 0.8716963635159303, \"f0_5\": 0.8602431690417048, \"p4\": 0.8284410845853771, \"phi\": 0.6603151360089489}, {\"truth_threshold\": -5.24, \"match_probability\": 0.025778667088937956, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10528, \"tn\": 6287, \"fp\": 1762, \"fn\": 1496, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8755821689953427, \"tn_rate\": 0.7810908187352467, \"fp_rate\": 0.2189091812647534, \"fn_rate\": 0.12441783100465735, \"precision\": 0.8566314076484947, \"recall\": 0.8755821689953427, \"specificity\": 0.7810908187352467, \"npv\": 0.8077862006938199, \"accuracy\": 0.8376924226573008, \"f1\": 0.8660031257711607, \"f2\": 0.8717252343258372, \"f0_5\": 0.8603556485355649, \"p4\": 0.8285565889121339, \"phi\": 0.6605339476294615}, {\"truth_threshold\": -5.22, \"match_probability\": 0.02612912112972733, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10527, \"tn\": 6288, \"fp\": 1761, \"fn\": 1497, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8754990019960079, \"tn_rate\": 0.7812150577711517, \"fp_rate\": 0.2187849422288483, \"fn_rate\": 0.12450099800399202, \"precision\": 0.856689453125, \"recall\": 0.8754990019960079, \"specificity\": 0.7812150577711517, \"npv\": 0.8077071290944123, \"accuracy\": 0.8376924226573008, \"f1\": 0.8659921026653504, \"f2\": 0.8716713036565977, \"f0_5\": 0.8603864260494312, \"p4\": 0.8285656879703612, \"phi\": 0.6605441520479428}, {\"truth_threshold\": -5.2, \"match_probability\": 0.026484209980595738, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10526, \"tn\": 6291, \"fp\": 1758, \"fn\": 1498, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8754158349966733, \"tn_rate\": 0.781587774878867, \"fp_rate\": 0.21841222512113306, \"fn_rate\": 0.12458416500332668, \"precision\": 0.8568870074894172, \"recall\": 0.8754158349966733, \"specificity\": 0.781587774878867, \"npv\": 0.8076774939016562, \"accuracy\": 0.8377920589847059, \"f1\": 0.8660523284515386, \"f2\": 0.8716462404769791, \"f0_5\": 0.8605297580117724, \"p4\": 0.8286902414803885, \"phi\": 0.6607732412931638}, {\"truth_threshold\": -5.18, \"match_probability\": 0.026843991395422352, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10519, \"tn\": 6291, \"fp\": 1758, \"fn\": 1505, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8748336660013307, \"tn_rate\": 0.781587774878867, \"fp_rate\": 0.21841222512113306, \"fn_rate\": 0.12516633399866933, \"precision\": 0.8568054084874155, \"recall\": 0.8748336660013307, \"specificity\": 0.781587774878867, \"npv\": 0.8069522832221652, \"accuracy\": 0.8374433318387884, \"f1\": 0.8657256903008107, \"f2\": 0.8711675749093137, \"f0_5\": 0.8603513708041615, \"p4\": 0.8283497628263865, \"phi\": 0.6600793743083607}, {\"truth_threshold\": -5.16, \"match_probability\": 0.027208523750875003, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10512, \"tn\": 6291, \"fp\": 1758, \"fn\": 1512, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.874251497005988, \"tn_rate\": 0.781587774878867, \"fp_rate\": 0.21841222512113306, \"fn_rate\": 0.12574850299401197, \"precision\": 0.8567237163814181, \"recall\": 0.874251497005988, \"specificity\": 0.781587774878867, \"npv\": 0.8062283737024222, \"accuracy\": 0.837094604692871, \"f1\": 0.8653988639170166, \"f2\": 0.8706887983301859, \"f0_5\": 0.8601728201099764, \"p4\": 0.8280093649421825, \"phi\": 0.6593860902802914}, {\"truth_threshold\": -5.14, \"match_probability\": 0.0275778660504259, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10498, \"tn\": 7001, \"fp\": 1048, \"fn\": 1526, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8730871590153028, \"tn_rate\": 0.8697974903714747, \"fp_rate\": 0.13020250962852528, \"fn_rate\": 0.12691284098469727, \"precision\": 0.9092326346786765, \"recall\": 0.8730871590153028, \"specificity\": 0.8697974903714747, \"npv\": 0.8210390524217193, \"accuracy\": 0.8717680466298012, \"f1\": 0.8907933814170556, \"f2\": 0.8800845042084438, \"f0_5\": 0.9017660802638813, \"p4\": 0.867142624014486, \"phi\": 0.7365511701359709}, {\"truth_threshold\": -5.12, \"match_probability\": 0.027952077928310608, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10496, \"tn\": 7002, \"fp\": 1047, \"fn\": 1528, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8729208250166334, \"tn_rate\": 0.8699217294073798, \"fp_rate\": 0.1300782705926202, \"fn_rate\": 0.1270791749833666, \"precision\": 0.9092956770337001, \"recall\": 0.8729208250166334, \"specificity\": 0.8699217294073798, \"npv\": 0.8208675263774912, \"accuracy\": 0.8717182284660987, \"f1\": 0.8907370475665125, \"f2\": 0.879961099280672, \"f0_5\": 0.9017801910784247, \"p4\": 0.8670989569108593, \"phi\": 0.7364755930568165}, {\"truth_threshold\": -5.1000000000000005, \"match_probability\": 0.028331219653427598, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10490, \"tn\": 7002, \"fp\": 1047, \"fn\": 1534, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8724218230206254, \"tn_rate\": 0.8699217294073798, \"fp_rate\": 0.1300782705926202, \"fn_rate\": 0.1275781769793746, \"precision\": 0.9092485048106094, \"recall\": 0.8724218230206254, \"specificity\": 0.8699217294073798, \"npv\": 0.82029053420806, \"accuracy\": 0.8714193194838838, \"f1\": 0.8904545647468274, \"f2\": 0.8795465597907199, \"f0_5\": 0.9016365261637901, \"p4\": 0.8668041033404107, \"phi\": 0.7359134472613149}, {\"truth_threshold\": -5.08, \"match_probability\": 0.02871535213317462, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10489, \"tn\": 7002, \"fp\": 1047, \"fn\": 1535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8723386560212908, \"tn_rate\": 0.8699217294073798, \"fp_rate\": 0.1300782705926202, \"fn_rate\": 0.12766134397870924, \"precision\": 0.9092406380027739, \"recall\": 0.8723386560212908, \"specificity\": 0.8699217294073798, \"npv\": 0.8201944476982547, \"accuracy\": 0.8713695013201813, \"f1\": 0.8904074702886248, \"f2\": 0.879477461765495, \"f0_5\": 0.9016125704854903, \"p4\": 0.8667549656931911, \"phi\": 0.7358197930591707}, {\"truth_threshold\": -5.0600000000000005, \"match_probability\": 0.029104536917218708, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10475, \"tn\": 7003, \"fp\": 1046, \"fn\": 1549, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8711743180306054, \"tn_rate\": 0.8700459684432849, \"fp_rate\": 0.12995403155671512, \"fn_rate\": 0.12882568196939453, \"precision\": 0.9092092700286434, \"recall\": 0.8711743180306054, \"specificity\": 0.8700459684432849, \"npv\": 0.8188727782974743, \"accuracy\": 0.870721865192049, \"f1\": 0.8897855170949246, \"f2\": 0.8785245819145546, \"f0_5\": 0.9013388862118813, \"p4\": 0.8661217858339268, \"phi\": 0.7346217968701866}, {\"truth_threshold\": -5.04, \"match_probability\": 0.029498836201196473, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10464, \"tn\": 7176, \"fp\": 873, \"fn\": 1560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8702594810379242, \"tn_rate\": 0.8915393216548639, \"fp_rate\": 0.10846067834513604, \"fn_rate\": 0.12974051896207583, \"precision\": 0.9229955014554115, \"recall\": 0.8702594810379242, \"specificity\": 0.8915393216548639, \"npv\": 0.8214285714285714, \"accuracy\": 0.8787924077118517, \"f1\": 0.8958520611275202, \"f2\": 0.8803190146888092, \"f0_5\": 0.9119431081363731, \"p4\": 0.8749751716381768, \"phi\": 0.753061330449723}, {\"truth_threshold\": -5.0200000000000005, \"match_probability\": 0.02989831283034073, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10461, \"tn\": 7176, \"fp\": 873, \"fn\": 1563, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8700099800399201, \"tn_rate\": 0.8915393216548639, \"fp_rate\": 0.10846067834513604, \"fn_rate\": 0.12999001996007983, \"precision\": 0.9229751191106406, \"recall\": 0.8700099800399201, \"specificity\": 0.8915393216548639, \"npv\": 0.8211465842773773, \"accuracy\": 0.8786429532207443, \"f1\": 0.8957102491651683, \"f2\": 0.8801110550227158, \"f0_5\": 0.9118723849372385, \"p4\": 0.8748275313417047, \"phi\": 0.7527850713125748}, {\"truth_threshold\": -5.0, \"match_probability\": 0.030303030303030304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10457, \"tn\": 7176, \"fp\": 873, \"fn\": 1567, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8696773120425815, \"tn_rate\": 0.8915393216548639, \"fp_rate\": 0.10846067834513604, \"fn_rate\": 0.1303226879574185, \"precision\": 0.9229479258605472, \"recall\": 0.8696773120425815, \"specificity\": 0.8915393216548639, \"npv\": 0.8207709024362347, \"accuracy\": 0.8784436805659344, \"f1\": 0.8955211098741115, \"f2\": 0.8798337428061791, \"f0_5\": 0.9117780412946429, \"p4\": 0.8746306947671723, \"phi\": 0.7524168677624691}, {\"truth_threshold\": -4.98, \"match_probability\": 0.03071305277425868, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10457, \"tn\": 7178, \"fp\": 871, \"fn\": 1567, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8696773120425815, \"tn_rate\": 0.8917877997266741, \"fp_rate\": 0.10821220027332588, \"fn_rate\": 0.1303226879574185, \"precision\": 0.9231108757062146, \"recall\": 0.8696773120425815, \"specificity\": 0.8917877997266741, \"npv\": 0.8208118925100057, \"accuracy\": 0.8785433168933393, \"f1\": 0.8955978074683111, \"f2\": 0.8798633548734518, \"f0_5\": 0.9119052602204548, \"p4\": 0.874738690355917, \"phi\": 0.7526428328546405}, {\"truth_threshold\": -4.96, \"match_probability\": 0.031128445059018316, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10456, \"tn\": 7181, \"fp\": 868, \"fn\": 1568, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8695941450432468, \"tn_rate\": 0.8921605168343893, \"fp_rate\": 0.10783948316561064, \"fn_rate\": 0.13040585495675316, \"precision\": 0.9233486400565172, \"recall\": 0.8695941450432468, \"specificity\": 0.8921605168343893, \"npv\": 0.820779517659161, \"accuracy\": 0.8786429532207443, \"f1\": 0.8956655816344012, \"f2\": 0.879838438236284, \"f0_5\": 0.9120725750174459, \"p4\": 0.8748514499815899, \"phi\": 0.7528898280454683}, {\"truth_threshold\": -4.94, \"match_probability\": 0.03154927263559596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10446, \"tn\": 7183, \"fp\": 866, \"fn\": 1578, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8687624750499002, \"tn_rate\": 0.8924089949061995, \"fp_rate\": 0.10759100509380047, \"fn_rate\": 0.1312375249500998, \"precision\": 0.9234441301272984, \"recall\": 0.8687624750499002, \"specificity\": 0.8924089949061995, \"npv\": 0.8198835749343683, \"accuracy\": 0.8782444079111243, \"f1\": 0.8952691121014741, \"f2\": 0.8791745219499058, \"f0_5\": 0.9119639614471294, \"p4\": 0.8744673747618974, \"phi\": 0.7521966776853531}, {\"truth_threshold\": -4.92, \"match_probability\": 0.03197560164877564, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10439, \"tn\": 7184, \"fp\": 865, \"fn\": 1585, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8681803060545575, \"tn_rate\": 0.8925332339421046, \"fp_rate\": 0.10746676605789539, \"fn_rate\": 0.13181969394544246, \"precision\": 0.9234784147204529, \"recall\": 0.8681803060545575, \"specificity\": 0.8925332339421046, \"npv\": 0.8192496293762117, \"accuracy\": 0.8779454989289095, \"f1\": 0.8949759945130316, \"f2\": 0.8787037037037037, \"f0_5\": 0.9118623340321453, \"p4\": 0.8741769865850546, \"phi\": 0.7516670005258783}, {\"truth_threshold\": -4.88, \"match_probability\": 0.032845031915098126, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10436, \"tn\": 7184, \"fp\": 865, \"fn\": 1588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8679308050565535, \"tn_rate\": 0.8925332339421046, \"fp_rate\": 0.10746676605789539, \"fn_rate\": 0.13206919494344643, \"precision\": 0.9234581010530042, \"recall\": 0.8679308050565535, \"specificity\": 0.8925332339421046, \"npv\": 0.8189694482444141, \"accuracy\": 0.877796044437802, \"f1\": 0.894833869239014, \"f2\": 0.8784955469131438, \"f0_5\": 0.9117914307681555, \"p4\": 0.8740294227325243, \"phi\": 0.7513916773578145}, {\"truth_threshold\": -4.86, \"match_probability\": 0.0332882688177396, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10430, \"tn\": 7184, \"fp\": 865, \"fn\": 1594, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8674318030605456, \"tn_rate\": 0.8925332339421046, \"fp_rate\": 0.10746676605789539, \"fn_rate\": 0.13256819693945443, \"precision\": 0.9234174413457282, \"recall\": 0.8674318030605456, \"specificity\": 0.8925332339421046, \"npv\": 0.8184096605149237, \"accuracy\": 0.877497135455587, \"f1\": 0.8945495089840902, \"f2\": 0.8780791702446499, \"f0_5\": 0.9116495349975526, \"p4\": 0.8737343275271063, \"phi\": 0.7508413020839351}, {\"truth_threshold\": -4.84, \"match_probability\": 0.03373727846166985, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10430, \"tn\": 7186, \"fp\": 863, \"fn\": 1594, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8674318030605456, \"tn_rate\": 0.8927817120139148, \"fp_rate\": 0.10721828798608522, \"fn_rate\": 0.13256819693945443, \"precision\": 0.92358097936775, \"recall\": 0.8674318030605456, \"specificity\": 0.8927817120139148, \"npv\": 0.8184510250569476, \"accuracy\": 0.8775967717829921, \"f1\": 0.8946262383668568, \"f2\": 0.8781087406758827, \"f0_5\": 0.9117770473459682, \"p4\": 0.8738422374247364, \"phi\": 0.7510677455339477}, {\"truth_threshold\": -4.82, \"match_probability\": 0.034192130368662726, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10426, \"tn\": 7187, \"fp\": 862, \"fn\": 1598, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8670991350632069, \"tn_rate\": 0.8929059510498198, \"fp_rate\": 0.10709404895018014, \"fn_rate\": 0.13290086493679307, \"precision\": 0.9236357193479802, \"recall\": 0.8670991350632069, \"specificity\": 0.8929059510498198, \"npv\": 0.8180990324416619, \"accuracy\": 0.8774473172918846, \"f1\": 0.8944749485243652, \"f2\": 0.87784588441331, \"f0_5\": 0.9117461872114174, \"p4\": 0.873699473892537, \"phi\": 0.750814347163739}, {\"truth_threshold\": -4.8, \"match_probability\": 0.034652894744021626, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10425, \"tn\": 7187, \"fp\": 862, \"fn\": 1599, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8670159680638723, \"tn_rate\": 0.8929059510498198, \"fp_rate\": 0.10709404895018014, \"fn_rate\": 0.13298403193612773, \"precision\": 0.9236289536635067, \"recall\": 0.8670159680638723, \"specificity\": 0.8929059510498198, \"npv\": 0.8180059185067152, \"accuracy\": 0.8773974991281821, \"f1\": 0.8944275234867659, \"f2\": 0.8777764680127309, \"f0_5\": 0.9117225215140279, \"p4\": 0.8736502984867419, \"phi\": 0.7507227153491712}, {\"truth_threshold\": -4.78, \"match_probability\": 0.03511964247901206, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10425, \"tn\": 7188, \"fp\": 861, \"fn\": 1599, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8670159680638723, \"tn_rate\": 0.8930301900857249, \"fp_rate\": 0.10696980991427507, \"fn_rate\": 0.13298403193612773, \"precision\": 0.9237107921318448, \"recall\": 0.8670159680638723, \"specificity\": 0.8930301900857249, \"npv\": 0.8180266302492318, \"accuracy\": 0.8774473172918846, \"f1\": 0.8944658944658944, \"f2\": 0.877791249873699, \"f0_5\": 0.9117863140218304, \"p4\": 0.8737042421787568, \"phi\": 0.7508359862423499}, {\"truth_threshold\": -4.76, \"match_probability\": 0.0355924451531659, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10420, \"tn\": 7188, \"fp\": 861, \"fn\": 1604, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.866600133067199, \"tn_rate\": 0.8930301900857249, \"fp_rate\": 0.10696980991427507, \"fn_rate\": 0.13339986693280106, \"precision\": 0.9236769789912241, \"recall\": 0.866600133067199, \"specificity\": 0.8930301900857249, \"npv\": 0.8175614194722475, \"accuracy\": 0.8771982264733722, \"f1\": 0.8942287062862047, \"f2\": 0.877444128197787, \"f0_5\": 0.9116679498845104, \"p4\": 0.8734583799466098, \"phi\": 0.7503780141756305}, {\"truth_threshold\": -4.74, \"match_probability\": 0.03607137503645171, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10415, \"tn\": 7205, \"fp\": 844, \"fn\": 1609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8661842980705257, \"tn_rate\": 0.8951422536961113, \"fp_rate\": 0.10485774630388868, \"fn_rate\": 0.1338157019294744, \"precision\": 0.925037747579714, \"recall\": 0.8661842980705257, \"specificity\": 0.8951422536961113, \"npv\": 0.8174495121397777, \"accuracy\": 0.877796044437802, \"f1\": 0.8946441609758192, \"f2\": 0.8773481593800017, \"f0_5\": 0.9126358219418156, \"p4\": 0.8741289879474228, \"phi\": 0.7518479002916082}, {\"truth_threshold\": -4.72, \"match_probability\": 0.036556505091306896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10415, \"tn\": 7206, \"fp\": 843, \"fn\": 1609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8661842980705257, \"tn_rate\": 0.8952664927320164, \"fp_rate\": 0.1047335072679836, \"fn_rate\": 0.1338157019294744, \"precision\": 0.925119914727305, \"recall\": 0.8661842980705257, \"specificity\": 0.8952664927320164, \"npv\": 0.81747022121384, \"accuracy\": 0.8778458626015045, \"f1\": 0.8946825874065802, \"f2\": 0.8773629409980793, \"f0_5\": 0.9126998037016265, \"p4\": 0.8741828671224043, \"phi\": 0.7519613329517364}, {\"truth_threshold\": -4.7, \"match_probability\": 0.03704790897452556, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10407, \"tn\": 7206, \"fp\": 843, \"fn\": 1617, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8655189620758483, \"tn_rate\": 0.8952664927320164, \"fp_rate\": 0.1047335072679836, \"fn_rate\": 0.1344810379241517, \"precision\": 0.9250666666666667, \"recall\": 0.8655189620758483, \"specificity\": 0.8952664927320164, \"npv\": 0.8167290037402244, \"accuracy\": 0.8774473172918846, \"f1\": 0.894302655323537, \"f2\": 0.8768071984632494, \"f0_5\": 0.9125105218855218, \"p4\": 0.8737895068766632, \"phi\": 0.7512305614689885}, {\"truth_threshold\": -4.68, \"match_probability\": 0.037545661038997695, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10402, \"tn\": 7206, \"fp\": 843, \"fn\": 1622, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.865103127079175, \"tn_rate\": 0.8952664927320164, \"fp_rate\": 0.1047335072679836, \"fn_rate\": 0.13489687292082503, \"precision\": 0.9250333481547355, \"recall\": 0.865103127079175, \"specificity\": 0.8952664927320164, \"npv\": 0.8162664250113276, \"accuracy\": 0.8771982264733722, \"f1\": 0.8940650651080837, \"f2\": 0.8764597832864293, \"f0_5\": 0.9123921128341871, \"p4\": 0.8735436949267351, \"phi\": 0.7507741515851499}, {\"truth_threshold\": -4.64, \"match_probability\": 0.03856051061308806, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10401, \"tn\": 7207, \"fp\": 842, \"fn\": 1623, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8650199600798403, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.13498003992015967, \"precision\": 0.925108956684159, \"recall\": 0.8650199600798403, \"specificity\": 0.8953907317679215, \"npv\": 0.8161947904869762, \"accuracy\": 0.8771982264733722, \"f1\": 0.8940559590836807, \"f2\": 0.8764050624378571, \"f0_5\": 0.9124324514000982, \"p4\": 0.8735484032763796, \"phi\": 0.750796440625381}, {\"truth_threshold\": -4.62, \"match_probability\": 0.03907776032242, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10399, \"tn\": 7207, \"fp\": 842, \"fn\": 1625, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.864853626081171, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.135146373918829, \"precision\": 0.9250956320612045, \"recall\": 0.864853626081171, \"specificity\": 0.8953907317679215, \"npv\": 0.816009963768116, \"accuracy\": 0.8770985901459672, \"f1\": 0.8939608854502471, \"f2\": 0.8762660734448995, \"f0_5\": 0.912385063522145, \"p4\": 0.873450087786313, \"phi\": 0.7506139805516754}, {\"truth_threshold\": -4.6000000000000005, \"match_probability\": 0.039601662614779175, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10396, \"tn\": 7207, \"fp\": 842, \"fn\": 1628, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.864604125083167, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.135395874916833, \"precision\": 0.9250756362342054, \"recall\": 0.864604125083167, \"specificity\": 0.8953907317679215, \"npv\": 0.8157328805885682, \"accuracy\": 0.8769491356548598, \"f1\": 0.8938182443470037, \"f2\": 0.8760575723868271, \"f0_5\": 0.9123139567537208, \"p4\": 0.8733026233141058, \"phi\": 0.7503403645658355}, {\"truth_threshold\": -4.58, \"match_probability\": 0.0401322953440168, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10391, \"tn\": 7207, \"fp\": 842, \"fn\": 1633, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8641882900864937, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.13581170991350633, \"precision\": 0.9250422861212498, \"recall\": 0.8641882900864937, \"specificity\": 0.8953907317679215, \"npv\": 0.8152714932126697, \"accuracy\": 0.8767000448363473, \"f1\": 0.8935804273982026, \"f2\": 0.8757100237657807, \"f0_5\": 0.912195378888967, \"p4\": 0.8730568725134965, \"phi\": 0.7498845353598139}, {\"truth_threshold\": -4.5600000000000005, \"match_probability\": 0.04066973706707255, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10388, \"tn\": 7207, \"fp\": 842, \"fn\": 1636, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8639387890884896, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.1360612109115103, \"precision\": 0.9250222617987534, \"recall\": 0.8639387890884896, \"specificity\": 0.8953907317679215, \"npv\": 0.8149949112292209, \"accuracy\": 0.8765505903452399, \"f1\": 0.893437688139675, \"f2\": 0.8755014664733843, \"f0_5\": 0.9121241921888171, \"p4\": 0.8729094359932962, \"phi\": 0.7496111561475373}, {\"truth_threshold\": -4.54, \"match_probability\": 0.041214067044512546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10383, \"tn\": 7207, \"fp\": 842, \"fn\": 1641, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8635229540918163, \"tn_rate\": 0.8953907317679215, \"fp_rate\": 0.10460926823207851, \"fn_rate\": 0.13647704590818363, \"precision\": 0.924988864142539, \"recall\": 0.8635229540918163, \"specificity\": 0.8953907317679215, \"npv\": 0.8145343580470162, \"accuracy\": 0.8763014995267274, \"f1\": 0.8931997075143017, \"f2\": 0.8751538241095059, \"f0_5\": 0.9120054809922001, \"p4\": 0.8726637316641522, \"phi\": 0.7491557210158281}, {\"truth_threshold\": -4.5200000000000005, \"match_probability\": 0.041765365240871495, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10377, \"tn\": 7210, \"fp\": 839, \"fn\": 1647, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8630239520958084, \"tn_rate\": 0.8957634488756367, \"fp_rate\": 0.10423655112436328, \"fn_rate\": 0.13697604790419163, \"precision\": 0.9251961483594865, \"recall\": 0.8630239520958084, \"specificity\": 0.8957634488756367, \"npv\": 0.814045387828836, \"accuracy\": 0.8761520450356199, \"f1\": 0.8930292598967298, \"f2\": 0.8747808200701376, \"f0_5\": 0.9120552664885389, \"p4\": 0.8725304616295257, \"phi\": 0.7489507086147096}, {\"truth_threshold\": -4.5, \"match_probability\": 0.04232371232479359, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10376, \"tn\": 7211, \"fp\": 838, \"fn\": 1648, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8629407850964738, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.1370592149035263, \"precision\": 0.9252719814517567, \"recall\": 0.8629407850964738, \"specificity\": 0.8958876879115418, \"npv\": 0.8139744892200023, \"accuracy\": 0.8761520450356199, \"f1\": 0.8930200533608744, \"f2\": 0.8747260158489294, \"f0_5\": 0.9120956399437412, \"p4\": 0.8725351678774859, \"phi\": 0.7489734778457884}, {\"truth_threshold\": -4.48, \"match_probability\": 0.04288918966896465, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10370, \"tn\": 7211, \"fp\": 838, \"fn\": 1654, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8624417831004657, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.13755821689953426, \"precision\": 0.925231977159172, \"recall\": 0.8624417831004657, \"specificity\": 0.8958876879115418, \"npv\": 0.813423575860124, \"accuracy\": 0.8758531360534051, \"f1\": 0.8927341597796143, \"f2\": 0.8743086469715365, \"f0_5\": 0.9119530040804841, \"p4\": 0.8722403939772894, \"phi\": 0.7484278687897751}, {\"truth_threshold\": -4.46, \"match_probability\": 0.0434618793498302, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10365, \"tn\": 7211, \"fp\": 838, \"fn\": 1659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8620259481037924, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.1379740518962076, \"precision\": 0.9251986075158439, \"recall\": 0.8620259481037924, \"specificity\": 0.8958876879115418, \"npv\": 0.8129650507328072, \"accuracy\": 0.8756040452348927, \"f1\": 0.8924958022990486, \"f2\": 0.8739607750552286, \"f0_5\": 0.911834048842283, \"p4\": 0.8719947805857661, \"phi\": 0.7479734635651293}, {\"truth_threshold\": -4.44, \"match_probability\": 0.04404186414709147, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10361, \"tn\": 7211, \"fp\": 838, \"fn\": 1663, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8616932801064537, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.13830671989354623, \"precision\": 0.9251718903473525, \"recall\": 0.8616932801064537, \"specificity\": 0.8958876879115418, \"npv\": 0.8125986026594546, \"accuracy\": 0.8754047725800826, \"f1\": 0.8923050424148473, \"f2\": 0.873682435281221, \"f0_5\": 0.9117388243576205, \"p4\": 0.8717983104423352, \"phi\": 0.7476101151450606}, {\"truth_threshold\": -4.42, \"match_probability\": 0.04462922754297395, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10359, \"tn\": 7211, \"fp\": 838, \"fn\": 1665, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8615269461077845, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.13847305389221556, \"precision\": 0.9251585246048049, \"recall\": 0.8615269461077845, \"specificity\": 0.8958876879115418, \"npv\": 0.812415502478594, \"accuracy\": 0.8753051362526777, \"f1\": 0.8922096378278283, \"f2\": 0.8735432513112846, \"f0_5\": 0.9116911920016898, \"p4\": 0.8717000822113299, \"phi\": 0.7474284994469593}, {\"truth_threshold\": -4.4, \"match_probability\": 0.04522405372126023, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10356, \"tn\": 7211, \"fp\": 838, \"fn\": 1668, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8612774451097804, \"tn_rate\": 0.8958876879115418, \"fp_rate\": 0.1041123120884582, \"fn_rate\": 0.13872255489021956, \"precision\": 0.9251384670359121, \"recall\": 0.8612774451097804, \"specificity\": 0.8958876879115418, \"npv\": 0.812141006870143, \"accuracy\": 0.8751556817615702, \"f1\": 0.8920665001292101, \"f2\": 0.8733344577500421, \"f0_5\": 0.9116197183098591, \"p4\": 0.8715527483994564, \"phi\": 0.7471561489635006}, {\"truth_threshold\": -4.38, \"match_probability\": 0.04582642756608153, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10355, \"tn\": 7215, \"fp\": 834, \"fn\": 1669, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8611942781104458, \"tn_rate\": 0.8963846440551622, \"fp_rate\": 0.10361535594483787, \"fn_rate\": 0.13880572188955423, \"precision\": 0.9254625078201806, \"recall\": 0.8611942781104458, \"specificity\": 0.8963846440551622, \"npv\": 0.8121341737955876, \"accuracy\": 0.8753051362526777, \"f1\": 0.8921724895532676, \"f2\": 0.8733237749852408, \"f0_5\": 0.9118527650581191, \"p4\": 0.8717189082494784, \"phi\": 0.7475210358587928}, {\"truth_threshold\": -4.36, \"match_probability\": 0.046436434660459415, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10350, \"tn\": 7215, \"fp\": 834, \"fn\": 1674, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8607784431137725, \"tn_rate\": 0.8963846440551622, \"fp_rate\": 0.10361535594483787, \"fn_rate\": 0.13922155688622753, \"precision\": 0.9254291845493562, \"recall\": 0.8607784431137725, \"specificity\": 0.8963846440551622, \"npv\": 0.8116773540330746, \"accuracy\": 0.8750560454341653, \"f1\": 0.8919338159255429, \"f2\": 0.8729757085020243, \"f0_5\": 0.9117336152219874, \"p4\": 0.8714733674020804, \"phi\": 0.7470675085462363}, {\"truth_threshold\": -4.34, \"match_probability\": 0.047054161284591715, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10349, \"tn\": 7215, \"fp\": 834, \"fn\": 1675, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8606952761144377, \"tn_rate\": 0.8963846440551622, \"fp_rate\": 0.10361535594483787, \"fn_rate\": 0.1393047238855622, \"precision\": 0.9254225163194134, \"recall\": 0.8606952761144377, \"specificity\": 0.8963846440551622, \"npv\": 0.811586051743532, \"accuracy\": 0.8750062272704628, \"f1\": 0.891886068858534, \"f2\": 0.8729060881593819, \"f0_5\": 0.9117097751779547, \"p4\": 0.8714242626257783, \"phi\": 0.7469768322199865}, {\"truth_threshold\": -4.32, \"match_probability\": 0.04767969441387431, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10345, \"tn\": 7216, \"fp\": 833, \"fn\": 1679, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8603626081170991, \"tn_rate\": 0.8965088830910672, \"fp_rate\": 0.10349111690893278, \"fn_rate\": 0.13963739188290086, \"precision\": 0.9254786187153337, \"recall\": 0.8603626081170991, \"specificity\": 0.8965088830910672, \"npv\": 0.8112422709387296, \"accuracy\": 0.8748567727793554, \"f1\": 0.8917334712524783, \"f2\": 0.8726423052265749, \"f0_5\": 0.9116786520022561, \"p4\": 0.8712816576069132, \"phi\": 0.7467282225526753}, {\"truth_threshold\": -4.3, \"match_probability\": 0.04831312171665215, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10343, \"tn\": 7374, \"fp\": 675, \"fn\": 1681, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8601962741184298, \"tn_rate\": 0.9161386507640701, \"fp_rate\": 0.08386134923592993, \"fn_rate\": 0.1398037258815702, \"precision\": 0.938736612815393, \"recall\": 0.8601962741184298, \"specificity\": 0.9161386507640701, \"npv\": 0.8143567090005521, \"accuracy\": 0.8826284063169432, \"f1\": 0.8977519312559674, \"f2\": 0.8748350644517373, \"f0_5\": 0.9219017398745009, \"p4\": 0.8796452137282921, \"phi\": 0.7646258218380374}, {\"truth_threshold\": -4.28, \"match_probability\": 0.04895453155169113, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10342, \"tn\": 7374, \"fp\": 675, \"fn\": 1682, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8601131071190952, \"tn_rate\": 0.9161386507640701, \"fp_rate\": 0.08386134923592993, \"fn_rate\": 0.13988689288090486, \"precision\": 0.9387310520105292, \"recall\": 0.8601131071190952, \"specificity\": 0.9161386507640701, \"npv\": 0.8142667844522968, \"accuracy\": 0.8825785881532406, \"f1\": 0.8977040927043097, \"f2\": 0.8747652800568403, \"f0_5\": 0.9218783427226699, \"p4\": 0.8795960178618806, \"phi\": 0.7645363917018527}, {\"truth_threshold\": -4.26, \"match_probability\": 0.04960401296536411, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10339, \"tn\": 7374, \"fp\": 675, \"fn\": 1685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8598636061210911, \"tn_rate\": 0.9161386507640701, \"fp_rate\": 0.08386134923592993, \"fn_rate\": 0.14013639387890886, \"precision\": 0.9387143635373162, \"recall\": 0.8598636061210911, \"specificity\": 0.9161386507640701, \"npv\": 0.8139971299260405, \"accuracy\": 0.8824291336621332, \"f1\": 0.8975605521312614, \"f2\": 0.874555912705126, \"f0_5\": 0.9218081312410842, \"p4\": 0.8794484366306713, \"phi\": 0.7642681582474603}, {\"truth_threshold\": -4.24, \"match_probability\": 0.05026165568854217, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10335, \"tn\": 7376, \"fp\": 673, \"fn\": 1689, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8595309381237525, \"tn_rate\": 0.9163871288358802, \"fp_rate\": 0.08361287116411976, \"fn_rate\": 0.1404690618762475, \"precision\": 0.9388626453488372, \"recall\": 0.8595309381237525, \"specificity\": 0.9163871288358802, \"npv\": 0.8136789851075565, \"accuracy\": 0.8823294973347282, \"f1\": 0.897447030218826, \"f2\": 0.8743063075257174, \"f0_5\": 0.9218460111317254, \"p4\": 0.8793582963933192, \"phi\": 0.7641404630108102}, {\"truth_threshold\": -4.22, \"match_probability\": 0.05092755013318443, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10332, \"tn\": 7376, \"fp\": 673, \"fn\": 1692, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8592814371257484, \"tn_rate\": 0.9163871288358802, \"fp_rate\": 0.08361287116411976, \"fn_rate\": 0.1407185628742515, \"precision\": 0.9388459791004089, \"recall\": 0.8592814371257484, \"specificity\": 0.9163871288358802, \"npv\": 0.8134097926775474, \"accuracy\": 0.8821800428436208, \"f1\": 0.8973034000607929, \"f2\": 0.8740968849934857, \"f0_5\": 0.9217757476268646, \"p4\": 0.879210733775882, \"phi\": 0.7638724734740516}, {\"truth_threshold\": -4.2, \"match_probability\": 0.05160178738861727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10313, \"tn\": 7376, \"fp\": 673, \"fn\": 1711, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8577012641383899, \"tn_rate\": 0.9163871288358802, \"fp_rate\": 0.08361287116411976, \"fn_rate\": 0.14229873586161013, \"precision\": 0.9387402148188604, \"recall\": 0.8577012641383899, \"specificity\": 0.9163871288358802, \"npv\": 0.8117090348850006, \"accuracy\": 0.8812334977332735, \"f1\": 0.8963928726640591, \"f2\": 0.8727700484072983, \"f0_5\": 0.9213300457404231, \"p4\": 0.878276389976314, \"phi\": 0.762177179999512}, {\"truth_threshold\": -4.18, \"match_probability\": 0.052284459217495936, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10304, \"tn\": 7376, \"fp\": 673, \"fn\": 1720, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8569527611443779, \"tn_rate\": 0.9163871288358802, \"fp_rate\": 0.08361287116411976, \"fn_rate\": 0.1430472388556221, \"precision\": 0.9386899881570556, \"recall\": 0.8569527611443779, \"specificity\": 0.9163871288358802, \"npv\": 0.810905892700088, \"accuracy\": 0.8807851342599512, \"f1\": 0.8959610451719491, \"f2\": 0.8721412489631473, \"f0_5\": 0.9211185010369735, \"p4\": 0.877833937426475, \"phi\": 0.7613753319038634}, {\"truth_threshold\": -4.16, \"match_probability\": 0.05297565805143919, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10299, \"tn\": 7376, \"fp\": 673, \"fn\": 1725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8565369261477046, \"tn_rate\": 0.9163871288358802, \"fp_rate\": 0.08361287116411976, \"fn_rate\": 0.1434630738522954, \"precision\": 0.9386620488516223, \"recall\": 0.8565369261477046, \"specificity\": 0.9163871288358802, \"npv\": 0.8104603889682452, \"accuracy\": 0.8805360434414388, \"f1\": 0.8957209949556445, \"f2\": 0.871791833141464, \"f0_5\": 0.9210008584919158, \"p4\": 0.8775881666632809, \"phi\": 0.7609301888602662}, {\"truth_threshold\": -4.14, \"match_probability\": 0.05367547698633007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10299, \"tn\": 7377, \"fp\": 672, \"fn\": 1725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8565369261477046, \"tn_rate\": 0.9165113678717853, \"fp_rate\": 0.08348863212821468, \"fn_rate\": 0.1434630738522954, \"precision\": 0.9387476073284112, \"recall\": 0.8565369261477046, \"specificity\": 0.9165113678717853, \"npv\": 0.8104812129202373, \"accuracy\": 0.8805858616051412, \"f1\": 0.8957599478147423, \"f2\": 0.8718065925135863, \"f0_5\": 0.9210667525220004, \"p4\": 0.8776414503703941, \"phi\": 0.7610453740240807}, {\"truth_threshold\": -4.12, \"match_probability\": 0.05438400977727288, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10295, \"tn\": 7378, \"fp\": 671, \"fn\": 1729, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8562042581503659, \"tn_rate\": 0.9166356069076904, \"fp_rate\": 0.0833643930923096, \"fn_rate\": 0.14379574184963406, \"precision\": 0.9388108699616998, \"recall\": 0.8562042581503659, \"specificity\": 0.9166356069076904, \"npv\": 0.8101460415065335, \"accuracy\": 0.8804364071140338, \"f1\": 0.8956067855589387, \"f2\": 0.8715417696657749, \"f0_5\": 0.9210385055825938, \"p4\": 0.8774981281836907, \"phi\": 0.7608046782147229}, {\"truth_threshold\": -4.08, \"match_probability\": 0.05582759521111378, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10292, \"tn\": 7379, \"fp\": 670, \"fn\": 1732, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8559547571523619, \"tn_rate\": 0.9167598459435955, \"fp_rate\": 0.08324015405640452, \"fn_rate\": 0.14404524284763806, \"precision\": 0.9388797664659734, \"recall\": 0.8559547571523619, \"specificity\": 0.9167598459435955, \"npv\": 0.8099001207331796, \"accuracy\": 0.8803367707866288, \"f1\": 0.8955016096754547, \"f2\": 0.8713468116089268, \"f0_5\": 0.9210337915234822, \"p4\": 0.8774039603111293, \"phi\": 0.7606531097309268}, {\"truth_threshold\": -4.0600000000000005, \"match_probability\": 0.05656283860997083, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10285, \"tn\": 7379, \"fp\": 670, \"fn\": 1739, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8553725881570193, \"tn_rate\": 0.9167598459435955, \"fp_rate\": 0.08324015405640452, \"fn_rate\": 0.1446274118429807, \"precision\": 0.9388407120036513, \"recall\": 0.8553725881570193, \"specificity\": 0.9167598459435955, \"npv\": 0.8092783505154639, \"accuracy\": 0.8799880436407114, \"f1\": 0.8951651507898516, \"f2\": 0.87085739445564, \"f0_5\": 0.9208688489363226, \"p4\": 0.8770599617185296, \"phi\": 0.7600309156474849}, {\"truth_threshold\": -4.04, \"match_probability\": 0.05730717736417426, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10276, \"tn\": 7380, \"fp\": 669, \"fn\": 1748, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8546240851630074, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.1453759148369927, \"precision\": 0.9388761991777067, \"recall\": 0.8546240851630074, \"specificity\": 0.9168840849795006, \"npv\": 0.8085013146362839, \"accuracy\": 0.8795894983310916, \"f1\": 0.8947712133745483, \"f2\": 0.8702427126911807, \"f0_5\": 0.9207225288509784, \"p4\": 0.8766710119000732, \"phi\": 0.7593469945211404}, {\"truth_threshold\": -4.0200000000000005, \"match_probability\": 0.0580607084366901, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10275, \"tn\": 7380, \"fp\": 669, \"fn\": 1749, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8545409181636726, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.14545908183632736, \"precision\": 0.9388706140350878, \"recall\": 0.8545409181636726, \"specificity\": 0.9168840849795006, \"npv\": 0.8084127505750903, \"accuracy\": 0.879539680167389, \"f1\": 0.894723092998955, \"f2\": 0.8701727642276422, \"f0_5\": 0.9206989247311828, \"p4\": 0.8766218818368222, \"phi\": 0.7592582379488864}, {\"truth_threshold\": -4.0, \"match_probability\": 0.058823529411764705, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10261, \"tn\": 7380, \"fp\": 669, \"fn\": 1763, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8533765801729873, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.14662341982701263, \"precision\": 0.9387923147301006, \"recall\": 0.8533765801729873, \"specificity\": 0.9168840849795006, \"npv\": 0.8071748878923767, \"accuracy\": 0.8788422258755543, \"f1\": 0.8940489675002178, \"f2\": 0.8691932368786637, \"f0_5\": 0.9203681113662457, \"p4\": 0.8759341667739711, \"phi\": 0.758016618336254}, {\"truth_threshold\": -3.98, \"match_probability\": 0.059595738487237926, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10258, \"tn\": 7380, \"fp\": 669, \"fn\": 1766, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8531270791749833, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.14687292082501663, \"precision\": 0.9387755102040817, \"recall\": 0.8531270791749833, \"specificity\": 0.9168840849795006, \"npv\": 0.8069101246446534, \"accuracy\": 0.8786927713844468, \"f1\": 0.8939044050368176, \"f2\": 0.8689832777053014, \"f0_5\": 0.9202971362951267, \"p4\": 0.8757868248490035, \"phi\": 0.7577507926641515}, {\"truth_threshold\": -3.96, \"match_probability\": 0.06037743446644346, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10255, \"tn\": 7380, \"fp\": 669, \"fn\": 1769, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8528775781769794, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.14712242182302063, \"precision\": 0.9387586964481874, \"recall\": 0.8528775781769794, \"specificity\": 0.9168840849795006, \"npv\": 0.806645535031151, \"accuracy\": 0.8785433168933393, \"f1\": 0.8937598047760154, \"f2\": 0.8687732971873942, \"f0_5\": 0.9202261306532663, \"p4\": 0.8756394919116018, \"phi\": 0.7574850499827791}, {\"truth_threshold\": -3.94, \"match_probability\": 0.061168716749686526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10249, \"tn\": 7380, \"fp\": 669, \"fn\": 1775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8523785761809713, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.1476214238190286, \"precision\": 0.93872504121634, \"recall\": 0.8523785761809713, \"specificity\": 0.9168840849795006, \"npv\": 0.8061168760240306, \"accuracy\": 0.8782444079111243, \"f1\": 0.8934704908028942, \"f2\": 0.8683532721049243, \"f0_5\": 0.9200840275782821, \"p4\": 0.8753448529208303, \"phi\": 0.75695381325428}, {\"truth_threshold\": -3.92, \"match_probability\": 0.061969685325289826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10245, \"tn\": 7380, \"fp\": 669, \"fn\": 1779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8520459081836327, \"tn_rate\": 0.9168840849795006, \"fp_rate\": 0.08311591502049943, \"fn_rate\": 0.14795409181636726, \"precision\": 0.9387025838372732, \"recall\": 0.8520459081836327, \"specificity\": 0.9168840849795006, \"npv\": 0.8057648214870619, \"accuracy\": 0.8780451352563144, \"f1\": 0.8932775307350248, \"f2\": 0.8680732079308592, \"f0_5\": 0.919989224137931, \"p4\": 0.8751484467779236, \"phi\": 0.7565998393379533}, {\"truth_threshold\": -3.9, \"match_probability\": 0.06278044076019877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10239, \"tn\": 7382, \"fp\": 667, \"fn\": 1785, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8515469061876247, \"tn_rate\": 0.9171325630513107, \"fp_rate\": 0.08286743694868928, \"fn_rate\": 0.14845309381237526, \"precision\": 0.9388410049514029, \"recall\": 0.8515469061876247, \"specificity\": 0.9171325630513107, \"npv\": 0.8052798080069815, \"accuracy\": 0.8778458626015045, \"f1\": 0.8930658525948539, \"f2\": 0.867682451442324, \"f0_5\": 0.9199791546866015, \"p4\": 0.8749603335476775, \"phi\": 0.7563004638068763}, {\"truth_threshold\": -3.88, \"match_probability\": 0.06360108419013638, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10238, \"tn\": 7382, \"fp\": 667, \"fn\": 1786, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8514637391882901, \"tn_rate\": 0.9171325630513107, \"fp_rate\": 0.08286743694868928, \"fn_rate\": 0.14853626081170992, \"precision\": 0.938835396607061, \"recall\": 0.8514637391882901, \"specificity\": 0.9171325630513107, \"npv\": 0.8051919720767888, \"accuracy\": 0.877796044437802, \"f1\": 0.8930175759954643, \"f2\": 0.8676124133489262, \"f0_5\": 0.9199554309539214, \"p4\": 0.8749112391333599, \"phi\": 0.7562120630719052}, {\"truth_threshold\": -3.84, \"match_probability\": 0.06527244235958121, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10234, \"tn\": 7385, \"fp\": 664, \"fn\": 1790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8511310711909514, \"tn_rate\": 0.917505280159026, \"fp_rate\": 0.08249471984097403, \"fn_rate\": 0.14886892880904856, \"precision\": 0.9390713892457332, \"recall\": 0.8511310711909514, \"specificity\": 0.917505280159026, \"npv\": 0.8049046321525886, \"accuracy\": 0.8777462262740995, \"f1\": 0.8929412791204956, \"f2\": 0.8673763433569516, \"f0_5\": 0.9200589758342923, \"p4\": 0.8748745396410573, \"phi\": 0.7562056694970481}, {\"truth_threshold\": -3.8200000000000003, \"match_probability\": 0.06612336211932712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10219, \"tn\": 7385, \"fp\": 664, \"fn\": 1805, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8498835662009314, \"tn_rate\": 0.917505280159026, \"fp_rate\": 0.08249471984097403, \"fn_rate\": 0.15011643379906853, \"precision\": 0.9389874115593126, \"recall\": 0.8498835662009314, \"specificity\": 0.917505280159026, \"npv\": 0.8035908596300326, \"accuracy\": 0.8769989538185623, \"f1\": 0.8922163530798446, \"f2\": 0.8663253022262161, \"f0_5\": 0.919702642378861, \"p4\": 0.8741382707759955, \"phi\": 0.7548816349997947}, {\"truth_threshold\": -3.8000000000000003, \"match_probability\": 0.06698457989158756, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10219, \"tn\": 7388, \"fp\": 661, \"fn\": 1805, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8498835662009314, \"tn_rate\": 0.9178779972667412, \"fp_rate\": 0.08212200273325879, \"fn_rate\": 0.15011643379906853, \"precision\": 0.9392463235294117, \"recall\": 0.8498835662009314, \"specificity\": 0.9178779972667412, \"npv\": 0.8036549548569564, \"accuracy\": 0.8771484083096697, \"f1\": 0.8923332169053441, \"f2\": 0.866369370591427, \"f0_5\": 0.9199013394786115, \"p4\": 0.8742978844752226, \"phi\": 0.7552291354258327}, {\"truth_threshold\": -3.7800000000000002, \"match_probability\": 0.06785619949188462, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10217, \"tn\": 7390, \"fp\": 659, \"fn\": 1807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8497172322022621, \"tn_rate\": 0.9181264753385514, \"fp_rate\": 0.08187352466144862, \"fn_rate\": 0.15028276779773786, \"precision\": 0.9394078705406399, \"recall\": 0.8497172322022621, \"specificity\": 0.9181264753385514, \"npv\": 0.8035228878982277, \"accuracy\": 0.8771484083096697, \"f1\": 0.8923144104803493, \"f2\": 0.8662585633860137, \"f0_5\": 0.9199863132113528, \"p4\": 0.8743061201884652, \"phi\": 0.75528452122747}, {\"truth_threshold\": -3.7600000000000002, \"match_probability\": 0.0687383252354679, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10216, \"tn\": 7392, \"fp\": 657, \"fn\": 1808, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8496340652029275, \"tn_rate\": 0.9183749534103616, \"fp_rate\": 0.08162504658963847, \"fn_rate\": 0.15036593479707253, \"precision\": 0.9395750942702106, \"recall\": 0.8496340652029275, \"specificity\": 0.9183749534103616, \"npv\": 0.8034782608695652, \"accuracy\": 0.8771982264733722, \"f1\": 0.8923439751932568, \"f2\": 0.8662178432735844, \"f0_5\": 0.9200951077166943, \"p4\": 0.8743634215987611, \"phi\": 0.7554281422201657}, {\"truth_threshold\": -3.74, \"match_probability\": 0.06963106192405447, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10214, \"tn\": 7392, \"fp\": 657, \"fn\": 1810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8494677312042581, \"tn_rate\": 0.9183749534103616, \"fp_rate\": 0.08162504658963847, \"fn_rate\": 0.15053226879574186, \"precision\": 0.9395639775549628, \"recall\": 0.8494677312042581, \"specificity\": 0.9183749534103616, \"npv\": 0.8033036296457292, \"accuracy\": 0.8770985901459672, \"f1\": 0.8922472155492466, \"f2\": 0.8660776366442248, \"f0_5\": 0.9200475607119695, \"p4\": 0.8742652657242272, \"phi\": 0.7552519167974472}, {\"truth_threshold\": -3.72, \"match_probability\": 0.07053451483204333, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10211, \"tn\": 7395, \"fp\": 654, \"fn\": 1813, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8492182302062542, \"tn_rate\": 0.9187476705180768, \"fp_rate\": 0.08125232948192322, \"fn_rate\": 0.15078176979374583, \"precision\": 0.9398067188219053, \"recall\": 0.8492182302062542, \"specificity\": 0.9187476705180768, \"npv\": 0.8031059947871416, \"accuracy\": 0.8770985901459672, \"f1\": 0.8922189698108262, \"f2\": 0.8659113651396686, \"f0_5\": 0.9201751856391032, \"p4\": 0.8742775773238742, \"phi\": 0.7553354428770893}, {\"truth_threshold\": -3.7, \"match_probability\": 0.07144878969219468, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10210, \"tn\": 7397, \"fp\": 652, \"fn\": 1814, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8491350632069194, \"tn_rate\": 0.918996148589887, \"fp_rate\": 0.08100385141011306, \"fn_rate\": 0.1508649367930805, \"precision\": 0.9399742220585527, \"recall\": 0.8491350632069194, \"specificity\": 0.918996148589887, \"npv\": 0.80306155683422, \"accuracy\": 0.8771484083096697, \"f1\": 0.8922485362230185, \"f2\": 0.8658706197632213, \"f0_5\": 0.9202841072973752, \"p4\": 0.8743348450342766, \"phi\": 0.7554793003446815}, {\"truth_threshold\": -3.68, \"match_probability\": 0.07237399268076448, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10208, \"tn\": 7398, \"fp\": 651, \"fn\": 1816, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8489687292082502, \"tn_rate\": 0.9191203876257921, \"fp_rate\": 0.08087961237420797, \"fn_rate\": 0.15103127079174983, \"precision\": 0.9400497283359426, \"recall\": 0.8489687292082502, \"specificity\": 0.9191203876257921, \"npv\": 0.8029086173214673, \"accuracy\": 0.8770985901459672, \"f1\": 0.8921907092601494, \"f2\": 0.8657450597913663, \"f0_5\": 0.9203029210241616, \"p4\": 0.874289860316227, \"phi\": 0.7554192343066736}, {\"truth_threshold\": -3.66, \"match_probability\": 0.07331023040208501, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10203, \"tn\": 7399, \"fp\": 650, \"fn\": 1821, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8485528942115769, \"tn_rate\": 0.9192446266616972, \"fp_rate\": 0.08075537333830289, \"fn_rate\": 0.15144710578842316, \"precision\": 0.9401087256979637, \"recall\": 0.8485528942115769, \"specificity\": 0.9192446266616972, \"npv\": 0.8024945770065076, \"accuracy\": 0.8768993174911572, \"f1\": 0.8919875857848494, \"f2\": 0.8654090824271828, \"f0_5\": 0.9202503788152103, \"p4\": 0.874097656842842, \"phi\": 0.7550953415356225}, {\"truth_threshold\": -3.64, \"match_probability\": 0.07425760987258186, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10199, \"tn\": 7399, \"fp\": 650, \"fn\": 1825, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8482202262142382, \"tn_rate\": 0.9192446266616972, \"fp_rate\": 0.08075537333830289, \"fn_rate\": 0.15177977378576182, \"precision\": 0.9400866439303162, \"recall\": 0.8482202262142382, \"specificity\": 0.9192446266616972, \"npv\": 0.8021465741543798, \"accuracy\": 0.8767000448363473, \"f1\": 0.8917938180387356, \"f2\": 0.865128509627619, \"f0_5\": 0.9201551786358715, \"p4\": 0.8739013806108125, \"phi\": 0.7547436038264936}, {\"truth_threshold\": -3.62, \"match_probability\": 0.0752162385042182, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10196, \"tn\": 7399, \"fp\": 650, \"fn\": 1828, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8479707252162342, \"tn_rate\": 0.9192446266616972, \"fp_rate\": 0.08075537333830289, \"fn_rate\": 0.1520292747837658, \"precision\": 0.9400700719159137, \"recall\": 0.8479707252162342, \"specificity\": 0.9192446266616972, \"npv\": 0.8018857700227593, \"accuracy\": 0.8765505903452399, \"f1\": 0.8916484477481417, \"f2\": 0.8649180550371551, \"f0_5\": 0.9200837424198671, \"p4\": 0.8737541833952142, \"phi\": 0.7544798952595527}, {\"truth_threshold\": -3.6, \"match_probability\": 0.0761862240873569, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10167, \"tn\": 7402, \"fp\": 647, \"fn\": 1857, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.845558882235529, \"tn_rate\": 0.9196173437694124, \"fp_rate\": 0.08038265623058766, \"fn_rate\": 0.15444111776447106, \"precision\": 0.9401701498058073, \"recall\": 0.845558882235529, \"specificity\": 0.9196173437694124, \"npv\": 0.7994383842747597, \"accuracy\": 0.8752553180889753, \"f1\": 0.8903581749715387, \"f2\": 0.8629264980478696, \"f0_5\": 0.9195911722141823, \"p4\": 0.8724911056057384, \"phi\": 0.7522837674899115}, {\"truth_threshold\": -3.58, \"match_probability\": 0.07716767477303127, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10157, \"tn\": 7402, \"fp\": 647, \"fn\": 1867, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8447272122421823, \"tn_rate\": 0.9196173437694124, \"fp_rate\": 0.08038265623058766, \"fn_rate\": 0.1552727877578177, \"precision\": 0.9401147723065532, \"recall\": 0.8447272122421823, \"specificity\": 0.9196173437694124, \"npv\": 0.7985758981551407, \"accuracy\": 0.8747571364519504, \"f1\": 0.8898720869108113, \"f2\": 0.8622241086587437, \"f0_5\": 0.9193519188993483, \"p4\": 0.8720007599809949, \"phi\": 0.7514081397908534}, {\"truth_threshold\": -3.56, \"match_probability\": 0.07816069905461534, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10153, \"tn\": 7402, \"fp\": 647, \"fn\": 1871, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8443945442448436, \"tn_rate\": 0.9196173437694124, \"fp_rate\": 0.08038265623058766, \"fn_rate\": 0.15560545575515636, \"precision\": 0.9400925925925926, \"recall\": 0.8443945442448436, \"specificity\": 0.9196173437694124, \"npv\": 0.7982314245659441, \"accuracy\": 0.8745578637971404, \"f1\": 0.8896775324220119, \"f2\": 0.8619430861179027, \"f0_5\": 0.919256120527307, \"p4\": 0.8718046474245786, \"phi\": 0.7510581377733442}, {\"truth_threshold\": -3.54, \"match_probability\": 0.07916540574888453, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10151, \"tn\": 7403, \"fp\": 646, \"fn\": 1873, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8442282102461743, \"tn_rate\": 0.9197415828053175, \"fp_rate\": 0.08025841719468257, \"fn_rate\": 0.1557717897538257, \"precision\": 0.9401685653422247, \"recall\": 0.8442282102461743, \"specificity\": 0.9197415828053175, \"npv\": 0.7980810694264769, \"accuracy\": 0.874508045633438, \"f1\": 0.8896192103764077, \"f2\": 0.8618171938940111, \"f0_5\": 0.9192747953343476, \"p4\": 0.8717597112876717, \"phi\": 0.7509996143105431}, {\"truth_threshold\": -3.52, \"match_probability\": 0.08018190397645779, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10149, \"tn\": 7409, \"fp\": 640, \"fn\": 1875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.844061876247505, \"tn_rate\": 0.9204870170207479, \"fp_rate\": 0.07951298297925208, \"fn_rate\": 0.15593812375249502, \"precision\": 0.9406803225507462, \"recall\": 0.844061876247505, \"specificity\": 0.9204870170207479, \"npv\": 0.7980396380870315, \"accuracy\": 0.8747073182882479, \"f1\": 0.8897558409678692, \"f2\": 0.8617644561433302, \"f0_5\": 0.9196266763320043, \"p4\": 0.8719802836329327, \"phi\": 0.7515234715834098}, {\"truth_threshold\": -3.5, \"match_probability\": 0.08121030314161229, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10148, \"tn\": 7410, \"fp\": 639, \"fn\": 1876, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8439787092481703, \"tn_rate\": 0.920611256056653, \"fp_rate\": 0.079388743943347, \"fn_rate\": 0.15602129075182966, \"precision\": 0.9407620283674794, \"recall\": 0.8439787092481703, \"specificity\": 0.920611256056653, \"npv\": 0.7979754469093259, \"accuracy\": 0.8747073182882479, \"f1\": 0.8897461750909649, \"f2\": 0.861708812390673, \"f0_5\": 0.9196693975204814, \"p4\": 0.8719843497409979, \"phi\": 0.7515525667518309}, {\"truth_threshold\": -3.48, \"match_probability\": 0.08225071291146206, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10137, \"tn\": 7410, \"fp\": 639, \"fn\": 1887, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8430638722554891, \"tn_rate\": 0.920611256056653, \"fp_rate\": 0.079388743943347, \"fn_rate\": 0.156936127744511, \"precision\": 0.9407015590200446, \"recall\": 0.8430638722554891, \"specificity\": 0.920611256056653, \"npv\": 0.7970313004194901, \"accuracy\": 0.8741593184875206, \"f1\": 0.8892105263157895, \"f2\": 0.8609355890746025, \"f0_5\": 0.9194057466260339, \"p4\": 0.8714451067307853, \"phi\": 0.7505919238125135}, {\"truth_threshold\": -3.46, \"match_probability\": 0.08330324319449184, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10135, \"tn\": 7410, \"fp\": 639, \"fn\": 1889, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8428975382568197, \"tn_rate\": 0.920611256056653, \"fp_rate\": 0.079388743943347, \"fn_rate\": 0.1571024617431803, \"precision\": 0.9406905513272693, \"recall\": 0.8428975382568197, \"specificity\": 0.920611256056653, \"npv\": 0.7968598774061727, \"accuracy\": 0.8740596821601155, \"f1\": 0.8891130800947451, \"f2\": 0.860794971972142, \"f0_5\": 0.9193577648766328, \"p4\": 0.8713470742540881, \"phi\": 0.7504173762564772}, {\"truth_threshold\": -3.44, \"match_probability\": 0.08436800411843749, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10131, \"tn\": 7410, \"fp\": 639, \"fn\": 1893, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.842564870259481, \"tn_rate\": 0.920611256056653, \"fp_rate\": 0.079388743943347, \"fn_rate\": 0.15743512974051896, \"precision\": 0.9406685236768803, \"recall\": 0.842564870259481, \"specificity\": 0.920611256056653, \"npv\": 0.7965172524991938, \"accuracy\": 0.8738604095053056, \"f1\": 0.8889181363516715, \"f2\": 0.8605137091020283, \"f0_5\": 0.9192617595818815, \"p4\": 0.871151020056905, \"phi\": 0.7500683869070932}, {\"truth_threshold\": -3.42, \"match_probability\": 0.08544510600750539, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10129, \"tn\": 7412, \"fp\": 637, \"fn\": 1895, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8423985362608117, \"tn_rate\": 0.9208597341284631, \"fp_rate\": 0.07914026587153683, \"fn_rate\": 0.1576014637391883, \"precision\": 0.9408322496749024, \"recall\": 0.8423985362608117, \"specificity\": 0.9208597341284631, \"npv\": 0.7963898141184055, \"accuracy\": 0.8738604095053056, \"f1\": 0.8888986397542782, \"f2\": 0.8604022968978288, \"f0_5\": 0.9193472262561719, \"p4\": 0.871159150527977, \"phi\": 0.7501272140801798}, {\"truth_threshold\": -3.4, \"match_probability\": 0.08653465935892166, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10128, \"tn\": 7412, \"fp\": 637, \"fn\": 1896, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8423153692614771, \"tn_rate\": 0.9208597341284631, \"fp_rate\": 0.07914026587153683, \"fn_rate\": 0.15768463073852296, \"precision\": 0.9408267533673943, \"recall\": 0.8423153692614771, \"specificity\": 0.9208597341284631, \"npv\": 0.7963042544048131, \"accuracy\": 0.8738105913416031, \"f1\": 0.8888498837158278, \"f2\": 0.8603319685360425, \"f0_5\": 0.9193232154527631, \"p4\": 0.8711101396618344, \"phi\": 0.7500400209778709}, {\"truth_threshold\": -3.38, \"match_probability\": 0.08763677481880414, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10127, \"tn\": 7412, \"fp\": 637, \"fn\": 1897, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8422322022621423, \"tn_rate\": 0.9208597341284631, \"fp_rate\": 0.07914026587153683, \"fn_rate\": 0.15776779773785762, \"precision\": 0.9408212560386473, \"recall\": 0.8422322022621423, \"specificity\": 0.9208597341284631, \"npv\": 0.7962187130733699, \"accuracy\": 0.8737607731779007, \"f1\": 0.8888011233982798, \"f2\": 0.8602616377845735, \"f0_5\": 0.9192992011619463, \"p4\": 0.8710611296865933, \"phi\": 0.7499528366683876}, {\"truth_threshold\": -3.36, \"match_probability\": 0.08875156315734896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10121, \"tn\": 7413, \"fp\": 636, \"fn\": 1903, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8417332002661344, \"tn_rate\": 0.9209839731643682, \"fp_rate\": 0.07901602683563176, \"fn_rate\": 0.1582667997338656, \"precision\": 0.9408757088407549, \"recall\": 0.8417332002661344, \"specificity\": 0.9209839731643682, \"npv\": 0.7957277801631601, \"accuracy\": 0.8735116823593883, \"f1\": 0.8885474737720029, \"f2\": 0.8598542130392673, \"f0_5\": 0.9192218266366344, \"p4\": 0.87082015504091, \"phi\": 0.7495466170106516}, {\"truth_threshold\": -3.34, \"match_probability\": 0.08987913524332442, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10118, \"tn\": 7416, \"fp\": 633, \"fn\": 1906, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8414836992681304, \"tn_rate\": 0.9213566902720834, \"fp_rate\": 0.07864330972791651, \"fn_rate\": 0.1585163007318696, \"precision\": 0.9411217561157101, \"recall\": 0.8414836992681304, \"specificity\": 0.9213566902720834, \"npv\": 0.7955374383179575, \"accuracy\": 0.8735116823593883, \"f1\": 0.8885181119648737, \"f2\": 0.8596869848930276, \"f0_5\": 0.9193501490150469, \"p4\": 0.8708323211981895, \"phi\": 0.7496355026545629}, {\"truth_threshold\": -3.3200000000000003, \"match_probability\": 0.0910196020178644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10072, \"tn\": 7416, \"fp\": 633, \"fn\": 1952, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8376580172987359, \"tn_rate\": 0.9213566902720834, \"fp_rate\": 0.07864330972791651, \"fn_rate\": 0.16234198270126413, \"precision\": 0.9408687529191966, \"recall\": 0.8376580172987359, \"specificity\": 0.9213566902720834, \"npv\": 0.7916310845431256, \"accuracy\": 0.8712200468290738, \"f1\": 0.8862686435830877, \"f2\": 0.8564480195915035, \"f0_5\": 0.9182408285318358, \"p4\": 0.8685790473025751, \"phi\": 0.7456394235333438}, {\"truth_threshold\": -3.3000000000000003, \"match_probability\": 0.09217307446755524, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10069, \"tn\": 7416, \"fp\": 633, \"fn\": 1955, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8374085163007319, \"tn_rate\": 0.9213566902720834, \"fp_rate\": 0.07864330972791651, \"fn_rate\": 0.16259148369926812, \"precision\": 0.9408521771631471, \"recall\": 0.8374085163007319, \"specificity\": 0.9213566902720834, \"npv\": 0.7913776544659055, \"accuracy\": 0.8710705923379665, \"f1\": 0.8861216228108774, \"f2\": 0.8562366066873023, \"f0_5\": 0.9181682229355121, \"p4\": 0.8684321577543878, \"phi\": 0.7453794466275522}, {\"truth_threshold\": -3.2800000000000002, \"match_probability\": 0.0933396635968081, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10066, \"tn\": 7416, \"fp\": 633, \"fn\": 1958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8371590153027278, \"tn_rate\": 0.9213566902720834, \"fp_rate\": 0.07864330972791651, \"fn_rate\": 0.16284098469727212, \"precision\": 0.9408355921114123, \"recall\": 0.8371590153027278, \"specificity\": 0.9213566902720834, \"npv\": 0.7911243866012375, \"accuracy\": 0.870921137846859, \"f1\": 0.8859745632178849, \"f2\": 0.8560251722085211, \"f0_5\": 0.918095585552718, \"p4\": 0.8682852758163172, \"phi\": 0.7451195472578541}, {\"truth_threshold\": -3.2600000000000002, \"match_probability\": 0.09451948039951134, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10066, \"tn\": 7420, \"fp\": 629, \"fn\": 1958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8371590153027278, \"tn_rate\": 0.9218536464157038, \"fp_rate\": 0.07814635358429618, \"fn_rate\": 0.16284098469727212, \"precision\": 0.9411874707807386, \"recall\": 0.8371590153027278, \"specificity\": 0.9218536464157038, \"npv\": 0.7912134783535936, \"accuracy\": 0.8711204105016689, \"f1\": 0.8861305515207536, \"f2\": 0.8560834141280128, \"f0_5\": 0.9183636230932049, \"p4\": 0.8684973307851347, \"phi\": 0.7455880859077317}, {\"truth_threshold\": -3.24, \"match_probability\": 0.09571263582995625, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10065, \"tn\": 7420, \"fp\": 629, \"fn\": 1959, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8370758483033932, \"tn_rate\": 0.9218536464157038, \"fp_rate\": 0.07814635358429618, \"fn_rate\": 0.1629241516966068, \"precision\": 0.9411819711988031, \"recall\": 0.8370758483033932, \"specificity\": 0.9218536464157038, \"npv\": 0.791129118242883, \"accuracy\": 0.8710705923379665, \"f1\": 0.8860815212606744, \"f2\": 0.8560129273686001, \"f0_5\": 0.9183394160583942, \"p4\": 0.8684483690610494, \"phi\": 0.7455014990509209}, {\"truth_threshold\": -3.22, \"match_probability\": 0.09691924077303016, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10063, \"tn\": 7420, \"fp\": 629, \"fn\": 1961, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8369095143047239, \"tn_rate\": 0.9218536464157038, \"fp_rate\": 0.07814635358429618, \"fn_rate\": 0.16309048569527612, \"precision\": 0.9411709689487467, \"recall\": 0.8369095143047239, \"specificity\": 0.9218536464157038, \"npv\": 0.7909604519774012, \"accuracy\": 0.8709709560105614, \"f1\": 0.8859834477901039, \"f2\": 0.85587194665578, \"f0_5\": 0.9182909913856038, \"p4\": 0.8683504481353017, \"phi\": 0.7453283511343587}, {\"truth_threshold\": -3.2, \"match_probability\": 0.09813940601367187, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10060, \"tn\": 7421, \"fp\": 628, \"fn\": 1964, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8366600133067199, \"tn_rate\": 0.9219778854516089, \"fp_rate\": 0.0780221145483911, \"fn_rate\": 0.16333998669328012, \"precision\": 0.9412425149700598, \"recall\": 0.8366600133067199, \"specificity\": 0.9219778854516089, \"npv\": 0.7907298881193394, \"accuracy\": 0.8708713196831565, \"f1\": 0.8858753082071151, \"f2\": 0.8556750136091453, \"f0_5\": 0.918285380458595, \"p4\": 0.8682565757108026, \"phi\": 0.7451858867617034}, {\"truth_threshold\": -3.18, \"match_probability\": 0.09937324220558363, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10055, \"tn\": 7421, \"fp\": 628, \"fn\": 1969, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8362441783100466, \"tn_rate\": 0.9219778854516089, \"fp_rate\": 0.0780221145483911, \"fn_rate\": 0.16375582168995342, \"precision\": 0.941215014509033, \"recall\": 0.8362441783100466, \"specificity\": 0.9219778854516089, \"npv\": 0.7903088391906283, \"accuracy\": 0.870622228864644, \"f1\": 0.885629981943894, \"f2\": 0.8553224791166913, \"f0_5\": 0.9181642194462707, \"p4\": 0.8680117971559592, \"phi\": 0.7447533323477221}, {\"truth_threshold\": -3.16, \"match_probability\": 0.10062085983919537, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10051, \"tn\": 7421, \"fp\": 628, \"fn\": 1973, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8359115103127079, \"tn_rate\": 0.9219778854516089, \"fp_rate\": 0.0780221145483911, \"fn_rate\": 0.1640884896872921, \"precision\": 0.9411929955988388, \"recall\": 0.8359115103127079, \"specificity\": 0.9219778854516089, \"npv\": 0.789972322759208, \"accuracy\": 0.8704229562098341, \"f1\": 0.8854336431308638, \"f2\": 0.8550404083368779, \"f0_5\": 0.9180672268907563, \"p4\": 0.8678159893143937, \"phi\": 0.7444074430943073}, {\"truth_threshold\": -3.14, \"match_probability\": 0.10188236920887628, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10046, \"tn\": 7422, \"fp\": 627, \"fn\": 1978, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8354956753160346, \"tn_rate\": 0.9221021244875139, \"fp_rate\": 0.07789787551248602, \"fn_rate\": 0.1645043246839654, \"precision\": 0.9412536306567976, \"recall\": 0.8354956753160346, \"specificity\": 0.9221021244875139, \"npv\": 0.7895744680851063, \"accuracy\": 0.8702236835550241, \"f1\": 0.8852271225272063, \"f2\": 0.8547023090404805, \"f0_5\": 0.9180130126471233, \"p4\": 0.8676242383602576, \"phi\": 0.7440925746447662}, {\"truth_threshold\": -3.12, \"match_probability\": 0.10315788037939025, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10042, \"tn\": 7422, \"fp\": 627, \"fn\": 1982, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.835163007318696, \"tn_rate\": 0.9221021244875139, \"fp_rate\": 0.07789787551248602, \"fn_rate\": 0.16483699268130406, \"precision\": 0.941231605586278, \"recall\": 0.835163007318696, \"specificity\": 0.9221021244875139, \"npv\": 0.7892386218630371, \"accuracy\": 0.8700244109002142, \"f1\": 0.8850306261842859, \"f2\": 0.854420148047307, \"f0_5\": 0.9179159049360146, \"p4\": 0.8674284575453695, \"phi\": 0.7437470222259163}, {\"truth_threshold\": -3.1, \"match_probability\": 0.10444750315159104, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10041, \"tn\": 7422, \"fp\": 627, \"fn\": 1983, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8350798403193613, \"tn_rate\": 0.9221021244875139, \"fp_rate\": 0.07789787551248602, \"fn_rate\": 0.16492015968063872, \"precision\": 0.9412260967379078, \"recall\": 0.8350798403193613, \"specificity\": 0.9221021244875139, \"npv\": 0.7891547049441786, \"accuracy\": 0.8699745927365118, \"f1\": 0.8849814912744579, \"f2\": 0.8543496017970186, \"f0_5\": 0.9178916191311979, \"p4\": 0.8673795144013088, \"phi\": 0.743660655457086}, {\"truth_threshold\": -3.08, \"match_probability\": 0.1057513470273544, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10034, \"tn\": 7422, \"fp\": 627, \"fn\": 1990, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8344976713240186, \"tn_rate\": 0.9221021244875139, \"fp_rate\": 0.07789787551248602, \"fn_rate\": 0.16550232867598136, \"precision\": 0.9411875058624894, \"recall\": 0.8344976713240186, \"specificity\": 0.9221021244875139, \"npv\": 0.7885677858053549, \"accuracy\": 0.8696258655905943, \"f1\": 0.8846374256116376, \"f2\": 0.8538557108089249, \"f0_5\": 0.9177215189873418, \"p4\": 0.8670369353773167, \"phi\": 0.7430563267130402}, {\"truth_threshold\": -3.06, \"match_probability\": 0.10706952117374435, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10029, \"tn\": 7422, \"fp\": 627, \"fn\": 1995, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8340818363273453, \"tn_rate\": 0.9221021244875139, \"fp_rate\": 0.07789787551248602, \"fn_rate\": 0.1659181636726547, \"precision\": 0.9411599099099099, \"recall\": 0.8340818363273453, \"specificity\": 0.9221021244875139, \"npv\": 0.7881490920675375, \"accuracy\": 0.8693767747720819, \"f1\": 0.8843915343915344, \"f2\": 0.8535028594771242, \"f0_5\": 0.9175999121651296, \"p4\": 0.8667922606033487, \"phi\": 0.7426249186320361}, {\"truth_threshold\": -3.04, \"match_probability\": 0.10840213438641137, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10027, \"tn\": 7423, \"fp\": 626, \"fn\": 1997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.833915502328676, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.16608449767132402, \"precision\": 0.9412372101755374, \"recall\": 0.833915502328676, \"specificity\": 0.922226363523419, \"npv\": 0.788004246284501, \"accuracy\": 0.8693269566083794, \"f1\": 0.8843321426996517, \"f2\": 0.8533762276804712, \"f0_5\": 0.9176184200893184, \"p4\": 0.8667473704867039, \"phi\": 0.7425698590330696}, {\"truth_threshold\": -3.02, \"match_probability\": 0.10974929505222096, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 10023, \"tn\": 7423, \"fp\": 626, \"fn\": 2001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8335828343313373, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.1664171656686627, \"precision\": 0.941215137571603, \"recall\": 0.8335828343313373, \"specificity\": 0.922226363523419, \"npv\": 0.7876697792869269, \"accuracy\": 0.8691276839535694, \"f1\": 0.8841353151325365, \"f2\": 0.8530938803302409, \"f0_5\": 0.9175210545587696, \"p4\": 0.8665516489800918, \"phi\": 0.7422249822926175}, {\"truth_threshold\": -3.0, \"match_probability\": 0.1111111111111111, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9989, \"tn\": 7423, \"fp\": 626, \"fn\": 2035, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8307551563539588, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.16924484364604125, \"precision\": 0.9410268487988696, \"recall\": 0.8307551563539588, \"specificity\": 0.922226363523419, \"npv\": 0.7848382321843942, \"accuracy\": 0.8674338663876849, \"f1\": 0.8824594725915456, \"f2\": 0.8506923745124423, \"f0_5\": 0.9166911386829161, \"p4\": 0.864888533620244, \"phi\": 0.7392989868143293}, {\"truth_threshold\": -2.98, \"match_probability\": 0.11248769001717858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9982, \"tn\": 7423, \"fp\": 626, \"fn\": 2042, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8301729873586161, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.1698270126413839, \"precision\": 0.9409879336349924, \"recall\": 0.8301729873586161, \"specificity\": 0.922226363523419, \"npv\": 0.784257791864765, \"accuracy\": 0.8670851392417676, \"f1\": 0.8821138211382114, \"f2\": 0.8501976015263014, \"f0_5\": 0.916519759071544, \"p4\": 0.8645462408425241, \"phi\": 0.7386977819758146}, {\"truth_threshold\": -2.96, \"match_probability\": 0.11387913869899342, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9976, \"tn\": 7423, \"fp\": 626, \"fn\": 2048, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8296739853626082, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.1703260146373919, \"precision\": 0.940954536879834, \"recall\": 0.8296739853626082, \"specificity\": 0.922226363523419, \"npv\": 0.7837609544926618, \"accuracy\": 0.8667862302595526, \"f1\": 0.881817378237426, \"f2\": 0.8497734164707486, \"f0_5\": 0.9163727219282775, \"p4\": 0.8642528773723638, \"phi\": 0.738182789562374}, {\"truth_threshold\": -2.94, \"match_probability\": 0.11528556351914263, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9973, \"tn\": 7423, \"fp\": 626, \"fn\": 2051, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8294244843646041, \"tn_rate\": 0.922226363523419, \"fp_rate\": 0.07777363647658095, \"fn_rate\": 0.17057551563539589, \"precision\": 0.9409378243230494, \"recall\": 0.8294244843646041, \"specificity\": 0.922226363523419, \"npv\": 0.7835127717964957, \"accuracy\": 0.8666367757684452, \"f1\": 0.8816690978208018, \"f2\": 0.8495612914217565, \"f0_5\": 0.9162991547225284, \"p4\": 0.8641062060850512, \"phi\": 0.7379254060040485}, {\"truth_threshold\": -2.92, \"match_probability\": 0.1167070702330039, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9969, \"tn\": 7428, \"fp\": 621, \"fn\": 2055, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8290918163672655, \"tn_rate\": 0.9228475587029444, \"fp_rate\": 0.07715244129705554, \"fn_rate\": 0.17090818363273452, \"precision\": 0.9413597733711048, \"recall\": 0.8290918163672655, \"specificity\": 0.9228475587029444, \"npv\": 0.7832964251819045, \"accuracy\": 0.8666865939321476, \"f1\": 0.8816662244627222, \"f2\": 0.8493507821286167, \"f0_5\": 0.9165379523389232, \"p4\": 0.8641752770870478, \"phi\": 0.738171747685255}, {\"truth_threshold\": -2.9, \"match_probability\": 0.1181437639467516, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9965, \"tn\": 7428, \"fp\": 621, \"fn\": 2059, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8287591483699268, \"tn_rate\": 0.9228475587029444, \"fp_rate\": 0.07715244129705554, \"fn_rate\": 0.1712408516300732, \"precision\": 0.941337615718874, \"recall\": 0.8287591483699268, \"specificity\": 0.9228475587029444, \"npv\": 0.7829661642247285, \"accuracy\": 0.8664873212773377, \"f1\": 0.8814683768244139, \"f2\": 0.8490678572645786, \"f0_5\": 0.9164398175397293, \"p4\": 0.863979723911747, \"phi\": 0.7378289632183361}, {\"truth_threshold\": -2.88, \"match_probability\": 0.11959574907459691, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9964, \"tn\": 7428, \"fp\": 621, \"fn\": 2060, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8286759813705922, \"tn_rate\": 0.9228475587029444, \"fp_rate\": 0.07715244129705554, \"fn_rate\": 0.17132401862940785, \"precision\": 0.9413320736891828, \"recall\": 0.8286759813705922, \"specificity\": 0.9228475587029444, \"npv\": 0.7828836424957841, \"accuracy\": 0.8664375031136352, \"f1\": 0.8814189039762926, \"f2\": 0.8489971200218128, \"f0_5\": 0.9164152748142153, \"p4\": 0.8639308375271596, \"phi\": 0.7377432878747309}, {\"truth_threshold\": -2.86, \"match_probability\": 0.12106312929526573, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9963, \"tn\": 7429, \"fp\": 620, \"fn\": 2061, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8285928143712575, \"tn_rate\": 0.9229717977388495, \"fp_rate\": 0.07702820226115045, \"fn_rate\": 0.17140718562874252, \"precision\": 0.9414154776528395, \"recall\": 0.8285928143712575, \"specificity\": 0.9229717977388495, \"npv\": 0.7828240252897787, \"accuracy\": 0.8664375031136352, \"f1\": 0.881408413323307, \"f2\": 0.8489408476627073, \"f0_5\": 0.9164581646920303, \"p4\": 0.8639348637535095, \"phi\": 0.7377755628264503}, {\"truth_threshold\": -2.84, \"match_probability\": 0.12254600750771812, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9960, \"tn\": 7429, \"fp\": 620, \"fn\": 2064, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8283433133732535, \"tn_rate\": 0.9229717977388495, \"fp_rate\": 0.07702820226115045, \"fn_rate\": 0.17165668662674652, \"precision\": 0.941398865784499, \"recall\": 0.8283433133732535, \"specificity\": 0.9229717977388495, \"npv\": 0.7825766354155693, \"accuracy\": 0.8662880486225277, \"f1\": 0.8812599539904442, \"f2\": 0.8487286113572841, \"f0_5\": 0.9163845134697483, \"p4\": 0.8637882092683661, \"phi\": 0.7375186330707652}, {\"truth_threshold\": -2.82, \"match_probability\": 0.12404448578611339, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9960, \"tn\": 7430, \"fp\": 619, \"fn\": 2064, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8283433133732535, \"tn_rate\": 0.9230960367747546, \"fp_rate\": 0.07690396322524537, \"fn_rate\": 0.17165668662674652, \"precision\": 0.9414878532942622, \"recall\": 0.8283433133732535, \"specificity\": 0.9230960367747546, \"npv\": 0.7825995365493996, \"accuracy\": 0.8663378667862303, \"f1\": 0.8812989426182365, \"f2\": 0.8487430762675756, \"f0_5\": 0.916451969083548, \"p4\": 0.8638411162132553, \"phi\": 0.7376366027214815}, {\"truth_threshold\": -2.8000000000000003, \"match_probability\": 0.12555866533402688, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9957, \"tn\": 7431, \"fp\": 618, \"fn\": 2067, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8280938123752495, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.1719061876247505, \"precision\": 0.9415602836879433, \"recall\": 0.8280938123752495, \"specificity\": 0.9232202758106597, \"npv\": 0.7823752368919773, \"accuracy\": 0.8662382304588253, \"f1\": 0.8811894331607594, \"f2\": 0.8485452779056093, \"f0_5\": 0.9164457698254915, \"p4\": 0.8637473684122051, \"phi\": 0.7374977664711226}, {\"truth_threshold\": -2.7800000000000002, \"match_probability\": 0.12708864643792386, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9952, \"tn\": 7431, \"fp\": 618, \"fn\": 2072, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8276779773785762, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.17232202262142382, \"precision\": 0.9415326395458846, \"recall\": 0.8276779773785762, \"specificity\": 0.9232202758106597, \"npv\": 0.7819635904451226, \"accuracy\": 0.8659891396403129, \"f1\": 0.8809418429671594, \"f2\": 0.8481914567210991, \"f0_5\": 0.9163229228049499, \"p4\": 0.8635029634719167, \"phi\": 0.7370699120770329}, {\"truth_threshold\": -2.7600000000000002, \"match_probability\": 0.12863452841989784, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9944, \"tn\": 7431, \"fp\": 618, \"fn\": 2080, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8270126413838988, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.17298735861610112, \"precision\": 0.9414883544783185, \"recall\": 0.8270126413838988, \"specificity\": 0.9232202758106597, \"npv\": 0.7813058563768268, \"accuracy\": 0.865590594330693, \"f1\": 0.8805454706455327, \"f2\": 0.8476252173616557, \"f0_5\": 0.9161261792452831, \"p4\": 0.8631119546300875, \"phi\": 0.7363857748090973}, {\"truth_threshold\": -2.74, \"match_probability\": 0.13019640958968035, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9943, \"tn\": 7431, \"fp\": 618, \"fn\": 2081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8269294743845642, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.1730705256154358, \"precision\": 0.94148281412745, \"recall\": 0.8269294743845642, \"specificity\": 0.9232202758106597, \"npv\": 0.7812237174095878, \"accuracy\": 0.8655407761669904, \"f1\": 0.8804959043613018, \"f2\": 0.8475544265816527, \"f0_5\": 0.9161015699859955, \"p4\": 0.8630630818893729, \"phi\": 0.736300294782615}, {\"truth_threshold\": -2.72, \"match_probability\": 0.13177438719593176, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9941, \"tn\": 7431, \"fp\": 618, \"fn\": 2083, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8267631403858948, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.17323685961410512, \"precision\": 0.9414717302774884, \"recall\": 0.8267631403858948, \"specificity\": 0.9232202758106597, \"npv\": 0.7810594912760143, \"accuracy\": 0.8654411398395855, \"f1\": 0.8803967586237436, \"f2\": 0.8474128377802403, \"f0_5\": 0.9160523405823812, \"p4\": 0.8629653386426165, \"phi\": 0.7361293594534629}, {\"truth_threshold\": -2.7, \"match_probability\": 0.13336855737682143, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9935, \"tn\": 7431, \"fp\": 618, \"fn\": 2089, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8262641383898869, \"tn_rate\": 0.9232202758106597, \"fp_rate\": 0.07677972418934029, \"fn_rate\": 0.17373586161011312, \"precision\": 0.941438453520326, \"recall\": 0.8262641383898869, \"specificity\": 0.9232202758106597, \"npv\": 0.7805672268907563, \"accuracy\": 0.8651422308573706, \"f1\": 0.8800992160162998, \"f2\": 0.8469880134358642, \"f0_5\": 0.9159045652334243, \"p4\": 0.862672126725132, \"phi\": 0.7356167510547643}, {\"truth_threshold\": -2.68, \"match_probability\": 0.13497901510990773, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9934, \"tn\": 7432, \"fp\": 617, \"fn\": 2090, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8261809713905522, \"tn_rate\": 0.9233445148465648, \"fp_rate\": 0.0766554851534352, \"fn_rate\": 0.17381902860944778, \"precision\": 0.9415221306037342, \"recall\": 0.8261809713905522, \"specificity\": 0.9233445148465648, \"npv\": 0.7805082965763495, \"accuracy\": 0.8651422308573706, \"f1\": 0.8800885935769657, \"f2\": 0.8469316418572135, \"f0_5\": 0.9159474810061223, \"p4\": 0.8626761431299133, \"phi\": 0.7356495137021063}, {\"truth_threshold\": -2.66, \"match_probability\": 0.13660585416132934, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9931, \"tn\": 7432, \"fp\": 617, \"fn\": 2093, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8259314703925482, \"tn_rate\": 0.9233445148465648, \"fp_rate\": 0.0766554851534352, \"fn_rate\": 0.17406852960745176, \"precision\": 0.9415054986727341, \"recall\": 0.8259314703925482, \"specificity\": 0.9233445148465648, \"npv\": 0.7802624671916011, \"accuracy\": 0.8649927763662631, \"f1\": 0.879939748360801, \"f2\": 0.8467191869585976, \"f0_5\": 0.9158735428655748, \"p4\": 0.8625295471578567, \"phi\": 0.7353933666664598}, {\"truth_threshold\": -2.62, \"match_probability\": 0.1399090449170576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9927, \"tn\": 7432, \"fp\": 617, \"fn\": 2097, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8255988023952096, \"tn_rate\": 0.9233445148465648, \"fp_rate\": 0.0766554851534352, \"fn_rate\": 0.17440119760479042, \"precision\": 0.9414833080424886, \"recall\": 0.8255988023952096, \"specificity\": 0.9233445148465648, \"npv\": 0.7799349354601742, \"accuracy\": 0.8647935037114532, \"f1\": 0.8797412265154201, \"f2\": 0.8464358799454298, \"f0_5\": 0.9157749077490774, \"p4\": 0.8623340961574489, \"phi\": 0.7350519521827137}, {\"truth_threshold\": -2.6, \"match_probability\": 0.14158557762986687, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9912, \"tn\": 7432, \"fp\": 617, \"fn\": 2112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8243512974051896, \"tn_rate\": 0.9233445148465648, \"fp_rate\": 0.0766554851534352, \"fn_rate\": 0.17564870259481039, \"precision\": 0.9413999430145313, \"recall\": 0.8243512974051896, \"specificity\": 0.9233445148465648, \"npv\": 0.7787091366303437, \"accuracy\": 0.864046231255916, \"f1\": 0.8789961424200772, \"f2\": 0.8453731343283583, \"f0_5\": 0.9154045068341338, \"p4\": 0.8616012589070122, \"phi\": 0.733772814442548}, {\"truth_threshold\": -2.58, \"match_probability\": 0.14327885357178247, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9896, \"tn\": 7730, \"fp\": 319, \"fn\": 2128, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.823020625415835, \"tn_rate\": 0.9603677475462791, \"fp_rate\": 0.039632252453720956, \"fn_rate\": 0.17697937458416502, \"precision\": 0.9687714145863926, \"recall\": 0.823020625415835, \"specificity\": 0.9603677475462791, \"npv\": 0.7841347129235139, \"accuracy\": 0.878094953420017, \"f1\": 0.8899680741040514, \"f2\": 0.8485534461765362, \"f0_5\": 0.93563270554421, \"p4\": 0.8764567421713264, \"phi\": 0.7679960326871433}, {\"truth_threshold\": -2.56, \"match_probability\": 0.14498895966649594, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9894, \"tn\": 7731, \"fp\": 318, \"fn\": 2130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8228542914171657, \"tn_rate\": 0.9604919865821842, \"fp_rate\": 0.03950801341781588, \"fn_rate\": 0.17714570858283432, \"precision\": 0.9688601645123385, \"recall\": 0.8228542914171657, \"specificity\": 0.9604919865821842, \"npv\": 0.7839975661697597, \"accuracy\": 0.8780451352563144, \"f1\": 0.8899082568807339, \"f2\": 0.8484256019757151, \"f0_5\": 0.9356559237403541, \"p4\": 0.8764107580490781, \"phi\": 0.7679507153410682}, {\"truth_threshold\": -2.54, \"match_probability\": 0.14671598130769928, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9893, \"tn\": 7731, \"fp\": 318, \"fn\": 2131, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.822771124417831, \"tn_rate\": 0.9604919865821842, \"fp_rate\": 0.03950801341781588, \"fn_rate\": 0.177228875582169, \"precision\": 0.968857114876114, \"recall\": 0.822771124417831, \"specificity\": 0.9604919865821842, \"npv\": 0.7839180693571284, \"accuracy\": 0.8779953170926119, \"f1\": 0.8898583314594108, \"f2\": 0.8483543999862795, \"f0_5\": 0.9356321404252099, \"p4\": 0.8763617100380223, \"phi\": 0.7678678484518928}, {\"truth_threshold\": -2.52, \"match_probability\": 0.14846000230384404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9887, \"tn\": 7732, \"fp\": 317, \"fn\": 2137, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.822272122421823, \"tn_rate\": 0.9606162256180892, \"fp_rate\": 0.0393837743819108, \"fn_rate\": 0.17772787757817698, \"precision\": 0.9689337514700117, \"recall\": 0.822272122421823, \"specificity\": 0.9606162256180892, \"npv\": 0.7834633701489513, \"accuracy\": 0.8777462262740995, \"f1\": 0.8895987043368724, \"f2\": 0.8479416809605489, \"f0_5\": 0.935560181680545, \"p4\": 0.8761195399391286, \"phi\": 0.7674913286899435}, {\"truth_threshold\": -2.5, \"match_probability\": 0.15022110482233483, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9884, \"tn\": 7737, \"fp\": 312, \"fn\": 2140, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.822022621423819, \"tn_rate\": 0.9612374207976147, \"fp_rate\": 0.03876257920238539, \"fn_rate\": 0.17797737857618098, \"precision\": 0.9693997646135739, \"recall\": 0.822022621423819, \"specificity\": 0.9612374207976147, \"npv\": 0.78333502075529, \"accuracy\": 0.8778458626015045, \"f1\": 0.8896489648964897, \"f2\": 0.8478007273725383, \"f0_5\": 0.9358430540827147, \"p4\": 0.8762328918331528, \"phi\": 0.7678457395659353}, {\"truth_threshold\": -2.48, \"match_probability\": 0.15199936933317765, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9883, \"tn\": 7738, \"fp\": 311, \"fn\": 2141, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8219394544244844, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17806054557551562, \"precision\": 0.9694918579556602, \"recall\": 0.8219394544244844, \"specificity\": 0.9613616598335197, \"npv\": 0.783277659682154, \"accuracy\": 0.8778458626015045, \"f1\": 0.889639031415969, \"f2\": 0.847744038428547, \"f0_5\": 0.9358901515151515, \"p4\": 0.8762359350892482, \"phi\": 0.7678835861933501}, {\"truth_threshold\": -2.46, \"match_probability\": 0.15379487455210342, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9881, \"tn\": 7738, \"fp\": 311, \"fn\": 2143, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8217731204258151, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17822687957418495, \"precision\": 0.9694858712715856, \"recall\": 0.8217731204258151, \"specificity\": 0.9613616598335197, \"npv\": 0.7831191174982289, \"accuracy\": 0.8777462262740995, \"f1\": 0.8895390709398632, \"f2\": 0.8476015646445237, \"f0_5\": 0.9358425519018033, \"p4\": 0.8761378434031608, \"phi\": 0.7677181400112465}, {\"truth_threshold\": -2.44, \"match_probability\": 0.15560769738318947, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9880, \"tn\": 7738, \"fp\": 311, \"fn\": 2144, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8216899534264803, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17831004657351962, \"precision\": 0.969482877048376, \"recall\": 0.8216899534264803, \"specificity\": 0.9613616598335197, \"npv\": 0.7830398704715644, \"accuracy\": 0.8776964081103971, \"f1\": 0.8894890839522845, \"f2\": 0.8475303240859883, \"f0_5\": 0.9358187466848527, \"p4\": 0.8760887984359044, \"phi\": 0.7676354287422755}, {\"truth_threshold\": -2.42, \"match_probability\": 0.1574379128610021, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9878, \"tn\": 7738, \"fp\": 311, \"fn\": 2146, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.821523619427811, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17847638057218895, \"precision\": 0.9694768868387477, \"recall\": 0.821523619427811, \"specificity\": 0.9613616598335197, \"npv\": 0.7828814245244841, \"accuracy\": 0.8775967717829921, \"f1\": 0.8893890964750372, \"f2\": 0.8473878356352407, \"f0_5\": 0.9357711254262978, \"p4\": 0.8759907102491465, \"phi\": 0.767470029835815}, {\"truth_threshold\": -2.4, \"match_probability\": 0.15928559409228404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9876, \"tn\": 7738, \"fp\": 311, \"fn\": 2148, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8213572854291418, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17864271457085829, \"precision\": 0.9694708942770197, \"recall\": 0.8213572854291418, \"specificity\": 0.9613616598335197, \"npv\": 0.7827230426866275, \"accuracy\": 0.877497135455587, \"f1\": 0.8892890909909504, \"f2\": 0.8472453374054184, \"f0_5\": 0.935723489729402, \"p4\": 0.8758926243876348, \"phi\": 0.7673046624210977}, {\"truth_threshold\": -2.38, \"match_probability\": 0.16115081219721364, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9874, \"tn\": 7738, \"fp\": 311, \"fn\": 2150, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8211909514304724, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17880904856952762, \"precision\": 0.9694648993618066, \"recall\": 0.8211909514304724, \"specificity\": 0.9613616598335197, \"npv\": 0.7825647249190939, \"accuracy\": 0.8773974991281821, \"f1\": 0.8891890674951596, \"f2\": 0.8471028293955148, \"f0_5\": 0.9356758395875976, \"p4\": 0.8757945408452548, \"phi\": 0.7671393264778553}, {\"truth_threshold\": -2.36, \"match_probability\": 0.16303363625026068, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9872, \"tn\": 7738, \"fp\": 311, \"fn\": 2152, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8210246174318031, \"tn_rate\": 0.9613616598335197, \"fp_rate\": 0.03863834016648031, \"fn_rate\": 0.17897538256819695, \"precision\": 0.9694589020917215, \"recall\": 0.8210246174318031, \"specificity\": 0.9613616598335197, \"npv\": 0.7824064711830131, \"accuracy\": 0.8772978628007772, \"f1\": 0.8890890259827983, \"f2\": 0.8469603116045231, \"f0_5\": 0.9356281749943134, \"p4\": 0.8756964596158902, \"phi\": 0.766974021985831}, {\"truth_threshold\": -2.34, \"match_probability\": 0.1649341332206679, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9869, \"tn\": 7739, \"fp\": 310, \"fn\": 2155, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8207751164337991, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.17922488356620092, \"precision\": 0.969545141958935, \"recall\": 0.8207751164337991, \"specificity\": 0.9614858988694248, \"npv\": 0.7821912270062664, \"accuracy\": 0.8771982264733722, \"f1\": 0.8889789668062874, \"f2\": 0.8467610467610468, \"f0_5\": 0.9356276071293136, \"p4\": 0.8756014198840748, \"phi\": 0.7668468264438978}, {\"truth_threshold\": -2.32, \"match_probability\": 0.16685236791258687, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9860, \"tn\": 7739, \"fp\": 310, \"fn\": 2164, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8200266134397871, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.17997338656021292, \"precision\": 0.9695181907571289, \"recall\": 0.8200266134397871, \"specificity\": 0.9614858988694248, \"npv\": 0.7814803594870241, \"accuracy\": 0.8767498630000499, \"f1\": 0.8885284311075066, \"f2\": 0.846119520818316, \"f0_5\": 0.9354128718882817, \"p4\": 0.8751600922573647, \"phi\": 0.7661036246761164}, {\"truth_threshold\": -2.3000000000000003, \"match_probability\": 0.1687884029048976, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9857, \"tn\": 7739, \"fp\": 310, \"fn\": 2167, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8197771124417831, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.1802228875582169, \"precision\": 0.9695091964197895, \"recall\": 0.8197771124417831, \"specificity\": 0.9614858988694248, \"npv\": 0.7812436906925095, \"accuracy\": 0.8766004085089424, \"f1\": 0.8883781713307196, \"f2\": 0.8459056347939515, \"f0_5\": 0.9353412282699461, \"p4\": 0.8750129932851528, \"phi\": 0.7658560317291613}, {\"truth_threshold\": -2.2800000000000002, \"match_probability\": 0.17074229849074432, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9853, \"tn\": 7739, \"fp\": 310, \"fn\": 2171, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8194444444444444, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.18055555555555555, \"precision\": 0.9694971957099282, \"recall\": 0.8194444444444444, \"specificity\": 0.9614858988694248, \"npv\": 0.780928355196771, \"accuracy\": 0.8764011358541324, \"f1\": 0.8881777617523775, \"f2\": 0.8456204191627045, \"f0_5\": 0.9352456526691473, \"p4\": 0.874816869226854, \"phi\": 0.7655260172594188}, {\"truth_threshold\": -2.24, \"match_probability\": 0.1747039008224231, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9852, \"tn\": 7739, \"fp\": 310, \"fn\": 2172, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8193612774451098, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.18063872255489022, \"precision\": 0.9694941940562881, \"recall\": 0.8193612774451098, \"specificity\": 0.9614858988694248, \"npv\": 0.7808495610937343, \"accuracy\": 0.87635131769043, \"f1\": 0.8881276480663481, \"f2\": 0.8455491091352261, \"f0_5\": 0.9352217496962333, \"p4\": 0.8747678396187115, \"phi\": 0.7654435331715459}, {\"truth_threshold\": -2.22, \"match_probability\": 0.17671171617835496, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9846, \"tn\": 7739, \"fp\": 310, \"fn\": 2178, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8188622754491018, \"tn_rate\": 0.9614858988694248, \"fp_rate\": 0.038514101130575226, \"fn_rate\": 0.18113772455089822, \"precision\": 0.9694761717211501, \"recall\": 0.8188622754491018, \"specificity\": 0.9614858988694248, \"npv\": 0.7803771301804981, \"accuracy\": 0.876052408708215, \"f1\": 0.8878268710550045, \"f2\": 0.8451211975554488, \"f0_5\": 0.9350782555842577, \"p4\": 0.8744736737248081, \"phi\": 0.7649487924989947}, {\"truth_threshold\": -2.2, \"match_probability\": 0.17873760922563603, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9845, \"tn\": 7740, \"fp\": 309, \"fn\": 2179, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8187791084497671, \"tn_rate\": 0.9616101379053299, \"fp_rate\": 0.038389862094670144, \"fn_rate\": 0.18122089155023285, \"precision\": 0.96956864289935, \"recall\": 0.8187791084497671, \"specificity\": 0.9616101379053299, \"npv\": 0.7803205968343583, \"accuracy\": 0.876052408708215, \"f1\": 0.8878167553431329, \"f2\": 0.8450643776824034, \"f0_5\": 0.9351253799392097, \"p4\": 0.8744767075094646, \"phi\": 0.7649872539105376}, {\"truth_threshold\": -2.18, \"match_probability\": 0.18078162791413613, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9843, \"tn\": 7749, \"fp\": 300, \"fn\": 2181, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8186127744510978, \"tn_rate\": 0.9627282892284756, \"fp_rate\": 0.03727171077152441, \"fn_rate\": 0.1813872255489022, \"precision\": 0.9704229517894114, \"recall\": 0.8186127744510978, \"specificity\": 0.9627282892284756, \"npv\": 0.7803625377643505, \"accuracy\": 0.8764011358541324, \"f1\": 0.8880768710244958, \"f2\": 0.8450522845515891, \"f0_5\": 0.9357175450604609, \"p4\": 0.8748470792142832, \"phi\": 0.7659109171458033}, {\"truth_threshold\": -2.16, \"match_probability\": 0.18284381754112208, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9842, \"tn\": 7749, \"fp\": 300, \"fn\": 2182, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8185296074517632, \"tn_rate\": 0.9627282892284756, \"fp_rate\": 0.03727171077152441, \"fn_rate\": 0.18147039254823685, \"precision\": 0.9704200354959575, \"recall\": 0.8185296074517632, \"specificity\": 0.9627282892284756, \"npv\": 0.7802839593193032, \"accuracy\": 0.87635131769043, \"f1\": 0.8880267075701525, \"f2\": 0.8449809402795425, \"f0_5\": 0.9356936416184971, \"p4\": 0.8747980484503863, \"phi\": 0.7658285865771943}, {\"truth_threshold\": -2.14, \"match_probability\": 0.18492422068977335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9838, \"tn\": 7750, \"fp\": 299, \"fn\": 2186, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8181969394544245, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18180306054557552, \"precision\": 0.9705040939133867, \"recall\": 0.8181969394544245, \"specificity\": 0.9628525282643806, \"npv\": 0.7799919484702094, \"accuracy\": 0.8762018631993225, \"f1\": 0.8878660710256757, \"f2\": 0.8447100441330517, \"f0_5\": 0.9356691775089401, \"p4\": 0.8746539633659319, \"phi\": 0.7656203592047285}, {\"truth_threshold\": -2.12, \"match_probability\": 0.187022877167705, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9836, \"tn\": 7750, \"fp\": 299, \"fn\": 2188, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8180306054557551, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18196939454424485, \"precision\": 0.9704982733103108, \"recall\": 0.8180306054557551, \"specificity\": 0.9628525282643806, \"npv\": 0.7798349768565104, \"accuracy\": 0.8761022268719175, \"f1\": 0.8877656933977165, \"f2\": 0.8445673266816645, \"f0_5\": 0.9356213377977323, \"p4\": 0.8745559065189464, \"phi\": 0.7654557986746733}, {\"truth_threshold\": -2.1, \"match_probability\": 0.18913982394553902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9834, \"tn\": 7750, \"fp\": 299, \"fn\": 2190, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8178642714570858, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18213572854291418, \"precision\": 0.9704924504095529, \"recall\": 0.8178642714570858, \"specificity\": 0.9628525282643806, \"npv\": 0.7796780684104627, \"accuracy\": 0.8760025905445126, \"f1\": 0.8876652976485986, \"f2\": 0.8444245994264027, \"f0_5\": 0.935573483522338, \"p4\": 0.8744578518509476, \"phi\": 0.7652912691900744}, {\"truth_threshold\": -2.08, \"match_probability\": 0.19127509509556725, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9833, \"tn\": 7750, \"fp\": 299, \"fn\": 2191, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8177811044577512, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18221889554224885, \"precision\": 0.970489538097118, \"recall\": 0.8177811044577512, \"specificity\": 0.9628525282643806, \"npv\": 0.779599637863394, \"accuracy\": 0.87595277238081, \"f1\": 0.8876150929770716, \"f2\": 0.8443532321220032, \"f0_5\": 0.9355495509209926, \"p4\": 0.8744088253321448, \"phi\": 0.7652090160835827}, {\"truth_threshold\": -2.06, \"match_probability\": 0.1934287217305493, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9831, \"tn\": 7750, \"fp\": 299, \"fn\": 2193, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8176147704590818, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18238522954091815, \"precision\": 0.9704837117472853, \"recall\": 0.8176147704590818, \"specificity\": 0.9628525282643806, \"npv\": 0.7794428240973549, \"accuracy\": 0.8758531360534051, \"f1\": 0.8875146700370137, \"f2\": 0.8442104901590355, \"f0_5\": 0.9355016747868453, \"p4\": 0.8743107739210855, \"phi\": 0.7650445331297455}, {\"truth_threshold\": -2.04, \"match_probability\": 0.19560073194269076, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9826, \"tn\": 7750, \"fp\": 299, \"fn\": 2198, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8171989354624085, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18280106453759148, \"precision\": 0.9704691358024692, \"recall\": 0.8171989354624085, \"specificity\": 0.9628525282643806, \"npv\": 0.7790510655408123, \"accuracy\": 0.8756040452348927, \"f1\": 0.8872635333423631, \"f2\": 0.8438535923464042, \"f0_5\": 0.9353819206458001, \"p4\": 0.8740656548456981, \"phi\": 0.7646334613071968}, {\"truth_threshold\": -2.02, \"match_probability\": 0.19779115074284692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9822, \"tn\": 7750, \"fp\": 299, \"fn\": 2202, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8168662674650699, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18313373253493015, \"precision\": 0.9704574646774035, \"recall\": 0.8168662674650699, \"specificity\": 0.9628525282643806, \"npv\": 0.7787379421221865, \"accuracy\": 0.8754047725800826, \"f1\": 0.8870625423346128, \"f2\": 0.8435680299568854, \"f0_5\": 0.9352860516492725, \"p4\": 0.8738695692568827, \"phi\": 0.7643047431200543}, {\"truth_threshold\": -2.0, \"match_probability\": 0.2, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9802, \"tn\": 7750, \"fp\": 299, \"fn\": 2222, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8152029274783765, \"tn_rate\": 0.9628525282643806, \"fp_rate\": 0.03714747173561933, \"fn_rate\": 0.18479707252162342, \"precision\": 0.9703989703989704, \"recall\": 0.8152029274783765, \"specificity\": 0.9628525282643806, \"npv\": 0.7771760930605696, \"accuracy\": 0.874408409306033, \"f1\": 0.8860564971751412, \"f2\": 0.8421396291905081, \"f0_5\": 0.9348058289463645, \"p4\": 0.8728892684770706, \"phi\": 0.7626630033651384}, {\"truth_threshold\": -1.98, \"match_probability\": 0.20222729838105732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9798, \"tn\": 7756, \"fp\": 293, \"fn\": 2226, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.814870259481038, \"tn_rate\": 0.9635979624798111, \"fp_rate\": 0.03640203752018884, \"fn_rate\": 0.18512974051896208, \"precision\": 0.9709642255475176, \"recall\": 0.814870259481038, \"specificity\": 0.9635979624798111, \"npv\": 0.7769985974754559, \"accuracy\": 0.874508045633438, \"f1\": 0.8860954103549626, \"f2\": 0.8419406396617801, \"f0_5\": 0.935137817820875, \"p4\": 0.8730052186945145, \"phi\": 0.7630630962977514}, {\"truth_threshold\": -1.96, \"match_probability\": 0.2044730612910191, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9793, \"tn\": 7757, \"fp\": 292, \"fn\": 2231, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8144544244843646, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18554557551563539, \"precision\": 0.9710461080813089, \"recall\": 0.8144544244843646, \"specificity\": 0.9637222015157162, \"npv\": 0.77663195835002, \"accuracy\": 0.874308772978628, \"f1\": 0.8858835768239178, \"f2\": 0.8415977724686753, \"f0_5\": 0.9350889924375525, \"p4\": 0.8728121522352593, \"phi\": 0.762774930808424}, {\"truth_threshold\": -1.94, \"match_probability\": 0.2067373008135667, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9790, \"tn\": 7757, \"fp\": 292, \"fn\": 2234, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8142049234863606, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18579507651363938, \"precision\": 0.9710374925609998, \"recall\": 0.8142049234863606, \"specificity\": 0.9637222015157162, \"npv\": 0.7763987588829947, \"accuracy\": 0.8741593184875206, \"f1\": 0.8857323803492264, \"f2\": 0.8413833407817388, \"f0_5\": 0.9350168092909535, \"p4\": 0.8726651245693321, \"phi\": 0.7625293005571367}, {\"truth_threshold\": -1.92, \"match_probability\": 0.2090200256521214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9781, \"tn\": 7757, \"fp\": 292, \"fn\": 2243, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8134564204923487, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18654357950765135, \"precision\": 0.9710116152089745, \"recall\": 0.8134564204923487, \"specificity\": 0.9637222015157162, \"npv\": 0.7757, \"accuracy\": 0.8737109550141982, \"f1\": 0.8852785445988143, \"f2\": 0.8407399130120855, \"f0_5\": 0.9348000611667558, \"p4\": 0.8722240688492079, \"phi\": 0.7617928223247625}, {\"truth_threshold\": -1.9000000000000001, \"match_probability\": 0.21132124107142602, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9771, \"tn\": 7757, \"fp\": 292, \"fn\": 2253, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.812624750499002, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18737524950099801, \"precision\": 0.9709828083076617, \"recall\": 0.812624750499002, \"specificity\": 0.9637222015157162, \"npv\": 0.7749250749250749, \"accuracy\": 0.8732127733771733, \"f1\": 0.8847738488703762, \"f2\": 0.840024759710449, \"f0_5\": 0.9345588797918739, \"p4\": 0.8717340543860657, \"phi\": 0.7609752371999272}, {\"truth_threshold\": -1.8800000000000001, \"match_probability\": 0.213640948839702, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9768, \"tn\": 7757, \"fp\": 292, \"fn\": 2256, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.812375249500998, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18762475049900199, \"precision\": 0.9709741550695825, \"recall\": 0.812375249500998, \"specificity\": 0.9637222015157162, \"npv\": 0.7746928992309997, \"accuracy\": 0.8730633188860658, \"f1\": 0.8846223510233653, \"f2\": 0.8398101657610565, \"f0_5\": 0.9344864533904791, \"p4\": 0.871587059675442, \"phi\": 0.7607301099271829}, {\"truth_threshold\": -1.86, \"match_probability\": 0.2159791471714348, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9763, \"tn\": 7757, \"fp\": 292, \"fn\": 2261, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8119594145043247, \"tn_rate\": 0.9637222015157162, \"fp_rate\": 0.03627779848428376, \"fn_rate\": 0.18804058549567532, \"precision\": 0.9709597215315763, \"recall\": 0.8119594145043247, \"specificity\": 0.9637222015157162, \"npv\": 0.774306248752246, \"accuracy\": 0.8728142280675534, \"f1\": 0.8843697631233298, \"f2\": 0.8394524599748929, \"f0_5\": 0.9343656687849322, \"p4\": 0.8713420782729946, \"phi\": 0.7603217162454976}, {\"truth_threshold\": -1.84, \"match_probability\": 0.21833583067084317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9762, \"tn\": 7759, \"fp\": 290, \"fn\": 2262, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.81187624750499, \"tn_rate\": 0.9639706795875264, \"fp_rate\": 0.0360293204124736, \"fn_rate\": 0.18812375249500998, \"precision\": 0.971150019896538, \"recall\": 0.81187624750499, \"specificity\": 0.9639706795875264, \"npv\": 0.7742740245484483, \"accuracy\": 0.8728640462312559, \"f1\": 0.8843993477079181, \"f2\": 0.8394097819357501, \"f0_5\": 0.934484607137387, \"p4\": 0.8713970067516814, \"phi\": 0.7604833688276936}, {\"truth_threshold\": -1.82, \"match_probability\": 0.2207109902760858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9759, \"tn\": 7805, \"fp\": 244, \"fn\": 2265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8116267465069861, \"tn_rate\": 0.9696856752391602, \"fp_rate\": 0.030314324760839857, \"fn_rate\": 0.18837325349301398, \"precision\": 0.9756073178046586, \"recall\": 0.8116267465069861, \"specificity\": 0.9696856752391602, \"npv\": 0.7750744786494538, \"accuracy\": 0.8750062272704628, \"f1\": 0.8860943387660598, \"f2\": 0.8398595500783146, \"f0_5\": 0.9377161964793604, \"p4\": 0.8736377717646319, \"phi\": 0.7658439869505473}, {\"truth_threshold\": -1.8, \"match_probability\": 0.22310461320426225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9758, \"tn\": 7805, \"fp\": 244, \"fn\": 2266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8115435795076513, \"tn_rate\": 0.9696856752391602, \"fp_rate\": 0.030314324760839857, \"fn_rate\": 0.18845642049234865, \"precision\": 0.9756048790241951, \"recall\": 0.8115435795076513, \"specificity\": 0.9696856752391602, \"npv\": 0.7749975176248635, \"accuracy\": 0.8749564091067603, \"f1\": 0.8860437664578226, \"f2\": 0.8397879445075562, \"f0_5\": 0.9376921894218943, \"p4\": 0.8735887456549575, \"phi\": 0.7657627249646686}, {\"truth_threshold\": -1.78, \"match_probability\": 0.225516682897264, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9747, \"tn\": 7805, \"fp\": 244, \"fn\": 2277, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8106287425149701, \"tn_rate\": 0.9696856752391602, \"fp_rate\": 0.030314324760839857, \"fn_rate\": 0.18937125748502995, \"precision\": 0.9755780202181964, \"recall\": 0.8106287425149701, \"specificity\": 0.9696856752391602, \"npv\": 0.7741519539773855, \"accuracy\": 0.874408409306033, \"f1\": 0.8854871678401091, \"f2\": 0.8390001205088918, \"f0_5\": 0.9374278679695315, \"p4\": 0.8730494889323347, \"phi\": 0.7648693406636486}, {\"truth_threshold\": -1.76, \"match_probability\": 0.22794717896853242, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9746, \"tn\": 7805, \"fp\": 244, \"fn\": 2278, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8105455755156354, \"tn_rate\": 0.9696856752391602, \"fp_rate\": 0.030314324760839857, \"fn_rate\": 0.18945442448436461, \"precision\": 0.9755755755755756, \"recall\": 0.8105455755156354, \"specificity\": 0.9696856752391602, \"npv\": 0.7740751760388773, \"accuracy\": 0.8743585911423305, \"f1\": 0.8854365403833924, \"f2\": 0.8389284853493096, \"f0_5\": 0.9374038165589412, \"p4\": 0.8730004683448984, \"phi\": 0.7647881690778285}, {\"truth_threshold\": -1.74, \"match_probability\": 0.2303960771507819, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9746, \"tn\": 7841, \"fp\": 208, \"fn\": 2278, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8105455755156354, \"tn_rate\": 0.974158280531743, \"fp_rate\": 0.025841719468256925, \"fn_rate\": 0.18945442448436461, \"precision\": 0.9791038778380551, \"recall\": 0.8105455755156354, \"specificity\": 0.974158280531743, \"npv\": 0.7748789406067793, \"accuracy\": 0.8761520450356199, \"f1\": 0.8868868868868869, \"f2\": 0.8394487510766581, \"f0_5\": 0.9400077160493827, \"p4\": 0.8748656856183669, \"phi\": 0.7691899798015651}, {\"truth_threshold\": -1.72, \"match_probability\": 0.23286334924474508, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9743, \"tn\": 7841, \"fp\": 208, \"fn\": 2281, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8102960745176314, \"tn_rate\": 0.974158280531743, \"fp_rate\": 0.025841719468256925, \"fn_rate\": 0.18970392548236858, \"precision\": 0.9790975781328509, \"recall\": 0.8102960745176314, \"specificity\": 0.974158280531743, \"npv\": 0.7746492787986564, \"accuracy\": 0.8760025905445126, \"f1\": 0.8867349260523322, \"f2\": 0.8392337243957483, \"f0_5\": 0.9399359419618739, \"p4\": 0.8747185526895414, \"phi\": 0.7689473353388375}, {\"truth_threshold\": -1.7, \"match_probability\": 0.2353489630689996, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9739, \"tn\": 7841, \"fp\": 208, \"fn\": 2285, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8099634065202928, \"tn_rate\": 0.974158280531743, \"fp_rate\": 0.025841719468256925, \"fn_rate\": 0.19003659347970725, \"precision\": 0.9790891726148587, \"recall\": 0.8099634065202928, \"specificity\": 0.974158280531743, \"npv\": 0.7743432747382974, \"accuracy\": 0.8758033178897026, \"f1\": 0.8865322470529334, \"f2\": 0.8389469875781748, \"f0_5\": 0.9398401914614375, \"p4\": 0.8745223816051615, \"phi\": 0.7686239143419238}, {\"truth_threshold\": -1.68, \"match_probability\": 0.2378528824109348, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9737, \"tn\": 7842, \"fp\": 207, \"fn\": 2287, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8097970725216235, \"tn_rate\": 0.9742825195676481, \"fp_rate\": 0.025717480432351846, \"fn_rate\": 0.19020292747837658, \"precision\": 0.9791834271922768, \"recall\": 0.8097970725216235, \"specificity\": 0.9742825195676481, \"npv\": 0.7742126567282062, \"accuracy\": 0.8757534997260001, \"f1\": 0.8864712308812819, \"f2\": 0.8388180565127499, \"f0_5\": 0.9398648648648649, \"p4\": 0.8744760655786669, \"phi\": 0.7685847345361647}, {\"truth_threshold\": -1.6600000000000001, \"match_probability\": 0.24037506697891697, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9735, \"tn\": 7843, \"fp\": 206, \"fn\": 2289, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8096307385229541, \"tn_rate\": 0.9744067586035532, \"fp_rate\": 0.025593241396446764, \"fn_rate\": 0.19036926147704591, \"precision\": 0.9792777386580827, \"recall\": 0.8096307385229541, \"specificity\": 0.9744067586035532, \"npv\": 0.7740821160679037, \"accuracy\": 0.8757036815622976, \"f1\": 0.8864101980423401, \"f2\": 0.8386891121181316, \"f0_5\": 0.9398895497026338, \"p4\": 0.8744297465011591, \"phi\": 0.768545623196796}, {\"truth_threshold\": -1.6400000000000001, \"match_probability\": 0.2429154723557138, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9709, \"tn\": 7843, \"fp\": 206, \"fn\": 2315, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8074683965402528, \"tn_rate\": 0.9744067586035532, \"fp_rate\": 0.025593241396446764, \"fn_rate\": 0.19253160345974718, \"precision\": 0.9792233988905699, \"recall\": 0.8074683965402528, \"specificity\": 0.9744067586035532, \"npv\": 0.7721008072455208, \"accuracy\": 0.874408409306033, \"f1\": 0.8850904781439446, \"f2\": 0.836824050611091, \"f0_5\": 0.9392655367231638, \"p4\": 0.8731548110370808, \"phi\": 0.7664474738923424}, {\"truth_threshold\": -1.62, \"match_probability\": 0.2454740499532359, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9708, \"tn\": 7843, \"fp\": 206, \"fn\": 2316, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8073852295409182, \"tn_rate\": 0.9744067586035532, \"fp_rate\": 0.025593241396446764, \"fn_rate\": 0.19261477045908185, \"precision\": 0.9792213032075853, \"recall\": 0.8073852295409182, \"specificity\": 0.9744067586035532, \"npv\": 0.7720248055911015, \"accuracy\": 0.8743585911423305, \"f1\": 0.8850396572157899, \"f2\": 0.8367522840889502, \"f0_5\": 0.9392414860681114, \"p4\": 0.8731057807146075, \"phi\": 0.7663668762306491}, {\"truth_threshold\": -1.6, \"match_probability\": 0.2480507469686566, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9704, \"tn\": 7843, \"fp\": 206, \"fn\": 2320, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8070525615435795, \"tn_rate\": 0.9744067586035532, \"fp_rate\": 0.025593241396446764, \"fn_rate\": 0.19294743845642048, \"precision\": 0.979212916246216, \"recall\": 0.8070525615435795, \"specificity\": 0.9744067586035532, \"npv\": 0.7717209485388172, \"accuracy\": 0.8741593184875206, \"f1\": 0.8848363271633081, \"f2\": 0.8364651932558701, \"f0_5\": 0.9391452462062558, \"p4\": 0.872909663533937, \"phi\": 0.7660445597028746}, {\"truth_threshold\": -1.58, \"match_probability\": 0.25064550634196875, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9702, \"tn\": 7845, \"fp\": 204, \"fn\": 2322, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8068862275449101, \"tn_rate\": 0.9746552366753634, \"fp_rate\": 0.0253447633246366, \"fn_rate\": 0.19311377245508982, \"precision\": 0.9794064203513022, \"recall\": 0.8068862275449101, \"specificity\": 0.9746552366753634, \"npv\": 0.7716140454411331, \"accuracy\": 0.8741593184875206, \"f1\": 0.8848153214774281, \"f2\": 0.836350470673425, \"f0_5\": 0.9392425650557621, \"p4\": 0.8729150827902759, \"phi\": 0.7661289933782769}, {\"truth_threshold\": -1.56, \"match_probability\": 0.2532582667150385, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9698, \"tn\": 7845, \"fp\": 204, \"fn\": 2326, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8065535595475716, \"tn_rate\": 0.9746552366753634, \"fp_rate\": 0.0253447633246366, \"fn_rate\": 0.19344644045242848, \"precision\": 0.9793981013936578, \"recall\": 0.8065535595475716, \"specificity\": 0.9746552366753634, \"npv\": 0.7713105889293088, \"accuracy\": 0.8739600458327106, \"f1\": 0.8846118763112287, \"f2\": 0.8360633125280182, \"f0_5\": 0.9391462658816238, \"p4\": 0.8727189698469802, \"phi\": 0.7658069157962083}, {\"truth_threshold\": -1.54, \"match_probability\": 0.2558889623922157, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9693, \"tn\": 7847, \"fp\": 202, \"fn\": 2331, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8061377245508982, \"tn_rate\": 0.9749037147471735, \"fp_rate\": 0.02509628525282644, \"fn_rate\": 0.19386227544910178, \"precision\": 0.9795856493178373, \"recall\": 0.8061377245508982, \"specificity\": 0.9749037147471735, \"npv\": 0.7709766162310867, \"accuracy\": 0.8738105913416031, \"f1\": 0.884438158675122, \"f2\": 0.8357331310030867, \"f0_5\": 0.9391713820634059, \"p4\": 0.8725772924283743, \"phi\": 0.7656502022249801}, {\"truth_threshold\": -1.52, \"match_probability\": 0.2585375233025599, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9689, \"tn\": 7847, \"fp\": 202, \"fn\": 2335, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8058050565535595, \"tn_rate\": 0.9749037147471735, \"fp_rate\": 0.02509628525282644, \"fn_rate\": 0.19419494344644045, \"precision\": 0.9795773935901324, \"recall\": 0.8058050565535595, \"specificity\": 0.9749037147471735, \"npv\": 0.7706737379689649, \"accuracy\": 0.8736113186867932, \"f1\": 0.8842345425507643, \"f2\": 0.8354458757997483, \"f0_5\": 0.9390749786772118, \"p4\": 0.8723811883567603, \"phi\": 0.7653284517685772}, {\"truth_threshold\": -1.5, \"match_probability\": 0.2612038749637415, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9687, \"tn\": 7847, \"fp\": 202, \"fn\": 2337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8056387225548902, \"tn_rate\": 0.9749037147471735, \"fp_rate\": 0.02509628525282644, \"fn_rate\": 0.19436127744510978, \"precision\": 0.9795732632217615, \"recall\": 0.8056387225548902, \"specificity\": 0.9749037147471735, \"npv\": 0.7705223880597015, \"accuracy\": 0.8735116823593883, \"f1\": 0.8841327066125131, \"f2\": 0.8353022333362077, \"f0_5\": 0.9390267545560295, \"p4\": 0.8722831386960617, \"phi\": 0.7651676207609102}, {\"truth_threshold\": -1.48, \"match_probability\": 0.2638879384476761, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9664, \"tn\": 7847, \"fp\": 202, \"fn\": 2360, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.803725881570193, \"tn_rate\": 0.9749037147471735, \"fp_rate\": 0.02509628525282644, \"fn_rate\": 0.19627411842980705, \"precision\": 0.9795256436245692, \"recall\": 0.803725881570193, \"specificity\": 0.9749037147471735, \"npv\": 0.7687861271676301, \"accuracy\": 0.872365864594231, \"f1\": 0.8829602558245774, \"f2\": 0.8336496325178565, \"f0_5\": 0.9384711000621504, \"p4\": 0.8711556792130786, \"phi\": 0.7633201766044598}, {\"truth_threshold\": -1.46, \"match_probability\": 0.26658963034795197, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9656, \"tn\": 7847, \"fp\": 202, \"fn\": 2368, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8030605455755156, \"tn_rate\": 0.9749037147471735, \"fp_rate\": 0.02509628525282644, \"fn_rate\": 0.19693945442448438, \"precision\": 0.9795090282004464, \"recall\": 0.8030605455755156, \"specificity\": 0.9749037147471735, \"npv\": 0.7681840430739109, \"accuracy\": 0.8719673192846111, \"f1\": 0.8825518691161686, \"f2\": 0.8330745073679124, \"f0_5\": 0.9382773631840796, \"p4\": 0.8707635664553206, \"phi\": 0.7626784952667508}, {\"truth_threshold\": -1.44, \"match_probability\": 0.26930886274910526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9652, \"tn\": 7848, \"fp\": 201, \"fn\": 2372, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.802727877578177, \"tn_rate\": 0.9750279537830786, \"fp_rate\": 0.024972046216921357, \"fn_rate\": 0.19727212242182302, \"precision\": 0.9796001217903176, \"recall\": 0.802727877578177, \"specificity\": 0.9750279537830786, \"npv\": 0.7679060665362035, \"accuracy\": 0.8718178647935038, \"f1\": 0.8823878959637976, \"f2\": 0.8328012562770712, \"f0_5\": 0.938253363403064, \"p4\": 0.8706192144426833, \"phi\": 0.7624810141567965}, {\"truth_threshold\": -1.42, \"match_probability\": 0.2720455431978043, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9651, \"tn\": 7849, \"fp\": 200, \"fn\": 2373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8026447105788423, \"tn_rate\": 0.9751521928189837, \"fp_rate\": 0.024847807181016274, \"fn_rate\": 0.19735528942115768, \"precision\": 0.9796974926403411, \"recall\": 0.8026447105788423, \"specificity\": 0.9751521928189837, \"npv\": 0.7678536489923694, \"accuracy\": 0.8718178647935038, \"f1\": 0.8823771428571429, \"f2\": 0.8327437140835591, \"f0_5\": 0.9383020922454693, \"p4\": 0.8706218955145215, \"phi\": 0.7625240737795967}, {\"truth_threshold\": -1.4000000000000001, \"match_probability\": 0.2747995746759952, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9648, \"tn\": 7851, \"fp\": 198, \"fn\": 2376, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8023952095808383, \"tn_rate\": 0.9754006708907939, \"fp_rate\": 0.024599329109206113, \"fn_rate\": 0.19760479041916168, \"precision\": 0.979890310786106, \"recall\": 0.8023952095808383, \"specificity\": 0.9754006708907939, \"npv\": 0.7676738046347903, \"accuracy\": 0.8717680466298012, \"f1\": 0.8823045267489712, \"f2\": 0.8325566946256602, \"f0_5\": 0.938375350140056, \"p4\": 0.8705782356992674, \"phi\": 0.7625301891484645}, {\"truth_threshold\": -1.3800000000000001, \"match_probability\": 0.27757085557606836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9642, \"tn\": 7851, \"fp\": 198, \"fn\": 2382, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8018962075848304, \"tn_rate\": 0.9754006708907939, \"fp_rate\": 0.024599329109206113, \"fn_rate\": 0.19810379241516965, \"precision\": 0.9798780487804878, \"recall\": 0.8018962075848304, \"specificity\": 0.9754006708907939, \"npv\": 0.7672236880680152, \"accuracy\": 0.8714691376475863, \"f1\": 0.8819978046103183, \"f2\": 0.8321251035625518, \"f0_5\": 0.9382297991592714, \"p4\": 0.8702841670354485, \"phi\": 0.7620497673748471}, {\"truth_threshold\": -1.36, \"match_probability\": 0.2803592796780973, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9636, \"tn\": 7851, \"fp\": 198, \"fn\": 2388, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8013972055888223, \"tn_rate\": 0.9754006708907939, \"fp_rate\": 0.024599329109206113, \"fn_rate\": 0.19860279441117765, \"precision\": 0.9798657718120806, \"recall\": 0.8013972055888223, \"specificity\": 0.9754006708907939, \"npv\": 0.7667740990331087, \"accuracy\": 0.8711702286653714, \"f1\": 0.8816909140818007, \"f2\": 0.831693423096841, \"f0_5\": 0.9380841121495327, \"p4\": 0.8699901112130172, \"phi\": 0.7615696069090191}, {\"truth_threshold\": -1.34, \"match_probability\": 0.28316473612920606, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9632, \"tn\": 7851, \"fp\": 198, \"fn\": 2392, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8010645375914837, \"tn_rate\": 0.9754006708907939, \"fp_rate\": 0.024599329109206113, \"fn_rate\": 0.1989354624085163, \"precision\": 0.9798575788402848, \"recall\": 0.8010645375914837, \"specificity\": 0.9754006708907939, \"npv\": 0.7664746656253051, \"accuracy\": 0.8709709560105614, \"f1\": 0.8814862267777066, \"f2\": 0.831405586437869, \"f0_5\": 0.9379869118105328, \"p4\": 0.869794081047388, \"phi\": 0.7612496448577303}, {\"truth_threshold\": -1.32, \"match_probability\": 0.2859871094251169, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9629, \"tn\": 7853, \"fp\": 196, \"fn\": 2395, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8008150365934797, \"tn_rate\": 0.975649148962604, \"fp_rate\": 0.02435085103739595, \"fn_rate\": 0.19918496340652028, \"precision\": 0.9800508905852418, \"recall\": 0.8008150365934797, \"specificity\": 0.975649148962604, \"npv\": 0.7662958626073381, \"accuracy\": 0.870921137846859, \"f1\": 0.8814133369948282, \"f2\": 0.831218383660503, \"f0_5\": 0.9380601667835711, \"p4\": 0.8697504020062455, \"phi\": 0.7612565427371405}, {\"truth_threshold\": -1.3, \"match_probability\": 0.2888262793939301, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9626, \"tn\": 7858, \"fp\": 191, \"fn\": 2398, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8005655355954757, \"tn_rate\": 0.9762703441421294, \"fp_rate\": 0.023729655857870544, \"fn_rate\": 0.19943446440452428, \"precision\": 0.9805439543648773, \"recall\": 0.8005655355954757, \"specificity\": 0.9762703441421294, \"npv\": 0.766185647425897, \"accuracy\": 0.8710207741742639, \"f1\": 0.8814614715443432, \"f2\": 0.8310741975031513, \"f0_5\": 0.938352959525852, \"p4\": 0.8698616856230449, \"phi\": 0.7616339981469102}, {\"truth_threshold\": -1.28, \"match_probability\": 0.29168212118218634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9625, \"tn\": 7858, \"fp\": 191, \"fn\": 2399, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8004823685961411, \"tn_rate\": 0.9762703441421294, \"fp_rate\": 0.023729655857870544, \"fn_rate\": 0.19951763140385895, \"precision\": 0.9805419722901385, \"recall\": 0.8004823685961411, \"specificity\": 0.9762703441421294, \"npv\": 0.7661109486204544, \"accuracy\": 0.8709709560105614, \"f1\": 0.8814102564102564, \"f2\": 0.8310022102500345, \"f0_5\": 0.9383286538761504, \"p4\": 0.8698126760118348, \"phi\": 0.7615541226933621}, {\"truth_threshold\": -1.26, \"match_probability\": 0.29455450524326093, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9623, \"tn\": 7858, \"fp\": 191, \"fn\": 2401, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.8003160345974717, \"tn_rate\": 0.9762703441421294, \"fp_rate\": 0.023729655857870544, \"fn_rate\": 0.19968396540252828, \"precision\": 0.9805380069288772, \"recall\": 0.8003160345974717, \"specificity\": 0.9762703441421294, \"npv\": 0.7659615946973389, \"accuracy\": 0.8708713196831565, \"f1\": 0.8813078120707024, \"f2\": 0.8308582282852702, \"f0_5\": 0.938280031201248, \"p4\": 0.8697146578106385, \"phi\": 0.7613943934371057}, {\"truth_threshold\": -1.2, \"match_probability\": 0.30326954502292763, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9617, \"tn\": 7858, \"fp\": 191, \"fn\": 2407, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7998170326014638, \"tn_rate\": 0.9762703441421294, \"fp_rate\": 0.023729655857870544, \"fn_rate\": 0.20018296739853625, \"precision\": 0.980526101141925, \"recall\": 0.7998170326014638, \"specificity\": 0.9762703441421294, \"npv\": 0.7655138821237214, \"accuracy\": 0.8705724107009416, \"f1\": 0.8810003664345915, \"f2\": 0.8304262227134568, \"f0_5\": 0.9381340721086312, \"p4\": 0.8694206113194476, \"phi\": 0.7609153787107142}, {\"truth_threshold\": -1.18, \"match_probability\": 0.3062067085740297, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9610, \"tn\": 7858, \"fp\": 191, \"fn\": 2414, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7992348636061211, \"tn_rate\": 0.9762703441421294, \"fp_rate\": 0.023729655857870544, \"fn_rate\": 0.2007651363938789, \"precision\": 0.9805121926334047, \"recall\": 0.7992348636061211, \"specificity\": 0.9762703441421294, \"npv\": 0.7649922118380063, \"accuracy\": 0.8702236835550241, \"f1\": 0.8806414662084765, \"f2\": 0.8299221030450628, \"f0_5\": 0.9379636136487858, \"p4\": 0.8690775722779978, \"phi\": 0.7603568557373815}, {\"truth_threshold\": -1.16, \"match_probability\": 0.309159696030225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9603, \"tn\": 7861, \"fp\": 188, \"fn\": 2421, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7986526946107785, \"tn_rate\": 0.9766430612498447, \"fp_rate\": 0.0233569387501553, \"fn_rate\": 0.20134730538922155, \"precision\": 0.9807986926769482, \"recall\": 0.7986526946107785, \"specificity\": 0.9766430612498447, \"npv\": 0.7645399727679439, \"accuracy\": 0.8700244109002142, \"f1\": 0.8804033921613569, \"f2\": 0.8294608461312557, \"f0_5\": 0.9380128155036337, \"p4\": 0.8688894578212678, \"phi\": 0.7601696547470478}, {\"truth_threshold\": -1.1400000000000001, \"match_probability\": 0.3121283495785485, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9601, \"tn\": 7861, \"fp\": 188, \"fn\": 2423, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7984863606121091, \"tn_rate\": 0.9766430612498447, \"fp_rate\": 0.0233569387501553, \"fn_rate\": 0.20151363938789088, \"precision\": 0.9807947696393912, \"recall\": 0.7984863606121091, \"specificity\": 0.9766430612498447, \"npv\": 0.7643912874367951, \"accuracy\": 0.8699247745728093, \"f1\": 0.8803007380919635, \"f2\": 0.8293167487259221, \"f0_5\": 0.9379640484564283, \"p4\": 0.8687914498449649, \"phi\": 0.7600102878257985}, {\"truth_threshold\": -1.12, \"match_probability\": 0.3151125067007146, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9599, \"tn\": 7861, \"fp\": 188, \"fn\": 2425, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7983200266134398, \"tn_rate\": 0.9766430612498447, \"fp_rate\": 0.0233569387501553, \"fn_rate\": 0.2016799733865602, \"precision\": 0.9807908449984674, \"recall\": 0.7983200266134398, \"specificity\": 0.9766430612498447, \"npv\": 0.7642426599261132, \"accuracy\": 0.8698251382454043, \"f1\": 0.8801980651964605, \"f2\": 0.829172641362749, \"f0_5\": 0.9379152661611819, \"p4\": 0.8686934431504036, \"phi\": 0.7598509495538966}, {\"truth_threshold\": -1.1, \"match_probability\": 0.3181120001817404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9595, \"tn\": 7861, \"fp\": 188, \"fn\": 2429, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7979873586161012, \"tn_rate\": 0.9766430612498447, \"fp_rate\": 0.0233569387501553, \"fn_rate\": 0.20201264138389888, \"precision\": 0.9807829909025861, \"recall\": 0.7979873586161012, \"specificity\": 0.9766430612498447, \"npv\": 0.7639455782312925, \"accuracy\": 0.8696258655905943, \"f1\": 0.8799926629064062, \"f2\": 0.8288843967587554, \"f0_5\": 0.9378176557979514, \"p4\": 0.868497433580892, \"phi\": 0.7595323588856117}, {\"truth_threshold\": -1.08, \"match_probability\": 0.32112665812126734, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9583, \"tn\": 7861, \"fp\": 188, \"fn\": 2441, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7969893546240852, \"tn_rate\": 0.9766430612498447, \"fp_rate\": 0.0233569387501553, \"fn_rate\": 0.20301064537591484, \"precision\": 0.9807593900317265, \"recall\": 0.7969893546240852, \"specificity\": 0.9766430612498447, \"npv\": 0.7630557173364395, \"accuracy\": 0.8690280476261645, \"f1\": 0.8793760036705667, \"f2\": 0.828019423851245, \"f0_5\": 0.9375244580104876, \"p4\": 0.8679094349677763, \"phi\": 0.7585772725812189}, {\"truth_threshold\": -1.06, \"match_probability\": 0.3241563039476125, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9579, \"tn\": 7862, \"fp\": 187, \"fn\": 2445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7966566866267465, \"tn_rate\": 0.9767673002857498, \"fp_rate\": 0.023232699714250217, \"fn_rate\": 0.20334331337325348, \"precision\": 0.980851935285685, \"recall\": 0.7966566866267465, \"specificity\": 0.9767673002857498, \"npv\": 0.7627825749490638, \"accuracy\": 0.868878593135057, \"f1\": 0.8792106470858192, \"f2\": 0.8277453250838201, \"f0_5\": 0.9375, \"p4\": 0.8677650599963525, \"phi\": 0.7583829953997393}, {\"truth_threshold\": -1.04, \"match_probability\": 0.32720075643457636, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9573, \"tn\": 7865, \"fp\": 184, \"fn\": 2451, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7961576846307385, \"tn_rate\": 0.977140017393465, \"fp_rate\": 0.022859982606534972, \"fn_rate\": 0.20384231536926148, \"precision\": 0.9811417443886441, \"recall\": 0.7961576846307385, \"specificity\": 0.977140017393465, \"npv\": 0.7624079100426522, \"accuracy\": 0.8687291386439496, \"f1\": 0.8790230016987283, \"f2\": 0.8273555390385978, \"f0_5\": 0.9375734545169631, \"p4\": 0.8676258991562208, \"phi\": 0.7582778113017761}, {\"truth_threshold\": -1.02, \"match_probability\": 0.33025982972103385, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9572, \"tn\": 7865, \"fp\": 184, \"fn\": 2452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7960745176314039, \"tn_rate\": 0.977140017393465, \"fp_rate\": 0.022859982606534972, \"fn_rate\": 0.20392548236859614, \"precision\": 0.981139811398114, \"recall\": 0.7960745176314039, \"specificity\": 0.977140017393465, \"npv\": 0.7623340118251429, \"accuracy\": 0.8686793204802471, \"f1\": 0.8789715335169881, \"f2\": 0.827283412846574, \"f0_5\": 0.937548973515123, \"p4\": 0.8675769013624387, \"phi\": 0.7581983688499548}, {\"truth_threshold\": -1.0, \"match_probability\": 0.3333333333333333, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9569, \"tn\": 7866, \"fp\": 183, \"fn\": 2455, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7958250166333999, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.20417498336660014, \"precision\": 0.9812346185397867, \"recall\": 0.7958250166333999, \"specificity\": 0.9772642564293701, \"npv\": 0.7621354519910861, \"accuracy\": 0.8685796841528421, \"f1\": 0.8788574577516532, \"f2\": 0.827081316553727, \"f0_5\": 0.9375489888697288, \"p4\": 0.8674815091828093, \"phi\": 0.7580840503818377}, {\"truth_threshold\": -0.98, \"match_probability\": 0.33642107221052214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9568, \"tn\": 7866, \"fp\": 183, \"fn\": 2456, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7957418496340652, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.2042581503659348, \"precision\": 0.9812326940826582, \"recall\": 0.7957418496340652, \"specificity\": 0.9772642564293701, \"npv\": 0.762061615965898, \"accuracy\": 0.8685298659891396, \"f1\": 0.8788059701492538, \"f2\": 0.8270091793870037, \"f0_5\": 0.9375244963549424, \"p4\": 0.8674325118331522, \"phi\": 0.7580046439631767}, {\"truth_threshold\": -0.96, \"match_probability\": 0.339522846732419, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9566, \"tn\": 7866, \"fp\": 183, \"fn\": 2458, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7955755156353959, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.20442448436460411, \"precision\": 0.9812288439839983, \"recall\": 0.7955755156353959, \"specificity\": 0.9772642564293701, \"npv\": 0.7619139868268113, \"accuracy\": 0.8684302296617347, \"f1\": 0.8787029807559822, \"f2\": 0.8268648975710952, \"f0_5\": 0.9374754998039985, \"p4\": 0.8673345180095162, \"phi\": 0.7578458523838414}, {\"truth_threshold\": -0.9400000000000001, \"match_probability\": 0.3426384527505482, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9553, \"tn\": 7866, \"fp\": 183, \"fn\": 2471, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7944943446440452, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.20550565535595475, \"precision\": 0.9812037797863599, \"recall\": 0.7944943446440452, \"specificity\": 0.9772642564293701, \"npv\": 0.76095578988101, \"accuracy\": 0.8677825935336023, \"f1\": 0.8780330882352941, \"f2\": 0.825926822520404, \"f0_5\": 0.9371566473081149, \"p4\": 0.8666975861965419, \"phi\": 0.7568143968369903}, {\"truth_threshold\": -0.92, \"match_probability\": 0.34576768162194854, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9550, \"tn\": 7866, \"fp\": 183, \"fn\": 2474, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7942448436460412, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.20575515635395875, \"precision\": 0.9811979862324052, \"recall\": 0.7942448436460412, \"specificity\": 0.9772642564293701, \"npv\": 0.7607350096711799, \"accuracy\": 0.8676331390424948, \"f1\": 0.877878383968378, \"f2\": 0.8257102837676599, \"f0_5\": 0.9370829735458043, \"p4\": 0.8665506087182256, \"phi\": 0.7565765380884004}, {\"truth_threshold\": -0.9, \"match_probability\": 0.34891032024586677, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9543, \"tn\": 7866, \"fp\": 183, \"fn\": 2481, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7936626746506986, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.2063373253493014, \"precision\": 0.9811844540407156, \"recall\": 0.7936626746506986, \"specificity\": 0.9772642564293701, \"npv\": 0.7602203537257176, \"accuracy\": 0.8672844118965775, \"f1\": 0.8775172413793103, \"f2\": 0.8252049392964615, \"f0_5\": 0.9369109330819981, \"p4\": 0.8662076709487989, \"phi\": 0.7560217808630811}, {\"truth_threshold\": -0.88, \"match_probability\": 0.3520661511033437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9541, \"tn\": 7866, \"fp\": 183, \"fn\": 2483, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7934963406520292, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.2065036593479707, \"precision\": 0.9811805841217606, \"recall\": 0.7934963406520292, \"specificity\": 0.9772642564293701, \"npv\": 0.7600734370470577, \"accuracy\": 0.8671847755691725, \"f1\": 0.8774140150818466, \"f2\": 0.8250605326876513, \"f0_5\": 0.9368617439120188, \"p4\": 0.8661096911890093, \"phi\": 0.7558633421095817}, {\"truth_threshold\": -0.86, \"match_probability\": 0.3552349522996959, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9540, \"tn\": 7866, \"fp\": 183, \"fn\": 2484, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7934131736526946, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.20658682634730538, \"precision\": 0.9811786485652576, \"recall\": 0.7934131736526946, \"specificity\": 0.9772642564293701, \"npv\": 0.76, \"accuracy\": 0.8671349574054701, \"f1\": 0.8773623948130777, \"f2\": 0.8249883256369014, \"f0_5\": 0.9368371435305208, \"p4\": 0.8660607017150795, \"phi\": 0.7557841332734966}, {\"truth_threshold\": -0.8200000000000001, \"match_probability\": 0.36161055652684515, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9538, \"tn\": 7866, \"fp\": 183, \"fn\": 2486, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7932468396540253, \"tn_rate\": 0.9772642564293701, \"fp_rate\": 0.022735743570629893, \"fn_rate\": 0.2067531603459747, \"precision\": 0.9811747762575866, \"recall\": 0.7932468396540253, \"specificity\": 0.9772642564293701, \"npv\": 0.759853168469861, \"accuracy\": 0.867035321078065, \"f1\": 0.8772591400321913, \"f2\": 0.8248439040420638, \"f0_5\": 0.9367879311699536, \"p4\": 0.8659627235751052, \"phi\": 0.7556257366715161}, {\"truth_threshold\": -0.8, \"match_probability\": 0.36481689431254416, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9537, \"tn\": 7870, \"fp\": 179, \"fn\": 2487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7931636726546906, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20683632734530938, \"precision\": 0.981576780568135, \"recall\": 0.7931636726546906, \"specificity\": 0.9777612125729904, \"npv\": 0.7598725499662065, \"accuracy\": 0.8671847755691725, \"f1\": 0.8773689052437903, \"f2\": 0.8248287552757213, \"f0_5\": 0.9370578525389089, \"p4\": 0.8661200182596046, \"phi\": 0.7560434776150959}, {\"truth_threshold\": -0.78, \"match_probability\": 0.36803527205213776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9535, \"tn\": 7870, \"fp\": 179, \"fn\": 2489, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7929973386560213, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.2070026613439787, \"precision\": 0.9815729874408071, \"recall\": 0.7929973386560213, \"specificity\": 0.9777612125729904, \"npv\": 0.7597258422627666, \"accuracy\": 0.8670851392417676, \"f1\": 0.8772656178121262, \"f2\": 0.8246843106728939, \"f0_5\": 0.9370086477987422, \"p4\": 0.8660220357662417, \"phi\": 0.7558851844097014}, {\"truth_threshold\": -0.76, \"match_probability\": 0.37126544671083744, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9528, \"tn\": 7870, \"fp\": 179, \"fn\": 2496, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7924151696606786, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20758483033932135, \"precision\": 0.9815596991861543, \"recall\": 0.7924151696606786, \"specificity\": 0.9777612125729904, \"npv\": 0.7592128111132549, \"accuracy\": 0.8667364120958502, \"f1\": 0.8769039620818186, \"f2\": 0.8241786758472743, \"f0_5\": 0.9368363092897034, \"p4\": 0.8656791053156754, \"phi\": 0.7553313789592965}, {\"truth_threshold\": -0.74, \"match_probability\": 0.37450717119369914, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9523, \"tn\": 7870, \"fp\": 179, \"fn\": 2501, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7919993346640053, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20800066533599468, \"precision\": 0.9815501958359101, \"recall\": 0.7919993346640053, \"specificity\": 0.9777612125729904, \"npv\": 0.7588467843023816, \"accuracy\": 0.8664873212773377, \"f1\": 0.8766454938783025, \"f2\": 0.823817433129174, \"f0_5\": 0.936713094113944, \"p4\": 0.865434162762479, \"phi\": 0.7549360135825224}, {\"truth_threshold\": -0.72, \"match_probability\": 0.3777601944082411, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9515, \"tn\": 7870, \"fp\": 179, \"fn\": 2509, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.791333998669328, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20866600133067198, \"precision\": 0.9815349700845885, \"recall\": 0.791333998669328, \"specificity\": 0.9777612125729904, \"npv\": 0.7582618749397823, \"accuracy\": 0.8660887759677178, \"f1\": 0.8762316972096879, \"f2\": 0.8232393147603392, \"f0_5\": 0.9365157480314961, \"p4\": 0.8650422678617656, \"phi\": 0.7543037921158948}, {\"truth_threshold\": -0.7000000000000001, \"match_probability\": 0.3810242613298804, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9514, \"tn\": 7870, \"fp\": 179, \"fn\": 2510, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7912508316699933, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20874916833000665, \"precision\": 0.9815330650985247, \"recall\": 0.7912508316699933, \"specificity\": 0.9777612125729904, \"npv\": 0.7581888246628131, \"accuracy\": 0.8660389578040153, \"f1\": 0.8761799511903118, \"f2\": 0.823167038709789, \"f0_5\": 0.9364910622883692, \"p4\": 0.8649932821230816, \"phi\": 0.7542247958113347}, {\"truth_threshold\": -0.68, \"match_probability\": 0.38429911307016507, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9512, \"tn\": 7870, \"fp\": 179, \"fn\": 2512, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.791084497671324, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.20891550232867598, \"precision\": 0.9815292539469611, \"recall\": 0.791084497671324, \"specificity\": 0.9777612125729904, \"npv\": 0.758042766326334, \"accuracy\": 0.8659393214766103, \"f1\": 0.8760764448537877, \"f2\": 0.8230224791042968, \"f0_5\": 0.936441679136804, \"p4\": 0.8648953113860444, \"phi\": 0.7540668240970718}, {\"truth_threshold\": -0.66, \"match_probability\": 0.38758448694777375, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9507, \"tn\": 7870, \"fp\": 179, \"fn\": 2517, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7906686626746507, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.2093313373253493, \"precision\": 0.9815197191823251, \"recall\": 0.7906686626746507, \"specificity\": 0.9777612125729904, \"npv\": 0.7576778665639742, \"accuracy\": 0.8656902306580979, \"f1\": 0.8758175955780746, \"f2\": 0.8226610363088851, \"f0_5\": 0.9363181531673496, \"p4\": 0.8646503888240986, \"phi\": 0.7536720165950082}, {\"truth_threshold\": -0.62, \"match_probability\": 0.3941857318704517, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9499, \"tn\": 7870, \"fp\": 179, \"fn\": 2525, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7900033266799734, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.2099966733200266, \"precision\": 0.9815044430667493, \"recall\": 0.7900033266799734, \"specificity\": 0.9777612125729904, \"npv\": 0.757094757094757, \"accuracy\": 0.865291685348478, \"f1\": 0.8754031886462077, \"f2\": 0.8220825977083117, \"f0_5\": 0.9361203090507726, \"p4\": 0.8642585252330287, \"phi\": 0.7530406858892862}, {\"truth_threshold\": -0.6, \"match_probability\": 0.39750105926563917, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9496, \"tn\": 7870, \"fp\": 179, \"fn\": 2528, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7897538256819694, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.2102461743180306, \"precision\": 0.9814987080103359, \"recall\": 0.7897538256819694, \"specificity\": 0.9777612125729904, \"npv\": 0.7568763223696865, \"accuracy\": 0.8651422308573706, \"f1\": 0.875247707267616, \"f2\": 0.8218656419310727, \"f0_5\": 0.9360460531503825, \"p4\": 0.8641115802835999, \"phi\": 0.7528040513232046}, {\"truth_threshold\": -0.58, \"match_probability\": 0.4008258216592253, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9495, \"tn\": 7870, \"fp\": 179, \"fn\": 2529, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7896706586826348, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.21032934131736528, \"precision\": 0.9814967955344222, \"recall\": 0.7896706586826348, \"specificity\": 0.9777612125729904, \"npv\": 0.7568035388018078, \"accuracy\": 0.8650924126936681, \"f1\": 0.8751958705871509, \"f2\": 0.8217933183313139, \"f0_5\": 0.9360212933753943, \"p4\": 0.8640625990996598, \"phi\": 0.7527251869894528}, {\"truth_threshold\": -0.56, \"match_probability\": 0.4041597385650814, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9491, \"tn\": 7870, \"fp\": 179, \"fn\": 2533, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7893379906852961, \"tn_rate\": 0.9777612125729904, \"fp_rate\": 0.022238787427009566, \"fn_rate\": 0.2106620093147039, \"precision\": 0.9814891416752843, \"recall\": 0.7893379906852961, \"specificity\": 0.9777612125729904, \"npv\": 0.7565125444583294, \"accuracy\": 0.8648931400388582, \"f1\": 0.8749884760763345, \"f2\": 0.8215039988920818, \"f0_5\": 0.9359222152098454, \"p4\": 0.8638666766714939, \"phi\": 0.7524097988705138}, {\"truth_threshold\": -0.54, \"match_probability\": 0.4075025261863895, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9489, \"tn\": 7874, \"fp\": 175, \"fn\": 2535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7891716566866267, \"tn_rate\": 0.9782581687166108, \"fp_rate\": 0.021741831283389242, \"fn_rate\": 0.21082834331337325, \"precision\": 0.9818915562913907, \"recall\": 0.7891716566866267, \"specificity\": 0.9782581687166108, \"npv\": 0.7564607551157652, \"accuracy\": 0.8649927763662631, \"f1\": 0.8750461084470675, \"f2\": 0.8214162049861495, \"f0_5\": 0.9361681136543015, \"p4\": 0.8639748243689942, \"phi\": 0.7527506794611816}, {\"truth_threshold\": -0.52, \"match_probability\": 0.4108538975049788, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9483, \"tn\": 7874, \"fp\": 175, \"fn\": 2541, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7886726546906188, \"tn_rate\": 0.9782581687166108, \"fp_rate\": 0.021741831283389242, \"fn_rate\": 0.21132734530938124, \"precision\": 0.9818803064816732, \"recall\": 0.7886726546906188, \"specificity\": 0.9782581687166108, \"npv\": 0.7560249639942391, \"accuracy\": 0.8646938673840482, \"f1\": 0.8747348030624481, \"f2\": 0.820982096478166, \"f0_5\": 0.9360194251421352, \"p4\": 0.8636809319857042, \"phi\": 0.7522780713822688}, {\"truth_threshold\": -0.5, \"match_probability\": 0.4142135623730951, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9476, \"tn\": 7874, \"fp\": 175, \"fn\": 2548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7880904856952761, \"tn_rate\": 0.9782581687166108, \"fp_rate\": 0.021741831283389242, \"fn_rate\": 0.21190951430472388, \"precision\": 0.9818671640244534, \"recall\": 0.7880904856952761, \"specificity\": 0.9782581687166108, \"npv\": 0.7555171752062944, \"accuracy\": 0.8643451402381308, \"f1\": 0.8743713956170703, \"f2\": 0.8204755225379673, \"f0_5\": 0.9358457770403729, \"p4\": 0.8633380675517562, \"phi\": 0.7517270090623869}, {\"truth_threshold\": -0.48, \"match_probability\": 0.41758122760754685, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9473, \"tn\": 7874, \"fp\": 175, \"fn\": 2551, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7878409846972722, \"tn_rate\": 0.9782581687166108, \"fp_rate\": 0.021741831283389242, \"fn_rate\": 0.21215901530272788, \"precision\": 0.9818615257048093, \"recall\": 0.7878409846972722, \"specificity\": 0.9782581687166108, \"npv\": 0.7552997601918465, \"accuracy\": 0.8641956857470233, \"f1\": 0.8742155777039498, \"f2\": 0.8202583818232198, \"f0_5\": 0.9357712976134028, \"p4\": 0.8631911288871129, \"phi\": 0.751490942763063}, {\"truth_threshold\": -0.46, \"match_probability\": 0.4209565970861701, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9463, \"tn\": 7876, \"fp\": 173, \"fn\": 2561, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7870093147039254, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.2129906852960745, \"precision\": 0.9820464923204649, \"recall\": 0.7870093147039254, \"specificity\": 0.9785066467884209, \"npv\": 0.7546229759509437, \"accuracy\": 0.8637971404374035, \"f1\": 0.8737765466297323, \"f2\": 0.8195628074551375, \"f0_5\": 0.9356707799398829, \"p4\": 0.8628043493585908, \"phi\": 0.7509542171836063}, {\"truth_threshold\": -0.44, \"match_probability\": 0.42433937184654724, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9457, \"tn\": 7876, \"fp\": 173, \"fn\": 2567, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7865103127079175, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.2134896872920825, \"precision\": 0.9820353063343717, \"recall\": 0.7865103127079175, \"specificity\": 0.9785066467884209, \"npv\": 0.7541894091736091, \"accuracy\": 0.8634982314551886, \"f1\": 0.8734644869308211, \"f2\": 0.8191282957419533, \"f0_5\": 0.9355215257993036, \"p4\": 0.8625104808342197, \"phi\": 0.750482773529128}, {\"truth_threshold\": -0.42, \"match_probability\": 0.4277292501869187, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9455, \"tn\": 7876, \"fp\": 173, \"fn\": 2569, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7863439787092482, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.21365602129075184, \"precision\": 0.9820315745741587, \"recall\": 0.7863439787092482, \"specificity\": 0.9785066467884209, \"npv\": 0.7540449976065103, \"accuracy\": 0.8633985951277836, \"f1\": 0.87336042859782, \"f2\": 0.8189834384311552, \"f0_5\": 0.9354717429159412, \"p4\": 0.8624125262547396, \"phi\": 0.7503256803859008}, {\"truth_threshold\": -0.4, \"match_probability\": 0.43112592776921604, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9452, \"tn\": 7876, \"fp\": 173, \"fn\": 2572, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7860944777112442, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.2139055222887558, \"precision\": 0.982025974025974, \"recall\": 0.7860944777112442, \"specificity\": 0.9785066467884209, \"npv\": 0.7538284839203675, \"accuracy\": 0.8632491406366761, \"f1\": 0.873204305048732, \"f2\": 0.8187661336428683, \"f0_5\": 0.9353970390309556, \"p4\": 0.8622655958585279, \"phi\": 0.7500900919315387}, {\"truth_threshold\": -0.38, \"match_probability\": 0.434529097724148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9449, \"tn\": 7876, \"fp\": 173, \"fn\": 2575, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7858449767132402, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.2141550232867598, \"precision\": 0.9820203699854501, \"recall\": 0.7858449767132402, \"specificity\": 0.9785066467884209, \"npv\": 0.753612094536408, \"accuracy\": 0.8630996861455686, \"f1\": 0.8730481382241523, \"f2\": 0.8185488062649433, \"f0_5\": 0.935322299651568, \"p4\": 0.8621186672101937, \"phi\": 0.7498545649376352}, {\"truth_threshold\": -0.36, \"match_probability\": 0.4379384507582655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9443, \"tn\": 7876, \"fp\": 173, \"fn\": 2581, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7853459747172322, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.2146540252827678, \"precision\": 0.9820091514143094, \"recall\": 0.7853459747172322, \"specificity\": 0.9785066467884209, \"npv\": 0.7531796882471072, \"accuracy\": 0.8628007771633538, \"f1\": 0.8727356746765249, \"f2\": 0.8181140837260882, \"f0_5\": 0.9351727143083505, \"p4\": 0.8618248150683036, \"phi\": 0.7493836950968925}, {\"truth_threshold\": -0.32, \"match_probability\": 0.4447744574251037, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9431, \"tn\": 7876, \"fp\": 173, \"fn\": 2593, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7843479707252162, \"tn_rate\": 0.9785066467884209, \"fp_rate\": 0.021493353211579077, \"fn_rate\": 0.21565202927478377, \"precision\": 0.9819866722199083, \"recall\": 0.7843479707252162, \"specificity\": 0.9785066467884209, \"npv\": 0.7523163625943261, \"accuracy\": 0.862202959198924, \"f1\": 0.8721102274828926, \"f2\": 0.8172443674176777, \"f0_5\": 0.9348731165741475, \"p4\": 0.8612371307809543, \"phi\": 0.7484426903660131}, {\"truth_threshold\": -0.3, \"match_probability\": 0.44820048133989093, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9429, \"tn\": 7877, \"fp\": 172, \"fn\": 2595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.784181636726547, \"tn_rate\": 0.978630885824326, \"fp_rate\": 0.021369114175673998, \"fn_rate\": 0.2158183632734531, \"precision\": 0.9820851994583898, \"recall\": 0.784181636726547, \"specificity\": 0.978630885824326, \"npv\": 0.752196333078686, \"accuracy\": 0.8621531410352214, \"f1\": 0.8720462427745664, \"f2\": 0.8171135414319636, \"f0_5\": 0.9348972792892837, \"p4\": 0.8611906578615285, \"phi\": 0.7484110822917628}, {\"truth_threshold\": -0.28, \"match_probability\": 0.45163142912472937, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9423, \"tn\": 7877, \"fp\": 172, \"fn\": 2601, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7836826347305389, \"tn_rate\": 0.978630885824326, \"fp_rate\": 0.021369114175673998, \"fn_rate\": 0.21631736526946108, \"precision\": 0.9820739968733716, \"recall\": 0.7836826347305389, \"specificity\": 0.978630885824326, \"npv\": 0.7517656041229243, \"accuracy\": 0.8618542320530065, \"f1\": 0.8717331976502151, \"f2\": 0.8166785113795912, \"f0_5\": 0.9347472422823585, \"p4\": 0.8608968227542131, \"phi\": 0.7479410737204258}, {\"truth_threshold\": -0.26, \"match_probability\": 0.4550669810351646, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9420, \"tn\": 7878, \"fp\": 171, \"fn\": 2604, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.783433133732535, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21656686626746507, \"precision\": 0.9821707851110416, \"recall\": 0.783433133732535, \"specificity\": 0.9787551248602311, \"npv\": 0.7515741270749857, \"accuracy\": 0.8617545957256015, \"f1\": 0.871616932685635, \"f2\": 0.8164751157106453, \"f0_5\": 0.9347463681829007, \"p4\": 0.8608013704940298, \"phi\": 0.7478313692740965}, {\"truth_threshold\": -0.24, \"match_probability\": 0.4585068155821077, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9411, \"tn\": 7878, \"fp\": 171, \"fn\": 2613, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7826846307385229, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21731536926147704, \"precision\": 0.9821540388227927, \"recall\": 0.7826846307385229, \"specificity\": 0.9787551248602311, \"npv\": 0.7509293680297398, \"accuracy\": 0.8613062322522792, \"f1\": 0.8711469036378784, \"f2\": 0.8158223239363362, \"f0_5\": 0.9345209723546235, \"p4\": 0.8603606266380275, \"phi\": 0.7471270642583457}, {\"truth_threshold\": -0.22, \"match_probability\": 0.46195060965049234, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9409, \"tn\": 7878, \"fp\": 171, \"fn\": 2615, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7825182967398536, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21748170326014638, \"precision\": 0.9821503131524009, \"recall\": 0.7825182967398536, \"specificity\": 0.9787551248602311, \"npv\": 0.7507862384446774, \"accuracy\": 0.8612065959248743, \"f1\": 0.8710423995556379, \"f2\": 0.8156772314307511, \"f0_5\": 0.934470840616558, \"p4\": 0.8602626853362663, \"phi\": 0.7469706262297566}, {\"truth_threshold\": -0.2, \"match_probability\": 0.46539803861923645, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9406, \"tn\": 7878, \"fp\": 171, \"fn\": 2618, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7822687957418496, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21773120425815037, \"precision\": 0.9821447217291427, \"recall\": 0.7822687957418496, \"specificity\": 0.9787551248602311, \"npv\": 0.7505716463414634, \"accuracy\": 0.8610571414337668, \"f1\": 0.8708856071478173, \"f2\": 0.8154595738040331, \"f0_5\": 0.9343956131288246, \"p4\": 0.8601157745664489, \"phi\": 0.746736019700677}, {\"truth_threshold\": -0.18, \"match_probability\": 0.4688487764824174, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9396, \"tn\": 7878, \"fp\": 171, \"fn\": 2628, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.781437125748503, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.218562874251497, \"precision\": 0.9821260583254939, \"recall\": 0.781437125748503, \"specificity\": 0.9787551248602311, \"npv\": 0.7498572244431754, \"accuracy\": 0.8605589597967419, \"f1\": 0.870362651104627, \"f2\": 0.8147338848134853, \"f0_5\": 0.9341445955619184, \"p4\": 0.8596260819818963, \"phi\": 0.7459544350266201}, {\"truth_threshold\": -0.16, \"match_probability\": 0.47230249597156454, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9389, \"tn\": 7878, \"fp\": 171, \"fn\": 2635, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7808549567531603, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21914504324683964, \"precision\": 0.9821129707112971, \"recall\": 0.7808549567531603, \"specificity\": 0.9787551248602311, \"npv\": 0.749357937791306, \"accuracy\": 0.8602102326508245, \"f1\": 0.8699962935507783, \"f2\": 0.8142257527403913, \"f0_5\": 0.9339686455514882, \"p4\": 0.8592833059801775, \"phi\": 0.7454077250106037}, {\"truth_threshold\": -0.14, \"match_probability\": 0.47575886867897205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9383, \"tn\": 7878, \"fp\": 171, \"fn\": 2641, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7803559547571524, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.21964404524284764, \"precision\": 0.9821017374921499, \"recall\": 0.7803559547571524, \"specificity\": 0.9787551248602311, \"npv\": 0.748930506702158, \"accuracy\": 0.8599113236686096, \"f1\": 0.8696820836036704, \"f2\": 0.8137901127493495, \"f0_5\": 0.9338176751592356, \"p4\": 0.8589895035030254, \"phi\": 0.74493937748347}, {\"truth_threshold\": -0.12, \"match_probability\": 0.4792175651819362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9376, \"tn\": 7878, \"fp\": 171, \"fn\": 2648, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7797737857618097, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.22022621423819028, \"precision\": 0.9820886142243637, \"recall\": 0.7797737857618097, \"specificity\": 0.9787551248602311, \"npv\": 0.7484324529735892, \"accuracy\": 0.8595625965226922, \"f1\": 0.869315284409624, \"f2\": 0.8132817514702566, \"f0_5\": 0.9336413606309248, \"p4\": 0.8586467401387808, \"phi\": 0.7443932759557369}, {\"truth_threshold\": -0.1, \"match_probability\": 0.48267825516781476, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9365, \"tn\": 7878, \"fp\": 171, \"fn\": 2659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7788589487691284, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.22114105123087158, \"precision\": 0.9820679530201343, \"recall\": 0.7788589487691284, \"specificity\": 0.9787551248602311, \"npv\": 0.7476511340988896, \"accuracy\": 0.8590145967219648, \"f1\": 0.8687384044526901, \"f2\": 0.8124826485285952, \"f0_5\": 0.933363897305055, \"p4\": 0.8581081248080697, \"phi\": 0.7435357760036441}, {\"truth_threshold\": -0.08, \"match_probability\": 0.4861406075598103, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9348, \"tn\": 7878, \"fp\": 171, \"fn\": 2676, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7774451097804391, \"tn_rate\": 0.9787551248602311, \"fp_rate\": 0.021244875139768915, \"fn_rate\": 0.22255489021956087, \"precision\": 0.9820359281437125, \"recall\": 0.7774451097804391, \"specificity\": 0.9787551248602311, \"npv\": 0.7464468447981808, \"accuracy\": 0.8581676879390225, \"f1\": 0.8678457039409553, \"f2\": 0.8112470710752409, \"f0_5\": 0.932934131736527, \"p4\": 0.8572757477797973, \"phi\": 0.7422121285928612}, {\"truth_threshold\": -0.06, \"match_probability\": 0.48960429064337574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9342, \"tn\": 7879, \"fp\": 170, \"fn\": 2682, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7769461077844312, \"tn_rate\": 0.9788793638961362, \"fp_rate\": 0.021120636103863832, \"fn_rate\": 0.22305389221556887, \"precision\": 0.9821278385197645, \"recall\": 0.7769461077844312, \"specificity\": 0.9788793638961362, \"npv\": 0.7460467758734969, \"accuracy\": 0.8579185971205101, \"f1\": 0.8675705794947994, \"f2\": 0.8108248854325788, \"f0_5\": 0.9328566863716249, \"p4\": 0.8570333741631216, \"phi\": 0.7418712296548519}, {\"truth_threshold\": -0.04, \"match_probability\": 0.49306897219313867, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9339, \"tn\": 7910, \"fp\": 139, \"fn\": 2685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7766966067864272, \"tn_rate\": 0.9827307740091937, \"fp_rate\": 0.01726922599080631, \"fn_rate\": 0.22330339321357284, \"precision\": 0.985334458746571, \"recall\": 0.7766966067864272, \"specificity\": 0.9827307740091937, \"npv\": 0.7465785747994337, \"accuracy\": 0.8593135057041797, \"f1\": 0.8686633801506837, \"f2\": 0.8110431792128391, \"f0_5\": 0.9350969240628004, \"p4\": 0.8584788456810402, \"phi\": 0.7455432905177403}, {\"truth_threshold\": -0.02, \"match_probability\": 0.4965343196002423, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9334, \"tn\": 7911, \"fp\": 138, \"fn\": 2690, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7762807717897539, \"tn_rate\": 0.9828550130450988, \"fp_rate\": 0.01714498695490123, \"fn_rate\": 0.22371922821024617, \"precision\": 0.9854307432432432, \"recall\": 0.7762807717897539, \"specificity\": 0.9828550130450988, \"npv\": 0.7462503537402132, \"accuracy\": 0.8591142330493698, \"f1\": 0.8684406401190919, \"f2\": 0.8106934408004447, \"f0_5\": 0.9350456803974996, \"p4\": 0.8582852428546749, \"phi\": 0.745282029709131}, {\"truth_threshold\": 0.0, \"match_probability\": 0.5, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9328, \"tn\": 7911, \"fp\": 138, \"fn\": 2696, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7757817697937458, \"tn_rate\": 0.9828550130450988, \"fp_rate\": 0.01714498695490123, \"fn_rate\": 0.22421823020625417, \"precision\": 0.9854215085569407, \"recall\": 0.7757817697937458, \"specificity\": 0.9828550130450988, \"npv\": 0.745828226642783, \"accuracy\": 0.8588153240671549, \"f1\": 0.8681247091670544, \"f2\": 0.8102567666168653, \"f0_5\": 0.9348941629249519, \"p4\": 0.8579913183177176, \"phi\": 0.7448173914213305}, {\"truth_threshold\": 0.02, \"match_probability\": 0.5034656803997578, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9324, \"tn\": 7911, \"fp\": 138, \"fn\": 2700, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7754491017964071, \"tn_rate\": 0.9828550130450988, \"fp_rate\": 0.01714498695490123, \"fn_rate\": 0.2245508982035928, \"precision\": 0.9854153455928979, \"recall\": 0.7754491017964071, \"specificity\": 0.9828550130450988, \"npv\": 0.7455470737913485, \"accuracy\": 0.858616051412345, \"f1\": 0.8679139905054454, \"f2\": 0.8099655999166059, \"f0_5\": 0.9347930702598652, \"p4\": 0.8577953702074161, \"phi\": 0.7445077638370043}, {\"truth_threshold\": 0.04, \"match_probability\": 0.5069310278068614, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9321, \"tn\": 7912, \"fp\": 137, \"fn\": 2703, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7751996007984032, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.2248003992015968, \"precision\": 0.9855149080143794, \"recall\": 0.7751996007984032, \"specificity\": 0.9829792520810039, \"npv\": 0.7453603391427226, \"accuracy\": 0.8585164150849399, \"f1\": 0.8677962945722, \"f2\": 0.8097612676790492, \"f0_5\": 0.9347922015404364, \"p4\": 0.8576997301635103, \"phi\": 0.7444018783476601}, {\"truth_threshold\": 0.06, \"match_probability\": 0.5103957093566241, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9317, \"tn\": 7912, \"fp\": 137, \"fn\": 2707, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7748669328010646, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22513306719893547, \"precision\": 0.9855087793526549, \"recall\": 0.7748669328010646, \"specificity\": 0.9829792520810039, \"npv\": 0.745079574347867, \"accuracy\": 0.85831714243013, \"f1\": 0.8675854362603594, \"f2\": 0.809470026064292, \"f0_5\": 0.9346910112359551, \"p4\": 0.8575037808876896, \"phi\": 0.7440924650681605}, {\"truth_threshold\": 0.08, \"match_probability\": 0.5138593924401896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9311, \"tn\": 7912, \"fp\": 137, \"fn\": 2713, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7743679308050565, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22563206919494344, \"precision\": 0.9854995766299746, \"recall\": 0.7743679308050565, \"specificity\": 0.9829792520810039, \"npv\": 0.7446588235294118, \"accuracy\": 0.8580182334479151, \"f1\": 0.8672690014903129, \"f2\": 0.8090330877241763, \"f0_5\": 0.9345391039023607, \"p4\": 0.8572098590226641, \"phi\": 0.7436285412901418}, {\"truth_threshold\": 0.1, \"match_probability\": 0.5173217448321853, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9303, \"tn\": 7912, \"fp\": 137, \"fn\": 2721, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7737025948103793, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22629740518962077, \"precision\": 0.9854872881355933, \"recall\": 0.7737025948103793, \"specificity\": 0.9829792520810039, \"npv\": 0.7440985610834195, \"accuracy\": 0.8576196881382953, \"f1\": 0.866846813268729, \"f2\": 0.808450361512792, \"f0_5\": 0.9343363329583803, \"p4\": 0.856817966742938, \"phi\": 0.743010341686346}, {\"truth_threshold\": 0.12, \"match_probability\": 0.5207824348180637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9299, \"tn\": 7912, \"fp\": 137, \"fn\": 2725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7733699268130406, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.2266300731869594, \"precision\": 0.9854811360746079, \"recall\": 0.7733699268130406, \"specificity\": 0.9829792520810039, \"npv\": 0.7438187458869983, \"accuracy\": 0.8574204154834852, \"f1\": 0.8666356011183597, \"f2\": 0.8081589376347076, \"f0_5\": 0.9342348497026202, \"p4\": 0.8566220219985273, \"phi\": 0.7427013982006392}, {\"truth_threshold\": 0.14, \"match_probability\": 0.5242411313210279, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9297, \"tn\": 7912, \"fp\": 137, \"fn\": 2727, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7732035928143712, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22679640718562874, \"precision\": 0.9854780580877677, \"recall\": 0.7732035928143712, \"specificity\": 0.9829792520810039, \"npv\": 0.7436789171914654, \"accuracy\": 0.8573207791560803, \"f1\": 0.8665299655140274, \"f2\": 0.8080132104988702, \"f0_5\": 0.9341840836012861, \"p4\": 0.8565240499514739, \"phi\": 0.7425469654789232}, {\"truth_threshold\": 0.16, \"match_probability\": 0.5276975040284355, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9295, \"tn\": 7912, \"fp\": 137, \"fn\": 2729, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.773037258815702, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22696274118429807, \"precision\": 0.9854749787955894, \"recall\": 0.773037258815702, \"specificity\": 0.9829792520810039, \"npv\": 0.7435391410581712, \"accuracy\": 0.8572211428286753, \"f1\": 0.8664243102162565, \"f2\": 0.807867473230427, \"f0_5\": 0.9341333011738222, \"p4\": 0.8564260781121483, \"phi\": 0.7423925587492597}, {\"truth_threshold\": 0.2, \"match_probability\": 0.5346019613807635, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9292, \"tn\": 7912, \"fp\": 137, \"fn\": 2732, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7727877578176979, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22721224218230207, \"precision\": 0.9854703574079966, \"recall\": 0.7727877578176979, \"specificity\": 0.9829792520810039, \"npv\": 0.7433295753476137, \"accuracy\": 0.8570716883375679, \"f1\": 0.8662657903323544, \"f2\": 0.8076488483268144, \"f0_5\": 0.9340570969039003, \"p4\": 0.8562791207278102, \"phi\": 0.7421609973537295}, {\"truth_threshold\": 0.22, \"match_probability\": 0.5380493903495076, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9286, \"tn\": 7912, \"fp\": 137, \"fn\": 2738, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.77228875582169, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22771124417831004, \"precision\": 0.9854611058049454, \"recall\": 0.77228875582169, \"specificity\": 0.9829792520810039, \"npv\": 0.7429107981220657, \"accuracy\": 0.856772779355353, \"f1\": 0.8659486175222642, \"f2\": 0.8072115301030963, \"f0_5\": 0.9339045780030574, \"p4\": 0.8559852072238717, \"phi\": 0.7416980496746948}, {\"truth_threshold\": 0.24, \"match_probability\": 0.5414931844178922, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9268, \"tn\": 7912, \"fp\": 137, \"fn\": 2756, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.770791749833666, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.229208250166334, \"precision\": 0.9854332801701223, \"recall\": 0.770791749833666, \"specificity\": 0.9829792520810039, \"npv\": 0.7416572928383952, \"accuracy\": 0.8558760524087082, \"f1\": 0.8649960334126651, \"f2\": 0.805899027842994, \"f0_5\": 0.9334461364918217, \"p4\": 0.8551034751780419, \"phi\": 0.7403106035302626}, {\"truth_threshold\": 0.26, \"match_probability\": 0.5449330189648354, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9266, \"tn\": 7912, \"fp\": 137, \"fn\": 2758, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7706254158349967, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.22937458416500334, \"precision\": 0.9854301818568542, \"recall\": 0.7706254158349967, \"specificity\": 0.9829792520810039, \"npv\": 0.741518275538894, \"accuracy\": 0.8557764160813033, \"f1\": 0.8648900919400756, \"f2\": 0.805753143532931, \"f0_5\": 0.9333951164477395, \"p4\": 0.8550055055871106, \"phi\": 0.7401565718331303}, {\"truth_threshold\": 0.28, \"match_probability\": 0.5483685708752706, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9258, \"tn\": 7912, \"fp\": 137, \"fn\": 2766, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7699600798403193, \"tn_rate\": 0.9829792520810039, \"fp_rate\": 0.01702074791899615, \"fn_rate\": 0.23003992015968064, \"precision\": 0.9854177754124535, \"recall\": 0.7699600798403193, \"specificity\": 0.9829792520810039, \"npv\": 0.7409627271024536, \"accuracy\": 0.8553778707716834, \"f1\": 0.8644661282039311, \"f2\": 0.8051695047920544, \"f0_5\": 0.9331908717038948, \"p4\": 0.8546136281779076, \"phi\": 0.7395407022498823}, {\"truth_threshold\": 0.3, \"match_probability\": 0.5517995186601091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9252, \"tn\": 7914, \"fp\": 135, \"fn\": 2772, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7694610778443114, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23053892215568864, \"precision\": 0.9856184084372004, \"recall\": 0.7694610778443114, \"specificity\": 0.9832277301528141, \"npv\": 0.7405951712521056, \"accuracy\": 0.8551785981168735, \"f1\": 0.864228667507356, \"f2\": 0.8047596680757789, \"f0_5\": 0.9331880900508351, \"p4\": 0.854422242810182, \"phi\": 0.7393326948320824}, {\"truth_threshold\": 0.32, \"match_probability\": 0.5552255425748963, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9251, \"tn\": 7914, \"fp\": 135, \"fn\": 2773, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7693779108449768, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23062208915502327, \"precision\": 0.9856168761985936, \"recall\": 0.7693779108449768, \"specificity\": 0.9832277301528141, \"npv\": 0.7405258725554412, \"accuracy\": 0.8551287799531709, \"f1\": 0.8641756188696871, \"f2\": 0.8046866845273303, \"f0_5\": 0.9331625242091672, \"p4\": 0.8543732566578555, \"phi\": 0.7392557939454572}, {\"truth_threshold\": 0.34, \"match_probability\": 0.5586463247370707, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9248, \"tn\": 7914, \"fp\": 135, \"fn\": 2776, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7691284098469727, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23087159015302727, \"precision\": 0.9856122775231803, \"recall\": 0.7691284098469727, \"specificity\": 0.9832277301528141, \"npv\": 0.7403180542563144, \"accuracy\": 0.8549793254620635, \"f1\": 0.8640164432195077, \"f2\": 0.8044677186450704, \"f0_5\": 0.933085801921059, \"p4\": 0.8542262982696877, \"phi\": 0.7390251296988385}, {\"truth_threshold\": 0.36, \"match_probability\": 0.5620615492417346, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9237, \"tn\": 7914, \"fp\": 135, \"fn\": 2787, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7682135728542914, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23178642714570857, \"precision\": 0.985595390524968, \"recall\": 0.7682135728542914, \"specificity\": 0.9832277301528141, \"npv\": 0.7395570507429212, \"accuracy\": 0.8544313256613362, \"f1\": 0.8634324172742569, \"f2\": 0.803664648152015, \"f0_5\": 0.932804168686379, \"p4\": 0.8536874513997936, \"phi\": 0.7381798529796963}, {\"truth_threshold\": 0.38, \"match_probability\": 0.5654709022758521, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9234, \"tn\": 7914, \"fp\": 135, \"fn\": 2790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7679640718562875, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23203592814371257, \"precision\": 0.9855907780979827, \"recall\": 0.7679640718562875, \"specificity\": 0.9832277301528141, \"npv\": 0.7393497757847534, \"accuracy\": 0.8542818711702287, \"f1\": 0.8632730332351704, \"f2\": 0.8034455755677369, \"f0_5\": 0.9327272727272727, \"p4\": 0.8535404932114753, \"phi\": 0.7379494569553179}, {\"truth_threshold\": 0.4, \"match_probability\": 0.5688740722307839, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9230, \"tn\": 7914, \"fp\": 135, \"fn\": 2794, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7676314038589488, \"tn_rate\": 0.9832277301528141, \"fp_rate\": 0.016772269847185987, \"fn_rate\": 0.23236859614105124, \"precision\": 0.9855846235985051, \"recall\": 0.7676314038589488, \"specificity\": 0.9832277301528141, \"npv\": 0.7390735898393724, \"accuracy\": 0.8540825985154187, \"f1\": 0.8630604516340175, \"f2\": 0.8031534432049564, \"f0_5\": 0.9326246867674399, \"p4\": 0.8533445489209254, \"phi\": 0.7376423514118993}, {\"truth_threshold\": 0.42, \"match_probability\": 0.5722707498130813, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9222, \"tn\": 7915, \"fp\": 134, \"fn\": 2802, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7669660678642715, \"tn_rate\": 0.9833519691887191, \"fp_rate\": 0.016648030811280905, \"fn_rate\": 0.23303393213572854, \"precision\": 0.9856776400171013, \"recall\": 0.7669660678642715, \"specificity\": 0.9833519691887191, \"npv\": 0.7385462349538117, \"accuracy\": 0.8537338713695013, \"f1\": 0.8626753975678204, \"f2\": 0.8025830258302583, \"f0_5\": 0.9324947419511406, \"p4\": 0.8530038931088179, \"phi\": 0.7371555034421746}, {\"truth_threshold\": 0.44, \"match_probability\": 0.5756606281534528, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9217, \"tn\": 7915, \"fp\": 134, \"fn\": 2807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7665502328675982, \"tn_rate\": 0.9833519691887191, \"fp_rate\": 0.016648030811280905, \"fn_rate\": 0.23344976713240187, \"precision\": 0.9856699818201262, \"recall\": 0.7665502328675982, \"specificity\": 0.9833519691887191, \"npv\": 0.7382018280171609, \"accuracy\": 0.8534847805509889, \"f1\": 0.8624093567251462, \"f2\": 0.8022176963113826, \"f0_5\": 0.9323662701302905, \"p4\": 0.8527589579278779, \"phi\": 0.736772057154364}, {\"truth_threshold\": 0.46, \"match_probability\": 0.57904340291383, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9213, \"tn\": 7916, \"fp\": 133, \"fn\": 2811, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7662175648702595, \"tn_rate\": 0.9834762082246242, \"fp_rate\": 0.016523791775375822, \"fn_rate\": 0.2337824351297405, \"precision\": 0.9857693130751124, \"recall\": 0.7662175648702595, \"specificity\": 0.9834762082246242, \"npv\": 0.7379509648550386, \"accuracy\": 0.8533353260598814, \"f1\": 0.8622367805334581, \"f2\": 0.801939347515755, \"f0_5\": 0.9323388924870466, \"p4\": 0.852614233186339, \"phi\": 0.7365925507543046}, {\"truth_threshold\": 0.48, \"match_probability\": 0.5824187723924531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9210, \"tn\": 7917, \"fp\": 132, \"fn\": 2814, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7659680638722555, \"tn_rate\": 0.9836004472605293, \"fp_rate\": 0.016399552739470743, \"fn_rate\": 0.2340319361277445, \"precision\": 0.9858702633269107, \"recall\": 0.7659680638722555, \"specificity\": 0.9836004472605293, \"npv\": 0.7377690802348337, \"accuracy\": 0.8532356897324764, \"f1\": 0.8621173827576524, \"f2\": 0.801734043664473, \"f0_5\": 0.9323372206025268, \"p4\": 0.8525184884665462, \"phi\": 0.7364898270517268}, {\"truth_threshold\": 0.5, \"match_probability\": 0.5857864376269051, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9196, \"tn\": 7919, \"fp\": 130, \"fn\": 2828, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7648037258815702, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.2351962741184298, \"precision\": 0.9860604760883551, \"recall\": 0.7648037258815702, \"specificity\": 0.9838489253323395, \"npv\": 0.736856797245743, \"accuracy\": 0.8526378717680466, \"f1\": 0.8614519906323185, \"f2\": 0.8007383929504371, \"f0_5\": 0.9321277975997405, \"p4\": 0.8519350505421076, \"phi\": 0.735672436135746}, {\"truth_threshold\": 0.52, \"match_probability\": 0.5891461024950211, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9195, \"tn\": 7919, \"fp\": 130, \"fn\": 2829, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7647205588822356, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23527944111776447, \"precision\": 0.986058981233244, \"recall\": 0.7647205588822356, \"specificity\": 0.9838489253323395, \"npv\": 0.7367882396724972, \"accuracy\": 0.8525880536043442, \"f1\": 0.861398660358799, \"f2\": 0.8006652618380036, \"f0_5\": 0.9321020193009488, \"p4\": 0.8518860594869138, \"phi\": 0.7355959293792684}, {\"truth_threshold\": 0.54, \"match_probability\": 0.5924974738136106, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9193, \"tn\": 7919, \"fp\": 130, \"fn\": 2831, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7645542248835662, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.2354457751164338, \"precision\": 0.9860559905609783, \"recall\": 0.7645542248835662, \"specificity\": 0.9838489253323395, \"npv\": 0.7366511627906976, \"accuracy\": 0.8524884172769391, \"f1\": 0.8612919848222232, \"f2\": 0.8005189919712987, \"f0_5\": 0.9320504501581637, \"p4\": 0.8517880772618285, \"phi\": 0.7354429347352273}, {\"truth_threshold\": 0.56, \"match_probability\": 0.5958402614349186, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9185, \"tn\": 7919, \"fp\": 130, \"fn\": 2839, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7638888888888888, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.2361111111111111, \"precision\": 0.9860440150295223, \"recall\": 0.7638888888888888, \"specificity\": 0.9838489253323395, \"npv\": 0.7361033649377208, \"accuracy\": 0.8520898719673193, \"f1\": 0.8608650827124045, \"f2\": 0.7999338105937887, \"f0_5\": 0.9318440061683305, \"p4\": 0.8513961467051616, \"phi\": 0.7348312074499104}, {\"truth_threshold\": 0.58, \"match_probability\": 0.5991741783407747, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9178, \"tn\": 7919, \"fp\": 130, \"fn\": 2846, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7633067198935463, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23669328010645377, \"precision\": 0.9860335195530726, \"recall\": 0.7633067198935463, \"specificity\": 0.9838489253323395, \"npv\": 0.735624709707385, \"accuracy\": 0.8517411448214018, \"f1\": 0.8604912807050441, \"f2\": 0.7994216430910738, \"f0_5\": 0.9316631476368361, \"p4\": 0.8510532050362556, \"phi\": 0.7342962752974219}, {\"truth_threshold\": 0.6, \"match_probability\": 0.6024989407343608, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9164, \"tn\": 7919, \"fp\": 130, \"fn\": 2860, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.762142381902861, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23785761809713907, \"precision\": 0.9860124811706478, \"recall\": 0.762142381902861, \"specificity\": 0.9838489253323395, \"npv\": 0.7346692643102328, \"accuracy\": 0.8510436905295671, \"f1\": 0.8597429402382962, \"f2\": 0.7983969332636348, \"f0_5\": 0.9313008130081301, \"p4\": 0.8503673136555318, \"phi\": 0.7332273299678812}, {\"truth_threshold\": 0.62, \"match_probability\": 0.6058142681295483, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9159, \"tn\": 7919, \"fp\": 130, \"fn\": 2865, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7617265469061876, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23827345309381237, \"precision\": 0.9860049520938745, \"recall\": 0.7617265469061876, \"specificity\": 0.9838489253323395, \"npv\": 0.7343286350148368, \"accuracy\": 0.8507945997110546, \"f1\": 0.8594754375263923, \"f2\": 0.7980308442972902, \"f0_5\": 0.9311712078080521, \"p4\": 0.8501223494911614, \"phi\": 0.7328458599036018}, {\"truth_threshold\": 0.64, \"match_probability\": 0.6091198834377483, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9156, \"tn\": 7919, \"fp\": 130, \"fn\": 2868, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7614770459081837, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23852295409181637, \"precision\": 0.9860004307559768, \"recall\": 0.7614770459081837, \"specificity\": 0.9838489253323395, \"npv\": 0.7341244090108464, \"accuracy\": 0.8506451452199472, \"f1\": 0.859314875645237, \"f2\": 0.7978111602941689, \"f0_5\": 0.9310933940774487, \"p4\": 0.849975370168857, \"phi\": 0.7326170524998947}, {\"truth_threshold\": 0.66, \"match_probability\": 0.6124155130522262, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9152, \"tn\": 7919, \"fp\": 130, \"fn\": 2872, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.761144377910845, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23885562208915503, \"precision\": 0.9859943977591037, \"recall\": 0.761144377910845, \"specificity\": 0.9838489253323395, \"npv\": 0.7338522843109999, \"accuracy\": 0.8504458725651373, \"f1\": 0.8591007228010888, \"f2\": 0.7975182125553348, \"f0_5\": 0.9309895833333334, \"p4\": 0.8497793967293067, \"phi\": 0.732312062924033}, {\"truth_threshold\": 0.68, \"match_probability\": 0.6157008869298349, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9149, \"tn\": 7919, \"fp\": 130, \"fn\": 2875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.760894876912841, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.239105123087159, \"precision\": 0.985989869598017, \"recall\": 0.760894876912841, \"specificity\": 0.9838489253323395, \"npv\": 0.7336483231424865, \"accuracy\": 0.8502964180740298, \"f1\": 0.8589400553912594, \"f2\": 0.7972984749455337, \"f0_5\": 0.9309116809116809, \"p4\": 0.8496324158617309, \"phi\": 0.7320833858942659}, {\"truth_threshold\": 0.7000000000000001, \"match_probability\": 0.6189757386701197, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9147, \"tn\": 7919, \"fp\": 130, \"fn\": 2877, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7607285429141717, \"tn_rate\": 0.9838489253323395, \"fp_rate\": 0.016151074667660578, \"fn_rate\": 0.23927145708582834, \"precision\": 0.9859868491969387, \"recall\": 0.7607285429141717, \"specificity\": 0.9838489253323395, \"npv\": 0.7335124120044461, \"accuracy\": 0.8501967817466248, \"f1\": 0.8588329186423173, \"f2\": 0.7971519704390567, \"f0_5\": 0.930859724822926, \"p4\": 0.8495344282283808, \"phi\": 0.7319309655360691}, {\"truth_threshold\": 0.72, \"match_probability\": 0.622239805591759, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9141, \"tn\": 8000, \"fp\": 49, \"fn\": 2883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7602295409181636, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.23977045908183633, \"precision\": 0.9946681175190424, \"recall\": 0.7602295409181636, \"specificity\": 0.9939122872406511, \"npv\": 0.7350914269962326, \"accuracy\": 0.8539331440243113, \"f1\": 0.861789384368813, \"f2\": 0.7978389135216283, \"f0_5\": 0.9368850442768121, \"p4\": 0.8533783638780464, \"phi\": 0.7418505220171334}, {\"truth_threshold\": 0.74, \"match_probability\": 0.6254928288063007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9138, \"tn\": 8000, \"fp\": 49, \"fn\": 2886, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7599800399201597, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24001996007984033, \"precision\": 0.9946663764014368, \"recall\": 0.7599800399201597, \"specificity\": 0.9939122872406511, \"npv\": 0.7348888480617307, \"accuracy\": 0.8537836895332038, \"f1\": 0.8616284003583047, \"f2\": 0.7976188397954018, \"f0_5\": 0.9368080045927991, \"p4\": 0.8532311721748177, \"phi\": 0.7416239518535421}, {\"truth_threshold\": 0.76, \"match_probability\": 0.6287345532891625, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9124, \"tn\": 8000, \"fp\": 49, \"fn\": 2900, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7588157019294743, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.2411842980705256, \"precision\": 0.9946582361277663, \"recall\": 0.7588157019294743, \"specificity\": 0.9939122872406511, \"npv\": 0.7339449541284404, \"accuracy\": 0.853086235241369, \"f1\": 0.8608765391328962, \"f2\": 0.7965915242103058, \"f0_5\": 0.9364479842351588, \"p4\": 0.8525442633139582, \"phi\": 0.7405673597347461}, {\"truth_threshold\": 0.78, \"match_probability\": 0.6319647279478622, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9117, \"tn\": 8000, \"fp\": 49, \"fn\": 2907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7582335329341318, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24176646706586827, \"precision\": 0.9946541566659394, \"recall\": 0.7582335329341318, \"specificity\": 0.9939122872406511, \"npv\": 0.7334739158338681, \"accuracy\": 0.8527375080954516, \"f1\": 0.8605002359603586, \"f2\": 0.7960776780412839, \"f0_5\": 0.936267663489977, \"p4\": 0.8522007995680294, \"phi\": 0.7400395167034335}, {\"truth_threshold\": 0.8, \"match_probability\": 0.6351831056874558, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9113, \"tn\": 8000, \"fp\": 49, \"fn\": 2911, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7579008649367931, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24209913506320693, \"precision\": 0.9946518227461253, \"recall\": 0.7579008649367931, \"specificity\": 0.9939122872406511, \"npv\": 0.7332050224544038, \"accuracy\": 0.8525382354406417, \"f1\": 0.8602850939299538, \"f2\": 0.7957839952495721, \"f0_5\": 0.9361645299145299, \"p4\": 0.8520045316207229, \"phi\": 0.7397380273611326}, {\"truth_threshold\": 0.84, \"match_probability\": 0.6415835023901045, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9111, \"tn\": 8000, \"fp\": 49, \"fn\": 2913, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7577345309381237, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24226546906187624, \"precision\": 0.994650655021834, \"recall\": 0.7577345309381237, \"specificity\": 0.9939122872406511, \"npv\": 0.7330706496838633, \"accuracy\": 0.8524385991132367, \"f1\": 0.8601774924471299, \"f2\": 0.7956371384658376, \"f0_5\": 0.9361129376952162, \"p4\": 0.851906396819713, \"phi\": 0.7395873195255203}, {\"truth_threshold\": 0.86, \"match_probability\": 0.6447650477003041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9110, \"tn\": 8000, \"fp\": 49, \"fn\": 2914, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7576513639387891, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.2423486360612109, \"precision\": 0.9946500709684464, \"recall\": 0.7576513639387891, \"specificity\": 0.9939122872406511, \"npv\": 0.7330034817665384, \"accuracy\": 0.8523887809495342, \"f1\": 0.8601236840862956, \"f2\": 0.7955637062265304, \"f0_5\": 0.9360871352240033, \"p4\": 0.8518573292092826, \"phi\": 0.7395119748098719}, {\"truth_threshold\": 0.88, \"match_probability\": 0.6479338488966562, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9106, \"tn\": 8000, \"fp\": 49, \"fn\": 2918, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7573186959414504, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24268130405854957, \"precision\": 0.9946477334789733, \"recall\": 0.7573186959414504, \"specificity\": 0.9939122872406511, \"npv\": 0.7327349331379374, \"accuracy\": 0.8521895082947243, \"f1\": 0.8599083998300203, \"f2\": 0.7952699516165657, \"f0_5\": 0.9359838829043664, \"p4\": 0.8516610573474673, \"phi\": 0.7392106572501782}, {\"truth_threshold\": 0.9, \"match_probability\": 0.6510896797541332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9105, \"tn\": 8000, \"fp\": 49, \"fn\": 2919, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7572355289421158, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24276447105788423, \"precision\": 0.9946471487874153, \"recall\": 0.7572355289421158, \"specificity\": 0.9939122872406511, \"npv\": 0.732667826724059, \"accuracy\": 0.8521396901310218, \"f1\": 0.8598545660591179, \"f2\": 0.7951965065502183, \"f0_5\": 0.9359580592105263, \"p4\": 0.8516119890225765, \"phi\": 0.7391353431763809}, {\"truth_threshold\": 0.92, \"match_probability\": 0.6542323183780514, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9101, \"tn\": 8000, \"fp\": 49, \"fn\": 2923, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7569028609447771, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.2430971390552229, \"precision\": 0.9946448087431694, \"recall\": 0.7569028609447771, \"specificity\": 0.9939122872406511, \"npv\": 0.7323995239403095, \"accuracy\": 0.8519404174762119, \"f1\": 0.8596391801265704, \"f2\": 0.7949027006253712, \"f0_5\": 0.9358547219480092, \"p4\": 0.851415714258768, \"phi\": 0.7388341480881362}, {\"truth_threshold\": 0.9400000000000001, \"match_probability\": 0.6573615472494517, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9099, \"tn\": 8000, \"fp\": 49, \"fn\": 2925, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7567365269461078, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.2432634730538922, \"precision\": 0.9946436379536511, \"recall\": 0.7567365269461078, \"specificity\": 0.9939122872406511, \"npv\": 0.7322654462242563, \"accuracy\": 0.8518407811488069, \"f1\": 0.8595314566408464, \"f2\": 0.7947557822653902, \"f0_5\": 0.9358030278097745, \"p4\": 0.8513175759859442, \"phi\": 0.7386835872413364}, {\"truth_threshold\": 0.96, \"match_probability\": 0.660477153267581, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9096, \"tn\": 8000, \"fp\": 49, \"fn\": 2928, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7564870259481038, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.2435129740518962, \"precision\": 0.9946418808091854, \"recall\": 0.7564870259481038, \"specificity\": 0.9939122872406511, \"npv\": 0.7320644216691069, \"accuracy\": 0.8516913266576994, \"f1\": 0.8593698332467287, \"f2\": 0.7945353854754459, \"f0_5\": 0.9357254546950868, \"p4\": 0.8511703674431639, \"phi\": 0.7384577917996735}, {\"truth_threshold\": 0.98, \"match_probability\": 0.6635789277894779, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9083, \"tn\": 8000, \"fp\": 49, \"fn\": 2941, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7554058549567532, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24459414504324684, \"precision\": 0.9946342531756461, \"recall\": 0.7554058549567532, \"specificity\": 0.9939122872406511, \"npv\": 0.7311945891600402, \"accuracy\": 0.8510436905295671, \"f1\": 0.8586689355265645, \"f2\": 0.7935800657021038, \"f0_5\": 0.9353888614269237, \"p4\": 0.8505324474868873, \"phi\": 0.7374799791806345}, {\"truth_threshold\": 1.0, \"match_probability\": 0.6666666666666666, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9081, \"tn\": 8000, \"fp\": 49, \"fn\": 2943, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7552395209580839, \"tn_rate\": 0.9939122872406511, \"fp_rate\": 0.006087712759348988, \"fn_rate\": 0.24476047904191617, \"precision\": 0.9946330777656078, \"recall\": 0.7552395209580839, \"specificity\": 0.9939122872406511, \"npv\": 0.7310609522068903, \"accuracy\": 0.8509440542021621, \"f1\": 0.8585610286470644, \"f2\": 0.7934330549051131, \"f0_5\": 0.9353370138431114, \"p4\": 0.850434303528628, \"phi\": 0.737329637782806}, {\"truth_threshold\": 1.02, \"match_probability\": 0.6697401702789662, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9078, \"tn\": 8001, \"fp\": 48, \"fn\": 2946, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7549900199600799, \"tn_rate\": 0.9940365262765561, \"fp_rate\": 0.005963473723443906, \"fn_rate\": 0.24500998003992017, \"precision\": 0.9947403024326101, \"recall\": 0.7549900199600799, \"specificity\": 0.9940365262765561, \"npv\": 0.7308851740202795, \"accuracy\": 0.8508444178747572, \"f1\": 0.8584397163120567, \"f2\": 0.7932263814616756, \"f0_5\": 0.9353363006923838, \"p4\": 0.8503380477329204, \"phi\": 0.7372331683319879}, {\"truth_threshold\": 1.04, \"match_probability\": 0.6727992435654236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9076, \"tn\": 8001, \"fp\": 48, \"fn\": 2948, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7548236859614105, \"tn_rate\": 0.9940365262765561, \"fp_rate\": 0.005963473723443906, \"fn_rate\": 0.2451763140385895, \"precision\": 0.9947391494958352, \"recall\": 0.7548236859614105, \"specificity\": 0.9940365262765561, \"npv\": 0.7307516668188876, \"accuracy\": 0.8507447815473521, \"f1\": 0.8583317571401551, \"f2\": 0.7930793428871024, \"f0_5\": 0.9352844187963726, \"p4\": 0.8502399003631392, \"phi\": 0.7370829035340183}, {\"truth_threshold\": 1.06, \"match_probability\": 0.6758436960523875, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9075, \"tn\": 8001, \"fp\": 48, \"fn\": 2949, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7547405189620758, \"tn_rate\": 0.9940365262765561, \"fp_rate\": 0.005963473723443906, \"fn_rate\": 0.24525948103792417, \"precision\": 0.9947385728378823, \"recall\": 0.7547405189620758, \"specificity\": 0.9940365262765561, \"npv\": 0.7306849315068493, \"accuracy\": 0.8506949633836497, \"f1\": 0.8582777698964392, \"f2\": 0.7930058197451896, \"f0_5\": 0.9352584714321048, \"p4\": 0.8501908264213027, \"phi\": 0.7370077802370217}, {\"truth_threshold\": 1.08, \"match_probability\": 0.6788733418787326, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9071, \"tn\": 8001, \"fp\": 48, \"fn\": 2953, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7544078509647372, \"tn_rate\": 0.9940365262765561, \"fp_rate\": 0.005963473723443906, \"fn_rate\": 0.2455921490352628, \"precision\": 0.9947362649413313, \"recall\": 0.7544078509647372, \"specificity\": 0.9940365262765561, \"npv\": 0.730418112105167, \"accuracy\": 0.8504956907288397, \"f1\": 0.8580617698529064, \"f2\": 0.7927117014768854, \"f0_5\": 0.9351546391752578, \"p4\": 0.8499945289202401, \"phi\": 0.7367073476845228}, {\"truth_threshold\": 1.1, \"match_probability\": 0.6818879998182596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9054, \"tn\": 8001, \"fp\": 48, \"fn\": 2970, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7529940119760479, \"tn_rate\": 0.9940365262765561, \"fp_rate\": 0.005963473723443906, \"fn_rate\": 0.2470059880239521, \"precision\": 0.994726433750824, \"recall\": 0.7529940119760479, \"specificity\": 0.9940365262765561, \"npv\": 0.7292863002461034, \"accuracy\": 0.8496487819458974, \"f1\": 0.8571428571428571, \"f2\": 0.7914612399034932, \"f0_5\": 0.9347125867195243, \"p4\": 0.8491602324285601, \"phi\": 0.7354315891906358}, {\"truth_threshold\": 1.12, \"match_probability\": 0.6848874932992853, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9048, \"tn\": 8003, \"fp\": 46, \"fn\": 2976, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7524950099800399, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24750499001996007, \"precision\": 0.9949417198152628, \"recall\": 0.7524950099800399, \"specificity\": 0.9942850043483663, \"npv\": 0.7289370616631752, \"accuracy\": 0.8494495092910875, \"f1\": 0.8568993275878397, \"f2\": 0.791047385906627, \"f0_5\": 0.9347107438016529, \"p4\": 0.8489676275327283, \"phi\": 0.7352402374764979}, {\"truth_threshold\": 1.1400000000000001, \"match_probability\": 0.6878716504214515, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9045, \"tn\": 8003, \"fp\": 46, \"fn\": 2979, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7522455089820359, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24775449101796407, \"precision\": 0.994940050599494, \"recall\": 0.7522455089820359, \"specificity\": 0.9942850043483663, \"npv\": 0.7287379348024039, \"accuracy\": 0.84930005479998, \"f1\": 0.856736916883732, \"f2\": 0.7908265864619581, \"f0_5\": 0.9346325535256675, \"p4\": 0.8488203843623484, \"phi\": 0.735015440605155}, {\"truth_threshold\": 1.16, \"match_probability\": 0.690840303969775, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9042, \"tn\": 8003, \"fp\": 46, \"fn\": 2982, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.751996007984032, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24800399201596807, \"precision\": 0.9949383802816901, \"recall\": 0.751996007984032, \"specificity\": 0.9942850043483663, \"npv\": 0.7285389167045971, \"accuracy\": 0.8491506003088726, \"f1\": 0.8565744600227359, \"f2\": 0.790605763850028, \"f0_5\": 0.9345543244584091, \"p4\": 0.8486731393923765, \"phi\": 0.7347906978143052}, {\"truth_threshold\": 1.18, \"match_probability\": 0.6937932914259702, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9035, \"tn\": 8003, \"fp\": 46, \"fn\": 2989, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7514138389886893, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.2485861610113107, \"precision\": 0.994934478581654, \"recall\": 0.7514138389886893, \"specificity\": 0.9942850043483663, \"npv\": 0.7280749636098981, \"accuracy\": 0.8488018731629552, \"f1\": 0.8561952144041697, \"f2\": 0.7900904209734684, \"f0_5\": 0.934371638950939, \"p4\": 0.8483295606615557, \"phi\": 0.7342665079955711}, {\"truth_threshold\": 1.2, \"match_probability\": 0.6967304549770723, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9033, \"tn\": 8003, \"fp\": 46, \"fn\": 2991, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7512475049900199, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24875249500998003, \"precision\": 0.9949333627051438, \"recall\": 0.7512475049900199, \"specificity\": 0.9942850043483663, \"npv\": 0.7279425140985992, \"accuracy\": 0.8487022368355502, \"f1\": 0.8560868123015685, \"f2\": 0.789943156974202, \"f0_5\": 0.9343194042201076, \"p4\": 0.8482313934431173, \"phi\": 0.7341167934148358}, {\"truth_threshold\": 1.22, \"match_probability\": 0.6996516415213959, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9030, \"tn\": 8003, \"fp\": 46, \"fn\": 2994, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.750998003992016, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24900199600798403, \"precision\": 0.9949316879682679, \"recall\": 0.750998003992016, \"specificity\": 0.9942850043483663, \"npv\": 0.7277439301627716, \"accuracy\": 0.8485527823444428, \"f1\": 0.8559241706161137, \"f2\": 0.7897222416567551, \"f0_5\": 0.9342410196987254, \"p4\": 0.8480841410329064, \"phi\": 0.7338922664362573}, {\"truth_threshold\": 1.24, \"match_probability\": 0.7025567026718631, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9028, \"tn\": 8003, \"fp\": 46, \"fn\": 2996, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7508316699933466, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24916833000665337, \"precision\": 0.9949305708618029, \"recall\": 0.7508316699933466, \"specificity\": 0.9942850043483663, \"npv\": 0.7276116010546413, \"accuracy\": 0.8484531460170378, \"f1\": 0.8558157171295857, \"f2\": 0.7895749518978485, \"f0_5\": 0.9341887417218543, \"p4\": 0.8479859716939253, \"phi\": 0.7337426116902434}, {\"truth_threshold\": 1.26, \"match_probability\": 0.705445494756739, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9023, \"tn\": 8003, \"fp\": 46, \"fn\": 3001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7504158349966733, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.24958416500332667, \"precision\": 0.9949277759400155, \"recall\": 0.7504158349966733, \"specificity\": 0.9942850043483663, \"npv\": 0.7272809887313704, \"accuracy\": 0.8482040551985254, \"f1\": 0.8555444934338406, \"f2\": 0.7892066824105659, \"f0_5\": 0.9340579710144927, \"p4\": 0.847740544564803, \"phi\": 0.7333685793876945}, {\"truth_threshold\": 1.28, \"match_probability\": 0.7083178788178136, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9018, \"tn\": 8003, \"fp\": 46, \"fn\": 3006, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.75, \"tn_rate\": 0.9942850043483663, \"fp_rate\": 0.005714995651633743, \"fn_rate\": 0.25, \"precision\": 0.9949249779346867, \"recall\": 0.75, \"specificity\": 0.9942850043483663, \"npv\": 0.726950676719048, \"accuracy\": 0.8479549643800129, \"f1\": 0.8552731411229135, \"f2\": 0.7888383484954513, \"f0_5\": 0.933927091963546, \"p4\": 0.8474951119434038, \"phi\": 0.7329946962720363}, {\"truth_threshold\": 1.3, \"match_probability\": 0.7111737206060699, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9013, \"tn\": 8004, \"fp\": 45, \"fn\": 3011, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7495841650033267, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2504158349966733, \"precision\": 0.9950320158975491, \"recall\": 0.7495841650033267, \"specificity\": 0.9944092433842714, \"npv\": 0.7266454834316841, \"accuracy\": 0.847755691725203, \"f1\": 0.8550422161085286, \"f2\": 0.7884837456695944, \"f0_5\": 0.9338735079575596, \"p4\": 0.8473005732605569, \"phi\": 0.7327505049350663}, {\"truth_threshold\": 1.32, \"match_probability\": 0.714012890574883, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9009, \"tn\": 8004, \"fp\": 45, \"fn\": 3015, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.749251497005988, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25074850299401197, \"precision\": 0.9950298210735586, \"recall\": 0.749251497005988, \"specificity\": 0.9944092433842714, \"npv\": 0.7263817043288865, \"accuracy\": 0.847556419070393, \"f1\": 0.8548249359521777, \"f2\": 0.7881889763779527, \"f0_5\": 0.933768656716418, \"p4\": 0.8471042150180337, \"phi\": 0.7324516564981259}, {\"truth_threshold\": 1.34, \"match_probability\": 0.7168352638707939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 9001, \"tn\": 8004, \"fp\": 45, \"fn\": 3023, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7485861610113107, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2514138389886893, \"precision\": 0.9950254256024762, \"recall\": 0.7485861610113107, \"specificity\": 0.9944092433842714, \"npv\": 0.7258547202321575, \"accuracy\": 0.8471578737607732, \"f1\": 0.854390128144281, \"f2\": 0.7875993139897098, \"f0_5\": 0.9335587454364421, \"p4\": 0.8467114873076904, \"phi\": 0.731854244692992}, {\"truth_threshold\": 1.36, \"match_probability\": 0.7196407203219027, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8996, \"tn\": 8004, \"fp\": 45, \"fn\": 3028, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7481703260146374, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2518296739853626, \"precision\": 0.9950226744829112, \"recall\": 0.7481703260146374, \"specificity\": 0.9944092433842714, \"npv\": 0.7255257432922407, \"accuracy\": 0.8469087829422608, \"f1\": 0.8541182055542369, \"f2\": 0.7872306911458424, \"f0_5\": 0.9334274093135221, \"p4\": 0.8464660247219765, \"phi\": 0.7314810549853887}, {\"truth_threshold\": 1.3800000000000001, \"match_probability\": 0.7224291444239316, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8991, \"tn\": 8004, \"fp\": 45, \"fn\": 3033, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7477544910179641, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2522455089820359, \"precision\": 0.9950199203187251, \"recall\": 0.7477544910179641, \"specificity\": 0.9944092433842714, \"npv\": 0.7251970644196792, \"accuracy\": 0.8466596921237484, \"f1\": 0.8538461538461538, \"f2\": 0.7868620037807184, \"f0_5\": 0.9332959641255605, \"p4\": 0.8462205560262369, \"phi\": 0.7311080132055536}, {\"truth_threshold\": 1.4000000000000001, \"match_probability\": 0.7252004253240049, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8987, \"tn\": 8004, \"fp\": 45, \"fn\": 3037, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7474218230206254, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25257817697937457, \"precision\": 0.9950177147918512, \"recall\": 0.7474218230206254, \"specificity\": 0.9944092433842714, \"npv\": 0.724934335658002, \"accuracy\": 0.8464604194689384, \"f1\": 0.8536284194528876, \"f2\": 0.7865670074219298, \"f0_5\": 0.9331907293570361, \"p4\": 0.8460241765943959, \"phi\": 0.7308096861328581}, {\"truth_threshold\": 1.42, \"match_probability\": 0.7279544568021957, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8981, \"tn\": 8004, \"fp\": 45, \"fn\": 3043, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7469228210246174, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25307717897538257, \"precision\": 0.9950144028362509, \"recall\": 0.7469228210246174, \"specificity\": 0.9944092433842714, \"npv\": 0.7245405992577171, \"accuracy\": 0.8461615104867235, \"f1\": 0.8533016627078385, \"f2\": 0.786124435418928, \"f0_5\": 0.9330327460106383, \"p4\": 0.8457295998519654, \"phi\": 0.7303623724960531}, {\"truth_threshold\": 1.44, \"match_probability\": 0.7306911372508947, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8979, \"tn\": 8004, \"fp\": 45, \"fn\": 3045, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7467564870259481, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2532435129740519, \"precision\": 0.9950132978723404, \"recall\": 0.7467564870259481, \"specificity\": 0.9944092433842714, \"npv\": 0.7244094488188977, \"accuracy\": 0.8460618741593184, \"f1\": 0.8531927023945268, \"f2\": 0.7859768907563025, \"f0_5\": 0.9329800498753117, \"p4\": 0.8456314055502198, \"phi\": 0.7302133150834335}, {\"truth_threshold\": 1.46, \"match_probability\": 0.7334103696520481, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8972, \"tn\": 8004, \"fp\": 45, \"fn\": 3052, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7461743180306054, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25382568196939453, \"precision\": 0.9950094266385716, \"recall\": 0.7461743180306054, \"specificity\": 0.9944092433842714, \"npv\": 0.7239507959479016, \"accuracy\": 0.8457131470134011, \"f1\": 0.8528111781759422, \"f2\": 0.7854604030605992, \"f0_5\": 0.9327954753389337, \"p4\": 0.8452877172624237, \"phi\": 0.7296917994322828}, {\"truth_threshold\": 1.48, \"match_probability\": 0.7361120615523239, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8967, \"tn\": 8004, \"fp\": 45, \"fn\": 3057, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7457584830339321, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25424151696606784, \"precision\": 0.9950066577896138, \"recall\": 0.7457584830339321, \"specificity\": 0.9944092433842714, \"npv\": 0.7236235421752102, \"accuracy\": 0.8454640561948886, \"f1\": 0.8525385054192812, \"f2\": 0.7850914057575121, \"f0_5\": 0.9326635047428856, \"p4\": 0.8450422176613265, \"phi\": 0.729319464462195}, {\"truth_threshold\": 1.5, \"match_probability\": 0.7387961250362586, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8945, \"tn\": 8004, \"fp\": 45, \"fn\": 3079, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7439288090485695, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2560711909514305, \"precision\": 0.9949944382647385, \"recall\": 0.7439288090485695, \"specificity\": 0.9944092433842714, \"npv\": 0.7221871334476225, \"accuracy\": 0.844368056593434, \"f1\": 0.851337203768916, \"f2\": 0.7834670497144659, \"f0_5\": 0.9320815271757252, \"p4\": 0.8439619374778543, \"phi\": 0.7276829288219069}, {\"truth_threshold\": 1.52, \"match_probability\": 0.74146247669744, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8943, \"tn\": 8004, \"fp\": 45, \"fn\": 3081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7437624750499002, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.2562375249500998, \"precision\": 0.9949933244325768, \"recall\": 0.7437624750499002, \"specificity\": 0.9944092433842714, \"npv\": 0.7220568335588633, \"accuracy\": 0.844268420266029, \"f1\": 0.8512278697886921, \"f2\": 0.7833193188984654, \"f0_5\": 0.9320285142571285, \"p4\": 0.8438637233554088, \"phi\": 0.7275342928879954}, {\"truth_threshold\": 1.54, \"match_probability\": 0.7441110376077843, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8942, \"tn\": 8004, \"fp\": 45, \"fn\": 3082, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7436793080505656, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25632069194943446, \"precision\": 0.9949927673305886, \"recall\": 0.7436793080505656, \"specificity\": 0.9944092433842714, \"npv\": 0.7219917012448133, \"accuracy\": 0.8442186021023265, \"f1\": 0.8511731949930988, \"f2\": 0.7832454496084649, \"f0_5\": 0.9320020011673477, \"p4\": 0.8438146158556937, \"phi\": 0.7274599836500251}, {\"truth_threshold\": 1.56, \"match_probability\": 0.7467417332849615, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8937, \"tn\": 8004, \"fp\": 45, \"fn\": 3087, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7432634730538922, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25673652694610777, \"precision\": 0.9949899799599199, \"recall\": 0.7432634730538922, \"specificity\": 0.9944092433842714, \"npv\": 0.7216662158506898, \"accuracy\": 0.843969511283814, \"f1\": 0.8508997429305912, \"f2\": 0.7828760643330179, \"f0_5\": 0.9318693693693694, \"p4\": 0.8435690739355661, \"phi\": 0.7270885246762273}, {\"truth_threshold\": 1.58, \"match_probability\": 0.7493544936580313, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8933, \"tn\": 8004, \"fp\": 45, \"fn\": 3091, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7429308050565535, \"tn_rate\": 0.9944092433842714, \"fp_rate\": 0.005590756615728662, \"fn_rate\": 0.25706919494344643, \"precision\": 0.994987747828024, \"recall\": 0.7429308050565535, \"specificity\": 0.9944092433842714, \"npv\": 0.7214060387561965, \"accuracy\": 0.8437702386290041, \"f1\": 0.8506808875345205, \"f2\": 0.7825805095139643, \"f0_5\": 0.9317631842456608, \"p4\": 0.8433726350386196, \"phi\": 0.72679146204583}, {\"truth_threshold\": 1.6, \"match_probability\": 0.7519492530313435, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8928, \"tn\": 8005, \"fp\": 44, \"fn\": 3096, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7425149700598802, \"tn_rate\": 0.9945334824201765, \"fp_rate\": 0.00546651757982358, \"fn_rate\": 0.25748502994011974, \"precision\": 0.9950958537672759, \"recall\": 0.7425149700598802, \"specificity\": 0.9945334824201765, \"npv\": 0.7211062066480497, \"accuracy\": 0.8435709659741942, \"f1\": 0.8504477043246332, \"f2\": 0.7822247143758323, \"f0_5\": 0.9317081315745533, \"p4\": 0.8431779008859553, \"phi\": 0.7265504939728167}, {\"truth_threshold\": 1.62, \"match_probability\": 0.754525950046764, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8920, \"tn\": 8007, \"fp\": 42, \"fn\": 3104, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7418496340652029, \"tn_rate\": 0.9947819604919865, \"fp_rate\": 0.005218039508013418, \"fn_rate\": 0.25815036593479707, \"precision\": 0.9953135460834636, \"recall\": 0.7418496340652029, \"specificity\": 0.9947819604919865, \"npv\": 0.7206372063720637, \"accuracy\": 0.8432720569919793, \"f1\": 0.850090536548175, \"f2\": 0.7816607662378632, \"f0_5\": 0.9316510695187166, \"p4\": 0.842886611944125, \"phi\": 0.7262175599679029}, {\"truth_threshold\": 1.6400000000000001, \"match_probability\": 0.7570845276442862, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8914, \"tn\": 8007, \"fp\": 42, \"fn\": 3110, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7413506320691949, \"tn_rate\": 0.9947819604919865, \"fp_rate\": 0.005218039508013418, \"fn_rate\": 0.25864936793080506, \"precision\": 0.9953104064314426, \"recall\": 0.7413506320691949, \"specificity\": 0.9947819604919865, \"npv\": 0.7202482684177386, \"accuracy\": 0.8429731480097643, \"f1\": 0.8497616777883699, \"f2\": 0.7812171352450397, \"f0_5\": 0.931491389399766, \"p4\": 0.8425919037349725, \"phi\": 0.7257727347085803}, {\"truth_threshold\": 1.6600000000000001, \"match_probability\": 0.7596249330210829, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8911, \"tn\": 8008, \"fp\": 41, \"fn\": 3113, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7411011310711909, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.25889886892880903, \"precision\": 0.995420017873101, \"recall\": 0.7411011310711909, \"specificity\": 0.9949061995278916, \"npv\": 0.7200791295746786, \"accuracy\": 0.8428735116823594, \"f1\": 0.8496376811594203, \"f2\": 0.7810089748983312, \"f0_5\": 0.9314893794948989, \"p4\": 0.8424953461732629, \"phi\": 0.7256807959144017}, {\"truth_threshold\": 1.68, \"match_probability\": 0.7621471175890653, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8909, \"tn\": 8008, \"fp\": 41, \"fn\": 3115, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7409347970725216, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.25906520292747837, \"precision\": 0.9954189944134079, \"recall\": 0.7409347970725216, \"specificity\": 0.9949061995278916, \"npv\": 0.7199496538703587, \"accuracy\": 0.8427738753549544, \"f1\": 0.8495279870315628, \"f2\": 0.7808610594958455, \"f0_5\": 0.9314360990297759, \"p4\": 0.8423971037699084, \"phi\": 0.7255326175230286}, {\"truth_threshold\": 1.7, \"match_probability\": 0.7646510369310004, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8907, \"tn\": 8008, \"fp\": 41, \"fn\": 3117, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7407684630738522, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2592315369261477, \"precision\": 0.9954179704962003, \"recall\": 0.7407684630738522, \"specificity\": 0.9949061995278916, \"npv\": 0.7198202247191011, \"accuracy\": 0.8426742390275495, \"f1\": 0.8494182719816898, \"f2\": 0.7807131337213379, \"f0_5\": 0.9313828007361553, \"p4\": 0.842298860065295, \"phi\": 0.7253844621612026}, {\"truth_threshold\": 1.72, \"match_probability\": 0.767136650755255, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8906, \"tn\": 8008, \"fp\": 41, \"fn\": 3118, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7406852960745176, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2593147039254824, \"precision\": 0.9954174583659328, \"recall\": 0.7406852960745176, \"specificity\": 0.9949061995278916, \"npv\": 0.7197555275930253, \"accuracy\": 0.8426244208638469, \"f1\": 0.8493634066091269, \"f2\": 0.7806391669442351, \"f0_5\": 0.9313561449008617, \"p4\": 0.8422497377227093, \"phi\": 0.7253103931117979}, {\"truth_threshold\": 1.74, \"match_probability\": 0.7696039228492181, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8901, \"tn\": 8008, \"fp\": 41, \"fn\": 3123, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7402694610778443, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2597305389221557, \"precision\": 0.9954148959964214, \"recall\": 0.7402694610778443, \"specificity\": 0.9949061995278916, \"npv\": 0.7194322163327643, \"accuracy\": 0.8423753300453345, \"f1\": 0.849089001240103, \"f2\": 0.780269294154774, \"f0_5\": 0.9312227987947773, \"p4\": 0.842004121070056, \"phi\": 0.7249401341067494}, {\"truth_threshold\": 1.76, \"match_probability\": 0.7720528210314674, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8894, \"tn\": 8008, \"fp\": 41, \"fn\": 3130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7396872920825016, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.26031270791749833, \"precision\": 0.9954113038612199, \"recall\": 0.7396872920825016, \"specificity\": 0.9949061995278916, \"npv\": 0.7189800682348716, \"accuracy\": 0.8420266028994171, \"f1\": 0.8487046137697409, \"f2\": 0.7797513632936474, \"f0_5\": 0.9310359266393099, \"p4\": 0.8416602437569214, \"phi\": 0.7244220126448447}, {\"truth_threshold\": 1.78, \"match_probability\": 0.774483317102736, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8882, \"tn\": 8008, \"fp\": 41, \"fn\": 3142, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7386892880904857, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2613107119095143, \"precision\": 0.995405132802869, \"recall\": 0.7386892880904857, \"specificity\": 0.9949061995278916, \"npv\": 0.7182062780269058, \"accuracy\": 0.8414287849349873, \"f1\": 0.8480450661192533, \"f2\": 0.7788631859555587, \"f0_5\": 0.9307150641294325, \"p4\": 0.8410707009491089, \"phi\": 0.7235344572981351}, {\"truth_threshold\": 1.8, \"match_probability\": 0.7768953867957377, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8871, \"tn\": 8008, \"fp\": 41, \"fn\": 3153, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7377744510978044, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2622255489021956, \"precision\": 0.9953994614003591, \"recall\": 0.7377744510978044, \"specificity\": 0.9949061995278916, \"npv\": 0.7174984320401397, \"accuracy\": 0.8408807851342599, \"f1\": 0.8474398165838747, \"f2\": 0.7780486949200113, \"f0_5\": 0.9304203725457292, \"p4\": 0.8405302424340841, \"phi\": 0.7227215870552594}, {\"truth_threshold\": 1.82, \"match_probability\": 0.7792890097239141, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8870, \"tn\": 8008, \"fp\": 41, \"fn\": 3154, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7376912840984697, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.26230871590153026, \"precision\": 0.9953989451240041, \"recall\": 0.7376912840984697, \"specificity\": 0.9949061995278916, \"npv\": 0.7174341515857373, \"accuracy\": 0.8408309669705575, \"f1\": 0.8473847623596847, \"f2\": 0.777974634693985, \"f0_5\": 0.9303935554250231, \"p4\": 0.8404811076972409, \"phi\": 0.7226477239258027}, {\"truth_threshold\": 1.84, \"match_probability\": 0.7816641693291569, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8869, \"tn\": 8008, \"fp\": 41, \"fn\": 3155, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7376081170991351, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.26239188290086496, \"precision\": 0.9953984287317621, \"recall\": 0.7376081170991351, \"specificity\": 0.9949061995278916, \"npv\": 0.7173698826480337, \"accuracy\": 0.840781148806855, \"f1\": 0.8473297028757046, \"f2\": 0.7779005718696278, \"f0_5\": 0.9303667338032897, \"p4\": 0.8404319725989385, \"phi\": 0.7225738664827084}, {\"truth_threshold\": 1.86, \"match_probability\": 0.7840208528285652, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8862, \"tn\": 8008, \"fp\": 41, \"fn\": 3162, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7370259481037924, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2629740518962076, \"precision\": 0.9953948107379536, \"recall\": 0.7370259481037924, \"specificity\": 0.9949061995278916, \"npv\": 0.7169203222918532, \"accuracy\": 0.8404324216609376, \"f1\": 0.8469441391503799, \"f2\": 0.7773820593343743, \"f0_5\": 0.9301788563271476, \"p4\": 0.8400880167117234, \"phi\": 0.7220570234469402}, {\"truth_threshold\": 1.8800000000000001, \"match_probability\": 0.786359051160298, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8856, \"tn\": 8008, \"fp\": 41, \"fn\": 3168, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7365269461077845, \"tn_rate\": 0.9949061995278916, \"fp_rate\": 0.005093800472108337, \"fn_rate\": 0.2634730538922156, \"precision\": 0.9953917050691244, \"recall\": 0.7365269461077845, \"specificity\": 0.9949061995278916, \"npv\": 0.7165354330708661, \"accuracy\": 0.8401335126787227, \"f1\": 0.8466134505998757, \"f2\": 0.7769375186426404, \"f0_5\": 0.9300176426111064, \"p4\": 0.8397931830042803, \"phi\": 0.7216142363570288}, {\"truth_threshold\": 1.9000000000000001, \"match_probability\": 0.7886787589285739, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8851, \"tn\": 8009, \"fp\": 40, \"fn\": 3173, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7361111111111112, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2638888888888889, \"precision\": 0.9955010684962321, \"recall\": 0.7361111111111112, \"specificity\": 0.9950304385637967, \"npv\": 0.7162403863351815, \"accuracy\": 0.8399342400239127, \"f1\": 0.8463781974659336, \"f2\": 0.7765806236510081, \"f0_5\": 0.9299613347902833, \"p4\": 0.8395982212768867, \"phi\": 0.7213762889458685}, {\"truth_threshold\": 1.92, \"match_probability\": 0.7909799743478786, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8846, \"tn\": 8009, \"fp\": 40, \"fn\": 3178, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7356952761144377, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2643047238855622, \"precision\": 0.995498537024533, \"recall\": 0.7356952761144377, \"specificity\": 0.9950304385637967, \"npv\": 0.715920264592831, \"accuracy\": 0.8396851492054003, \"f1\": 0.8461023433763749, \"f2\": 0.7762100312379347, \"f0_5\": 0.9298267743020519, \"p4\": 0.8393525020296931, \"phi\": 0.7210076367469219}, {\"truth_threshold\": 1.94, \"match_probability\": 0.7932626991864332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8841, \"tn\": 8009, \"fp\": 40, \"fn\": 3183, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7352794411177644, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2647205588822355, \"precision\": 0.9954960027023984, \"recall\": 0.7352794411177644, \"specificity\": 0.9950304385637967, \"npv\": 0.7156004288777699, \"accuracy\": 0.8394360583868878, \"f1\": 0.8458263573307822, \"f2\": 0.7758393737824034, \"f0_5\": 0.9296921006141162, \"p4\": 0.8391067731768824, \"phi\": 0.7206391256303672}, {\"truth_threshold\": 1.96, \"match_probability\": 0.795526938708981, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8832, \"tn\": 8009, \"fp\": 40, \"fn\": 3192, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7345309381237525, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2654690618762475, \"precision\": 0.9954914337240758, \"recall\": 0.7345309381237525, \"specificity\": 0.9950304385637967, \"npv\": 0.7150254441567717, \"accuracy\": 0.8389876949135655, \"f1\": 0.8453292496171516, \"f2\": 0.7751720264007864, \"f0_5\": 0.9294494022562722, \"p4\": 0.8386644366618334, \"phi\": 0.7199761604292814}, {\"truth_threshold\": 1.98, \"match_probability\": 0.7977727016189426, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8825, \"tn\": 8009, \"fp\": 40, \"fn\": 3199, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7339487691284099, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.26605123087159016, \"precision\": 0.9954878736604625, \"recall\": 0.7339487691284099, \"specificity\": 0.9950304385637967, \"npv\": 0.7145788722341185, \"accuracy\": 0.8386389677676481, \"f1\": 0.8449423141366269, \"f2\": 0.7746528326398764, \"f0_5\": 0.929260382444613, \"p4\": 0.8383203749334167, \"phi\": 0.7194608355086572}, {\"truth_threshold\": 2.0, \"match_probability\": 0.8, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8813, \"tn\": 8009, \"fp\": 40, \"fn\": 3211, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7329507651363939, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2670492348636061, \"precision\": 0.9954817575962951, \"recall\": 0.7329507651363939, \"specificity\": 0.9950304385637967, \"npv\": 0.7138146167557933, \"accuracy\": 0.8380411498032182, \"f1\": 0.8442783924893423, \"f2\": 0.7737624892447629, \"f0_5\": 0.9289358293279366, \"p4\": 0.837730508600354, \"phi\": 0.7185780600470726}, {\"truth_threshold\": 2.02, \"match_probability\": 0.8022088492571531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8804, \"tn\": 8009, \"fp\": 40, \"fn\": 3220, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7322022621423819, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2677977378576181, \"precision\": 0.9954771596562642, \"recall\": 0.7322022621423819, \"specificity\": 0.9950304385637967, \"npv\": 0.7132424971057084, \"accuracy\": 0.8375927863298959, \"f1\": 0.8437799501629288, \"f2\": 0.7730944854232525, \"f0_5\": 0.9286919831223629, \"p4\": 0.8372880696996198, \"phi\": 0.7179165063087526}, {\"truth_threshold\": 2.06, \"match_probability\": 0.8065712782694506, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8801, \"tn\": 8009, \"fp\": 40, \"fn\": 3223, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7319527611443779, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2680472388556221, \"precision\": 0.9954756249293066, \"recall\": 0.7319527611443779, \"specificity\": 0.9950304385637967, \"npv\": 0.7130519943019943, \"accuracy\": 0.8374433318387884, \"f1\": 0.8436137071651091, \"f2\": 0.7728717705534187, \"f0_5\": 0.9286106187220393, \"p4\": 0.8371405824727971, \"phi\": 0.7176960886826586}, {\"truth_threshold\": 2.08, \"match_probability\": 0.8087249049044327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8799, \"tn\": 8009, \"fp\": 40, \"fn\": 3225, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7317864271457086, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2682135728542914, \"precision\": 0.9954746011992307, \"recall\": 0.7317864271457086, \"specificity\": 0.9950304385637967, \"npv\": 0.7129250489585188, \"accuracy\": 0.8373436955113834, \"f1\": 0.8435028519388391, \"f2\": 0.7727232809343989, \"f0_5\": 0.9285563528915154, \"p4\": 0.8370422555236223, \"phi\": 0.717549171414312}, {\"truth_threshold\": 2.1, \"match_probability\": 0.8108601760544609, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8783, \"tn\": 8009, \"fp\": 40, \"fn\": 3241, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.730455755156354, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.26954424484364603, \"precision\": 0.9954663946503457, \"recall\": 0.730455755156354, \"specificity\": 0.9950304385637967, \"npv\": 0.7119111111111112, \"accuracy\": 0.8365466048921437, \"f1\": 0.8426152443996738, \"f2\": 0.7715349883167308, \"f0_5\": 0.9281215656437569, \"p4\": 0.8362555775943857, \"phi\": 0.7163746325618554}, {\"truth_threshold\": 2.12, \"match_probability\": 0.8129771228322951, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8782, \"tn\": 8009, \"fp\": 40, \"fn\": 3242, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7303725881570193, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.2696274118429807, \"precision\": 0.9954658807526638, \"recall\": 0.7303725881570193, \"specificity\": 0.9950304385637967, \"npv\": 0.7118478357479335, \"accuracy\": 0.8364967867284412, \"f1\": 0.8425597236879977, \"f2\": 0.7714606978460241, \"f0_5\": 0.9280943523841731, \"p4\": 0.8362064064932144, \"phi\": 0.7163012709682166}, {\"truth_threshold\": 2.14, \"match_probability\": 0.8150757793102267, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8778, \"tn\": 8009, \"fp\": 40, \"fn\": 3246, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7300399201596807, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.26996007984031933, \"precision\": 0.995463823996371, \"recall\": 0.7300399201596807, \"specificity\": 0.9950304385637967, \"npv\": 0.7115948467347846, \"accuracy\": 0.8362975140736313, \"f1\": 0.8423375875635736, \"f2\": 0.7711635098569772, \"f0_5\": 0.9279854533152909, \"p4\": 0.8360097176331268, \"phi\": 0.7160078798627736}, {\"truth_threshold\": 2.16, \"match_probability\": 0.8171561824588779, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8774, \"tn\": 8009, \"fp\": 40, \"fn\": 3250, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.729707252162342, \"tn_rate\": 0.9950304385637967, \"fp_rate\": 0.004969561436203255, \"fn_rate\": 0.270292747837658, \"precision\": 0.9954617653732698, \"recall\": 0.729707252162342, \"specificity\": 0.9950304385637967, \"npv\": 0.7113420374811262, \"accuracy\": 0.8360982414188213, \"f1\": 0.8421153661579807, \"f2\": 0.7708662800913724, \"f0_5\": 0.9278764805414551, \"p4\": 0.8358130215987494, \"phi\": 0.7157145771025961}, {\"truth_threshold\": 2.18, \"match_probability\": 0.8192183720858639, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8769, \"tn\": 8012, \"fp\": 37, \"fn\": 3255, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7292914171656687, \"tn_rate\": 0.9954031556715119, \"fp_rate\": 0.004596844328488011, \"fn_rate\": 0.27070858283433136, \"precision\": 0.9957983193277311, \"recall\": 0.7292914171656687, \"specificity\": 0.9954031556715119, \"npv\": 0.7111032217981716, \"accuracy\": 0.8359986050914163, \"f1\": 0.8419587133941431, \"f2\": 0.7705353063161224, \"f0_5\": 0.9279757873349136, \"p4\": 0.8357191264389796, \"phi\": 0.7157427683072884}, {\"truth_threshold\": 2.2, \"match_probability\": 0.8212623907743639, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8760, \"tn\": 8012, \"fp\": 37, \"fn\": 3264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7285429141716567, \"tn_rate\": 0.9954031556715119, \"fp_rate\": 0.004596844328488011, \"fn_rate\": 0.2714570858283433, \"precision\": 0.9957940206888712, \"recall\": 0.7285429141716567, \"specificity\": 0.9954031556715119, \"npv\": 0.7105356509400497, \"accuracy\": 0.835550241618094, \"f1\": 0.8414581432207867, \"f2\": 0.7698662401349903, \"f0_5\": 0.9277302380750657, \"p4\": 0.8352764868743996, \"phi\": 0.7150836243331078}, {\"truth_threshold\": 2.22, \"match_probability\": 0.823288283821645, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8742, \"tn\": 8012, \"fp\": 37, \"fn\": 3282, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7270459081836327, \"tn_rate\": 0.9954031556715119, \"fp_rate\": 0.004596844328488011, \"fn_rate\": 0.27295409181636726, \"precision\": 0.9957853969700421, \"recall\": 0.7270459081836327, \"specificity\": 0.9954031556715119, \"npv\": 0.709403222950239, \"accuracy\": 0.8346535146714492, \"f1\": 0.8404557035043022, \"f2\": 0.7685274725274726, \"f0_5\": 0.9272380144251167, \"p4\": 0.8343910936547777, \"phi\": 0.7137666693694156}, {\"truth_threshold\": 2.2600000000000002, \"match_probability\": 0.8272858873831817, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8739, \"tn\": 8012, \"fp\": 37, \"fn\": 3285, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7267964071856288, \"tn_rate\": 0.9954031556715119, \"fp_rate\": 0.004596844328488011, \"fn_rate\": 0.27320359281437123, \"precision\": 0.9957839562443026, \"recall\": 0.7267964071856288, \"specificity\": 0.9954031556715119, \"npv\": 0.7092148357971143, \"accuracy\": 0.8345040601803417, \"f1\": 0.8402884615384615, \"f2\": 0.7683042622028414, \"f0_5\": 0.927155830928535, \"p4\": 0.8342435130271814, \"phi\": 0.7135473491136546}, {\"truth_threshold\": 2.2800000000000002, \"match_probability\": 0.8292577015092557, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8734, \"tn\": 8012, \"fp\": 37, \"fn\": 3290, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7263805721889555, \"tn_rate\": 0.9954031556715119, \"fp_rate\": 0.004596844328488011, \"fn_rate\": 0.2736194278110446, \"precision\": 0.9957815528446016, \"recall\": 0.7263805721889555, \"specificity\": 0.9954031556715119, \"npv\": 0.7089010794549637, \"accuracy\": 0.8342549693618293, \"f1\": 0.8400096176965617, \"f2\": 0.7679321926600665, \"f0_5\": 0.9270187653901673, \"p4\": 0.8339975355666922, \"phi\": 0.7131819244061836}, {\"truth_threshold\": 2.3000000000000003, \"match_probability\": 0.8312115970951024, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8719, \"tn\": 8014, \"fp\": 35, \"fn\": 3305, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7251330671989354, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27486693280106456, \"precision\": 0.9960018277358922, \"recall\": 0.7251330671989354, \"specificity\": 0.9956516337433221, \"npv\": 0.7080130753600141, \"accuracy\": 0.833607333233697, \"f1\": 0.8392530561170469, \"f2\": 0.7668425681618294, \"f0_5\": 0.9267644557823129, \"p4\": 0.8333607466468246, \"phi\": 0.7123504554549505}, {\"truth_threshold\": 2.32, \"match_probability\": 0.8331476320874132, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8715, \"tn\": 8014, \"fp\": 35, \"fn\": 3309, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7248003992015968, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.2751996007984032, \"precision\": 0.996, \"recall\": 0.7248003992015968, \"specificity\": 0.9956516337433221, \"npv\": 0.707762960346198, \"accuracy\": 0.833408060578887, \"f1\": 0.8390295561759892, \"f2\": 0.7665446997150195, \"f0_5\": 0.9266544743109901, \"p4\": 0.8331639178734929, \"phi\": 0.7120586039735443}, {\"truth_threshold\": 2.34, \"match_probability\": 0.835065866779332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8706, \"tn\": 8014, \"fp\": 35, \"fn\": 3318, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7240518962075848, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.2759481037924152, \"precision\": 0.9959958814780917, \"recall\": 0.7240518962075848, \"specificity\": 0.9956516337433221, \"npv\": 0.7072008471584892, \"accuracy\": 0.8329596971055647, \"f1\": 0.8385263664820611, \"f2\": 0.7658743424177912, \"f0_5\": 0.9264067421469311, \"p4\": 0.8327210231698535, \"phi\": 0.7114022545997991}, {\"truth_threshold\": 2.36, \"match_probability\": 0.8369663637497393, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8703, \"tn\": 8014, \"fp\": 35, \"fn\": 3321, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7238023952095808, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27619760479041916, \"precision\": 0.9959945067521172, \"recall\": 0.7238023952095808, \"specificity\": 0.9956516337433221, \"npv\": 0.7070136744596383, \"accuracy\": 0.8328102426144572, \"f1\": 0.8383585396397264, \"f2\": 0.765650842805363, \"f0_5\": 0.9263240803814714, \"p4\": 0.8325733822895772, \"phi\": 0.7111835686794584}, {\"truth_threshold\": 2.38, \"match_probability\": 0.8388491878027863, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8699, \"tn\": 8014, \"fp\": 35, \"fn\": 3325, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7234697272122422, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.2765302727877578, \"precision\": 0.9959926723150905, \"recall\": 0.7234697272122422, \"specificity\": 0.9956516337433221, \"npv\": 0.7067642649263604, \"accuracy\": 0.8326109699596473, \"f1\": 0.8381346950573273, \"f2\": 0.7653528066162238, \"f0_5\": 0.9262137989778535, \"p4\": 0.8323765204672909, \"phi\": 0.7108920629251928}, {\"truth_threshold\": 2.4, \"match_probability\": 0.840714405907716, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8698, \"tn\": 8014, \"fp\": 35, \"fn\": 3326, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7233865602129075, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27661343978709246, \"precision\": 0.9959922134432612, \"recall\": 0.7233865602129075, \"specificity\": 0.9956516337433221, \"npv\": 0.7067019400352734, \"accuracy\": 0.8325611517959448, \"f1\": 0.8380787204316617, \"f2\": 0.7652782910133911, \"f0_5\": 0.9261862168838914, \"p4\": 0.8323273036989646, \"phi\": 0.7108191999522854}, {\"truth_threshold\": 2.42, \"match_probability\": 0.8425620871389979, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8696, \"tn\": 8014, \"fp\": 35, \"fn\": 3328, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7232202262142382, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.2767797737857618, \"precision\": 0.995991295384263, \"recall\": 0.7232202262142382, \"specificity\": 0.9956516337433221, \"npv\": 0.7065773232234174, \"accuracy\": 0.8324615154685399, \"f1\": 0.8379667549987955, \"f2\": 0.7651292519400988, \"f0_5\": 0.9261310385958933, \"p4\": 0.8322288685802193, \"phi\": 0.7106734901530498}, {\"truth_threshold\": 2.44, \"match_probability\": 0.8443923026168105, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8691, \"tn\": 8014, \"fp\": 35, \"fn\": 3333, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7228043912175649, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27719560878243515, \"precision\": 0.9959889983955994, \"recall\": 0.7228043912175649, \"specificity\": 0.9956516337433221, \"npv\": 0.7062659733850357, \"accuracy\": 0.8322124246500274, \"f1\": 0.8376867469879518, \"f2\": 0.7647566083559185, \"f0_5\": 0.9259930105693829, \"p4\": 0.8319827715092025, \"phi\": 0.7103093097619761}, {\"truth_threshold\": 2.46, \"match_probability\": 0.8462051254478966, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8675, \"tn\": 8014, \"fp\": 35, \"fn\": 3349, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7214737192282102, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27852628077178976, \"precision\": 0.9959816303099885, \"recall\": 0.7214737192282102, \"specificity\": 0.9956516337433221, \"npv\": 0.7052714952037314, \"accuracy\": 0.8314153340307876, \"f1\": 0.8367898138323526, \"f2\": 0.7635637080590079, \"f0_5\": 0.9255505291908501, \"p4\": 0.8311951705985332, \"phi\": 0.7091448336950757}, {\"truth_threshold\": 2.48, \"match_probability\": 0.8480006306668223, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8659, \"tn\": 8014, \"fp\": 35, \"fn\": 3365, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7201430472388556, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.27985695276114436, \"precision\": 0.9959742351046699, \"recall\": 0.7201430472388556, \"specificity\": 0.9956516337433221, \"npv\": 0.7042798136918885, \"accuracy\": 0.8306182434115479, \"f1\": 0.8358914953180809, \"f2\": 0.7623701355872513, \"f0_5\": 0.9251068376068377, \"p4\": 0.8304074290378698, \"phi\": 0.7079817253748933}, {\"truth_threshold\": 2.5, \"match_probability\": 0.8497788951776651, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8657, \"tn\": 8014, \"fp\": 35, \"fn\": 3367, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7199767132401863, \"tn_rate\": 0.9956516337433221, \"fp_rate\": 0.0043483662566778485, \"fn_rate\": 0.2800232867598137, \"precision\": 0.9959733087896917, \"recall\": 0.7199767132401863, \"specificity\": 0.9956516337433221, \"npv\": 0.704156049556278, \"accuracy\": 0.8305186070841428, \"f1\": 0.8357791079358949, \"f2\": 0.762220891737691, \"f0_5\": 0.9250512908189434, \"p4\": 0.8303089512541627, \"phi\": 0.7078364326507578}, {\"truth_threshold\": 2.52, \"match_probability\": 0.851539997696156, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8648, \"tn\": 8018, \"fp\": 31, \"fn\": 3376, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7192282102461743, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.28077178975382566, \"precision\": 0.9964281599262588, \"recall\": 0.7192282102461743, \"specificity\": 0.9961485898869424, \"npv\": 0.7037037037037037, \"accuracy\": 0.8302695162656305, \"f1\": 0.8354344780949621, \"f2\": 0.7616028181417878, \"f0_5\": 0.9251176722293539, \"p4\": 0.8300679059051579, \"phi\": 0.7077132839468525}, {\"truth_threshold\": 2.54, \"match_probability\": 0.8532840186923007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8636, \"tn\": 8018, \"fp\": 31, \"fn\": 3388, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7182302062541583, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.28176979374584166, \"precision\": 0.9964232144917503, \"recall\": 0.7182302062541583, \"specificity\": 0.9961485898869424, \"npv\": 0.7029633526214273, \"accuracy\": 0.8296716983012006, \"f1\": 0.8347590739935238, \"f2\": 0.7607067984426475, \"f0_5\": 0.9247836888546218, \"p4\": 0.8294768801691219, \"phi\": 0.7068429343578169}, {\"truth_threshold\": 2.56, \"match_probability\": 0.8550110403335041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8632, \"tn\": 8018, \"fp\": 31, \"fn\": 3392, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7178975382568197, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2821024617431803, \"precision\": 0.9964215629689483, \"recall\": 0.7178975382568197, \"specificity\": 0.9961485898869424, \"npv\": 0.7027169149868536, \"accuracy\": 0.8294724256463907, \"f1\": 0.8345337651665297, \"f2\": 0.7604080410155217, \"f0_5\": 0.9246722084154597, \"p4\": 0.8292798528236655, \"phi\": 0.7065529868457592}, {\"truth_threshold\": 2.58, \"match_probability\": 0.8567211464282175, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8628, \"tn\": 8018, \"fp\": 31, \"fn\": 3396, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.717564870259481, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.282435129740519, \"precision\": 0.9964199099203142, \"recall\": 0.717564870259481, \"specificity\": 0.9961485898869424, \"npv\": 0.7024706500788506, \"accuracy\": 0.8292731529915808, \"f1\": 0.8343083691920902, \"f2\": 0.7601092414765219, \"f0_5\": 0.9245606515216459, \"p4\": 0.8290828159897792, \"phi\": 0.7062631236590761}, {\"truth_threshold\": 2.6, \"match_probability\": 0.8584144223701331, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8624, \"tn\": 8018, \"fp\": 31, \"fn\": 3400, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7172322022621423, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2827677977378576, \"precision\": 0.996418255343732, \"recall\": 0.7172322022621423, \"specificity\": 0.9961485898869424, \"npv\": 0.7022245577158872, \"accuracy\": 0.8290738803367708, \"f1\": 0.8340828860196334, \"f2\": 0.7598103998167434, \"f0_5\": 0.9244490180945031, \"p4\": 0.8288857696043452, \"phi\": 0.7059733446878402}, {\"truth_threshold\": 2.62, \"match_probability\": 0.8600909550829424, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8615, \"tn\": 8018, \"fp\": 31, \"fn\": 3409, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7164836992681304, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2835163007318696, \"precision\": 0.9964145269488781, \"recall\": 0.7164836992681304, \"specificity\": 0.9961485898869424, \"npv\": 0.7016714798284764, \"accuracy\": 0.8286255168634484, \"f1\": 0.8335752298016449, \"f2\": 0.7591378520320045, \"f0_5\": 0.9241975626501888, \"p4\": 0.8284423799869153, \"phi\": 0.705321649346502}, {\"truth_threshold\": 2.64, \"match_probability\": 0.8617508329656802, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8607, \"tn\": 8018, \"fp\": 31, \"fn\": 3417, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.715818363273453, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2841816367265469, \"precision\": 0.9964112062977541, \"recall\": 0.715818363273453, \"specificity\": 0.9961485898869424, \"npv\": 0.7011805859204198, \"accuracy\": 0.8282269715538285, \"f1\": 0.8331236085567709, \"f2\": 0.7585398526456798, \"f0_5\": 0.9239737203710066, \"p4\": 0.8280482144371563, \"phi\": 0.7047427210374527}, {\"truth_threshold\": 2.66, \"match_probability\": 0.8633941458386707, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8605, \"tn\": 8018, \"fp\": 31, \"fn\": 3419, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7156520292747838, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2843479707252162, \"precision\": 0.9964103751736916, \"recall\": 0.7156520292747838, \"specificity\": 0.9961485898869424, \"npv\": 0.7010579697473114, \"accuracy\": 0.8281273352264236, \"f1\": 0.8330106485963213, \"f2\": 0.7583903264471551, \"f0_5\": 0.9239177117333791, \"p4\": 0.8279496668920796, \"phi\": 0.7045980412692575}, {\"truth_threshold\": 2.68, \"match_probability\": 0.8650209848900923, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8598, \"tn\": 8018, \"fp\": 31, \"fn\": 3426, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7150698602794411, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.28493013972055886, \"precision\": 0.9964074632054699, \"recall\": 0.7150698602794411, \"specificity\": 0.9961485898869424, \"npv\": 0.700629150646627, \"accuracy\": 0.8277786080805062, \"f1\": 0.8326151164479737, \"f2\": 0.7578669017188189, \"f0_5\": 0.9237215298667812, \"p4\": 0.8276047309106738, \"phi\": 0.7040918265490038}, {\"truth_threshold\": 2.7, \"match_probability\": 0.8666314426231786, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8595, \"tn\": 8018, \"fp\": 31, \"fn\": 3429, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7148203592814372, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2851796407185629, \"precision\": 0.9964062137723163, \"recall\": 0.7148203592814372, \"specificity\": 0.9961485898869424, \"npv\": 0.7004455315803267, \"accuracy\": 0.8276291535893987, \"f1\": 0.8324455205811138, \"f2\": 0.7576425372871196, \"f0_5\": 0.9236373796423659, \"p4\": 0.8274568918239795, \"phi\": 0.7038749555990181}, {\"truth_threshold\": 2.72, \"match_probability\": 0.8682256128040682, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8594, \"tn\": 8018, \"fp\": 31, \"fn\": 3430, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7147371922821024, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2852628077178975, \"precision\": 0.9964057971014493, \"recall\": 0.7147371922821024, \"specificity\": 0.9961485898869424, \"npv\": 0.7003843466107617, \"accuracy\": 0.8275793354256962, \"f1\": 0.8323889776744636, \"f2\": 0.7575677438691137, \"f0_5\": 0.923609319920901, \"p4\": 0.8274076108704077, \"phi\": 0.7038026756986197}, {\"truth_threshold\": 2.74, \"match_probability\": 0.8698035904103196, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8592, \"tn\": 8018, \"fp\": 31, \"fn\": 3432, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7145708582834331, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.28542914171656686, \"precision\": 0.9964049634697901, \"recall\": 0.7145708582834331, \"specificity\": 0.9961485898869424, \"npv\": 0.7002620087336244, \"accuracy\": 0.8274796990982912, \"f1\": 0.8322758754298445, \"f2\": 0.7574181491211058, \"f0_5\": 0.923553186000516, \"p4\": 0.8273090470702842, \"phi\": 0.7036581315119845}, {\"truth_threshold\": 2.7600000000000002, \"match_probability\": 0.8713654715801021, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8581, \"tn\": 8018, \"fp\": 31, \"fn\": 3443, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7136560212907518, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.28634397870924816, \"precision\": 0.9964003715745472, \"recall\": 0.7136560212907518, \"specificity\": 0.9961485898869424, \"npv\": 0.6995899136201029, \"accuracy\": 0.8269316992975639, \"f1\": 0.83165342120566, \"f2\": 0.7565951893912676, \"f0_5\": 0.9232441039765881, \"p4\": 0.8267669007212617, \"phi\": 0.7028635100544353}, {\"truth_threshold\": 2.7800000000000002, \"match_probability\": 0.8729113535620762, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8571, \"tn\": 8018, \"fp\": 31, \"fn\": 3453, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7128243512974052, \"tn_rate\": 0.9961485898869424, \"fp_rate\": 0.0038514101130575225, \"fn_rate\": 0.2871756487025948, \"precision\": 0.9963961869332714, \"recall\": 0.7128243512974052, \"specificity\": 0.9961485898869424, \"npv\": 0.6989800366140703, \"accuracy\": 0.8264335176605391, \"f1\": 0.831086977601086, \"f2\": 0.7558467670817313, \"f0_5\": 0.9229626119917298, \"p4\": 0.8262739728586894, \"phi\": 0.7021416712017762}, {\"truth_threshold\": 2.8000000000000003, \"match_probability\": 0.8744413346659732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8558, \"tn\": 8020, \"fp\": 29, \"fn\": 3466, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7117431803060545, \"tn_rate\": 0.9963970679587526, \"fp_rate\": 0.00360293204124736, \"fn_rate\": 0.28825681969394545, \"precision\": 0.9966228019098637, \"recall\": 0.7117431803060545, \"specificity\": 0.9963970679587526, \"npv\": 0.6982413372801671, \"accuracy\": 0.8258855178598117, \"f1\": 0.8304303527242735, \"f2\": 0.7549000582185135, \"f0_5\": 0.92275511084275, \"p4\": 0.8257339409875609, \"phi\": 0.701470786302851}, {\"truth_threshold\": 2.82, \"match_probability\": 0.8759555142138866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8555, \"tn\": 8020, \"fp\": 29, \"fn\": 3469, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7114936793080505, \"tn_rate\": 0.9963970679587526, \"fp_rate\": 0.00360293204124736, \"fn_rate\": 0.2885063206919494, \"precision\": 0.9966216216216216, \"recall\": 0.7114936793080505, \"specificity\": 0.9963970679587526, \"npv\": 0.6980590129689268, \"accuracy\": 0.8257360633687042, \"f1\": 0.8302600931677019, \"f2\": 0.7546753705010586, \"f0_5\": 0.9226704055220017, \"p4\": 0.8255860178461978, \"phi\": 0.7012545853911263}, {\"truth_threshold\": 2.84, \"match_probability\": 0.8774539924922818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8549, \"tn\": 8020, \"fp\": 29, \"fn\": 3475, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7109946773120426, \"tn_rate\": 0.9963970679587526, \"fp_rate\": 0.00360293204124736, \"fn_rate\": 0.2890053226879574, \"precision\": 0.9966192585684309, \"recall\": 0.7109946773120426, \"specificity\": 0.9963970679587526, \"npv\": 0.6976946498477599, \"accuracy\": 0.8254371543864893, \"f1\": 0.8299194252985147, \"f2\": 0.7542259237039912, \"f0_5\": 0.9225008632596685, \"p4\": 0.8252901534356675, \"phi\": 0.7008223223045312}, {\"truth_threshold\": 2.86, \"match_probability\": 0.8789368707047344, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8546, \"tn\": 8020, \"fp\": 29, \"fn\": 3478, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7107451763140386, \"tn_rate\": 0.9963970679587526, \"fp_rate\": 0.00360293204124736, \"fn_rate\": 0.2892548236859614, \"precision\": 0.9966180758017493, \"recall\": 0.7107451763140386, \"specificity\": 0.9963970679587526, \"npv\": 0.6975126108888502, \"accuracy\": 0.8252876998953819, \"f1\": 0.82974901694257, \"f2\": 0.7540011646168234, \"f0_5\": 0.922416026249892, \"p4\": 0.8251422121121914, \"phi\": 0.7006062600384072}, {\"truth_threshold\": 2.88, \"match_probability\": 0.880404250925403, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8543, \"tn\": 8020, \"fp\": 29, \"fn\": 3481, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7104956753160346, \"tn_rate\": 0.9963970679587526, \"fp_rate\": 0.00360293204124736, \"fn_rate\": 0.2895043246839654, \"precision\": 0.9966168922071862, \"recall\": 0.7104956753160346, \"specificity\": 0.9963970679587526, \"npv\": 0.6973306668985305, \"accuracy\": 0.8251382454042744, \"f1\": 0.8295785589434842, \"f2\": 0.7537763817321945, \"f0_5\": 0.9223311452755225, \"p4\": 0.824994264673668, \"phi\": 0.7003902438962744}, {\"truth_threshold\": 2.9, \"match_probability\": 0.8818562360532484, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8532, \"tn\": 8021, \"fp\": 28, \"fn\": 3492, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7095808383233533, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2904191616766467, \"precision\": 0.9967289719626168, \"recall\": 0.7095808383233533, \"specificity\": 0.9965213069946577, \"npv\": 0.6966906974724225, \"accuracy\": 0.8246400637672495, \"f1\": 0.8289933929265448, \"f2\": 0.7529652640497034, \"f0_5\": 0.9220992564412934, \"p4\": 0.8245021446037829, \"phi\": 0.6997321746166795}, {\"truth_threshold\": 2.92, \"match_probability\": 0.8832929297669961, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8529, \"tn\": 8021, \"fp\": 28, \"fn\": 3495, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7093313373253493, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2906686626746507, \"precision\": 0.9967278251723735, \"recall\": 0.7093313373253493, \"specificity\": 0.9965213069946577, \"npv\": 0.6965092045849253, \"accuracy\": 0.824490609276142, \"f1\": 0.82882270054905, \"f2\": 0.7527403667943445, \"f0_5\": 0.9220141831704575, \"p4\": 0.8243541651017978, \"phi\": 0.6995163976596522}, {\"truth_threshold\": 2.94, \"match_probability\": 0.8847144364808572, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8524, \"tn\": 8021, \"fp\": 28, \"fn\": 3500, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.708915502328676, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.291084497671324, \"precision\": 0.9967259120673526, \"recall\": 0.708915502328676, \"specificity\": 0.9965213069946577, \"npv\": 0.6962069264820762, \"accuracy\": 0.8242415184576296, \"f1\": 0.828538102643857, \"f2\": 0.7523654851009745, \"f0_5\": 0.9218722962450251, \"p4\": 0.8241075186454451, \"phi\": 0.6991568713112029}, {\"truth_threshold\": 2.96, \"match_probability\": 0.8861208613010066, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8522, \"tn\": 8021, \"fp\": 28, \"fn\": 3502, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7087491683300067, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2912508316699933, \"precision\": 0.9967251461988305, \"recall\": 0.7087491683300067, \"specificity\": 0.9965213069946577, \"npv\": 0.6960860886921808, \"accuracy\": 0.8241418821302247, \"f1\": 0.828424224749684, \"f2\": 0.7522155138933022, \"f0_5\": 0.9218155070958809, \"p4\": 0.8240088551557201, \"phi\": 0.6990130964022429}, {\"truth_threshold\": 2.98, \"match_probability\": 0.8875123099828214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8513, \"tn\": 8021, \"fp\": 28, \"fn\": 3511, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7080006653359947, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29199933466400535, \"precision\": 0.9967216953518323, \"recall\": 0.7080006653359947, \"specificity\": 0.9965213069946577, \"npv\": 0.6955428373222338, \"accuracy\": 0.8236935186569023, \"f1\": 0.8279115001215658, \"f2\": 0.7515405123858961, \"f0_5\": 0.9215597124794319, \"p4\": 0.8235648344836087, \"phi\": 0.6983663608265295}, {\"truth_threshold\": 3.0, \"match_probability\": 0.8888888888888888, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8509, \"tn\": 8021, \"fp\": 28, \"fn\": 3515, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.707667997338656, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29233200266134396, \"precision\": 0.996720159306548, \"recall\": 0.707667997338656, \"specificity\": 0.9965213069946577, \"npv\": 0.6953016643550625, \"accuracy\": 0.8234942460020923, \"f1\": 0.8276834784300374, \"f2\": 0.7512404428513411, \"f0_5\": 0.9214458979468075, \"p4\": 0.8233674734635413, \"phi\": 0.6980790546834509}, {\"truth_threshold\": 3.02, \"match_probability\": 0.890250704947779, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8500, \"tn\": 8021, \"fp\": 28, \"fn\": 3524, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7069194943446441, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2930805056553559, \"precision\": 0.9967166979362101, \"recall\": 0.7069194943446441, \"specificity\": 0.9965213069946577, \"npv\": 0.6947596362061499, \"accuracy\": 0.82304588252877, \"f1\": 0.8271701050992604, \"f2\": 0.7505651313930489, \"f0_5\": 0.9211895266169585, \"p4\": 0.82292336910936, \"phi\": 0.6974329118963806}, {\"truth_threshold\": 3.04, \"match_probability\": 0.8915978656135887, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8497, \"tn\": 8021, \"fp\": 28, \"fn\": 3527, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.70666999334664, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29333000665335995, \"precision\": 0.9967155425219941, \"recall\": 0.70666999334664, \"specificity\": 0.9965213069946577, \"npv\": 0.694579147904399, \"accuracy\": 0.8228964280376625, \"f1\": 0.8269988807241229, \"f2\": 0.7503399798661274, \"f0_5\": 0.9211039805741046, \"p4\": 0.8227753212856728, \"phi\": 0.6972176218943196}, {\"truth_threshold\": 3.06, \"match_probability\": 0.8929304788262556, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8486, \"tn\": 8021, \"fp\": 28, \"fn\": 3538, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7057551563539588, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29424484364604125, \"precision\": 0.9967112990368804, \"recall\": 0.7057551563539588, \"specificity\": 0.9965213069946577, \"npv\": 0.693918159010295, \"accuracy\": 0.8223484282369352, \"f1\": 0.8263706300516116, \"f2\": 0.7495142201024554, \"f0_5\": 0.9207899305555556, \"p4\": 0.822232422885759, \"phi\": 0.6964286131986122}, {\"truth_threshold\": 3.08, \"match_probability\": 0.8942486529726457, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8482, \"tn\": 8021, \"fp\": 28, \"fn\": 3542, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7054224883566201, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2945775116433799, \"precision\": 0.9967097532314924, \"recall\": 0.7054224883566201, \"specificity\": 0.9965213069946577, \"npv\": 0.6936781112168122, \"accuracy\": 0.8221491555821252, \"f1\": 0.8261420083763514, \"f2\": 0.7492138642546726, \"f0_5\": 0.9206755817992358, \"p4\": 0.8220349831358015, \"phi\": 0.6961418518055831}, {\"truth_threshold\": 3.1, \"match_probability\": 0.895552496848409, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8475, \"tn\": 8021, \"fp\": 28, \"fn\": 3549, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7048403193612774, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29515968063872255, \"precision\": 0.9967070445725038, \"recall\": 0.7048403193612774, \"specificity\": 0.9965213069946577, \"npv\": 0.6932584269662921, \"accuracy\": 0.8218004284362078, \"f1\": 0.825741706045696, \"f2\": 0.7486881393664199, \"f0_5\": 0.9204752802154835, \"p4\": 0.8216894348587022, \"phi\": 0.695640212500607}, {\"truth_threshold\": 3.12, \"match_probability\": 0.8968421196206098, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8470, \"tn\": 8021, \"fp\": 28, \"fn\": 3554, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7044244843646041, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29557551563539586, \"precision\": 0.9967051070840197, \"recall\": 0.7044244843646041, \"specificity\": 0.9965213069946577, \"npv\": 0.6929589632829374, \"accuracy\": 0.8215513376176954, \"f1\": 0.8254556086151448, \"f2\": 0.7483125419655794, \"f0_5\": 0.9203320584144645, \"p4\": 0.8214425921217232, \"phi\": 0.695282048937995}, {\"truth_threshold\": 3.14, \"match_probability\": 0.8981176307911237, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8462, \"tn\": 8021, \"fp\": 28, \"fn\": 3562, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7037591483699268, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2962408516300732, \"precision\": 0.9967020023557126, \"recall\": 0.7037591483699268, \"specificity\": 0.9965213069946577, \"npv\": 0.6924803591470258, \"accuracy\": 0.8211527923080755, \"f1\": 0.8249975626401482, \"f2\": 0.7477114480613579, \"f0_5\": 0.9201026443980515, \"p4\": 0.8210476043190265, \"phi\": 0.6947092470540301}, {\"truth_threshold\": 3.16, \"match_probability\": 0.8993791401608047, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8459, \"tn\": 8021, \"fp\": 28, \"fn\": 3565, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7035096473719228, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29649035262807716, \"precision\": 0.9967008365735831, \"recall\": 0.7035096473719228, \"specificity\": 0.9965213069946577, \"npv\": 0.692301052994994, \"accuracy\": 0.8210033378169681, \"f1\": 0.8248257032811662, \"f2\": 0.7474859940264744, \"f0_5\": 0.9200165318019664, \"p4\": 0.8208994712931621, \"phi\": 0.694494528643004}, {\"truth_threshold\": 3.18, \"match_probability\": 0.9006267577944164, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8454, \"tn\": 8021, \"fp\": 28, \"fn\": 3570, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7030938123752495, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2969061876247505, \"precision\": 0.9966988917708087, \"recall\": 0.7030938123752495, \"specificity\": 0.9965213069946577, \"npv\": 0.6920024156673281, \"accuracy\": 0.8207542469984557, \"f1\": 0.8245391592704574, \"f2\": 0.7471101841705257, \"f0_5\": 0.9198729108635098, \"p4\": 0.8206525675343704, \"phi\": 0.6941367641996377}, {\"truth_threshold\": 3.2, \"match_probability\": 0.9018605939863281, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8451, \"tn\": 8021, \"fp\": 28, \"fn\": 3573, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7028443113772455, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2971556886227545, \"precision\": 0.9966977237881826, \"recall\": 0.7028443113772455, \"specificity\": 0.9965213069946577, \"npv\": 0.6918233569087459, \"accuracy\": 0.8206047925073482, \"f1\": 0.8243671657806174, \"f2\": 0.7468846663720725, \"f0_5\": 0.9197866782760122, \"p4\": 0.8205044160043355, \"phi\": 0.6939221652056508}, {\"truth_threshold\": 3.22, \"match_probability\": 0.9030807592269698, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8444, \"tn\": 8021, \"fp\": 28, \"fn\": 3580, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7022621423819029, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.2977378576180971, \"precision\": 0.9966949952785646, \"recall\": 0.7022621423819029, \"specificity\": 0.9965213069946577, \"npv\": 0.6914059132833377, \"accuracy\": 0.8202560653614308, \"f1\": 0.8239656518345043, \"f2\": 0.7463583651534437, \"f0_5\": 0.9195852936051577, \"p4\": 0.8201587018689609, \"phi\": 0.6934216079731229}, {\"truth_threshold\": 3.24, \"match_probability\": 0.9042873641700437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8437, \"tn\": 8021, \"fp\": 28, \"fn\": 3587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7016799733865602, \"tn_rate\": 0.9965213069946577, \"fp_rate\": 0.0034786930053422784, \"fn_rate\": 0.29832002661343976, \"precision\": 0.9966922622563497, \"recall\": 0.7016799733865602, \"specificity\": 0.9965213069946577, \"npv\": 0.6909889731219848, \"accuracy\": 0.8199073382155134, \"f1\": 0.8235638635365318, \"f2\": 0.7458319336645391, \"f0_5\": 0.9193836631505535, \"p4\": 0.8198129493219171, \"phi\": 0.6929212935357744}, {\"truth_threshold\": 3.2600000000000002, \"match_probability\": 0.9054805196004887, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8436, \"tn\": 8025, \"fp\": 24, \"fn\": 3588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7015968063872255, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.29840319361277445, \"precision\": 0.9971631205673759, \"recall\": 0.7015968063872255, \"specificity\": 0.997018263138278, \"npv\": 0.6910359080340998, \"accuracy\": 0.8200567927066208, \"f1\": 0.8236672524897481, \"f2\": 0.7458094631869298, \"f0_5\": 0.9196755625327054, \"p4\": 0.8199647535391168, \"phi\": 0.6933874906672343}, {\"truth_threshold\": 3.2800000000000002, \"match_probability\": 0.9066603364031919, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8434, \"tn\": 8025, \"fp\": 24, \"fn\": 3590, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7014304723885563, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.2985695276114438, \"precision\": 0.9971624497517143, \"recall\": 0.7014304723885563, \"specificity\": 0.997018263138278, \"npv\": 0.6909169177787344, \"accuracy\": 0.8199571563792158, \"f1\": 0.8235523874621619, \"f2\": 0.7456590161615447, \"f0_5\": 0.9196179344033496, \"p4\": 0.819865949688067, \"phi\": 0.693244664021113}, {\"truth_threshold\": 3.3000000000000003, \"match_probability\": 0.9078269255324448, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8430, \"tn\": 8025, \"fp\": 24, \"fn\": 3594, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7010978043912176, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.29890219560878245, \"precision\": 0.9971611071682044, \"recall\": 0.7010978043912176, \"specificity\": 0.997018263138278, \"npv\": 0.6906790601600826, \"accuracy\": 0.819757883724406, \"f1\": 0.8233225900966892, \"f2\": 0.7453580901856764, \"f0_5\": 0.9195026178010471, \"p4\": 0.8196683324287094, \"phi\": 0.6929590700063417}, {\"truth_threshold\": 3.3200000000000003, \"match_probability\": 0.9089803979821356, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8423, \"tn\": 8025, \"fp\": 24, \"fn\": 3601, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7005156353958749, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.2994843646041251, \"precision\": 0.9971587545874275, \"recall\": 0.7005156353958749, \"specificity\": 0.997018263138278, \"npv\": 0.6902632031653191, \"accuracy\": 0.8194091565784886, \"f1\": 0.822920228616091, \"f2\": 0.7448313672780008, \"f0_5\": 0.9193006199249105, \"p4\": 0.8193224713888357, \"phi\": 0.6924594703874395}, {\"truth_threshold\": 3.34, \"match_probability\": 0.9101208647566755, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8419, \"tn\": 8025, \"fp\": 24, \"fn\": 3605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.7001829673985362, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.29981703260146375, \"precision\": 0.9971574085040862, \"recall\": 0.7001829673985362, \"specificity\": 0.997018263138278, \"npv\": 0.6900257953568357, \"accuracy\": 0.8192098839236786, \"f1\": 0.8226901841989545, \"f2\": 0.744530324200994, \"f0_5\": 0.9191850816665211, \"p4\": 0.8191248187740604, \"phi\": 0.6921740932280444}, {\"truth_threshold\": 3.36, \"match_probability\": 0.911248436842651, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8415, \"tn\": 8025, \"fp\": 24, \"fn\": 3609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6998502994011976, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3001497005988024, \"precision\": 0.9971560611446854, \"recall\": 0.6998502994011976, \"specificity\": 0.997018263138278, \"npv\": 0.6897885507993812, \"accuracy\": 0.8190106112688686, \"f1\": 0.8224600498460636, \"f2\": 0.7442292385248076, \"f0_5\": 0.9190694626474443, \"p4\": 0.818927153178, \"phi\": 0.6918887947276641}, {\"truth_threshold\": 3.38, \"match_probability\": 0.9123632251811958, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8413, \"tn\": 8025, \"fp\": 24, \"fn\": 3611, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6996839654025283, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30031603459747175, \"precision\": 0.9971553869858955, \"recall\": 0.6996839654025283, \"specificity\": 0.997018263138278, \"npv\": 0.6896699896871777, \"accuracy\": 0.8189109749414637, \"f1\": 0.8223449489272274, \"f2\": 0.7440786797091964, \"f0_5\": 0.919011622826182, \"p4\": 0.8188283154911611, \"phi\": 0.6917461749417259}, {\"truth_threshold\": 3.4, \"match_probability\": 0.9134653406410783, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8408, \"tn\": 8025, \"fp\": 24, \"fn\": 3616, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.699268130405855, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30073186959414505, \"precision\": 0.9971537001897534, \"recall\": 0.699268130405855, \"specificity\": 0.997018263138278, \"npv\": 0.6893737651404519, \"accuracy\": 0.8186618841229513, \"f1\": 0.8220570981619085, \"f2\": 0.7437022360600056, \"f0_5\": 0.9188669347788074, \"p4\": 0.8185812069481536, \"phi\": 0.6913897113088706}, {\"truth_threshold\": 3.42, \"match_probability\": 0.9145548939924946, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8403, \"tn\": 8025, \"fp\": 24, \"fn\": 3621, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6988522954091816, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30114770459081835, \"precision\": 0.9971520113919544, \"recall\": 0.6988522954091816, \"specificity\": 0.997018263138278, \"npv\": 0.6890777949510561, \"accuracy\": 0.8184127933044388, \"f1\": 0.8217691066451518, \"f2\": 0.7433257258107319, \"f0_5\": 0.9187221201784309, \"p4\": 0.8183340778352143, \"phi\": 0.6910333701289871}, {\"truth_threshold\": 3.44, \"match_probability\": 0.9156319958815625, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8394, \"tn\": 8025, \"fp\": 24, \"fn\": 3630, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6981037924151696, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3018962075848303, \"precision\": 0.9971489665003563, \"recall\": 0.6981037924151696, \"specificity\": 0.997018263138278, \"npv\": 0.6885456885456885, \"accuracy\": 0.8179644298311164, \"f1\": 0.8212503668916936, \"f2\": 0.7426478394734048, \"f0_5\": 0.9184611344537815, \"p4\": 0.8178891931787802, \"phi\": 0.690392263932338}, {\"truth_threshold\": 3.46, \"match_probability\": 0.9166967568055082, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8387, \"tn\": 8025, \"fp\": 24, \"fn\": 3637, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.697521623419827, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.302478376580173, \"precision\": 0.9971465937462847, \"recall\": 0.697521623419827, \"specificity\": 0.997018263138278, \"npv\": 0.688132395815469, \"accuracy\": 0.817615702685199, \"f1\": 0.8208465867384389, \"f2\": 0.7421204452545702, \"f0_5\": 0.9182578610843479, \"p4\": 0.8175431249217903, \"phi\": 0.6898938988503038}, {\"truth_threshold\": 3.48, \"match_probability\": 0.9177492870885379, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8384, \"tn\": 8025, \"fp\": 24, \"fn\": 3640, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.697272122421823, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.302727877578177, \"precision\": 0.9971455756422455, \"recall\": 0.697272122421823, \"specificity\": 0.997018263138278, \"npv\": 0.6879554222031719, \"accuracy\": 0.8174662481940915, \"f1\": 0.8206734534064213, \"f2\": 0.7418943791589976, \"f0_5\": 0.9181706676011915, \"p4\": 0.8173947973037887, \"phi\": 0.6896803868037026}, {\"truth_threshold\": 3.5, \"match_probability\": 0.9187896968583877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8382, \"tn\": 8025, \"fp\": 24, \"fn\": 3642, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6971057884231537, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3028942115768463, \"precision\": 0.9971448965024983, \"recall\": 0.6971057884231537, \"specificity\": 0.997018263138278, \"npv\": 0.6878374903574184, \"accuracy\": 0.8173666118666866, \"f1\": 0.8205580029368575, \"f2\": 0.7417436550918551, \"f0_5\": 0.9181125131440588, \"p4\": 0.8172959079872182, \"phi\": 0.689538069736128}, {\"truth_threshold\": 3.52, \"match_probability\": 0.9198180960235423, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8376, \"tn\": 8025, \"fp\": 24, \"fn\": 3648, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6966067864271457, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3033932135728543, \"precision\": 0.9971428571428571, \"recall\": 0.6966067864271457, \"specificity\": 0.997018263138278, \"npv\": 0.6874839372911847, \"accuracy\": 0.8170677028844717, \"f1\": 0.8202115158636898, \"f2\": 0.7412914188615123, \"f0_5\": 0.917937927406628, \"p4\": 0.8169992196030805, \"phi\": 0.6891112350144419}, {\"truth_threshold\": 3.54, \"match_probability\": 0.9208345942511155, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8368, \"tn\": 8025, \"fp\": 24, \"fn\": 3656, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6959414504324684, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3040585495675316, \"precision\": 0.9971401334604385, \"recall\": 0.6959414504324684, \"specificity\": 0.997018263138278, \"npv\": 0.6870130981936478, \"accuracy\": 0.8166691575748518, \"f1\": 0.8197492163009404, \"f2\": 0.7406882877779352, \"f0_5\": 0.9177048605018424, \"p4\": 0.8166035870962596, \"phi\": 0.6885423933538997}, {\"truth_threshold\": 3.56, \"match_probability\": 0.9218393009453847, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8363, \"tn\": 8025, \"fp\": 24, \"fn\": 3661, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.695525615435795, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30447438456420495, \"precision\": 0.9971384285203291, \"recall\": 0.695525615435795, \"specificity\": 0.997018263138278, \"npv\": 0.6867191511209995, \"accuracy\": 0.8164200667563394, \"f1\": 0.8194600950467885, \"f2\": 0.7403112440911425, \"f0_5\": 0.9175590274730098, \"p4\": 0.8163562887085497, \"phi\": 0.6881870244323732}, {\"truth_threshold\": 3.58, \"match_probability\": 0.9228323252269688, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8357, \"tn\": 8025, \"fp\": 24, \"fn\": 3667, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6950266134397871, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3049733865602129, \"precision\": 0.9971363799069324, \"recall\": 0.6950266134397871, \"specificity\": 0.997018263138278, \"npv\": 0.6863667464933287, \"accuracy\": 0.8161211577741244, \"f1\": 0.819112962509189, \"f2\": 0.7398587035430352, \"f0_5\": 0.9173838587863353, \"p4\": 0.8160595019198714, \"phi\": 0.6877607409196823}, {\"truth_threshold\": 3.6, \"match_probability\": 0.9238137759126431, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8351, \"tn\": 8025, \"fp\": 24, \"fn\": 3673, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6945276114437791, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3054723885562209, \"precision\": 0.9971343283582089, \"recall\": 0.6945276114437791, \"specificity\": 0.997018263138278, \"npv\": 0.6860147033680971, \"accuracy\": 0.8158222487919096, \"f1\": 0.8187656257659689, \"f2\": 0.7394060668307627, \"f0_5\": 0.9172085054037431, \"p4\": 0.8157626835808466, \"phi\": 0.6873346307404086}, {\"truth_threshold\": 3.62, \"match_probability\": 0.9247837614957818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8345, \"tn\": 8025, \"fp\": 24, \"fn\": 3679, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6940286094477711, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3059713905522289, \"precision\": 0.9971322738678456, \"recall\": 0.6940286094477711, \"specificity\": 0.997018263138278, \"npv\": 0.685663021189337, \"accuracy\": 0.8155233398096946, \"f1\": 0.8184180846368853, \"f2\": 0.7389533339236696, \"f0_5\": 0.917032967032967, \"p4\": 0.8154658334627376, \"phi\": 0.6869086935435704}, {\"truth_threshold\": 3.64, \"match_probability\": 0.9257423901274181, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8343, \"tn\": 8025, \"fp\": 24, \"fn\": 3681, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6938622754491018, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3061377245508982, \"precision\": 0.9971315883829329, \"recall\": 0.6938622754491018, \"specificity\": 0.997018263138278, \"npv\": 0.685545873910815, \"accuracy\": 0.8154237034822897, \"f1\": 0.8183021921435928, \"f2\": 0.7388024015727114, \"f0_5\": 0.916974413083619, \"p4\": 0.8153668763217615, \"phi\": 0.68676675285789}, {\"truth_threshold\": 3.66, \"match_probability\": 0.9266897695979149, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8339, \"tn\": 8025, \"fp\": 24, \"fn\": 3685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6935296074517632, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3064703925482369, \"precision\": 0.9971302164295109, \"recall\": 0.6935296074517632, \"specificity\": 0.997018263138278, \"npv\": 0.6853116994022204, \"accuracy\": 0.8152244308274798, \"f1\": 0.8180703389414823, \"f2\": 0.7385005047910873, \"f0_5\": 0.9168572433811241, \"p4\": 0.8151689513364401, \"phi\": 0.6864829289785656}, {\"truth_threshold\": 3.68, \"match_probability\": 0.9276260073192355, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8338, \"tn\": 8025, \"fp\": 24, \"fn\": 3686, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6934464404524284, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3065535595475715, \"precision\": 0.9971298732360679, \"recall\": 0.6934464404524284, \"specificity\": 0.997018263138278, \"npv\": 0.685253180770216, \"accuracy\": 0.8151746126637772, \"f1\": 0.8180123614245071, \"f2\": 0.7384250239115803, \"f0_5\": 0.9168279380717804, \"p4\": 0.8151194678540427, \"phi\": 0.6864119849767849}, {\"truth_threshold\": 3.7, \"match_probability\": 0.9285512103078053, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8332, \"tn\": 8025, \"fp\": 24, \"fn\": 3692, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6929474384564205, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3070525615435795, \"precision\": 0.9971278123504069, \"recall\": 0.6929474384564205, \"specificity\": 0.997018263138278, \"npv\": 0.6849022787402919, \"accuracy\": 0.8148757036815623, \"f1\": 0.8176643768400392, \"f2\": 0.7379720824771487, \"f0_5\": 0.9166519978876958, \"p4\": 0.8148225480948058, \"phi\": 0.6859864213729672}, {\"truth_threshold\": 3.72, \"match_probability\": 0.9294654851679567, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8329, \"tn\": 8025, \"fp\": 24, \"fn\": 3695, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6926979374584165, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3073020625415835, \"precision\": 0.9971267807973183, \"recall\": 0.6926979374584165, \"specificity\": 0.997018263138278, \"npv\": 0.6847269624573379, \"accuracy\": 0.8147262491904549, \"f1\": 0.8174903076998576, \"f2\": 0.7377455756523588, \"f0_5\": 0.9165639580949028, \"p4\": 0.8146740760398792, \"phi\": 0.6857737040454639}, {\"truth_threshold\": 3.74, \"match_probability\": 0.9303689380759456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8322, \"tn\": 8025, \"fp\": 24, \"fn\": 3702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6921157684630739, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3078842315369261, \"precision\": 0.9971243709561467, \"recall\": 0.6921157684630739, \"specificity\": 0.997018263138278, \"npv\": 0.6843182399590688, \"accuracy\": 0.8143775220445374, \"f1\": 0.8170839469808542, \"f2\": 0.7372169660890826, \"f0_5\": 0.9163583509513742, \"p4\": 0.8143276094805031, \"phi\": 0.6852775304684621}, {\"truth_threshold\": 3.7600000000000002, \"match_probability\": 0.9312616747645321, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8314, \"tn\": 8025, \"fp\": 24, \"fn\": 3710, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6914504324683965, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30854956753160345, \"precision\": 0.9971216118973375, \"recall\": 0.6914504324683965, \"specificity\": 0.997018263138278, \"npv\": 0.6838517256071581, \"accuracy\": 0.8139789767349176, \"f1\": 0.8166191926136922, \"f2\": 0.7366126802991104, \"f0_5\": 0.9161230606488011, \"p4\": 0.8139315928605717, \"phi\": 0.684710760405183}, {\"truth_threshold\": 3.7800000000000002, \"match_probability\": 0.9321438005081154, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8308, \"tn\": 8025, \"fp\": 24, \"fn\": 3716, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6909514304723886, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.30904856952761145, \"precision\": 0.9971195391262602, \"recall\": 0.6909514304723886, \"specificity\": 0.997018263138278, \"npv\": 0.6835022570479516, \"accuracy\": 0.8136800677527026, \"f1\": 0.8162703871094518, \"f2\": 0.7361593535124407, \"f0_5\": 0.9159463750220498, \"p4\": 0.8136345416948392, \"phi\": 0.684285882200352}, {\"truth_threshold\": 3.8000000000000003, \"match_probability\": 0.9330154201084124, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8301, \"tn\": 8025, \"fp\": 24, \"fn\": 3723, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6903692614770459, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3096307385229541, \"precision\": 0.9971171171171171, \"recall\": 0.6903692614770459, \"specificity\": 0.997018263138278, \"npv\": 0.6830949948927477, \"accuracy\": 0.8133313406067852, \"f1\": 0.8158631873802152, \"f2\": 0.7356303504014463, \"f0_5\": 0.9157400052952078, \"p4\": 0.8132879397344651, \"phi\": 0.6837904064022999}, {\"truth_threshold\": 3.8200000000000003, \"match_probability\": 0.9338766378806729, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8293, \"tn\": 8025, \"fp\": 24, \"fn\": 3731, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6897039254823686, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3102960745176314, \"precision\": 0.9971143441144643, \"recall\": 0.6897039254823686, \"specificity\": 0.997018263138278, \"npv\": 0.6826301463082681, \"accuracy\": 0.8129327952971653, \"f1\": 0.8153974730839192, \"f2\": 0.7350256146632869, \"f0_5\": 0.9155038417380553, \"p4\": 0.8128917670208192, \"phi\": 0.6832244317688917}, {\"truth_threshold\": 3.84, \"match_probability\": 0.9347275576404188, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8289, \"tn\": 8025, \"fp\": 24, \"fn\": 3735, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6893712574850299, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3106287425149701, \"precision\": 0.9971129556116926, \"recall\": 0.6893712574850299, \"specificity\": 0.997018263138278, \"npv\": 0.6823979591836735, \"accuracy\": 0.8127335226423554, \"f1\": 0.8151644785366573, \"f2\": 0.7347231824708823, \"f0_5\": 0.9153856347733899, \"p4\": 0.8126936580255811, \"phi\": 0.6829415575762664}, {\"truth_threshold\": 3.86, \"match_probability\": 0.9355682826907014, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8284, \"tn\": 8025, \"fp\": 24, \"fn\": 3740, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6889554224883566, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3110445775116434, \"precision\": 0.9971112181030333, \"recall\": 0.6889554224883566, \"specificity\": 0.997018263138278, \"npv\": 0.6821079473013175, \"accuracy\": 0.812484431823843, \"f1\": 0.8148731064332088, \"f2\": 0.7343450819090844, \"f0_5\": 0.9152377585292558, \"p4\": 0.8124460004207227, \"phi\": 0.682588070684413}, {\"truth_threshold\": 3.88, \"match_probability\": 0.9363989158098637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8282, \"tn\": 8025, \"fp\": 24, \"fn\": 3742, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6887890884896873, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3112109115103127, \"precision\": 0.9971105225138455, \"recall\": 0.6887890884896873, \"specificity\": 0.997018263138278, \"npv\": 0.6819920115577462, \"accuracy\": 0.812384795496438, \"f1\": 0.814756517461879, \"f2\": 0.7341938229140811, \"f0_5\": 0.9151785714285714, \"p4\": 0.8123469307055193, \"phi\": 0.6824467088172368}, {\"truth_threshold\": 3.9, \"match_probability\": 0.9372195592398013, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8274, \"tn\": 8025, \"fp\": 24, \"fn\": 3750, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.68812375249501, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31187624750499005, \"precision\": 0.9971077368040492, \"recall\": 0.68812375249501, \"specificity\": 0.997018263138278, \"npv\": 0.6815286624203821, \"accuracy\": 0.8119862501868181, \"f1\": 0.8142899320932979, \"f2\": 0.7335886796467709, \"f0_5\": 0.9149416135881104, \"p4\": 0.8119506134958691, \"phi\": 0.6818814489680326}, {\"truth_threshold\": 3.92, \"match_probability\": 0.9380303146747102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8264, \"tn\": 8025, \"fp\": 24, \"fn\": 3760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6872920825016633, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31270791749833665, \"precision\": 0.997104247104247, \"recall\": 0.6872920825016633, \"specificity\": 0.997018263138278, \"npv\": 0.6809503606279168, \"accuracy\": 0.8114880685497933, \"f1\": 0.8137061835368256, \"f2\": 0.7328320090805902, \"f0_5\": 0.9146449442181689, \"p4\": 0.8114551300500535, \"phi\": 0.6811752953388371}, {\"truth_threshold\": 3.94, \"match_probability\": 0.9388312832503134, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8253, \"tn\": 8025, \"fp\": 24, \"fn\": 3771, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.686377245508982, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31362275449101795, \"precision\": 0.9971003986951794, \"recall\": 0.686377245508982, \"specificity\": 0.997018263138278, \"npv\": 0.6803153611393693, \"accuracy\": 0.8109400687490659, \"f1\": 0.813063395891828, \"f2\": 0.7319993613964132, \"f0_5\": 0.9143180005317735, \"p4\": 0.8109099854846845, \"phi\": 0.6803990650771072}, {\"truth_threshold\": 3.96, \"match_probability\": 0.9396225655335566, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8250, \"tn\": 8025, \"fp\": 24, \"fn\": 3774, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.686127744510978, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.313872255489022, \"precision\": 0.9970993473531544, \"recall\": 0.686127744510978, \"specificity\": 0.997018263138278, \"npv\": 0.6801423849478769, \"accuracy\": 0.8107906142579584, \"f1\": 0.812887969258055, \"f2\": 0.7317722192655668, \"f0_5\": 0.9142287234042553, \"p4\": 0.810761289007124, \"phi\": 0.6801874635972909}, {\"truth_threshold\": 3.98, \"match_probability\": 0.9404042615127621, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8247, \"tn\": 8025, \"fp\": 24, \"fn\": 3777, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6858782435129741, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31412175648702595, \"precision\": 0.9970982952484585, \"recall\": 0.6858782435129741, \"specificity\": 0.997018263138278, \"npv\": 0.6799694966954754, \"accuracy\": 0.810641159766851, \"f1\": 0.8127124907612713, \"f2\": 0.7315450529565171, \"f0_5\": 0.9141393987762703, \"p4\": 0.8106125836082105, \"phi\": 0.6799759038999759}, {\"truth_threshold\": 4.0, \"match_probability\": 0.9411764705882353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8234, \"tn\": 8025, \"fp\": 24, \"fn\": 3790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6847970725216235, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3152029274783766, \"precision\": 0.9970937272947444, \"recall\": 0.6847970725216235, \"specificity\": 0.997018263138278, \"npv\": 0.6792213288192975, \"accuracy\": 0.8099935236387187, \"f1\": 0.8119514840745489, \"f2\": 0.730560386130532, \"f0_5\": 0.9137517755681818, \"p4\": 0.8099680897368917, \"phi\": 0.6790596269814902}, {\"truth_threshold\": 4.0200000000000005, \"match_probability\": 0.9419392915633099, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8226, \"tn\": 8025, \"fp\": 24, \"fn\": 3798, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6841317365269461, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3158682634730539, \"precision\": 0.9970909090909091, \"recall\": 0.6841317365269461, \"specificity\": 0.997018263138278, \"npv\": 0.6787617356001014, \"accuracy\": 0.8095949783290988, \"f1\": 0.8114826871855578, \"f2\": 0.7299542114790757, \"f0_5\": 0.9135127931769723, \"p4\": 0.8095713935436823, \"phi\": 0.6784961523140886}, {\"truth_threshold\": 4.04, \"match_probability\": 0.9426928226358258, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8210, \"tn\": 8025, \"fp\": 24, \"fn\": 3814, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6828010645375915, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3171989354624085, \"precision\": 0.9970852562545542, \"recall\": 0.6828010645375915, \"specificity\": 0.997018263138278, \"npv\": 0.6778444125348425, \"accuracy\": 0.808797887709859, \"f1\": 0.8105439826241485, \"f2\": 0.728741345641754, \"f0_5\": 0.9130338078291815, \"p4\": 0.8087778052375054, \"phi\": 0.6773700861898945}, {\"truth_threshold\": 4.0600000000000005, \"match_probability\": 0.9434371613900292, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8201, \"tn\": 8025, \"fp\": 24, \"fn\": 3823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6820525615435795, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3179474384564205, \"precision\": 0.9970820668693009, \"recall\": 0.6820525615435795, \"specificity\": 0.997018263138278, \"npv\": 0.6773295070898042, \"accuracy\": 0.8083495242365366, \"f1\": 0.8100153093979949, \"f2\": 0.7280588057740452, \"f0_5\": 0.9127637788264624, \"p4\": 0.8083312956587242, \"phi\": 0.6767371895377104}, {\"truth_threshold\": 4.08, \"match_probability\": 0.9441724047888862, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8198, \"tn\": 8025, \"fp\": 24, \"fn\": 3826, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6818030605455755, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3181969394544245, \"precision\": 0.9970810021892483, \"recall\": 0.6818030605455755, \"specificity\": 0.997018263138278, \"npv\": 0.6771580457345372, \"accuracy\": 0.8082000697454291, \"f1\": 0.8098389805393658, \"f2\": 0.7278312440072445, \"f0_5\": 0.912673672960456, \"p4\": 0.8081824403623489, \"phi\": 0.6765263062076488}, {\"truth_threshold\": 4.1, \"match_probability\": 0.9448986491668007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8186, \"tn\": 8025, \"fp\": 24, \"fn\": 3838, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6808050565535595, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31919494344644045, \"precision\": 0.9970767356881851, \"recall\": 0.6808050565535595, \"specificity\": 0.997018263138278, \"npv\": 0.6764730675208632, \"accuracy\": 0.8076022517809993, \"f1\": 0.8091331422358407, \"f2\": 0.7269207544489042, \"f0_5\": 0.9123127674750356, \"p4\": 0.8075869245309361, \"phi\": 0.6756831828519496}, {\"truth_threshold\": 4.12, \"match_probability\": 0.9456159902227271, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8184, \"tn\": 8025, \"fp\": 24, \"fn\": 3840, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6806387225548902, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3193612774451098, \"precision\": 0.9970760233918129, \"recall\": 0.6806387225548902, \"specificity\": 0.997018263138278, \"npv\": 0.6763590391908976, \"accuracy\": 0.8075026154535944, \"f1\": 0.8090154211150652, \"f2\": 0.726768968456948, \"f0_5\": 0.9122525414660246, \"p4\": 0.8074876570818772, \"phi\": 0.6755427259395883}, {\"truth_threshold\": 4.14, \"match_probability\": 0.94632452301367, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8183, \"tn\": 8025, \"fp\": 24, \"fn\": 3841, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6805555555555556, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.3194444444444444, \"precision\": 0.9970756671134398, \"recall\": 0.6805555555555556, \"specificity\": 0.997018263138278, \"npv\": 0.676302039440418, \"accuracy\": 0.8074527972898919, \"f1\": 0.808956551826405, \"f2\": 0.7266930714171537, \"f0_5\": 0.9122224204048872, \"p4\": 0.8074380217621995, \"phi\": 0.6754725042908801}, {\"truth_threshold\": 4.16, \"match_probability\": 0.9470243419485608, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8180, \"tn\": 8025, \"fp\": 24, \"fn\": 3844, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6803060545575516, \"tn_rate\": 0.997018263138278, \"fp_rate\": 0.002981736861721953, \"fn_rate\": 0.31969394544244845, \"precision\": 0.9970745977571916, \"recall\": 0.6803060545575516, \"specificity\": 0.997018263138278, \"npv\": 0.6761310978178448, \"accuracy\": 0.8073033427987845, \"f1\": 0.8087799090369785, \"f2\": 0.7264653641207816, \"f0_5\": 0.9121320249776985, \"p4\": 0.8072891094092602, \"phi\": 0.6752618665557147}, {\"truth_threshold\": 4.18, \"match_probability\": 0.9477155407825041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8171, \"tn\": 8029, \"fp\": 20, \"fn\": 3853, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6795575515635396, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3204424484364604, \"precision\": 0.9975582956903919, \"recall\": 0.6795575515635396, \"specificity\": 0.9975152192818983, \"npv\": 0.6757279919205521, \"accuracy\": 0.807054251980272, \"f1\": 0.8084095968340341, \"f2\": 0.7258336738500897, \"f0_5\": 0.9121862999017594, \"p4\": 0.8070422870125133, \"phi\": 0.6751768748446442}, {\"truth_threshold\": 4.2, \"match_probability\": 0.9483982126113827, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8167, \"tn\": 8029, \"fp\": 20, \"fn\": 3857, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6792248835662009, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3207751164337991, \"precision\": 0.9975571027238305, \"recall\": 0.6792248835662009, \"specificity\": 0.9975152192818983, \"npv\": 0.6755005889281508, \"accuracy\": 0.806854979325462, \"f1\": 0.8081737667606749, \"f2\": 0.7255299113409023, \"f0_5\": 0.912065576699723, \"p4\": 0.8068436645203612, \"phi\": 0.6748963857298883}, {\"truth_threshold\": 4.22, \"match_probability\": 0.9490724498668156, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8165, \"tn\": 8029, \"fp\": 20, \"fn\": 3859, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6790585495675316, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3209414504324684, \"precision\": 0.9975565058032987, \"recall\": 0.6790585495675316, \"specificity\": 0.9975152192818983, \"npv\": 0.6753869448183042, \"accuracy\": 0.8067553429980571, \"f1\": 0.8080558167153249, \"f2\": 0.7253780138945648, \"f0_5\": 0.9120051827361273, \"p4\": 0.8067443467733962, \"phi\": 0.6747561682634684}, {\"truth_threshold\": 4.24, \"match_probability\": 0.9497383443114579, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8158, \"tn\": 8029, \"fp\": 20, \"fn\": 3866, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.678476380572189, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.32152361942781105, \"precision\": 0.9975544142822206, \"recall\": 0.678476380572189, \"specificity\": 0.9975152192818983, \"npv\": 0.674989491382934, \"accuracy\": 0.8064066158521397, \"f1\": 0.8076428076428076, \"f2\": 0.7248462878060916, \"f0_5\": 0.9117936337625179, \"p4\": 0.8063967003771348, \"phi\": 0.6742655491441812}, {\"truth_threshold\": 4.26, \"match_probability\": 0.9503959870346359, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8155, \"tn\": 8029, \"fp\": 20, \"fn\": 3869, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6782268795741849, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.321773120425815, \"precision\": 0.9975535168195718, \"recall\": 0.6782268795741849, \"specificity\": 0.9975152192818983, \"npv\": 0.674819297360901, \"accuracy\": 0.8062571613610322, \"f1\": 0.8074657161245606, \"f2\": 0.7246183646994011, \"f0_5\": 0.911702888829264, \"p4\": 0.8062476926727604, \"phi\": 0.6740553513385115}, {\"truth_threshold\": 4.28, \"match_probability\": 0.9510454684483088, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8148, \"tn\": 8029, \"fp\": 20, \"fn\": 3876, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6776447105788423, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3223552894211577, \"precision\": 0.9975514201762977, \"recall\": 0.6776447105788423, \"specificity\": 0.9975152192818983, \"npv\": 0.674422511549769, \"accuracy\": 0.8059084342151148, \"f1\": 0.8070522979397782, \"f2\": 0.7240864495947675, \"f0_5\": 0.9114909611598353, \"p4\": 0.8058999695602272, \"phi\": 0.6735650470536735}, {\"truth_threshold\": 4.3, \"match_probability\": 0.9516868782833479, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8141, \"tn\": 8029, \"fp\": 20, \"fn\": 3883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6770625415834997, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.32293745841650034, \"precision\": 0.9975493199362823, \"recall\": 0.6770625415834997, \"specificity\": 0.9975152192818983, \"npv\": 0.6740261920752183, \"accuracy\": 0.8055597070691974, \"f1\": 0.8066385930146148, \"f2\": 0.7235544021188475, \"f0_5\": 0.9112787677979762, \"p4\": 0.8055521922801809, \"phi\": 0.6730749625002785}, {\"truth_threshold\": 4.32, \"match_probability\": 0.9523203055861257, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8138, \"tn\": 8029, \"fp\": 20, \"fn\": 3886, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6768130405854956, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3231869594145043, \"precision\": 0.9975484187300809, \"recall\": 0.6768130405854956, \"specificity\": 0.9975152192818983, \"npv\": 0.6738564834242552, \"accuracy\": 0.80541025257809, \"f1\": 0.8064612030522248, \"f2\": 0.7233263412379564, \"f0_5\": 0.9111877463274812, \"p4\": 0.8054031281972409, \"phi\": 0.6728649933947904}, {\"truth_threshold\": 4.34, \"match_probability\": 0.9529458387154083, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8127, \"tn\": 8029, \"fp\": 20, \"fn\": 3897, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6758982035928144, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3241017964071856, \"precision\": 0.9975451086289432, \"recall\": 0.6758982035928144, \"specificity\": 0.9975152192818983, \"npv\": 0.6732349488512493, \"accuracy\": 0.8048622527773627, \"f1\": 0.8058103217490457, \"f2\": 0.7224899098554487, \"f0_5\": 0.9108535819958755, \"p4\": 0.8048564736778757, \"phi\": 0.6720954504412546}, {\"truth_threshold\": 4.36, \"match_probability\": 0.9535635653395406, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8114, \"tn\": 8029, \"fp\": 20, \"fn\": 3910, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6748170326014638, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.32518296739853625, \"precision\": 0.9975411851487583, \"recall\": 0.6748170326014638, \"specificity\": 0.9975152192818983, \"npv\": 0.6725018845799481, \"accuracy\": 0.8042146166492303, \"f1\": 0.8050401825577934, \"f2\": 0.7215009781255558, \"f0_5\": 0.9104578096947935, \"p4\": 0.8042102511766043, \"phi\": 0.6711866848571578}, {\"truth_threshold\": 4.38, \"match_probability\": 0.9541735724339184, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8107, \"tn\": 8029, \"fp\": 20, \"fn\": 3917, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6742348636061211, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3257651363938789, \"precision\": 0.9975390673065092, \"recall\": 0.6742348636061211, \"specificity\": 0.9975152192818983, \"npv\": 0.6721078185166584, \"accuracy\": 0.803865889503313, \"f1\": 0.8046250806411592, \"f2\": 0.7209682869999822, \"f0_5\": 0.9102443186921764, \"p4\": 0.8038622053107333, \"phi\": 0.6706976599462807}, {\"truth_threshold\": 4.4, \"match_probability\": 0.9547759462787397, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8102, \"tn\": 8029, \"fp\": 20, \"fn\": 3922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6738190286094478, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.32618097139055224, \"precision\": 0.997537552327013, \"recall\": 0.6738190286094478, \"specificity\": 0.9975152192818983, \"npv\": 0.6718266253869969, \"accuracy\": 0.8036167986848005, \"f1\": 0.8043284026605778, \"f2\": 0.7205877121206731, \"f0_5\": 0.9100916606757729, \"p4\": 0.8036135665934471, \"phi\": 0.6703484890794073}, {\"truth_threshold\": 4.42, \"match_probability\": 0.9553707724570261, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8096, \"tn\": 8029, \"fp\": 20, \"fn\": 3928, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6733200266134398, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.32667997338656024, \"precision\": 0.9975357318876293, \"recall\": 0.6733200266134398, \"specificity\": 0.9975152192818983, \"npv\": 0.6714895040562013, \"accuracy\": 0.8033178897025856, \"f1\": 0.8039721946375372, \"f2\": 0.7201309328968903, \"f0_5\": 0.9099082898759216, \"p4\": 0.8033151619279919, \"phi\": 0.6699296296362525}, {\"truth_threshold\": 4.44, \"match_probability\": 0.9559581358529086, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8090, \"tn\": 8029, \"fp\": 20, \"fn\": 3934, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6728210246174318, \"tn_rate\": 0.9975152192818983, \"fp_rate\": 0.0024847807181016274, \"fn_rate\": 0.3271789753825682, \"precision\": 0.9975339087546239, \"recall\": 0.6728210246174318, \"specificity\": 0.9975152192818983, \"npv\": 0.671152720889409, \"accuracy\": 0.8030189807203707, \"f1\": 0.8036157743121088, \"f2\": 0.7196740561505889, \"f0_5\": 0.909724721122706, \"p4\": 0.8030167153528737, \"phi\": 0.6695109287093703}, {\"truth_threshold\": 4.46, \"match_probability\": 0.9565381206501699, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8087, \"tn\": 8031, \"fp\": 18, \"fn\": 3937, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6725715236194278, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3274284763805722, \"precision\": 0.9977791486736582, \"recall\": 0.6725715236194278, \"specificity\": 0.9977636973537085, \"npv\": 0.6710394385026738, \"accuracy\": 0.8029691625566682, \"f1\": 0.8035173133290278, \"f2\": 0.7194711837867653, \"f0_5\": 0.9097965979659797, \"p4\": 0.8029672527428522, \"phi\": 0.6695764746657303}, {\"truth_threshold\": 4.48, \"match_probability\": 0.9571108103310354, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8083, \"tn\": 8031, \"fp\": 18, \"fn\": 3941, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6722388556220892, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3277611443779108, \"precision\": 0.9977780520923343, \"recall\": 0.6722388556220892, \"specificity\": 0.9977636973537085, \"npv\": 0.6708152355496158, \"accuracy\": 0.8027698899018583, \"f1\": 0.80327950310559, \"f2\": 0.7191665035500115, \"f0_5\": 0.9096740794093815, \"p4\": 0.802768241102191, \"phi\": 0.6692975493923374}, {\"truth_threshold\": 4.5, \"match_probability\": 0.9576762876752064, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8076, \"tn\": 8031, \"fp\": 18, \"fn\": 3948, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6716566866267465, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3283433133732535, \"precision\": 0.9977761304670126, \"recall\": 0.6716566866267465, \"specificity\": 0.9977636973537085, \"npv\": 0.6704232406711745, \"accuracy\": 0.8024211627559408, \"f1\": 0.8028631076647779, \"f2\": 0.7186332087560064, \"f0_5\": 0.9094594594594595, \"p4\": 0.8024199252672758, \"phi\": 0.6688095989164807}, {\"truth_threshold\": 4.5200000000000005, \"match_probability\": 0.9582346347591285, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8069, \"tn\": 8031, \"fp\": 18, \"fn\": 3955, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6710745176314039, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.32892548236859614, \"precision\": 0.9977742055150242, \"recall\": 0.6710745176314039, \"specificity\": 0.9977636973537085, \"npv\": 0.6700317036542633, \"accuracy\": 0.8020724356100234, \"f1\": 0.8024464223559247, \"f2\": 0.7180997810725664, \"f0_5\": 0.9092445686468944, \"p4\": 0.8020715512334018, \"phi\": 0.6683218627617208}, {\"truth_threshold\": 4.54, \"match_probability\": 0.9587859329554874, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8064, \"tn\": 8031, \"fp\": 18, \"fn\": 3960, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6706586826347305, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.32934131736526945, \"precision\": 0.9977728285077951, \"recall\": 0.6706586826347305, \"specificity\": 0.9977636973537085, \"npv\": 0.6697523142356767, \"accuracy\": 0.801823344791511, \"f1\": 0.8021486123545211, \"f2\": 0.7177186799102852, \"f0_5\": 0.9090909090909091, \"p4\": 0.8018226767882659, \"phi\": 0.6679736107173052}, {\"truth_threshold\": 4.5600000000000005, \"match_probability\": 0.9593302629329274, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8059, \"tn\": 8031, \"fp\": 18, \"fn\": 3965, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6702428476380572, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3297571523619428, \"precision\": 0.9977714497957162, \"recall\": 0.6702428476380572, \"specificity\": 0.9977636973537085, \"npv\": 0.6694731577192398, \"accuracy\": 0.8015742539729985, \"f1\": 0.8018506541963086, \"f2\": 0.717337510903815, \"f0_5\": 0.9089371108905531, \"p4\": 0.8015737723060905, \"phi\": 0.6676254675568125}, {\"truth_threshold\": 4.58, \"match_probability\": 0.9598677046559833, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8050, \"tn\": 8031, \"fp\": 18, \"fn\": 3974, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6694943446440452, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3305056553559548, \"precision\": 0.9977689638076351, \"recall\": 0.6694943446440452, \"specificity\": 0.9977636973537085, \"npv\": 0.6689712619741774, \"accuracy\": 0.8011258904996762, \"f1\": 0.8013139558033048, \"f2\": 0.7166512356669753, \"f0_5\": 0.9086599241466498, \"p4\": 0.8011256680864555, \"phi\": 0.6669990836397847}, {\"truth_threshold\": 4.6000000000000005, \"match_probability\": 0.9603983373852208, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8040, \"tn\": 8031, \"fp\": 18, \"fn\": 3984, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6686626746506986, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3313373253493014, \"precision\": 0.9977661950856291, \"recall\": 0.6686626746506986, \"specificity\": 0.9977636973537085, \"npv\": 0.668414481897628, \"accuracy\": 0.8006277088626513, \"f1\": 0.8007170600537795, \"f2\": 0.715888449620686, \"f0_5\": 0.908351409978308, \"p4\": 0.8006276588022022, \"phi\": 0.6663035131690301}, {\"truth_threshold\": 4.62, \"match_probability\": 0.96092223967758, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8032, \"tn\": 8031, \"fp\": 18, \"fn\": 3992, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6679973386560213, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3320026613439787, \"precision\": 0.9977639751552795, \"recall\": 0.6679973386560213, \"specificity\": 0.9977636973537085, \"npv\": 0.6679697246943359, \"accuracy\": 0.8002291635530314, \"f1\": 0.8002391152734881, \"f2\": 0.7152780251487194, \"f0_5\": 0.9081041968162084, \"p4\": 0.8002291629334575, \"phi\": 0.6657473677893668}, {\"truth_threshold\": 4.64, \"match_probability\": 0.9614394893869119, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8026, \"tn\": 8031, \"fp\": 18, \"fn\": 3998, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6674983366600133, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3325016633399867, \"precision\": 0.9977623073097961, \"recall\": 0.6674983366600133, \"specificity\": 0.9977636973537085, \"npv\": 0.6676365450162108, \"accuracy\": 0.7999302545708166, \"f1\": 0.7998804066175005, \"f2\": 0.7148200926255789, \"f0_5\": 0.9079185520361991, \"p4\": 0.7999302390524942, \"phi\": 0.6653304396529559}, {\"truth_threshold\": 4.66, \"match_probability\": 0.9619501636647065, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8024, \"tn\": 8031, \"fp\": 18, \"fn\": 4000, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.667332002661344, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.33266799733865604, \"precision\": 0.9977617508082567, \"recall\": 0.667332002661344, \"specificity\": 0.9977636973537085, \"npv\": 0.667525558972654, \"accuracy\": 0.7998306182434115, \"f1\": 0.7997607893949965, \"f2\": 0.714667426698493, \"f0_5\": 0.9078566256335988, \"p4\": 0.7998305878085592, \"phi\": 0.6651914979987836}, {\"truth_threshold\": 4.68, \"match_probability\": 0.9624543389610023, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8023, \"tn\": 8031, \"fp\": 18, \"fn\": 4001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6672488356620093, \"tn_rate\": 0.9977636973537085, \"fp_rate\": 0.0022363026462914647, \"fn_rate\": 0.3327511643379907, \"precision\": 0.997761472453675, \"recall\": 0.6672488356620093, \"specificity\": 0.9977636973537085, \"npv\": 0.667470079787234, \"accuracy\": 0.7997808000797091, \"f1\": 0.7997009718415151, \"f2\": 0.7145910896556639, \"f0_5\": 0.9078256540237168, \"p4\": 0.7997807603156932, \"phi\": 0.6651220336131595}, {\"truth_threshold\": 4.7, \"match_probability\": 0.9629520910254744, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8018, \"tn\": 8032, \"fp\": 17, \"fn\": 4006, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.666833000665336, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.333166999334664, \"precision\": 0.9978842563783448, \"recall\": 0.666833000665336, \"specificity\": 0.9978879363896136, \"npv\": 0.6672204685163649, \"accuracy\": 0.7995815274248991, \"f1\": 0.7994416471409342, \"f2\": 0.7142220876164687, \"f0_5\": 0.9077529209310751, \"p4\": 0.7995814054959692, \"phi\": 0.6649128032845253}, {\"truth_threshold\": 4.72, \"match_probability\": 0.9634434949086931, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8008, \"tn\": 8032, \"fp\": 17, \"fn\": 4016, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6660013306719893, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33399866932801064, \"precision\": 0.9978816199376948, \"recall\": 0.6660013306719893, \"specificity\": 0.9978879363896136, \"npv\": 0.6666666666666666, \"accuracy\": 0.7990833457878742, \"f1\": 0.7988428350541175, \"f2\": 0.7134584201992125, \"f0_5\": 0.9074426615900644, \"p4\": 0.7990829863510659, \"phi\": 0.6642186951003514}, {\"truth_threshold\": 4.74, \"match_probability\": 0.9639286249635483, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8004, \"tn\": 8032, \"fp\": 17, \"fn\": 4020, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6656686626746507, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3343313373253493, \"precision\": 0.997880563520758, \"recall\": 0.6656686626746507, \"specificity\": 0.9978879363896136, \"npv\": 0.6664454032525722, \"accuracy\": 0.7988840731330643, \"f1\": 0.7986031429284111, \"f2\": 0.7131528770247875, \"f0_5\": 0.9073184002901968, \"p4\": 0.7988835832919289, \"phi\": 0.6639411714769543}, {\"truth_threshold\": 4.76, \"match_probability\": 0.9644075548468342, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7995, \"tn\": 8032, \"fp\": 17, \"fn\": 4029, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6649201596806387, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3350798403193613, \"precision\": 0.9978781827259111, \"recall\": 0.6649201596806387, \"specificity\": 0.9978879363896136, \"npv\": 0.6659480971727054, \"accuracy\": 0.798435709659742, \"f1\": 0.7980634857256937, \"f2\": 0.7124652455977757, \"f0_5\": 0.9070384824832093, \"p4\": 0.7984348519222996, \"phi\": 0.6633169926219292}, {\"truth_threshold\": 4.78, \"match_probability\": 0.9648803575209879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7992, \"tn\": 8032, \"fp\": 17, \"fn\": 4032, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6646706586826348, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33532934131736525, \"precision\": 0.9978773879385691, \"recall\": 0.6646706586826348, \"specificity\": 0.9978879363896136, \"npv\": 0.6657824933687002, \"accuracy\": 0.7982862551686345, \"f1\": 0.7978834922378076, \"f2\": 0.7122359860974957, \"f0_5\": 0.9069450748978666, \"p4\": 0.7982852517679008, \"phi\": 0.6631090095638571}, {\"truth_threshold\": 4.8, \"match_probability\": 0.9653471052559783, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7984, \"tn\": 8032, \"fp\": 17, \"fn\": 4040, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6640053226879574, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3359946773120426, \"precision\": 0.9978752655918011, \"recall\": 0.6640053226879574, \"specificity\": 0.9978879363896136, \"npv\": 0.6653412856196156, \"accuracy\": 0.7978877098590146, \"f1\": 0.7974032459425718, \"f2\": 0.7116245075494233, \"f0_5\": 0.906695739075134, \"p4\": 0.7978862613808071, \"phi\": 0.6625545747751738}, {\"truth_threshold\": 4.82, \"match_probability\": 0.9658078696313372, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7981, \"tn\": 8032, \"fp\": 17, \"fn\": 4043, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6637558216899534, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33624417831004655, \"precision\": 0.9978744686171543, \"recall\": 0.6637558216899534, \"specificity\": 0.9978879363896136, \"npv\": 0.665175983436853, \"accuracy\": 0.7977382553679071, \"f1\": 0.7972230546398961, \"f2\": 0.7113951581274289, \"f0_5\": 0.9066021446746637, \"p4\": 0.7977366186545479, \"phi\": 0.6623467316242824}, {\"truth_threshold\": 4.84, \"match_probability\": 0.9662627215383301, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7975, \"tn\": 8032, \"fp\": 17, \"fn\": 4049, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6632568196939455, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33674318030605455, \"precision\": 0.9978728728728729, \"recall\": 0.6632568196939455, \"specificity\": 0.9978879363896136, \"npv\": 0.6648456253621389, \"accuracy\": 0.7974393463856922, \"f1\": 0.7968625099920064, \"f2\": 0.7109363856796462, \"f0_5\": 0.9064148026913984, \"p4\": 0.7974372981168295, \"phi\": 0.6619311594627114}, {\"truth_threshold\": 4.86, \"match_probability\": 0.9667117311822604, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7966, \"tn\": 8032, \"fp\": 17, \"fn\": 4058, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6625083166999335, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3374916833000665, \"precision\": 0.9978704747588626, \"recall\": 0.6625083166999335, \"specificity\": 0.9978879363896136, \"npv\": 0.6643507030603805, \"accuracy\": 0.7969909829123698, \"f1\": 0.7963212875493577, \"f2\": 0.7102480429394248, \"f0_5\": 0.9061334061334061, \"p4\": 0.7969882291204987, \"phi\": 0.6613080859541752}, {\"truth_threshold\": 4.88, \"match_probability\": 0.9671549680849019, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7963, \"tn\": 8032, \"fp\": 17, \"fn\": 4061, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6622588157019295, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33774118429807054, \"precision\": 0.9978696741854637, \"recall\": 0.6622588157019295, \"specificity\": 0.9978879363896136, \"npv\": 0.6641858926651782, \"accuracy\": 0.7968415284212624, \"f1\": 0.7961407718456309, \"f2\": 0.710018546258649, \"f0_5\": 0.9060395048243218, \"p4\": 0.7968385158104577, \"phi\": 0.6611004705493536}, {\"truth_threshold\": 4.9, \"match_probability\": 0.9675925010870554, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7957, \"tn\": 8032, \"fp\": 17, \"fn\": 4067, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6617598137059215, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3382401862940785, \"precision\": 0.9978680712315023, \"recall\": 0.6617598137059215, \"specificity\": 0.9978879363896136, \"npv\": 0.6638565170675262, \"accuracy\": 0.7965426194390475, \"f1\": 0.7957795779577957, \"f2\": 0.7095594792224006, \"f0_5\": 0.905851548269581, \"p4\": 0.7965390535321488, \"phi\": 0.6606853531404707}, {\"truth_threshold\": 4.92, \"match_probability\": 0.9680243983512243, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7949, \"tn\": 8032, \"fp\": 17, \"fn\": 4075, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6610944777112442, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3389055222887558, \"precision\": 0.9978659302033643, \"recall\": 0.6610944777112442, \"specificity\": 0.9978879363896136, \"npv\": 0.6634178574378459, \"accuracy\": 0.7961440741294276, \"f1\": 0.7952976488244122, \"f2\": 0.7089472369876209, \"f0_5\": 0.9056006197593875, \"p4\": 0.7961396961610953, \"phi\": 0.660132097981581}, {\"truth_threshold\": 4.94, \"match_probability\": 0.9684507273644041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7939, \"tn\": 8032, \"fp\": 17, \"fn\": 4085, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6602628077178976, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3397371922821025, \"precision\": 0.9978632478632479, \"recall\": 0.6602628077178976, \"specificity\": 0.9978879363896136, \"npv\": 0.6628703474457374, \"accuracy\": 0.7956458924924027, \"f1\": 0.7946946946946947, \"f2\": 0.7081816884321701, \"f0_5\": 0.9052864440795475, \"p4\": 0.7956403791293551, \"phi\": 0.6594409051684917}, {\"truth_threshold\": 4.96, \"match_probability\": 0.9688715549409818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7936, \"tn\": 8032, \"fp\": 17, \"fn\": 4088, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6600133067198936, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.33998669328010644, \"precision\": 0.9978624418458444, \"recall\": 0.6600133067198936, \"specificity\": 0.9978879363896136, \"npv\": 0.6627062706270627, \"accuracy\": 0.7954964380012953, \"f1\": 0.794513690744356, \"f2\": 0.7079519705971561, \"f0_5\": 0.9051920795693038, \"p4\": 0.7954905577887846, \"phi\": 0.6592336286136896}, {\"truth_threshold\": 4.98, \"match_probability\": 0.9692869472257413, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7933, \"tn\": 8032, \"fp\": 17, \"fn\": 4091, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6597638057218895, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.34023619427811047, \"precision\": 0.9978616352201258, \"recall\": 0.6597638057218895, \"specificity\": 0.9978879363896136, \"npv\": 0.6625422750144354, \"accuracy\": 0.7953469835101878, \"f1\": 0.7943326324221488, \"f2\": 0.7077222281697177, \"f0_5\": 0.9050976633807959, \"p4\": 0.7953407242844505, \"phi\": 0.6590263895042504}, {\"truth_threshold\": 5.0, \"match_probability\": 0.9696969696969697, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7927, \"tn\": 8032, \"fp\": 17, \"fn\": 4097, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6592648037258816, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3407351962741184, \"precision\": 0.997860020140987, \"recall\": 0.6592648037258816, \"specificity\": 0.9978879363896136, \"npv\": 0.6622145271662957, \"accuracy\": 0.7950480745279729, \"f1\": 0.7939703525641025, \"f2\": 0.7072626695217702, \"f0_5\": 0.9049086757990867, \"p4\": 0.795041020655748, \"phi\": 0.6586120234580263}, {\"truth_threshold\": 5.0200000000000005, \"match_probability\": 0.9701016871696593, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7921, \"tn\": 8032, \"fp\": 17, \"fn\": 4103, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6587658017298735, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3412341982701264, \"precision\": 0.9978584026203073, \"recall\": 0.6587658017298735, \"specificity\": 0.9978879363896136, \"npv\": 0.6618871034198599, \"accuracy\": 0.794749165545758, \"f1\": 0.7936078549243563, \"f2\": 0.7068030124567227, \"f0_5\": 0.904719480994152, \"p4\": 0.794741267985477, \"phi\": 0.6581978067031282}, {\"truth_threshold\": 5.04, \"match_probability\": 0.9705011637988036, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7917, \"tn\": 8032, \"fp\": 17, \"fn\": 4107, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.658433133732535, \"tn_rate\": 0.9978879363896136, \"fp_rate\": 0.0021120636103863833, \"fn_rate\": 0.3415668662674651, \"precision\": 0.9978573229140408, \"recall\": 0.658433133732535, \"specificity\": 0.9978879363896136, \"npv\": 0.661669000741412, \"accuracy\": 0.794549892890948, \"f1\": 0.7933660687443632, \"f2\": 0.7064965197215777, \"f0_5\": 0.9045932358318098, \"p4\": 0.7945414054991454, \"phi\": 0.6579217449782864}, {\"truth_threshold\": 5.0600000000000005, \"match_probability\": 0.9708954630827813, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7910, \"tn\": 8035, \"fp\": 14, \"fn\": 4114, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6578509647371923, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3421490352628077, \"precision\": 0.9982332155477032, \"recall\": 0.6578509647371923, \"specificity\": 0.9982606534973288, \"npv\": 0.6613713062803523, \"accuracy\": 0.7943506202361381, \"f1\": 0.7930619610988571, \"f2\": 0.70599785790789, \"f0_5\": 0.9046203110704483, \"p4\": 0.7943405802798053, \"phi\": 0.6578557518266546}, {\"truth_threshold\": 5.08, \"match_probability\": 0.9712846478668253, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7902, \"tn\": 8035, \"fp\": 14, \"fn\": 4122, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.657185628742515, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34281437125748504, \"precision\": 0.9982314300151591, \"recall\": 0.657185628742515, \"specificity\": 0.9982606534973288, \"npv\": 0.6609360862054783, \"accuracy\": 0.7939520749265182, \"f1\": 0.7925777331995988, \"f2\": 0.7053845604513319, \"f0_5\": 0.9043673319904779, \"p4\": 0.7939406809141885, \"phi\": 0.657304265831349}, {\"truth_threshold\": 5.1000000000000005, \"match_probability\": 0.9716687803465724, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7895, \"tn\": 8035, \"fp\": 14, \"fn\": 4129, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6566034597471723, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3433965402528277, \"precision\": 0.9982298647110887, \"recall\": 0.6566034597471723, \"specificity\": 0.9982606534973288, \"npv\": 0.6605557382439987, \"accuracy\": 0.7936033477806008, \"f1\": 0.7921537149450659, \"f2\": 0.704847781448085, \"f0_5\": 0.9041456710948237, \"p4\": 0.7935906958360253, \"phi\": 0.6568219314985054}, {\"truth_threshold\": 5.12, \"match_probability\": 0.9720479220716894, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7885, \"tn\": 8035, \"fp\": 14, \"fn\": 4139, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6557717897538257, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34422821024617434, \"precision\": 0.9982276237498418, \"recall\": 0.6557717897538257, \"specificity\": 0.9982606534973288, \"npv\": 0.660013142763266, \"accuracy\": 0.793105166143576, \"f1\": 0.7915474577121919, \"f2\": 0.7040807214929904, \"f0_5\": 0.9038285190279688, \"p4\": 0.7930905978932318, \"phi\": 0.6561332309600548}, {\"truth_threshold\": 5.14, \"match_probability\": 0.9724221339495741, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7880, \"tn\": 8035, \"fp\": 14, \"fn\": 4144, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6553559547571524, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34464404524284764, \"precision\": 0.9982265011401064, \"recall\": 0.6553559547571524, \"specificity\": 0.9982606534973288, \"npv\": 0.6597421791608507, \"accuracy\": 0.7928560753250635, \"f1\": 0.7912441008133346, \"f2\": 0.703697088765851, \"f0_5\": 0.9036697247706422, \"p4\": 0.7928404959751628, \"phi\": 0.6557890340315159}, {\"truth_threshold\": 5.16, \"match_probability\": 0.972791476249125, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7864, \"tn\": 8035, \"fp\": 14, \"fn\": 4160, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6540252827677977, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34597471723220224, \"precision\": 0.9982228992129982, \"recall\": 0.6540252827677977, \"specificity\": 0.9982606534973288, \"npv\": 0.6588765887658876, \"accuracy\": 0.7920589847058237, \"f1\": 0.7902723344387499, \"f2\": 0.7024690034658949, \"f0_5\": 0.9031606027195884, \"p4\": 0.7920399305338481, \"phi\": 0.6546882882224508}, {\"truth_threshold\": 5.18, \"match_probability\": 0.9731560086045776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7858, \"tn\": 8035, \"fp\": 14, \"fn\": 4166, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6535262807717898, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34647371922821024, \"precision\": 0.9982215447154471, \"recall\": 0.6535262807717898, \"specificity\": 0.9982606534973288, \"npv\": 0.658552577657569, \"accuracy\": 0.7917600757236088, \"f1\": 0.7899075190993164, \"f2\": 0.7020082904516867, \"f0_5\": 0.9029692958264387, \"p4\": 0.7917396237599018, \"phi\": 0.6542757765107915}, {\"truth_threshold\": 5.2, \"match_probability\": 0.9735157900194042, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7853, \"tn\": 8035, \"fp\": 14, \"fn\": 4171, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6531104457751165, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34688955422488355, \"precision\": 0.9982204143892208, \"recall\": 0.6531104457751165, \"specificity\": 0.9982606534973288, \"npv\": 0.6582828117319351, \"accuracy\": 0.7915109849050964, \"f1\": 0.7896033381931526, \"f2\": 0.7016242874756535, \"f0_5\": 0.9028097121309666, \"p4\": 0.7914893283413826, \"phi\": 0.653932128033517}, {\"truth_threshold\": 5.22, \"match_probability\": 0.9738708788702727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7847, \"tn\": 8035, \"fp\": 14, \"fn\": 4177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6526114437791084, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34738855622089154, \"precision\": 0.9982190560997328, \"recall\": 0.6526114437791084, \"specificity\": 0.9982606534973288, \"npv\": 0.6579593842122502, \"accuracy\": 0.7912120759228815, \"f1\": 0.7892381191853156, \"f2\": 0.7011633933198707, \"f0_5\": 0.9026180178522131, \"p4\": 0.7911889258826753, \"phi\": 0.6535198831202016}, {\"truth_threshold\": 5.24, \"match_probability\": 0.974221332911062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7837, \"tn\": 8035, \"fp\": 14, \"fn\": 4187, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6517797737857618, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3482202262142382, \"precision\": 0.9982167876703605, \"recall\": 0.6517797737857618, \"specificity\": 0.9982606534973288, \"npv\": 0.6574210440189822, \"accuracy\": 0.7907138942858566, \"f1\": 0.7886289308176101, \"f2\": 0.7003950167122455, \"f0_5\": 0.9022980565533757, \"p4\": 0.7906881381752251, \"phi\": 0.6528331304815185}, {\"truth_threshold\": 5.26, \"match_probability\": 0.9745672092769317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7835, \"tn\": 8035, \"fp\": 14, \"fn\": 4189, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6516134397870925, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.34838656021290754, \"precision\": 0.9982163332908651, \"recall\": 0.6516134397870925, \"specificity\": 0.9982606534973288, \"npv\": 0.6573134816753927, \"accuracy\": 0.7906142579584516, \"f1\": 0.7885070195742968, \"f2\": 0.7002413084279203, \"f0_5\": 0.9022339935513588, \"p4\": 0.7905879630040967, \"phi\": 0.6526958281788702}, {\"truth_threshold\": 5.28, \"match_probability\": 0.9749085644884405, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7831, \"tn\": 8035, \"fp\": 14, \"fn\": 4193, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6512807717897539, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3487192282102462, \"precision\": 0.9982154238368387, \"recall\": 0.6512807717897539, \"specificity\": 0.9982606534973288, \"npv\": 0.6570984625449787, \"accuracy\": 0.7904149853036417, \"f1\": 0.7882631234586542, \"f2\": 0.6999338588870417, \"f0_5\": 0.902105796700765, \"p4\": 0.7903875949536731, \"phi\": 0.6524212717032325}, {\"truth_threshold\": 5.3, \"match_probability\": 0.9752454544557132, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7828, \"tn\": 8035, \"fp\": 14, \"fn\": 4196, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6510312707917498, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3489687292082502, \"precision\": 0.9982147411374649, \"recall\": 0.6510312707917498, \"specificity\": 0.9982606534973288, \"npv\": 0.6569372904913744, \"accuracy\": 0.7902655308125343, \"f1\": 0.7880801369173462, \"f2\": 0.6997032428760414, \"f0_5\": 0.9020095870206489, \"p4\": 0.7902373033825033, \"phi\": 0.6522153964130166}, {\"truth_threshold\": 5.32, \"match_probability\": 0.9755779344826514, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7820, \"tn\": 8035, \"fp\": 14, \"fn\": 4204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6503659347970725, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3496340652029275, \"precision\": 0.9982129180495277, \"recall\": 0.6503659347970725, \"specificity\": 0.9982606534973288, \"npv\": 0.6565078846310973, \"accuracy\": 0.7898669855029143, \"f1\": 0.7875919025078054, \"f2\": 0.6990881458966566, \"f0_5\": 0.9017527675276753, \"p4\": 0.7898364604965652, \"phi\": 0.651666571590185}, {\"truth_threshold\": 5.34, \"match_probability\": 0.9759060592711867, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7813, \"tn\": 8035, \"fp\": 14, \"fn\": 4211, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6497837658017299, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35021623419827014, \"precision\": 0.9982113197904688, \"recall\": 0.6497837658017299, \"specificity\": 0.9982606534973288, \"npv\": 0.6561326147313409, \"accuracy\": 0.789518258356997, \"f1\": 0.7871643745907008, \"f2\": 0.6985497916778427, \"f0_5\": 0.9015277393150558, \"p4\": 0.7894856445934358, \"phi\": 0.651186559343056}, {\"truth_threshold\": 5.36, \"match_probability\": 0.9762298829255712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7805, \"tn\": 8035, \"fp\": 14, \"fn\": 4219, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6491184298070526, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3508815701929474, \"precision\": 0.9982094897045658, \"recall\": 0.6491184298070526, \"specificity\": 0.9982606534973288, \"npv\": 0.6557042598335238, \"accuracy\": 0.789119713047377, \"f1\": 0.7866754019049539, \"f2\": 0.6979343646606456, \"f0_5\": 0.901270207852194, \"p4\": 0.7890846219899113, \"phi\": 0.6506382126313357}, {\"truth_threshold\": 5.38, \"match_probability\": 0.9765494589567063, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7802, \"tn\": 8035, \"fp\": 14, \"fn\": 4222, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6488689288090486, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35113107119095144, \"precision\": 0.9982088024564995, \"recall\": 0.6488689288090486, \"specificity\": 0.9982606534973288, \"npv\": 0.6555437709064208, \"accuracy\": 0.7889702585562696, \"f1\": 0.786491935483871, \"f2\": 0.6977035341250537, \"f0_5\": 0.9011735353908704, \"p4\": 0.7889342136018278, \"phi\": 0.6504326481135968}, {\"truth_threshold\": 5.4, \"match_probability\": 0.9768648402865033, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7800, \"tn\": 8035, \"fp\": 14, \"fn\": 4224, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6487025948103793, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35129740518962077, \"precision\": 0.9982083439979524, \"recall\": 0.6487025948103793, \"specificity\": 0.9982606534973288, \"npv\": 0.6554368219267477, \"accuracy\": 0.7888706222288646, \"f1\": 0.7863695937090432, \"f2\": 0.6975496333392953, \"f0_5\": 0.9011090573012939, \"p4\": 0.7888339337672383, \"phi\": 0.6502956249178329}, {\"truth_threshold\": 5.42, \"match_probability\": 0.9771760792522766, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7794, \"tn\": 8035, \"fp\": 14, \"fn\": 4230, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6482035928143712, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35179640718562877, \"precision\": 0.9982069672131147, \"recall\": 0.6482035928143712, \"specificity\": 0.9982606534973288, \"npv\": 0.6551161842641663, \"accuracy\": 0.7885717132466498, \"f1\": 0.7860024203307785, \"f2\": 0.6970878649112765, \"f0_5\": 0.9009154799334197, \"p4\": 0.7885330577901037, \"phi\": 0.6498846503170738}, {\"truth_threshold\": 5.44, \"match_probability\": 0.9774832276111642, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7785, \"tn\": 8035, \"fp\": 14, \"fn\": 4239, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6474550898203593, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35254491017964074, \"precision\": 0.9982048980638544, \"recall\": 0.6474550898203593, \"specificity\": 0.9982606534973288, \"npv\": 0.6546358155450546, \"accuracy\": 0.7881233497733273, \"f1\": 0.7854512435050194, \"f2\": 0.6963950263887646, \"f0_5\": 0.9006247107820453, \"p4\": 0.7880816407676707, \"phi\": 0.6492684549984132}, {\"truth_threshold\": 5.46, \"match_probability\": 0.9777863365445763, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7780, \"tn\": 8035, \"fp\": 14, \"fn\": 4244, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.647039254823686, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35296074517631404, \"precision\": 0.9982037464716449, \"recall\": 0.647039254823686, \"specificity\": 0.9982606534973288, \"npv\": 0.654369248310123, \"accuracy\": 0.7878742589548149, \"f1\": 0.7851448178423656, \"f2\": 0.6960100196815172, \"f0_5\": 0.9004629629629629, \"p4\": 0.7878307998056773, \"phi\": 0.648926262148054}, {\"truth_threshold\": 5.48, \"match_probability\": 0.9780854566626659, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7777, \"tn\": 8035, \"fp\": 14, \"fn\": 4247, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6467897538256819, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.353210246174318, \"precision\": 0.9982030548068284, \"recall\": 0.6467897538256819, \"specificity\": 0.9982606534973288, \"npv\": 0.6542094121478587, \"accuracy\": 0.7877248044637075, \"f1\": 0.784960888215998, \"f2\": 0.6957789825898688, \"f0_5\": 0.9003658423636195, \"p4\": 0.7876802767228851, \"phi\": 0.6487209936110679}, {\"truth_threshold\": 5.5, \"match_probability\": 0.9783806380088231, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7774, \"tn\": 8035, \"fp\": 14, \"fn\": 4250, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.646540252827678, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35345974717232204, \"precision\": 0.9982023626091423, \"recall\": 0.646540252827678, \"specificity\": 0.9982606534973288, \"npv\": 0.6540496540496541, \"accuracy\": 0.7875753499726, \"f1\": 0.7847769028871391, \"f2\": 0.6955479206928638, \"f0_5\": 0.9002686677783954, \"p4\": 0.787529739719678, \"phi\": 0.6485157604051773}, {\"truth_threshold\": 5.5200000000000005, \"match_probability\": 0.9786719300641882, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7768, \"tn\": 8035, \"fp\": 14, \"fn\": 4256, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.64604125083167, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35395874916833003, \"precision\": 0.9982009766126959, \"recall\": 0.64604125083167, \"specificity\": 0.9982606534973288, \"npv\": 0.6537303718167765, \"accuracy\": 0.7872764409903851, \"f1\": 0.7844087650207008, \"f2\": 0.6950857224668027, \"f0_5\": 0.900074156470152, \"p4\": 0.7872286238169468, \"phi\": 0.6481053998269736}, {\"truth_threshold\": 5.54, \"match_probability\": 0.9789593817521819, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7764, \"tn\": 8035, \"fp\": 14, \"fn\": 4260, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6457085828343313, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35429141716566864, \"precision\": 0.9982000514271021, \"recall\": 0.6457085828343313, \"specificity\": 0.9982606534973288, \"npv\": 0.6535176901179341, \"accuracy\": 0.7870771683355752, \"f1\": 0.7841632158367842, \"f2\": 0.6947775351684147, \"f0_5\": 0.8999443620178041, \"p4\": 0.7870278487389603, \"phi\": 0.6478319043753181}, {\"truth_threshold\": 5.5600000000000005, \"match_probability\": 0.9792430414430521, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7759, \"tn\": 8035, \"fp\": 14, \"fn\": 4265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.645292747837658, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.354707252162342, \"precision\": 0.9981988936060723, \"recall\": 0.645292747837658, \"specificity\": 0.9982606534973288, \"npv\": 0.6532520325203252, \"accuracy\": 0.7868280775170627, \"f1\": 0.7838561398191645, \"f2\": 0.6943922389876318, \"f0_5\": 0.8997819834864088, \"p4\": 0.786776844714724, \"phi\": 0.6474901229451074}, {\"truth_threshold\": 5.58, \"match_probability\": 0.9795229569584335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7756, \"tn\": 8035, \"fp\": 14, \"fn\": 4268, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.645043246839654, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.354956753160346, \"precision\": 0.9981981981981982, \"recall\": 0.645043246839654, \"specificity\": 0.9982606534973288, \"npv\": 0.653092741607738, \"accuracy\": 0.7866786230259553, \"f1\": 0.7836718197433565, \"f2\": 0.6941610281745606, \"f0_5\": 0.8996844840386043, \"p4\": 0.7866262234789754, \"phi\": 0.6472851008877757}, {\"truth_threshold\": 5.6000000000000005, \"match_probability\": 0.979799175575919, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7748, \"tn\": 8035, \"fp\": 14, \"fn\": 4276, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6443779108449768, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3556220891550233, \"precision\": 0.9981963411491883, \"recall\": 0.6443779108449768, \"specificity\": 0.9982606534973288, \"npv\": 0.6526683453821785, \"accuracy\": 0.7862800777163353, \"f1\": 0.783180026281209, \"f2\": 0.6935443445880626, \"f0_5\": 0.899424219910847, \"p4\": 0.7862244975441054, \"phi\": 0.6467385466582477}, {\"truth_threshold\": 5.62, \"match_probability\": 0.9800717440336414, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7733, \"tn\": 8035, \"fp\": 14, \"fn\": 4291, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6431304058549567, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35686959414504327, \"precision\": 0.998192848844714, \"recall\": 0.6431304058549567, \"specificity\": 0.9982606534973288, \"npv\": 0.6518740872951485, \"accuracy\": 0.785532805260798, \"f1\": 0.7822568408274746, \"f2\": 0.692387586626793, \"f0_5\": 0.8989351808797544, \"p4\": 0.7854709878197911, \"phi\": 0.6457144266784203}, {\"truth_threshold\": 5.64, \"match_probability\": 0.9803407085348623, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7722, \"tn\": 8035, \"fp\": 14, \"fn\": 4302, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6422155688622755, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35778443113772457, \"precision\": 0.9981902792140641, \"recall\": 0.6422155688622755, \"specificity\": 0.9982606534973288, \"npv\": 0.6512928588797925, \"accuracy\": 0.7849848054600708, \"f1\": 0.781578947368421, \"f2\": 0.6915389024215504, \"f0_5\": 0.8985756842301248, \"p4\": 0.784918185165627, \"phi\": 0.6449639577314491}, {\"truth_threshold\": 5.66, \"match_probability\": 0.9806061147525681, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7713, \"tn\": 8035, \"fp\": 14, \"fn\": 4311, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6414670658682635, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35853293413173654, \"precision\": 0.998188171347224, \"recall\": 0.6414670658682635, \"specificity\": 0.9982606534973288, \"npv\": 0.650818078729953, \"accuracy\": 0.7845364419867483, \"f1\": 0.7810237456331325, \"f2\": 0.6908442756569873, \"f0_5\": 0.898281002515606, \"p4\": 0.7844657467176565, \"phi\": 0.6443502837866123}, {\"truth_threshold\": 5.68, \"match_probability\": 0.9808680078340698, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7704, \"tn\": 8035, \"fp\": 14, \"fn\": 4320, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6407185628742516, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3592814371257485, \"precision\": 0.9981860585643949, \"recall\": 0.6407185628742516, \"specificity\": 0.9982606534973288, \"npv\": 0.650343990287333, \"accuracy\": 0.784088078513426, \"f1\": 0.7804680376861514, \"f2\": 0.6901494248754793, \"f0_5\": 0.8979858261842596, \"p4\": 0.7840131764425633, \"phi\": 0.6437369201845579}, {\"truth_threshold\": 5.7, \"match_probability\": 0.9811264324056064, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7696, \"tn\": 8035, \"fp\": 14, \"fn\": 4328, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6400532268795742, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.35994677312042583, \"precision\": 0.9981841763942931, \"recall\": 0.6400532268795742, \"specificity\": 0.9982606534973288, \"npv\": 0.6499231578095931, \"accuracy\": 0.7836895332038061, \"f1\": 0.7799736495388669, \"f2\": 0.6895315915851342, \"f0_5\": 0.8977230309817096, \"p4\": 0.7836107803316777, \"phi\": 0.6431919677642228}, {\"truth_threshold\": 5.72, \"match_probability\": 0.9813814325769498, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7691, \"tn\": 8035, \"fp\": 14, \"fn\": 4333, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6396373918829009, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.36036260811709914, \"precision\": 0.9981829980532122, \"recall\": 0.6396373918829009, \"specificity\": 0.9982606534973288, \"npv\": 0.6496604139715395, \"accuracy\": 0.7834404423852936, \"f1\": 0.7796644533427949, \"f2\": 0.6891453558179961, \"f0_5\": 0.8975585846326206, \"p4\": 0.7833592292043082, \"phi\": 0.6428514962594767}, {\"truth_threshold\": 5.74, \"match_probability\": 0.9816330519460089, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7681, \"tn\": 8035, \"fp\": 14, \"fn\": 4343, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6388057218895542, \"tn_rate\": 0.9982606534973288, \"fp_rate\": 0.0017393465026711392, \"fn_rate\": 0.3611942781104458, \"precision\": 0.998180636777128, \"recall\": 0.6388057218895542, \"specificity\": 0.9982606534973288, \"npv\": 0.6491355630958151, \"accuracy\": 0.7829422607482688, \"f1\": 0.779045590547188, \"f2\": 0.6883726765965836, \"f0_5\": 0.8972292309129988, \"p4\": 0.7828560026164866, \"phi\": 0.6421708380036165}, {\"truth_threshold\": 5.76, \"match_probability\": 0.9818813336034329, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7679, \"tn\": 8037, \"fp\": 12, \"fn\": 4345, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6386393878908849, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3613606121091151, \"precision\": 0.9984397347549083, \"recall\": 0.6386393878908849, \"specificity\": 0.998509131569139, \"npv\": 0.6490873849135842, \"accuracy\": 0.7829422607482688, \"f1\": 0.7790007608419984, \"f2\": 0.6882427805761199, \"f0_5\": 0.8973310273908572, \"p4\": 0.7828540414702263, \"phi\": 0.6423168576388089}, {\"truth_threshold\": 5.78, \"match_probability\": 0.9821263201372112, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7673, \"tn\": 8037, \"fp\": 12, \"fn\": 4351, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6381403858948769, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3618596141051231, \"precision\": 0.9984385165907612, \"recall\": 0.6381403858948769, \"specificity\": 0.998509131569139, \"npv\": 0.6487730061349694, \"accuracy\": 0.7826433517660539, \"f1\": 0.7786290527170329, \"f2\": 0.6877789928470268, \"f0_5\": 0.8971331026096717, \"p4\": 0.7825519888952766, \"phi\": 0.6419087969801375}, {\"truth_threshold\": 5.8, \"match_probability\": 0.9823680536372692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7662, \"tn\": 8037, \"fp\": 12, \"fn\": 4362, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6372255489021956, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3627744510978044, \"precision\": 0.9984362783424551, \"recall\": 0.6372255489021956, \"specificity\": 0.998509131569139, \"npv\": 0.6481974352770384, \"accuracy\": 0.7820953519653265, \"f1\": 0.7779469996954006, \"f2\": 0.6869284561592254, \"f0_5\": 0.8967696629213483, \"p4\": 0.7819980685962075, \"phi\": 0.6411610385151932}, {\"truth_threshold\": 5.82, \"match_probability\": 0.982606575700058, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7656, \"tn\": 8037, \"fp\": 12, \"fn\": 4368, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6367265469061876, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.36327345309381237, \"precision\": 0.9984350547730829, \"recall\": 0.6367265469061876, \"specificity\": 0.998509131569139, \"npv\": 0.6478839177750907, \"accuracy\": 0.7817964429831117, \"f1\": 0.7775746496039001, \"f2\": 0.6864643856251345, \"f0_5\": 0.8965711073636875, \"p4\": 0.7816958439756678, \"phi\": 0.6407533620966144}, {\"truth_threshold\": 5.84, \"match_probability\": 0.9828419274331381, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7655, \"tn\": 8037, \"fp\": 12, \"fn\": 4369, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6366433799068529, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.36335662009314706, \"precision\": 0.998434850658667, \"recall\": 0.6366433799068529, \"specificity\": 0.998509131569139, \"npv\": 0.6478316943414477, \"accuracy\": 0.7817466248194092, \"f1\": 0.7775125691940481, \"f2\": 0.6863870308268923, \"f0_5\": 0.8965379930666167, \"p4\": 0.781645467257498, \"phi\": 0.640685429161406}, {\"truth_threshold\": 5.86, \"match_probability\": 0.9830741494597539, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7651, \"tn\": 8037, \"fp\": 12, \"fn\": 4373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6363107119095143, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3636892880904857, \"precision\": 0.9984340336682761, \"recall\": 0.6363107119095143, \"specificity\": 0.998509131569139, \"npv\": 0.6476228847703465, \"accuracy\": 0.7815473521645993, \"f1\": 0.7772641844872251, \"f2\": 0.6860775838878028, \"f0_5\": 0.8964054738026057, \"p4\": 0.7814439433427192, \"phi\": 0.6404137348944879}, {\"truth_threshold\": 5.88, \"match_probability\": 0.9833032819233992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7646, \"tn\": 8037, \"fp\": 12, \"fn\": 4378, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.635894876912841, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.36410512308715903, \"precision\": 0.9984330112300862, \"recall\": 0.635894876912841, \"specificity\": 0.998509131569139, \"npv\": 0.6473620620217478, \"accuracy\": 0.7812982613460868, \"f1\": 0.7769535616299157, \"f2\": 0.6856907127739714, \"f0_5\": 0.8962396849212303, \"p4\": 0.7811920000070681, \"phi\": 0.6400742012680073}, {\"truth_threshold\": 5.9, \"match_probability\": 0.9835293644923733, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7640, \"tn\": 8037, \"fp\": 12, \"fn\": 4384, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.635395874916833, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.364604125083167, \"precision\": 0.9984317825405122, \"recall\": 0.635395874916833, \"specificity\": 0.998509131569139, \"npv\": 0.6470493519040335, \"accuracy\": 0.7809993523638719, \"f1\": 0.7765806058141899, \"f2\": 0.6852263758341106, \"f0_5\": 0.8960405329330081, \"p4\": 0.7808896114077549, \"phi\": 0.6396668841800726}, {\"truth_threshold\": 5.92, \"match_probability\": 0.9837524363643234, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7638, \"tn\": 8037, \"fp\": 12, \"fn\": 4386, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6352295409181636, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3647704590818363, \"precision\": 0.9984313725490196, \"recall\": 0.6352295409181636, \"specificity\": 0.998509131569139, \"npv\": 0.6469451823231104, \"accuracy\": 0.7808997160364669, \"f1\": 0.7764562366575175, \"f2\": 0.6850715746421268, \"f0_5\": 0.8959740990990991, \"p4\": 0.7807888014424493, \"phi\": 0.6395311416491714}, {\"truth_threshold\": 5.94, \"match_probability\": 0.9839725362707769, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7631, \"tn\": 8037, \"fp\": 12, \"fn\": 4393, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6346473719228211, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.365352628077179, \"precision\": 0.9984299358890488, \"recall\": 0.6346473719228211, \"specificity\": 0.998509131569139, \"npv\": 0.646580852775543, \"accuracy\": 0.7805509888905495, \"f1\": 0.7760207454110948, \"f2\": 0.6845296829867776, \"f0_5\": 0.8957413841675275, \"p4\": 0.7804359121565752, \"phi\": 0.6390561600246606}, {\"truth_threshold\": 5.96, \"match_probability\": 0.9841897024816576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7628, \"tn\": 8037, \"fp\": 12, \"fn\": 4396, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.634397870924817, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.36560212907518297, \"precision\": 0.9984293193717277, \"recall\": 0.634397870924817, \"specificity\": 0.998509131569139, \"npv\": 0.6464248371270007, \"accuracy\": 0.780401534399442, \"f1\": 0.7758340113913751, \"f2\": 0.68429740203818, \"f0_5\": 0.895641555513808, \"p4\": 0.7802846479045583, \"phi\": 0.6388526522097084}, {\"truth_threshold\": 5.98, \"match_probability\": 0.9844039728097899, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7622, \"tn\": 8037, \"fp\": 12, \"fn\": 4402, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6338988689288091, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.36610113107119097, \"precision\": 0.9984280848834163, \"recall\": 0.6338988689288091, \"specificity\": 0.998509131569139, \"npv\": 0.6461130315941795, \"accuracy\": 0.7801026254172271, \"f1\": 0.775460372367484, \"f2\": 0.683832765117531, \"f0_5\": 0.8954417293233082, \"p4\": 0.7799820724361359, \"phi\": 0.6384457366999262}, {\"truth_threshold\": 6.0, \"match_probability\": 0.9846153846153847, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7612, \"tn\": 8037, \"fp\": 12, \"fn\": 4412, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6330671989354624, \"tn_rate\": 0.998509131569139, \"fp_rate\": 0.0014908684308609765, \"fn_rate\": 0.3669328010645376, \"precision\": 0.9984260230849947, \"recall\": 0.6330671989354624, \"specificity\": 0.998509131569139, \"npv\": 0.6455940236163548, \"accuracy\": 0.7796044437802022, \"f1\": 0.7748371335504886, \"f2\": 0.6830581478822685, \"f0_5\": 0.8951081843838193, \"p4\": 0.7794776401706518, \"phi\": 0.6377678401009574}, {\"truth_threshold\": 6.0200000000000005, \"match_probability\": 0.9848239748105114, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7603, \"tn\": 8038, \"fp\": 11, \"fn\": 4421, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6323186959414504, \"tn_rate\": 0.9986333706050441, \"fp_rate\": 0.001366629394955895, \"fn_rate\": 0.36768130405854954, \"precision\": 0.998555292881534, \"recall\": 0.6323186959414504, \"specificity\": 0.9986333706050441, \"npv\": 0.6451561120475159, \"accuracy\": 0.7792058984705824, \"f1\": 0.7743151033710154, \"f2\": 0.6823730030515168, \"f0_5\": 0.894891713747646, \"p4\": 0.7790727454542807, \"phi\": 0.6372998048011088}, {\"truth_threshold\": 6.04, \"match_probability\": 0.9850297798635513, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7589, \"tn\": 8040, \"fp\": 9, \"fn\": 4435, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6311543579507651, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.36884564204923487, \"precision\": 0.9988154777573045, \"recall\": 0.6311543579507651, \"specificity\": 0.9988818486768543, \"npv\": 0.6444889779559119, \"accuracy\": 0.7786080805061525, \"f1\": 0.7735195189073489, \"f2\": 0.6813121700721801, \"f0_5\": 0.8945916635231987, \"p4\": 0.778464447900257, \"phi\": 0.6366357663406921}, {\"truth_threshold\": 6.0600000000000005, \"match_probability\": 0.9852328358036327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7583, \"tn\": 8040, \"fp\": 9, \"fn\": 4441, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6306553559547572, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.36934464404524286, \"precision\": 0.9988145416227608, \"recall\": 0.6306553559547572, \"specificity\": 0.9988818486768543, \"npv\": 0.6441791523115135, \"accuracy\": 0.7783091715239376, \"f1\": 0.7731443719412724, \"f2\": 0.6808468610831777, \"f0_5\": 0.8943904510284959, \"p4\": 0.7781614333477892, \"phi\": 0.636229874082581}, {\"truth_threshold\": 6.08, \"match_probability\": 0.9854331782250482, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7579, \"tn\": 8040, \"fp\": 9, \"fn\": 4445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6303226879574185, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.36967731204258153, \"precision\": 0.9988139167105957, \"recall\": 0.6303226879574185, \"specificity\": 0.9988818486768543, \"npv\": 0.6439727673207849, \"accuracy\": 0.7781098988691277, \"f1\": 0.7728941464409546, \"f2\": 0.6805365993822283, \"f0_5\": 0.89425618274495, \"p4\": 0.7779593876901818, \"phi\": 0.6359593522235879}, {\"truth_threshold\": 6.1000000000000005, \"match_probability\": 0.9856308422916512, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7570, \"tn\": 8040, \"fp\": 9, \"fn\": 4454, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6295741849634066, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3704258150365935, \"precision\": 0.9988125082464705, \"recall\": 0.6295741849634066, \"specificity\": 0.9988818486768543, \"npv\": 0.643508884264447, \"accuracy\": 0.7776615353958053, \"f1\": 0.7723307656991277, \"f2\": 0.6798383475527615, \"f0_5\": 0.8939537080774681, \"p4\": 0.7775046792967892, \"phi\": 0.6353508909726185}, {\"truth_threshold\": 6.12, \"match_probability\": 0.9858258627412329, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7562, \"tn\": 8040, \"fp\": 9, \"fn\": 4462, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6289088489687292, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37109115103127077, \"precision\": 0.9988112534671774, \"recall\": 0.6289088489687292, \"specificity\": 0.9988818486768543, \"npv\": 0.6430971044632858, \"accuracy\": 0.7772629900861854, \"f1\": 0.771829548354172, \"f2\": 0.6792174897156305, \"f0_5\": 0.8936844095679304, \"p4\": 0.7771003706011465, \"phi\": 0.6348102833521968}, {\"truth_threshold\": 6.140000000000001, \"match_probability\": 0.9860182738898777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7558, \"tn\": 8040, \"fp\": 9, \"fn\": 4466, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6285761809713906, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37142381902860944, \"precision\": 0.9988106250825954, \"recall\": 0.6285761809713906, \"specificity\": 0.9988818486768543, \"npv\": 0.6428914121221814, \"accuracy\": 0.7770637174313755, \"f1\": 0.7715787861773263, \"f2\": 0.678906993873848, \"f0_5\": 0.8935496074907784, \"p4\": 0.7768981724559495, \"phi\": 0.6345400664148592}, {\"truth_threshold\": 6.16, \"match_probability\": 0.9862081096362973, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7548, \"tn\": 8040, \"fp\": 9, \"fn\": 4476, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.627744510978044, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3722554890219561, \"precision\": 0.9988090512107979, \"recall\": 0.627744510978044, \"specificity\": 0.9988818486768543, \"npv\": 0.6423777564717162, \"accuracy\": 0.7765655357943506, \"f1\": 0.7709514325111078, \"f2\": 0.6781305589995148, \"f0_5\": 0.8932121556376029, \"p4\": 0.776392548663569, \"phi\": 0.6338647767125407}, {\"truth_threshold\": 6.18, \"match_probability\": 0.9863954034661423, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7539, \"tn\": 8040, \"fp\": 9, \"fn\": 4485, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.626996007984032, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37300399201596807, \"precision\": 0.9988076311605724, \"recall\": 0.626996007984032, \"specificity\": 0.9988818486768543, \"npv\": 0.6419161676646706, \"accuracy\": 0.7761171723210283, \"f1\": 0.7703862660944206, \"f2\": 0.6774315290058227, \"f0_5\": 0.8929079022171689, \"p4\": 0.7759373295035951, \"phi\": 0.6332573236215779}, {\"truth_threshold\": 6.2, \"match_probability\": 0.9865801884562904, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7534, \"tn\": 8040, \"fp\": 9, \"fn\": 4490, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6265801729873586, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37341982701264137, \"precision\": 0.9988068407795306, \"recall\": 0.6265801729873586, \"specificity\": 0.9988818486768543, \"npv\": 0.641660015961692, \"accuracy\": 0.7758680815025158, \"f1\": 0.7700720601011908, \"f2\": 0.6770430812918996, \"f0_5\": 0.8927386482131008, \"p4\": 0.7756843650190162, \"phi\": 0.6329199752151048}, {\"truth_threshold\": 6.22, \"match_probability\": 0.9867624972791117, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7526, \"tn\": 8040, \"fp\": 9, \"fn\": 4498, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6259148369926814, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3740851630073187, \"precision\": 0.9988055739880557, \"recall\": 0.6259148369926814, \"specificity\": 0.9988818486768543, \"npv\": 0.6412505981815282, \"accuracy\": 0.7754695361928959, \"f1\": 0.7695689963699576, \"f2\": 0.6764214197120311, \"f0_5\": 0.8924675078265819, \"p4\": 0.7752795248305465, \"phi\": 0.6323804037238074}, {\"truth_threshold\": 6.24, \"match_probability\": 0.9869423622067105, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7523, \"tn\": 8040, \"fp\": 9, \"fn\": 4501, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6256653359946773, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37433466400532267, \"precision\": 0.9988050982474774, \"recall\": 0.6256653359946773, \"specificity\": 0.9988818486768543, \"npv\": 0.6410972011801291, \"accuracy\": 0.7753200817017885, \"f1\": 0.769380241358151, \"f2\": 0.6761882505213201, \"f0_5\": 0.8923657240463087, \"p4\": 0.775127678857969, \"phi\": 0.6321781232946543}, {\"truth_threshold\": 6.26, \"match_probability\": 0.9871198151151404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7513, \"tn\": 8040, \"fp\": 9, \"fn\": 4511, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6248336660013307, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37516633399866933, \"precision\": 0.9988035097048658, \"recall\": 0.6248336660013307, \"specificity\": 0.9988818486768543, \"npv\": 0.6405864074575731, \"accuracy\": 0.7748219000647636, \"f1\": 0.7687506395170367, \"f2\": 0.6754108382178431, \"f0_5\": 0.8920260258358662, \"p4\": 0.7746214032652978, \"phi\": 0.6315040864974768}, {\"truth_threshold\": 6.28, \"match_probability\": 0.9872948874885967, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7509, \"tn\": 8040, \"fp\": 9, \"fn\": 4515, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6245009980039921, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.375499001996008, \"precision\": 0.9988028731045491, \"recall\": 0.6245009980039921, \"specificity\": 0.9988818486768543, \"npv\": 0.6403823178016727, \"accuracy\": 0.7746226274099537, \"f1\": 0.7684986183604544, \"f2\": 0.6750997950156435, \"f0_5\": 0.8918899657924744, \"p4\": 0.7744188401080532, \"phi\": 0.6312345711883663}, {\"truth_threshold\": 6.3, \"match_probability\": 0.9874676104235824, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7501, \"tn\": 8040, \"fp\": 9, \"fn\": 4523, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6238356620093147, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37616433799068527, \"precision\": 0.9988015978695073, \"recall\": 0.6238356620093147, \"specificity\": 0.9988818486768543, \"npv\": 0.63997452837698, \"accuracy\": 0.7742240821003338, \"f1\": 0.7679942664072898, \"f2\": 0.6744775743624789, \"f0_5\": 0.8916175351844808, \"p4\": 0.7740136225947861, \"phi\": 0.6306957104832461}, {\"truth_threshold\": 6.32, \"match_probability\": 0.9876380146330476, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7491, \"tn\": 8040, \"fp\": 9, \"fn\": 4533, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.623003992015968, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37699600798403193, \"precision\": 0.9988, \"recall\": 0.623003992015968, \"specificity\": 0.9988818486768543, \"npv\": 0.6394655213552851, \"accuracy\": 0.7737259004633089, \"f1\": 0.7673632452366318, \"f2\": 0.6736995467299806, \"f0_5\": 0.8912764134780126, \"p4\": 0.7735069288060176, \"phi\": 0.6300224522453736}, {\"truth_threshold\": 6.34, \"match_probability\": 0.9878061304505031, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7486, \"tn\": 8040, \"fp\": 9, \"fn\": 4538, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6225881570192947, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37741184298070524, \"precision\": 0.9987991994663109, \"recall\": 0.6225881570192947, \"specificity\": 0.9988818486768543, \"npv\": 0.6392113213547463, \"accuracy\": 0.7734768096447965, \"f1\": 0.7670474921870998, \"f2\": 0.6733104279469698, \"f0_5\": 0.89110560898962, \"p4\": 0.7732535098951271, \"phi\": 0.6296859550671791}, {\"truth_threshold\": 6.36, \"match_probability\": 0.9879719878341077, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7479, \"tn\": 8040, \"fp\": 9, \"fn\": 4545, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6220059880239521, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.37799401197604793, \"precision\": 0.9987980769230769, \"recall\": 0.6220059880239521, \"specificity\": 0.9988818486768543, \"npv\": 0.6388557806912991, \"accuracy\": 0.7731280824988791, \"f1\": 0.7666051660516605, \"f2\": 0.6727655440414507, \"f0_5\": 0.8908662092624356, \"p4\": 0.7728986423396853, \"phi\": 0.6292150063516556}, {\"truth_threshold\": 6.38, \"match_probability\": 0.9881356163707273, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7477, \"tn\": 8040, \"fp\": 9, \"fn\": 4547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6218396540252827, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3781603459747172, \"precision\": 0.998797755810847, \"recall\": 0.6218396540252827, \"specificity\": 0.9988818486768543, \"npv\": 0.6387542702788591, \"accuracy\": 0.7730284461714741, \"f1\": 0.7664787288569964, \"f2\": 0.6726098377172466, \"f0_5\": 0.890797750667175, \"p4\": 0.7727972341776131, \"phi\": 0.6290804810874316}, {\"truth_threshold\": 6.4, \"match_probability\": 0.9882970452799678, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7471, \"tn\": 8040, \"fp\": 9, \"fn\": 4553, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6213406520292748, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3786593479707252, \"precision\": 0.9987967914438503, \"recall\": 0.6213406520292748, \"specificity\": 0.9988818486768543, \"npv\": 0.6384499325021837, \"accuracy\": 0.7727295371892592, \"f1\": 0.7660992616899097, \"f2\": 0.6721426515042465, \"f0_5\": 0.8905922181956895, \"p4\": 0.7724929630413148, \"phi\": 0.6286769891546831}, {\"truth_threshold\": 6.42, \"match_probability\": 0.9884563034181787, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7454, \"tn\": 8040, \"fp\": 9, \"fn\": 4570, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6199268130405855, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.3800731869594145, \"precision\": 0.9987940506498727, \"recall\": 0.6199268130405855, \"specificity\": 0.9988818486768543, \"npv\": 0.6375892149088025, \"accuracy\": 0.7718826284063169, \"f1\": 0.765022835736645, \"f2\": 0.670818409258626, \"f0_5\": 0.8900085968096284, \"p4\": 0.7716304792401537, \"phi\": 0.627534442799547}, {\"truth_threshold\": 6.44, \"match_probability\": 0.9886134192824297, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7450, \"tn\": 8040, \"fp\": 9, \"fn\": 4574, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6195941450432468, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.38040585495675316, \"precision\": 0.9987934039415471, \"recall\": 0.6195941450432468, \"specificity\": 0.9988818486768543, \"npv\": 0.6373870302838116, \"accuracy\": 0.771683355751507, \"f1\": 0.7647692860442437, \"f2\": 0.6705067050670507, \"f0_5\": 0.8898709985666508, \"p4\": 0.7714274592333178, \"phi\": 0.6272657540810068}, {\"truth_threshold\": 6.46, \"match_probability\": 0.9887684210144592, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7446, \"tn\": 8040, \"fp\": 9, \"fn\": 4578, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6192614770459082, \"tn_rate\": 0.9988818486768543, \"fp_rate\": 0.0011181513231457323, \"fn_rate\": 0.38073852295409183, \"precision\": 0.9987927565392354, \"recall\": 0.6192614770459082, \"specificity\": 0.9988818486768543, \"npv\": 0.6371849738468854, \"accuracy\": 0.771484083096697, \"f1\": 0.7645156322193131, \"f2\": 0.6701949559863909, \"f0_5\": 0.8897332950960711, \"p4\": 0.771224407559269, \"phi\": 0.6269971206843705}, {\"truth_threshold\": 6.48, \"match_probability\": 0.9889213364045922, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7437, \"tn\": 8041, \"fp\": 8, \"fn\": 4587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6185129740518962, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3814870259481038, \"precision\": 0.9989254533243788, \"recall\": 0.6185129740518962, \"specificity\": 0.9990060877127593, \"npv\": 0.6367595818815331, \"accuracy\": 0.7710855377870771, \"f1\": 0.763983769068776, \"f2\": 0.6695054104175294, \"f0_5\": 0.8895081810353076, \"p4\": 0.7708164275398973, \"phi\": 0.626536213253621}, {\"truth_threshold\": 6.5, \"match_probability\": 0.989072192895632, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7434, \"tn\": 8041, \"fp\": 8, \"fn\": 4590, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6182634730538922, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38173652694610777, \"precision\": 0.998925020155872, \"recall\": 0.6182634730538922, \"specificity\": 0.9990060877127593, \"npv\": 0.6366083445491252, \"accuracy\": 0.7709360832959697, \"f1\": 0.7637932805918011, \"f2\": 0.6692714897907739, \"f0_5\": 0.8894046707503829, \"p4\": 0.7706640597107677, \"phi\": 0.6263348951511529}, {\"truth_threshold\": 6.5200000000000005, \"match_probability\": 0.9892210175867204, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7430, \"tn\": 8041, \"fp\": 8, \"fn\": 4594, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6179308050565535, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38206919494344643, \"precision\": 0.9989244420543156, \"recall\": 0.6179308050565535, \"specificity\": 0.9990060877127593, \"npv\": 0.636406806489909, \"accuracy\": 0.7707368106411597, \"f1\": 0.7635392046038434, \"f2\": 0.6689595563078474, \"f0_5\": 0.889266564534661, \"p4\": 0.7704608745725838, \"phi\": 0.6260665191144804}, {\"truth_threshold\": 6.54, \"match_probability\": 0.9893678372371703, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7427, \"tn\": 8041, \"fp\": 8, \"fn\": 4597, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6176813040585496, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38231869594145046, \"precision\": 0.9989240080699395, \"recall\": 0.6176813040585496, \"specificity\": 0.9990060877127593, \"npv\": 0.6362557366671941, \"accuracy\": 0.7705873561500524, \"f1\": 0.7633485790636724, \"f2\": 0.6687255767049035, \"f0_5\": 0.8891629154295566, \"p4\": 0.7703084646456053, \"phi\": 0.6258652731122799}, {\"truth_threshold\": 6.5600000000000005, \"match_probability\": 0.9895126782702673, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7422, \"tn\": 8041, \"fp\": 8, \"fn\": 4602, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6172654690618763, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38273453093812376, \"precision\": 0.9989232839838492, \"recall\": 0.6172654690618763, \"specificity\": 0.9990060877127593, \"npv\": 0.6360041129478763, \"accuracy\": 0.7703382653315399, \"f1\": 0.7630307391796032, \"f2\": 0.6683355545150019, \"f0_5\": 0.8889900344959755, \"p4\": 0.7700544078491889, \"phi\": 0.6255299316147721}, {\"truth_threshold\": 6.58, \"match_probability\": 0.9896555667770431, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7412, \"tn\": 8041, \"fp\": 8, \"fn\": 4612, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6164337990685296, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38356620093147037, \"precision\": 0.9989218328840971, \"recall\": 0.6164337990685296, \"specificity\": 0.9990060877127593, \"npv\": 0.6355014621038488, \"accuracy\": 0.7698400836945151, \"f1\": 0.7623945690187204, \"f2\": 0.6675552993731537, \"f0_5\": 0.888643775177441, \"p4\": 0.7695461426836423, \"phi\": 0.6248595048799319}, {\"truth_threshold\": 6.6000000000000005, \"match_probability\": 0.9897965285200179, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7397, \"tn\": 8041, \"fp\": 8, \"fn\": 4627, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6151862940785097, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38481370592149033, \"precision\": 0.9989196488858879, \"recall\": 0.6151862940785097, \"specificity\": 0.9990060877127593, \"npv\": 0.6347489737922324, \"accuracy\": 0.7690928112389778, \"f1\": 0.7614390859025169, \"f2\": 0.66638438947046, \"f0_5\": 0.8881231389876093, \"p4\": 0.7687833633723229, \"phi\": 0.6238545027721348}, {\"truth_threshold\": 6.62, \"match_probability\": 0.9899355889369128, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7387, \"tn\": 8041, \"fp\": 8, \"fn\": 4637, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6143546240851631, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.385645375914837, \"precision\": 0.9989181879648411, \"recall\": 0.6143546240851631, \"specificity\": 0.9990060877127593, \"npv\": 0.6342483041489194, \"accuracy\": 0.7685946296019529, \"f1\": 0.7608012770997477, \"f2\": 0.6656034311870394, \"f0_5\": 0.8877752139217383, \"p4\": 0.7682745874028089, \"phi\": 0.6231849246327207}, {\"truth_threshold\": 6.640000000000001, \"match_probability\": 0.9900727731443332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7367, \"tn\": 8041, \"fp\": 8, \"fn\": 4657, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6126912840984697, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38730871590153026, \"precision\": 0.9989152542372881, \"recall\": 0.6126912840984697, \"specificity\": 0.9990060877127593, \"npv\": 0.6332493306032446, \"accuracy\": 0.7675982663279032, \"f1\": 0.7595236867879788, \"f2\": 0.6640406698995872, \"f0_5\": 0.8870773528561796, \"p4\": 0.7672564136701158, \"phi\": 0.621846777831236}, {\"truth_threshold\": 6.66, \"match_probability\": 0.9902081059414205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7365, \"tn\": 8041, \"fp\": 8, \"fn\": 4659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6125249500998003, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3874750499001996, \"precision\": 0.9989149599891496, \"recall\": 0.6125249500998003, \"specificity\": 0.9990060877127593, \"npv\": 0.6331496062992126, \"accuracy\": 0.7674986300004982, \"f1\": 0.7593957828530185, \"f2\": 0.6638843317889271, \"f0_5\": 0.8870074188264765, \"p4\": 0.7671545503654223, \"phi\": 0.6217130368480844}, {\"truth_threshold\": 6.68, \"match_probability\": 0.9903416118134748, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7359, \"tn\": 8041, \"fp\": 8, \"fn\": 4665, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6120259481037924, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3879740518962076, \"precision\": 0.9989140762861409, \"recall\": 0.6120259481037924, \"specificity\": 0.9990060877127593, \"npv\": 0.6328506217535023, \"accuracy\": 0.7671997210182833, \"f1\": 0.7590119127430252, \"f2\": 0.663415249806177, \"f0_5\": 0.8867974549310711, \"p4\": 0.7668489100252474, \"phi\": 0.6213118939793382}, {\"truth_threshold\": 6.7, \"match_probability\": 0.9904733149355459, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7356, \"tn\": 8041, \"fp\": 8, \"fn\": 4668, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6117764471057884, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38822355289421157, \"precision\": 0.9989136338946225, \"recall\": 0.6117764471057884, \"specificity\": 0.9990060877127593, \"npv\": 0.6327012353450311, \"accuracy\": 0.7670502665271758, \"f1\": 0.758819888590881, \"f2\": 0.6631806707536964, \"f0_5\": 0.8866923818707811, \"p4\": 0.7666960614197864, \"phi\": 0.6211113675205769}, {\"truth_threshold\": 6.72, \"match_probability\": 0.9906032391759949, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7352, \"tn\": 8041, \"fp\": 8, \"fn\": 4672, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6114437791084497, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38855622089155023, \"precision\": 0.9989130434782608, \"recall\": 0.6114437791084497, \"specificity\": 0.9990060877127593, \"npv\": 0.6325021631400928, \"accuracy\": 0.7668509938723659, \"f1\": 0.7585637639290136, \"f2\": 0.6628678592036931, \"f0_5\": 0.8865521898514374, \"p4\": 0.7664922337038838, \"phi\": 0.620844045464769}, {\"truth_threshold\": 6.74, \"match_probability\": 0.9907314081000241, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7339, \"tn\": 8041, \"fp\": 8, \"fn\": 4685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6103626081170991, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.38963739188290086, \"precision\": 0.9989111201851095, \"recall\": 0.6103626081170991, \"specificity\": 0.9990060877127593, \"npv\": 0.6318560427471318, \"accuracy\": 0.7662033577442335, \"f1\": 0.7577306282587373, \"f2\": 0.6618509099435457, \"f0_5\": 0.8860958176373998, \"p4\": 0.7658295591379547, \"phi\": 0.619975615204598}, {\"truth_threshold\": 6.76, \"match_probability\": 0.9908578449731781, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7329, \"tn\": 8041, \"fp\": 8, \"fn\": 4695, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6095309381237525, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3904690618762475, \"precision\": 0.9989096360910454, \"recall\": 0.6095309381237525, \"specificity\": 0.9990060877127593, \"npv\": 0.6313599246231156, \"accuracy\": 0.7657051761072087, \"f1\": 0.757088993337121, \"f2\": 0.6610683167066549, \"f0_5\": 0.8857439814367205, \"p4\": 0.7653195639462649, \"phi\": 0.6193079718139275}, {\"truth_threshold\": 6.78, \"match_probability\": 0.9909825727648117, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7323, \"tn\": 8041, \"fp\": 8, \"fn\": 4701, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6090319361277445, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.39096806387225547, \"precision\": 0.9989087436911744, \"recall\": 0.6090319361277445, \"specificity\": 0.9990060877127593, \"npv\": 0.6310626275309998, \"accuracy\": 0.7654062671249938, \"f1\": 0.7567036941358822, \"f2\": 0.6605986252187562, \"f0_5\": 0.8855325529650769, \"p4\": 0.7650134636825116, \"phi\": 0.6189075436880886}, {\"truth_threshold\": 6.8, \"match_probability\": 0.9911056141515298, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7318, \"tn\": 8041, \"fp\": 8, \"fn\": 4706, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6086161011310712, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3913838988689288, \"precision\": 0.9989079989079989, \"recall\": 0.6086161011310712, \"specificity\": 0.9990060877127593, \"npv\": 0.6308150937475484, \"accuracy\": 0.7651571763064814, \"f1\": 0.7563824289405685, \"f2\": 0.660207137959655, \"f0_5\": 0.8853561749903214, \"p4\": 0.7647583207556182, \"phi\": 0.6185739437810729}, {\"truth_threshold\": 6.82, \"match_probability\": 0.9912269915205945, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7316, \"tn\": 8041, \"fp\": 8, \"fn\": 4708, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6084497671324018, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.39155023286759816, \"precision\": 0.9989077007099946, \"recall\": 0.6084497671324018, \"specificity\": 0.9990060877127593, \"npv\": 0.630716134598792, \"accuracy\": 0.7650575399790763, \"f1\": 0.7562538763696506, \"f2\": 0.6600505232767954, \"f0_5\": 0.8852855759922555, \"p4\": 0.7646562484276267, \"phi\": 0.6184405267351001}, {\"truth_threshold\": 6.84, \"match_probability\": 0.9913467269733026, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7310, \"tn\": 8041, \"fp\": 8, \"fn\": 4714, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6079507651363939, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3920492348636061, \"precision\": 0.9989068051380159, \"recall\": 0.6079507651363939, \"specificity\": 0.9990060877127593, \"npv\": 0.6304194433555469, \"accuracy\": 0.7647586309968615, \"f1\": 0.7558680591459002, \"f2\": 0.6595806113978417, \"f0_5\": 0.8850736148779543, \"p4\": 0.7643499793251933, \"phi\": 0.6180403540231147}, {\"truth_threshold\": 6.86, \"match_probability\": 0.9914648423283329, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7304, \"tn\": 8041, \"fp\": 8, \"fn\": 4720, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6074517631403858, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3925482368596141, \"precision\": 0.9989059080962801, \"recall\": 0.6074517631403858, \"specificity\": 0.9990060877127593, \"npv\": 0.6301230311104146, \"accuracy\": 0.7644597220146465, \"f1\": 0.7554820024824163, \"f2\": 0.6591105977476177, \"f0_5\": 0.8848614072494669, \"p4\": 0.7640436318010839, \"phi\": 0.6176402987141673}, {\"truth_threshold\": 6.88, \"match_probability\": 0.9915813591250612, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7287, \"tn\": 8041, \"fp\": 8, \"fn\": 4737, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6060379241516967, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.3939620758483034, \"precision\": 0.9989033584647018, \"recall\": 0.6060379241516967, \"specificity\": 0.9990060877127593, \"npv\": 0.6292847080920332, \"accuracy\": 0.7636128132317043, \"f1\": 0.7543868730265542, \"f2\": 0.6577783394414255, \"f0_5\": 0.884258809824289, \"p4\": 0.7631752185243283, \"phi\": 0.6165074435843113}, {\"truth_threshold\": 6.9, \"match_probability\": 0.9916962986268459, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7274, \"tn\": 8041, \"fp\": 8, \"fn\": 4750, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.604956753160346, \"tn_rate\": 0.9990060877127593, \"fp_rate\": 0.000993912287240651, \"fn_rate\": 0.395043246839654, \"precision\": 0.9989014007140895, \"recall\": 0.604956753160346, \"specificity\": 0.9990060877127593, \"npv\": 0.6286451411148464, \"accuracy\": 0.7629651771035719, \"f1\": 0.7535481197555164, \"f2\": 0.6567590017696558, \"f0_5\": 0.8837966562986003, \"p4\": 0.7625107068348852, \"phi\": 0.6156417726105801}, {\"truth_threshold\": 6.92, \"match_probability\": 0.9918096818242835, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7268, \"tn\": 8043, \"fp\": 6, \"fn\": 4756, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.604457751164338, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.395542248835662, \"precision\": 0.9991751443497388, \"recall\": 0.604457751164338, \"specificity\": 0.9992545657845695, \"npv\": 0.6284084694116728, \"accuracy\": 0.762765904448762, \"f1\": 0.7532386775831692, \"f2\": 0.6563120823550659, \"f0_5\": 0.8837548638132295, \"p4\": 0.7623013739473647, \"phi\": 0.6155322554855026}, {\"truth_threshold\": 6.94, \"match_probability\": 0.9919215294384318, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7264, \"tn\": 8043, \"fp\": 6, \"fn\": 4760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6041250831669993, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.3958749168330007, \"precision\": 0.9991746905089408, \"recall\": 0.6041250831669993, \"specificity\": 0.9992545657845695, \"npv\": 0.6282121377802078, \"accuracy\": 0.7625666317939521, \"f1\": 0.7529802010987872, \"f2\": 0.6559982660838782, \"f0_5\": 0.8836123005060335, \"p4\": 0.762096767013999, \"phi\": 0.6152661572116125}, {\"truth_threshold\": 6.96, \"match_probability\": 0.9920318619240045, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7260, \"tn\": 8043, \"fp\": 6, \"fn\": 4764, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6037924151696606, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.3962075848303393, \"precision\": 0.9991742361684558, \"recall\": 0.6037924151696606, \"specificity\": 0.9992545657845695, \"npv\": 0.6280159287889435, \"accuracy\": 0.7623673591391421, \"f1\": 0.7527216174183515, \"f2\": 0.6556844044651566, \"f0_5\": 0.8834696261682243, \"p4\": 0.76189212413472, \"phi\": 0.6150001101314904}, {\"truth_threshold\": 6.98, \"match_probability\": 0.9921406994725337, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7258, \"tn\": 8043, \"fp\": 6, \"fn\": 4766, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6036260811709914, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.39637391882900863, \"precision\": 0.9991740088105727, \"recall\": 0.6036260811709914, \"specificity\": 0.9992545657845695, \"npv\": 0.6279178702474822, \"accuracy\": 0.7622677228117372, \"f1\": 0.7525922853587723, \"f2\": 0.6555274566473989, \"f0_5\": 0.883398247322298, \"p4\": 0.7617897891858205, \"phi\": 0.6148671057611542}, {\"truth_threshold\": 7.0, \"match_probability\": 0.9922480620155039, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7249, \"tn\": 8043, \"fp\": 6, \"fn\": 4775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6028775781769794, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.3971224218230206, \"precision\": 0.9991729841488629, \"recall\": 0.6028775781769794, \"specificity\": 0.9992545657845695, \"npv\": 0.6274769854891559, \"accuracy\": 0.7618193593384148, \"f1\": 0.7520099590227709, \"f2\": 0.6548210511101877, \"f0_5\": 0.8830766981775655, \"p4\": 0.7613291700981973, \"phi\": 0.6142687438992641}, {\"truth_threshold\": 7.0200000000000005, \"match_probability\": 0.9923539692274538, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7241, \"tn\": 8043, \"fp\": 6, \"fn\": 4783, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6022122421823021, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.39778775781769793, \"precision\": 0.9991720712018767, \"recall\": 0.6022122421823021, \"specificity\": 0.9992545657845695, \"npv\": 0.6270856073600499, \"accuracy\": 0.7614208140287949, \"f1\": 0.7514918789891547, \"f2\": 0.6541929421968451, \"f0_5\": 0.882790402808934, \"p4\": 0.7609195766627803, \"phi\": 0.6137370828696804}, {\"truth_threshold\": 7.04, \"match_probability\": 0.9924584405290495, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7234, \"tn\": 8043, \"fp\": 6, \"fn\": 4790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6016300731869594, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.39836992681304056, \"precision\": 0.9991712707182321, \"recall\": 0.6016300731869594, \"specificity\": 0.9992545657845695, \"npv\": 0.6267435517805657, \"accuracy\": 0.7610720868828775, \"f1\": 0.7510382059800664, \"f2\": 0.6536431979181726, \"f0_5\": 0.8825395276205349, \"p4\": 0.7605610626954693, \"phi\": 0.6132720457872826}, {\"truth_threshold\": 7.0600000000000005, \"match_probability\": 0.9925614950901266, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7224, \"tn\": 8043, \"fp\": 6, \"fn\": 4800, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.6007984031936128, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.3992015968063872, \"precision\": 0.9991701244813278, \"recall\": 0.6007984031936128, \"specificity\": 0.9992545657845695, \"npv\": 0.6262555477692128, \"accuracy\": 0.7605739052458527, \"f1\": 0.7503895294484263, \"f2\": 0.6528576076347468, \"f0_5\": 0.8821805392731535, \"p4\": 0.7600487050112182, \"phi\": 0.6126079753881045}, {\"truth_threshold\": 7.08, \"match_probability\": 0.9926631518327027, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7212, \"tn\": 8043, \"fp\": 6, \"fn\": 4812, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5998003992015968, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4001996007984032, \"precision\": 0.999168744804655, \"recall\": 0.5998003992015968, \"specificity\": 0.9992545657845695, \"npv\": 0.6256709451575263, \"accuracy\": 0.7599760872814229, \"f1\": 0.7496102276270658, \"f2\": 0.651914524351882, \"f0_5\": 0.8817488262910798, \"p4\": 0.7594335712551499, \"phi\": 0.6118115057697604}, {\"truth_threshold\": 7.1000000000000005, \"match_probability\": 0.9927634294339601, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7201, \"tn\": 8043, \"fp\": 6, \"fn\": 4823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5988855622089155, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4011144377910845, \"precision\": 0.9991674760649368, \"recall\": 0.5988855622089155, \"specificity\": 0.9992545657845695, \"npv\": 0.6251360174102285, \"accuracy\": 0.7594280874806955, \"f1\": 0.7488950132598409, \"f2\": 0.6510496718080393, \"f0_5\": 0.8813521981787917, \"p4\": 0.758869404712168, \"phi\": 0.6110818042570202}, {\"truth_threshold\": 7.12, \"match_probability\": 0.9928623463291987, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7199, \"tn\": 8043, \"fp\": 6, \"fn\": 4825, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5987192282102461, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4012807717897538, \"precision\": 0.9991672449687717, \"recall\": 0.5987192282102461, \"specificity\": 0.9992545657845695, \"npv\": 0.6250388560770904, \"accuracy\": 0.7593284511532905, \"f1\": 0.748764886369546, \"f2\": 0.6508923889260592, \"f0_5\": 0.8812799921653119, \"p4\": 0.7587667986075104, \"phi\": 0.6109491717623533}, {\"truth_threshold\": 7.140000000000001, \"match_probability\": 0.9929599207147589, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7197, \"tn\": 8043, \"fp\": 6, \"fn\": 4827, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5985528942115769, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40144710578842313, \"precision\": 0.9991670137442732, \"recall\": 0.5985528942115769, \"specificity\": 0.9992545657845695, \"npv\": 0.624941724941725, \"accuracy\": 0.7592288148258856, \"f1\": 0.7486347324075519, \"f2\": 0.650735094667173, \"f0_5\": 0.8812077578607111, \"p4\": 0.7586641831282086, \"phi\": 0.6108165517037625}, {\"truth_threshold\": 7.16, \"match_probability\": 0.9930561705509157, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7179, \"tn\": 8043, \"fp\": 6, \"fn\": 4845, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5970558882235529, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4029441117764471, \"precision\": 0.9991649269311065, \"recall\": 0.5970558882235529, \"specificity\": 0.9992545657845695, \"npv\": 0.6240689013035382, \"accuracy\": 0.7583320878792408, \"f1\": 0.7474621271279088, \"f2\": 0.6493189341726814, \"f0_5\": 0.8805563732705328, \"p4\": 0.7577402199591995, \"phi\": 0.6096235289650663}, {\"truth_threshold\": 7.18, \"match_probability\": 0.9931511135647422, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7167, \"tn\": 8043, \"fp\": 6, \"fn\": 4857, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5960578842315369, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40394211576846306, \"precision\": 0.999163529903806, \"recall\": 0.5960578842315369, \"specificity\": 0.9992545657845695, \"npv\": 0.6234883720930232, \"accuracy\": 0.757734269914811, \"f1\": 0.7466791686200969, \"f2\": 0.6483743147153015, \"f0_5\": 0.8801208370173887, \"p4\": 0.7571238177455913, \"phi\": 0.6088287355939443}, {\"truth_threshold\": 7.2, \"match_probability\": 0.9932447672529455, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7164, \"tn\": 8043, \"fp\": 6, \"fn\": 4860, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5958083832335329, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4041916167664671, \"precision\": 0.999163179916318, \"recall\": 0.5958083832335329, \"specificity\": 0.9992545657845695, \"npv\": 0.6233434085096489, \"accuracy\": 0.7575848154237035, \"f1\": 0.7464832760237574, \"f2\": 0.6481380957550754, \"f0_5\": 0.8800117924528302, \"p4\": 0.7569696634696813, \"phi\": 0.6086301062977036}, {\"truth_threshold\": 7.22, \"match_probability\": 0.9933371488846718, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7160, \"tn\": 8043, \"fp\": 6, \"fn\": 4864, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5954757152361942, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4045242847638057, \"precision\": 0.999162712810494, \"recall\": 0.5954757152361942, \"specificity\": 0.9992545657845695, \"npv\": 0.6231502285581467, \"accuracy\": 0.7573855427688936, \"f1\": 0.7462219906201146, \"f2\": 0.6478230972458471, \"f0_5\": 0.8798662996460873, \"p4\": 0.7567640908724603, \"phi\": 0.6083653100753114}, {\"truth_threshold\": 7.24, \"match_probability\": 0.993428275504284, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7159, \"tn\": 8043, \"fp\": 6, \"fn\": 4865, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5953925482368596, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4046074517631404, \"precision\": 0.9991625959525471, \"recall\": 0.5953925482368596, \"specificity\": 0.9992545657845695, \"npv\": 0.6231019522776573, \"accuracy\": 0.757335724605191, \"f1\": 0.7461566522486841, \"f2\": 0.6477443404932954, \"f0_5\": 0.879829908563563, \"p4\": 0.7567126917196269, \"phi\": 0.6082991186603343}, {\"truth_threshold\": 7.26, \"match_probability\": 0.9935181639341092, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7149, \"tn\": 8043, \"fp\": 6, \"fn\": 4875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.594560878243513, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40543912175648705, \"precision\": 0.9991614255765199, \"recall\": 0.594560878243513, \"specificity\": 0.9992545657845695, \"npv\": 0.6226196005573619, \"accuracy\": 0.7568375429681662, \"f1\": 0.7455028937900829, \"f2\": 0.6469566161698431, \"f0_5\": 0.8794656037791556, \"p4\": 0.7561985676925362, \"phi\": 0.6076373722228807}, {\"truth_threshold\": 7.28, \"match_probability\": 0.9936068307771581, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7147, \"tn\": 8043, \"fp\": 6, \"fn\": 4877, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5943945442448436, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40560545575515633, \"precision\": 0.9991611911086258, \"recall\": 0.5943945442448436, \"specificity\": 0.9992545657845695, \"npv\": 0.6225232198142415, \"accuracy\": 0.7567379066407612, \"f1\": 0.7453720602805444, \"f2\": 0.6467990370866441, \"f0_5\": 0.8793926567575548, \"p4\": 0.7560957138985467, \"phi\": 0.6075050594550798}, {\"truth_threshold\": 7.3, \"match_probability\": 0.9936942924198163, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7144, \"tn\": 8043, \"fp\": 6, \"fn\": 4880, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5941450432468397, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40585495675316036, \"precision\": 0.9991608391608392, \"recall\": 0.5941450432468397, \"specificity\": 0.9992545657845695, \"npv\": 0.6223787046351467, \"accuracy\": 0.7565884521496538, \"f1\": 0.745175758840096, \"f2\": 0.6465626470694711, \"f0_5\": 0.8792831823552579, \"p4\": 0.7559414150321117, \"phi\": 0.6073066130762108}, {\"truth_threshold\": 7.32, \"match_probability\": 0.9937805650345067, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7132, \"tn\": 8043, \"fp\": 6, \"fn\": 4892, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5931470392548237, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4068529607451763, \"precision\": 0.9991594284113197, \"recall\": 0.5931470392548237, \"specificity\": 0.9992545657845695, \"npv\": 0.6218013142636258, \"accuracy\": 0.7559906341852239, \"f1\": 0.7443899384197892, \"f2\": 0.6456168302132744, \"f0_5\": 0.8788446372239748, \"p4\": 0.7553240006758359, \"phi\": 0.6065131001281765}, {\"truth_threshold\": 7.34, \"match_probability\": 0.9938656645823235, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7125, \"tn\": 8043, \"fp\": 6, \"fn\": 4899, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.592564870259481, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.407435129740519, \"precision\": 0.9991586032814472, \"recall\": 0.592564870259481, \"specificity\": 0.9992545657845695, \"npv\": 0.6214649976819657, \"accuracy\": 0.7556419070393066, \"f1\": 0.7439310884886453, \"f2\": 0.6450649139008093, \"f0_5\": 0.8785883397454868, \"p4\": 0.7549636798132325, \"phi\": 0.6060504182968567}, {\"truth_threshold\": 7.36, \"match_probability\": 0.9939496068156388, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7110, \"tn\": 8043, \"fp\": 6, \"fn\": 4914, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5913173652694611, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4086826347305389, \"precision\": 0.9991568296795953, \"recall\": 0.5913173652694611, \"specificity\": 0.9992545657845695, \"npv\": 0.6207455429497569, \"accuracy\": 0.7548946345837693, \"f1\": 0.7429467084639498, \"f2\": 0.6438817648337318, \"f0_5\": 0.8780379371665679, \"p4\": 0.7541911576188622, \"phi\": 0.6050594526727864}, {\"truth_threshold\": 7.38, \"match_probability\": 0.994032407280681, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7106, \"tn\": 8043, \"fp\": 6, \"fn\": 4918, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5909846972721224, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.40901530272787756, \"precision\": 0.999156355455568, \"recall\": 0.5909846972721224, \"specificity\": 0.9992545657845695, \"npv\": 0.620553969601111, \"accuracy\": 0.7546953619289593, \"f1\": 0.7426839464882943, \"f2\": 0.6435661498333575, \"f0_5\": 0.8778908875271793, \"p4\": 0.7539850576720446, \"phi\": 0.6047953088195024}, {\"truth_threshold\": 7.4, \"match_probability\": 0.9941140813200855, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7098, \"tn\": 8043, \"fp\": 6, \"fn\": 4926, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5903193612774451, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4096806387225549, \"precision\": 0.9991554054054054, \"recall\": 0.5903193612774451, \"specificity\": 0.9992545657845695, \"npv\": 0.6201711774230858, \"accuracy\": 0.7542968166193394, \"f1\": 0.7421580928481807, \"f2\": 0.6429347826086956, \"f0_5\": 0.8775964391691394, \"p4\": 0.7535727383329356, \"phi\": 0.6042671640690827}, {\"truth_threshold\": 7.42, \"match_probability\": 0.9941946440754179, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7091, \"tn\": 8043, \"fp\": 6, \"fn\": 4933, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5897371922821024, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4102628077178975, \"precision\": 0.999154572354516, \"recall\": 0.5897371922821024, \"specificity\": 0.9992545657845695, \"npv\": 0.6198366214549939, \"accuracy\": 0.753948089473422, \"f1\": 0.7416976099576382, \"f2\": 0.642382186146794, \"f0_5\": 0.8773384143323765, \"p4\": 0.7532118277482892, \"phi\": 0.6038051933112626}, {\"truth_threshold\": 7.44, \"match_probability\": 0.9942741104896703, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7089, \"tn\": 8043, \"fp\": 6, \"fn\": 4935, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5895708582834331, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.41042914171656686, \"precision\": 0.999154334038055, \"recall\": 0.5895708582834331, \"specificity\": 0.9992545657845695, \"npv\": 0.6197411003236246, \"accuracy\": 0.753848453146017, \"f1\": 0.7415659814843872, \"f2\": 0.6422242756971245, \"f0_5\": 0.8772646272646273, \"p4\": 0.753108687873496, \"phi\": 0.6036732283212223}, {\"truth_threshold\": 7.46, \"match_probability\": 0.9943524953097296, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7073, \"tn\": 8043, \"fp\": 6, \"fn\": 4951, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5882401862940785, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4117598137059215, \"precision\": 0.9991524226585676, \"recall\": 0.5882401862940785, \"specificity\": 0.9992545657845695, \"npv\": 0.6189779898414652, \"accuracy\": 0.7530513625267773, \"f1\": 0.7405119614720201, \"f2\": 0.6409605799728137, \"f0_5\": 0.8766732771442737, \"p4\": 0.7522832059532105, \"phi\": 0.6026179332246754}, {\"truth_threshold\": 7.48, \"match_probability\": 0.9944298130888198, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7064, \"tn\": 8043, \"fp\": 6, \"fn\": 4960, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5874916833000665, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4125083166999335, \"precision\": 0.9991513437057992, \"recall\": 0.5874916833000665, \"specificity\": 0.9992545657845695, \"npv\": 0.6185495654848882, \"accuracy\": 0.7526029990534548, \"f1\": 0.7399182989420761, \"f2\": 0.6402494289961208, \"f0_5\": 0.8763398173878523, \"p4\": 0.7518185872461749, \"phi\": 0.6020246602289686}, {\"truth_threshold\": 7.5, \"match_probability\": 0.994506078188917, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7059, \"tn\": 8043, \"fp\": 6, \"fn\": 4965, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5870758483033932, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4129241516966068, \"precision\": 0.9991507430997877, \"recall\": 0.5870758483033932, \"specificity\": 0.9992545657845695, \"npv\": 0.6183118081180812, \"accuracy\": 0.7523539082349424, \"f1\": 0.7395882445387396, \"f2\": 0.6398542448469027, \"f0_5\": 0.8761543044384867, \"p4\": 0.751560376483511, \"phi\": 0.6016951664583844}, {\"truth_threshold\": 7.5200000000000005, \"match_probability\": 0.9945813047831374, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7056, \"tn\": 8043, \"fp\": 6, \"fn\": 4968, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5868263473053892, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.41317365269461076, \"precision\": 0.9991503823279524, \"recall\": 0.5868263473053892, \"specificity\": 0.9992545657845695, \"npv\": 0.6181692414111136, \"accuracy\": 0.752204453743835, \"f1\": 0.7393901288902861, \"f2\": 0.6396170999673665, \"f0_5\": 0.8760429082240763, \"p4\": 0.7514054193152305, \"phi\": 0.6014975051896239}, {\"truth_threshold\": 7.54, \"match_probability\": 0.9946555068581004, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7054, \"tn\": 8043, \"fp\": 6, \"fn\": 4970, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5866600133067199, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4133399866932801, \"precision\": 0.9991501416430595, \"recall\": 0.5866600133067199, \"specificity\": 0.9992545657845695, \"npv\": 0.6180742334588488, \"accuracy\": 0.75210481741643, \"f1\": 0.7392580171871725, \"f2\": 0.6394589890492421, \"f0_5\": 0.8759686071925293, \"p4\": 0.7513021017138225, \"phi\": 0.6013657455681349}, {\"truth_threshold\": 7.5600000000000005, \"match_probability\": 0.9947286982162634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7048, \"tn\": 8043, \"fp\": 6, \"fn\": 4976, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5861610113107119, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4138389886892881, \"precision\": 0.9991494187694925, \"recall\": 0.5861610113107119, \"specificity\": 0.9992545657845695, \"npv\": 0.6177893847453721, \"accuracy\": 0.7518059084342151, \"f1\": 0.738861515882168, \"f2\": 0.6389845874886673, \"f0_5\": 0.8757455268389662, \"p4\": 0.750992087221551, \"phi\": 0.6009705364592568}, {\"truth_threshold\": 7.58, \"match_probability\": 0.9948008924782327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7046, \"tn\": 8043, \"fp\": 6, \"fn\": 4978, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5859946773120426, \"tn_rate\": 0.9992545657845695, \"fp_rate\": 0.0007454342154304882, \"fn_rate\": 0.4140053226879574, \"precision\": 0.999149177538287, \"recall\": 0.5859946773120426, \"specificity\": 0.9992545657845695, \"npv\": 0.6176944935104831, \"accuracy\": 0.7517062721068102, \"f1\": 0.7387292933529042, \"f2\": 0.6388264306955828, \"f0_5\": 0.8756711075760588, \"p4\": 0.7508887284523696, \"phi\": 0.600838823304743}, {\"truth_threshold\": 7.6000000000000005, \"match_probability\": 0.9948721030850469, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7044, \"tn\": 8044, \"fp\": 5, \"fn\": 4980, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5858283433133733, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.41417165668662675, \"precision\": 0.9992906795290112, \"recall\": 0.5858283433133733, \"specificity\": 0.9993788048204746, \"npv\": 0.6176289926289926, \"accuracy\": 0.7516564539431076, \"f1\": 0.738635767839354, \"f2\": 0.6386798440475111, \"f0_5\": 0.8756837394331178, \"p4\": 0.7508337468122459, \"phi\": 0.6008542268897289}, {\"truth_threshold\": 7.62, \"match_probability\": 0.9949423433004362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7027, \"tn\": 8044, \"fp\": 5, \"fn\": 4997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.584414504324684, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.41558549567531605, \"precision\": 0.9992889647326507, \"recall\": 0.584414504324684, \"specificity\": 0.9993788048204746, \"npv\": 0.6168238632006748, \"accuracy\": 0.7508095451601654, \"f1\": 0.737510495382032, \"f2\": 0.6373349296183428, \"f0_5\": 0.8750498107192668, \"p4\": 0.7499546628871465, \"phi\": 0.5997353971761028}, {\"truth_threshold\": 7.640000000000001, \"match_probability\": 0.9950116262130546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7013, \"tn\": 8044, \"fp\": 5, \"fn\": 5011, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5832501663339986, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4167498336660013, \"precision\": 0.9992875463094899, \"recall\": 0.5832501663339986, \"specificity\": 0.9993788048204746, \"npv\": 0.6161623898889315, \"accuracy\": 0.7501120908683306, \"f1\": 0.7365822917760739, \"f2\": 0.636226730050441, \"f0_5\": 0.8745261372705507, \"p4\": 0.7492301450114585, \"phi\": 0.5988146316886157}, {\"truth_threshold\": 7.66, \"match_probability\": 0.9950799647386886, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7009, \"tn\": 8044, \"fp\": 5, \"fn\": 5015, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5829174983366601, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.41708250166334, \"precision\": 0.9992871400057028, \"recall\": 0.5829174983366601, \"specificity\": 0.9993788048204746, \"npv\": 0.6159736580136305, \"accuracy\": 0.7499128182135206, \"f1\": 0.7363168400042022, \"f2\": 0.6359099981854472, \"f0_5\": 0.87437624750499, \"p4\": 0.7490230452631925, \"phi\": 0.5985516587264347}, {\"truth_threshold\": 7.68, \"match_probability\": 0.9951473716224397, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7002, \"tn\": 8044, \"fp\": 5, \"fn\": 5022, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5823353293413174, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4176646706586826, \"precision\": 0.9992864278578564, \"recall\": 0.5823353293413174, \"specificity\": 0.9993788048204746, \"npv\": 0.6156436552885352, \"accuracy\": 0.7495640910676032, \"f1\": 0.7358520308969576, \"f2\": 0.635355606772771, \"f0_5\": 0.8741136522520723, \"p4\": 0.7486605189732289, \"phi\": 0.5980915656381904}, {\"truth_threshold\": 7.7, \"match_probability\": 0.9952138594408825, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6991, \"tn\": 8044, \"fp\": 5, \"fn\": 5033, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.581420492348636, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4185795076513639, \"precision\": 0.9992853058890795, \"recall\": 0.581420492348636, \"specificity\": 0.9993788048204746, \"npv\": 0.615125793377686, \"accuracy\": 0.7490160912668758, \"f1\": 0.7351209253417456, \"f2\": 0.6344841356276774, \"f0_5\": 0.8737002599480104, \"p4\": 0.7480905720362411, \"phi\": 0.5973688430333792}, {\"truth_threshold\": 7.72, \"match_probability\": 0.9952794406041985, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6985, \"tn\": 8044, \"fp\": 5, \"fn\": 5039, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5809214903526281, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4190785096473719, \"precision\": 0.9992846924177397, \"recall\": 0.5809214903526281, \"specificity\": 0.9993788048204746, \"npv\": 0.6148436902851028, \"accuracy\": 0.748717182284661, \"f1\": 0.7347217839486694, \"f2\": 0.6340086410340195, \"f0_5\": 0.8734743897559024, \"p4\": 0.7477795558623296, \"phi\": 0.596974774807646}, {\"truth_threshold\": 7.74, \"match_probability\": 0.9953441273582849, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6979, \"tn\": 8044, \"fp\": 5, \"fn\": 5045, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5804224883566201, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4195775116433799, \"precision\": 0.9992840778923253, \"recall\": 0.5804224883566201, \"specificity\": 0.9993788048204746, \"npv\": 0.6145618458247384, \"accuracy\": 0.748418273302446, \"f1\": 0.7343223905723906, \"f2\": 0.6335330428467684, \"f0_5\": 0.8732482482482482, \"p4\": 0.7474684432209584, \"phi\": 0.596580807923488}, {\"truth_threshold\": 7.76, \"match_probability\": 0.9954079317868398, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6971, \"tn\": 8044, \"fp\": 5, \"fn\": 5053, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5797571523619428, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4202428476380572, \"precision\": 0.9992832568807339, \"recall\": 0.5797571523619428, \"specificity\": 0.9993788048204746, \"npv\": 0.6141864549133389, \"accuracy\": 0.7480197279928262, \"f1\": 0.7337894736842105, \"f2\": 0.632898750726322, \"f0_5\": 0.8729463033460229, \"p4\": 0.7470534756965589, \"phi\": 0.5960556758745631}, {\"truth_threshold\": 7.78, \"match_probability\": 0.9954708658134229, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6967, \"tn\": 8044, \"fp\": 5, \"fn\": 5057, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5794244843646041, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42057551563539586, \"precision\": 0.9992828456683879, \"recall\": 0.5794244843646041, \"specificity\": 0.9993788048204746, \"npv\": 0.6139989313792841, \"accuracy\": 0.7478204553380162, \"f1\": 0.73352284691514, \"f2\": 0.6325815355560398, \"f0_5\": 0.8727951493285228, \"p4\": 0.746845927126517, \"phi\": 0.5957931769938815}, {\"truth_threshold\": 7.8, \"match_probability\": 0.9955329412034929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6956, \"tn\": 8044, \"fp\": 5, \"fn\": 5068, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5785096473719228, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42149035262807716, \"precision\": 0.999281712397644, \"recall\": 0.5785096473719228, \"specificity\": 0.9993788048204746, \"npv\": 0.6134838316046369, \"accuracy\": 0.7472724555372889, \"f1\": 0.7327890439820911, \"f2\": 0.6317089561726937, \"f0_5\": 0.8723788502056787, \"p4\": 0.746274944745655, \"phi\": 0.5950715350109688}, {\"truth_threshold\": 7.82, \"match_probability\": 0.9955941695664209, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6949, \"tn\": 8044, \"fp\": 5, \"fn\": 5075, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5779274783765802, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42207252162341985, \"precision\": 0.9992809893586425, \"recall\": 0.5779274783765802, \"specificity\": 0.9993788048204746, \"npv\": 0.6131564905861727, \"accuracy\": 0.7469237283913714, \"f1\": 0.7323216355780378, \"f2\": 0.6311534968210718, \"f0_5\": 0.8721134538152611, \"p4\": 0.745911420650534, \"phi\": 0.5946124832506564}, {\"truth_threshold\": 7.84, \"match_probability\": 0.9956545623574807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6948, \"tn\": 8044, \"fp\": 5, \"fn\": 5076, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5778443113772455, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4221556886227545, \"precision\": 0.9992808859485114, \"recall\": 0.5778443113772455, \"specificity\": 0.9993788048204746, \"npv\": 0.613109756097561, \"accuracy\": 0.746873910227669, \"f1\": 0.7322548348000211, \"f2\": 0.631074133953387, \"f0_5\": 0.8720755095893162, \"p4\": 0.7458594776954972, \"phi\": 0.5945469155013391}, {\"truth_threshold\": 7.86, \"match_probability\": 0.995714130879816, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6943, \"tn\": 8044, \"fp\": 5, \"fn\": 5081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5774284763805722, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4225715236194278, \"precision\": 0.9992803684513529, \"recall\": 0.5774284763805722, \"specificity\": 0.9993788048204746, \"npv\": 0.6128761904761905, \"accuracy\": 0.7466248194091566, \"f1\": 0.731920725279359, \"f2\": 0.6306772763607296, \"f0_5\": 0.8718856741008639, \"p4\": 0.7455997217826403, \"phi\": 0.5942191181915848}, {\"truth_threshold\": 7.88, \"match_probability\": 0.9957728862863844, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6942, \"tn\": 8044, \"fp\": 5, \"fn\": 5082, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5773453093812375, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4226546906187625, \"precision\": 0.9992802648625306, \"recall\": 0.5773453093812375, \"specificity\": 0.9993788048204746, \"npv\": 0.6128294987048606, \"accuracy\": 0.7465750012454541, \"f1\": 0.7318538822413156, \"f2\": 0.6305978961902513, \"f0_5\": 0.8718476841153421, \"p4\": 0.7455477623609705, \"phi\": 0.5941535670074052}, {\"truth_threshold\": 7.9, \"match_probability\": 0.9958308395818786, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6936, \"tn\": 8044, \"fp\": 5, \"fn\": 5088, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5768463073852296, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4231536926147705, \"precision\": 0.9992796427027806, \"recall\": 0.5768463073852296, \"specificity\": 0.9993788048204746, \"npv\": 0.6125494974109047, \"accuracy\": 0.7462760922632392, \"f1\": 0.7314526759820722, \"f2\": 0.6301215545905482, \"f0_5\": 0.8716195837941088, \"p4\": 0.7452359480183312, \"phi\": 0.5937603177315975}, {\"truth_threshold\": 7.92, \"match_probability\": 0.9958880016246255, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6933, \"tn\": 8044, \"fp\": 5, \"fn\": 5091, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5765968063872255, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42340319361277445, \"precision\": 0.9992793312193716, \"recall\": 0.5765968063872255, \"specificity\": 0.9993788048204746, \"npv\": 0.6124095926912828, \"accuracy\": 0.7461266377721317, \"f1\": 0.7312519776394895, \"f2\": 0.6298833448413708, \"f0_5\": 0.8715054304102977, \"p4\": 0.7450800036072265, \"phi\": 0.5935637302079867}, {\"truth_threshold\": 7.94, \"match_probability\": 0.9959443831284631, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6926, \"tn\": 8044, \"fp\": 5, \"fn\": 5098, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5760146373918829, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4239853626081171, \"precision\": 0.9992786033761362, \"recall\": 0.5760146373918829, \"specificity\": 0.9993788048204746, \"npv\": 0.6120833967432658, \"accuracy\": 0.7457779106262143, \"f1\": 0.7307834344500131, \"f2\": 0.629327421084195, \"f0_5\": 0.8712388044681494, \"p4\": 0.7447160364574215, \"phi\": 0.5931051219527061}, {\"truth_threshold\": 7.96, \"match_probability\": 0.9959999946645937, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6917, \"tn\": 8044, \"fp\": 5, \"fn\": 5107, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5752661343978709, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42473386560212906, \"precision\": 0.99927766541462, \"recall\": 0.5752661343978709, \"specificity\": 0.9993788048204746, \"npv\": 0.6116645122043951, \"accuracy\": 0.7453295471528919, \"f1\": 0.7301805130370527, \"f2\": 0.6286124541059289, \"f0_5\": 0.8708954472199839, \"p4\": 0.7442478786861073, \"phi\": 0.5925156795594548}, {\"truth_threshold\": 7.98, \"match_probability\": 0.9960548466634173, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6916, \"tn\": 8044, \"fp\": 5, \"fn\": 5108, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5751829673985362, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42481703260146375, \"precision\": 0.9992775610460916, \"recall\": 0.5751829673985362, \"specificity\": 0.9993788048204746, \"npv\": 0.61161800486618, \"accuracy\": 0.7452797289891895, \"f1\": 0.7301134864080232, \"f2\": 0.6285329988912518, \"f0_5\": 0.870857257983278, \"p4\": 0.7441958472193752, \"phi\": 0.5924501995875183}, {\"truth_threshold\": 8.0, \"match_probability\": 0.9961089494163424, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6901, \"tn\": 8044, \"fp\": 5, \"fn\": 5123, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5739354624085163, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4260645375914837, \"precision\": 0.9992759918911092, \"recall\": 0.5739354624085163, \"specificity\": 0.9993788048204746, \"npv\": 0.6109212425001899, \"accuracy\": 0.7445324565336522, \"f1\": 0.7291072371896461, \"f2\": 0.6273408239700374, \"f0_5\": 0.8702834947538337, \"p4\": 0.74341503906985, \"phi\": 0.5914683256947953}, {\"truth_threshold\": 8.02, \"match_probability\": 0.9961623130775747, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6897, \"tn\": 8044, \"fp\": 5, \"fn\": 5127, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5736027944111777, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4263972055888224, \"precision\": 0.9992755722978847, \"recall\": 0.5736027944111777, \"specificity\": 0.9993788048204746, \"npv\": 0.6107357072355933, \"accuracy\": 0.7443331838788422, \"f1\": 0.7288386346824475, \"f2\": 0.6270228008291211, \"f0_5\": 0.8701301978199435, \"p4\": 0.74320671669196, \"phi\": 0.5912065954439604}, {\"truth_threshold\": 8.040000000000001, \"match_probability\": 0.9962149476658856, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6895, \"tn\": 8044, \"fp\": 5, \"fn\": 5129, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5734364604125083, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42656353958749166, \"precision\": 0.9992753623188406, \"recall\": 0.5734364604125083, \"specificity\": 0.9993788048204746, \"npv\": 0.6106429818568284, \"accuracy\": 0.7442335475514372, \"f1\": 0.7287042908476009, \"f2\": 0.6268637719106844, \"f0_5\": 0.8700535029275187, \"p4\": 0.743102538558103, \"phi\": 0.5910757464906232}, {\"truth_threshold\": 8.06, \"match_probability\": 0.9962668630663583, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6876, \"tn\": 8044, \"fp\": 5, \"fn\": 5148, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5718562874251497, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4281437125748503, \"precision\": 0.9992733614300247, \"recall\": 0.5718562874251497, \"specificity\": 0.9993788048204746, \"npv\": 0.6097634930260765, \"accuracy\": 0.74328700244109, \"f1\": 0.7274266067177996, \"f2\": 0.6253524201029521, \"f0_5\": 0.8693233538990593, \"p4\": 0.7421122800677096, \"phi\": 0.5898332168810229}, {\"truth_threshold\": 8.08, \"match_probability\": 0.9963180690321144, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6868, \"tn\": 8044, \"fp\": 5, \"fn\": 5156, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5711909514304724, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.4288090485695276, \"precision\": 0.9992725156409137, \"recall\": 0.5711909514304724, \"specificity\": 0.9993788048204746, \"npv\": 0.6093939393939394, \"accuracy\": 0.7428884571314701, \"f1\": 0.726887865798804, \"f2\": 0.6247157488766396, \"f0_5\": 0.8690150824982286, \"p4\": 0.7416950208360183, \"phi\": 0.5893103349571974}, {\"truth_threshold\": 8.1, \"match_probability\": 0.9963685751860192, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6866, \"tn\": 8044, \"fp\": 5, \"fn\": 5158, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5710246174318031, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42897538256819695, \"precision\": 0.9992723038858973, \"recall\": 0.5710246174318031, \"specificity\": 0.9993788048204746, \"npv\": 0.6093016209665202, \"accuracy\": 0.7427888208040652, \"f1\": 0.7267531092881715, \"f2\": 0.624556552113086, \"f0_5\": 0.8689379366204313, \"p4\": 0.7415906773190827, \"phi\": 0.5891796410512836}, {\"truth_threshold\": 8.120000000000001, \"match_probability\": 0.9964183910223661, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6860, \"tn\": 8044, \"fp\": 5, \"fn\": 5164, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.570525615435795, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.42947438456420495, \"precision\": 0.9992716678805535, \"recall\": 0.570525615435795, \"specificity\": 0.9993788048204746, \"npv\": 0.6090248334342823, \"accuracy\": 0.7424899118218502, \"f1\": 0.7263486685372439, \"f2\": 0.624078892305453, \"f0_5\": 0.8687063114172829, \"p4\": 0.7412775776490581, \"phi\": 0.5887876229386524}, {\"truth_threshold\": 8.14, \"match_probability\": 0.996467525908541, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6844, \"tn\": 8044, \"fp\": 5, \"fn\": 5180, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5691949434464405, \"tn_rate\": 0.9993788048204746, \"fp_rate\": 0.0006211951795254069, \"fn_rate\": 0.43080505655355955, \"precision\": 0.9992699664184552, \"recall\": 0.5691949434464405, \"specificity\": 0.9993788048204746, \"npv\": 0.6082879612825166, \"accuracy\": 0.7416928212026105, \"f1\": 0.7252689026651831, \"f2\": 0.6228046228046228, \"f0_5\": 0.8680872653475393, \"p4\": 0.7404421359208624, \"phi\": 0.5877427058179633}, {\"truth_threshold\": 8.16, \"match_probability\": 0.9965159890866674, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6837, \"tn\": 8045, \"fp\": 4, \"fn\": 5187, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5686127744510978, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4313872255489022, \"precision\": 0.9994152901622569, \"recall\": 0.5686127744510978, \"specificity\": 0.9995030438563797, \"npv\": 0.6079957678355502, \"accuracy\": 0.7413939122203955, \"f1\": 0.7248343493241453, \"f2\": 0.6222582230554999, \"f0_5\": 0.8679039301310044, \"p4\": 0.740124432597023, \"phi\": 0.5874349583259706}, {\"truth_threshold\": 8.18, \"match_probability\": 0.9965637896752301, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6832, \"tn\": 8045, \"fp\": 4, \"fn\": 5192, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5681969394544245, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4318030605455755, \"precision\": 0.9994148624926857, \"recall\": 0.5681969394544245, \"specificity\": 0.9995030438563797, \"npv\": 0.6077661101458034, \"accuracy\": 0.7411448214018831, \"f1\": 0.7244962884411453, \"f2\": 0.6218597538775213, \"f0_5\": 0.8677098150782361, \"p4\": 0.7398630932421008, \"phi\": 0.587108702059089}, {\"truth_threshold\": 8.2, \"match_probability\": 0.9966109366706807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6828, \"tn\": 8045, \"fp\": 4, \"fn\": 5196, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5678642714570858, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43213572854291415, \"precision\": 0.9994145199063232, \"recall\": 0.5678642714570858, \"specificity\": 0.9995030438563797, \"npv\": 0.6075825088739522, \"accuracy\": 0.7409455487470732, \"f1\": 0.7242257106491302, \"f2\": 0.6215409263035246, \"f0_5\": 0.8675543809717422, \"p4\": 0.7396539689139711, \"phi\": 0.5868477439867305}, {\"truth_threshold\": 8.22, \"match_probability\": 0.9966574389490227, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6810, \"tn\": 8045, \"fp\": 4, \"fn\": 5214, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5663672654690619, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43363273453093815, \"precision\": 0.9994129732902847, \"recall\": 0.5663672654690619, \"specificity\": 0.9995030438563797, \"npv\": 0.6067576740327325, \"accuracy\": 0.7400488218004284, \"f1\": 0.7230066886081326, \"f2\": 0.620105627390275, \"f0_5\": 0.8668533604887984, \"p4\": 0.7387123250757881, \"phi\": 0.585673946581781}, {\"truth_threshold\": 8.24, \"match_probability\": 0.9967033052673774, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6803, \"tn\": 8045, \"fp\": 4, \"fn\": 5221, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5657850964737192, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4342149035262808, \"precision\": 0.9994123696195093, \"recall\": 0.5657850964737192, \"specificity\": 0.9995030438563797, \"npv\": 0.606437509422584, \"accuracy\": 0.739700094654511, \"f1\": 0.722531995114439, \"f2\": 0.6195472014279729, \"f0_5\": 0.8665800468765923, \"p4\": 0.7383458705448009, \"phi\": 0.5852176957704888}, {\"truth_threshold\": 8.26, \"match_probability\": 0.9967485442655314, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6796, \"tn\": 8045, \"fp\": 4, \"fn\": 5228, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5652029274783765, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4347970725216234, \"precision\": 0.9994117647058823, \"recall\": 0.5652029274783765, \"specificity\": 0.9995030438563797, \"npv\": 0.6061176825133731, \"accuracy\": 0.7393513675085936, \"f1\": 0.7220569485762856, \"f2\": 0.6189886330515885, \"f0_5\": 0.8663063430552723, \"p4\": 0.7379792696710443, \"phi\": 0.5847615707822699}, {\"truth_threshold\": 8.28, \"match_probability\": 0.9967931644674644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6786, \"tn\": 8045, \"fp\": 4, \"fn\": 5238, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5643712574850299, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4356287425149701, \"precision\": 0.9994108983799705, \"recall\": 0.5643712574850299, \"specificity\": 0.9995030438563797, \"npv\": 0.6056613716780848, \"accuracy\": 0.7388531858715688, \"f1\": 0.7213776974593388, \"f2\": 0.6181904310753198, \"f0_5\": 0.8659146590445079, \"p4\": 0.7374552990912914, \"phi\": 0.5841101809933179}, {\"truth_threshold\": 8.3, \"match_probability\": 0.9968371742828585, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6784, \"tn\": 8045, \"fp\": 4, \"fn\": 5240, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5642049234863606, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4357950765136394, \"precision\": 0.9994107248084856, \"recall\": 0.5642049234863606, \"specificity\": 0.9995030438563797, \"npv\": 0.6055701919458035, \"accuracy\": 0.7387535495441638, \"f1\": 0.7212417605783542, \"f2\": 0.6180307557758181, \"f0_5\": 0.8658362262609761, \"p4\": 0.7373504688360073, \"phi\": 0.5839799336147672}, {\"truth_threshold\": 8.32, \"match_probability\": 0.9968805820085895, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6774, \"tn\": 8045, \"fp\": 4, \"fn\": 5250, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5633732534930139, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.436626746506986, \"precision\": 0.9994098554145766, \"recall\": 0.5633732534930139, \"specificity\": 0.9995030438563797, \"npv\": 0.6051147047762316, \"accuracy\": 0.738255367907139, \"f1\": 0.7205616423784704, \"f2\": 0.6172322046871014, \"f0_5\": 0.865443581357318, \"p4\": 0.7368261360916047, \"phi\": 0.5833288490182642}, {\"truth_threshold\": 8.34, \"match_probability\": 0.9969233958301993, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6769, \"tn\": 8045, \"fp\": 4, \"fn\": 5255, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5629574184963406, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4370425815036593, \"precision\": 0.9994094197549092, \"recall\": 0.5629574184963406, \"specificity\": 0.9995030438563797, \"npv\": 0.6048872180451128, \"accuracy\": 0.7380062770886265, \"f1\": 0.7202213119114752, \"f2\": 0.6168328199894294, \"f0_5\": 0.8652469577666428, \"p4\": 0.7365638559284606, \"phi\": 0.5830034016154578}, {\"truth_threshold\": 8.36, \"match_probability\": 0.9969656238233504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6758, \"tn\": 8045, \"fp\": 4, \"fn\": 5266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5620425815036594, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4379574184963407, \"precision\": 0.9994084590357882, \"recall\": 0.5620425815036594, \"specificity\": 0.9995030438563797, \"npv\": 0.6043873488092555, \"accuracy\": 0.7374582772878991, \"f1\": 0.7194719471947195, \"f2\": 0.6159539173867075, \"f0_5\": 0.8648136773136773, \"p4\": 0.7359865711962651, \"phi\": 0.5822876389776062}, {\"truth_threshold\": 8.38, \"match_probability\": 0.9970072739552628, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6755, \"tn\": 8045, \"fp\": 4, \"fn\": 5269, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5617930805056554, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43820691949434465, \"precision\": 0.999408196478769, \"recall\": 0.5617930805056554, \"specificity\": 0.9995030438563797, \"npv\": 0.6042511641880727, \"accuracy\": 0.7373088227967917, \"f1\": 0.7192674226694351, \"f2\": 0.615714155500866, \"f0_5\": 0.8646953405017921, \"p4\": 0.735829065627049, \"phi\": 0.5820924836975325}, {\"truth_threshold\": 8.4, \"match_probability\": 0.9970483540861322, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6751, \"tn\": 8045, \"fp\": 4, \"fn\": 5273, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5614604125083167, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4385395874916833, \"precision\": 0.9994078460399703, \"recall\": 0.5614604125083167, \"specificity\": 0.9995030438563797, \"npv\": 0.604069680132152, \"accuracy\": 0.7371095501419818, \"f1\": 0.7189946216518451, \"f2\": 0.6153944321890211, \"f0_5\": 0.8645374449339207, \"p4\": 0.735619015200277, \"phi\": 0.5818323116843291}, {\"truth_threshold\": 8.42, \"match_probability\": 0.9970888719705324, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6750, \"tn\": 8045, \"fp\": 4, \"fn\": 5274, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.561377245508982, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43862275449101795, \"precision\": 0.9994077583654131, \"recall\": 0.561377245508982, \"specificity\": 0.9995030438563797, \"npv\": 0.6040243261506119, \"accuracy\": 0.7370597319782792, \"f1\": 0.7189264032378315, \"f2\": 0.6153144940747494, \"f0_5\": 0.8644979508196722, \"p4\": 0.7355664949029812, \"phi\": 0.5817672749267455}, {\"truth_threshold\": 8.44, \"match_probability\": 0.9971288352587981, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6744, \"tn\": 8045, \"fp\": 4, \"fn\": 5280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5608782435129741, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43912175648702595, \"precision\": 0.999407231772377, \"recall\": 0.5608782435129741, \"specificity\": 0.9995030438563797, \"npv\": 0.6037523452157598, \"accuracy\": 0.7367608229960644, \"f1\": 0.7185169401235884, \"f2\": 0.6148348041718328, \"f0_5\": 0.8642608160754562, \"p4\": 0.7352513083813748, \"phi\": 0.5813771067403385}, {\"truth_threshold\": 8.46, \"match_probability\": 0.9971682514983926, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6739, \"tn\": 8045, \"fp\": 4, \"fn\": 5285, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5604624085163007, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.43953759148369925, \"precision\": 0.9994067922289782, \"recall\": 0.5604624085163007, \"specificity\": 0.9995030438563797, \"npv\": 0.6035258814703676, \"accuracy\": 0.736511732177552, \"f1\": 0.7181755208610859, \"f2\": 0.6144349824030343, \"f0_5\": 0.8640629808185455, \"p4\": 0.7349885679752909, \"phi\": 0.5810520350005874}, {\"truth_threshold\": 8.48, \"match_probability\": 0.9972071281352571, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6731, \"tn\": 8045, \"fp\": 4, \"fn\": 5293, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5597970725216235, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4402029274783766, \"precision\": 0.9994060876020787, \"recall\": 0.5597970725216235, \"specificity\": 0.9995030438563797, \"npv\": 0.6031638926375769, \"accuracy\": 0.736113186867932, \"f1\": 0.7176288714750253, \"f2\": 0.6137951159015885, \"f0_5\": 0.863746021968997, \"p4\": 0.7345680220653804, \"phi\": 0.580532049135903}, {\"truth_threshold\": 8.5, \"match_probability\": 0.9972454725151444, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6721, \"tn\": 8045, \"fp\": 4, \"fn\": 5303, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5589654025282768, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44103459747172324, \"precision\": 0.9994052044609666, \"recall\": 0.5589654025282768, \"specificity\": 0.9995030438563797, \"npv\": 0.6027120167815403, \"accuracy\": 0.7356150052309072, \"f1\": 0.7169449037281989, \"f2\": 0.6129950201565094, \"f0_5\": 0.8633490905354023, \"p4\": 0.7340420593406962, \"phi\": 0.579882288993852}, {\"truth_threshold\": 8.52, \"match_probability\": 0.9972832918849344, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6716, \"tn\": 8045, \"fp\": 4, \"fn\": 5308, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5585495675316035, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44145043246839655, \"precision\": 0.9994047619047619, \"recall\": 0.5585495675316035, \"specificity\": 0.9995030438563797, \"npv\": 0.6024863326593275, \"accuracy\": 0.7353659144123947, \"f1\": 0.7166026461801109, \"f2\": 0.612594862813777, \"f0_5\": 0.8631503187332922, \"p4\": 0.7337789606559726, \"phi\": 0.5795575011098223}, {\"truth_threshold\": 8.540000000000001, \"match_probability\": 0.997320593393935, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6710, \"tn\": 8045, \"fp\": 4, \"fn\": 5314, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5580505655355955, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44194943446440454, \"precision\": 0.9994042299672327, \"recall\": 0.5580505655355955, \"specificity\": 0.9995030438563797, \"npv\": 0.6022157347106819, \"accuracy\": 0.7350670054301799, \"f1\": 0.7161916960187854, \"f2\": 0.612114577631819, \"f0_5\": 0.8629115226337448, \"p4\": 0.7334631385755371, \"phi\": 0.579167836458866}, {\"truth_threshold\": 8.56, \"match_probability\": 0.9973573840951653, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6706, \"tn\": 8045, \"fp\": 4, \"fn\": 5318, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5577178975382568, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44228210246174315, \"precision\": 0.9994038748137108, \"recall\": 0.5577178975382568, \"specificity\": 0.9995030438563797, \"npv\": 0.602035471076854, \"accuracy\": 0.7348677327753699, \"f1\": 0.7159175830041635, \"f2\": 0.6117943290880561, \"f0_5\": 0.8627521613832853, \"p4\": 0.7332525275183066, \"phi\": 0.5789081088643645}, {\"truth_threshold\": 8.58, \"match_probability\": 0.9973936709466236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6694, \"tn\": 8045, \"fp\": 4, \"fn\": 5330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5567198935462409, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44328010645375915, \"precision\": 0.9994028068080024, \"recall\": 0.5567198935462409, \"specificity\": 0.9995030438563797, \"npv\": 0.6014953271028037, \"accuracy\": 0.7342699148109401, \"f1\": 0.7150945411814977, \"f2\": 0.6108333029163777, \"f0_5\": 0.8622732893652102, \"p4\": 0.7326203906580573, \"phi\": 0.5781291595514119}, {\"truth_threshold\": 8.6, \"match_probability\": 0.9974294608125389, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6689, \"tn\": 8045, \"fp\": 4, \"fn\": 5335, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5563040585495675, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44369594145043245, \"precision\": 0.9994023606753324, \"recall\": 0.5563040585495675, \"specificity\": 0.9995030438563797, \"npv\": 0.601270553064275, \"accuracy\": 0.7340208239924276, \"f1\": 0.7147512956136133, \"f2\": 0.6104327510996733, \"f0_5\": 0.8620734096298588, \"p4\": 0.732356865315573, \"phi\": 0.5778047002918449}, {\"truth_threshold\": 8.620000000000001, \"match_probability\": 0.9974647604646075, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6687, \"tn\": 8045, \"fp\": 4, \"fn\": 5337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5561377245508982, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4438622754491018, \"precision\": 0.9994021820355702, \"recall\": 0.5561377245508982, \"specificity\": 0.9995030438563797, \"npv\": 0.6011806904797489, \"accuracy\": 0.7339211876650227, \"f1\": 0.7146139460325942, \"f2\": 0.610272509901984, \"f0_5\": 0.861993400020625, \"p4\": 0.7322514328654759, \"phi\": 0.5776749334847948}, {\"truth_threshold\": 8.64, \"match_probability\": 0.9974995765832131, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6668, \"tn\": 8045, \"fp\": 4, \"fn\": 5356, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5545575515635396, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4454424484364604, \"precision\": 0.999400479616307, \"recall\": 0.5545575515635396, \"specificity\": 0.9995030438563797, \"npv\": 0.6003283337064398, \"accuracy\": 0.7329746425546755, \"f1\": 0.7133076593923834, \"f2\": 0.6087496348232545, \"f0_5\": 0.8612316594337673, \"p4\": 0.7312491855176727, \"phi\": 0.5764426280212825}, {\"truth_threshold\": 8.66, \"match_probability\": 0.9975339157586318, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6666, \"tn\": 8045, \"fp\": 4, \"fn\": 5358, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5543912175648703, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44560878243512975, \"precision\": 0.999400299850075, \"recall\": 0.5543912175648703, \"specificity\": 0.9995030438563797, \"npv\": 0.600238752518093, \"accuracy\": 0.7328750062272704, \"f1\": 0.713170001069862, \"f2\": 0.6085892707154074, \"f0_5\": 0.861151302190988, \"p4\": 0.7311436182321673, \"phi\": 0.5763129618799187}, {\"truth_threshold\": 8.68, \"match_probability\": 0.9975677844922232, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6663, \"tn\": 8045, \"fp\": 4, \"fn\": 5361, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5541417165668663, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4458582834331337, \"precision\": 0.9994000299985001, \"recall\": 0.5541417165668663, \"specificity\": 0.9995030438563797, \"npv\": 0.6001044308518574, \"accuracy\": 0.732725551736163, \"f1\": 0.712963458348938, \"f2\": 0.6083487025911656, \"f0_5\": 0.8610307040215032, \"p4\": 0.7309852430638418, \"phi\": 0.5761184805230287}, {\"truth_threshold\": 8.700000000000001, \"match_probability\": 0.9976011891976038, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6657, \"tn\": 8045, \"fp\": 4, \"fn\": 5367, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5536427145708582, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4463572854291417, \"precision\": 0.9993994895661312, \"recall\": 0.5536427145708582, \"specificity\": 0.9995030438563797, \"npv\": 0.5998359677900388, \"accuracy\": 0.7324266427539481, \"f1\": 0.7125501739363126, \"f2\": 0.6078674872619025, \"f0_5\": 0.860789283128168, \"p4\": 0.730668405281219, \"phi\": 0.5757295819529958}, {\"truth_threshold\": 8.72, \"match_probability\": 0.9976341362018084, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6651, \"tn\": 8045, \"fp\": 4, \"fn\": 5373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5531437125748503, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4468562874251497, \"precision\": 0.9993989481592788, \"recall\": 0.5531437125748503, \"specificity\": 0.9995030438563797, \"npv\": 0.5995677448203905, \"accuracy\": 0.7321277337717331, \"f1\": 0.712136624016275, \"f2\": 0.607386166462713, \"f0_5\": 0.8605475623641445, \"p4\": 0.7303514505730109, \"phi\": 0.5753407686628461}, {\"truth_threshold\": 8.74, \"match_probability\": 0.9976666317464351, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6638, \"tn\": 8045, \"fp\": 4, \"fn\": 5386, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5520625415834997, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.44793745841650034, \"precision\": 0.9993977717554954, \"recall\": 0.5520625415834997, \"specificity\": 0.9995030438563797, \"npv\": 0.5989874171692353, \"accuracy\": 0.7314800976436009, \"f1\": 0.7112396871316833, \"f2\": 0.6063429427454419, \"f0_5\": 0.8600228026533997, \"p4\": 0.7296643123548068, \"phi\": 0.5744986310234532}, {\"truth_threshold\": 8.76, \"match_probability\": 0.9976986819887761, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6629, \"tn\": 8045, \"fp\": 4, \"fn\": 5395, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5513140385894877, \"tn_rate\": 0.9995030438563797, \"fp_rate\": 0.0004969561436203255, \"fn_rate\": 0.4486859614105123, \"precision\": 0.9993969546208352, \"recall\": 0.5513140385894877, \"specificity\": 0.9995030438563797, \"npv\": 0.5985863095238095, \"accuracy\": 0.7310317341702784, \"f1\": 0.7106179986064212, \"f2\": 0.605620420617954, \"f0_5\": 0.8596586782861293, \"p4\": 0.7291882765052731, \"phi\": 0.5739158447957415}, {\"truth_threshold\": 8.78, \"match_probability\": 0.9977302930029345, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6625, \"tn\": 8046, \"fp\": 3, \"fn\": 5399, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.550981370592149, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.449018629407851, \"precision\": 0.9995473747736874, \"recall\": 0.550981370592149, \"specificity\": 0.9996272828922848, \"npv\": 0.5984380810710301, \"accuracy\": 0.7308822796791711, \"f1\": 0.7103795839588248, \"f2\": 0.6053102843359404, \"f0_5\": 0.8595858418102553, \"p4\": 0.7290242761298971, \"phi\": 0.573808301304482}, {\"truth_threshold\": 8.8, \"match_probability\": 0.9977614707809268, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6617, \"tn\": 8046, \"fp\": 3, \"fn\": 5407, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5503160345974717, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.44968396540252825, \"precision\": 0.9995468277945619, \"recall\": 0.5503160345974717, \"specificity\": 0.9996272828922848, \"npv\": 0.5980822121459898, \"accuracy\": 0.7304837343695512, \"f1\": 0.709826217549882, \"f2\": 0.6046677388698004, \"f0_5\": 0.8592613754415126, \"p4\": 0.7286007881299192, \"phi\": 0.5732905867473538}, {\"truth_threshold\": 8.82, \"match_probability\": 0.997792221233771, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6609, \"tn\": 8046, \"fp\": 3, \"fn\": 5415, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5496506986027944, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4503493013972056, \"precision\": 0.9995462794918331, \"recall\": 0.5496506986027944, \"specificity\": 0.9996272828922848, \"npv\": 0.5977267662135057, \"accuracy\": 0.7300851890599312, \"f1\": 0.7092723760463618, \"f2\": 0.6040250054836587, \"f0_5\": 0.8589363693075484, \"p4\": 0.7281770874831703, \"phi\": 0.57277302044217}, {\"truth_threshold\": 8.84, \"match_probability\": 0.9978225501925614, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6592, \"tn\": 8046, \"fp\": 3, \"fn\": 5432, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5482368596141052, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4517631403858949, \"precision\": 0.9995451099317665, \"recall\": 0.5482368596141052, \"specificity\": 0.9996272828922848, \"npv\": 0.5969728446357027, \"accuracy\": 0.729238280276989, \"f1\": 0.7080938825930501, \"f2\": 0.6026585727084895, \"f0_5\": 0.8582439329236538, \"p4\": 0.7272760131758708, \"phi\": 0.5716736811055517}, {\"truth_threshold\": 8.86, \"match_probability\": 0.9978524634095293, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6587, \"tn\": 8046, \"fp\": 3, \"fn\": 5437, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5478210246174318, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4521789753825682, \"precision\": 0.9995447647951442, \"recall\": 0.5478210246174318, \"specificity\": 0.9996272828922848, \"npv\": 0.5967514648075354, \"accuracy\": 0.7289891894584766, \"f1\": 0.7077468572042549, \"f2\": 0.6022565190359507, \"f0_5\": 0.858039808253439, \"p4\": 0.7270108064098101, \"phi\": 0.5713504718387937}, {\"truth_threshold\": 8.88, \"match_probability\": 0.9978819665590902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6585, \"tn\": 8046, \"fp\": 3, \"fn\": 5439, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5476546906187625, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4523453093812375, \"precision\": 0.9995446265938069, \"recall\": 0.5476546906187625, \"specificity\": 0.9996272828922848, \"npv\": 0.5966629588431591, \"accuracy\": 0.7288895531310716, \"f1\": 0.7076079948420374, \"f2\": 0.6020956769804696, \"f0_5\": 0.8579580988117573, \"p4\": 0.7269047000636336, \"phi\": 0.5712212040708915}, {\"truth_threshold\": 8.9, \"match_probability\": 0.9979110652388782, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6583, \"tn\": 8046, \"fp\": 3, \"fn\": 5441, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5474883566200931, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.45251164337990685, \"precision\": 0.9995444883085333, \"recall\": 0.5474883566200931, \"specificity\": 0.9996272828922848, \"npv\": 0.5965744791280493, \"accuracy\": 0.7287899168036667, \"f1\": 0.707469102632993, \"f2\": 0.6019348231593578, \"f0_5\": 0.8578763552960801, \"p4\": 0.7267985801863354, \"phi\": 0.5710919453945434}, {\"truth_threshold\": 8.94, \"match_probability\": 0.9979680712018738, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6576, \"tn\": 8046, \"fp\": 3, \"fn\": 5448, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5469061876247505, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4530938123752495, \"precision\": 0.9995440036479708, \"recall\": 0.5469061876247505, \"specificity\": 0.9996272828922848, \"npv\": 0.5962650066696309, \"accuracy\": 0.7284411896577492, \"f1\": 0.7069827447185938, \"f2\": 0.6013717421124829, \"f0_5\": 0.8575899843505478, \"p4\": 0.726427053839458, \"phi\": 0.5706396114661152}, {\"truth_threshold\": 8.96, \"match_probability\": 0.9979959893055618, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6570, \"tn\": 8046, \"fp\": 3, \"fn\": 5454, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5464071856287425, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4535928143712575, \"precision\": 0.9995435874030123, \"recall\": 0.5464071856287425, \"specificity\": 0.9996272828922848, \"npv\": 0.596, \"accuracy\": 0.7281422806755343, \"f1\": 0.7065655750927569, \"f2\": 0.6008889864457004, \"f0_5\": 0.8573441904165362, \"p4\": 0.7261084701157925, \"phi\": 0.570251984852933}, {\"truth_threshold\": 8.98, \"match_probability\": 0.9980235245824145, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6563, \"tn\": 8046, \"fp\": 3, \"fn\": 5461, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5458250166333999, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4541749833666001, \"precision\": 0.9995431008224185, \"recall\": 0.5458250166333999, \"specificity\": 0.9996272828922848, \"npv\": 0.5956911231213445, \"accuracy\": 0.7277935535296169, \"f1\": 0.7060785368477677, \"f2\": 0.6003256375544254, \"f0_5\": 0.8570570413706644, \"p4\": 0.7257366338641027, \"phi\": 0.5697998562710523}, {\"truth_threshold\": 9.0, \"match_probability\": 0.9980506822612085, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6553, \"tn\": 8046, \"fp\": 3, \"fn\": 5471, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5449933466400533, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4550066533599468, \"precision\": 0.99954240390482, \"recall\": 0.5449933466400533, \"specificity\": 0.9996272828922848, \"npv\": 0.5952504253902493, \"accuracy\": 0.7272953718925921, \"f1\": 0.7053821313240043, \"f2\": 0.5995206030886335, \"f0_5\": 0.8566460991424388, \"p4\": 0.7252051479661011, \"phi\": 0.5691541488314049}, {\"truth_threshold\": 9.02, \"match_probability\": 0.9980774674998706, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6549, \"tn\": 8046, \"fp\": 3, \"fn\": 5475, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5446606786427146, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.45533932135728544, \"precision\": 0.9995421245421245, \"recall\": 0.5446606786427146, \"specificity\": 0.9996272828922848, \"npv\": 0.5950743288218328, \"accuracy\": 0.7270960992377821, \"f1\": 0.7051033591731266, \"f2\": 0.5991985068072024, \"f0_5\": 0.8564814814814815, \"p4\": 0.7249924572901212, \"phi\": 0.5688959283530155}, {\"truth_threshold\": 9.040000000000001, \"match_probability\": 0.9981038853864208, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6546, \"tn\": 8046, \"fp\": 3, \"fn\": 5478, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5444111776447106, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4555888223552894, \"precision\": 0.9995419147961521, \"recall\": 0.5444111776447106, \"specificity\": 0.9996272828922848, \"npv\": 0.5949423247559894, \"accuracy\": 0.7269466447466746, \"f1\": 0.7048942012598934, \"f2\": 0.5989569036508372, \"f0_5\": 0.8563579277864992, \"p4\": 0.7248329030503275, \"phi\": 0.5687022863497678}, {\"truth_threshold\": 9.06, \"match_probability\": 0.9981299409399065, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6540, \"tn\": 8046, \"fp\": 3, \"fn\": 5484, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5439121756487026, \"tn_rate\": 0.9996272828922848, \"fp_rate\": 0.0003727171077152441, \"fn_rate\": 0.4560878243512974, \"precision\": 0.9995414947271893, \"recall\": 0.5439121756487026, \"specificity\": 0.9996272828922848, \"npv\": 0.5946784922394679, \"accuracy\": 0.7266477357644597, \"f1\": 0.7044756826627888, \"f2\": 0.5984736177455664, \"f0_5\": 0.8561105874960729, \"p4\": 0.7245137011759549, \"phi\": 0.568315062241086}, {\"truth_threshold\": 9.08, \"match_probability\": 0.9981556391113212, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6537, \"tn\": 8047, \"fp\": 2, \"fn\": 5487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5436626746506986, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4563373253493014, \"precision\": 0.9996941428352959, \"recall\": 0.5436626746506986, \"specificity\": 0.9997515219281898, \"npv\": 0.5945766218412886, \"accuracy\": 0.7265480994370548, \"f1\": 0.7043042611646825, \"f2\": 0.5982428845977853, \"f0_5\": 0.856076479832373, \"p4\": 0.7244015458658477, \"phi\": 0.5682738513578184}, {\"truth_threshold\": 9.1, \"match_probability\": 0.9981809847845143, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6536, \"tn\": 8047, \"fp\": 2, \"fn\": 5488, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.543579507651364, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4564204923486361, \"precision\": 0.9996940960538391, \"recall\": 0.543579507651364, \"specificity\": 0.9997515219281898, \"npv\": 0.5945326930181012, \"accuracy\": 0.7264982812733523, \"f1\": 0.7042344574938045, \"f2\": 0.5981623165062049, \"f0_5\": 0.856035205364627, \"p4\": 0.7243483211235168, \"phi\": 0.5682093391613778}, {\"truth_threshold\": 9.120000000000001, \"match_probability\": 0.9982059827770873, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6528, \"tn\": 8047, \"fp\": 2, \"fn\": 5496, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5429141716566867, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.45708582834331335, \"precision\": 0.9996937212863706, \"recall\": 0.5429141716566867, \"specificity\": 0.9997515219281898, \"npv\": 0.5941814959757808, \"accuracy\": 0.7260997359637323, \"f1\": 0.7036757572491107, \"f2\": 0.5975176655804928, \"f0_5\": 0.8557046979865772, \"p4\": 0.7239223978544723, \"phi\": 0.5676933209739521}, {\"truth_threshold\": 9.14, \"match_probability\": 0.9982306378412784, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6525, \"tn\": 8047, \"fp\": 2, \"fn\": 5499, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5426646706586826, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4573353293413174, \"precision\": 0.9996935805117205, \"recall\": 0.5426646706586826, \"specificity\": 0.9997515219281898, \"npv\": 0.5940499040307101, \"accuracy\": 0.725950281472625, \"f1\": 0.703466120424775, \"f2\": 0.5972758728008348, \"f0_5\": 0.8555806147068079, \"p4\": 0.723762619057944, \"phi\": 0.5674998504482339}, {\"truth_threshold\": 9.16, \"match_probability\": 0.9982549546648377, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6504, \"tn\": 8047, \"fp\": 2, \"fn\": 5520, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5409181636726547, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4590818363273453, \"precision\": 0.9996925914540424, \"recall\": 0.5409181636726547, \"specificity\": 0.9997515219281898, \"npv\": 0.5931303899167096, \"accuracy\": 0.7249041000348727, \"f1\": 0.7019967620075553, \"f2\": 0.5955825793926962, \"f0_5\": 0.8547098402018503, \"p4\": 0.7226432830104561, \"phi\": 0.5661461074269432}, {\"truth_threshold\": 9.18, \"match_probability\": 0.9982789378718879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6496, \"tn\": 8047, \"fp\": 2, \"fn\": 5528, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5402528276779773, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4597471723220226, \"precision\": 0.9996922129886119, \"recall\": 0.5402528276779773, \"specificity\": 0.9997515219281898, \"npv\": 0.5927808471454881, \"accuracy\": 0.7245055547252528, \"f1\": 0.7014361300075586, \"f2\": 0.5949371725830678, \"f0_5\": 0.8543771043771043, \"p4\": 0.7222164597320166, \"phi\": 0.5656306475933657}, {\"truth_threshold\": 9.200000000000001, \"match_probability\": 0.9983025920237768, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6492, \"tn\": 8047, \"fp\": 2, \"fn\": 5532, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5399201596806387, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4600798403193613, \"precision\": 0.9996920234062211, \"recall\": 0.5399201596806387, \"specificity\": 0.9997515219281898, \"npv\": 0.5926062302084101, \"accuracy\": 0.7243062820704429, \"f1\": 0.7011556323577061, \"f2\": 0.5946143982414361, \"f0_5\": 0.8542105263157894, \"p4\": 0.7220029628434712, \"phi\": 0.5653729694123875}, {\"truth_threshold\": 9.22, \"match_probability\": 0.9983259216199165, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6483, \"tn\": 8047, \"fp\": 2, \"fn\": 5541, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5391716566866267, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46082834331337325, \"precision\": 0.9996915959907479, \"recall\": 0.5391716566866267, \"specificity\": 0.9997515219281898, \"npv\": 0.5922137179864586, \"accuracy\": 0.7238579185971206, \"f1\": 0.700524069371657, \"f2\": 0.5938879829977465, \"f0_5\": 0.8538352123063956, \"p4\": 0.7215223862458338, \"phi\": 0.5647933190536137}, {\"truth_threshold\": 9.24, \"match_probability\": 0.9983489310986134, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6477, \"tn\": 8047, \"fp\": 2, \"fn\": 5547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5386726546906188, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46132734530938124, \"precision\": 0.9996913103874054, \"recall\": 0.5386726546906188, \"specificity\": 0.9997515219281898, \"npv\": 0.5919523319111373, \"accuracy\": 0.7235590096149056, \"f1\": 0.7001026860509106, \"f2\": 0.59340357306459, \"f0_5\": 0.8535846072746441, \"p4\": 0.7212018408266091, \"phi\": 0.5644069816686765}, {\"truth_threshold\": 9.26, \"match_probability\": 0.9983716248378863, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6476, \"tn\": 8047, \"fp\": 2, \"fn\": 5548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5385894876912841, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4614105123087159, \"precision\": 0.9996912627354122, \"recall\": 0.5385894876912841, \"specificity\": 0.9997515219281898, \"npv\": 0.5919087899963221, \"accuracy\": 0.7235091914512031, \"f1\": 0.7000324289266026, \"f2\": 0.5933228277201598, \"f0_5\": 0.8535428089413749, \"p4\": 0.7211484040294488, \"phi\": 0.564342599560352}, {\"truth_threshold\": 9.28, \"match_probability\": 0.998394007156274, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6473, \"tn\": 8047, \"fp\": 2, \"fn\": 5551, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5383399866932801, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4616600133067199, \"precision\": 0.9996911196911197, \"recall\": 0.5383399866932801, \"specificity\": 0.9997515219281898, \"npv\": 0.5917782026768642, \"accuracy\": 0.7233597369600957, \"f1\": 0.6998216119790259, \"f2\": 0.5930805739312088, \"f0_5\": 0.8534173610378653, \"p4\": 0.7209880720659873, \"phi\": 0.5641494659895612}, {\"truth_threshold\": 9.3, \"match_probability\": 0.9984160823136331, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6463, \"tn\": 8047, \"fp\": 2, \"fn\": 5561, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5375083166999335, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4624916833000665, \"precision\": 0.9996906419180202, \"recall\": 0.5375083166999335, \"specificity\": 0.9997515219281898, \"npv\": 0.5913433274544385, \"accuracy\": 0.7228615553230708, \"f1\": 0.6991183947211855, \"f2\": 0.5922728688990304, \"f0_5\": 0.8529986273888713, \"p4\": 0.7204533978912858, \"phi\": 0.5635058251773325}, {\"truth_threshold\": 9.32, \"match_probability\": 0.9984378545119243, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6458, \"tn\": 8047, \"fp\": 2, \"fn\": 5566, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5370924817032602, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4629075182967399, \"precision\": 0.9996904024767802, \"recall\": 0.5370924817032602, \"specificity\": 0.9997515219281898, \"npv\": 0.5911261294350988, \"accuracy\": 0.7226124645045584, \"f1\": 0.6987665007574119, \"f2\": 0.5918689053449666, \"f0_5\": 0.8527889287978027, \"p4\": 0.7201859251869558, \"phi\": 0.5631840839398975}, {\"truth_threshold\": 9.34, \"match_probability\": 0.9984593278959899, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6448, \"tn\": 8047, \"fp\": 2, \"fn\": 5576, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5362608117099135, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4637391882900865, \"precision\": 0.9996899224806202, \"recall\": 0.5362608117099135, \"specificity\": 0.9997515219281898, \"npv\": 0.5906922117008001, \"accuracy\": 0.7221142828675335, \"f1\": 0.6980621413878965, \"f2\": 0.5910607560591061, \"f0_5\": 0.8523688663282571, \"p4\": 0.7196507073022068, \"phi\": 0.5625407589506977}, {\"truth_threshold\": 9.36, \"match_probability\": 0.9984805065543192, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6437, \"tn\": 8047, \"fp\": 2, \"fn\": 5587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5353459747172322, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4646540252827678, \"precision\": 0.9996893927628514, \"recall\": 0.5353459747172322, \"specificity\": 0.9997515219281898, \"npv\": 0.5902156373771453, \"accuracy\": 0.7215662830668061, \"f1\": 0.697286464821535, \"f2\": 0.5901714495278262, \"f0_5\": 0.8519057702488089, \"p4\": 0.7190615460192658, \"phi\": 0.5618333426261337}, {\"truth_threshold\": 9.38, \"match_probability\": 0.9985013945198057, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6432, \"tn\": 8047, \"fp\": 2, \"fn\": 5592, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5349301397205589, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46506986027944114, \"precision\": 0.9996891513832763, \"recall\": 0.5349301397205589, \"specificity\": 0.9997515219281898, \"npv\": 0.5899992668084171, \"accuracy\": 0.7213171922482937, \"f1\": 0.6969335789359627, \"f2\": 0.5897671006785256, \"f0_5\": 0.8516949152542372, \"p4\": 0.7187935987305045, \"phi\": 0.5615118727985694}, {\"truth_threshold\": 9.4, \"match_probability\": 0.9985219957704938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6428, \"tn\": 8047, \"fp\": 2, \"fn\": 5596, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5345974717232203, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46540252827677975, \"precision\": 0.9996889580093312, \"recall\": 0.5345974717232203, \"specificity\": 0.9997515219281898, \"npv\": 0.5898262845415231, \"accuracy\": 0.7211179195934838, \"f1\": 0.6966511325457895, \"f2\": 0.5894435682059934, \"f0_5\": 0.8515260703688003, \"p4\": 0.7185791746411664, \"phi\": 0.561254734144146}, {\"truth_threshold\": 9.42, \"match_probability\": 0.998542314230315, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6423, \"tn\": 8047, \"fp\": 2, \"fn\": 5601, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.534181636726547, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4658183632734531, \"precision\": 0.9996887159533074, \"recall\": 0.534181636726547, \"specificity\": 0.9997515219281898, \"npv\": 0.5896101992966002, \"accuracy\": 0.7208688287749714, \"f1\": 0.6962979023253293, \"f2\": 0.5890390858568259, \"f0_5\": 0.8513148128512353, \"p4\": 0.7183110614953497, \"phi\": 0.5609333571924504}, {\"truth_threshold\": 9.44, \"match_probability\": 0.9985623537698158, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6417, \"tn\": 8047, \"fp\": 2, \"fn\": 5607, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5336826347305389, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4663173652694611, \"precision\": 0.9996884249883159, \"recall\": 0.5336826347305389, \"specificity\": 0.9997515219281898, \"npv\": 0.5893511059030321, \"accuracy\": 0.7205699197927564, \"f1\": 0.6958737732473025, \"f2\": 0.5885536090984133, \"f0_5\": 0.8510610079575597, \"p4\": 0.7179892036043566, \"phi\": 0.560547772629309}, {\"truth_threshold\": 9.46, \"match_probability\": 0.9985821182068747, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6414, \"tn\": 8047, \"fp\": 2, \"fn\": 5610, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.533433133732535, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4665668662674651, \"precision\": 0.9996882793017456, \"recall\": 0.533433133732535, \"specificity\": 0.9997515219281898, \"npv\": 0.5892216445778722, \"accuracy\": 0.7204204653016489, \"f1\": 0.6956616052060738, \"f2\": 0.5883108306427942, \"f0_5\": 0.8509339842920823, \"p4\": 0.7178282245750867, \"phi\": 0.5603550079895223}, {\"truth_threshold\": 9.48, \"match_probability\": 0.9986016113074108, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6404, \"tn\": 8047, \"fp\": 2, \"fn\": 5620, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5326014637391883, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46739853626081174, \"precision\": 0.999687792694349, \"recall\": 0.5326014637391883, \"specificity\": 0.9997515219281898, \"npv\": 0.588790517304456, \"accuracy\": 0.7199222836646241, \"f1\": 0.6949538795442214, \"f2\": 0.58750137609629, \"f0_5\": 0.8505099872503188, \"p4\": 0.7172913858334341, \"phi\": 0.559712591718604}, {\"truth_threshold\": 9.5, \"match_probability\": 0.9986208367860828, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6399, \"tn\": 8047, \"fp\": 2, \"fn\": 5625, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.532185628742515, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46781437125748504, \"precision\": 0.9996875488204968, \"recall\": 0.532185628742515, \"specificity\": 0.9997515219281898, \"npv\": 0.5885751901696898, \"accuracy\": 0.7196731928461116, \"f1\": 0.6945997286295794, \"f2\": 0.5870965374240784, \"f0_5\": 0.8502976506856597, \"p4\": 0.7170228264036912, \"phi\": 0.559391459734759}, {\"truth_threshold\": 9.52, \"match_probability\": 0.9986397983069785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6393, \"tn\": 8047, \"fp\": 2, \"fn\": 5631, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.531686626746507, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46831337325349304, \"precision\": 0.999687255668491, \"recall\": 0.531686626746507, \"specificity\": 0.9997515219281898, \"npv\": 0.5883170054101476, \"accuracy\": 0.7193742838638968, \"f1\": 0.6941744937293013, \"f2\": 0.5866106329485603, \"f0_5\": 0.8500425486650356, \"p4\": 0.7167004313662875, \"phi\": 0.559006168052254}, {\"truth_threshold\": 9.540000000000001, \"match_probability\": 0.9986584994842955, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6389, \"tn\": 8047, \"fp\": 2, \"fn\": 5635, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5313539587491684, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.46864604125083165, \"precision\": 0.9996870599280238, \"recall\": 0.5313539587491684, \"specificity\": 0.9997515219281898, \"npv\": 0.5881450080397602, \"accuracy\": 0.7191750112090868, \"f1\": 0.6938908498506652, \"f2\": 0.5862866371795107, \"f0_5\": 0.8498722996701075, \"p4\": 0.7164854261545788, \"phi\": 0.5587493472171537}, {\"truth_threshold\": 9.56, \"match_probability\": 0.9986769438830138, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6384, \"tn\": 8047, \"fp\": 2, \"fn\": 5640, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.530938123752495, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.469061876247505, \"precision\": 0.9996868149076104, \"recall\": 0.530938123752495, \"specificity\": 0.9997515219281898, \"npv\": 0.587930152699642, \"accuracy\": 0.7189259203905745, \"f1\": 0.6935361216730038, \"f2\": 0.5858815755662421, \"f0_5\": 0.8496592844974447, \"p4\": 0.7162165848249543, \"phi\": 0.5584283663420504}, {\"truth_threshold\": 9.58, \"match_probability\": 0.9986951350195571, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6364, \"tn\": 8047, \"fp\": 2, \"fn\": 5660, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5292747837658017, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4707252162341983, \"precision\": 0.9996858309770656, \"recall\": 0.5292747837658017, \"specificity\": 0.9997515219281898, \"npv\": 0.5870722988254177, \"accuracy\": 0.7179295571165247, \"f1\": 0.6921152800435019, \"f2\": 0.584260585362271, \"f0_5\": 0.848804950917627, \"p4\": 0.7151402721623107, \"phi\": 0.5571449414158971}, {\"truth_threshold\": 9.6, \"match_probability\": 0.9987130763624487, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6360, \"tn\": 8047, \"fp\": 2, \"fn\": 5664, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5289421157684631, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47105788423153694, \"precision\": 0.9996856334486011, \"recall\": 0.5289421157684631, \"specificity\": 0.9997515219281898, \"npv\": 0.5869010283713807, \"accuracy\": 0.7177302844617147, \"f1\": 0.691830740781029, \"f2\": 0.5839362444452606, \"f0_5\": 0.8486336464560205, \"p4\": 0.7149248267850967, \"phi\": 0.5568883515229444}, {\"truth_threshold\": 9.620000000000001, \"match_probability\": 0.9987307713329557, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6356, \"tn\": 8047, \"fp\": 2, \"fn\": 5668, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5286094477711244, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4713905522288756, \"precision\": 0.9996854356715948, \"recall\": 0.5286094477711244, \"specificity\": 0.9997515219281898, \"npv\": 0.5867298578199052, \"accuracy\": 0.7175310118069048, \"f1\": 0.6915460776846916, \"f2\": 0.5836118558783561, \"f0_5\": 0.8484621956428876, \"p4\": 0.7147093201513975, \"phi\": 0.556631793123315}, {\"truth_threshold\": 9.64, \"match_probability\": 0.998748223305727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6354, \"tn\": 8047, \"fp\": 2, \"fn\": 5670, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5284431137724551, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47155688622754494, \"precision\": 0.999685336689742, \"recall\": 0.5284431137724551, \"specificity\": 0.9997515219281898, \"npv\": 0.5866443099803164, \"accuracy\": 0.7174313754794999, \"f1\": 0.6914036996735582, \"f2\": 0.583449643722912, \"f0_5\": 0.8483764152958769, \"p4\": 0.7146015438219561, \"phi\": 0.5565035257061534}, {\"truth_threshold\": 9.66, \"match_probability\": 0.9987654356094217, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6349, \"tn\": 8047, \"fp\": 2, \"fn\": 5675, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5280272787757818, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47197272122421824, \"precision\": 0.9996850889623682, \"recall\": 0.5280272787757818, \"specificity\": 0.9997515219281898, \"npv\": 0.5864305494825827, \"accuracy\": 0.7171822846609874, \"f1\": 0.691047619047619, \"f2\": 0.5830440611971275, \"f0_5\": 0.8481618039970076, \"p4\": 0.7143320357452343, \"phi\": 0.5561828914415822}, {\"truth_threshold\": 9.68, \"match_probability\": 0.9987824115273289, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6347, \"tn\": 8047, \"fp\": 2, \"fn\": 5677, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5278609447771124, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47213905522288757, \"precision\": 0.9996849897621672, \"recall\": 0.5278609447771124, \"specificity\": 0.9997515219281898, \"npv\": 0.5863450888953657, \"accuracy\": 0.7170826483335824, \"f1\": 0.690905132531432, \"f2\": 0.5828818073284966, \"f0_5\": 0.8480758952431855, \"p4\": 0.7142242055696943, \"phi\": 0.5560546514183685}, {\"truth_threshold\": 9.700000000000001, \"match_probability\": 0.9987991542979808, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6345, \"tn\": 8047, \"fp\": 2, \"fn\": 5679, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5276946107784432, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4723053892215569, \"precision\": 0.9996848904994485, \"recall\": 0.5276946107784432, \"specificity\": 0.9997515219281898, \"npv\": 0.5862596532128806, \"accuracy\": 0.7169830120061774, \"f1\": 0.6907626149910184, \"f2\": 0.5827195415388572, \"f0_5\": 0.8479899497487438, \"p4\": 0.7141163599721522, \"phi\": 0.5559264191973796}, {\"truth_threshold\": 9.72, \"match_probability\": 0.9988156671157563, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6335, \"tn\": 8047, \"fp\": 2, \"fn\": 5689, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5268629407850964, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4731370592149035, \"precision\": 0.9996843932460154, \"recall\": 0.5268629407850964, \"specificity\": 0.9997515219281898, \"npv\": 0.5858328479906815, \"accuracy\": 0.7164848303691526, \"f1\": 0.6900495615707205, \"f2\": 0.581908033729539, \"f0_5\": 0.8475596703414321, \"p4\": 0.7135769000712495, \"phi\": 0.5552853747427793}, {\"truth_threshold\": 9.74, \"match_probability\": 0.9988319531314767, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6331, \"tn\": 8047, \"fp\": 2, \"fn\": 5693, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5265302727877578, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4734697272122422, \"precision\": 0.9996841939049423, \"recall\": 0.5265302727877578, \"specificity\": 0.9997515219281898, \"npv\": 0.5856622998544396, \"accuracy\": 0.7162855577143427, \"f1\": 0.6897641226779975, \"f2\": 0.5815833471127524, \"f0_5\": 0.8473873005675125, \"p4\": 0.713361007573145, \"phi\": 0.5550290111934463}, {\"truth_threshold\": 9.78, \"match_probability\": 0.9988638571457743, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6322, \"tn\": 8047, \"fp\": 2, \"fn\": 5702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5257817697937458, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47421823020625414, \"precision\": 0.9996837444655281, \"recall\": 0.5257817697937458, \"specificity\": 0.9997515219281898, \"npv\": 0.5852789293766819, \"accuracy\": 0.7158371942410203, \"f1\": 0.6891214301286244, \"f2\": 0.5808526277104006, \"f0_5\": 0.8469989281886388, \"p4\": 0.7128750217478647, \"phi\": 0.5544523059008428}, {\"truth_threshold\": 9.8, \"match_probability\": 0.9988794812334637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6319, \"tn\": 8047, \"fp\": 2, \"fn\": 5705, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5255322687957419, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47446773120425817, \"precision\": 0.9996835943679797, \"recall\": 0.5255322687957419, \"specificity\": 0.9997515219281898, \"npv\": 0.585151250727167, \"accuracy\": 0.7156877397499128, \"f1\": 0.6889070591441809, \"f2\": 0.5806090008637007, \"f0_5\": 0.8468693041706873, \"p4\": 0.712712956208486, \"phi\": 0.5542601053467786}, {\"truth_threshold\": 9.82, \"match_probability\": 0.9988948906984604, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6314, \"tn\": 8047, \"fp\": 2, \"fn\": 5710, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5251164337990686, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4748835662009315, \"precision\": 0.9996833438885371, \"recall\": 0.5251164337990686, \"specificity\": 0.9997515219281898, \"npv\": 0.5849385767245766, \"accuracy\": 0.7154386489314004, \"f1\": 0.6885496183206107, \"f2\": 0.5802028964199074, \"f0_5\": 0.8466530787384682, \"p4\": 0.712442768666548, \"phi\": 0.5539398093164531}, {\"truth_threshold\": 9.84, \"match_probability\": 0.9989100884824688, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6311, \"tn\": 8047, \"fp\": 2, \"fn\": 5713, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5248669328010646, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47513306719893544, \"precision\": 0.9996831934104229, \"recall\": 0.5248669328010646, \"specificity\": 0.9997515219281898, \"npv\": 0.5848110465116279, \"accuracy\": 0.7152891944402929, \"f1\": 0.6883350602606751, \"f2\": 0.5799591979268136, \"f0_5\": 0.8465232321064492, \"p4\": 0.7122806090629299, \"phi\": 0.5537476545738649}, {\"truth_threshold\": 9.86, \"match_probability\": 0.9989250774870504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6305, \"tn\": 8047, \"fp\": 2, \"fn\": 5719, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5243679308050565, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47563206919494344, \"precision\": 0.9996828920247344, \"recall\": 0.5243679308050565, \"specificity\": 0.9997515219281898, \"npv\": 0.5845561528403312, \"accuracy\": 0.714990285458078, \"f1\": 0.6879057334569855, \"f2\": 0.5794717203095417, \"f0_5\": 0.846263287877161, \"p4\": 0.7119561836633319, \"phi\": 0.5533633963862019}, {\"truth_threshold\": 9.88, \"match_probability\": 0.9989398605741672, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6292, \"tn\": 8047, \"fp\": 2, \"fn\": 5732, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5232867598137059, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4767132401862941, \"precision\": 0.9996822370511599, \"recall\": 0.5232867598137059, \"specificity\": 0.9997515219281898, \"npv\": 0.5840046447492561, \"accuracy\": 0.7143426493299457, \"f1\": 0.6869745605415438, \"f2\": 0.5784151498437212, \"f0_5\": 0.8456989247311828, \"p4\": 0.7112527743163976, \"phi\": 0.5525310703772002}, {\"truth_threshold\": 9.9, \"match_probability\": 0.9989544405667166, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6280, \"tn\": 8047, \"fp\": 2, \"fn\": 5744, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.52228875582169, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47771124417831007, \"precision\": 0.9996816300541229, \"recall\": 0.52228875582169, \"specificity\": 0.9997515219281898, \"npv\": 0.5834964832136901, \"accuracy\": 0.7137448313655159, \"f1\": 0.6861138424560254, \"f2\": 0.5774394056419876, \"f0_5\": 0.845176571920758, \"p4\": 0.7106028778052862, \"phi\": 0.5517630507998701}, {\"truth_threshold\": 9.92, \"match_probability\": 0.998968820249061, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6272, \"tn\": 8047, \"fp\": 2, \"fn\": 5752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5216234198270127, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47837658017298734, \"precision\": 0.999681224099458, \"recall\": 0.5216234198270127, \"specificity\": 0.9997515219281898, \"npv\": 0.5831581998695557, \"accuracy\": 0.713346286055896, \"f1\": 0.685539403213466, \"f2\": 0.5767886702225492, \"f0_5\": 0.8448275862068966, \"p4\": 0.7101692939485406, \"phi\": 0.551251186596891}, {\"truth_threshold\": 9.94, \"match_probability\": 0.9989830023675484, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6268, \"tn\": 8047, \"fp\": 2, \"fn\": 5756, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.521290751829674, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.478709248170326, \"precision\": 0.9996810207336523, \"recall\": 0.521290751829674, \"specificity\": 0.9997515219281898, \"npv\": 0.5829892052452366, \"accuracy\": 0.713147013401086, \"f1\": 0.6852519951896797, \"f2\": 0.5764632306956554, \"f0_5\": 0.8446528676153514, \"p4\": 0.7099524057545552, \"phi\": 0.5509952988865228}, {\"truth_threshold\": 9.96, \"match_probability\": 0.9989969896310279, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6264, \"tn\": 8047, \"fp\": 2, \"fn\": 5760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5209580838323353, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.47904191616766467, \"precision\": 0.999680817108203, \"recall\": 0.5209580838323353, \"specificity\": 0.9997515219281898, \"npv\": 0.5828203085391468, \"accuracy\": 0.7129477407462761, \"f1\": 0.6849644614543466, \"f2\": 0.5761377432765534, \"f0_5\": 0.8444779982743744, \"p4\": 0.7097354532003862, \"phi\": 0.5507394406531038}, {\"truth_threshold\": 9.98, \"match_probability\": 0.9990107847113568, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6257, \"tn\": 8047, \"fp\": 2, \"fn\": 5767, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5203759148369926, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.4796240851630073, \"precision\": 0.9996804601374022, \"recall\": 0.5203759148369926, \"specificity\": 0.9997515219281898, \"npv\": 0.5825249746633849, \"accuracy\": 0.7125990136003587, \"f1\": 0.6844609746759285, \"f2\": 0.5755680250206973, \"f0_5\": 0.8441716135995683, \"p4\": 0.7093556309498519, \"phi\": 0.5502917594092174}, {\"truth_threshold\": 10.0, \"match_probability\": 0.9990243902439024, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6249, \"tn\": 8047, \"fp\": 2, \"fn\": 5775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5197105788423154, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.48028942115768464, \"precision\": 0.9996800511918094, \"recall\": 0.5197105788423154, \"specificity\": 0.9997515219281898, \"npv\": 0.5821878165243815, \"accuracy\": 0.7122004682907388, \"f1\": 0.6838850889192887, \"f2\": 0.5749167387344287, \"f0_5\": 0.8438208922977206, \"p4\": 0.7089213055625783, \"phi\": 0.549780233306643}, {\"truth_threshold\": 10.02, \"match_probability\": 0.9990378088280355, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6243, \"tn\": 8047, \"fp\": 2, \"fn\": 5781, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5192115768463074, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.48078842315369263, \"precision\": 0.999679743795036, \"recall\": 0.5192115768463074, \"specificity\": 0.9997515219281898, \"npv\": 0.5819352039340469, \"accuracy\": 0.7119015593085238, \"f1\": 0.6834528436148667, \"f2\": 0.5744281481754109, \"f0_5\": 0.8435574532482975, \"p4\": 0.7085953909159599, \"phi\": 0.5493966650490809}, {\"truth_threshold\": 10.040000000000001, \"match_probability\": 0.9990510430276189, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6239, \"tn\": 8047, \"fp\": 2, \"fn\": 5785, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5188789088489687, \"tn_rate\": 0.9997515219281898, \"fp_rate\": 0.00024847807181016274, \"fn_rate\": 0.48112109115103124, \"precision\": 0.9996795385354911, \"recall\": 0.5188789088489687, \"specificity\": 0.9997515219281898, \"npv\": 0.581766917293233, \"accuracy\": 0.7117022866537139, \"f1\": 0.6831645223104298, \"f2\": 0.5741023611903491, \"f0_5\": 0.843381637287769, \"p4\": 0.7083780329837934, \"phi\": 0.5491409890549998}, {\"truth_threshold\": 10.06, \"match_probability\": 0.9990640953714882, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6238, \"tn\": 8048, \"fp\": 1, \"fn\": 5786, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5187957418496341, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48120425815036594, \"precision\": 0.9998397179035102, \"recall\": 0.5187957418496341, \"specificity\": 0.9998757609640949, \"npv\": 0.581755096139945, \"accuracy\": 0.7117022866537139, \"f1\": 0.683129825329902, \"f2\": 0.5740314714272569, \"f0_5\": 0.8434288804759329, \"p4\": 0.708370589333094, \"phi\": 0.5492327887413406}, {\"truth_threshold\": 10.08, \"match_probability\": 0.9990769683539271, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6233, \"tn\": 8048, \"fp\": 1, \"fn\": 5791, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5183799068529608, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48162009314703924, \"precision\": 0.9998395893487327, \"recall\": 0.5183799068529608, \"specificity\": 0.9998757609640949, \"npv\": 0.5815449093142568, \"accuracy\": 0.7114531958352015, \"f1\": 0.6827691970643006, \"f2\": 0.5736241487207804, \"f0_5\": 0.8432088744588745, \"p4\": 0.7080987693301799, \"phi\": 0.5489133006341455}, {\"truth_threshold\": 10.1, \"match_probability\": 0.9990896644351354, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6225, \"tn\": 8048, \"fp\": 1, \"fn\": 5799, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5177145708582834, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48228542914171657, \"precision\": 0.9998393832316094, \"recall\": 0.5177145708582834, \"specificity\": 0.9998757609640949, \"npv\": 0.5812089261211815, \"accuracy\": 0.7110546505255816, \"f1\": 0.6821917808219178, \"f2\": 0.5729722764257575, \"f0_5\": 0.8428563691507799, \"p4\": 0.7076636440747994, \"phi\": 0.5484022130177294}, {\"truth_threshold\": 10.120000000000001, \"match_probability\": 0.9991021860416915, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6214, \"tn\": 8048, \"fp\": 1, \"fn\": 5810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5167997338656022, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48320026613439787, \"precision\": 0.9998390989541432, \"recall\": 0.5167997338656022, \"specificity\": 0.9998757609640949, \"npv\": 0.5807475826237553, \"accuracy\": 0.7105066507248543, \"f1\": 0.6813970064148254, \"f2\": 0.5720756384526154, \"f0_5\": 0.8423706756317102, \"p4\": 0.7070649164701931, \"phi\": 0.547699654003718}, {\"truth_threshold\": 10.14, \"match_probability\": 0.9991145355670089, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6211, \"tn\": 8048, \"fp\": 1, \"fn\": 5813, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5165502328675982, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48344976713240184, \"precision\": 0.9998390212491951, \"recall\": 0.5165502328675982, \"specificity\": 0.9998757609640949, \"npv\": 0.5806218887526152, \"accuracy\": 0.7103571962337468, \"f1\": 0.6811800833516122, \"f2\": 0.5718310377844885, \"f0_5\": 0.8422380125840746, \"p4\": 0.7069015402985348, \"phi\": 0.5475080842582453}, {\"truth_threshold\": 10.16, \"match_probability\": 0.9991267153717854, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6201, \"tn\": 8048, \"fp\": 1, \"fn\": 5823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5157185628742516, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4842814371257485, \"precision\": 0.9998387616897775, \"recall\": 0.5157185628742516, \"specificity\": 0.9998757609640949, \"npv\": 0.5802033018527863, \"accuracy\": 0.709859014596722, \"f1\": 0.6804564907275321, \"f2\": 0.571015507016833, \"f0_5\": 0.8417951781059948, \"p4\": 0.7063566831726891, \"phi\": 0.5468696330479755}, {\"truth_threshold\": 10.18, \"match_probability\": 0.9991387277844479, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6197, \"tn\": 8048, \"fp\": 1, \"fn\": 5827, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5153858948769129, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48461410512308717, \"precision\": 0.999838657631494, \"recall\": 0.5153858948769129, \"specificity\": 0.9998757609640949, \"npv\": 0.580036036036036, \"accuracy\": 0.7096597419419121, \"f1\": 0.6801668313028207, \"f2\": 0.5706892105941724, \"f0_5\": 0.8416177748804867, \"p4\": 0.7061386237135331, \"phi\": 0.5466143017150472}, {\"truth_threshold\": 10.200000000000001, \"match_probability\": 0.9991505751015896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6191, \"tn\": 8048, \"fp\": 1, \"fn\": 5833, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5148868928809048, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48511310711909517, \"precision\": 0.9998385012919897, \"recall\": 0.5148868928809048, \"specificity\": 0.9998757609640949, \"npv\": 0.5797853180606585, \"accuracy\": 0.7093608329596971, \"f1\": 0.6797321036451471, \"f2\": 0.570199675803124, \"f0_5\": 0.8413513807349424, \"p4\": 0.7058114091447876, \"phi\": 0.5462313571022299}, {\"truth_threshold\": 10.22, \"match_probability\": 0.9991622595884027, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6189, \"tn\": 8048, \"fp\": 1, \"fn\": 5835, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5147205588822356, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4852794411177645, \"precision\": 0.9998384491114701, \"recall\": 0.5147205588822356, \"specificity\": 0.9998757609640949, \"npv\": 0.5797017935604697, \"accuracy\": 0.7092611966322921, \"f1\": 0.6795871307785221, \"f2\": 0.5700364734922447, \"f0_5\": 0.8412625054371465, \"p4\": 0.7057023041163216, \"phi\": 0.5461037228236313}, {\"truth_threshold\": 10.24, \"match_probability\": 0.999173783479105, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6185, \"tn\": 8048, \"fp\": 1, \"fn\": 5839, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5143878908848969, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4856121091151031, \"precision\": 0.9998383446492078, \"recall\": 0.5143878908848969, \"specificity\": 0.9998757609640949, \"npv\": 0.579534816735076, \"accuracy\": 0.7090619239774822, \"f1\": 0.6792970895112576, \"f2\": 0.5697100327917173, \"f0_5\": 0.8410846388163621, \"p4\": 0.7054840436945644, \"phi\": 0.5458484750888081}, {\"truth_threshold\": 10.26, \"match_probability\": 0.9991851489773601, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6184, \"tn\": 8048, \"fp\": 1, \"fn\": 5840, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5143047238855623, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4856952761144378, \"precision\": 0.9998383185125304, \"recall\": 0.5143047238855623, \"specificity\": 0.9998757609640949, \"npv\": 0.5794930875576036, \"accuracy\": 0.7090121058137797, \"f1\": 0.6792245592838706, \"f2\": 0.569628415099206, \"f0_5\": 0.841040147970841, \"p4\": 0.7054294680834929, \"phi\": 0.5457846674850578}, {\"truth_threshold\": 10.28, \"match_probability\": 0.9991963582566927, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6181, \"tn\": 8048, \"fp\": 1, \"fn\": 5843, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5140552228875582, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4859447771124418, \"precision\": 0.9998382400517631, \"recall\": 0.5140552228875582, \"specificity\": 0.9998757609640949, \"npv\": 0.5793679360737168, \"accuracy\": 0.7088626513226722, \"f1\": 0.6790069207953422, \"f2\": 0.5693835439773021, \"f0_5\": 0.8409066173269482, \"p4\": 0.7052657160011766, \"phi\": 0.5455932550436468}, {\"truth_threshold\": 10.3, \"match_probability\": 0.9992074134608979, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6176, \"tn\": 8048, \"fp\": 1, \"fn\": 5848, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5136393878908849, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4863606121091151, \"precision\": 0.9998381091144568, \"recall\": 0.5136393878908849, \"specificity\": 0.9998757609640949, \"npv\": 0.5791594703511802, \"accuracy\": 0.7086135605041598, \"f1\": 0.6786440305477721, \"f2\": 0.5689753652829215, \"f0_5\": 0.8406838723728629, \"p4\": 0.7049927115666839, \"phi\": 0.5452742687913759}, {\"truth_threshold\": 10.32, \"match_probability\": 0.9992183167044456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6157, \"tn\": 8048, \"fp\": 1, \"fn\": 5867, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5120592149035262, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4879407850964737, \"precision\": 0.9998376096135109, \"recall\": 0.5120592149035262, \"specificity\": 0.9998757609640949, \"npv\": 0.5783686669062164, \"accuracy\": 0.7076670153938126, \"f1\": 0.6772632273677264, \"f2\": 0.5674236001032182, \"f0_5\": 0.8398352247926669, \"p4\": 0.7039543291430147, \"phi\": 0.544062511313391}, {\"truth_threshold\": 10.34, \"match_probability\": 0.9992290700728785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6154, \"tn\": 8048, \"fp\": 1, \"fn\": 5870, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5118097139055223, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48819028609447773, \"precision\": 0.9998375304630381, \"recall\": 0.5118097139055223, \"specificity\": 0.9998757609640949, \"npv\": 0.5782440005747952, \"accuracy\": 0.7075175609027051, \"f1\": 0.6770449419660047, \"f2\": 0.5671784851892131, \"f0_5\": 0.8397009060146272, \"p4\": 0.7037902336040871, \"phi\": 0.5438712372634255}, {\"truth_threshold\": 10.36, \"match_probability\": 0.999239675623206, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6151, \"tn\": 8048, \"fp\": 1, \"fn\": 5873, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5115602129075183, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4884397870924817, \"precision\": 0.9998374512353706, \"recall\": 0.5115602129075183, \"specificity\": 0.9998757609640949, \"npv\": 0.5781193879750018, \"accuracy\": 0.7073681064115976, \"f1\": 0.6768265845070423, \"f2\": 0.566933343164725, \"f0_5\": 0.839566499235641, \"p4\": 0.7036260996003815, \"phi\": 0.5436799784039469}, {\"truth_threshold\": 10.38, \"match_probability\": 0.9992501353842916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6147, \"tn\": 8048, \"fp\": 1, \"fn\": 5877, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5112275449101796, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.48877245508982037, \"precision\": 0.9998373454782042, \"recall\": 0.5112275449101796, \"specificity\": 0.9998757609640949, \"npv\": 0.5779533213644524, \"accuracy\": 0.7071688337567877, \"f1\": 0.676535329077702, \"f2\": 0.5666064449524372, \"f0_5\": 0.8393871531570898, \"p4\": 0.7034071943227962, \"phi\": 0.543424990156492}, {\"truth_threshold\": 10.4, \"match_probability\": 0.999260451357236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6140, \"tn\": 8048, \"fp\": 1, \"fn\": 5884, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5106453759148369, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.489354624085163, \"precision\": 0.9998371600716496, \"recall\": 0.5106453759148369, \"specificity\": 0.9998757609640949, \"npv\": 0.5776629342520815, \"accuracy\": 0.7068201066108704, \"f1\": 0.6760253234241673, \"f2\": 0.5660342570569906, \"f0_5\": 0.8390729200830873, \"p4\": 0.7030239448481241, \"phi\": 0.542978825279441}, {\"truth_threshold\": 10.42, \"match_probability\": 0.9992706255157543, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6137, \"tn\": 8048, \"fp\": 1, \"fn\": 5887, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.510395874916833, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.489604125083167, \"precision\": 0.9998370804822417, \"recall\": 0.510395874916833, \"specificity\": 0.9998757609640949, \"npv\": 0.5775385719411553, \"accuracy\": 0.7066706521197629, \"f1\": 0.6758066292258562, \"f2\": 0.5657889884574252, \"f0_5\": 0.8389381014873141, \"p4\": 0.7028596305360899, \"phi\": 0.5427876368156379}, {\"truth_threshold\": 10.44, \"match_probability\": 0.9992806598065492, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6127, \"tn\": 8048, \"fp\": 1, \"fn\": 5897, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5095642049234863, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49043579507651364, \"precision\": 0.9998368146214099, \"recall\": 0.5095642049234863, \"specificity\": 0.9998757609640949, \"npv\": 0.5771244173538903, \"accuracy\": 0.706172470482738, \"f1\": 0.6750771264874394, \"f2\": 0.5649712304514606, \"f0_5\": 0.8384880665644844, \"p4\": 0.7023116355186033, \"phi\": 0.5421504499084675}, {\"truth_threshold\": 10.46, \"match_probability\": 0.9992905561496781, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6116, \"tn\": 8048, \"fp\": 1, \"fn\": 5908, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5086493679308051, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49135063206919494, \"precision\": 0.9998365211705085, \"recall\": 0.5086493679308051, \"specificity\": 0.9998757609640949, \"npv\": 0.5766695328174262, \"accuracy\": 0.7056244706820106, \"f1\": 0.6742737445565294, \"f2\": 0.5640713482006161, \"f0_5\": 0.837991888633125, \"p4\": 0.7017083402136909, \"phi\": 0.5414497348904186}, {\"truth_threshold\": 10.48, \"match_probability\": 0.9993003164389153, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6111, \"tn\": 8048, \"fp\": 1, \"fn\": 5913, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5082335329341318, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49176646706586824, \"precision\": 0.9998363874345549, \"recall\": 0.5082335329341318, \"specificity\": 0.9998757609640949, \"npv\": 0.576463004082802, \"accuracy\": 0.7053753798634982, \"f1\": 0.6739082487869431, \"f2\": 0.5636621900826446, \"f0_5\": 0.8377659574468085, \"p4\": 0.7014339408514757, \"phi\": 0.5411312935858191}, {\"truth_threshold\": 10.5, \"match_probability\": 0.9993099425421107, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6107, \"tn\": 8048, \"fp\": 1, \"fn\": 5917, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5079008649367931, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4920991350632069, \"precision\": 0.9998362802881466, \"recall\": 0.5079008649367931, \"specificity\": 0.9998757609640949, \"npv\": 0.576297887576083, \"accuracy\": 0.7051761072086883, \"f1\": 0.6736157070372821, \"f2\": 0.5633348092391706, \"f0_5\": 0.8375850340136054, \"p4\": 0.7012143426862776, \"phi\": 0.5408765698607348}, {\"truth_threshold\": 10.52, \"match_probability\": 0.9993194363015417, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6098, \"tn\": 8048, \"fp\": 1, \"fn\": 5926, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5071523619427811, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4928476380572189, \"precision\": 0.999836038694868, \"recall\": 0.5071523619427811, \"specificity\": 0.9998757609640949, \"npv\": 0.5759267210533848, \"accuracy\": 0.704727743735366, \"f1\": 0.6729570159465872, \"f2\": 0.5625980256481226, \"f0_5\": 0.8371773750686436, \"p4\": 0.7007199903131949, \"phi\": 0.5403035362783029}, {\"truth_threshold\": 10.540000000000001, \"match_probability\": 0.9993287995342623, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6093, \"tn\": 8048, \"fp\": 1, \"fn\": 5931, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5067365269461078, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49326347305389223, \"precision\": 0.9998359041680341, \"recall\": 0.5067365269461078, \"specificity\": 0.9998757609640949, \"npv\": 0.5757207239430574, \"accuracy\": 0.7044786529168535, \"f1\": 0.6725907936858373, \"f2\": 0.5621885956818601, \"f0_5\": 0.8369505494505495, \"p4\": 0.7004451961600094, \"phi\": 0.5399852407142641}, {\"truth_threshold\": 10.56, \"match_probability\": 0.9993380340324456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6085, \"tn\": 8048, \"fp\": 1, \"fn\": 5939, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5060711909514305, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4939288090485695, \"precision\": 0.9998356884653302, \"recall\": 0.5060711909514305, \"specificity\": 0.9998757609640949, \"npv\": 0.5753914349038393, \"accuracy\": 0.7040801076072336, \"f1\": 0.6720044174489233, \"f2\": 0.5615333505592263, \"f0_5\": 0.8365871095468543, \"p4\": 0.7000052959147771, \"phi\": 0.5394760511160501}, {\"truth_threshold\": 10.58, \"match_probability\": 0.9993471415637232, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6081, \"tn\": 8048, \"fp\": 1, \"fn\": 5943, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5057385229540918, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49426147704590817, \"precision\": 0.9998355804011838, \"recall\": 0.5057385229540918, \"specificity\": 0.9998757609640949, \"npv\": 0.575226931598885, \"accuracy\": 0.7038808349524237, \"f1\": 0.6717110350160168, \"f2\": 0.5612056554320942, \"f0_5\": 0.8364051496478874, \"p4\": 0.6997852395079803, \"phi\": 0.539221494576309}, {\"truth_threshold\": 10.6, \"match_probability\": 0.9993561238715196, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6073, \"tn\": 8048, \"fp\": 1, \"fn\": 5951, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5050731869594145, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4949268130405855, \"precision\": 0.9998353638459005, \"recall\": 0.5050731869594145, \"specificity\": 0.9998757609640949, \"npv\": 0.5748982070147868, \"accuracy\": 0.7034822896428038, \"f1\": 0.6711238810918333, \"f2\": 0.5605501199926158, \"f0_5\": 0.8360407488986784, \"p4\": 0.6993449133831444, \"phi\": 0.5387124575712221}, {\"truth_threshold\": 10.620000000000001, \"match_probability\": 0.9993649826753817, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6066, \"tn\": 8048, \"fp\": 1, \"fn\": 5958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5044910179640718, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49550898203592814, \"precision\": 0.9998351738915444, \"recall\": 0.5044910179640718, \"specificity\": 0.9998757609640949, \"npv\": 0.5746108810509781, \"accuracy\": 0.7031335624968864, \"f1\": 0.6706096954286662, \"f2\": 0.5599763676310396, \"f0_5\": 0.8357213711010691, \"p4\": 0.6989593939406218, \"phi\": 0.5382671329361963}, {\"truth_threshold\": 10.64, \"match_probability\": 0.9993737196713037, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6065, \"tn\": 8048, \"fp\": 1, \"fn\": 5959, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5044078509647372, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49559214903526283, \"precision\": 0.9998351467194198, \"recall\": 0.5044078509647372, \"specificity\": 0.9998757609640949, \"npv\": 0.5745698579281787, \"accuracy\": 0.7030837443331839, \"f1\": 0.6705362078496406, \"f2\": 0.5598943909013699, \"f0_5\": 0.8356757054673721, \"p4\": 0.698904301849856, \"phi\": 0.5382035214058791}, {\"truth_threshold\": 10.66, \"match_probability\": 0.9993823365320493, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6055, \"tn\": 8048, \"fp\": 1, \"fn\": 5969, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5035761809713906, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49642381902860944, \"precision\": 0.9998348745046235, \"recall\": 0.5035761809713906, \"specificity\": 0.9998757609640949, \"npv\": 0.5741599486338018, \"accuracy\": 0.702585562696159, \"f1\": 0.6698008849557522, \"f2\": 0.5590744570837642, \"f0_5\": 0.835218494813507, \"p4\": 0.6983531342556236, \"phi\": 0.5375674919207408}, {\"truth_threshold\": 10.68, \"match_probability\": 0.9993908349074672, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6051, \"tn\": 8048, \"fp\": 1, \"fn\": 5973, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5032435129740519, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4967564870259481, \"precision\": 0.9998347653668209, \"recall\": 0.5032435129740519, \"specificity\": 0.9998757609640949, \"npv\": 0.5739961486341916, \"accuracy\": 0.7023862900413491, \"f1\": 0.6695065279929188, \"f2\": 0.5587463987589569, \"f0_5\": 0.8350353278869508, \"p4\": 0.6981325413037226, \"phi\": 0.5373131236210898}, {\"truth_threshold\": 10.700000000000001, \"match_probability\": 0.9993992164248033, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6043, \"tn\": 8048, \"fp\": 1, \"fn\": 5981, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5025781769793746, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49742182302062543, \"precision\": 0.9998345466578424, \"recall\": 0.5025781769793746, \"specificity\": 0.9998757609640949, \"npv\": 0.5736688288545156, \"accuracy\": 0.7019877447317292, \"f1\": 0.6689174230684083, \"f2\": 0.5580901366826746, \"f0_5\": 0.8346685082872928, \"p4\": 0.697691138719484, \"phi\": 0.5368044610936618}, {\"truth_threshold\": 10.72, \"match_probability\": 0.9994074826890101, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6032, \"tn\": 8048, \"fp\": 1, \"fn\": 5992, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5016633399866933, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49833666001330673, \"precision\": 0.9998342449859108, \"recall\": 0.5016633399866933, \"specificity\": 0.9998757609640949, \"npv\": 0.5732193732193732, \"accuracy\": 0.7014397449310018, \"f1\": 0.6681065514758819, \"f2\": 0.5571874595872822, \"f0_5\": 0.8341630711361876, \"p4\": 0.6970837365446878, \"phi\": 0.5361052102631296}, {\"truth_threshold\": 10.74, \"match_probability\": 0.9994156352830494, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6023, \"tn\": 8048, \"fp\": 1, \"fn\": 6001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5009148369926814, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.4990851630073187, \"precision\": 0.9998339973439575, \"recall\": 0.5009148369926814, \"specificity\": 0.9998757609640949, \"npv\": 0.5728521602961065, \"accuracy\": 0.7009913814576795, \"f1\": 0.6674423758865248, \"f2\": 0.5564486326681448, \"f0_5\": 0.83374861572536, \"p4\": 0.6965863612367716, \"phi\": 0.5355332327000223}, {\"truth_threshold\": 10.76, \"match_probability\": 0.9994236757681928, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6022, \"tn\": 8048, \"fp\": 1, \"fn\": 6002, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.5008316699933466, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49916833000665334, \"precision\": 0.9998339697825004, \"recall\": 0.5008316699933466, \"specificity\": 0.9998757609640949, \"npv\": 0.5728113879003559, \"accuracy\": 0.7009415632939769, \"f1\": 0.6673685377070981, \"f2\": 0.5563665256194682, \"f0_5\": 0.8337025141211651, \"p4\": 0.6965310744587696, \"phi\": 0.5354696871860145}, {\"truth_threshold\": 10.78, \"match_probability\": 0.9994316056843171, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6015, \"tn\": 8048, \"fp\": 1, \"fn\": 6009, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.500249500998004, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.49975049900199603, \"precision\": 0.9998337765957447, \"recall\": 0.500249500998004, \"specificity\": 0.9998757609640949, \"npv\": 0.5725261435583695, \"accuracy\": 0.7005928361480596, \"f1\": 0.6668514412416852, \"f2\": 0.555791691306919, \"f0_5\": 0.8333795167368654, \"p4\": 0.6961439386474038, \"phi\": 0.5350249106384509}, {\"truth_threshold\": 10.8, \"match_probability\": 0.9994394265501966, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6009, \"tn\": 8048, \"fp\": 1, \"fn\": 6015, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49975049900199603, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.500249500998004, \"precision\": 0.9998336106489185, \"recall\": 0.49975049900199603, \"specificity\": 0.9998757609640949, \"npv\": 0.5722818744222428, \"accuracy\": 0.7002939271658447, \"f1\": 0.6664078961960741, \"f2\": 0.5552988577976564, \"f0_5\": 0.8331022626441881, \"p4\": 0.6958119287227907, \"phi\": 0.5346437319138702}, {\"truth_threshold\": 10.82, \"match_probability\": 0.9994471398637907, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6001, \"tn\": 8048, \"fp\": 1, \"fn\": 6023, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4990851630073187, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5009148369926814, \"precision\": 0.9998333888703765, \"recall\": 0.4990851630073187, \"specificity\": 0.9998757609640949, \"npv\": 0.5719565062895317, \"accuracy\": 0.6998953818562248, \"f1\": 0.6658160434927327, \"f2\": 0.5546415763983881, \"f0_5\": 0.8327320159857904, \"p4\": 0.6953689905304302, \"phi\": 0.5341355768028427}, {\"truth_threshold\": 10.84, \"match_probability\": 0.9994547471025279, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5993, \"tn\": 8048, \"fp\": 1, \"fn\": 6031, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49841982701264137, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5015801729873586, \"precision\": 0.9998331664998331, \"recall\": 0.49841982701264137, \"specificity\": 0.9998757609640949, \"npv\": 0.5716315079195966, \"accuracy\": 0.6994968365466049, \"f1\": 0.6652236652236653, \"f2\": 0.5539841005731189, \"f0_5\": 0.8323611111111111, \"p4\": 0.6949257560194227, \"phi\": 0.5336275161081594}, {\"truth_threshold\": 10.86, \"match_probability\": 0.999462249723586, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5986, \"tn\": 8048, \"fp\": 1, \"fn\": 6038, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49783765801729873, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5021623419827013, \"precision\": 0.9998329714381159, \"recall\": 0.49783765801729873, \"specificity\": 0.9998757609640949, \"npv\": 0.5713474371716598, \"accuracy\": 0.6991481094006875, \"f1\": 0.664704902559547, \"f2\": 0.5534086496681028, \"f0_5\": 0.8320360280217948, \"p4\": 0.694537681779043, \"phi\": 0.5331830398881429}, {\"truth_threshold\": 10.88, \"match_probability\": 0.9994696491641683, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5980, \"tn\": 8048, \"fp\": 1, \"fn\": 6044, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49733865602129074, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5026613439787092, \"precision\": 0.99983280387895, \"recall\": 0.49733865602129074, \"specificity\": 0.9998757609640949, \"npv\": 0.5711041725801873, \"accuracy\": 0.6988492004184725, \"f1\": 0.6642599277978339, \"f2\": 0.552915287460473, \"f0_5\": 0.831756982307778, \"p4\": 0.6942048647670517, \"phi\": 0.5328021170054872}, {\"truth_threshold\": 10.9, \"match_probability\": 0.9994769468417765, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5976, \"tn\": 8048, \"fp\": 1, \"fn\": 6048, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49700598802395207, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5029940119760479, \"precision\": 0.9998326919859462, \"recall\": 0.49700598802395207, \"specificity\": 0.9998757609640949, \"npv\": 0.5709421112372304, \"accuracy\": 0.6986499277636626, \"f1\": 0.6639631131603799, \"f2\": 0.5525863184953673, \"f0_5\": 0.8315707447400645, \"p4\": 0.6939828931774347, \"phi\": 0.532548197352916}, {\"truth_threshold\": 10.92, \"match_probability\": 0.9994841441544793, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5969, \"tn\": 8048, \"fp\": 1, \"fn\": 6055, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49642381902860944, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5035761809713906, \"precision\": 0.9998324958123953, \"recall\": 0.49642381902860944, \"specificity\": 0.9998757609640949, \"npv\": 0.5706587250939517, \"accuracy\": 0.6983012006177453, \"f1\": 0.6634433700122263, \"f2\": 0.5520105056782451, \"f0_5\": 0.8312444295900179, \"p4\": 0.6935942622211153, \"phi\": 0.5321038933566875}, {\"truth_threshold\": 10.94, \"match_probability\": 0.9994912424811782, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5965, \"tn\": 8048, \"fp\": 1, \"fn\": 6059, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49609115103127077, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5039088489687292, \"precision\": 0.999832383506537, \"recall\": 0.49609115103127077, \"specificity\": 0.9998757609640949, \"npv\": 0.5704969164244701, \"accuracy\": 0.6981019279629352, \"f1\": 0.6631461923290717, \"f2\": 0.5516814028337834, \"f0_5\": 0.8310577351761035, \"p4\": 0.6933720838785999, \"phi\": 0.5318500368593203}, {\"truth_threshold\": 10.96, \"match_probability\": 0.9994982431818683, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5958, \"tn\": 8048, \"fp\": 1, \"fn\": 6066, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49550898203592814, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5044910179640718, \"precision\": 0.9998321866084914, \"recall\": 0.49550898203592814, \"specificity\": 0.9998757609640949, \"npv\": 0.5702139719427519, \"accuracy\": 0.6977532008170179, \"f1\": 0.6626258132680866, \"f2\": 0.551105355656276, \"f0_5\": 0.8307306190741773, \"p4\": 0.6929830900724618, \"phi\": 0.5314058427906659}, {\"truth_threshold\": 10.98, \"match_probability\": 0.9995051475978975, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5953, \"tn\": 8048, \"fp\": 1, \"fn\": 6071, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49509314703925483, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5049068529607452, \"precision\": 0.9998320456835741, \"recall\": 0.49509314703925483, \"specificity\": 0.9998757609640949, \"npv\": 0.5700120405127842, \"accuracy\": 0.6975041099985054, \"f1\": 0.6622538658360217, \"f2\": 0.5506938020351526, \"f0_5\": 0.8304966517857143, \"p4\": 0.6927050953727428, \"phi\": 0.5310886037910982}, {\"truth_threshold\": 11.0, \"match_probability\": 0.9995119570522206, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5945, \"tn\": 8048, \"fp\": 1, \"fn\": 6079, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4944278110445775, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5055721889554224, \"precision\": 0.9998318197107299, \"recall\": 0.4944278110445775, \"specificity\": 0.9998757609640949, \"npv\": 0.5696892475401713, \"accuracy\": 0.6971055646888855, \"f1\": 0.6616583194212576, \"f2\": 0.5500351578401984, \"f0_5\": 0.8301217605004468, \"p4\": 0.6922600569024948, \"phi\": 0.5305810945334481}, {\"truth_threshold\": 11.02, \"match_probability\": 0.9995186728496503, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5938, \"tn\": 8048, \"fp\": 1, \"fn\": 6086, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49384564204923487, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5061543579507651, \"precision\": 0.9998316214850985, \"recall\": 0.49384564204923487, \"specificity\": 0.9998757609640949, \"npv\": 0.5694071034385171, \"accuracy\": 0.6967568375429681, \"f1\": 0.6611367811612759, \"f2\": 0.5494586841861756, \"f0_5\": 0.829793180547792, \"p4\": 0.6918703980548938, \"phi\": 0.5301370972859817}, {\"truth_threshold\": 11.040000000000001, \"match_probability\": 0.9995252962771056, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5932, \"tn\": 8048, \"fp\": 1, \"fn\": 6092, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49334664005322687, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5066533599467731, \"precision\": 0.9998314512051238, \"recall\": 0.49334664005322687, \"specificity\": 0.9998757609640949, \"npv\": 0.5691654879773692, \"accuracy\": 0.6964579285607533, \"f1\": 0.6606894247368714, \"f2\": 0.5489644450202669, \"f0_5\": 0.8295111309989932, \"p4\": 0.6915362182309805, \"phi\": 0.5297565823235199}, {\"truth_threshold\": 11.06, \"match_probability\": 0.9995318286038558, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5929, \"tn\": 8048, \"fp\": 1, \"fn\": 6095, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4930971390552229, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5069028609447771, \"precision\": 0.999831365935919, \"recall\": 0.4930971390552229, \"specificity\": 0.9998757609640949, \"npv\": 0.5690447571236654, \"accuracy\": 0.6963084740696458, \"f1\": 0.6604656343990197, \"f2\": 0.5487172842705365, \"f0_5\": 0.8293699641897941, \"p4\": 0.691369063574274, \"phi\": 0.52956634347023}, {\"truth_threshold\": 11.08, \"match_probability\": 0.9995382710817619, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5923, \"tn\": 8048, \"fp\": 1, \"fn\": 6101, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4925981370592149, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.507401862940785, \"precision\": 0.99983119513842, \"recall\": 0.4925981370592149, \"specificity\": 0.9998757609640949, \"npv\": 0.568803449006997, \"accuracy\": 0.6960095650874308, \"f1\": 0.6600178292846, \"f2\": 0.5482228804146613, \"f0_5\": 0.8290873460246361, \"p4\": 0.6910346244366815, \"phi\": 0.5291859028294226}, {\"truth_threshold\": 11.1, \"match_probability\": 0.999544624945514, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5908, \"tn\": 8048, \"fp\": 1, \"fn\": 6116, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49135063206919494, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5086493679308051, \"precision\": 0.9998307666271788, \"recall\": 0.49135063206919494, \"specificity\": 0.9998757609640949, \"npv\": 0.5682010731431799, \"accuracy\": 0.6952622926318935, \"f1\": 0.6588970055205488, \"f2\": 0.5469863901490603, \"f0_5\": 0.8283791362871564, \"p4\": 0.6901977661510601, \"phi\": 0.5282350156686482}, {\"truth_threshold\": 11.120000000000001, \"match_probability\": 0.9995508914128666, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5899, \"tn\": 8048, \"fp\": 1, \"fn\": 6125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49060212907518297, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.509397870924817, \"precision\": 0.9998305084745762, \"recall\": 0.49060212907518297, \"specificity\": 0.9998757609640949, \"npv\": 0.5678402596486277, \"accuracy\": 0.6948139291585712, \"f1\": 0.6582236108011604, \"f2\": 0.5462441662345359, \"f0_5\": 0.8279530653492028, \"p4\": 0.689695127038058, \"phi\": 0.5276646288941919}, {\"truth_threshold\": 11.14, \"match_probability\": 0.9995570716848697, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5897, \"tn\": 8048, \"fp\": 1, \"fn\": 6127, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49043579507651364, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5095642049234863, \"precision\": 0.9998304510003391, \"recall\": 0.49043579507651364, \"specificity\": 0.9998757609640949, \"npv\": 0.5677601410934744, \"accuracy\": 0.6947142928311663, \"f1\": 0.6580738756835175, \"f2\": 0.5460791939845168, \"f0_5\": 0.8278582659478886, \"p4\": 0.6895833758337863, \"phi\": 0.527537890964742}, {\"truth_threshold\": 11.16, \"match_probability\": 0.9995631669460973, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5894, \"tn\": 8048, \"fp\": 1, \"fn\": 6130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.49018629407850967, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5098137059214903, \"precision\": 0.999830364715861, \"recall\": 0.49018629407850967, \"specificity\": 0.9998757609640949, \"npv\": 0.5676400056425448, \"accuracy\": 0.6945648383400588, \"f1\": 0.6578492103353982, \"f2\": 0.5458317126928562, \"f0_5\": 0.8277159869677564, \"p4\": 0.6894157123778764, \"phi\": 0.527347794035045}, {\"truth_threshold\": 11.18, \"match_probability\": 0.9995691783648718, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5890, \"tn\": 8048, \"fp\": 1, \"fn\": 6134, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.489853626081171, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.510146373918829, \"precision\": 0.9998302495331862, \"recall\": 0.489853626081171, \"specificity\": 0.9998757609640949, \"npv\": 0.5674799041037936, \"accuracy\": 0.6943655656852489, \"f1\": 0.6575495394920458, \"f2\": 0.5455016948524645, \"f0_5\": 0.8275261324041812, \"p4\": 0.689192092585173, \"phi\": 0.5270943500031031}, {\"truth_threshold\": 11.200000000000001, \"match_probability\": 0.9995751070934877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5883, \"tn\": 8048, \"fp\": 1, \"fn\": 6141, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48927145708582837, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5107285429141717, \"precision\": 0.9998300475866757, \"recall\": 0.48927145708582837, \"specificity\": 0.9998757609640949, \"npv\": 0.5671999436182958, \"accuracy\": 0.6940168385393315, \"f1\": 0.6570247933884298, \"f2\": 0.5449240459429419, \"f0_5\": 0.827193475815523, \"p4\": 0.6888005690698276, \"phi\": 0.5266508736808326}, {\"truth_threshold\": 11.22, \"match_probability\": 0.9995809542684295, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5879, \"tn\": 8048, \"fp\": 1, \"fn\": 6145, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4889387890884897, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5110612109115104, \"precision\": 0.9998299319727891, \"recall\": 0.4889387890884897, \"specificity\": 0.9998757609640949, \"npv\": 0.5670400901853027, \"accuracy\": 0.6938175658845215, \"f1\": 0.6567247542448614, \"f2\": 0.5445938935823329, \"f0_5\": 0.8270031510240828, \"p4\": 0.6885767331384139, \"phi\": 0.5263974874745379}, {\"truth_threshold\": 11.24, \"match_probability\": 0.9995867210105881, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5875, \"tn\": 8048, \"fp\": 1, \"fn\": 6149, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48860612109115104, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.511393878908849, \"precision\": 0.9998298162014976, \"recall\": 0.48860612109115104, \"specificity\": 0.9998757609640949, \"npv\": 0.5668803268296119, \"accuracy\": 0.6936182932297116, \"f1\": 0.6564245810055865, \"f2\": 0.5442636922848885, \"f0_5\": 0.8268126548074758, \"p4\": 0.6883528183074014, \"phi\": 0.5261441221259}, {\"truth_threshold\": 11.26, \"match_probability\": 0.9995924084254744, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5871, \"tn\": 8048, \"fp\": 1, \"fn\": 6153, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48827345309381237, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5117265469061876, \"precision\": 0.9998297002724795, \"recall\": 0.48827345309381237, \"specificity\": 0.9998757609640949, \"npv\": 0.5667206534751074, \"accuracy\": 0.6934190205749016, \"f1\": 0.6561242735806885, \"f2\": 0.5439334420397273, \"f0_5\": 0.8266219869339941, \"p4\": 0.6881288244143623, \"phi\": 0.5258907775442672}, {\"truth_threshold\": 11.28, \"match_probability\": 0.9995980176034294, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5867, \"tn\": 8048, \"fp\": 1, \"fn\": 6157, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4879407850964737, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5120592149035262, \"precision\": 0.9998295841854125, \"recall\": 0.4879407850964737, \"specificity\": 0.9998757609640949, \"npv\": 0.5665610700457585, \"accuracy\": 0.6932197479200917, \"f1\": 0.6558238318801699, \"f2\": 0.5436031428359647, \"f0_5\": 0.8264311471715123, \"p4\": 0.6879047512965827, \"phi\": 0.5256374536389465}, {\"truth_threshold\": 11.3, \"match_probability\": 0.9996035496198316, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5861, \"tn\": 8048, \"fp\": 1, \"fn\": 6163, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4874417831004657, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5125582168995343, \"precision\": 0.9998294097577619, \"recall\": 0.4874417831004657, \"specificity\": 0.9998757609640949, \"npv\": 0.5663218633452959, \"accuracy\": 0.6929208389378767, \"f1\": 0.6553729173655373, \"f2\": 0.5431076022091256, \"f0_5\": 0.8261445647271087, \"p4\": 0.6875684927168813, \"phi\": 0.5252575063505579}, {\"truth_threshold\": 11.32, \"match_probability\": 0.999609005535302, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5850, \"tn\": 8048, \"fp\": 1, \"fn\": 6174, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4865269461077844, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5134730538922155, \"precision\": 0.9998290890446078, \"recall\": 0.4865269461077844, \"specificity\": 0.9998757609640949, \"npv\": 0.5658838419350303, \"accuracy\": 0.6923728391371494, \"f1\": 0.6545454545454545, \"f2\": 0.5421988247724618, \"f0_5\": 0.8256181551315344, \"p4\": 0.6869515529010644, \"phi\": 0.524561055601789}, {\"truth_threshold\": 11.34, \"match_probability\": 0.9996143863959054, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5847, \"tn\": 8048, \"fp\": 1, \"fn\": 6177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48627744510978044, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5137225548902196, \"precision\": 0.999829001367989, \"recall\": 0.48627744510978044, \"specificity\": 0.9998757609640949, \"npv\": 0.5657644991212654, \"accuracy\": 0.6922233846460419, \"f1\": 0.654319606087735, \"f2\": 0.5419509120569479, \"f0_5\": 0.8254743618703411, \"p4\": 0.6867831916214494, \"phi\": 0.5243711410798625}, {\"truth_threshold\": 11.36, \"match_probability\": 0.9996196932333503, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5846, \"tn\": 8048, \"fp\": 1, \"fn\": 6178, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4861942781104458, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5138057218895542, \"precision\": 0.9998289721224559, \"recall\": 0.4861942781104458, \"specificity\": 0.9998757609640949, \"npv\": 0.5657247293687614, \"accuracy\": 0.6921735664823394, \"f1\": 0.6542443064182195, \"f2\": 0.5418682683573401, \"f0_5\": 0.8254264091268496, \"p4\": 0.686727061172457, \"phi\": 0.5243078387575253}, {\"truth_threshold\": 11.38, \"match_probability\": 0.9996249270651847, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5839, \"tn\": 8048, \"fp\": 1, \"fn\": 6185, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4856121091151031, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5143878908848969, \"precision\": 0.9998287671232877, \"recall\": 0.4856121091151031, \"specificity\": 0.9998757609640949, \"npv\": 0.5654464975760557, \"accuracy\": 0.691824839336422, \"f1\": 0.65371697268249, \"f2\": 0.5412896766538119, \"f0_5\": 0.8250904363554149, \"p4\": 0.6863340074509426, \"phi\": 0.5238647576114842}, {\"truth_threshold\": 11.4, \"match_probability\": 0.9996300888949902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5835, \"tn\": 8048, \"fp\": 1, \"fn\": 6189, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4852794411177645, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5147205588822356, \"precision\": 0.9998286497601097, \"recall\": 0.4852794411177645, \"specificity\": 0.9998757609640949, \"npv\": 0.5652876308210999, \"accuracy\": 0.6916255666816121, \"f1\": 0.6534154535274356, \"f2\": 0.5409589853890083, \"f0_5\": 0.8248982130739652, \"p4\": 0.6861092946429325, \"phi\": 0.5236115958466977}, {\"truth_threshold\": 11.42, \"match_probability\": 0.9996351797125727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5829, \"tn\": 8048, \"fp\": 1, \"fn\": 6195, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4847804391217565, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5152195608782435, \"precision\": 0.9998284734133791, \"recall\": 0.4847804391217565, \"specificity\": 0.9998757609640949, \"npv\": 0.565049497999017, \"accuracy\": 0.6913266576993972, \"f1\": 0.6529629214741794, \"f2\": 0.5404628565070653, \"f0_5\": 0.8246095518334088, \"p4\": 0.6857720740626014, \"phi\": 0.5232318904051397}, {\"truth_threshold\": 11.44, \"match_probability\": 0.9996402004941516, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5822, \"tn\": 8048, \"fp\": 1, \"fn\": 6202, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48419827012641387, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5158017298735862, \"precision\": 0.9998282672162115, \"recall\": 0.48419827012641387, \"specificity\": 0.9998757609640949, \"npv\": 0.5647719298245614, \"accuracy\": 0.6909779305534798, \"f1\": 0.6524345828430549, \"f2\": 0.53988389992396, \"f0_5\": 0.8242722845169328, \"p4\": 0.6853784198092051, \"phi\": 0.5227889567846881}, {\"truth_threshold\": 11.46, \"match_probability\": 0.9996451522025451, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5813, \"tn\": 8048, \"fp\": 1, \"fn\": 6211, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48344976713240184, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5165502328675982, \"precision\": 0.999828001375989, \"recall\": 0.48344976713240184, \"specificity\": 0.9998757609640949, \"npv\": 0.5644154569044112, \"accuracy\": 0.6905295670801574, \"f1\": 0.6517546810180513, \"f2\": 0.5391393062511594, \"f0_5\": 0.8238378684807256, \"p4\": 0.6848719272000385, \"phi\": 0.5222195586612667}, {\"truth_threshold\": 11.48, \"match_probability\": 0.9996500357873543, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5809, \"tn\": 8048, \"fp\": 1, \"fn\": 6215, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48311709913506323, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5168829008649368, \"precision\": 0.999827882960413, \"recall\": 0.48311709913506323, \"specificity\": 0.9998757609640949, \"npv\": 0.5642571688985487, \"accuracy\": 0.6903302944253474, \"f1\": 0.6514522821576764, \"f2\": 0.5388082959225318, \"f0_5\": 0.8236445099818511, \"p4\": 0.6846466868596013, \"phi\": 0.5219665243447533}, {\"truth_threshold\": 11.5, \"match_probability\": 0.9996548521851435, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5803, \"tn\": 8048, \"fp\": 1, \"fn\": 6221, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48261809713905524, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5173819028609448, \"precision\": 0.9998277050310131, \"recall\": 0.48261809713905524, \"specificity\": 0.9998757609640949, \"npv\": 0.5640199032868456, \"accuracy\": 0.6900313854431326, \"f1\": 0.6509984294368409, \"f2\": 0.5383116883116883, \"f0_5\": 0.8233541430192962, \"p4\": 0.6843086729516726, \"phi\": 0.5215870089635262}, {\"truth_threshold\": 11.52, \"match_probability\": 0.9996596023196187, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5794, \"tn\": 8048, \"fp\": 1, \"fn\": 6230, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48186959414504327, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5181304058549567, \"precision\": 0.9998274374460742, \"recall\": 0.48186959414504327, \"specificity\": 0.9998757609640949, \"npv\": 0.5636643787645329, \"accuracy\": 0.6895830219698101, \"f1\": 0.6503170772770638, \"f2\": 0.5375665695570689, \"f0_5\": 0.8229178502442904, \"p4\": 0.68380130582566, \"phi\": 0.5210178164914057}, {\"truth_threshold\": 11.540000000000001, \"match_probability\": 0.9996642871018043, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5791, \"tn\": 8048, \"fp\": 1, \"fn\": 6233, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48162009314703924, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5183799068529608, \"precision\": 0.9998273480662984, \"recall\": 0.48162009314703924, \"specificity\": 0.9998757609640949, \"npv\": 0.5635459701701562, \"accuracy\": 0.6894335674787028, \"f1\": 0.6500898069151325, \"f2\": 0.5373181413301663, \"f0_5\": 0.8227722209593089, \"p4\": 0.6836320908295171, \"phi\": 0.5208281070062228}, {\"truth_threshold\": 11.56, \"match_probability\": 0.9996689074302161, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5783, \"tn\": 8048, \"fp\": 1, \"fn\": 6241, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48095475715236197, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5190452428476381, \"precision\": 0.9998271092669433, \"recall\": 0.48095475715236197, \"specificity\": 0.9998757609640949, \"npv\": 0.5632304569948912, \"accuracy\": 0.6890350221690829, \"f1\": 0.6494833782569631, \"f2\": 0.5366555308092057, \"f0_5\": 0.8223833902161547, \"p4\": 0.683180623660589, \"phi\": 0.5203222667876796}, {\"truth_threshold\": 11.58, \"match_probability\": 0.9996734641910328, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5774, \"tn\": 8048, \"fp\": 1, \"fn\": 6250, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.48020625415834994, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5197937458416501, \"precision\": 0.9998268398268398, \"recall\": 0.48020625415834994, \"specificity\": 0.9998757609640949, \"npv\": 0.5628759267030354, \"accuracy\": 0.6885866586957605, \"f1\": 0.6488004944097983, \"f2\": 0.5359098587366116, \"f0_5\": 0.8219451087575447, \"p4\": 0.6826723267655223, \"phi\": 0.5197532857718526}, {\"truth_threshold\": 11.6, \"match_probability\": 0.9996779582582649, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5767, \"tn\": 8048, \"fp\": 1, \"fn\": 6257, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4796240851630073, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5203759148369926, \"precision\": 0.9998266296809986, \"recall\": 0.4796240851630073, \"specificity\": 0.9998757609640949, \"npv\": 0.5626004893393918, \"accuracy\": 0.688237931549843, \"f1\": 0.6482688848920863, \"f2\": 0.5353297192930343, \"f0_5\": 0.8216036015500342, \"p4\": 0.6822766934243976, \"phi\": 0.5193108096583265}, {\"truth_threshold\": 11.620000000000001, \"match_probability\": 0.9996823904939214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5760, \"tn\": 8048, \"fp\": 1, \"fn\": 6264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47904191616766467, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5209580838323353, \"precision\": 0.9998264190244749, \"recall\": 0.47904191616766467, \"specificity\": 0.9998757609640949, \"npv\": 0.5623253214086081, \"accuracy\": 0.6878892044039256, \"f1\": 0.6477368569018837, \"f2\": 0.5347494290435784, \"f0_5\": 0.8212615489905327, \"p4\": 0.681880804186207, \"phi\": 0.5188683895977746}, {\"truth_threshold\": 11.64, \"match_probability\": 0.9996867617481742, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5756, \"tn\": 8048, \"fp\": 1, \"fn\": 6268, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.478709248170326, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.521290751829674, \"precision\": 0.9998262984193156, \"recall\": 0.478709248170326, \"specificity\": 0.9998757609640949, \"npv\": 0.5621682034087734, \"accuracy\": 0.6876899317491157, \"f1\": 0.6474326528316743, \"f2\": 0.5344177668839247, \"f0_5\": 0.8210658450302408, \"p4\": 0.6816544665195977, \"phi\": 0.5186156031116788}, {\"truth_threshold\": 11.66, \"match_probability\": 0.9996910728595202, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5753, \"tn\": 8048, \"fp\": 1, \"fn\": 6271, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47845974717232204, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.521540252827678, \"precision\": 0.9998262078554049, \"recall\": 0.47845974717232204, \"specificity\": 0.9998757609640949, \"npv\": 0.5620504225155388, \"accuracy\": 0.6875404772580083, \"f1\": 0.6472044099448757, \"f2\": 0.5341689879294336, \"f0_5\": 0.8209189497716894, \"p4\": 0.6814846581353884, \"phi\": 0.5184260250975669}, {\"truth_threshold\": 11.68, \"match_probability\": 0.9996953246549412, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5744, \"tn\": 8048, \"fp\": 1, \"fn\": 6280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47771124417831007, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.52228875582169, \"precision\": 0.9998259355961706, \"recall\": 0.47771124417831007, \"specificity\": 0.9998757609640949, \"npv\": 0.5616973757677275, \"accuracy\": 0.6870921137846859, \"f1\": 0.6465192188643143, \"f2\": 0.5334224847235378, \"f0_5\": 0.8204776596960347, \"p4\": 0.6809749486628779, \"phi\": 0.5178573515862551}, {\"truth_threshold\": 11.700000000000001, \"match_probability\": 0.9996995179500615, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5740, \"tn\": 8048, \"fp\": 1, \"fn\": 6284, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4773785761809714, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5226214238190287, \"precision\": 0.999825814318063, \"recall\": 0.4773785761809714, \"specificity\": 0.9998757609640949, \"npv\": 0.561540608428691, \"accuracy\": 0.6868928411298759, \"f1\": 0.6462144666479032, \"f2\": 0.5330906254063191, \"f0_5\": 0.8202812392820396, \"p4\": 0.6807482738520967, \"phi\": 0.5176046367484541}, {\"truth_threshold\": 11.72, \"match_probability\": 0.999703653549304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5734, \"tn\": 8048, \"fp\": 1, \"fn\": 6290, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4768795741849634, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5231204258150366, \"precision\": 0.9998256320836966, \"recall\": 0.4768795741849634, \"specificity\": 0.9998757609640949, \"npv\": 0.5613056214255824, \"accuracy\": 0.6865939321476611, \"f1\": 0.6457570809167182, \"f2\": 0.5325927439579424, \"f0_5\": 0.8199862715936391, \"p4\": 0.6804081027384973, \"phi\": 0.5172255976161926}, {\"truth_threshold\": 11.74, \"match_probability\": 0.999707732246043, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5726, \"tn\": 8048, \"fp\": 1, \"fn\": 6298, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4762142381902861, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5237857618097139, \"precision\": 0.999825388510564, \"recall\": 0.4762142381902861, \"specificity\": 0.9998757609640949, \"npv\": 0.560992611180817, \"accuracy\": 0.6861953868380412, \"f1\": 0.6451467522956453, \"f2\": 0.531928729353622, \"f0_5\": 0.819592350853086, \"p4\": 0.6799542437371258, \"phi\": 0.5167202734544399}, {\"truth_threshold\": 11.76, \"match_probability\": 0.9997117548227562, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5725, \"tn\": 8048, \"fp\": 1, \"fn\": 6299, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47613107119095144, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5238689288090486, \"precision\": 0.9998253580160671, \"recall\": 0.47613107119095144, \"specificity\": 0.9998757609640949, \"npv\": 0.5609535094444832, \"accuracy\": 0.6861455686743386, \"f1\": 0.6450704225352113, \"f2\": 0.5318457136486938, \"f0_5\": 0.8195430600091617, \"p4\": 0.6798974873934358, \"phi\": 0.5166571128315095}, {\"truth_threshold\": 11.78, \"match_probability\": 0.9997157220511734, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5718, \"tn\": 8048, \"fp\": 1, \"fn\": 6306, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4755489021956088, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5244510978043913, \"precision\": 0.9998251442559888, \"recall\": 0.4755489021956088, \"specificity\": 0.9998757609640949, \"npv\": 0.5606799498397659, \"accuracy\": 0.6857968415284212, \"f1\": 0.6445358733021473, \"f2\": 0.5312645173278826, \"f0_5\": 0.8191977077363897, \"p4\": 0.6795000434447139, \"phi\": 0.516215018727441}, {\"truth_threshold\": 11.8, \"match_probability\": 0.9997196346924244, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5709, \"tn\": 8048, \"fp\": 1, \"fn\": 6315, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4748003992015968, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5251996007984032, \"precision\": 0.9998248686514886, \"recall\": 0.4748003992015968, \"specificity\": 0.9998757609640949, \"npv\": 0.560328622154146, \"accuracy\": 0.6853484780550989, \"f1\": 0.6438479756400135, \"f2\": 0.5305170427089916, \"f0_5\": 0.8187528682882056, \"p4\": 0.6789886584323377, \"phi\": 0.5156466892350098}, {\"truth_threshold\": 11.82, \"match_probability\": 0.9997234934971839, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5706, \"tn\": 8048, \"fp\": 1, \"fn\": 6318, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4745508982035928, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5254491017964071, \"precision\": 0.9998247765901525, \"recall\": 0.4745508982035928, \"specificity\": 0.9998757609640949, \"npv\": 0.5602116107475985, \"accuracy\": 0.6851990235639914, \"f1\": 0.643618521233997, \"f2\": 0.5302678289314722, \"f0_5\": 0.8186043842534144, \"p4\": 0.6788181000380201, \"phi\": 0.5154572652092415}, {\"truth_threshold\": 11.84, \"match_probability\": 0.9997272992058148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5700, \"tn\": 8048, \"fp\": 1, \"fn\": 6324, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4740518962075848, \"tn_rate\": 0.9998757609640949, \"fp_rate\": 0.00012423903590508137, \"fn_rate\": 0.5259481037924152, \"precision\": 0.9998245921768111, \"recall\": 0.4740518962075848, \"specificity\": 0.9998757609640949, \"npv\": 0.5599777344837183, \"accuracy\": 0.6849001145817765, \"f1\": 0.6431593794076164, \"f2\": 0.5297693179917096, \"f0_5\": 0.8183071092224646, \"p4\": 0.678476837720766, \"phi\": 0.5150784456308379}, {\"truth_threshold\": 11.86, \"match_probability\": 0.9997310525485098, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5691, \"tn\": 8049, \"fp\": 0, \"fn\": 6333, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47330339321357284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5266966067864272, \"precision\": 1.0, \"recall\": 0.47330339321357284, \"specificity\": 1.0, \"npv\": 0.5596579057154777, \"accuracy\": 0.6845015692721567, \"f1\": 0.6425063505503811, \"f2\": 0.5290311785375649, \"f0_5\": 0.8179544670576061, \"p4\": 0.6780102856817055, \"phi\": 0.5146726977545413}, {\"truth_threshold\": 11.88, \"match_probability\": 0.9997347542454303, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5685, \"tn\": 8049, \"fp\": 0, \"fn\": 6339, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47280439121756485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5271956087824351, \"precision\": 1.0, \"recall\": 0.47280439121756485, \"specificity\": 1.0, \"npv\": 0.5594245204336947, \"accuracy\": 0.6842026602899417, \"f1\": 0.642046417076063, \"f2\": 0.5285323813242595, \"f0_5\": 0.8176561960648947, \"p4\": 0.6776685217757785, \"phi\": 0.5142940499518065}, {\"truth_threshold\": 11.9, \"match_probability\": 0.9997384050068445, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5674, \"tn\": 8049, \"fp\": 0, \"fn\": 6350, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47188955422488355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5281104457751165, \"precision\": 1.0, \"recall\": 0.47188955422488355, \"specificity\": 1.0, \"npv\": 0.5589971525800402, \"accuracy\": 0.6836546604892144, \"f1\": 0.6412023957509323, \"f2\": 0.5276176306490609, \"f0_5\": 0.8171082949308756, \"p4\": 0.6770414450158344, \"phi\": 0.5135999582787896}, {\"truth_threshold\": 11.92, \"match_probability\": 0.9997420055332628, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5670, \"tn\": 8049, \"fp\": 0, \"fn\": 6354, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.47155688622754494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5284431137724551, \"precision\": 1.0, \"recall\": 0.47155688622754494, \"specificity\": 1.0, \"npv\": 0.5588419079358466, \"accuracy\": 0.6834553878344044, \"f1\": 0.6408952187182095, \"f2\": 0.5272849012387011, \"f0_5\": 0.816908713692946, \"p4\": 0.6768132530132542, \"phi\": 0.5133475917930153}, {\"truth_threshold\": 11.94, \"match_probability\": 0.9997455565155712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5662, \"tn\": 8049, \"fp\": 0, \"fn\": 6362, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4708915502328676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5291084497671324, \"precision\": 1.0, \"recall\": 0.4708915502328676, \"specificity\": 1.0, \"npv\": 0.5585316771910346, \"accuracy\": 0.6830568425247845, \"f1\": 0.6402804478118286, \"f2\": 0.5266192938725399, \"f0_5\": 0.8165089986155976, \"p4\": 0.6763566054407782, \"phi\": 0.5128429070647754}, {\"truth_threshold\": 11.96, \"match_probability\": 0.9997490586351637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5650, \"tn\": 8049, \"fp\": 0, \"fn\": 6374, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4698935462408516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5301064537591483, \"precision\": 1.0, \"recall\": 0.4698935462408516, \"specificity\": 1.0, \"npv\": 0.5580669763572073, \"accuracy\": 0.6824590245603547, \"f1\": 0.6393572479348195, \"f2\": 0.5256205112938638, \"f0_5\": 0.8159080406654344, \"p4\": 0.6756709724830503, \"phi\": 0.512085999184119}, {\"truth_threshold\": 11.98, \"match_probability\": 0.9997525125640727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5643, \"tn\": 8049, \"fp\": 0, \"fn\": 6381, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.469311377245509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.530688622754491, \"precision\": 1.0, \"recall\": 0.469311377245509, \"specificity\": 1.0, \"npv\": 0.5577962577962577, \"accuracy\": 0.6821102974144373, \"f1\": 0.6388181355068773, \"f2\": 0.5250376821302964, \"f0_5\": 0.8155567117585848, \"p4\": 0.6752706516110645, \"phi\": 0.511644534778544}, {\"truth_threshold\": 12.0, \"match_probability\": 0.9997559189650964, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5640, \"tn\": 8049, \"fp\": 0, \"fn\": 6384, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.469061876247505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.530938123752495, \"precision\": 1.0, \"recall\": 0.469061876247505, \"specificity\": 1.0, \"npv\": 0.5576803159426315, \"accuracy\": 0.6819608429233298, \"f1\": 0.6385869565217391, \"f2\": 0.5247878517195177, \"f0_5\": 0.8154059680777238, \"p4\": 0.6750990021355658, \"phi\": 0.5114553502920388}, {\"truth_threshold\": 12.02, \"match_probability\": 0.9997592784919264, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5629, \"tn\": 8049, \"fp\": 0, \"fn\": 6395, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4681470392548237, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5318529607451763, \"precision\": 1.0, \"recall\": 0.4681470392548237, \"specificity\": 1.0, \"npv\": 0.5572556078648574, \"accuracy\": 0.6814128431226025, \"f1\": 0.6377386279952416, \"f2\": 0.5238715681712425, \"f0_5\": 0.8148523451071221, \"p4\": 0.6744691911481717, \"phi\": 0.5107617477161734}, {\"truth_threshold\": 12.040000000000001, \"match_probability\": 0.9997625917892721, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5626, \"tn\": 8049, \"fp\": 0, \"fn\": 6398, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4678975382568197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5321024617431803, \"precision\": 1.0, \"recall\": 0.4678975382568197, \"specificity\": 1.0, \"npv\": 0.5571398906347339, \"accuracy\": 0.681263388631495, \"f1\": 0.6375070821529745, \"f2\": 0.523621607535088, \"f0_5\": 0.8147011121408712, \"p4\": 0.674297307021006, \"phi\": 0.5105726033510471}, {\"truth_threshold\": 12.06, \"match_probability\": 0.9997658594929839, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5625, \"tn\": 8049, \"fp\": 0, \"fn\": 6399, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46781437125748504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.532185628742515, \"precision\": 1.0, \"recall\": 0.46781437125748504, \"specificity\": 1.0, \"npv\": 0.5571013289036545, \"accuracy\": 0.6812135704677925, \"f1\": 0.6374298827129016, \"f2\": 0.5235382811191154, \"f0_5\": 0.814650677789364, \"p4\": 0.674240001093661, \"phi\": 0.5105095571169774}, {\"truth_threshold\": 12.08, \"match_probability\": 0.9997690822301749, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5614, \"tn\": 8049, \"fp\": 0, \"fn\": 6410, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46689953426480374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5331004657351963, \"precision\": 1.0, \"recall\": 0.46689953426480374, \"specificity\": 1.0, \"npv\": 0.5566775019019296, \"accuracy\": 0.6806655706670652, \"f1\": 0.6365801111237102, \"f2\": 0.5226214857568423, \"f0_5\": 0.8140951276102089, \"p4\": 0.6736092647505588, \"phi\": 0.5098161103512768}, {\"truth_threshold\": 12.1, \"match_probability\": 0.9997722606193405, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5611, \"tn\": 8049, \"fp\": 0, \"fn\": 6413, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4666500332667997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5333499667332002, \"precision\": 1.0, \"recall\": 0.4666500332667997, \"specificity\": 1.0, \"npv\": 0.5565620246162356, \"accuracy\": 0.6805161161759578, \"f1\": 0.6363481712503544, \"f2\": 0.5223713854804775, \"f0_5\": 0.8139433677614019, \"p4\": 0.6734371273578496, \"phi\": 0.5096270080188096}, {\"truth_threshold\": 12.120000000000001, \"match_probability\": 0.999775395270477, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5604, \"tn\": 8049, \"fp\": 0, \"fn\": 6420, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4660678642714571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5339321357285429, \"precision\": 1.0, \"recall\": 0.4660678642714571, \"specificity\": 1.0, \"npv\": 0.5562927638399336, \"accuracy\": 0.6801673890300404, \"f1\": 0.6358066712049013, \"f2\": 0.5217877094972067, \"f0_5\": 0.813588850174216, \"p4\": 0.673035275424625, \"phi\": 0.5091858014050902}, {\"truth_threshold\": 12.14, \"match_probability\": 0.9997784867851973, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5603, \"tn\": 8049, \"fp\": 0, \"fn\": 6421, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46598469727212244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5340153027278776, \"precision\": 1.0, \"recall\": 0.46598469727212244, \"specificity\": 1.0, \"npv\": 0.5562543192812716, \"accuracy\": 0.6801175708663378, \"f1\": 0.6357292789470699, \"f2\": 0.5217043147917093, \"f0_5\": 0.813538157741898, \"p4\": 0.6729778453330691, \"phi\": 0.5091227755429861}, {\"truth_threshold\": 12.16, \"match_probability\": 0.9997815357568474, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5597, \"tn\": 8049, \"fp\": 0, \"fn\": 6427, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46548569527611444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5345143047238856, \"precision\": 1.0, \"recall\": 0.46548569527611444, \"specificity\": 1.0, \"npv\": 0.556023763470572, \"accuracy\": 0.679818661884123, \"f1\": 0.6352647409341127, \"f2\": 0.5212038813253125, \"f0_5\": 0.8132337556666279, \"p4\": 0.6726331454716586, \"phi\": 0.5087446394107175}, {\"truth_threshold\": 12.18, \"match_probability\": 0.999784542770618, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5593, \"tn\": 8049, \"fp\": 0, \"fn\": 6431, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4651530272787758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5348469727212242, \"precision\": 1.0, \"recall\": 0.4651530272787758, \"specificity\": 1.0, \"npv\": 0.5558701657458563, \"accuracy\": 0.679619389229313, \"f1\": 0.6349548731339048, \"f2\": 0.5208701968745926, \"f0_5\": 0.8130305849517385, \"p4\": 0.6724032317225517, \"phi\": 0.5084925666817952}, {\"truth_threshold\": 12.200000000000001, \"match_probability\": 0.9997875084036579, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5588, \"tn\": 8049, \"fp\": 0, \"fn\": 6436, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4647371922821025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5352628077178976, \"precision\": 1.0, \"recall\": 0.4647371922821025, \"specificity\": 1.0, \"npv\": 0.555678287884018, \"accuracy\": 0.6793702984108005, \"f1\": 0.6345673404496934, \"f2\": 0.5204530213843976, \"f0_5\": 0.8127763555969281, \"p4\": 0.6721157111402621, \"phi\": 0.5081774958844049}, {\"truth_threshold\": 12.22, \"match_probability\": 0.9997904332251836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5576, \"tn\": 8049, \"fp\": 0, \"fn\": 6448, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4637391882900865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5362608117099135, \"precision\": 1.0, \"recall\": 0.4637391882900865, \"specificity\": 1.0, \"npv\": 0.5552183210319377, \"accuracy\": 0.6787724804463707, \"f1\": 0.6336363636363637, \"f2\": 0.5194514830824266, \"f0_5\": 0.8121649965043114, \"p4\": 0.6714250776171954, \"phi\": 0.5074214161021738}, {\"truth_threshold\": 12.24, \"match_probability\": 0.999793317796588, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5572, \"tn\": 8049, \"fp\": 0, \"fn\": 6452, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4634065202927478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5365934797072521, \"precision\": 1.0, \"recall\": 0.4634065202927478, \"specificity\": 1.0, \"npv\": 0.5550651679194538, \"accuracy\": 0.6785732077915608, \"f1\": 0.6333257558536031, \"f2\": 0.5191175374524857, \"f0_5\": 0.81196083003031, \"p4\": 0.671194682538313, \"phi\": 0.5071694174546252}, {\"truth_threshold\": 12.26, \"match_probability\": 0.9997961626715484, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5567, \"tn\": 8049, \"fp\": 0, \"fn\": 6457, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4629906852960745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5370093147039254, \"precision\": 1.0, \"recall\": 0.4629906852960745, \"specificity\": 1.0, \"npv\": 0.5548738453053909, \"accuracy\": 0.6783241169730484, \"f1\": 0.6329372974816667, \"f2\": 0.5187000354061457, \"f0_5\": 0.8117053540184299, \"p4\": 0.6709065589238229, \"phi\": 0.5068544385627998}, {\"truth_threshold\": 12.280000000000001, \"match_probability\": 0.9997989683961317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5564, \"tn\": 8049, \"fp\": 0, \"fn\": 6460, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46274118429807054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5372588157019295, \"precision\": 1.0, \"recall\": 0.46274118429807054, \"specificity\": 1.0, \"npv\": 0.5547591150320491, \"accuracy\": 0.6781746624819409, \"f1\": 0.6327041164430294, \"f2\": 0.5184494968319046, \"f0_5\": 0.8115519253208868, \"p4\": 0.670733615406681, \"phi\": 0.5066654615128999}, {\"truth_threshold\": 12.3, \"match_probability\": 0.9998017355088994, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5561, \"tn\": 8049, \"fp\": 0, \"fn\": 6463, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4624916833000665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5375083166999335, \"precision\": 1.0, \"recall\": 0.4624916833000665, \"specificity\": 1.0, \"npv\": 0.5546444321940464, \"accuracy\": 0.6780252079908334, \"f1\": 0.6324708558430481, \"f2\": 0.5181989302420933, \"f0_5\": 0.8113983891677367, \"p4\": 0.670560619781803, \"phi\": 0.5064764921281482}, {\"truth_threshold\": 12.32, \"match_probability\": 0.9998044645410099, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5556, \"tn\": 8049, \"fp\": 0, \"fn\": 6468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4620758483033932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5379241516966068, \"precision\": 1.0, \"recall\": 0.4620758483033932, \"specificity\": 1.0, \"npv\": 0.5544533994626989, \"accuracy\": 0.677776117172321, \"f1\": 0.6320819112627987, \"f2\": 0.5177812569894878, \"f0_5\": 0.8111422564821303, \"p4\": 0.6702721777307511, \"phi\": 0.5061615600788217}, {\"truth_threshold\": 12.34, \"match_probability\": 0.9998071560163209, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5552, \"tn\": 8049, \"fp\": 0, \"fn\": 6472, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46174318030605455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5382568196939455, \"precision\": 1.0, \"recall\": 0.46174318030605455, \"specificity\": 1.0, \"npv\": 0.5543006679980718, \"accuracy\": 0.6775768445175111, \"f1\": 0.6317705962676377, \"f2\": 0.5174470623322398, \"f0_5\": 0.8109371348445898, \"p4\": 0.6700413194701941, \"phi\": 0.5059096295655975}, {\"truth_threshold\": 12.36, \"match_probability\": 0.9998098104514891, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5547, \"tn\": 8049, \"fp\": 0, \"fn\": 6477, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.46132734530938124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5386726546906188, \"precision\": 1.0, \"recall\": 0.46132734530938124, \"specificity\": 1.0, \"npv\": 0.5541098719537382, \"accuracy\": 0.6773277536989987, \"f1\": 0.6313812532012976, \"f2\": 0.5170292489234383, \"f0_5\": 0.8106804629954402, \"p4\": 0.6697526155614124, \"phi\": 0.5055947351764446}, {\"truth_threshold\": 12.38, \"match_probability\": 0.9998124283560689, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5545, \"tn\": 8049, \"fp\": 0, \"fn\": 6479, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4611610113107119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5388389886892881, \"precision\": 1.0, \"recall\": 0.4611610113107119, \"specificity\": 1.0, \"npv\": 0.5540335903083701, \"accuracy\": 0.6772281173715937, \"f1\": 0.6312254539245261, \"f2\": 0.5168621017505266, \"f0_5\": 0.8105777102093322, \"p4\": 0.6696370931409583, \"phi\": 0.5054687832168397}, {\"truth_threshold\": 12.4, \"match_probability\": 0.9998150102326104, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5533, \"tn\": 8049, \"fp\": 0, \"fn\": 6491, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4601630073186959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.539836992681304, \"precision\": 1.0, \"recall\": 0.4601630073186959, \"specificity\": 1.0, \"npv\": 0.553576341127923, \"accuracy\": 0.6766302994071639, \"f1\": 0.6302899128552714, \"f2\": 0.5158589569076433, \"f0_5\": 0.8099601826911816, \"p4\": 0.6689434667650616, \"phi\": 0.5047131402231424}, {\"truth_threshold\": 12.42, \"match_probability\": 0.9998175565767553, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5529, \"tn\": 8049, \"fp\": 0, \"fn\": 6495, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4598303393213573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5401696606786427, \"precision\": 1.0, \"recall\": 0.4598303393213573, \"specificity\": 1.0, \"npv\": 0.553424092409241, \"accuracy\": 0.6764310267523539, \"f1\": 0.629977781575799, \"f2\": 0.5155244755244756, \"f0_5\": 0.8097539543057997, \"p4\": 0.6687120700323681, \"phi\": 0.5044612851360899}, {\"truth_threshold\": 12.44, \"match_probability\": 0.9998200678773314, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5524, \"tn\": 8049, \"fp\": 0, \"fn\": 6500, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.45941450432468395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.540585495675316, \"precision\": 1.0, \"recall\": 0.45941450432468395, \"specificity\": 1.0, \"npv\": 0.553233899237061, \"accuracy\": 0.6761819359338415, \"f1\": 0.6295874173695007, \"f2\": 0.515106303618053, \"f0_5\": 0.809495896834701, \"p4\": 0.6684226915034142, \"phi\": 0.5041464842618726}, {\"truth_threshold\": 12.46, \"match_probability\": 0.9998225446164466, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5510, \"tn\": 8049, \"fp\": 0, \"fn\": 6514, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4582501663339987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5417498336660014, \"precision\": 1.0, \"recall\": 0.4582501663339987, \"specificity\": 1.0, \"npv\": 0.5527020531483897, \"accuracy\": 0.6754844816420067, \"f1\": 0.6284932131858104, \"f2\": 0.5139350072753051, \"f0_5\": 0.8087717238139972, \"p4\": 0.6676116446941726, \"phi\": 0.5032651466060333}, {\"truth_threshold\": 12.48, \"match_probability\": 0.999824987269581, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5498, \"tn\": 8049, \"fp\": 0, \"fn\": 6526, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4572521623419827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5427478376580173, \"precision\": 1.0, \"recall\": 0.4572521623419827, \"specificity\": 1.0, \"npv\": 0.5522469982847341, \"accuracy\": 0.6748866636775769, \"f1\": 0.6275539321995206, \"f2\": 0.5129305519274545, \"f0_5\": 0.8081491063029163, \"p4\": 0.6669155338796622, \"phi\": 0.5025098348416316}, {\"truth_threshold\": 12.5, \"match_probability\": 0.9998273963056777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5493, \"tn\": 8049, \"fp\": 0, \"fn\": 6531, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4568363273453094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5431636726546906, \"precision\": 1.0, \"recall\": 0.4568363273453094, \"specificity\": 1.0, \"npv\": 0.5520576131687243, \"accuracy\": 0.6746375728590644, \"f1\": 0.627162185305703, \"f2\": 0.5125118960980798, \"f0_5\": 0.8078891634309919, \"p4\": 0.6666252336122036, \"phi\": 0.502195153782887}, {\"truth_threshold\": 12.52, \"match_probability\": 0.999829772187233, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5489, \"tn\": 8049, \"fp\": 0, \"fn\": 6535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4565036593479707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5434963406520292, \"precision\": 1.0, \"recall\": 0.4565036593479707, \"specificity\": 1.0, \"npv\": 0.5519061985737795, \"accuracy\": 0.6744383002042544, \"f1\": 0.6268486267344259, \"f2\": 0.5121769151814873, \"f0_5\": 0.8076809888169512, \"p4\": 0.6663928854016126, \"phi\": 0.5019434223752296}, {\"truth_threshold\": 12.540000000000001, \"match_probability\": 0.9998321153703844, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5486, \"tn\": 8049, \"fp\": 0, \"fn\": 6538, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.45625415834996674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5437458416500333, \"precision\": 1.0, \"recall\": 0.45625415834996674, \"specificity\": 1.0, \"npv\": 0.5517926921231233, \"accuracy\": 0.6742888457131471, \"f1\": 0.6266133637921187, \"f2\": 0.5119256466723899, \"f0_5\": 0.8075247291568535, \"p4\": 0.6662185611186061, \"phi\": 0.5017546315962594}, {\"truth_threshold\": 12.56, \"match_probability\": 0.999834426304998, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5482, \"tn\": 8049, \"fp\": 0, \"fn\": 6542, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4559214903526281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5440785096473719, \"precision\": 1.0, \"recall\": 0.4559214903526281, \"specificity\": 1.0, \"npv\": 0.5516414227948736, \"accuracy\": 0.674089573058337, \"f1\": 0.6262995544384783, \"f2\": 0.5115905782224047, \"f0_5\": 0.8073162111215834, \"p4\": 0.6659860444189596, \"phi\": 0.5015029208498022}, {\"truth_threshold\": 12.58, \"match_probability\": 0.9998367054347549, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5476, \"tn\": 8049, \"fp\": 0, \"fn\": 6548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4554224883566201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5445775116433799, \"precision\": 1.0, \"recall\": 0.4554224883566201, \"specificity\": 1.0, \"npv\": 0.5514146742481332, \"accuracy\": 0.6737906640761222, \"f1\": 0.6258285714285714, \"f2\": 0.5110878817292616, \"f0_5\": 0.8070030653147843, \"p4\": 0.6656370882841137, \"phi\": 0.5011253765899706}, {\"truth_threshold\": 12.6, \"match_probability\": 0.999838953197236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5473, \"tn\": 8049, \"fp\": 0, \"fn\": 6551, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4551729873586161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5448270126413839, \"precision\": 1.0, \"recall\": 0.4551729873586161, \"specificity\": 1.0, \"npv\": 0.5513013698630137, \"accuracy\": 0.6736412095850147, \"f1\": 0.625592958792936, \"f2\": 0.5108364912542702, \"f0_5\": 0.8068463262177143, \"p4\": 0.6654625285503116, \"phi\": 0.5009366142092683}, {\"truth_threshold\": 12.620000000000001, \"match_probability\": 0.9998411700240056, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5471, \"tn\": 8049, \"fp\": 0, \"fn\": 6553, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4550066533599468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5449933466400533, \"precision\": 1.0, \"recall\": 0.4550066533599468, \"specificity\": 1.0, \"npv\": 0.5512258594713053, \"accuracy\": 0.6735415732576098, \"f1\": 0.6254358388110889, \"f2\": 0.5106688819609088, \"f0_5\": 0.80674177185325, \"p4\": 0.665346125091767, \"phi\": 0.5008107762054437}, {\"truth_threshold\": 12.64, \"match_probability\": 0.9998433563406941, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5467, \"tn\": 8049, \"fp\": 0, \"fn\": 6557, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4546739853626081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5453260146373918, \"precision\": 1.0, \"recall\": 0.4546739853626081, \"specificity\": 1.0, \"npv\": 0.5510749007257292, \"accuracy\": 0.6733423006027998, \"f1\": 0.6251214910525413, \"f2\": 0.5103336258237963, \"f0_5\": 0.8065325150477989, \"p4\": 0.665113245338353, \"phi\": 0.5005591087436836}, {\"truth_threshold\": 12.66, \"match_probability\": 0.9998455125670797, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5454, \"tn\": 8049, \"fp\": 0, \"fn\": 6570, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4535928143712575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5464071856287425, \"precision\": 1.0, \"recall\": 0.4535928143712575, \"specificity\": 1.0, \"npv\": 0.5505848553252617, \"accuracy\": 0.6726946644746674, \"f1\": 0.6240988671472708, \"f2\": 0.5092436974789916, \"f0_5\": 0.8058510638297872, \"p4\": 0.6643557132965899, \"phi\": 0.49974126713448136}, {\"truth_threshold\": 12.68, \"match_probability\": 0.9998476391171683, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5442, \"tn\": 8049, \"fp\": 0, \"fn\": 6582, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.45259481037924154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5474051896207585, \"precision\": 1.0, \"recall\": 0.45259481037924154, \"specificity\": 1.0, \"npv\": 0.5501332786549108, \"accuracy\": 0.6720968465102376, \"f1\": 0.6231535554792168, \"f2\": 0.5082371399753446, \"f0_5\": 0.8052201704545454, \"p4\": 0.6636555351342351, \"phi\": 0.49898643963150924}, {\"truth_threshold\": 12.700000000000001, \"match_probability\": 0.9998497363992734, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5439, \"tn\": 8049, \"fp\": 0, \"fn\": 6585, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4523453093812375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5476546906187625, \"precision\": 1.0, \"recall\": 0.4523453093812375, \"specificity\": 1.0, \"npv\": 0.550020500205002, \"accuracy\": 0.6719473920191302, \"f1\": 0.6229170245662258, \"f2\": 0.5079854300924629, \"f0_5\": 0.8050621669626998, \"p4\": 0.6634803522736743, \"phi\": 0.4987977479211937}, {\"truth_threshold\": 12.72, \"match_probability\": 0.9998518048160936, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5433, \"tn\": 8049, \"fp\": 0, \"fn\": 6591, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4518463073852295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5481536926147704, \"precision\": 1.0, \"recall\": 0.4518463073852295, \"specificity\": 1.0, \"npv\": 0.5497950819672132, \"accuracy\": 0.6716484830369153, \"f1\": 0.6224437188520364, \"f2\": 0.5074819256851426, \"f0_5\": 0.8047458229648062, \"p4\": 0.6631298199834386, \"phi\": 0.498420382413726}, {\"truth_threshold\": 12.74, \"match_probability\": 0.9998538447647903, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5428, \"tn\": 8049, \"fp\": 0, \"fn\": 6596, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4514304723885562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5485695276114437, \"precision\": 1.0, \"recall\": 0.4514304723885562, \"specificity\": 1.0, \"npv\": 0.5496073745305565, \"accuracy\": 0.6713993922184028, \"f1\": 0.6220490488196195, \"f2\": 0.5070622524475001, \"f0_5\": 0.8044818591415699, \"p4\": 0.6628375396893006, \"phi\": 0.4981059292083997}, {\"truth_threshold\": 12.76, \"match_probability\": 0.9998558566370636, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5424, \"tn\": 8049, \"fp\": 0, \"fn\": 6600, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.45109780439121755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5489021956087824, \"precision\": 1.0, \"recall\": 0.45109780439121755, \"specificity\": 1.0, \"npv\": 0.5494573008396477, \"accuracy\": 0.6712001195635929, \"f1\": 0.6217331499312242, \"f2\": 0.5067264573991032, \"f0_5\": 0.8042704626334519, \"p4\": 0.6626036038669488, \"phi\": 0.49785437832310947}, {\"truth_threshold\": 12.780000000000001, \"match_probability\": 0.9998578408192266, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5413, \"tn\": 8049, \"fp\": 0, \"fn\": 6611, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.45018296739853625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5498170326014638, \"precision\": 1.0, \"recall\": 0.45018296739853625, \"specificity\": 1.0, \"npv\": 0.5490450204638472, \"accuracy\": 0.6706521197628655, \"f1\": 0.6208636806790159, \"f2\": 0.5058027621521614, \"f0_5\": 0.8036880864710774, \"p4\": 0.6619597671978757, \"phi\": 0.49716266608405424}, {\"truth_threshold\": 12.8, \"match_probability\": 0.9998597976922806, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5408, \"tn\": 8049, \"fp\": 0, \"fn\": 6616, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44976713240186295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.550232867598137, \"precision\": 1.0, \"recall\": 0.44976713240186295, \"specificity\": 1.0, \"npv\": 0.5488578247528129, \"accuracy\": 0.6704030289443531, \"f1\": 0.6204681046351538, \"f2\": 0.5053827751196173, \"f0_5\": 0.8034228666508201, \"p4\": 0.6616668645278305, \"phi\": 0.4968482765748482}, {\"truth_threshold\": 12.82, \"match_probability\": 0.9998617276319876, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5405, \"tn\": 8049, \"fp\": 0, \"fn\": 6619, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.449517631403859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5504823685961411, \"precision\": 1.0, \"recall\": 0.449517631403859, \"specificity\": 1.0, \"npv\": 0.5487455685846742, \"accuracy\": 0.6702535744532456, \"f1\": 0.620230650065982, \"f2\": 0.5051307452197156, \"f0_5\": 0.803263583402687, \"p4\": 0.6614910477955935, \"phi\": 0.496659650297411}, {\"truth_threshold\": 12.84, \"match_probability\": 0.9998636310089414, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5404, \"tn\": 8049, \"fp\": 0, \"fn\": 6620, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4494344644045243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5505655355954757, \"precision\": 1.0, \"recall\": 0.4494344644045243, \"specificity\": 1.0, \"npv\": 0.5487081600654441, \"accuracy\": 0.6702037562895432, \"f1\": 0.6201514803764058, \"f2\": 0.5050467289719626, \"f0_5\": 0.8032104637336505, \"p4\": 0.6614324296775966, \"phi\": 0.4965967761004947}, {\"truth_threshold\": 12.86, \"match_probability\": 0.99986550818864, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5400, \"tn\": 8049, \"fp\": 0, \"fn\": 6624, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4491017964071856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5508982035928144, \"precision\": 1.0, \"recall\": 0.4491017964071856, \"specificity\": 1.0, \"npv\": 0.548558576978123, \"accuracy\": 0.6700044836347332, \"f1\": 0.6198347107438017, \"f2\": 0.5047106325706595, \"f0_5\": 0.8029978586723768, \"p4\": 0.6611978944186322, \"phi\": 0.49634528541675954}, {\"truth_threshold\": 12.88, \"match_probability\": 0.9998673595315546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5398, \"tn\": 8049, \"fp\": 0, \"fn\": 6626, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4489354624085163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5510645375914837, \"precision\": 1.0, \"recall\": 0.4489354624085163, \"specificity\": 1.0, \"npv\": 0.5484838160136286, \"accuracy\": 0.6699048473073282, \"f1\": 0.6196762713810126, \"f2\": 0.5045425655213669, \"f0_5\": 0.8028914802475012, \"p4\": 0.6610805890727828, \"phi\": 0.49621954371595034}, {\"truth_threshold\": 12.9, \"match_probability\": 0.9998691853931992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5391, \"tn\": 8049, \"fp\": 0, \"fn\": 6633, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44835329341317365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5516467065868264, \"precision\": 1.0, \"recall\": 0.44835329341317365, \"specificity\": 1.0, \"npv\": 0.548222313036371, \"accuracy\": 0.6695561201614109, \"f1\": 0.6191214470284238, \"f2\": 0.5039542318694262, \"f0_5\": 0.802518756698821, \"p4\": 0.6606698219198974, \"phi\": 0.4957794666708624}, {\"truth_threshold\": 12.92, \"match_probability\": 0.9998709861241983, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5384, \"tn\": 8049, \"fp\": 0, \"fn\": 6640, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.447771124417831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.552228875582169, \"precision\": 1.0, \"recall\": 0.447771124417831, \"specificity\": 1.0, \"npv\": 0.5479610592960719, \"accuracy\": 0.6692073930154935, \"f1\": 0.6185661764705882, \"f2\": 0.5033657442034405, \"f0_5\": 0.8021454112038141, \"p4\": 0.6602587452507516, \"phi\": 0.4953394186395707}, {\"truth_threshold\": 12.94, \"match_probability\": 0.9998727620703545, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5377, \"tn\": 8049, \"fp\": 0, \"fn\": 6647, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4471889554224884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5528110445775116, \"precision\": 1.0, \"recall\": 0.4471889554224884, \"specificity\": 1.0, \"npv\": 0.5477000544365814, \"accuracy\": 0.6688586658695761, \"f1\": 0.6180104591690133, \"f2\": 0.5027771024629252, \"f0_5\": 0.8017714422044614, \"p4\": 0.6598473579755222, \"phi\": 0.49489939909878133}, {\"truth_threshold\": 12.96, \"match_probability\": 0.9998745135727142, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5374, \"tn\": 8049, \"fp\": 0, \"fn\": 6650, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44693945442448435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5530605455755156, \"precision\": 1.0, \"recall\": 0.44693945442448435, \"specificity\": 1.0, \"npv\": 0.5475882713109735, \"accuracy\": 0.6687092113784686, \"f1\": 0.6177721577192781, \"f2\": 0.5025247802506079, \"f0_5\": 0.8016109785202864, \"p4\": 0.6596709537889377, \"phi\": 0.49471082788733567}, {\"truth_threshold\": 12.98, \"match_probability\": 0.9998762409676335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5369, \"tn\": 8049, \"fp\": 0, \"fn\": 6655, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44652361942781105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.553476380572189, \"precision\": 1.0, \"recall\": 0.44652361942781105, \"specificity\": 1.0, \"npv\": 0.5474020674646355, \"accuracy\": 0.6684601205599562, \"f1\": 0.6173748059564192, \"f2\": 0.5021041803048724, \"f0_5\": 0.8013432835820895, \"p4\": 0.6593768193526879, \"phi\": 0.49439655383768183}, {\"truth_threshold\": 13.0, \"match_probability\": 0.9998779445868424, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5359, \"tn\": 8049, \"fp\": 0, \"fn\": 6665, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4456919494344644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5543080505655356, \"precision\": 1.0, \"recall\": 0.4456919494344644, \"specificity\": 1.0, \"npv\": 0.5470300394182411, \"accuracy\": 0.6679619389229313, \"f1\": 0.6165794166714607, \"f2\": 0.5012627443644186, \"f0_5\": 0.800806933652122, \"p4\": 0.6587880710684125, \"phi\": 0.4937680474347523}, {\"truth_threshold\": 13.02, \"match_probability\": 0.9998796247575082, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5353, \"tn\": 8049, \"fp\": 0, \"fn\": 6671, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44519294743845644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5548070525615436, \"precision\": 1.0, \"recall\": 0.44519294743845644, \"specificity\": 1.0, \"npv\": 0.5468070652173913, \"accuracy\": 0.6676630299407164, \"f1\": 0.6161017436841802, \"f2\": 0.5007577316694419, \"f0_5\": 0.800484507716234, \"p4\": 0.6584345141945215, \"phi\": 0.49339096976363755}, {\"truth_threshold\": 13.040000000000001, \"match_probability\": 0.9998812818022986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5348, \"tn\": 8049, \"fp\": 0, \"fn\": 6676, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4447771124417831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5552228875582169, \"precision\": 1.0, \"recall\": 0.4447771124417831, \"specificity\": 1.0, \"npv\": 0.5466213921901528, \"accuracy\": 0.6674139391222039, \"f1\": 0.6157034308081971, \"f2\": 0.5003368011376395, \"f0_5\": 0.8002154656451999, \"p4\": 0.6581397064427695, \"phi\": 0.4930767530691785}, {\"truth_threshold\": 13.06, \"match_probability\": 0.999882916039443, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5342, \"tn\": 8049, \"fp\": 0, \"fn\": 6682, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44427811044577514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5557218895542249, \"precision\": 1.0, \"recall\": 0.44427811044577514, \"specificity\": 1.0, \"npv\": 0.5463987509334057, \"accuracy\": 0.6671150301399891, \"f1\": 0.6152251525970287, \"f2\": 0.4998315805232232, \"f0_5\": 0.7998921897460469, \"p4\": 0.6577857241076666, \"phi\": 0.49269971038617955}, {\"truth_threshold\": 13.08, \"match_probability\": 0.999884527782794, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5338, \"tn\": 8049, \"fp\": 0, \"fn\": 6686, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4439454424484365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5560545575515635, \"precision\": 1.0, \"recall\": 0.4439454424484365, \"specificity\": 1.0, \"npv\": 0.5462504241601629, \"accuracy\": 0.6669157574851791, \"f1\": 0.6149061168068195, \"f2\": 0.49949470374667815, \"f0_5\": 0.799676414189837, \"p4\": 0.6575496064491205, \"phi\": 0.49244835895901773}, {\"truth_threshold\": 13.1, \"match_probability\": 0.9998861173418873, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5329, \"tn\": 8049, \"fp\": 0, \"fn\": 6695, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4431969394544245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5568030605455755, \"precision\": 1.0, \"recall\": 0.4431969394544245, \"specificity\": 1.0, \"npv\": 0.5459169831795985, \"accuracy\": 0.6664673940118567, \"f1\": 0.6141877485161067, \"f2\": 0.49873654656059896, \"f0_5\": 0.7991901619676065, \"p4\": 0.657017961914832, \"phi\": 0.4918828479845487}, {\"truth_threshold\": 13.120000000000001, \"match_probability\": 0.9998876850220009, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5322, \"tn\": 8049, \"fp\": 0, \"fn\": 6702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4426147704590818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5573852295409182, \"precision\": 1.0, \"recall\": 0.4426147704590818, \"specificity\": 1.0, \"npv\": 0.5456579214968477, \"accuracy\": 0.6661186668659393, \"f1\": 0.613628502248357, \"f2\": 0.49814669212624957, \"f0_5\": 0.7988112391930836, \"p4\": 0.6566040958209179, \"phi\": 0.49144303400547545}, {\"truth_threshold\": 13.14, \"match_probability\": 0.9998892311242138, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5320, \"tn\": 8049, \"fp\": 0, \"fn\": 6704, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4424484364604125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5575515635395875, \"precision\": 1.0, \"recall\": 0.4424484364604125, \"specificity\": 1.0, \"npv\": 0.5455839490273164, \"accuracy\": 0.6660190305385344, \"f1\": 0.6134686346863468, \"f2\": 0.4979781338924667, \"f0_5\": 0.7987028585154936, \"p4\": 0.6564857895620233, \"phi\": 0.491317377267519}, {\"truth_threshold\": 13.16, \"match_probability\": 0.9998907559454638, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5312, \"tn\": 8049, \"fp\": 0, \"fn\": 6712, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4417831004657352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5582168995342648, \"precision\": 1.0, \"recall\": 0.4417831004657352, \"specificity\": 1.0, \"npv\": 0.545288259603008, \"accuracy\": 0.6656204852289145, \"f1\": 0.6128287955699123, \"f2\": 0.49730377471539844, \"f0_5\": 0.7982688146188988, \"p4\": 0.656012302433934, \"phi\": 0.49081476951593617}, {\"truth_threshold\": 13.18, \"match_probability\": 0.9998922597786042, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5309, \"tn\": 8049, \"fp\": 0, \"fn\": 6715, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4415335994677312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5584664005322688, \"precision\": 1.0, \"recall\": 0.4415335994677312, \"specificity\": 1.0, \"npv\": 0.5451774586832837, \"accuracy\": 0.665471030737807, \"f1\": 0.6125887036289159, \"f2\": 0.49705083793652277, \"f0_5\": 0.7981058328322309, \"p4\": 0.6558346364125902, \"phi\": 0.49062629941850905}, {\"truth_threshold\": 13.200000000000001, \"match_probability\": 0.9998937429124599, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5299, \"tn\": 8049, \"fp\": 0, \"fn\": 6725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4407019294743846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5592980705256154, \"precision\": 1.0, \"recall\": 0.4407019294743846, \"specificity\": 1.0, \"npv\": 0.544808447272235, \"accuracy\": 0.6649728491007821, \"f1\": 0.6117877965710328, \"f2\": 0.4962075100664856, \"f0_5\": 0.7975617098133655, \"p4\": 0.6552419880141906, \"phi\": 0.48999809581958326}, {\"truth_threshold\": 13.22, \"match_probability\": 0.9998952056318829, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5292, \"tn\": 8049, \"fp\": 0, \"fn\": 6732, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.44011976047904194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5598802395209581, \"precision\": 1.0, \"recall\": 0.44011976047904194, \"specificity\": 1.0, \"npv\": 0.5445504363710169, \"accuracy\": 0.6646241219548648, \"f1\": 0.6112266112266113, \"f2\": 0.49561699258260283, \"f0_5\": 0.797180043383948, \"p4\": 0.6548267407384962, \"phi\": 0.4895583802003288}, {\"truth_threshold\": 13.24, \"match_probability\": 0.999896648217807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5289, \"tn\": 8049, \"fp\": 0, \"fn\": 6735, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4398702594810379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.560129740518962, \"precision\": 1.0, \"recall\": 0.4398702594810379, \"specificity\": 1.0, \"npv\": 0.544439935064935, \"accuracy\": 0.6644746674637573, \"f1\": 0.61098596430428, \"f2\": 0.4953638662545659, \"f0_5\": 0.7970162748643761, \"p4\": 0.6546486781128336, \"phi\": 0.4893699372753218}, {\"truth_threshold\": 13.26, \"match_probability\": 0.9998980709473013, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5282, \"tn\": 8049, \"fp\": 0, \"fn\": 6742, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4392880904856953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5607119095143047, \"precision\": 1.0, \"recall\": 0.4392880904856953, \"specificity\": 1.0, \"npv\": 0.5441822730038537, \"accuracy\": 0.6641259403178399, \"f1\": 0.6104241303594129, \"f2\": 0.49477312750571395, \"f0_5\": 0.7966336872586872, \"p4\": 0.6542329658084601, \"phi\": 0.4889302522692048}, {\"truth_threshold\": 13.280000000000001, \"match_probability\": 0.9998994740936238, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5272, \"tn\": 8049, \"fp\": 0, \"fn\": 6752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4384564204923486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5615435795076513, \"precision\": 1.0, \"recall\": 0.4384564204923486, \"specificity\": 1.0, \"npv\": 0.5438146071211405, \"accuracy\": 0.663627758680815, \"f1\": 0.6096207215541165, \"f2\": 0.4939289461849798, \"f0_5\": 0.7960860111137956, \"p4\": 0.6536385237156473, \"phi\": 0.48830216674697247}, {\"truth_threshold\": 13.3, \"match_probability\": 0.9999008579262733, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5271, \"tn\": 8049, \"fp\": 0, \"fn\": 6753, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.438373253493014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5616267465069861, \"precision\": 1.0, \"recall\": 0.438373253493014, \"specificity\": 1.0, \"npv\": 0.5437778678556952, \"accuracy\": 0.6635779405171125, \"f1\": 0.6095403295750217, \"f2\": 0.4938445106526505, \"f0_5\": 0.7960311707140268, \"p4\": 0.653579042683533, \"phi\": 0.48823936046717425}, {\"truth_threshold\": 13.32, \"match_probability\": 0.9999022227110415, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5262, \"tn\": 8049, \"fp\": 0, \"fn\": 6762, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.437624750499002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.562375249500998, \"precision\": 1.0, \"recall\": 0.437624750499002, \"specificity\": 1.0, \"npv\": 0.5434474377152116, \"accuracy\": 0.6631295770437902, \"f1\": 0.6088163832002776, \"f2\": 0.4930844484425953, \"f0_5\": 0.7955370101596516, \"p4\": 0.6530434111088438, \"phi\": 0.4876741220727643}, {\"truth_threshold\": 13.34, \"match_probability\": 0.9999035687100634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5251, \"tn\": 8049, \"fp\": 0, \"fn\": 6773, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4367099135063207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5632900864936793, \"precision\": 1.0, \"recall\": 0.4367099135063207, \"specificity\": 1.0, \"npv\": 0.5430441236000539, \"accuracy\": 0.6625815772430628, \"f1\": 0.6079305354558611, \"f2\": 0.49215513524659305, \"f0_5\": 0.7949315732106091, \"p4\": 0.6523880087780104, \"phi\": 0.48698331824354646}, {\"truth_threshold\": 13.36, \"match_probability\": 0.9999048961818684, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5243, \"tn\": 8049, \"fp\": 0, \"fn\": 6781, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4360445775116434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5639554224883566, \"precision\": 1.0, \"recall\": 0.4360445775116434, \"specificity\": 1.0, \"npv\": 0.5427511800404585, \"accuracy\": 0.662183031933443, \"f1\": 0.6072855736375745, \"f2\": 0.491479030353025, \"f0_5\": 0.7944902412413626, \"p4\": 0.651910837815639, \"phi\": 0.4864809441228789}, {\"truth_threshold\": 13.38, \"match_probability\": 0.999906205381429, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5241, \"tn\": 8049, \"fp\": 0, \"fn\": 6783, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.43587824351297405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5641217564870259, \"precision\": 1.0, \"recall\": 0.43587824351297405, \"specificity\": 1.0, \"npv\": 0.5426779935275081, \"accuracy\": 0.662083395606038, \"f1\": 0.6071242397914857, \"f2\": 0.4913099724393948, \"f0_5\": 0.7943797744634412, \"p4\": 0.6517914771107172, \"phi\": 0.4863553542543922}, {\"truth_threshold\": 13.42, \"match_probability\": 0.9999087699662178, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5234, \"tn\": 8049, \"fp\": 0, \"fn\": 6790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4352960745176314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5647039254823686, \"precision\": 1.0, \"recall\": 0.4352960745176314, \"specificity\": 1.0, \"npv\": 0.5424219960913809, \"accuracy\": 0.6617346684601205, \"f1\": 0.6065592768571098, \"f2\": 0.49071816988561784, \"f0_5\": 0.7939927184466019, \"p4\": 0.6513734999474344, \"phi\": 0.48591580096822956}, {\"truth_threshold\": 13.44, \"match_probability\": 0.9999100258440452, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5227, \"tn\": 8049, \"fp\": 0, \"fn\": 6797, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4347139055222888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5652860944777113, \"precision\": 1.0, \"recall\": 0.4347139055222888, \"specificity\": 1.0, \"npv\": 0.5421662400646639, \"accuracy\": 0.6613859413142031, \"f1\": 0.6059938554286708, \"f2\": 0.490126211953566, \"f0_5\": 0.7936050042511843, \"p4\": 0.6509551879191289, \"phi\": 0.48547626477598754}, {\"truth_threshold\": 13.46, \"match_probability\": 0.9999112644349214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5214, \"tn\": 8049, \"fp\": 0, \"fn\": 6810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.43363273453093815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5663672654690619, \"precision\": 1.0, \"recall\": 0.43363273453093815, \"specificity\": 1.0, \"npv\": 0.5416919038966284, \"accuracy\": 0.6607383051860708, \"f1\": 0.6049425687434737, \"f2\": 0.48902644907146875, \"f0_5\": 0.7928832116788321, \"p4\": 0.6501774302923541, \"phi\": 0.4846600267816246}, {\"truth_threshold\": 13.48, \"match_probability\": 0.9999124859767564, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5210, \"tn\": 8049, \"fp\": 0, \"fn\": 6814, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4333000665335995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5666999334664006, \"precision\": 1.0, \"recall\": 0.4333000665335995, \"specificity\": 1.0, \"npv\": 0.5415461212406647, \"accuracy\": 0.6605390325312609, \"f1\": 0.604618776836486, \"f2\": 0.48868795257569503, \"f0_5\": 0.7926606621226875, \"p4\": 0.6499378859115124, \"phi\": 0.4844088875780385}, {\"truth_threshold\": 13.5, \"match_probability\": 0.9999136907041872, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5208, \"tn\": 8049, \"fp\": 0, \"fn\": 6816, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.43313373253493015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5668662674650699, \"precision\": 1.0, \"recall\": 0.43313373253493015, \"specificity\": 1.0, \"npv\": 0.541473259334006, \"accuracy\": 0.6604393962038559, \"f1\": 0.6044568245125348, \"f2\": 0.4885186852769023, \"f0_5\": 0.7925493060628196, \"p4\": 0.6498180722353677, \"phi\": 0.48428331984819817}, {\"truth_threshold\": 13.52, \"match_probability\": 0.9999148788486228, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5207, \"tn\": 8049, \"fp\": 0, \"fn\": 6817, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.43305056553559546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5669494344644045, \"precision\": 1.0, \"recall\": 0.43305056553559546, \"specificity\": 1.0, \"npv\": 0.5414368357325441, \"accuracy\": 0.6603895780401534, \"f1\": 0.6043758342522199, \"f2\": 0.488434046864154, \"f0_5\": 0.7924936076951175, \"p4\": 0.6497581550137428, \"phi\": 0.48422053644572066}, {\"truth_threshold\": 13.540000000000001, \"match_probability\": 0.9999160506382885, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5206, \"tn\": 8049, \"fp\": 0, \"fn\": 6818, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4329673985362608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5670326014637392, \"precision\": 1.0, \"recall\": 0.4329673985362608, \"specificity\": 1.0, \"npv\": 0.5414004170310083, \"accuracy\": 0.660339759876451, \"f1\": 0.60429483459083, \"f2\": 0.4883494052755994, \"f0_5\": 0.7924378957622991, \"p4\": 0.6496982308651272, \"phi\": 0.4841577533494247}, {\"truth_threshold\": 13.56, \"match_probability\": 0.9999172062982694, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5203, \"tn\": 8049, \"fp\": 0, \"fn\": 6821, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.43271789753825685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5672821024617432, \"precision\": 1.0, \"recall\": 0.43271789753825685, \"specificity\": 1.0, \"npv\": 0.5412911903160726, \"accuracy\": 0.6601903053853435, \"f1\": 0.6040517791838393, \"f2\": 0.48809546145331056, \"f0_5\": 0.7922706785235717, \"p4\": 0.6495184168226398, \"phi\": 0.4839694058817679}, {\"truth_threshold\": 13.58, \"match_probability\": 0.9999183460505544, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5200, \"tn\": 8049, \"fp\": 0, \"fn\": 6824, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4324683965402528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5675316034597472, \"precision\": 1.0, \"recall\": 0.4324683965402528, \"specificity\": 1.0, \"npv\": 0.5411820076648961, \"accuracy\": 0.660040850894236, \"f1\": 0.6038086391082211, \"f2\": 0.48784148904232966, \"f0_5\": 0.7921033390202291, \"p4\": 0.6493385403122556, \"phi\": 0.4837810611126405}, {\"truth_threshold\": 13.6, \"match_probability\": 0.9999194701140777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5195, \"tn\": 8049, \"fp\": 0, \"fn\": 6829, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4320525615435795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5679474384564205, \"precision\": 1.0, \"recall\": 0.4320525615435795, \"specificity\": 1.0, \"npv\": 0.5410001344266703, \"accuracy\": 0.6597917600757236, \"f1\": 0.6034032173761542, \"f2\": 0.4874181381471543, \"f0_5\": 0.7918241677844166, \"p4\": 0.649038607055661, \"phi\": 0.4834671590444006}, {\"truth_threshold\": 13.620000000000001, \"match_probability\": 0.9999205787047616, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5189, \"tn\": 8049, \"fp\": 0, \"fn\": 6835, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4315535595475715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5684464404524284, \"precision\": 1.0, \"recall\": 0.4315535595475715, \"specificity\": 1.0, \"npv\": 0.5407820478366031, \"accuracy\": 0.6594928510935087, \"f1\": 0.6029164003950502, \"f2\": 0.48691001219855495, \"f0_5\": 0.7914887126296523, \"p4\": 0.6486784571411482, \"phi\": 0.4830904860202808}, {\"truth_threshold\": 13.64, \"match_probability\": 0.9999216720355576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5183, \"tn\": 8049, \"fp\": 0, \"fn\": 6841, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4310545575515635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5689454424484365, \"precision\": 1.0, \"recall\": 0.4310545575515635, \"specificity\": 1.0, \"npv\": 0.5405641370047012, \"accuracy\": 0.6591939421112938, \"f1\": 0.6024292439123613, \"f2\": 0.48640177180502636, \"f0_5\": 0.791152765905483, \"p4\": 0.6483180555975365, \"phi\": 0.48271382298915394}, {\"truth_threshold\": 13.66, \"match_probability\": 0.9999227503164871, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5173, \"tn\": 8049, \"fp\": 0, \"fn\": 6851, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4302228875582169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5697771124417831, \"precision\": 1.0, \"recall\": 0.4302228875582169, \"specificity\": 1.0, \"npv\": 0.5402013422818792, \"accuracy\": 0.6586957604742689, \"f1\": 0.6016165610280862, \"f2\": 0.4855544500553793, \"f0_5\": 0.7905917593837878, \"p4\": 0.6477168251256554, \"phi\": 0.48208607254237784}, {\"truth_threshold\": 13.68, \"match_probability\": 0.9999238137546823, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5162, \"tn\": 8049, \"fp\": 0, \"fn\": 6862, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4293080505655356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5706919494344644, \"precision\": 1.0, \"recall\": 0.4293080505655356, \"specificity\": 1.0, \"npv\": 0.5398028301254107, \"accuracy\": 0.6581477606735415, \"f1\": 0.6007215175142558, \"f2\": 0.48462202861541925, \"f0_5\": 0.7899730656219393, \"p4\": 0.6470546576679179, \"phi\": 0.4813955761023351}, {\"truth_threshold\": 13.700000000000001, \"match_probability\": 0.9999248625544251, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5149, \"tn\": 8049, \"fp\": 0, \"fn\": 6875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.428226879574185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5717731204258151, \"precision\": 1.0, \"recall\": 0.428226879574185, \"specificity\": 1.0, \"npv\": 0.5393326186009113, \"accuracy\": 0.6575001245454093, \"f1\": 0.5996622605252431, \"f2\": 0.483519579303221, \"f0_5\": 0.7892397302268547, \"p4\": 0.6462709905266801, \"phi\": 0.4805795712637422}, {\"truth_threshold\": 13.72, \"match_probability\": 0.9999258969171868, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5142, \"tn\": 8049, \"fp\": 0, \"fn\": 6882, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4276447105788423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5723552894211577, \"precision\": 1.0, \"recall\": 0.4276447105788423, \"specificity\": 1.0, \"npv\": 0.5390797669278682, \"accuracy\": 0.6571513973994919, \"f1\": 0.5990912268437609, \"f2\": 0.48292572974191367, \"f0_5\": 0.7888438880706922, \"p4\": 0.645848517237551, \"phi\": 0.4801401992197466}, {\"truth_threshold\": 13.74, \"match_probability\": 0.9999269170416667, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5136, \"tn\": 8049, \"fp\": 0, \"fn\": 6888, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.42714570858283435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5728542914171657, \"precision\": 1.0, \"recall\": 0.42714570858283435, \"specificity\": 1.0, \"npv\": 0.5388632255472987, \"accuracy\": 0.656852488417277, \"f1\": 0.5986013986013986, \"f2\": 0.4824165915238954, \"f0_5\": 0.7885040530582167, \"p4\": 0.6454861182350936, \"phi\": 0.4797636025227764}, {\"truth_threshold\": 13.76, \"match_probability\": 0.99992792312383, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5131, \"tn\": 8049, \"fp\": 0, \"fn\": 6893, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.426729873586161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.573270126413839, \"precision\": 1.0, \"recall\": 0.426729873586161, \"specificity\": 1.0, \"npv\": 0.5386829072413332, \"accuracy\": 0.6566033975987645, \"f1\": 0.5981929466627806, \"f2\": 0.4819922219925977, \"f0_5\": 0.7882204743763057, \"p4\": 0.6451839217154998, \"phi\": 0.47944977725526144}, {\"truth_threshold\": 13.780000000000001, \"match_probability\": 0.999928915356946, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5120, \"tn\": 8049, \"fp\": 0, \"fn\": 6904, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4258150365934797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5741849634065203, \"precision\": 1.0, \"recall\": 0.4258150365934797, \"specificity\": 1.0, \"npv\": 0.538286631445195, \"accuracy\": 0.6560553977980371, \"f1\": 0.5972935137657489, \"f2\": 0.4810583283223091, \"f0_5\": 0.7875953728771844, \"p4\": 0.6445184555271587, \"phi\": 0.4787593776278608}, {\"truth_threshold\": 13.8, \"match_probability\": 0.999929893931624, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5117, \"tn\": 8049, \"fp\": 0, \"fn\": 6907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4255655355954757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5744344644045243, \"precision\": 1.0, \"recall\": 0.4255655355954757, \"specificity\": 1.0, \"npv\": 0.5381786573950255, \"accuracy\": 0.6559059433069298, \"f1\": 0.5970480135347996, \"f2\": 0.480803563039107, \"f0_5\": 0.7874245968238336, \"p4\": 0.6443368130098652, \"phi\": 0.4785710904143375}, {\"truth_threshold\": 13.82, \"match_probability\": 0.9999308590358513, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5114, \"tn\": 8049, \"fp\": 0, \"fn\": 6910, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.42531603459747175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5746839654025283, \"precision\": 1.0, \"recall\": 0.42531603459747175, \"specificity\": 1.0, \"npv\": 0.5380707266528512, \"accuracy\": 0.6557564888158223, \"f1\": 0.5968024273544171, \"f2\": 0.4805487690283781, \"f0_5\": 0.7872536945812808, \"p4\": 0.6441551052771024, \"phi\": 0.47838280465853994}, {\"truth_threshold\": 13.84, \"match_probability\": 0.9999318108550282, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5111, \"tn\": 8049, \"fp\": 0, \"fn\": 6913, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4250665335994677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5749334664005322, \"precision\": 1.0, \"recall\": 0.4250665335994677, \"specificity\": 1.0, \"npv\": 0.5379628391926213, \"accuracy\": 0.6556070343247148, \"f1\": 0.5965567551794573, \"f2\": 0.48029394628526323, \"f0_5\": 0.7870826660096094, \"p4\": 0.6439733322308876, \"phi\": 0.4781945203167174}, {\"truth_threshold\": 13.86, \"match_probability\": 0.9999327495720041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5106, \"tn\": 8049, \"fp\": 0, \"fn\": 6918, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4246506986027944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5753493013972056, \"precision\": 1.0, \"recall\": 0.4246506986027944, \"specificity\": 1.0, \"npv\": 0.5377831228703147, \"accuracy\": 0.6553579435062024, \"f1\": 0.5961471103327496, \"f2\": 0.47986917785045674, \"f0_5\": 0.7867973372781065, \"p4\": 0.6436702317462665, \"phi\": 0.4778807161035812}, {\"truth_threshold\": 13.88, \"match_probability\": 0.9999336753671121, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5094, \"tn\": 8049, \"fp\": 0, \"fn\": 6930, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4236526946107784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5763473053892215, \"precision\": 1.0, \"recall\": 0.4236526946107784, \"specificity\": 1.0, \"npv\": 0.5373522932104947, \"accuracy\": 0.6547601255417725, \"f1\": 0.5951629863301787, \"f2\": 0.47884940778341795, \"f0_5\": 0.7861111111111111, \"p4\": 0.6429420465252746, \"phi\": 0.47712760030615203}, {\"truth_threshold\": 13.9, \"match_probability\": 0.9999345884182044, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5090, \"tn\": 8049, \"fp\": 0, \"fn\": 6934, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.42332002661343976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5766799733865602, \"precision\": 1.0, \"recall\": 0.42332002661343976, \"specificity\": 1.0, \"npv\": 0.5372088366815725, \"accuracy\": 0.6545608528869626, \"f1\": 0.5948346383078181, \"f2\": 0.47850938216823974, \"f0_5\": 0.7858819169960475, \"p4\": 0.6426990838692263, \"phi\": 0.47687656583335936}, {\"truth_threshold\": 13.92, \"match_probability\": 0.9999354889006857, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5082, \"tn\": 8049, \"fp\": 0, \"fn\": 6942, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4226546906187625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5773453093812375, \"precision\": 1.0, \"recall\": 0.4226546906187625, \"specificity\": 1.0, \"npv\": 0.5369221532919752, \"accuracy\": 0.6541623075773427, \"f1\": 0.5941774815854086, \"f2\": 0.4778291774794088, \"f0_5\": 0.7854228486646885, \"p4\": 0.6422128057742325, \"phi\": 0.4763745024515686}, {\"truth_threshold\": 13.94, \"match_probability\": 0.999936376987547, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5075, \"tn\": 8049, \"fp\": 0, \"fn\": 6949, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.42207252162341985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5779274783765802, \"precision\": 1.0, \"recall\": 0.42207252162341985, \"specificity\": 1.0, \"npv\": 0.5366715562074943, \"accuracy\": 0.6538135804314253, \"f1\": 0.5936019650271945, \"f2\": 0.47723383047149764, \"f0_5\": 0.7850204182650662, \"p4\": 0.6417869253597548, \"phi\": 0.47593520253503213}, {\"truth_threshold\": 13.96, \"match_probability\": 0.9999372528493993, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5059, \"tn\": 8049, \"fp\": 0, \"fn\": 6965, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4207418496340652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5792581503659348, \"precision\": 1.0, \"recall\": 0.4207418496340652, \"specificity\": 1.0, \"npv\": 0.5360996403356867, \"accuracy\": 0.6530164898121855, \"f1\": 0.5922847275068782, \"f2\": 0.47587244849967075, \"f0_5\": 0.7840979541227526, \"p4\": 0.6408121207482113, \"phi\": 0.47493110475414635}, {\"truth_threshold\": 14.0, \"match_probability\": 0.9999389685688129, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5050, \"tn\": 8049, \"fp\": 0, \"fn\": 6974, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4199933466400532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5800066533599467, \"precision\": 1.0, \"recall\": 0.4199933466400532, \"specificity\": 1.0, \"npv\": 0.5357784730080544, \"accuracy\": 0.6525681263388632, \"f1\": 0.5915426964975987, \"f2\": 0.4751063109170963, \"f0_5\": 0.783577457795432, \"p4\": 0.6402629549289688, \"phi\": 0.47436630775841376}, {\"truth_threshold\": 14.02, \"match_probability\": 0.9999398087559863, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5045, \"tn\": 8049, \"fp\": 0, \"fn\": 6979, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4195775116433799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5804224883566201, \"precision\": 1.0, \"recall\": 0.4195775116433799, \"specificity\": 1.0, \"npv\": 0.535600212935853, \"accuracy\": 0.6523190355203508, \"f1\": 0.5911301189290527, \"f2\": 0.4746805667940009, \"f0_5\": 0.7832877903366041, \"p4\": 0.639957600718132, \"phi\": 0.4740525335648884}, {\"truth_threshold\": 14.040000000000001, \"match_probability\": 0.9999406373774375, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5041, \"tn\": 8049, \"fp\": 0, \"fn\": 6983, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41924484364604125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5807551563539588, \"precision\": 1.0, \"recall\": 0.41924484364604125, \"specificity\": 1.0, \"npv\": 0.535457690260777, \"accuracy\": 0.6521197628655407, \"f1\": 0.5907998828010548, \"f2\": 0.4743399138077046, \"f0_5\": 0.7830557971915, \"p4\": 0.6397131821555173, \"phi\": 0.47380151501704787}, {\"truth_threshold\": 14.06, \"match_probability\": 0.9999414545923574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5037, \"tn\": 8049, \"fp\": 0, \"fn\": 6987, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4189121756487026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5810878243512974, \"precision\": 1.0, \"recall\": 0.4189121756487026, \"specificity\": 1.0, \"npv\": 0.5353152434158021, \"accuracy\": 0.6519204902107308, \"f1\": 0.590469491823457, \"f2\": 0.47399920953080005, \"f0_5\": 0.7828235732935472, \"p4\": 0.6394686431595913, \"phi\": 0.47355049707209523}, {\"truth_threshold\": 14.08, \"match_probability\": 0.9999422605577463, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5034, \"tn\": 8049, \"fp\": 0, \"fn\": 6990, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4186626746506986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5813373253493014, \"precision\": 1.0, \"recall\": 0.4186626746506986, \"specificity\": 1.0, \"npv\": 0.5352084580091762, \"accuracy\": 0.6517710357196234, \"f1\": 0.5902215969046781, \"f2\": 0.47374364765669114, \"f0_5\": 0.7826492537313433, \"p4\": 0.6392851597331092, \"phi\": 0.47336223394541926}, {\"truth_threshold\": 14.1, \"match_probability\": 0.9999430554284441, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5028, \"tn\": 8049, \"fp\": 0, \"fn\": 6996, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4181636726546906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5818363273453094, \"precision\": 1.0, \"recall\": 0.4181636726546906, \"specificity\": 1.0, \"npv\": 0.5349950149551346, \"accuracy\": 0.6514721267374085, \"f1\": 0.58972554539057, \"f2\": 0.47323243731646714, \"f0_5\": 0.7823002240477969, \"p4\": 0.6389179888334834, \"phi\": 0.47298570835236686}, {\"truth_threshold\": 14.120000000000001, \"match_probability\": 0.9999438393571597, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5022, \"tn\": 8049, \"fp\": 0, \"fn\": 7002, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4176646706586826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5823353293413174, \"precision\": 1.0, \"recall\": 0.4176646706586826, \"specificity\": 1.0, \"npv\": 0.5347817420769384, \"accuracy\": 0.6511732177551935, \"f1\": 0.5892291446673706, \"f2\": 0.4727211114876313, \"f0_5\": 0.7819506726457399, \"p4\": 0.6385505451897923, \"phi\": 0.47260918334162855}, {\"truth_threshold\": 14.14, \"match_probability\": 0.9999446124945011, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5015, \"tn\": 8049, \"fp\": 0, \"fn\": 7009, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41708250166334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5829174983366601, \"precision\": 1.0, \"recall\": 0.41708250166334, \"specificity\": 1.0, \"npv\": 0.5345331385310134, \"accuracy\": 0.6508244906092762, \"f1\": 0.5886495686366571, \"f2\": 0.47212441867033195, \"f0_5\": 0.7815422017204837, \"p4\": 0.6381215151259868, \"phi\": 0.47216990442050805}, {\"truth_threshold\": 14.16, \"match_probability\": 0.999945374989003, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5011, \"tn\": 8049, \"fp\": 0, \"fn\": 7013, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4167498336660013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5832501663339986, \"precision\": 1.0, \"recall\": 0.4167498336660013, \"specificity\": 1.0, \"npv\": 0.5343911831098128, \"accuracy\": 0.6506252179544662, \"f1\": 0.5883181684766657, \"f2\": 0.4717833807219387, \"f0_5\": 0.7813084695023076, \"p4\": 0.6378761874083756, \"phi\": 0.47191888781186975}, {\"truth_threshold\": 14.18, \"match_probability\": 0.9999461269871569, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5004, \"tn\": 8049, \"fp\": 0, \"fn\": 7020, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4161676646706587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5838323353293413, \"precision\": 1.0, \"recall\": 0.4161676646706587, \"specificity\": 1.0, \"npv\": 0.5341429424646625, \"accuracy\": 0.6502764908085488, \"f1\": 0.587737843551797, \"f2\": 0.4711864406779661, \"f0_5\": 0.7808988764044944, \"p4\": 0.6374465695778083, \"phi\": 0.4714796082184601}, {\"truth_threshold\": 14.200000000000001, \"match_probability\": 0.9999468686334378, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5001, \"tn\": 8049, \"fp\": 0, \"fn\": 7023, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4159181636726547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5840818363273453, \"precision\": 1.0, \"recall\": 0.4159181636726547, \"specificity\": 1.0, \"npv\": 0.5340366242038217, \"accuracy\": 0.6501270363174413, \"f1\": 0.587488986784141, \"f2\": 0.47093056104864683, \"f0_5\": 0.7807231172723866, \"p4\": 0.6372623327102329, \"phi\": 0.4712913452131251}, {\"truth_threshold\": 14.22, \"match_probability\": 0.9999476000703327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4997, \"tn\": 8049, \"fp\": 0, \"fn\": 7027, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41558549567531605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.584414504324684, \"precision\": 1.0, \"recall\": 0.41558549567531605, \"specificity\": 1.0, \"npv\": 0.5338949323427965, \"accuracy\": 0.6499277636626314, \"f1\": 0.5871570413019211, \"f2\": 0.47058934322792084, \"f0_5\": 0.7804885667874547, \"p4\": 0.6370165760250529, \"phi\": 0.471040327462756}, {\"truth_threshold\": 14.24, \"match_probability\": 0.9999483214383678, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4990, \"tn\": 8049, \"fp\": 0, \"fn\": 7034, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41500332667997336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5849966733200266, \"precision\": 1.0, \"recall\": 0.41500332667997336, \"specificity\": 1.0, \"npv\": 0.533647152423258, \"accuracy\": 0.649579036516714, \"f1\": 0.5865757611378865, \"f2\": 0.4699920883095355, \"f0_5\": 0.7800775387693847, \"p4\": 0.6365862054310223, \"phi\": 0.47060104497222155}, {\"truth_threshold\": 14.26, \"match_probability\": 0.9999490328761353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4982, \"tn\": 8049, \"fp\": 0, \"fn\": 7042, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4143379906852961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5856620093147039, \"precision\": 1.0, \"recall\": 0.4143379906852961, \"specificity\": 1.0, \"npv\": 0.5333642568418262, \"accuracy\": 0.6491804912070941, \"f1\": 0.5859108549923556, \"f2\": 0.46930931836165646, \"f0_5\": 0.7796069103655483, \"p4\": 0.636093889941979, \"phi\": 0.47009900498001317}, {\"truth_threshold\": 14.280000000000001, \"match_probability\": 0.9999497345203204, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4974, \"tn\": 8049, \"fp\": 0, \"fn\": 7050, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41367265469061876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5863273453093812, \"precision\": 1.0, \"recall\": 0.41367265469061876, \"specificity\": 1.0, \"npv\": 0.5330816610371548, \"accuracy\": 0.6487819458974742, \"f1\": 0.585245322979174, \"f2\": 0.4686263425664217, \"f0_5\": 0.7791353383458647, \"p4\": 0.6356010782780329, \"phi\": 0.469596961114661}, {\"truth_threshold\": 14.3, \"match_probability\": 0.9999504265057271, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4971, \"tn\": 8049, \"fp\": 0, \"fn\": 7053, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4134231536926148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5865768463073853, \"precision\": 1.0, \"recall\": 0.4134231536926148, \"specificity\": 1.0, \"npv\": 0.5329757647993644, \"accuracy\": 0.6486324914063668, \"f1\": 0.5849955869373346, \"f2\": 0.4683701735541862, \"f0_5\": 0.7789582549830764, \"p4\": 0.635416145577702, \"phi\": 0.46940869349116926}, {\"truth_threshold\": 14.32, \"match_probability\": 0.9999511089653043, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4967, \"tn\": 8049, \"fp\": 0, \"fn\": 7057, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4130904856952761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5869095143047239, \"precision\": 1.0, \"recall\": 0.4130904856952761, \"specificity\": 1.0, \"npv\": 0.5328346352442738, \"accuracy\": 0.6484332187515568, \"f1\": 0.5846624683656053, \"f2\": 0.46802856981324087, \"f0_5\": 0.7787219365358083, \"p4\": 0.6351694594880267, \"phi\": 0.4691576688793676}, {\"truth_threshold\": 14.34, \"match_probability\": 0.9999517820301712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4964, \"tn\": 8049, \"fp\": 0, \"fn\": 7060, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4128409846972721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5871590153027278, \"precision\": 1.0, \"recall\": 0.4128409846972721, \"specificity\": 1.0, \"npv\": 0.5327288371169502, \"accuracy\": 0.6482837642604493, \"f1\": 0.5844125264892865, \"f2\": 0.4677723332076894, \"f0_5\": 0.7785445420326224, \"p4\": 0.6349843629170623, \"phi\": 0.4689693995262318}, {\"truth_threshold\": 14.36, \"match_probability\": 0.9999524458296426, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4954, \"tn\": 8049, \"fp\": 0, \"fn\": 7070, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4120093147039255, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5879906852960746, \"precision\": 1.0, \"recall\": 0.4120093147039255, \"specificity\": 1.0, \"npv\": 0.5323764799259211, \"accuracy\": 0.6477855826234244, \"f1\": 0.5835787489692543, \"f2\": 0.46691800188501414, \"f0_5\": 0.7779522613065326, \"p4\": 0.6343668652620138, \"phi\": 0.46834182885875875}, {\"truth_threshold\": 14.38, \"match_probability\": 0.9999531004912537, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4951, \"tn\": 8049, \"fp\": 0, \"fn\": 7073, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4117598137059215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5882401862940785, \"precision\": 1.0, \"recall\": 0.4117598137059215, \"specificity\": 1.0, \"npv\": 0.5322708636423753, \"accuracy\": 0.6476361281323171, \"f1\": 0.5833284241531664, \"f2\": 0.4666616396780214, \"f0_5\": 0.7777742867915043, \"p4\": 0.6341814628314218, \"phi\": 0.4681535556358345}, {\"truth_threshold\": 14.4, \"match_probability\": 0.9999537461407846, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4944, \"tn\": 8049, \"fp\": 0, \"fn\": 7080, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4111776447105788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5888223552894212, \"precision\": 1.0, \"recall\": 0.4111776447105788, \"specificity\": 1.0, \"npv\": 0.5320245885385683, \"accuracy\": 0.6472874009863996, \"f1\": 0.5827439886845828, \"f2\": 0.4660633484162896, \"f0_5\": 0.7773584905660378, \"p4\": 0.633748581384729, \"phi\": 0.46771424742400497}, {\"truth_threshold\": 14.42, \"match_probability\": 0.9999543829022842, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4940, \"tn\": 8049, \"fp\": 0, \"fn\": 7084, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41084497671324016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5891550232867598, \"precision\": 1.0, \"recall\": 0.41084497671324016, \"specificity\": 1.0, \"npv\": 0.5318839622018107, \"accuracy\": 0.6470881283315897, \"f1\": 0.5824098090073095, \"f2\": 0.465721396787088, \"f0_5\": 0.7771205638056884, \"p4\": 0.6335010468078371, \"phi\": 0.4674632114562052}, {\"truth_threshold\": 14.44, \"match_probability\": 0.9999550108980944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4935, \"tn\": 8049, \"fp\": 0, \"fn\": 7089, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.41042914171656686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5895708582834331, \"precision\": 1.0, \"recall\": 0.41042914171656686, \"specificity\": 1.0, \"npv\": 0.5317082837891399, \"accuracy\": 0.6468390375130773, \"f1\": 0.5819918627277552, \"f2\": 0.46529388470894384, \"f0_5\": 0.7768228182848508, \"p4\": 0.6331914504122562, \"phi\": 0.4671494135275838}, {\"truth_threshold\": 14.46, \"match_probability\": 0.9999556302488732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4923, \"tn\": 8049, \"fp\": 0, \"fn\": 7101, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4094311377245509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5905688622754491, \"precision\": 1.0, \"recall\": 0.4094311377245509, \"specificity\": 1.0, \"npv\": 0.5312871287128713, \"accuracy\": 0.6462412195486474, \"f1\": 0.580987785448752, \"f2\": 0.46426752673569854, \"f0_5\": 0.7761066969353008, \"p4\": 0.6324476084998556, \"phi\": 0.4663962838266626}, {\"truth_threshold\": 14.48, \"match_probability\": 0.9999562410736184, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4915, \"tn\": 8049, \"fp\": 0, \"fn\": 7109, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4087658017298736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5912341982701265, \"precision\": 1.0, \"recall\": 0.4087658017298736, \"specificity\": 1.0, \"npv\": 0.5310067291199366, \"accuracy\": 0.6458426742390275, \"f1\": 0.5803176102485389, \"f2\": 0.46358302993718287, \"f0_5\": 0.7756280772629719, \"p4\": 0.6319510754954097, \"phi\": 0.4658941847165177}, {\"truth_threshold\": 14.5, \"match_probability\": 0.9999568434896896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4912, \"tn\": 8049, \"fp\": 0, \"fn\": 7112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4085163007318696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5914836992681304, \"precision\": 1.0, \"recall\": 0.4085163007318696, \"specificity\": 1.0, \"npv\": 0.5309016555636171, \"accuracy\": 0.64569321974792, \"f1\": 0.5800661313179027, \"f2\": 0.4633262903712647, \"f0_5\": 0.7754483455418035, \"p4\": 0.6317647434428784, \"phi\": 0.4657058947267836}, {\"truth_threshold\": 14.52, \"match_probability\": 0.9999574376128317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4907, \"tn\": 8049, \"fp\": 0, \"fn\": 7117, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40810046573519626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5918995342648037, \"precision\": 1.0, \"recall\": 0.40810046573519626, \"specificity\": 1.0, \"npv\": 0.5307266253461691, \"accuracy\": 0.6454441289294076, \"f1\": 0.5796468017246471, \"f2\": 0.4628983265098202, \"f0_5\": 0.7751484898268671, \"p4\": 0.6314540293800612, \"phi\": 0.4653920744725254}, {\"truth_threshold\": 14.540000000000001, \"match_probability\": 0.9999580235571964, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4898, \"tn\": 8049, \"fp\": 0, \"fn\": 7126, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4073519627411843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5926480372588157, \"precision\": 1.0, \"recall\": 0.4073519627411843, \"specificity\": 1.0, \"npv\": 0.5304118616144975, \"accuracy\": 0.6449957654560853, \"f1\": 0.5788913839971634, \"f2\": 0.46212778805147753, \"f0_5\": 0.7746077935222672, \"p4\": 0.6308942366052502, \"phi\": 0.46482718604861206}, {\"truth_threshold\": 14.56, \"match_probability\": 0.9999586014353645, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4895, \"tn\": 8049, \"fp\": 0, \"fn\": 7129, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4071024617431803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5928975382568197, \"precision\": 1.0, \"recall\": 0.4071024617431803, \"specificity\": 1.0, \"npv\": 0.530307023323231, \"accuracy\": 0.6448463109649778, \"f1\": 0.5786393994916957, \"f2\": 0.46187088373497387, \"f0_5\": 0.7744272876851032, \"p4\": 0.6307074936121821, \"phi\": 0.46463888631343103}, {\"truth_threshold\": 14.58, \"match_probability\": 0.9999591713583673, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4888, \"tn\": 8049, \"fp\": 0, \"fn\": 7136, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40652029274783763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5934797072521624, \"precision\": 1.0, \"recall\": 0.40652029274783763, \"specificity\": 1.0, \"npv\": 0.5300625617385578, \"accuracy\": 0.6444975838190604, \"f1\": 0.5780510879848628, \"f2\": 0.4612713271931149, \"f0_5\": 0.7740055738535596, \"p4\": 0.6302714763376134, \"phi\": 0.46419951289572386}, {\"truth_threshold\": 14.6, \"match_probability\": 0.9999597334357079, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4879, \"tn\": 8049, \"fp\": 0, \"fn\": 7145, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40577178975382566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5942282102461743, \"precision\": 1.0, \"recall\": 0.40577178975382566, \"specificity\": 1.0, \"npv\": 0.5297485849677505, \"accuracy\": 0.6440492203457381, \"f1\": 0.5772939714843519, \"f2\": 0.46050023596035866, \"f0_5\": 0.7734622701331643, \"p4\": 0.6297102973875304, \"phi\": 0.46363458827175597}, {\"truth_threshold\": 14.620000000000001, \"match_probability\": 0.9999602877753826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4872, \"tn\": 8049, \"fp\": 0, \"fn\": 7152, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.405189620758483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5948103792415169, \"precision\": 1.0, \"recall\": 0.405189620758483, \"specificity\": 1.0, \"npv\": 0.5295046378527728, \"accuracy\": 0.6437004931998207, \"f1\": 0.5767045454545454, \"f2\": 0.4599003171726325, \"f0_5\": 0.773038842345773, \"p4\": 0.6292733678751687, \"phi\": 0.4631951893116151}, {\"truth_threshold\": 14.64, \"match_probability\": 0.9999608344839012, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4866, \"tn\": 8049, \"fp\": 0, \"fn\": 7158, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40469061876247503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.595309381237525, \"precision\": 1.0, \"recall\": 0.40469061876247503, \"specificity\": 1.0, \"npv\": 0.529295719076741, \"accuracy\": 0.6434015842176057, \"f1\": 0.5761989342806394, \"f2\": 0.45938597484989235, \"f0_5\": 0.7726753048780488, \"p4\": 0.6288985374272816, \"phi\": 0.4628185519850036}, {\"truth_threshold\": 14.66, \"match_probability\": 0.9999613736663076, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4856, \"tn\": 8049, \"fp\": 0, \"fn\": 7168, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4038589487691284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5961410512308716, \"precision\": 1.0, \"recall\": 0.4038589487691284, \"specificity\": 1.0, \"npv\": 0.528947887231386, \"accuracy\": 0.6429034025805809, \"f1\": 0.5753554502369668, \"f2\": 0.45852847862214835, \"f0_5\": 0.7720681760366319, \"p4\": 0.6282731622332672, \"phi\": 0.4621908022569456}, {\"truth_threshold\": 14.68, \"match_probability\": 0.9999619054261999, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4847, \"tn\": 8049, \"fp\": 0, \"fn\": 7177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40311044577511645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5968895542248835, \"precision\": 1.0, \"recall\": 0.40311044577511645, \"specificity\": 1.0, \"npv\": 0.528635229213188, \"accuracy\": 0.6424550391072585, \"f1\": 0.5745954596645131, \"f2\": 0.457756455055437, \"f0_5\": 0.7715204380491532, \"p4\": 0.6277096186099819, \"phi\": 0.4616258039804091}, {\"truth_threshold\": 14.700000000000001, \"match_probability\": 0.9999624298657506, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4843, \"tn\": 8049, \"fp\": 0, \"fn\": 7181, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4027777777777778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5972222222222222, \"precision\": 1.0, \"recall\": 0.4027777777777778, \"specificity\": 1.0, \"npv\": 0.5284963887065003, \"accuracy\": 0.6422557664524485, \"f1\": 0.5742574257425742, \"f2\": 0.45741324921135645, \"f0_5\": 0.7712765957446809, \"p4\": 0.627458939275826, \"phi\": 0.46137468613566657}, {\"truth_threshold\": 14.72, \"match_probability\": 0.9999629470857259, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4833, \"tn\": 8049, \"fp\": 0, \"fn\": 7191, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40194610778443113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5980538922155688, \"precision\": 1.0, \"recall\": 0.40194610778443113, \"specificity\": 1.0, \"npv\": 0.5281496062992126, \"accuracy\": 0.6417575848154237, \"f1\": 0.5734116390816871, \"f2\": 0.4565550076517599, \"f0_5\": 0.7706659012629162, \"p4\": 0.626831658507351, \"phi\": 0.46074687039615164}, {\"truth_threshold\": 14.74, \"match_probability\": 0.9999634571855048, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4829, \"tn\": 8049, \"fp\": 0, \"fn\": 7195, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40161343978709246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5983865602129075, \"precision\": 1.0, \"recall\": 0.40161343978709246, \"specificity\": 1.0, \"npv\": 0.5280110207294674, \"accuracy\": 0.6415583121606138, \"f1\": 0.5730730433750667, \"f2\": 0.4562116202172886, \"f0_5\": 0.7704211869814933, \"p4\": 0.6265805125241276, \"phi\": 0.460495735355557}, {\"truth_threshold\": 14.76, \"match_probability\": 0.9999639602630992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4825, \"tn\": 8049, \"fp\": 0, \"fn\": 7199, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4012807717897538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5987192282102461, \"precision\": 1.0, \"recall\": 0.4012807717897538, \"specificity\": 1.0, \"npv\": 0.5278725078698846, \"accuracy\": 0.6413590395058039, \"f1\": 0.5727342869012998, \"f2\": 0.45586818087337727, \"f0_5\": 0.7701762227046354, \"p4\": 0.6263292326092144, \"phi\": 0.46024459514981836}, {\"truth_threshold\": 14.780000000000001, \"match_probability\": 0.9999644564151715, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4823, \"tn\": 8049, \"fp\": 0, \"fn\": 7201, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4011144377910845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5988855622089155, \"precision\": 1.0, \"recall\": 0.4011144377910845, \"specificity\": 1.0, \"npv\": 0.5278032786885246, \"accuracy\": 0.6412594031783988, \"f1\": 0.5725648483409509, \"f2\": 0.45569644173170315, \"f0_5\": 0.7700536466981734, \"p4\": 0.6262035423432704, \"phi\": 0.4601190230749416}, {\"truth_threshold\": 14.8, \"match_probability\": 0.9999649457370537, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4821, \"tn\": 8049, \"fp\": 0, \"fn\": 7203, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4009481037924152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5990518962075848, \"precision\": 1.0, \"recall\": 0.4009481037924152, \"specificity\": 1.0, \"npv\": 0.5277340676632573, \"accuracy\": 0.6411597668509939, \"f1\": 0.5723953695458593, \"f2\": 0.45552468960825443, \"f0_5\": 0.7699310080490609, \"p4\": 0.626077818493409, \"phi\": 0.45999344966666766}, {\"truth_threshold\": 14.82, \"match_probability\": 0.9999654283227661, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4813, \"tn\": 8049, \"fp\": 0, \"fn\": 7211, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.40028276779773786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5997172322022621, \"precision\": 1.0, \"recall\": 0.40028276779773786, \"specificity\": 1.0, \"npv\": 0.5274574049803408, \"accuracy\": 0.6407612215413739, \"f1\": 0.571717051731306, \"f2\": 0.4548375512672702, \"f0_5\": 0.7694398260647142, \"p4\": 0.6255745865794874, \"phi\": 0.4594911424183747}, {\"truth_threshold\": 14.84, \"match_probability\": 0.9999659042650346, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4810, \"tn\": 8049, \"fp\": 0, \"fn\": 7214, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.4000332667997339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5999667332002662, \"precision\": 1.0, \"recall\": 0.4000332667997339, \"specificity\": 1.0, \"npv\": 0.5273537312454957, \"accuracy\": 0.6406117670502666, \"f1\": 0.5714625163359867, \"f2\": 0.4545798208142744, \"f0_5\": 0.7692553735926305, \"p4\": 0.6253857354971751, \"phi\": 0.4593027714581794}, {\"truth_threshold\": 14.86, \"match_probability\": 0.9999663736553089, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4806, \"tn\": 8049, \"fp\": 0, \"fn\": 7218, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3997005988023952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6002994011976048, \"precision\": 1.0, \"recall\": 0.3997005988023952, \"specificity\": 1.0, \"npv\": 0.5272155629789742, \"accuracy\": 0.6404124943954566, \"f1\": 0.5711229946524065, \"f2\": 0.45423613473970736, \"f0_5\": 0.7690092165898618, \"p4\": 0.6251338157207811, \"phi\": 0.45905160518250876}, {\"truth_threshold\": 14.88, \"match_probability\": 0.9999668365837804, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4799, \"tn\": 8049, \"fp\": 0, \"fn\": 7225, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3991184298070526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6008815701929474, \"precision\": 1.0, \"recall\": 0.3991184298070526, \"specificity\": 1.0, \"npv\": 0.5269739426476365, \"accuracy\": 0.6400637672495392, \"f1\": 0.5705284432027581, \"f2\": 0.45363455903204464, \"f0_5\": 0.7685778347213325, \"p4\": 0.6246926299317829, \"phi\": 0.4586120501456067}, {\"truth_threshold\": 14.9, \"match_probability\": 0.9999672931393985, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4792, \"tn\": 8049, \"fp\": 0, \"fn\": 7232, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3985362608117099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6014637391882901, \"precision\": 1.0, \"recall\": 0.3985362608117099, \"specificity\": 1.0, \"npv\": 0.5267325436816962, \"accuracy\": 0.6397150401036218, \"f1\": 0.5699333967649858, \"f2\": 0.453032824081077, \"f0_5\": 0.7681456783790716, \"p4\": 0.6242510277510589, \"phi\": 0.4581724767014534}, {\"truth_threshold\": 14.92, \"match_probability\": 0.9999677434098888, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4786, \"tn\": 8049, \"fp\": 0, \"fn\": 7238, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39803725881570196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.601962741184298, \"precision\": 1.0, \"recall\": 0.39803725881570196, \"specificity\": 1.0, \"npv\": 0.5265258062405966, \"accuracy\": 0.6394161311214068, \"f1\": 0.5694229625223082, \"f2\": 0.4525169244733558, \"f0_5\": 0.7677746406570842, \"p4\": 0.6238721790705952, \"phi\": 0.457795684352457}, {\"truth_threshold\": 14.94, \"match_probability\": 0.9999681874817694, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4780, \"tn\": 8049, \"fp\": 0, \"fn\": 7244, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39753825681969396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6024617431803061, \"precision\": 1.0, \"recall\": 0.39753825681969396, \"specificity\": 1.0, \"npv\": 0.5263192310207284, \"accuracy\": 0.639117222139192, \"f1\": 0.5689121637705308, \"f2\": 0.45200090778424995, \"f0_5\": 0.7674030310814282, \"p4\": 0.6234930224652129, \"phi\": 0.45741887765008366}, {\"truth_threshold\": 14.96, \"match_probability\": 0.9999686254403675, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4772, \"tn\": 8049, \"fp\": 0, \"fn\": 7252, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39687292082501663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6031270791749833, \"precision\": 1.0, \"recall\": 0.39687292082501663, \"specificity\": 1.0, \"npv\": 0.5260440494085354, \"accuracy\": 0.6387186768295721, \"f1\": 0.5682305310788283, \"f2\": 0.45131270333661194, \"f0_5\": 0.7669066598097197, \"p4\": 0.622986999722858, \"phi\": 0.45691644572217444}, {\"truth_threshold\": 14.98, \"match_probability\": 0.9999690573698359, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4763, \"tn\": 8049, \"fp\": 0, \"fn\": 7261, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39612441783100466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6038755821689954, \"precision\": 1.0, \"recall\": 0.39612441783100466, \"specificity\": 1.0, \"npv\": 0.5257348138471587, \"accuracy\": 0.6382703133562497, \"f1\": 0.5674629177339608, \"f2\": 0.45053822433265855, \"f0_5\": 0.7663470202085211, \"p4\": 0.6224170650661741, \"phi\": 0.45635117734996294}, {\"truth_threshold\": 15.0, \"match_probability\": 0.9999694833531692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4758, \"tn\": 8049, \"fp\": 0, \"fn\": 7266, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39570858283433136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6042914171656687, \"precision\": 1.0, \"recall\": 0.39570858283433136, \"specificity\": 1.0, \"npv\": 0.5255631733594515, \"accuracy\": 0.6380212225377373, \"f1\": 0.5670361101179836, \"f2\": 0.4501078442501987, \"f0_5\": 0.7660355486862442, \"p4\": 0.6221001320518251, \"phi\": 0.4560371240589768}, {\"truth_threshold\": 15.02, \"match_probability\": 0.9999699034722195, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4752, \"tn\": 8049, \"fp\": 0, \"fn\": 7272, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39520958083832336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6047904191616766, \"precision\": 1.0, \"recall\": 0.39520958083832336, \"specificity\": 1.0, \"npv\": 0.525357352653221, \"accuracy\": 0.6377223135555223, \"f1\": 0.5665236051502146, \"f2\": 0.44959128065395093, \"f0_5\": 0.765661252900232, \"p4\": 0.6217195261213452, \"phi\": 0.4556602452841489}, {\"truth_threshold\": 15.040000000000001, \"match_probability\": 0.9999703178077124, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4746, \"tn\": 8049, \"fp\": 0, \"fn\": 7278, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39471057884231536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6052894211576846, \"precision\": 1.0, \"recall\": 0.39471057884231536, \"specificity\": 1.0, \"npv\": 0.5251516930906244, \"accuracy\": 0.6374234045733074, \"f1\": 0.5660107334525939, \"f2\": 0.4490745997501987, \"f0_5\": 0.7652863777089783, \"p4\": 0.6213386069577382, \"phi\": 0.45528334996990866}, {\"truth_threshold\": 15.06, \"match_probability\": 0.9999707264392624, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4736, \"tn\": 8049, \"fp\": 0, \"fn\": 7288, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39387890884896876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6061210911510313, \"precision\": 1.0, \"recall\": 0.39387890884896876, \"specificity\": 1.0, \"npv\": 0.5248092847362588, \"accuracy\": 0.6369252229362826, \"f1\": 0.5651551312649165, \"f2\": 0.4482132041187159, \"f0_5\": 0.7646602944975458, \"p4\": 0.6207030430387799, \"phi\": 0.4546551533038258}, {\"truth_threshold\": 15.08, \"match_probability\": 0.9999711294453882, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4729, \"tn\": 8049, \"fp\": 0, \"fn\": 7295, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39329673985362607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6067032601463739, \"precision\": 1.0, \"recall\": 0.39329673985362607, \"specificity\": 1.0, \"npv\": 0.5245698644421272, \"accuracy\": 0.6365764957903651, \"f1\": 0.5645556019817346, \"f2\": 0.44761003312825365, \"f0_5\": 0.7642210730446024, \"p4\": 0.6202576266692268, \"phi\": 0.4542153866950648}, {\"truth_threshold\": 15.1, \"match_probability\": 0.9999715269035279, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4722, \"tn\": 8049, \"fp\": 0, \"fn\": 7302, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39271457085828343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6072854291417166, \"precision\": 1.0, \"recall\": 0.39271457085828343, \"specificity\": 1.0, \"npv\": 0.5243306624975571, \"accuracy\": 0.6362277686444477, \"f1\": 0.5639555714797564, \"f2\": 0.44700670226059297, \"f0_5\": 0.7637810559006211, \"p4\": 0.6198117789925525, \"phi\": 0.4537755955431799}, {\"truth_threshold\": 15.120000000000001, \"match_probability\": 0.9999719188900533, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4719, \"tn\": 8049, \"fp\": 0, \"fn\": 7305, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39246506986027946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6075349301397206, \"precision\": 1.0, \"recall\": 0.39246506986027946, \"specificity\": 1.0, \"npv\": 0.5242282141461508, \"accuracy\": 0.6360783141533403, \"f1\": 0.5636982619602222, \"f2\": 0.4467480829309855, \"f0_5\": 0.7635922330097087, \"p4\": 0.6196205690070133, \"phi\": 0.4535871059538605}, {\"truth_threshold\": 15.14, \"match_probability\": 0.9999723054802854, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4717, \"tn\": 8049, \"fp\": 0, \"fn\": 7307, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3922987358616101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6077012641383899, \"precision\": 1.0, \"recall\": 0.3922987358616101, \"specificity\": 1.0, \"npv\": 0.5241599374837197, \"accuracy\": 0.6359786778259353, \"f1\": 0.5635266710471298, \"f2\": 0.44657565372162156, \"f0_5\": 0.7634662695843584, \"p4\": 0.6194930514577759, \"phi\": 0.45346144363568974}, {\"truth_threshold\": 15.16, \"match_probability\": 0.9999726867485083, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4710, \"tn\": 8049, \"fp\": 0, \"fn\": 7314, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3917165668662675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6082834331337326, \"precision\": 1.0, \"recall\": 0.3917165668662675, \"specificity\": 1.0, \"npv\": 0.5239211091583675, \"accuracy\": 0.6356299506800179, \"f1\": 0.5629257798494084, \"f2\": 0.4459720486308374, \"f0_5\": 0.7630248833592534, \"p4\": 0.6190464608527855, \"phi\": 0.4530216089639463}, {\"truth_threshold\": 15.18, \"match_probability\": 0.9999730627679836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4703, \"tn\": 8049, \"fp\": 0, \"fn\": 7321, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3911343978709248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6088656021290751, \"precision\": 1.0, \"recall\": 0.3911343978709248, \"specificity\": 1.0, \"npv\": 0.5236824983734548, \"accuracy\": 0.6352812235341005, \"f1\": 0.5623243857236803, \"f2\": 0.4453682834902176, \"f0_5\": 0.762582695550655, \"p4\": 0.6185994347956357, \"phi\": 0.4525817480597763}, {\"truth_threshold\": 15.200000000000001, \"match_probability\": 0.9999734336109646, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4694, \"tn\": 8049, \"fp\": 0, \"fn\": 7330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.39038589487691283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6096141051230871, \"precision\": 1.0, \"recall\": 0.39038589487691283, \"specificity\": 1.0, \"npv\": 0.5233760322517719, \"accuracy\": 0.6348328600607782, \"f1\": 0.5615504246919488, \"f2\": 0.4445917787459746, \"f0_5\": 0.762012987012987, \"p4\": 0.6180240446843974, \"phi\": 0.4520161730599204}, {\"truth_threshold\": 15.22, \"match_probability\": 0.9999737993487102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4681, \"tn\": 8049, \"fp\": 0, \"fn\": 7343, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3893047238855622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6106952761144377, \"precision\": 1.0, \"recall\": 0.3893047238855622, \"specificity\": 1.0, \"npv\": 0.5229339916839917, \"accuracy\": 0.6341852239326459, \"f1\": 0.5604310086800359, \"f2\": 0.44346969323758456, \"f0_5\": 0.7611877195264732, \"p4\": 0.6171916436801465, \"phi\": 0.4511991503127098}, {\"truth_threshold\": 15.24, \"match_probability\": 0.9999741600514982, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4675, \"tn\": 8049, \"fp\": 0, \"fn\": 7349, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3888057218895542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6111942781104458, \"precision\": 1.0, \"recall\": 0.3888057218895542, \"specificity\": 1.0, \"npv\": 0.522730224704507, \"accuracy\": 0.6338863149504309, \"f1\": 0.5599137672914546, \"f2\": 0.4429516211555589, \"f0_5\": 0.7608058846504362, \"p4\": 0.6168069452038385, \"phi\": 0.4508220295967409}, {\"truth_threshold\": 15.26, \"match_probability\": 0.9999745157886392, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4667, \"tn\": 8049, \"fp\": 0, \"fn\": 7357, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3881403858948769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6118596141051231, \"precision\": 1.0, \"recall\": 0.3881403858948769, \"specificity\": 1.0, \"npv\": 0.5224587822926132, \"accuracy\": 0.633487769640811, \"f1\": 0.5592235336408843, \"f2\": 0.44226067509428957, \"f0_5\": 0.7602958425648377, \"p4\": 0.6162935072188733, \"phi\": 0.45031916833866004}, {\"truth_threshold\": 15.280000000000001, \"match_probability\": 0.9999748666284898, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4659, \"tn\": 8049, \"fp\": 0, \"fn\": 7365, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3874750499001996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6125249500998003, \"precision\": 1.0, \"recall\": 0.3874750499001996, \"specificity\": 1.0, \"npv\": 0.5221876216426625, \"accuracy\": 0.6330892243311912, \"f1\": 0.5585326380147455, \"f2\": 0.4415695194768268, \"f0_5\": 0.7597847358121331, \"p4\": 0.6157794880222459, \"phi\": 0.44981626777302886}, {\"truth_threshold\": 15.3, \"match_probability\": 0.9999752126384654, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4656, \"tn\": 8049, \"fp\": 0, \"fn\": 7368, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3872255489021956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6127744510978044, \"precision\": 1.0, \"recall\": 0.3872255489021956, \"specificity\": 1.0, \"npv\": 0.5220860089511579, \"accuracy\": 0.6329397698400837, \"f1\": 0.5582733812949641, \"f2\": 0.44131028207461326, \"f0_5\": 0.759592795614722, \"p4\": 0.6155865805006456, \"phi\": 0.449627669733824}, {\"truth_threshold\": 15.32, \"match_probability\": 0.9999755538850542, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4652, \"tn\": 8049, \"fp\": 0, \"fn\": 7372, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38689288090485696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.613107119095143, \"precision\": 1.0, \"recall\": 0.38689288090485696, \"specificity\": 1.0, \"npv\": 0.5219505868620712, \"accuracy\": 0.6327404971852737, \"f1\": 0.557927560566083, \"f2\": 0.44096458633502694, \"f0_5\": 0.7593366414207365, \"p4\": 0.6153292426031592, \"phi\": 0.4493761967895579}, {\"truth_threshold\": 15.34, \"match_probability\": 0.9999758904338284, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4649, \"tn\": 8049, \"fp\": 0, \"fn\": 7375, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38664337990685294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6133566200931471, \"precision\": 1.0, \"recall\": 0.38664337990685294, \"specificity\": 1.0, \"npv\": 0.5218490663900415, \"accuracy\": 0.6325910426941663, \"f1\": 0.5576680861272716, \"f2\": 0.4407052801213385, \"f0_5\": 0.7591443500979752, \"p4\": 0.6151361431171328, \"phi\": 0.4491875853474597}, {\"truth_threshold\": 15.36, \"match_probability\": 0.999976222349458, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4644, \"tn\": 8049, \"fp\": 0, \"fn\": 7380, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38622754491017963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6137724550898204, \"precision\": 1.0, \"recall\": 0.38622754491017963, \"specificity\": 1.0, \"npv\": 0.5216799533346296, \"accuracy\": 0.6323419518756539, \"f1\": 0.5572354211663066, \"f2\": 0.4402730375426621, \"f0_5\": 0.7588235294117647, \"p4\": 0.6148141272937934, \"phi\": 0.4488732199689474}, {\"truth_threshold\": 15.38, \"match_probability\": 0.999976549695723, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4642, \"tn\": 8049, \"fp\": 0, \"fn\": 7382, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3860612109115103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6139387890884896, \"precision\": 1.0, \"recall\": 0.3860612109115103, \"specificity\": 1.0, \"npv\": 0.5216123387985224, \"accuracy\": 0.632242315548249, \"f1\": 0.5570622824912996, \"f2\": 0.44010011756228906, \"f0_5\": 0.7586950836820083, \"p4\": 0.6146852566851179, \"phi\": 0.4487474692329112}, {\"truth_threshold\": 15.4, \"match_probability\": 0.999976872535525, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4631, \"tn\": 8049, \"fp\": 0, \"fn\": 7393, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.385146373918829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.614853626081171, \"precision\": 1.0, \"recall\": 0.385146373918829, \"specificity\": 1.0, \"npv\": 0.5212407719207357, \"accuracy\": 0.6316943157475216, \"f1\": 0.5561092764935455, \"f2\": 0.4391488231835682, \"f0_5\": 0.7579874296189604, \"p4\": 0.6139758097782024, \"phi\": 0.4480557925570461}, {\"truth_threshold\": 15.42, \"match_probability\": 0.9999771909309003, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4621, \"tn\": 8049, \"fp\": 0, \"fn\": 7403, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3843147039254824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6156852960745176, \"precision\": 1.0, \"recall\": 0.3843147039254824, \"specificity\": 1.0, \"npv\": 0.5209034429200103, \"accuracy\": 0.6311961341104967, \"f1\": 0.5552418143586663, \"f2\": 0.4382836656107138, \"f0_5\": 0.7573423364363445, \"p4\": 0.6133298871783006, \"phi\": 0.4474269241335038}, {\"truth_threshold\": 15.44, \"match_probability\": 0.999977504943031, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4619, \"tn\": 8049, \"fp\": 0, \"fn\": 7405, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38414836992681306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.615851630073187, \"precision\": 1.0, \"recall\": 0.38414836992681306, \"specificity\": 1.0, \"npv\": 0.5208360295069238, \"accuracy\": 0.6310964977830917, \"f1\": 0.5550681968395121, \"f2\": 0.4381105947073888, \"f0_5\": 0.7572131147540984, \"p4\": 0.6132005912719792, \"phi\": 0.4473011421114843}, {\"truth_threshold\": 15.46, \"match_probability\": 0.999977814632257, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4612, \"tn\": 8049, \"fp\": 0, \"fn\": 7412, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38356620093147037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6164337990685296, \"precision\": 1.0, \"recall\": 0.38356620093147037, \"specificity\": 1.0, \"npv\": 0.520600219908156, \"accuracy\": 0.6307477706371744, \"f1\": 0.554460206780476, \"f2\": 0.4375047431129999, \"f0_5\": 0.7567603045418745, \"p4\": 0.6127477622740611, \"phi\": 0.44686088277478425}, {\"truth_threshold\": 15.48, \"match_probability\": 0.9999781200580878, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4609, \"tn\": 8049, \"fp\": 0, \"fn\": 7415, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3833166999334664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6166833000665336, \"precision\": 1.0, \"recall\": 0.3833166999334664, \"specificity\": 1.0, \"npv\": 0.5204992240041386, \"accuracy\": 0.6305983161460669, \"f1\": 0.5541994829555702, \"f2\": 0.43724504316478513, \"f0_5\": 0.7565659881812212, \"p4\": 0.6125535527420355, \"phi\": 0.4466721894893352}, {\"truth_threshold\": 15.5, \"match_probability\": 0.9999784212792137, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4603, \"tn\": 8049, \"fp\": 0, \"fn\": 7421, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3828176979374584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6171823020625415, \"precision\": 1.0, \"recall\": 0.3828176979374584, \"specificity\": 1.0, \"npv\": 0.5202973497091145, \"accuracy\": 0.6302994071638519, \"f1\": 0.5536777530522644, \"f2\": 0.43672555456460277, \"f0_5\": 0.7561768957813116, \"p4\": 0.6121648810675493, \"phi\": 0.4462947833647666}, {\"truth_threshold\": 15.52, \"match_probability\": 0.999978718353517, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4599, \"tn\": 8049, \"fp\": 0, \"fn\": 7425, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38248502994011974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6175149700598802, \"precision\": 1.0, \"recall\": 0.38248502994011974, \"specificity\": 1.0, \"npv\": 0.5201628538193098, \"accuracy\": 0.630100134509042, \"f1\": 0.5533297238765565, \"f2\": 0.4363791631084543, \"f0_5\": 0.7559171597633136, \"p4\": 0.6119055790888273, \"phi\": 0.4460431646341157}, {\"truth_threshold\": 15.540000000000001, \"match_probability\": 0.9999790113380835, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4589, \"tn\": 8049, \"fp\": 0, \"fn\": 7435, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38165335994677313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6183466400532269, \"precision\": 1.0, \"recall\": 0.38165335994677313, \"specificity\": 1.0, \"npv\": 0.5198269181090157, \"accuracy\": 0.6296019528720171, \"f1\": 0.5524589177150424, \"f2\": 0.4355129543513334, \"f0_5\": 0.7552666227781435, \"p4\": 0.6112566655744807, \"phi\": 0.44541406565922675}, {\"truth_threshold\": 15.56, \"match_probability\": 0.9999793002892131, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4582, \"tn\": 8049, \"fp\": 0, \"fn\": 7442, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3810711909514305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6189288090485695, \"precision\": 1.0, \"recall\": 0.3810711909514305, \"specificity\": 1.0, \"npv\": 0.5195920211735847, \"accuracy\": 0.6292532257260998, \"f1\": 0.5518487293749247, \"f2\": 0.4349064125441361, \"f0_5\": 0.7548102266736954, \"p4\": 0.6108018643471339, \"phi\": 0.44497365126204813}, {\"truth_threshold\": 15.58, \"match_probability\": 0.9999795852624306, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4578, \"tn\": 8049, \"fp\": 0, \"fn\": 7446, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.38073852295409183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6192614770459082, \"precision\": 1.0, \"recall\": 0.38073852295409183, \"specificity\": 1.0, \"npv\": 0.5194578896418199, \"accuracy\": 0.6290539530712898, \"f1\": 0.5514998192988797, \"f2\": 0.4345597448456544, \"f0_5\": 0.7545490506329114, \"p4\": 0.6105417694828132, \"phi\": 0.4447219689188698}, {\"truth_threshold\": 15.6, \"match_probability\": 0.9999798663124968, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4565, \"tn\": 8049, \"fp\": 0, \"fn\": 7459, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3796573519627412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6203426480372588, \"precision\": 1.0, \"recall\": 0.3796573519627412, \"specificity\": 1.0, \"npv\": 0.5190224400309518, \"accuracy\": 0.6284063169431575, \"f1\": 0.5503646994996685, \"f2\": 0.433432711114487, \"f0_5\": 0.7536983225465592, \"p4\": 0.6096954099459806, \"phi\": 0.4439039143681792}, {\"truth_threshold\": 15.620000000000001, \"match_probability\": 0.9999801434934182, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4560, \"tn\": 8049, \"fp\": 0, \"fn\": 7464, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37924151696606784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6207584830339321, \"precision\": 1.0, \"recall\": 0.37924151696606784, \"specificity\": 1.0, \"npv\": 0.5188551537420228, \"accuracy\": 0.6281572261246451, \"f1\": 0.5499276410998553, \"f2\": 0.43299908842297175, \"f0_5\": 0.753370340999207, \"p4\": 0.6093694573537309, \"phi\": 0.4435892419691748}, {\"truth_threshold\": 15.64, \"match_probability\": 0.9999804168584587, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4556, \"tn\": 8049, \"fp\": 0, \"fn\": 7468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37890884896872923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6210911510312708, \"precision\": 1.0, \"recall\": 0.37890884896872923, \"specificity\": 1.0, \"npv\": 0.5187214023329252, \"accuracy\": 0.6279579534698351, \"f1\": 0.549577804583836, \"f2\": 0.4326521309731824, \"f0_5\": 0.7531076434805607, \"p4\": 0.6091085227636165, \"phi\": 0.44333748938411893}, {\"truth_threshold\": 15.66, \"match_probability\": 0.9999806864601481, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4549, \"tn\": 8049, \"fp\": 0, \"fn\": 7475, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37832667997338654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6216733200266135, \"precision\": 1.0, \"recall\": 0.37832667997338654, \"specificity\": 1.0, \"npv\": 0.5184875032208194, \"accuracy\": 0.6276092263239177, \"f1\": 0.5489651843359682, \"f2\": 0.43204482856871496, \"f0_5\": 0.7526472534745202, \"p4\": 0.6086515172398494, \"phi\": 0.44289689059782655}, {\"truth_threshold\": 15.68, \"match_probability\": 0.9999809523502939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4545, \"tn\": 8049, \"fp\": 0, \"fn\": 7479, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37799401197604793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6220059880239521, \"precision\": 1.0, \"recall\": 0.37799401197604793, \"specificity\": 1.0, \"npv\": 0.518353941267388, \"accuracy\": 0.6274099536691078, \"f1\": 0.5486148832156437, \"f2\": 0.43169772610702684, \"f0_5\": 0.7523837902264601, \"p4\": 0.6083901592667788, \"phi\": 0.4426451015014813}, {\"truth_threshold\": 15.700000000000001, \"match_probability\": 0.9999812145799899, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4537, \"tn\": 8049, \"fp\": 0, \"fn\": 7487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3773286759813706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6226713240186295, \"precision\": 1.0, \"recall\": 0.3773286759813706, \"specificity\": 1.0, \"npv\": 0.5180870236869207, \"accuracy\": 0.6270114083594879, \"f1\": 0.547913773322867, \"f2\": 0.43100336290920144, \"f0_5\": 0.7518560254540634, \"p4\": 0.607866979377518, \"phi\": 0.44214148266241066}, {\"truth_threshold\": 15.72, \"match_probability\": 0.9999814731996269, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4533, \"tn\": 8049, \"fp\": 0, \"fn\": 7491, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37699600798403193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.623003992015968, \"precision\": 1.0, \"recall\": 0.37699600798403193, \"specificity\": 1.0, \"npv\": 0.5179536679536679, \"accuracy\": 0.626812135704678, \"f1\": 0.5475629643051277, \"f2\": 0.4306561021490053, \"f0_5\": 0.7515917230401911, \"p4\": 0.6076051568336439, \"phi\": 0.44188965267272284}, {\"truth_threshold\": 15.74, \"match_probability\": 0.999981728258902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4529, \"tn\": 8049, \"fp\": 0, \"fn\": 7495, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37666333998669327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6233366600133067, \"precision\": 1.0, \"recall\": 0.37666333998669327, \"specificity\": 1.0, \"npv\": 0.5178203808543489, \"accuracy\": 0.626612863049868, \"f1\": 0.5472119857427656, \"f2\": 0.4303087885985748, \"f0_5\": 0.7513271400132714, \"p4\": 0.6073431788040003, \"phi\": 0.44163780880465914}, {\"truth_threshold\": 15.76, \"match_probability\": 0.9999819798068281, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4524, \"tn\": 8049, \"fp\": 0, \"fn\": 7500, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37624750499001997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6237524950099801, \"precision\": 1.0, \"recall\": 0.37624750499001997, \"specificity\": 1.0, \"npv\": 0.5176538684159753, \"accuracy\": 0.6263637722313555, \"f1\": 0.5467730239303843, \"f2\": 0.4298745724059293, \"f0_5\": 0.750996015936255, \"p4\": 0.6070154871342628, \"phi\": 0.44132298426429456}, {\"truth_threshold\": 15.780000000000001, \"match_probability\": 0.9999822278917435, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4521, \"tn\": 8049, \"fp\": 0, \"fn\": 7503, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.375998003992016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.624001996007984, \"precision\": 1.0, \"recall\": 0.375998003992016, \"specificity\": 1.0, \"npv\": 0.517554012345679, \"accuracy\": 0.626214317740248, \"f1\": 0.5465095194922938, \"f2\": 0.42961400307885284, \"f0_5\": 0.7507971303308091, \"p4\": 0.6068187550244231, \"phi\": 0.44113407893749773}, {\"truth_threshold\": 15.8, \"match_probability\": 0.9999824725613211, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4515, \"tn\": 8049, \"fp\": 0, \"fn\": 7509, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.375499001996008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6245009980039921, \"precision\": 1.0, \"recall\": 0.375499001996008, \"specificity\": 1.0, \"npv\": 0.5173544157346702, \"accuracy\": 0.6259154087580332, \"f1\": 0.5459822238345728, \"f2\": 0.42909277527513257, \"f0_5\": 0.7503988831272437, \"p4\": 0.606425026687468, \"phi\": 0.4407562441833315}, {\"truth_threshold\": 15.82, \"match_probability\": 0.9999827138625776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4502, \"tn\": 8049, \"fp\": 0, \"fn\": 7522, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37441783100465736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6255821689953427, \"precision\": 1.0, \"recall\": 0.37441783100465736, \"specificity\": 1.0, \"npv\": 0.5169224841050671, \"accuracy\": 0.6252677726299009, \"f1\": 0.5448384364032434, \"f2\": 0.42796304041978783, \"f0_5\": 0.7495338305807139, \"p4\": 0.605570736028116, \"phi\": 0.4399374902144152}, {\"truth_threshold\": 15.84, \"match_probability\": 0.9999829518418826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4494, \"tn\": 8049, \"fp\": 0, \"fn\": 7530, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37375249500998003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6262475049900199, \"precision\": 1.0, \"recall\": 0.37375249500998003, \"specificity\": 1.0, \"npv\": 0.5166570383208164, \"accuracy\": 0.6248692273202809, \"f1\": 0.5441336723574283, \"f2\": 0.4272675413576726, \"f0_5\": 0.749, \"p4\": 0.6050441901624058, \"phi\": 0.4394335639625995}, {\"truth_threshold\": 15.860000000000001, \"match_probability\": 0.999983186544967, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4486, \"tn\": 8049, \"fp\": 0, \"fn\": 7538, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3730871590153027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6269128409846972, \"precision\": 1.0, \"recall\": 0.3730871590153027, \"specificity\": 1.0, \"npv\": 0.5163918650157182, \"accuracy\": 0.6244706820106611, \"f1\": 0.5434282253179891, \"f2\": 0.42657183066448595, \"f0_5\": 0.7484650293646556, \"p4\": 0.604517009926072, \"phi\": 0.4389295773325466}, {\"truth_threshold\": 15.88, \"match_probability\": 0.9999834180169326, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4480, \"tn\": 8049, \"fp\": 0, \"fn\": 7544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37258815701929476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6274118429807053, \"precision\": 1.0, \"recall\": 0.37258815701929476, \"specificity\": 1.0, \"npv\": 0.5161931635990509, \"accuracy\": 0.6241717730284462, \"f1\": 0.5428986912263694, \"f2\": 0.426049908703591, \"f0_5\": 0.7480630510285867, \"p4\": 0.6041212068900756, \"phi\": 0.438551547131383}, {\"truth_threshold\": 15.9, \"match_probability\": 0.9999836463022602, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4477, \"tn\": 8049, \"fp\": 0, \"fn\": 7547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37233865602129074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6276613439787092, \"precision\": 1.0, \"recall\": 0.37233865602129074, \"specificity\": 1.0, \"npv\": 0.5160938702231341, \"accuracy\": 0.6240223185373387, \"f1\": 0.542633779770923, \"f2\": 0.4257889030490936, \"f0_5\": 0.7478618201256181, \"p4\": 0.6039231706732648, \"phi\": 0.4383625189494515}, {\"truth_threshold\": 15.92, \"match_probability\": 0.9999838714448183, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4472, \"tn\": 8049, \"fp\": 0, \"fn\": 7552, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37192282102461743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6280771789753826, \"precision\": 1.0, \"recall\": 0.37192282102461743, \"specificity\": 1.0, \"npv\": 0.5159284661239664, \"accuracy\": 0.6237732277188263, \"f1\": 0.542192046556741, \"f2\": 0.4253538274235276, \"f0_5\": 0.7475260764910404, \"p4\": 0.6035929102844286, \"phi\": 0.43804745241552234}, {\"truth_threshold\": 15.94, \"match_probability\": 0.9999840934878717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4466, \"tn\": 8049, \"fp\": 0, \"fn\": 7558, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37142381902860944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6285761809713906, \"precision\": 1.0, \"recall\": 0.37142381902860944, \"specificity\": 1.0, \"npv\": 0.5157301210995067, \"accuracy\": 0.6234743187366114, \"f1\": 0.5416616130988477, \"f2\": 0.42483162741143793, \"f0_5\": 0.747122591006424, \"p4\": 0.6031962669887174, \"phi\": 0.4376693399895245}, {\"truth_threshold\": 15.96, \"match_probability\": 0.9999843124740891, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4465, \"tn\": 8049, \"fp\": 0, \"fn\": 7559, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3713406520292748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6286593479707252, \"precision\": 1.0, \"recall\": 0.3713406520292748, \"specificity\": 1.0, \"npv\": 0.5156970784213224, \"accuracy\": 0.6234245005729089, \"f1\": 0.5415731699921159, \"f2\": 0.42474458248511254, \"f0_5\": 0.7470552804176148, \"p4\": 0.6031301246134305, \"phi\": 0.4376063177681121}, {\"truth_threshold\": 15.98, \"match_probability\": 0.9999845284455526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4460, \"tn\": 8049, \"fp\": 0, \"fn\": 7564, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37092481703260144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6290751829673985, \"precision\": 1.0, \"recall\": 0.37092481703260144, \"specificity\": 1.0, \"npv\": 0.5155319285211042, \"accuracy\": 0.6231754097543964, \"f1\": 0.5411307934967241, \"f2\": 0.4243093081665271, \"f0_5\": 0.7467184570050898, \"p4\": 0.6027992617474108, \"phi\": 0.43729119161167057}, {\"truth_threshold\": 16.0, \"match_probability\": 0.9999847414437646, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4455, \"tn\": 8049, \"fp\": 0, \"fn\": 7569, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.37050898203592814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6294910179640718, \"precision\": 1.0, \"recall\": 0.37050898203592814, \"specificity\": 1.0, \"npv\": 0.5153668843641952, \"accuracy\": 0.622926318935884, \"f1\": 0.5406881485527034, \"f2\": 0.4238739510190101, \"f0_5\": 0.7463811821471653, \"p4\": 0.6024681467623719, \"phi\": 0.43697604019077046}, {\"truth_threshold\": 16.02, \"match_probability\": 0.999984951509656, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4453, \"tn\": 8049, \"fp\": 0, \"fn\": 7571, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3703426480372588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6296573519627412, \"precision\": 1.0, \"recall\": 0.3703426480372588, \"specificity\": 1.0, \"npv\": 0.5153008962868117, \"accuracy\": 0.6228266826084791, \"f1\": 0.5405110153547369, \"f2\": 0.42369978496260635, \"f0_5\": 0.7462461455959244, \"p4\": 0.602335630031296, \"phi\": 0.4368499724926519}, {\"truth_threshold\": 16.04, \"match_probability\": 0.9999851586835948, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4444, \"tn\": 8049, \"fp\": 0, \"fn\": 7580, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36959414504324684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6304058549567532, \"precision\": 1.0, \"recall\": 0.36959414504324684, \"specificity\": 1.0, \"npv\": 0.5150041589353126, \"accuracy\": 0.6223783191351567, \"f1\": 0.5397133835316978, \"f2\": 0.42291587362009897, \"f0_5\": 0.7456375838926175, \"p4\": 0.6017388031701977, \"phi\": 0.43628261690722137}, {\"truth_threshold\": 16.06, \"match_probability\": 0.9999853630053928, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4438, \"tn\": 8049, \"fp\": 0, \"fn\": 7586, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36909514304723884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6309048569527611, \"precision\": 1.0, \"recall\": 0.36909514304723884, \"specificity\": 1.0, \"npv\": 0.5148065238247521, \"accuracy\": 0.6220794101529418, \"f1\": 0.5391811444538939, \"f2\": 0.4223931168386188, \"f0_5\": 0.745231058570661, \"p4\": 0.6013404613053798, \"phi\": 0.43590433302818715}, {\"truth_threshold\": 16.080000000000002, \"match_probability\": 0.9999855645143139, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4437, \"tn\": 8049, \"fp\": 0, \"fn\": 7587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3690119760479042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6309880239520959, \"precision\": 1.0, \"recall\": 0.3690119760479042, \"specificity\": 1.0, \"npv\": 0.5147735993860323, \"accuracy\": 0.6220295919892392, \"f1\": 0.5390924002186988, \"f2\": 0.42230597909885215, \"f0_5\": 0.7451632406287787, \"p4\": 0.6012740353308766, \"phi\": 0.4358412820359402}, {\"truth_threshold\": 16.1, \"match_probability\": 0.9999857632490817, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4435, \"tn\": 8049, \"fp\": 0, \"fn\": 7589, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36884564204923487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6311543579507651, \"precision\": 1.0, \"recall\": 0.36884564204923487, \"specificity\": 1.0, \"npv\": 0.5147077631410666, \"accuracy\": 0.6219299556618343, \"f1\": 0.5389148793972902, \"f2\": 0.42213169366659686, \"f0_5\": 0.7450275500604757, \"p4\": 0.6011411527662723, \"phi\": 0.4357151768799111}, {\"truth_threshold\": 16.12, \"match_probability\": 0.9999859592478867, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4424, \"tn\": 8049, \"fp\": 0, \"fn\": 7600, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36793080505655357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6320691949434465, \"precision\": 1.0, \"recall\": 0.36793080505655357, \"specificity\": 1.0, \"npv\": 0.5143459645983769, \"accuracy\": 0.621381955861107, \"f1\": 0.5379377431906615, \"f2\": 0.4211728865194212, \"f0_5\": 0.7442799461641992, \"p4\": 0.6004095672525332, \"phi\": 0.43502152226329033}, {\"truth_threshold\": 16.14, \"match_probability\": 0.9999861525483934, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4418, \"tn\": 8049, \"fp\": 0, \"fn\": 7606, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36743180306054557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6325681969394544, \"precision\": 1.0, \"recall\": 0.36743180306054557, \"specificity\": 1.0, \"npv\": 0.5141488342382625, \"accuracy\": 0.621083046878892, \"f1\": 0.5374042087337307, \"f2\": 0.4206497315001714, \"f0_5\": 0.7438712284482759, \"p4\": 0.6000099972189171, \"phi\": 0.43464311015549567}, {\"truth_threshold\": 16.16, \"match_probability\": 0.9999863431877482, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4407, \"tn\": 8049, \"fp\": 0, \"fn\": 7617, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36651696606786427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6334830339321357, \"precision\": 1.0, \"recall\": 0.36651696606786427, \"specificity\": 1.0, \"npv\": 0.5137878207583302, \"accuracy\": 0.6205350470781646, \"f1\": 0.536425050209969, \"f2\": 0.41969030341123365, \"f0_5\": 0.7431201942533388, \"p4\": 0.5992764880354592, \"phi\": 0.4339492519488457}, {\"truth_threshold\": 16.18, \"match_probability\": 0.9999865312025857, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4402, \"tn\": 8049, \"fp\": 0, \"fn\": 7622, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36610113107119097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6338988689288091, \"precision\": 1.0, \"recall\": 0.36610113107119097, \"specificity\": 1.0, \"npv\": 0.5136238912641184, \"accuracy\": 0.6202859562596522, \"f1\": 0.535979544624376, \"f2\": 0.4192540668215932, \"f0_5\": 0.7427780777537797, \"p4\": 0.5989426607671303, \"phi\": 0.4336338173355258}, {\"truth_threshold\": 16.2, \"match_probability\": 0.9999867166290367, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4394, \"tn\": 8049, \"fp\": 0, \"fn\": 7630, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36543579507651364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6345642049234863, \"precision\": 1.0, \"recall\": 0.36543579507651364, \"specificity\": 1.0, \"npv\": 0.5133618215447414, \"accuracy\": 0.6198874109500324, \"f1\": 0.5352661712754294, \"f2\": 0.4185559154124595, \"f0_5\": 0.7422297297297298, \"p4\": 0.5984079967340035, \"phi\": 0.43312906323419337}, {\"truth_threshold\": 16.22, \"match_probability\": 0.9999868995027343, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4391, \"tn\": 8049, \"fp\": 0, \"fn\": 7633, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36518629407850967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6348137059214903, \"precision\": 1.0, \"recall\": 0.36518629407850967, \"specificity\": 1.0, \"npv\": 0.5132636143349063, \"accuracy\": 0.6197379564589249, \"f1\": 0.5349984770027414, \"f2\": 0.41829405376569434, \"f0_5\": 0.7420237934297689, \"p4\": 0.5982073257801994, \"phi\": 0.4329397616346942}, {\"truth_threshold\": 16.240000000000002, \"match_probability\": 0.9999870798588212, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4386, \"tn\": 8049, \"fp\": 0, \"fn\": 7638, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3647704590818363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6352295409181636, \"precision\": 1.0, \"recall\": 0.3647704590818363, \"specificity\": 1.0, \"npv\": 0.5131000191241155, \"accuracy\": 0.6194888656404125, \"f1\": 0.5345521023765997, \"f2\": 0.41785755116039786, \"f0_5\": 0.7416801948051948, \"p4\": 0.5978726652088754, \"phi\": 0.4326242359494006}, {\"truth_threshold\": 16.26, \"match_probability\": 0.9999872577319563, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4385, \"tn\": 8049, \"fp\": 0, \"fn\": 7639, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36468729208250167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6353127079174984, \"precision\": 1.0, \"recall\": 0.36468729208250167, \"specificity\": 1.0, \"npv\": 0.5130673125956144, \"accuracy\": 0.61943904747671, \"f1\": 0.5344627948077275, \"f2\": 0.41777024065852403, \"f0_5\": 0.7416114192937356, \"p4\": 0.5978057016993354, \"phi\": 0.432561127341028}, {\"truth_threshold\": 16.28, \"match_probability\": 0.9999874331563213, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4380, \"tn\": 8049, \"fp\": 0, \"fn\": 7644, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36427145708582837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6357285429141717, \"precision\": 1.0, \"recall\": 0.36427145708582837, \"specificity\": 1.0, \"npv\": 0.5129038424775377, \"accuracy\": 0.6191899566581975, \"f1\": 0.5340160936356986, \"f2\": 0.41733363823462155, \"f0_5\": 0.7412672623883022, \"p4\": 0.5974707268811799, \"phi\": 0.43224556683002874}, {\"truth_threshold\": 16.3, \"match_probability\": 0.9999876061656275, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4378, \"tn\": 8049, \"fp\": 0, \"fn\": 7646, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36410512308715903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.635894876912841, \"precision\": 1.0, \"recall\": 0.36410512308715903, \"specificity\": 1.0, \"npv\": 0.5128384835935011, \"accuracy\": 0.6190903203307926, \"f1\": 0.5338373369101329, \"f2\": 0.4171589739680604, \"f0_5\": 0.7411294691224268, \"p4\": 0.5973366634610459, \"phi\": 0.43211933443511147}, {\"truth_threshold\": 16.32, \"match_probability\": 0.9999877767931221, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4375, \"tn\": 8049, \"fp\": 0, \"fn\": 7649, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.363855622089155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.636144377910845, \"precision\": 1.0, \"recall\": 0.363855622089155, \"specificity\": 1.0, \"npv\": 0.5127404764938208, \"accuracy\": 0.6189408658396851, \"f1\": 0.5335691200682968, \"f2\": 0.4168969526023899, \"f0_5\": 0.7409226392087793, \"p4\": 0.597135489454356, \"phi\": 0.4319299770158919}, {\"truth_threshold\": 16.34, \"match_probability\": 0.9999879450715947, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4367, \"tn\": 8049, \"fp\": 0, \"fn\": 7657, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36319028609447773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6368097139055223, \"precision\": 1.0, \"recall\": 0.36319028609447773, \"specificity\": 1.0, \"npv\": 0.5124793072711066, \"accuracy\": 0.6185423205300653, \"f1\": 0.5328533951558783, \"f2\": 0.41619808245811335, \"f0_5\": 0.7403702699037027, \"p4\": 0.5965985616689126, \"phi\": 0.43142497172195876}, {\"truth_threshold\": 16.36, \"match_probability\": 0.9999881110333831, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4363, \"tn\": 8049, \"fp\": 0, \"fn\": 7661, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36285761809713907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.637142381902861, \"precision\": 1.0, \"recall\": 0.36285761809713907, \"specificity\": 1.0, \"npv\": 0.5123488224061108, \"accuracy\": 0.6183430478752553, \"f1\": 0.532495270641362, \"f2\": 0.41584856745267734, \"f0_5\": 0.7400936355000679, \"p4\": 0.5963298441650491, \"phi\": 0.43117244036830027}, {\"truth_threshold\": 16.38, \"match_probability\": 0.9999882747103807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4360, \"tn\": 8049, \"fp\": 0, \"fn\": 7664, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36260811709913504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6373918829008649, \"precision\": 1.0, \"recall\": 0.36260811709913504, \"specificity\": 1.0, \"npv\": 0.5122510023547381, \"accuracy\": 0.6181935933841478, \"f1\": 0.5322265625, \"f2\": 0.41558639621778254, \"f0_5\": 0.7398859625305457, \"p4\": 0.5961281947984963, \"phi\": 0.4309830291856005}, {\"truth_threshold\": 16.4, \"match_probability\": 0.9999884361340411, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4352, \"tn\": 8049, \"fp\": 0, \"fn\": 7672, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36194278110445777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6380572188955422, \"precision\": 1.0, \"recall\": 0.36194278110445777, \"specificity\": 1.0, \"npv\": 0.5119903314038547, \"accuracy\": 0.617795048074528, \"f1\": 0.5315095261358085, \"f2\": 0.41488712629652225, \"f0_5\": 0.7393313400380538, \"p4\": 0.5955899958183686, \"phi\": 0.4304778791609438}, {\"truth_threshold\": 16.42, \"match_probability\": 0.9999885953353853, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4347, \"tn\": 8049, \"fp\": 0, \"fn\": 7677, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3615269461077844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6384730538922155, \"precision\": 1.0, \"recall\": 0.3615269461077844, \"specificity\": 1.0, \"npv\": 0.5118275467378863, \"accuracy\": 0.6175459572560156, \"f1\": 0.5310610225398571, \"f2\": 0.4144499742577656, \"f0_5\": 0.738984088127295, \"p4\": 0.5952532753217904, \"phi\": 0.43016212049178315}, {\"truth_threshold\": 16.44, \"match_probability\": 0.9999887523450072, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4340, \"tn\": 8049, \"fp\": 0, \"fn\": 7684, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3609447771124418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6390552228875582, \"precision\": 1.0, \"recall\": 0.3609447771124418, \"specificity\": 1.0, \"npv\": 0.5115998220301278, \"accuracy\": 0.6171972301100982, \"f1\": 0.5304326570520655, \"f2\": 0.41383782134411473, \"f0_5\": 0.7384971413013885, \"p4\": 0.5947814177872482, \"phi\": 0.42972000620570294}, {\"truth_threshold\": 16.46, \"match_probability\": 0.9999889071930795, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4333, \"tn\": 8049, \"fp\": 0, \"fn\": 7691, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.36036260811709914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6396373918829009, \"precision\": 1.0, \"recall\": 0.36036260811709914, \"specificity\": 1.0, \"npv\": 0.5113722998729352, \"accuracy\": 0.6168485029641807, \"f1\": 0.5298037537445742, \"f2\": 0.41322550496862426, \"f0_5\": 0.738009265567516, \"p4\": 0.5943090349071164, \"phi\": 0.42927783043275164}, {\"truth_threshold\": 16.48, \"match_probability\": 0.9999890599093596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4325, \"tn\": 8049, \"fp\": 0, \"fn\": 7699, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3596972721224218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6403027278775781, \"precision\": 1.0, \"recall\": 0.3596972721224218, \"specificity\": 1.0, \"npv\": 0.5111125222250444, \"accuracy\": 0.6164499576545609, \"f1\": 0.5290843476665239, \"f2\": 0.41252551458385, \"f0_5\": 0.7374505524485063, \"p4\": 0.5937685230589348, \"phi\": 0.4287724104836495}, {\"truth_threshold\": 16.5, \"match_probability\": 0.9999892105231952, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4314, \"tn\": 8049, \"fp\": 0, \"fn\": 7710, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3587824351297405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6412175648702595, \"precision\": 1.0, \"recall\": 0.3587824351297405, \"specificity\": 1.0, \"npv\": 0.5107557586141253, \"accuracy\": 0.6159019578538335, \"f1\": 0.5280940139551965, \"f2\": 0.4115626788780767, \"f0_5\": 0.7366803278688525, \"p4\": 0.593024189671631, \"phi\": 0.42807732342663724}, {\"truth_threshold\": 16.52, \"match_probability\": 0.9999893590635301, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4308, \"tn\": 8049, \"fp\": 0, \"fn\": 7716, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3582834331337325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6417165668662674, \"precision\": 1.0, \"recall\": 0.3582834331337325, \"specificity\": 1.0, \"npv\": 0.5105613701236917, \"accuracy\": 0.6156030488716185, \"f1\": 0.5275532696546656, \"f2\": 0.41103732539500804, \"f0_5\": 0.7362592288761279, \"p4\": 0.5926176359976959, \"phi\": 0.4276981184356305}, {\"truth_threshold\": 16.54, \"match_probability\": 0.9999895055589096, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4303, \"tn\": 8049, \"fp\": 0, \"fn\": 7721, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3578675981370592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6421324018629407, \"precision\": 1.0, \"recall\": 0.3578675981370592, \"specificity\": 1.0, \"npv\": 0.5103994927076728, \"accuracy\": 0.6153539580531061, \"f1\": 0.527102345807558, \"f2\": 0.4105994389205901, \"f0_5\": 0.735907784922698, \"p4\": 0.5922785416117486, \"phi\": 0.42738207794158656}, {\"truth_threshold\": 16.56, \"match_probability\": 0.999989650037486, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4293, \"tn\": 8049, \"fp\": 0, \"fn\": 7731, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3570359281437126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6429640718562875, \"precision\": 1.0, \"recall\": 0.3570359281437126, \"specificity\": 1.0, \"npv\": 0.5100760456273764, \"accuracy\": 0.6148557764160814, \"f1\": 0.5261996690568119, \"f2\": 0.40972341522075245, \"f0_5\": 0.7352034525277436, \"p4\": 0.5915995326524975, \"phi\": 0.42674989674801916}, {\"truth_threshold\": 16.580000000000002, \"match_probability\": 0.9999897925270239, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4285, \"tn\": 8049, \"fp\": 0, \"fn\": 7739, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35637059214903527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6436294078509648, \"precision\": 1.0, \"recall\": 0.35637059214903527, \"specificity\": 1.0, \"npv\": 0.5098175829744109, \"accuracy\": 0.6144572311064614, \"f1\": 0.5254767306395242, \"f2\": 0.40902235543422233, \"f0_5\": 0.734638595528734, \"p4\": 0.5910555350020692, \"phi\": 0.4262440544249042}, {\"truth_threshold\": 16.6, \"match_probability\": 0.999989933054906, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4278, \"tn\": 8049, \"fp\": 0, \"fn\": 7746, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35578842315369263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6442115768463074, \"precision\": 1.0, \"recall\": 0.35578842315369263, \"specificity\": 1.0, \"npv\": 0.5095916429249763, \"accuracy\": 0.6141085039605441, \"f1\": 0.5248435774751564, \"f2\": 0.40840875243441405, \"f0_5\": 0.7341433278418451, \"p4\": 0.5905789581940064, \"phi\": 0.425801370463479}, {\"truth_threshold\": 16.62, \"match_probability\": 0.9999900716481379, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4272, \"tn\": 8049, \"fp\": 0, \"fn\": 7752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35528942115768464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6447105788423154, \"precision\": 1.0, \"recall\": 0.35528942115768464, \"specificity\": 1.0, \"npv\": 0.5093981393582685, \"accuracy\": 0.6138095949783291, \"f1\": 0.524300441826215, \"f2\": 0.4078826764436297, \"f0_5\": 0.7337180544105524, \"p4\": 0.5901700322257054, \"phi\": 0.4254218730523864}, {\"truth_threshold\": 16.64, \"match_probability\": 0.9999902083333535, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4264, \"tn\": 8049, \"fp\": 0, \"fn\": 7760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3546240851630073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6453759148369926, \"precision\": 1.0, \"recall\": 0.3546240851630073, \"specificity\": 1.0, \"npv\": 0.5091403630843191, \"accuracy\": 0.6134110496687092, \"f1\": 0.5235756385068763, \"f2\": 0.40718105423987777, \"f0_5\": 0.7331499312242091, \"p4\": 0.5896241756911179, \"phi\": 0.424915798103975}, {\"truth_threshold\": 16.66, \"match_probability\": 0.99999034313682, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4258, \"tn\": 8049, \"fp\": 0, \"fn\": 7766, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3541250831669993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6458749168330007, \"precision\": 1.0, \"recall\": 0.3541250831669993, \"specificity\": 1.0, \"npv\": 0.5089472020233955, \"accuracy\": 0.6131121406864943, \"f1\": 0.5230315686033656, \"f2\": 0.40665469687129924, \"f0_5\": 0.7327230176211453, \"p4\": 0.5892143152568483, \"phi\": 0.4245361824911353}, {\"truth_threshold\": 16.68, \"match_probability\": 0.9999904760844428, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4256, \"tn\": 8049, \"fp\": 0, \"fn\": 7768, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35395874916833003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.64604125083167, \"precision\": 1.0, \"recall\": 0.35395874916833003, \"specificity\": 1.0, \"npv\": 0.5088828475690712, \"accuracy\": 0.6130125043590893, \"f1\": 0.5228501228501229, \"f2\": 0.406479217603912, \"f0_5\": 0.7325805563205728, \"p4\": 0.5890776057181991, \"phi\": 0.42440963254710234}, {\"truth_threshold\": 16.7, \"match_probability\": 0.9999906072017711, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4252, \"tn\": 8049, \"fp\": 0, \"fn\": 7772, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35362608117099137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6463739188290086, \"precision\": 1.0, \"recall\": 0.35362608117099137, \"specificity\": 1.0, \"npv\": 0.5087541874723469, \"accuracy\": 0.6128132317042794, \"f1\": 0.5224870975669698, \"f2\": 0.4061282188431268, \"f0_5\": 0.7322953981813172, \"p4\": 0.588804052273996, \"phi\": 0.4241565154458645}, {\"truth_threshold\": 16.72, \"match_probability\": 0.999990736514002, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4246, \"tn\": 8049, \"fp\": 0, \"fn\": 7778, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35312707917498337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6468729208250167, \"precision\": 1.0, \"recall\": 0.35312707917498337, \"specificity\": 1.0, \"npv\": 0.508561319264548, \"accuracy\": 0.6125143227220645, \"f1\": 0.5219422249539029, \"f2\": 0.40560162011386647, \"f0_5\": 0.7318670711527855, \"p4\": 0.5883933854984725, \"phi\": 0.42377679650172684}, {\"truth_threshold\": 16.740000000000002, \"match_probability\": 0.9999908640459861, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4245, \"tn\": 8049, \"fp\": 0, \"fn\": 7779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3530439121756487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6469560878243513, \"precision\": 1.0, \"recall\": 0.3530439121756487, \"specificity\": 1.0, \"npv\": 0.5085291887793784, \"accuracy\": 0.612464504558362, \"f1\": 0.5218513737783514, \"f2\": 0.40551384192124723, \"f0_5\": 0.7317956143980141, \"p4\": 0.5883249016906702, \"phi\": 0.42371350493249643}, {\"truth_threshold\": 16.76, \"match_probability\": 0.9999909898222314, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4238, \"tn\": 8049, \"fp\": 0, \"fn\": 7786, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35246174318030604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6475382568196939, \"precision\": 1.0, \"recall\": 0.35246174318030604, \"specificity\": 1.0, \"npv\": 0.508304389011683, \"accuracy\": 0.6121157774124446, \"f1\": 0.5212151026933957, \"f2\": 0.40489930064585167, \"f0_5\": 0.7312948647156268, \"p4\": 0.5878451995174941, \"phi\": 0.4232704230362171}, {\"truth_threshold\": 16.78, \"match_probability\": 0.9999911138669091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4236, \"tn\": 8049, \"fp\": 0, \"fn\": 7788, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3522954091816367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6477045908183633, \"precision\": 1.0, \"recall\": 0.3522954091816367, \"specificity\": 1.0, \"npv\": 0.508240197007009, \"accuracy\": 0.6120161410850397, \"f1\": 0.5210332103321034, \"f2\": 0.4047236872277001, \"f0_5\": 0.7311516155758078, \"p4\": 0.5877080401628842, \"phi\": 0.4231438149933659}, {\"truth_threshold\": 16.8, \"match_probability\": 0.9999912362038571, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4231, \"tn\": 8049, \"fp\": 0, \"fn\": 7793, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3518795741849634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6481204258150366, \"precision\": 1.0, \"recall\": 0.3518795741849634, \"specificity\": 1.0, \"npv\": 0.5080797879055675, \"accuracy\": 0.6117670502665272, \"f1\": 0.5205782836050447, \"f2\": 0.40428459495098135, \"f0_5\": 0.7307931463313527, \"p4\": 0.5873649437634595, \"phi\": 0.42282726901206075}, {\"truth_threshold\": 16.82, \"match_probability\": 0.9999913568565856, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4220, \"tn\": 8049, \"fp\": 0, \"fn\": 7804, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3509647371922821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.649035262807718, \"precision\": 1.0, \"recall\": 0.3509647371922821, \"specificity\": 1.0, \"npv\": 0.507727244054753, \"accuracy\": 0.6112190504657998, \"f1\": 0.5195764590002463, \"f2\": 0.40331829650584905, \"f0_5\": 0.7300027677830058, \"p4\": 0.5866091328796332, \"phi\": 0.4221307365912107}, {\"truth_threshold\": 16.84, \"match_probability\": 0.9999914758482807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4214, \"tn\": 8049, \"fp\": 0, \"fn\": 7810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3504657351962741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6495342648037259, \"precision\": 1.0, \"recall\": 0.3504657351962741, \"specificity\": 1.0, \"npv\": 0.5075351535405763, \"accuracy\": 0.6109201414835849, \"f1\": 0.5190294371227984, \"f2\": 0.4027910533358822, \"f0_5\": 0.7295706371191135, \"p4\": 0.5861962913531488, \"phi\": 0.42175073292592147}, {\"truth_threshold\": 16.86, \"match_probability\": 0.9999915932018099, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4213, \"tn\": 8049, \"fp\": 0, \"fn\": 7811, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35038256819693947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6496174318030605, \"precision\": 1.0, \"recall\": 0.35038256819693947, \"specificity\": 1.0, \"npv\": 0.5075031525851198, \"accuracy\": 0.6108703233198824, \"f1\": 0.518938227505081, \"f2\": 0.40270316771492476, \"f0_5\": 0.7294985455049176, \"p4\": 0.5861274444330126, \"phi\": 0.421687393658878}, {\"truth_threshold\": 16.88, \"match_probability\": 0.9999917089397252, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4210, \"tn\": 8049, \"fp\": 0, \"fn\": 7814, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.35013306719893544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6498669328010646, \"precision\": 1.0, \"recall\": 0.35013306719893544, \"specificity\": 1.0, \"npv\": 0.5074071739267477, \"accuracy\": 0.610720868828775, \"f1\": 0.5186645312307503, \"f2\": 0.40243949068940466, \"f0_5\": 0.7292821507760532, \"p4\": 0.5859208349848563, \"phi\": 0.4214973666889461}, {\"truth_threshold\": 16.9, \"match_probability\": 0.9999918230842687, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4204, \"tn\": 8049, \"fp\": 0, \"fn\": 7820, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3496340652029275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6503659347970725, \"precision\": 1.0, \"recall\": 0.3496340652029275, \"specificity\": 1.0, \"npv\": 0.5072153254773457, \"accuracy\": 0.61042195984656, \"f1\": 0.5181168350998274, \"f2\": 0.40191204588910134, \"f0_5\": 0.7288488210818308, \"p4\": 0.5855073064617206, \"phi\": 0.4211172712913475}, {\"truth_threshold\": 16.92, \"match_probability\": 0.9999919356573761, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4199, \"tn\": 8049, \"fp\": 0, \"fn\": 7825, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.34921823020625414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6507817697937458, \"precision\": 1.0, \"recall\": 0.34921823020625414, \"specificity\": 1.0, \"npv\": 0.5070555625551216, \"accuracy\": 0.6101728690280476, \"f1\": 0.5176601121864021, \"f2\": 0.4014724161009657, \"f0_5\": 0.7284871616932685, \"p4\": 0.585162383238269, \"phi\": 0.42080048261823105}, {\"truth_threshold\": 16.94, \"match_probability\": 0.999992046680681, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4190, \"tn\": 8049, \"fp\": 0, \"fn\": 7834, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3484697272122422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6515302727877578, \"precision\": 1.0, \"recall\": 0.3484697272122422, \"specificity\": 1.0, \"npv\": 0.5067682427752943, \"accuracy\": 0.6097245055547252, \"f1\": 0.5168373010978167, \"f2\": 0.40068087059633556, \"f0_5\": 0.7278349082823791, \"p4\": 0.5845407947357459, \"phi\": 0.42023016469517527}, {\"truth_threshold\": 16.96, \"match_probability\": 0.9999921561755195, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4186, \"tn\": 8049, \"fp\": 0, \"fn\": 7838, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3481370592149035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6518629407850964, \"precision\": 1.0, \"recall\": 0.3481370592149035, \"specificity\": 1.0, \"npv\": 0.5066406495877133, \"accuracy\": 0.6095252328999153, \"f1\": 0.5164713140037014, \"f2\": 0.4003289851191615, \"f0_5\": 0.7275444938820912, \"p4\": 0.5842642323406005, \"phi\": 0.41997664914396715}, {\"truth_threshold\": 17.0, \"match_probability\": 0.999992370663676, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4179, \"tn\": 8049, \"fp\": 0, \"fn\": 7845, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3475548902195609, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6524451097804391, \"precision\": 1.0, \"recall\": 0.3475548902195609, \"specificity\": 1.0, \"npv\": 0.5064175160437902, \"accuracy\": 0.609176505753998, \"f1\": 0.5158304017774487, \"f2\": 0.39971305595408896, \"f0_5\": 0.7270354906054279, \"p4\": 0.5837798011403751, \"phi\": 0.4195329357676965}, {\"truth_threshold\": 17.02, \"match_probability\": 0.9999924756982134, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4170, \"tn\": 8049, \"fp\": 0, \"fn\": 7854, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3468063872255489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6531936127744511, \"precision\": 1.0, \"recall\": 0.3468063872255489, \"specificity\": 1.0, \"npv\": 0.5061309186945859, \"accuracy\": 0.6087281422806755, \"f1\": 0.5150055576139311, \"f2\": 0.39892090460337504, \"f0_5\": 0.7263795986622074, \"p4\": 0.5831561221760527, \"phi\": 0.4189623316905917}, {\"truth_threshold\": 17.04, \"match_probability\": 0.9999925792867308, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4165, \"tn\": 8049, \"fp\": 0, \"fn\": 7859, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3463905522288756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6536094477711244, \"precision\": 1.0, \"recall\": 0.3463905522288756, \"specificity\": 1.0, \"npv\": 0.5059718380688961, \"accuracy\": 0.6084790514621631, \"f1\": 0.5145469145716227, \"f2\": 0.3984807026271981, \"f0_5\": 0.7260145028587366, \"p4\": 0.5828092246102271, \"phi\": 0.4186452727559982}, {\"truth_threshold\": 17.06, \"match_probability\": 0.9999926814491356, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4157, \"tn\": 8049, \"fp\": 0, \"fn\": 7867, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3457252162341983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6542747837658017, \"precision\": 1.0, \"recall\": 0.3457252162341983, \"specificity\": 1.0, \"npv\": 0.5057175169640613, \"accuracy\": 0.6080805061525432, \"f1\": 0.5138124961374452, \"f2\": 0.3977762042370773, \"f0_5\": 0.7254292894038811, \"p4\": 0.5822535781624784, \"phi\": 0.4181378934105613}, {\"truth_threshold\": 17.080000000000002, \"match_probability\": 0.9999927822050607, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4153, \"tn\": 8049, \"fp\": 0, \"fn\": 7871, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3453925482368596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6546074517631404, \"precision\": 1.0, \"recall\": 0.3453925482368596, \"specificity\": 1.0, \"npv\": 0.5055904522613065, \"accuracy\": 0.6078812334977333, \"f1\": 0.5134450145267972, \"f2\": 0.3974238741411319, \"f0_5\": 0.7251361922056153, \"p4\": 0.5819754724149652, \"phi\": 0.41788416417801594}, {\"truth_threshold\": 17.1, \"match_probability\": 0.9999928815738692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4147, \"tn\": 8049, \"fp\": 0, \"fn\": 7877, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3448935462408516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6551064537591483, \"precision\": 1.0, \"recall\": 0.3448935462408516, \"specificity\": 1.0, \"npv\": 0.5053999748838377, \"accuracy\": 0.6075823245155184, \"f1\": 0.5128934512398738, \"f2\": 0.39689527783626516, \"f0_5\": 0.7246959317768769, \"p4\": 0.5815579595407192, \"phi\": 0.4175035204734496}, {\"truth_threshold\": 17.12, \"match_probability\": 0.9999929795746573, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4133, \"tn\": 8049, \"fp\": 0, \"fn\": 7891, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.34372920825016634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6562707917498337, \"precision\": 1.0, \"recall\": 0.34372920825016634, \"specificity\": 1.0, \"npv\": 0.5049560853199498, \"accuracy\": 0.6068848702236835, \"f1\": 0.5116048771430339, \"f2\": 0.39566141415688605, \"f0_5\": 0.7236657795209414, \"p4\": 0.5805821027867936, \"phi\": 0.4166151166342021}, {\"truth_threshold\": 17.14, \"match_probability\": 0.9999930762262584, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4130, \"tn\": 8049, \"fp\": 0, \"fn\": 7894, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.34347970725216237, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6565202927478376, \"precision\": 1.0, \"recall\": 0.34347970725216237, \"specificity\": 1.0, \"npv\": 0.5048610675531581, \"accuracy\": 0.6067354157325761, \"f1\": 0.5113284635384425, \"f2\": 0.39539692873281507, \"f0_5\": 0.7234445067264574, \"p4\": 0.5803726870560881, \"phi\": 0.41642470109993823}, {\"truth_threshold\": 17.16, \"match_probability\": 0.9999931715472467, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4123, \"tn\": 8049, \"fp\": 0, \"fn\": 7901, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3428975382568197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6571024617431803, \"precision\": 1.0, \"recall\": 0.3428975382568197, \"specificity\": 1.0, \"npv\": 0.5046394984326019, \"accuracy\": 0.6063866885866587, \"f1\": 0.5106830990276832, \"f2\": 0.39477967789501905, \"f0_5\": 0.7229274793098611, \"p4\": 0.5798836319564443, \"phi\": 0.41598033814075325}, {\"truth_threshold\": 17.18, \"match_probability\": 0.9999932655559404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4119, \"tn\": 8049, \"fp\": 0, \"fn\": 7905, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.342564870259481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.657435129740519, \"precision\": 1.0, \"recall\": 0.342564870259481, \"specificity\": 1.0, \"npv\": 0.5045129748025573, \"accuracy\": 0.6061874159318488, \"f1\": 0.5103140680170972, \"f2\": 0.3944268888250503, \"f0_5\": 0.7226315789473684, \"p4\": 0.5796039082712088, \"phi\": 0.41572637847202204}, {\"truth_threshold\": 17.2, \"match_probability\": 0.999993358270406, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4115, \"tn\": 8049, \"fp\": 0, \"fn\": 7909, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3422322022621424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6577677977378577, \"precision\": 1.0, \"recall\": 0.3422322022621424, \"specificity\": 1.0, \"npv\": 0.5043865146008272, \"accuracy\": 0.6059881432770388, \"f1\": 0.5099448540801784, \"f2\": 0.39407404569918214, \"f0_5\": 0.7223353461592473, \"p4\": 0.5793239923583381, \"phi\": 0.4154723909998922}, {\"truth_threshold\": 17.22, \"match_probability\": 0.9999934497084612, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4108, \"tn\": 8049, \"fp\": 0, \"fn\": 7916, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3416500332667997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6583499667332002, \"precision\": 1.0, \"recall\": 0.3416500332667997, \"specificity\": 1.0, \"npv\": 0.5041653617287817, \"accuracy\": 0.6056394161311214, \"f1\": 0.5092982891148029, \"f2\": 0.39345644011953107, \"f0_5\": 0.7218161371942649, \"p4\": 0.5788336757609478, \"phi\": 0.41502784557979533}, {\"truth_threshold\": 17.240000000000002, \"match_probability\": 0.9999935398876778, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4102, \"tn\": 8049, \"fp\": 0, \"fn\": 7922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.34115103127079177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6588489687292083, \"precision\": 1.0, \"recall\": 0.34115103127079177, \"specificity\": 1.0, \"npv\": 0.5039759564210131, \"accuracy\": 0.6053405071489065, \"f1\": 0.5087436438050353, \"f2\": 0.3929269320663627, \"f0_5\": 0.7213702870005627, \"p4\": 0.5784129332347863, \"phi\": 0.41464673792122403}, {\"truth_threshold\": 17.26, \"match_probability\": 0.9999936288253866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4094, \"tn\": 8049, \"fp\": 0, \"fn\": 7930, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.34048569527611444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6595143047238856, \"precision\": 1.0, \"recall\": 0.34048569527611444, \"specificity\": 1.0, \"npv\": 0.503723637273922, \"accuracy\": 0.6049419618392866, \"f1\": 0.5080034743764735, \"f2\": 0.3922207319409849, \"f0_5\": 0.7207746478873239, \"p4\": 0.5778512642021912, \"phi\": 0.41413849478673753}, {\"truth_threshold\": 17.28, \"match_probability\": 0.999993716538679, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4087, \"tn\": 8049, \"fp\": 0, \"fn\": 7937, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3399035262807718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6600964737192282, \"precision\": 1.0, \"recall\": 0.3399035262807718, \"specificity\": 1.0, \"npv\": 0.5035030651820342, \"accuracy\": 0.6045932346933692, \"f1\": 0.5073552231394699, \"f2\": 0.39160262920874617, \"f0_5\": 0.7202523614831524, \"p4\": 0.5773591649181432, \"phi\": 0.4136936878277825}, {\"truth_threshold\": 17.3, \"match_probability\": 0.9999938030444118, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4085, \"tn\": 8049, \"fp\": 0, \"fn\": 7939, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3397371922821025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6602628077178976, \"precision\": 1.0, \"recall\": 0.3397371922821025, \"specificity\": 1.0, \"npv\": 0.503440080060045, \"accuracy\": 0.6044935983659643, \"f1\": 0.5071699050220374, \"f2\": 0.3914259979686093, \"f0_5\": 0.7201029473981103, \"p4\": 0.5772184552772446, \"phi\": 0.41356658385546163}, {\"truth_threshold\": 17.32, \"match_probability\": 0.9999938883592091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4082, \"tn\": 8049, \"fp\": 0, \"fn\": 7942, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33948769128409845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6605123087159015, \"precision\": 1.0, \"recall\": 0.33948769128409845, \"specificity\": 1.0, \"npv\": 0.5033456319179539, \"accuracy\": 0.6043441438748568, \"f1\": 0.506891841549733, \"f2\": 0.39116102571965194, \"f0_5\": 0.7198786681715575, \"p4\": 0.5770072990874058, \"phi\": 0.41337591426903647}, {\"truth_threshold\": 17.34, \"match_probability\": 0.9999939724994668, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4079, \"tn\": 8049, \"fp\": 0, \"fn\": 7945, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3392381902860945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6607618097139055, \"precision\": 1.0, \"recall\": 0.3392381902860945, \"specificity\": 1.0, \"npv\": 0.5032512192072027, \"accuracy\": 0.6041946893837493, \"f1\": 0.5066136744705956, \"f2\": 0.39089602299952086, \"f0_5\": 0.7196541990119972, \"p4\": 0.5767960326705499, \"phi\": 0.41318522827313425}, {\"truth_threshold\": 17.36, \"match_probability\": 0.9999940554813546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4073, \"tn\": 8049, \"fp\": 0, \"fn\": 7951, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3387391882900865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6612608117099135, \"precision\": 1.0, \"recall\": 0.3387391882900865, \"specificity\": 1.0, \"npv\": 0.5030625, \"accuracy\": 0.6038957804015344, \"f1\": 0.5060570292601105, \"f2\": 0.39036592612471005, \"f0_5\": 0.7192046899279559, \"p4\": 0.5763731684666327, \"phi\": 0.4128038068007387}, {\"truth_threshold\": 17.38, \"match_probability\": 0.9999941373208195, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4066, \"tn\": 8049, \"fp\": 0, \"fn\": 7958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33815701929474384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6618429807052562, \"precision\": 1.0, \"recall\": 0.33815701929474384, \"specificity\": 1.0, \"npv\": 0.5028425064034485, \"accuracy\": 0.603547053255617, \"f1\": 0.5054070851460535, \"f2\": 0.3897473256393543, \"f0_5\": 0.7186792986425339, \"p4\": 0.57587926692239, \"phi\": 0.41235873113114546}, {\"truth_threshold\": 17.400000000000002, \"match_probability\": 0.9999942180335896, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4059, \"tn\": 8049, \"fp\": 0, \"fn\": 7965, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3375748502994012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6624251497005988, \"precision\": 1.0, \"recall\": 0.3375748502994012, \"specificity\": 1.0, \"npv\": 0.5026227051330087, \"accuracy\": 0.6031983261096996, \"f1\": 0.5047565752658086, \"f2\": 0.38912855910267474, \"f0_5\": 0.7181528662420382, \"p4\": 0.5753847602327724, \"phi\": 0.4119135642854645}, {\"truth_threshold\": 17.42, \"match_probability\": 0.9999942976351759, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4056, \"tn\": 8049, \"fp\": 0, \"fn\": 7968, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3373253493013972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6626746506986028, \"precision\": 1.0, \"recall\": 0.3373253493013972, \"specificity\": 1.0, \"npv\": 0.5025285634013861, \"accuracy\": 0.6030488716185921, \"f1\": 0.5044776119402985, \"f2\": 0.3888633225954901, \"f0_5\": 0.7179269328802039, \"p4\": 0.5751726429981276, \"phi\": 0.41172275038343686}, {\"truth_threshold\": 17.44, \"match_probability\": 0.9999943761408759, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4048, \"tn\": 8049, \"fp\": 0, \"fn\": 7976, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3366600133067199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6633399866932801, \"precision\": 1.0, \"recall\": 0.3366600133067199, \"specificity\": 1.0, \"npv\": 0.5022776911076443, \"accuracy\": 0.6026503263089723, \"f1\": 0.5037332005973121, \"f2\": 0.38815587603559376, \"f0_5\": 0.7173235043946697, \"p4\": 0.5746064503294931, \"phi\": 0.4112138302294417}, {\"truth_threshold\": 17.46, \"match_probability\": 0.999994453565777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4041, \"tn\": 8049, \"fp\": 0, \"fn\": 7983, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33607784431137727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6639221556886228, \"precision\": 1.0, \"recall\": 0.33607784431137727, \"specificity\": 1.0, \"npv\": 0.5020583832335329, \"accuracy\": 0.6023015991630548, \"f1\": 0.5030812324929972, \"f2\": 0.38753668220265836, \"f0_5\": 0.716794380587484, \"p4\": 0.5741103773758001, \"phi\": 0.4107684252173979}, {\"truth_threshold\": 17.48, \"match_probability\": 0.9999945299247582, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4037, \"tn\": 8049, \"fp\": 0, \"fn\": 7987, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3357451763140386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6642548236859614, \"precision\": 1.0, \"recall\": 0.3357451763140386, \"specificity\": 1.0, \"npv\": 0.5019331504115739, \"accuracy\": 0.6021023265082449, \"f1\": 0.502708424132993, \"f2\": 0.3871827824986093, \"f0_5\": 0.7164915518954991, \"p4\": 0.5738266319975246, \"phi\": 0.4105138658837174}, {\"truth_threshold\": 17.5, \"match_probability\": 0.9999946052324943, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4033, \"tn\": 8049, \"fp\": 0, \"fn\": 7991, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33541250831669994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6645874916833001, \"precision\": 1.0, \"recall\": 0.33541250831669994, \"specificity\": 1.0, \"npv\": 0.5018079800498753, \"accuracy\": 0.601903053853435, \"f1\": 0.5023354300305163, \"f2\": 0.38682882848318595, \"f0_5\": 0.7161883790311123, \"p4\": 0.5735426860098997, \"phi\": 0.41025927568047155}, {\"truth_threshold\": 17.52, \"match_probability\": 0.9999946795034576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4027, \"tn\": 8049, \"fp\": 0, \"fn\": 7997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33491350632069194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.665086493679308, \"precision\": 1.0, \"recall\": 0.33491350632069194, \"specificity\": 1.0, \"npv\": 0.5016203415181354, \"accuracy\": 0.60160414487122, \"f1\": 0.5017755903058999, \"f2\": 0.3862977955988719, \"f0_5\": 0.7157329731266885, \"p4\": 0.5731163899681779, \"phi\": 0.4098773321612476}, {\"truth_threshold\": 17.54, \"match_probability\": 0.9999947527519214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4023, \"tn\": 8049, \"fp\": 0, \"fn\": 8001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3345808383233533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6654191616766467, \"precision\": 1.0, \"recall\": 0.3345808383233533, \"specificity\": 1.0, \"npv\": 0.5014953271028038, \"accuracy\": 0.6014048722164101, \"f1\": 0.501402131239484, \"f2\": 0.3859437057503022, \"f0_5\": 0.7154289372599232, \"p4\": 0.5728319406200221, \"phi\": 0.4096226641157693}, {\"truth_threshold\": 17.56, \"match_probability\": 0.9999948249919623, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4017, \"tn\": 8049, \"fp\": 0, \"fn\": 8007, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3340818363273453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6659181636726547, \"precision\": 1.0, \"recall\": 0.3340818363273453, \"specificity\": 1.0, \"npv\": 0.5013079222720478, \"accuracy\": 0.6011059632341952, \"f1\": 0.5008415934168693, \"f2\": 0.3854124690576248, \"f0_5\": 0.7149722340879966, \"p4\": 0.5724048875624351, \"phi\": 0.40924060311519905}, {\"truth_threshold\": 17.580000000000002, \"match_probability\": 0.9999948962374636, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4010, \"tn\": 8049, \"fp\": 0, \"fn\": 8014, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33349966733200265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6665003326679974, \"precision\": 1.0, \"recall\": 0.33349966733200265, \"specificity\": 1.0, \"npv\": 0.5010894602502646, \"accuracy\": 0.6007572360882778, \"f1\": 0.5001871024073843, \"f2\": 0.38479253828733734, \"f0_5\": 0.7144384264538198, \"p4\": 0.5719060824192642, \"phi\": 0.40879477528099106}, {\"truth_threshold\": 17.6, \"match_probability\": 0.999994966502117, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4003, \"tn\": 8049, \"fp\": 0, \"fn\": 8021, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33291749833666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6670825016633399, \"precision\": 1.0, \"recall\": 0.33291749833666, \"specificity\": 1.0, \"npv\": 0.5008711885500934, \"accuracy\": 0.6004085089423604, \"f1\": 0.4995320396830349, \"f2\": 0.3841724409297683, \"f0_5\": 0.7139035525752604, \"p4\": 0.5714066541792477, \"phi\": 0.40834884973635793}, {\"truth_threshold\": 17.62, \"match_probability\": 0.9999950357994258, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4000, \"tn\": 8049, \"fp\": 0, \"fn\": 8024, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33266799733865604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.667332002661344, \"precision\": 1.0, \"recall\": 0.33266799733865604, \"specificity\": 1.0, \"npv\": 0.5007777017358302, \"accuracy\": 0.6002590544512529, \"f1\": 0.49925112331502747, \"f2\": 0.38390663390663393, \"f0_5\": 0.7136739937196689, \"p4\": 0.5711924221947251, \"phi\": 0.40815770867192186}, {\"truth_threshold\": 17.64, \"match_probability\": 0.9999951041427074, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3995, \"tn\": 8049, \"fp\": 0, \"fn\": 8029, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3322521623419827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6677478376580173, \"precision\": 1.0, \"recall\": 0.3322521623419827, \"specificity\": 1.0, \"npv\": 0.5006219679064561, \"accuracy\": 0.6000099636327405, \"f1\": 0.49878269554903554, \"f2\": 0.3834635541648269, \"f0_5\": 0.7132909584345094, \"p4\": 0.5708351131384429, \"phi\": 0.4078390998332782}, {\"truth_threshold\": 17.66, \"match_probability\": 0.9999951715450961, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3990, \"tn\": 8049, \"fp\": 0, \"fn\": 8034, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3318363273453094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6681636726546906, \"precision\": 1.0, \"recall\": 0.3318363273453094, \"specificity\": 1.0, \"npv\": 0.5004663309084126, \"accuracy\": 0.5997608728142281, \"f1\": 0.49831397527163734, \"f2\": 0.38302038935606497, \"f0_5\": 0.7129073756432247, \"p4\": 0.5704774836699084, \"phi\": 0.40752044023414324}, {\"truth_threshold\": 17.68, \"match_probability\": 0.999995238019545, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3986, \"tn\": 8049, \"fp\": 0, \"fn\": 8038, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3315036593479707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6684963406520292, \"precision\": 1.0, \"recall\": 0.3315036593479707, \"specificity\": 1.0, \"npv\": 0.5003418909678623, \"accuracy\": 0.5995616001594182, \"f1\": 0.49793878825733917, \"f2\": 0.38266579624438385, \"f0_5\": 0.712600114416476, \"p4\": 0.5701911488336374, \"phi\": 0.4072654758028597}, {\"truth_threshold\": 17.7, \"match_probability\": 0.9999953035788293, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3977, \"tn\": 8049, \"fp\": 0, \"fn\": 8047, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.33075515635395875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6692448436460412, \"precision\": 1.0, \"recall\": 0.33075515635395875, \"specificity\": 1.0, \"npv\": 0.5000621272365805, \"accuracy\": 0.5991132366860957, \"f1\": 0.4970939316292732, \"f2\": 0.3818677625640927, \"f0_5\": 0.7119074896176428, \"p4\": 0.5695461414848364, \"phi\": 0.40669168553196217}, {\"truth_threshold\": 17.72, \"match_probability\": 0.9999953682355479, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3973, \"tn\": 8049, \"fp\": 0, \"fn\": 8051, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3304224883566201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6695775116433799, \"precision\": 1.0, \"recall\": 0.3304224883566201, \"specificity\": 1.0, \"npv\": 0.4999378881987578, \"accuracy\": 0.5989139640312858, \"f1\": 0.49671813465024695, \"f2\": 0.38151299237550174, \"f0_5\": 0.7115990829631752, \"p4\": 0.5692591354584388, \"phi\": 0.4064366138063687}, {\"truth_threshold\": 17.740000000000002, \"match_probability\": 0.9999954320021266, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3967, \"tn\": 8049, \"fp\": 0, \"fn\": 8057, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3299234863606121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6700765136393879, \"precision\": 1.0, \"recall\": 0.3299234863606121, \"specificity\": 1.0, \"npv\": 0.4997516453495592, \"accuracy\": 0.5986150550490709, \"f1\": 0.496154086673754, \"f2\": 0.3809807348788967, \"f0_5\": 0.7111358095511258, \"p4\": 0.5688282373282559, \"phi\": 0.40605394364318}, {\"truth_threshold\": 17.76, \"match_probability\": 0.9999954948908198, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3962, \"tn\": 8049, \"fp\": 0, \"fn\": 8062, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3295076513639388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6704923486360612, \"precision\": 1.0, \"recall\": 0.3295076513639388, \"specificity\": 1.0, \"npv\": 0.49959654894171684, \"accuracy\": 0.5983659642305584, \"f1\": 0.4956837232578506, \"f2\": 0.38053709324215296, \"f0_5\": 0.7107491389207807, \"p4\": 0.5684687979495853, \"phi\": 0.40573499414188346}, {\"truth_threshold\": 17.78, \"match_probability\": 0.9999955569137137, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3956, \"tn\": 8049, \"fp\": 0, \"fn\": 8068, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3290086493679308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6709913506320692, \"precision\": 1.0, \"recall\": 0.3290086493679308, \"specificity\": 1.0, \"npv\": 0.4994105602779674, \"accuracy\": 0.5980670552483436, \"f1\": 0.4951188986232791, \"f2\": 0.38000461077384157, \"f0_5\": 0.7102844010341856, \"p4\": 0.5680370402923837, \"phi\": 0.40535218504053444}, {\"truth_threshold\": 17.8, \"match_probability\": 0.9999956180827274, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3947, \"tn\": 8049, \"fp\": 0, \"fn\": 8077, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3282601463739188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6717398536260811, \"precision\": 1.0, \"recall\": 0.3282601463739188, \"specificity\": 1.0, \"npv\": 0.49913183678531564, \"accuracy\": 0.5976186917750211, \"f1\": 0.49427086594452446, \"f2\": 0.3792056568606729, \"f0_5\": 0.7095857903063426, \"p4\": 0.5673885203483063, \"phi\": 0.4047778277067936}, {\"truth_threshold\": 17.82, \"match_probability\": 0.9999956784096167, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3945, \"tn\": 8049, \"fp\": 0, \"fn\": 8079, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3280938123752495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6719061876247505, \"precision\": 1.0, \"recall\": 0.3280938123752495, \"specificity\": 1.0, \"npv\": 0.49906994047619047, \"accuracy\": 0.5975190554476162, \"f1\": 0.49408228442607555, \"f2\": 0.3790280740185623, \"f0_5\": 0.7094302977988779, \"p4\": 0.567244260404899, \"phi\": 0.4046501691742167}, {\"truth_threshold\": 17.84, \"match_probability\": 0.999995737905975, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3942, \"tn\": 8049, \"fp\": 0, \"fn\": 8082, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3278443113772455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6721556886227545, \"precision\": 1.0, \"recall\": 0.3278443113772455, \"specificity\": 1.0, \"npv\": 0.49897712479077555, \"accuracy\": 0.5973696009565087, \"f1\": 0.49379932356257045, \"f2\": 0.3787616741611899, \"f0_5\": 0.7091968911917098, \"p4\": 0.567027771793269, \"phi\": 0.40445866521812796}, {\"truth_threshold\": 17.86, \"match_probability\": 0.9999957965832362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3937, \"tn\": 8049, \"fp\": 0, \"fn\": 8087, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3274284763805722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6725715236194278, \"precision\": 1.0, \"recall\": 0.3274284763805722, \"specificity\": 1.0, \"npv\": 0.4988225086762519, \"accuracy\": 0.5971205101379963, \"f1\": 0.4933274857465071, \"f2\": 0.37831760613456844, \"f0_5\": 0.7088074319458447, \"p4\": 0.5666666937879657, \"phi\": 0.40413944870576535}, {\"truth_threshold\": 17.88, \"match_probability\": 0.9999958544526771, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3932, \"tn\": 8049, \"fp\": 0, \"fn\": 8092, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32701264138389885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6729873586161012, \"precision\": 1.0, \"recall\": 0.32701264138389885, \"specificity\": 1.0, \"npv\": 0.49866798835264237, \"accuracy\": 0.5968714193194838, \"f1\": 0.49285535221860116, \"f2\": 0.3778734527562082, \"f0_5\": 0.70841741135774, \"p4\": 0.5663052854646792, \"phi\": 0.40382017785741325}, {\"truth_threshold\": 17.900000000000002, \"match_probability\": 0.9999959115254188, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3931, \"tn\": 8049, \"fp\": 0, \"fn\": 8093, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3269294743845642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6730705256154358, \"precision\": 1.0, \"recall\": 0.3269294743845642, \"specificity\": 1.0, \"npv\": 0.49863709577499693, \"accuracy\": 0.5968216011557814, \"f1\": 0.49276089000313383, \"f2\": 0.37778461183616197, \"f0_5\": 0.7083393397722358, \"p4\": 0.5662329640853189, \"phi\": 0.4037563171398874}, {\"truth_threshold\": 17.92, \"match_probability\": 0.9999959678124296, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3921, \"tn\": 8049, \"fp\": 0, \"fn\": 8103, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32609780439121755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6739021956087824, \"precision\": 1.0, \"recall\": 0.32609780439121755, \"specificity\": 1.0, \"npv\": 0.49832838038632987, \"accuracy\": 0.5963234195187566, \"f1\": 0.49181561618062086, \"f2\": 0.37689601476440393, \"f0_5\": 0.7075573841489823, \"p4\": 0.5655090201410966, \"phi\": 0.40311758918436397}, {\"truth_threshold\": 17.94, \"match_probability\": 0.9999960233245266, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3918, \"tn\": 8049, \"fp\": 0, \"fn\": 8106, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3258483033932136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6741516966067864, \"precision\": 1.0, \"recall\": 0.3258483033932136, \"specificity\": 1.0, \"npv\": 0.49823584029712165, \"accuracy\": 0.5961739650276491, \"f1\": 0.49153180278509595, \"f2\": 0.37662936901603417, \"f0_5\": 0.7073223570190641, \"p4\": 0.5652915774491445, \"phi\": 0.40292592774666314}, {\"truth_threshold\": 17.96, \"match_probability\": 0.9999960780723782, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3912, \"tn\": 8049, \"fp\": 0, \"fn\": 8112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3253493013972056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6746506986027944, \"precision\": 1.0, \"recall\": 0.3253493013972056, \"specificity\": 1.0, \"npv\": 0.4980508631891591, \"accuracy\": 0.5958750560454341, \"f1\": 0.49096385542168675, \"f2\": 0.37609598523304105, \"f0_5\": 0.7068516912402428, \"p4\": 0.5648563315446756, \"phi\": 0.40254254483081425}, {\"truth_threshold\": 17.98, \"match_probability\": 0.999996132066506, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3904, \"tn\": 8049, \"fp\": 0, \"fn\": 8120, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32468396540252825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6753160345974717, \"precision\": 1.0, \"recall\": 0.32468396540252825, \"specificity\": 1.0, \"npv\": 0.4978044405962026, \"accuracy\": 0.5954765107358143, \"f1\": 0.49020592667001506, \"f2\": 0.37538461538461537, \"f0_5\": 0.7062228654124457, \"p4\": 0.5642752536880283, \"phi\": 0.40203124227821196}, {\"truth_threshold\": 18.0, \"match_probability\": 0.9999961853172863, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3902, \"tn\": 8049, \"fp\": 0, \"fn\": 8122, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.324517631403859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6754823685961411, \"precision\": 1.0, \"recall\": 0.324517631403859, \"specificity\": 1.0, \"npv\": 0.4977428730443386, \"accuracy\": 0.5953768744084093, \"f1\": 0.49001632550546276, \"f2\": 0.37520673872072, \"f0_5\": 0.7060654313839028, \"p4\": 0.5641298499209775, \"phi\": 0.4019033941241358}, {\"truth_threshold\": 18.02, \"match_probability\": 0.9999962378349528, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3897, \"tn\": 8049, \"fp\": 0, \"fn\": 8127, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3241017964071856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6758982035928144, \"precision\": 1.0, \"recall\": 0.3241017964071856, \"specificity\": 1.0, \"npv\": 0.49758902077151335, \"accuracy\": 0.5951277835898969, \"f1\": 0.4895421141888072, \"f2\": 0.37476198719058335, \"f0_5\": 0.7056714471968709, \"p4\": 0.5637661048525108, \"phi\": 0.40158373411349707}, {\"truth_threshold\": 18.04, \"match_probability\": 0.9999962896295986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3892, \"tn\": 8049, \"fp\": 0, \"fn\": 8132, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3236859614105123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6763140385894877, \"precision\": 1.0, \"recall\": 0.3236859614105123, \"specificity\": 1.0, \"npv\": 0.49743526358074286, \"accuracy\": 0.5948786927713845, \"f1\": 0.48906760492586077, \"f2\": 0.3743171501115642, \"f0_5\": 0.7052768918527109, \"p4\": 0.5634020224283467, \"phi\": 0.4012640172400515}, {\"truth_threshold\": 18.06, \"match_probability\": 0.9999963407111775, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3883, \"tn\": 8049, \"fp\": 0, \"fn\": 8141, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32293745841650034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6770625415834997, \"precision\": 1.0, \"recall\": 0.32293745841650034, \"specificity\": 1.0, \"npv\": 0.4971587399629401, \"accuracy\": 0.594430329298062, \"f1\": 0.48821273653108693, \"f2\": 0.37351622770734333, \"f0_5\": 0.7045652489475976, \"p4\": 0.5627458210799031, \"phi\": 0.40068838255330247}, {\"truth_threshold\": 18.080000000000002, \"match_probability\": 0.9999963910895062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3881, \"tn\": 8049, \"fp\": 0, \"fn\": 8143, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.322771124417831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.677228875582169, \"precision\": 1.0, \"recall\": 0.322771124417831, \"specificity\": 1.0, \"npv\": 0.4970973320158103, \"accuracy\": 0.5943306929706571, \"f1\": 0.48802263439170074, \"f2\": 0.373338207283991, \"f0_5\": 0.7044068534920865, \"p4\": 0.562599849203957, \"phi\": 0.4005604383858283}, {\"truth_threshold\": 18.1, \"match_probability\": 0.9999964407742665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3876, \"tn\": 8049, \"fp\": 0, \"fn\": 8148, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3223552894211577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6776447105788423, \"precision\": 1.0, \"recall\": 0.3223552894211577, \"specificity\": 1.0, \"npv\": 0.4969438784960178, \"accuracy\": 0.5940816021521447, \"f1\": 0.48754716981132074, \"f2\": 0.3728930962826137, \"f0_5\": 0.7040104620749782, \"p4\": 0.5622346812347041, \"phi\": 0.40024053740051924}, {\"truth_threshold\": 18.12, \"match_probability\": 0.999996489775007, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3871, \"tn\": 8049, \"fp\": 0, \"fn\": 8153, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32193945442448435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6780605455755156, \"precision\": 1.0, \"recall\": 0.32193945442448435, \"specificity\": 1.0, \"npv\": 0.4967905196889273, \"accuracy\": 0.5938325113336322, \"f1\": 0.48707140610254795, \"f2\": 0.37244789962861047, \"f0_5\": 0.7036134942562163, \"p4\": 0.5618691721454645, \"phi\": 0.39992057820510973}, {\"truth_threshold\": 18.14, \"match_probability\": 0.9999965381011445, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3863, \"tn\": 8049, \"fp\": 0, \"fn\": 8161, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3212741184298071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.678725881570193, \"precision\": 1.0, \"recall\": 0.3212741184298071, \"specificity\": 1.0, \"npv\": 0.49654534238124615, \"accuracy\": 0.5934339660240123, \"f1\": 0.48630956127651537, \"f2\": 0.3717354067630247, \"f0_5\": 0.7029771436890377, \"p4\": 0.5612836458170963, \"phi\": 0.39940852160909335}, {\"truth_threshold\": 18.16, \"match_probability\": 0.9999965857619664, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3862, \"tn\": 8049, \"fp\": 0, \"fn\": 8162, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3211909514304724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6788090485695276, \"precision\": 1.0, \"recall\": 0.3211909514304724, \"specificity\": 1.0, \"npv\": 0.49651471223243476, \"accuracy\": 0.5933841478603099, \"f1\": 0.4862142767216417, \"f2\": 0.3716463297278571, \"f0_5\": 0.7028974956319162, \"p4\": 0.5612103932769297, \"phi\": 0.39934450393258564}, {\"truth_threshold\": 18.18, \"match_probability\": 0.999996632766632, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3855, \"tn\": 8049, \"fp\": 0, \"fn\": 8169, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32060878243512975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6793912175648703, \"precision\": 1.0, \"recall\": 0.32060878243512975, \"specificity\": 1.0, \"npv\": 0.4963004069552349, \"accuracy\": 0.5930354207143924, \"f1\": 0.4855469488003023, \"f2\": 0.3710226944620893, \"f0_5\": 0.7023393091386095, \"p4\": 0.5606972401925492, \"phi\": 0.3988963138410498}, {\"truth_threshold\": 18.2, \"match_probability\": 0.9999966791241749, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3851, \"tn\": 8049, \"fp\": 0, \"fn\": 8173, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3202761144377911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6797238855622089, \"precision\": 1.0, \"recall\": 0.3202761144377911, \"specificity\": 1.0, \"npv\": 0.49617802983602516, \"accuracy\": 0.5928361480595825, \"f1\": 0.4851653543307087, \"f2\": 0.37066625599168385, \"f0_5\": 0.7020198337465364, \"p4\": 0.5604037064781648, \"phi\": 0.3986401528512657}, {\"truth_threshold\": 18.22, \"match_probability\": 0.999996724843504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3849, \"tn\": 8049, \"fp\": 0, \"fn\": 8175, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.32010978043912175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6798902195608783, \"precision\": 1.0, \"recall\": 0.32010978043912175, \"specificity\": 1.0, \"npv\": 0.49611686390532544, \"accuracy\": 0.5927365117321776, \"f1\": 0.484974484974485, \"f2\": 0.37048801617095006, \"f0_5\": 0.7018599562363238, \"p4\": 0.5602568566906948, \"phi\": 0.39851205800688067}, {\"truth_threshold\": 18.240000000000002, \"match_probability\": 0.9999967699334056, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3847, \"tn\": 8049, \"fp\": 0, \"fn\": 8177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3199434464404524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6800565535595475, \"precision\": 1.0, \"recall\": 0.3199434464404524, \"specificity\": 1.0, \"npv\": 0.4960557130531246, \"accuracy\": 0.5926368754047726, \"f1\": 0.48478356751307417, \"f2\": 0.37030976262441523, \"f0_5\": 0.7016999854078506, \"p4\": 0.56010995153818, \"phi\": 0.3983839535682792}, {\"truth_threshold\": 18.26, \"match_probability\": 0.9999968144025453, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3838, \"tn\": 8049, \"fp\": 0, \"fn\": 8186, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31919494344644045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6808050565535595, \"precision\": 1.0, \"recall\": 0.31919494344644045, \"specificity\": 1.0, \"npv\": 0.49578072066522944, \"accuracy\": 0.5921885119314502, \"f1\": 0.4839238431471441, \"f2\": 0.3695074517657026, \"f0_5\": 0.7009789596727061, \"p4\": 0.559448191632896, \"phi\": 0.397807364304098}, {\"truth_threshold\": 18.28, \"match_probability\": 0.999996858259469, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3833, \"tn\": 8049, \"fp\": 0, \"fn\": 8191, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31877910844976715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6812208915502329, \"precision\": 1.0, \"recall\": 0.31877910844976715, \"specificity\": 1.0, \"npv\": 0.49562807881773396, \"accuracy\": 0.5919394211129377, \"f1\": 0.48344579680898025, \"f2\": 0.36906160334302607, \"f0_5\": 0.7005775698201492, \"p4\": 0.5590800603064168, \"phi\": 0.3974869520980383}, {\"truth_threshold\": 18.3, \"match_probability\": 0.9999969015126052, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3827, \"tn\": 8049, \"fp\": 0, \"fn\": 8197, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31828010645375915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6817198935462409, \"precision\": 1.0, \"recall\": 0.31828010645375915, \"specificity\": 1.0, \"npv\": 0.495445032623415, \"accuracy\": 0.5916405121307229, \"f1\": 0.4828717431076904, \"f2\": 0.36852647189106946, \"f0_5\": 0.700095126591541, \"p4\": 0.5586378419778335, \"phi\": 0.39710237688204125}, {\"truth_threshold\": 18.32, \"match_probability\": 0.9999969441702665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3820, \"tn\": 8049, \"fp\": 0, \"fn\": 8204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3176979374584165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6823020625415835, \"precision\": 1.0, \"recall\": 0.3176979374584165, \"specificity\": 1.0, \"npv\": 0.4952316495416231, \"accuracy\": 0.5912917849848055, \"f1\": 0.4822014642766978, \"f2\": 0.36790199553124275, \"f0_5\": 0.699531204219162, \"p4\": 0.5581212833087608, \"phi\": 0.3966535939878813}, {\"truth_threshold\": 18.34, \"match_probability\": 0.9999969862406507, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3817, \"tn\": 8049, \"fp\": 0, \"fn\": 8207, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3174484364604125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6825515635395875, \"precision\": 1.0, \"recall\": 0.3174484364604125, \"specificity\": 1.0, \"npv\": 0.4951402559055118, \"accuracy\": 0.591142330493698, \"f1\": 0.4819140205795089, \"f2\": 0.36763431125151697, \"f0_5\": 0.699289168987249, \"p4\": 0.5578996903317748, \"phi\": 0.3964612213897007}, {\"truth_threshold\": 18.36, \"match_probability\": 0.9999970277318428, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3816, \"tn\": 8049, \"fp\": 0, \"fn\": 8208, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31736526946107785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6826347305389222, \"precision\": 1.0, \"recall\": 0.31736526946107785, \"specificity\": 1.0, \"npv\": 0.49510979885587747, \"accuracy\": 0.5910925123299955, \"f1\": 0.4818181818181818, \"f2\": 0.36754507628294036, \"f0_5\": 0.6992084432717678, \"p4\": 0.557825797859299, \"phi\": 0.3963970922278765}, {\"truth_threshold\": 18.38, \"match_probability\": 0.999997068651817, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3811, \"tn\": 8049, \"fp\": 0, \"fn\": 8213, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31694943446440454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6830505655355955, \"precision\": 1.0, \"recall\": 0.31694943446440454, \"specificity\": 1.0, \"npv\": 0.4949575697946132, \"accuracy\": 0.5908434215114831, \"f1\": 0.48133880644142724, \"f2\": 0.3670988498661067, \"f0_5\": 0.6988044594396362, \"p4\": 0.5574561240588225, \"phi\": 0.39607640908072106}, {\"truth_threshold\": 18.400000000000002, \"match_probability\": 0.999997109008437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3798, \"tn\": 8049, \"fp\": 0, \"fn\": 8226, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3158682634730539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6841317365269461, \"precision\": 1.0, \"recall\": 0.3158682634730539, \"specificity\": 1.0, \"npv\": 0.4945622119815668, \"accuracy\": 0.5901957853833508, \"f1\": 0.4800910125142207, \"f2\": 0.36593825875823793, \"f0_5\": 0.6977513227513228, \"p4\": 0.5564933173922286, \"phi\": 0.3952423396828962}, {\"truth_threshold\": 18.42, \"match_probability\": 0.9999971488094587, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3788, \"tn\": 8049, \"fp\": 0, \"fn\": 8236, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31503659347970725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6849634065202928, \"precision\": 1.0, \"recall\": 0.31503659347970725, \"specificity\": 1.0, \"npv\": 0.4942585201105312, \"accuracy\": 0.589697603746326, \"f1\": 0.47912977485454084, \"f2\": 0.365045100609051, \"f0_5\": 0.6969384751251104, \"p4\": 0.5557510622790878, \"phi\": 0.39460045675840655}, {\"truth_threshold\": 18.44, \"match_probability\": 0.999997188062531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3783, \"tn\": 8049, \"fp\": 0, \"fn\": 8241, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31462075848303395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.685379241516966, \"precision\": 1.0, \"recall\": 0.31462075848303395, \"specificity\": 1.0, \"npv\": 0.4941068139963168, \"accuracy\": 0.5894485129278135, \"f1\": 0.4786486999430632, \"f2\": 0.36459839241311515, \"f0_5\": 0.6965311533362792, \"p4\": 0.5553793990451106, \"phi\": 0.39427941943646583}, {\"truth_threshold\": 18.46, \"match_probability\": 0.9999972267751978, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3779, \"tn\": 8049, \"fp\": 0, \"fn\": 8245, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3142880904856953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6857119095143047, \"precision\": 1.0, \"recall\": 0.3142880904856953, \"specificity\": 1.0, \"npv\": 0.49398551614091074, \"accuracy\": 0.5892492402730035, \"f1\": 0.4782636208314877, \"f2\": 0.3642409638554217, \"f0_5\": 0.69620486366986, \"p4\": 0.5550818104635025, \"phi\": 0.394022543258019}, {\"truth_threshold\": 18.48, \"match_probability\": 0.9999972649548987, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3774, \"tn\": 8049, \"fp\": 0, \"fn\": 8250, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.313872255489022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.686127744510978, \"precision\": 1.0, \"recall\": 0.313872255489022, \"specificity\": 1.0, \"npv\": 0.49383397754463465, \"accuracy\": 0.5890001494544911, \"f1\": 0.47778199772123053, \"f2\": 0.3637941006362059, \"f0_5\": 0.6957964601769911, \"p4\": 0.5547095014398113, \"phi\": 0.3937013898490193}, {\"truth_threshold\": 18.5, \"match_probability\": 0.9999973026089712, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3769, \"tn\": 8049, \"fp\": 0, \"fn\": 8255, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3134564204923486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6865435795076513, \"precision\": 1.0, \"recall\": 0.3134564204923486, \"specificity\": 1.0, \"npv\": 0.49368253189401373, \"accuracy\": 0.5887510586359787, \"f1\": 0.47730006965111127, \"f2\": 0.3633471512580738, \"f0_5\": 0.6953874538745387, \"p4\": 0.5543368323019893, \"phi\": 0.39338017147169135}, {\"truth_threshold\": 18.52, \"match_probability\": 0.9999973397446519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3767, \"tn\": 8049, \"fp\": 0, \"fn\": 8257, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3132900864936793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6867099135063207, \"precision\": 1.0, \"recall\": 0.3132900864936793, \"specificity\": 1.0, \"npv\": 0.4936219796393965, \"accuracy\": 0.5886514223085737, \"f1\": 0.47710721296941294, \"f2\": 0.3631683473767426, \"f0_5\": 0.6952236822678282, \"p4\": 0.5541876635994224, \"phi\": 0.39325166585331556}, {\"truth_threshold\": 18.54, \"match_probability\": 0.9999973763690773, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3761, \"tn\": 8049, \"fp\": 0, \"fn\": 8263, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31279108449767135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6872089155023287, \"precision\": 1.0, \"recall\": 0.31279108449767135, \"specificity\": 1.0, \"npv\": 0.49344041196665034, \"accuracy\": 0.5883525133263587, \"f1\": 0.4765283496990814, \"f2\": 0.36263185298031125, \"f0_5\": 0.6947317866114969, \"p4\": 0.5537398102407467, \"phi\": 0.3928660860828105}, {\"truth_threshold\": 18.56, \"match_probability\": 0.999997412489286, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3755, \"tn\": 8049, \"fp\": 0, \"fn\": 8269, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31229208250166335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6877079174983367, \"precision\": 1.0, \"recall\": 0.31229208250166335, \"specificity\": 1.0, \"npv\": 0.49325897781590883, \"accuracy\": 0.5880536043441439, \"f1\": 0.47594904620064643, \"f2\": 0.3620952344217084, \"f0_5\": 0.6942390178967608, \"p4\": 0.553291434705211, \"phi\": 0.3924804114790596}, {\"truth_threshold\": 18.580000000000002, \"match_probability\": 0.9999974481122197, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3749, \"tn\": 8049, \"fp\": 0, \"fn\": 8275, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31179308050565535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6882069194943446, \"precision\": 1.0, \"recall\": 0.31179308050565535, \"specificity\": 1.0, \"npv\": 0.4930776770399412, \"accuracy\": 0.5877546953619289, \"f1\": 0.47536930197172383, \"f2\": 0.3615584916578262, \"f0_5\": 0.6937453737971873, \"p4\": 0.5528425353156264, \"phi\": 0.39209464144879097}, {\"truth_threshold\": 18.6, \"match_probability\": 0.9999974832447245, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3744, \"tn\": 8049, \"fp\": 0, \"fn\": 8280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31137724550898205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.688622754491018, \"precision\": 1.0, \"recall\": 0.31137724550898205, \"specificity\": 1.0, \"npv\": 0.49292669483740587, \"accuracy\": 0.5875056045434165, \"f1\": 0.4748858447488584, \"f2\": 0.3611111111111111, \"f0_5\": 0.6933333333333334, \"p4\": 0.5524680511103037, \"phi\": 0.39177309309894925}, {\"truth_threshold\": 18.62, \"match_probability\": 0.9999975178935521, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3741, \"tn\": 8049, \"fp\": 0, \"fn\": 8283, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.311127744510978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.688872255489022, \"precision\": 1.0, \"recall\": 0.311127744510978, \"specificity\": 1.0, \"npv\": 0.4928361498897869, \"accuracy\": 0.5873561500523091, \"f1\": 0.47459562321598475, \"f2\": 0.36084264135655997, \"f0_5\": 0.6930858159181859, \"p4\": 0.5522431850014117, \"phi\": 0.3915801319381305}, {\"truth_threshold\": 18.64, \"match_probability\": 0.9999975520653613, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3738, \"tn\": 8049, \"fp\": 0, \"fn\": 8286, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.31087824351297405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6891217564870259, \"precision\": 1.0, \"recall\": 0.31087824351297405, \"specificity\": 1.0, \"npv\": 0.49274563820018363, \"accuracy\": 0.5872066955612016, \"f1\": 0.4743052912066997, \"f2\": 0.3605741405255238, \"f0_5\": 0.692838078291815, \"p4\": 0.5520181869445843, \"phi\": 0.3913871465727414}, {\"truth_threshold\": 18.66, \"match_probability\": 0.9999975857667196, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3727, \"tn\": 8049, \"fp\": 0, \"fn\": 8297, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30996340652029275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6900365934797072, \"precision\": 1.0, \"recall\": 0.30996340652029275, \"specificity\": 1.0, \"npv\": 0.4924140462498471, \"accuracy\": 0.5866586957604742, \"f1\": 0.47323979429877466, \"f2\": 0.3595893715145785, \"f0_5\": 0.6919278182088222, \"p4\": 0.5511920617497208, \"phi\": 0.3906793252707949}, {\"truth_threshold\": 18.68, \"match_probability\": 0.9999976190041034, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3721, \"tn\": 8049, \"fp\": 0, \"fn\": 8303, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30946440452428475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6905355954757152, \"precision\": 1.0, \"recall\": 0.30946440452428475, \"specificity\": 1.0, \"npv\": 0.4922333659491194, \"accuracy\": 0.5863597867782594, \"f1\": 0.4726579866624325, \"f2\": 0.3590520485554934, \"f0_5\": 0.6914300579753233, \"p4\": 0.5507406953450593, \"phi\": 0.39029310201491973}, {\"truth_threshold\": 18.7, \"match_probability\": 0.9999976517839005, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3715, \"tn\": 8049, \"fp\": 0, \"fn\": 8309, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30896540252827676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6910345974717232, \"precision\": 1.0, \"recall\": 0.30896540252827676, \"specificity\": 1.0, \"npv\": 0.4920528181929331, \"accuracy\": 0.5860608777960444, \"f1\": 0.47207573543427156, \"f2\": 0.3585146011464747, \"f0_5\": 0.6909314090165154, \"p4\": 0.550288795461895, \"phi\": 0.3899067799335536}, {\"truth_threshold\": 18.72, \"match_probability\": 0.9999976841124106, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3705, \"tn\": 8049, \"fp\": 0, \"fn\": 8319, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30813373253493015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6918662674650699, \"precision\": 1.0, \"recall\": 0.30813373253493015, \"specificity\": 1.0, \"npv\": 0.49175219941348974, \"accuracy\": 0.5855626961590196, \"f1\": 0.4711043295823002, \"f2\": 0.3576185787919152, \"f0_5\": 0.6900983459991059, \"p4\": 0.54953443880777, \"phi\": 0.38926268853762475}, {\"truth_threshold\": 18.740000000000002, \"match_probability\": 0.9999977159958466, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3699, \"tn\": 8049, \"fp\": 0, \"fn\": 8325, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30763473053892215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6923652694610778, \"precision\": 1.0, \"recall\": 0.30763473053892215, \"specificity\": 1.0, \"npv\": 0.4915720043972151, \"accuracy\": 0.5852637871768047, \"f1\": 0.4705208929593589, \"f2\": 0.35708079930495223, \"f0_5\": 0.6895973154362416, \"p4\": 0.5490811078889084, \"phi\": 0.38887609995114786}, {\"truth_threshold\": 18.76, \"match_probability\": 0.9999977474403359, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3696, \"tn\": 8049, \"fp\": 0, \"fn\": 8328, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3073852295409182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6926147704590818, \"precision\": 1.0, \"recall\": 0.3073852295409182, \"specificity\": 1.0, \"npv\": 0.4914819564022715, \"accuracy\": 0.5851143326856972, \"f1\": 0.47022900763358777, \"f2\": 0.3568118628359592, \"f0_5\": 0.6893464637421666, \"p4\": 0.5488542401069595, \"phi\": 0.3886827677990519}, {\"truth_threshold\": 18.78, \"match_probability\": 0.9999977784519215, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3692, \"tn\": 8049, \"fp\": 0, \"fn\": 8332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3070525615435795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6929474384564205, \"precision\": 1.0, \"recall\": 0.3070525615435795, \"specificity\": 1.0, \"npv\": 0.4913619437152799, \"accuracy\": 0.5849150600308872, \"f1\": 0.469839653855943, \"f2\": 0.3564532324090523, \"f0_5\": 0.6890116452672439, \"p4\": 0.5485515394258633, \"phi\": 0.38842495216297424}, {\"truth_threshold\": 18.8, \"match_probability\": 0.9999978090365634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3689, \"tn\": 8049, \"fp\": 0, \"fn\": 8335, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3068030605455755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6931969394544245, \"precision\": 1.0, \"recall\": 0.3068030605455755, \"specificity\": 1.0, \"npv\": 0.49127197265625, \"accuracy\": 0.5847656055397799, \"f1\": 0.4695475084325081, \"f2\": 0.35618422323066523, \"f0_5\": 0.6887602688573562, \"p4\": 0.5483243559032094, \"phi\": 0.38823156076135773}, {\"truth_threshold\": 18.82, \"match_probability\": 0.9999978392001393, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3679, \"tn\": 8049, \"fp\": 0, \"fn\": 8345, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3059713905522289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6940286094477711, \"precision\": 1.0, \"recall\": 0.3059713905522289, \"specificity\": 1.0, \"npv\": 0.49097230694156396, \"accuracy\": 0.584267423902755, \"f1\": 0.468572884162262, \"f2\": 0.35528730082085946, \"f0_5\": 0.6879207180254301, \"p4\": 0.5475660963386133, \"phi\": 0.38758673800524457}, {\"truth_threshold\": 18.84, \"match_probability\": 0.9999978689484461, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3674, \"tn\": 8049, \"fp\": 0, \"fn\": 8350, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3055555555555556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6944444444444444, \"precision\": 1.0, \"recall\": 0.3055555555555556, \"specificity\": 1.0, \"npv\": 0.4908226111348253, \"accuracy\": 0.5840183330842426, \"f1\": 0.46808510638297873, \"f2\": 0.3548387096774194, \"f0_5\": 0.6875, \"p4\": 0.5471863986737348, \"phi\": 0.3872642193961765}, {\"truth_threshold\": 18.86, \"match_probability\": 0.999997898287201, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3668, \"tn\": 8049, \"fp\": 0, \"fn\": 8356, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3050565535595476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6949434464404525, \"precision\": 1.0, \"recall\": 0.3050565535595476, \"specificity\": 1.0, \"npv\": 0.4906430966168851, \"accuracy\": 0.5837194241020276, \"f1\": 0.4674993627326026, \"f2\": 0.35430028591298973, \"f0_5\": 0.6869943062631105, \"p4\": 0.5467302598520071, \"phi\": 0.3868771020385299}, {\"truth_threshold\": 18.88, \"match_probability\": 0.9999979272220422, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3665, \"tn\": 8049, \"fp\": 0, \"fn\": 8359, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30480705256154356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6951929474384564, \"precision\": 1.0, \"recall\": 0.30480705256154356, \"specificity\": 1.0, \"npv\": 0.4905533885909312, \"accuracy\": 0.5835699696109201, \"f1\": 0.4672063229013959, \"f2\": 0.354031027221267, \"f0_5\": 0.6867411182731225, \"p4\": 0.5465019847147172, \"phi\": 0.3866835043035574}, {\"truth_threshold\": 18.900000000000002, \"match_probability\": 0.9999979557585305, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3656, \"tn\": 8049, \"fp\": 0, \"fn\": 8368, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3040585495675316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6959414504324684, \"precision\": 1.0, \"recall\": 0.3040585495675316, \"specificity\": 1.0, \"npv\": 0.4902844612292136, \"accuracy\": 0.5831216061375978, \"f1\": 0.4663265306122449, \"f2\": 0.3532230638429433, \"f0_5\": 0.6859801861302912, \"p4\": 0.5458163337302865, \"phi\": 0.38610255393723225}, {\"truth_threshold\": 18.92, \"match_probability\": 0.9999979839021501, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3655, \"tn\": 8049, \"fp\": 0, \"fn\": 8369, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30397538256819695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6960246174318031, \"precision\": 1.0, \"recall\": 0.30397538256819695, \"specificity\": 1.0, \"npv\": 0.4902545986112803, \"accuracy\": 0.5830717879738953, \"f1\": 0.4662287135659162, \"f2\": 0.3531332727869993, \"f0_5\": 0.6858955111845069, \"p4\": 0.545740073666788, \"phi\": 0.3860379892817309}, {\"truth_threshold\": 18.94, \"match_probability\": 0.9999980116583098, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3646, \"tn\": 8049, \"fp\": 0, \"fn\": 8378, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.303226879574185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6967731204258151, \"precision\": 1.0, \"recall\": 0.303226879574185, \"specificity\": 1.0, \"npv\": 0.48998599866074144, \"accuracy\": 0.5826234245005729, \"f1\": 0.46534779834077855, \"f2\": 0.3523249971010011, \"f0_5\": 0.6851322910402886, \"p4\": 0.5450530411470123, \"phi\": 0.3854567750201537}, {\"truth_threshold\": 18.96, \"match_probability\": 0.9999980390323437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3644, \"tn\": 8049, \"fp\": 0, \"fn\": 8380, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30306054557551565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6969394544244844, \"precision\": 1.0, \"recall\": 0.30306054557551565, \"specificity\": 1.0, \"npv\": 0.4899263497473979, \"accuracy\": 0.582523788173168, \"f1\": 0.46515190196579015, \"f2\": 0.35214534209509085, \"f0_5\": 0.6849624060150376, \"p4\": 0.5449001977450477, \"phi\": 0.38532758381183574}, {\"truth_threshold\": 18.98, \"match_probability\": 0.9999980660295127, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3638, \"tn\": 8049, \"fp\": 0, \"fn\": 8386, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30256154357950765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6974384564204924, \"precision\": 1.0, \"recall\": 0.30256154357950765, \"specificity\": 1.0, \"npv\": 0.48974749011256463, \"accuracy\": 0.582224879190953, \"f1\": 0.4645639126548334, \"f2\": 0.3516062937333282, \"f0_5\": 0.6844521372667068, \"p4\": 0.5444412965682256, \"phi\": 0.38493993891599143}, {\"truth_threshold\": 19.0, \"match_probability\": 0.9999980926550052, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3636, \"tn\": 8049, \"fp\": 0, \"fn\": 8388, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3023952095808383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6976047904191617, \"precision\": 1.0, \"recall\": 0.3023952095808383, \"specificity\": 1.0, \"npv\": 0.48968789925168826, \"accuracy\": 0.582125242863548, \"f1\": 0.46436781609195404, \"f2\": 0.35142658315935976, \"f0_5\": 0.6842818428184282, \"p4\": 0.5442882056293175, \"phi\": 0.38481070011554347}, {\"truth_threshold\": 19.02, \"match_probability\": 0.999998118913938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3629, \"tn\": 8049, \"fp\": 0, \"fn\": 8395, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3018130405854957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6981869594145044, \"precision\": 1.0, \"recall\": 0.3018130405854957, \"specificity\": 1.0, \"npv\": 0.48947944539041593, \"accuracy\": 0.5817765157176307, \"f1\": 0.4636810834983709, \"f2\": 0.3507974867085549, \"f0_5\": 0.6836850037678975, \"p4\": 0.5437518982451347, \"phi\": 0.38435826999998784}, {\"truth_threshold\": 19.04, \"match_probability\": 0.9999981448113576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3624, \"tn\": 8049, \"fp\": 0, \"fn\": 8400, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3013972055888224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6986027944111777, \"precision\": 1.0, \"recall\": 0.3013972055888224, \"specificity\": 1.0, \"npv\": 0.48933065839868684, \"accuracy\": 0.5815274248991182, \"f1\": 0.46319018404907975, \"f2\": 0.3503480278422274, \"f0_5\": 0.6832579185520362, \"p4\": 0.5433683545568609, \"phi\": 0.3840350153961261}, {\"truth_threshold\": 19.06, \"match_probability\": 0.9999981703522411, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3616, \"tn\": 8049, \"fp\": 0, \"fn\": 8408, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.30073186959414505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.699268130405855, \"precision\": 1.0, \"recall\": 0.30073186959414505, \"specificity\": 1.0, \"npv\": 0.4890927872637783, \"accuracy\": 0.5811288795894983, \"f1\": 0.46240409207161126, \"f2\": 0.3496287128712871, \"f0_5\": 0.6825732407127756, \"p4\": 0.5427538722880333, \"phi\": 0.3835176505962242}, {\"truth_threshold\": 19.080000000000002, \"match_probability\": 0.999998195541497, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3609, \"tn\": 8049, \"fp\": 0, \"fn\": 8415, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.3001497005988024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6998502994011976, \"precision\": 1.0, \"recall\": 0.3001497005988024, \"specificity\": 1.0, \"npv\": 0.4888848396501458, \"accuracy\": 0.5807801524435809, \"f1\": 0.46171560161197467, \"f2\": 0.34899912967798086, \"f0_5\": 0.6819727891156463, \"p4\": 0.5422153771565925, \"phi\": 0.3830647964095432}, {\"truth_threshold\": 19.1, \"match_probability\": 0.9999982203839662, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3604, \"tn\": 8049, \"fp\": 0, \"fn\": 8420, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29973386560212906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7002661343978709, \"precision\": 1.0, \"recall\": 0.29973386560212906, \"specificity\": 1.0, \"npv\": 0.48873641386848016, \"accuracy\": 0.5805310616250685, \"f1\": 0.4612234450985411, \"f2\": 0.3485493230174081, \"f0_5\": 0.6815431164901664, \"p4\": 0.5418302657052415, \"phi\": 0.3827412371163076}, {\"truth_threshold\": 19.12, \"match_probability\": 0.9999982448844231, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3601, \"tn\": 8049, \"fp\": 0, \"fn\": 8423, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2994843646041251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7005156353958749, \"precision\": 1.0, \"recall\": 0.2994843646041251, \"specificity\": 1.0, \"npv\": 0.488647401651287, \"accuracy\": 0.580381607133961, \"f1\": 0.460928, \"f2\": 0.3482793972570942, \"f0_5\": 0.6812850007567731, \"p4\": 0.5415990094930928, \"phi\": 0.38254706455414395}, {\"truth_threshold\": 19.14, \"match_probability\": 0.999998269047576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3597, \"tn\": 8049, \"fp\": 0, \"fn\": 8427, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2991516966067864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7008483033932136, \"precision\": 1.0, \"recall\": 0.2991516966067864, \"specificity\": 1.0, \"npv\": 0.4885287691187181, \"accuracy\": 0.5801823344791511, \"f1\": 0.46053389667754946, \"f2\": 0.34791944750739945, \"f0_5\": 0.680940481599273, \"p4\": 0.5412904464987389, \"phi\": 0.3822881244860865}, {\"truth_threshold\": 19.16, \"match_probability\": 0.9999982928780689, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3586, \"tn\": 8049, \"fp\": 0, \"fn\": 8438, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2982368596141051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7017631403858948, \"precision\": 1.0, \"recall\": 0.2982368596141051, \"specificity\": 1.0, \"npv\": 0.4882028264693395, \"accuracy\": 0.5796343346784237, \"f1\": 0.45944907110826394, \"f2\": 0.3469292984017646, \"f0_5\": 0.6799908980582524, \"p4\": 0.5404405894564377, \"phi\": 0.38157578253991137}, {\"truth_threshold\": 19.18, \"match_probability\": 0.9999983163804814, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3581, \"tn\": 8049, \"fp\": 0, \"fn\": 8443, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2978210246174318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7021789753825682, \"precision\": 1.0, \"recall\": 0.2978210246174318, \"specificity\": 1.0, \"npv\": 0.4880548144554936, \"accuracy\": 0.5793852438599113, \"f1\": 0.45895546299263057, \"f2\": 0.3464790912785185, \"f0_5\": 0.6795582207378169, \"p4\": 0.5400536539249611, \"phi\": 0.3812518654519682}, {\"truth_threshold\": 19.2, \"match_probability\": 0.9999983395593304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3577, \"tn\": 8049, \"fp\": 0, \"fn\": 8447, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29748835662009315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7025116433799069, \"precision\": 1.0, \"recall\": 0.29748835662009315, \"specificity\": 1.0, \"npv\": 0.4879364694471387, \"accuracy\": 0.5791859712051014, \"f1\": 0.4585603486955964, \"f2\": 0.3461188628490701, \"f0_5\": 0.679211605650919, \"p4\": 0.5397438178655309, \"phi\": 0.3809926750356752}, {\"truth_threshold\": 19.22, \"match_probability\": 0.9999983624190703, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3574, \"tn\": 8049, \"fp\": 0, \"fn\": 8450, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2972388556220892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7027611443779108, \"precision\": 1.0, \"recall\": 0.2972388556220892, \"specificity\": 1.0, \"npv\": 0.48784774834838474, \"accuracy\": 0.5790365167139939, \"f1\": 0.45826387998461343, \"f2\": 0.34584865492548866, \"f0_5\": 0.6789513677811551, \"p4\": 0.5395112726689225, \"phi\": 0.3807982489939874}, {\"truth_threshold\": 19.240000000000002, \"match_probability\": 0.9999983849640944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3571, \"tn\": 8049, \"fp\": 0, \"fn\": 8453, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29698935462408516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7030106453759148, \"precision\": 1.0, \"recall\": 0.29698935462408516, \"specificity\": 1.0, \"npv\": 0.4877590595079384, \"accuracy\": 0.5788870622228864, \"f1\": 0.45796729721064444, \"f2\": 0.345578415623125, \"f0_5\": 0.6786908925041812, \"p4\": 0.5392785830803702, \"phi\": 0.38060379437850245}, {\"truth_threshold\": 19.26, \"match_probability\": 0.9999984071987357, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3568, \"tn\": 8049, \"fp\": 0, \"fn\": 8456, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2967398536260812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7032601463739189, \"precision\": 1.0, \"recall\": 0.2967398536260812, \"specificity\": 1.0, \"npv\": 0.4876704029082096, \"accuracy\": 0.578737607731779, \"f1\": 0.4576706003078502, \"f2\": 0.34530814493651285, \"f0_5\": 0.6784301794949802, \"p4\": 0.539045748863913, \"phi\": 0.38040931110680526}, {\"truth_threshold\": 19.28, \"match_probability\": 0.9999984291272669, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3561, \"tn\": 8049, \"fp\": 0, \"fn\": 8463, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29615768463073855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7038423153692615, \"precision\": 1.0, \"recall\": 0.29615768463073855, \"specificity\": 1.0, \"npv\": 0.4874636627906977, \"accuracy\": 0.5783888805858616, \"f1\": 0.45697786333012513, \"f2\": 0.3446773912538475, \"f0_5\": 0.6778209227957972, \"p4\": 0.5385019052547595, \"phi\": 0.37995540490130164}, {\"truth_threshold\": 19.3, \"match_probability\": 0.9999984507539025, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3559, \"tn\": 8049, \"fp\": 0, \"fn\": 8465, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2959913506320692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7040086493679308, \"precision\": 1.0, \"recall\": 0.2959913506320692, \"specificity\": 1.0, \"npv\": 0.487404626377619, \"accuracy\": 0.5782892442584566, \"f1\": 0.45677982416736185, \"f2\": 0.3444971445165037, \"f0_5\": 0.6776466108149276, \"p4\": 0.5383463760806081, \"phi\": 0.3798256885280806}, {\"truth_threshold\": 19.32, \"match_probability\": 0.9999984720827987, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3555, \"tn\": 8049, \"fp\": 0, \"fn\": 8469, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29565868263473055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7043413173652695, \"precision\": 1.0, \"recall\": 0.29565868263473055, \"specificity\": 1.0, \"npv\": 0.487286596440247, \"accuracy\": 0.5780899716036467, \"f1\": 0.4563835932986713, \"f2\": 0.3441366091653598, \"f0_5\": 0.6772976680384087, \"p4\": 0.5380351235599564, \"phi\": 0.37956621710721966}, {\"truth_threshold\": 19.34, \"match_probability\": 0.9999984931180547, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3548, \"tn\": 8049, \"fp\": 0, \"fn\": 8476, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2950765136393879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7049234863606121, \"precision\": 1.0, \"recall\": 0.2950765136393879, \"specificity\": 1.0, \"npv\": 0.4870801815431165, \"accuracy\": 0.5777412444577293, \"f1\": 0.45568969946057025, \"f2\": 0.34350553791340716, \"f0_5\": 0.6766859932865426, \"p4\": 0.5374898072052577, \"phi\": 0.3791120175259325}, {\"truth_threshold\": 19.36, \"match_probability\": 0.9999985138637129, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3540, \"tn\": 8049, \"fp\": 0, \"fn\": 8484, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2944111776447106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7055888223552894, \"precision\": 1.0, \"recall\": 0.2944111776447106, \"specificity\": 1.0, \"npv\": 0.4868444928325168, \"accuracy\": 0.5773426991481094, \"f1\": 0.4548959136468774, \"f2\": 0.34278410411340926, \"f0_5\": 0.6759853345554537, \"p4\": 0.5368656119866762, \"phi\": 0.37859273694124557}, {\"truth_threshold\": 19.38, \"match_probability\": 0.9999985343237603, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3531, \"tn\": 8049, \"fp\": 0, \"fn\": 8493, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2936626746506986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7063373253493014, \"precision\": 1.0, \"recall\": 0.2936626746506986, \"specificity\": 1.0, \"npv\": 0.48657961552412043, \"accuracy\": 0.576894335674787, \"f1\": 0.4540019286403086, \"f2\": 0.3419722238363647, \"f0_5\": 0.6751950435979808, \"p4\": 0.536162141843042, \"phi\": 0.37800829531284336}, {\"truth_threshold\": 19.400000000000002, \"match_probability\": 0.999998554502129, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3520, \"tn\": 8049, \"fp\": 0, \"fn\": 8504, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2927478376580173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7072521623419827, \"precision\": 1.0, \"recall\": 0.2927478376580173, \"specificity\": 1.0, \"npv\": 0.4862562677460279, \"accuracy\": 0.5763463358740597, \"f1\": 0.45290787442099845, \"f2\": 0.34097954122752633, \"f0_5\": 0.6742261722341404, \"p4\": 0.5353005376682748, \"phi\": 0.3772936136887392}, {\"truth_threshold\": 19.42, \"match_probability\": 0.999998574402697, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3516, \"tn\": 8049, \"fp\": 0, \"fn\": 8508, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29241516966067865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7075848303393214, \"precision\": 1.0, \"recall\": 0.29241516966067865, \"specificity\": 1.0, \"npv\": 0.4861387932596485, \"accuracy\": 0.5761470632192497, \"f1\": 0.4525096525096525, \"f2\": 0.3406184608230644, \"f0_5\": 0.6738730450781969, \"p4\": 0.5349867319895925, \"phi\": 0.3770336294147482}, {\"truth_threshold\": 19.44, \"match_probability\": 0.9999985940292888, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3510, \"tn\": 8049, \"fp\": 0, \"fn\": 8514, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29191616766467066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7080838323353293, \"precision\": 1.0, \"recall\": 0.29191616766467066, \"specificity\": 1.0, \"npv\": 0.4859626879188553, \"accuracy\": 0.5758481542370348, \"f1\": 0.4519119351100811, \"f2\": 0.3400767352633415, \"f0_5\": 0.6733425414364641, \"p4\": 0.5345155265019058, \"phi\": 0.3766435522948648}, {\"truth_threshold\": 19.46, \"match_probability\": 0.9999986133856762, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3509, \"tn\": 8049, \"fp\": 0, \"fn\": 8515, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.291833000665336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.708166999334664, \"precision\": 1.0, \"recall\": 0.291833000665336, \"specificity\": 1.0, \"npv\": 0.4859333494325042, \"accuracy\": 0.5757983360733323, \"f1\": 0.45181227064958474, \"f2\": 0.3399864354229241, \"f0_5\": 0.6732540291634689, \"p4\": 0.5344369341576352, \"phi\": 0.3765785276515975}, {\"truth_threshold\": 19.48, \"match_probability\": 0.9999986324755792, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3506, \"tn\": 8049, \"fp\": 0, \"fn\": 8518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.291583499667332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.708416500332668, \"precision\": 1.0, \"recall\": 0.291583499667332, \"specificity\": 1.0, \"npv\": 0.48584535522424094, \"accuracy\": 0.5756488815822248, \"f1\": 0.451513200257566, \"f2\": 0.33971551490252316, \"f0_5\": 0.6729883292383292, \"p4\": 0.5342010573491075, \"phi\": 0.3763834334470664}, {\"truth_threshold\": 19.52, \"match_probability\": 0.9999986698705566, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3500, \"tn\": 8049, \"fp\": 0, \"fn\": 8524, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.291084497671324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.708915502328676, \"precision\": 1.0, \"recall\": 0.291084497671324, \"specificity\": 1.0, \"npv\": 0.48566946237856756, \"accuracy\": 0.57534997260001, \"f1\": 0.4509147127029116, \"f2\": 0.33917357934723624, \"f0_5\": 0.672456194282201, \"p4\": 0.5337288539200903, \"phi\": 0.37599315351581514}, {\"truth_threshold\": 19.54, \"match_probability\": 0.9999986881828178, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3496, \"tn\": 8049, \"fp\": 0, \"fn\": 8528, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2907518296739854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7092481703260146, \"precision\": 1.0, \"recall\": 0.2907518296739854, \"specificity\": 1.0, \"npv\": 0.48555227121915906, \"accuracy\": 0.5751506999452001, \"f1\": 0.4505154639175258, \"f2\": 0.3388122189486742, \"f0_5\": 0.6721008920332205, \"p4\": 0.5334137176473924, \"phi\": 0.3757328988248563}, {\"truth_threshold\": 19.56, \"match_probability\": 0.9999987062429692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3494, \"tn\": 8049, \"fp\": 0, \"fn\": 8530, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.29058549567531605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.709414504324684, \"precision\": 1.0, \"recall\": 0.29058549567531605, \"specificity\": 1.0, \"npv\": 0.48549369684540683, \"accuracy\": 0.575051063617795, \"f1\": 0.4503157623405078, \"f2\": 0.33863151773599537, \"f0_5\": 0.671923076923077, \"p4\": 0.5332560490949964, \"phi\": 0.37560275098175755}, {\"truth_threshold\": 19.580000000000002, \"match_probability\": 0.9999987240544819, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3492, \"tn\": 8049, \"fp\": 0, \"fn\": 8532, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2904191616766467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7095808383233533, \"precision\": 1.0, \"recall\": 0.2904191616766467, \"specificity\": 1.0, \"npv\": 0.485435136602135, \"accuracy\": 0.5749514272903901, \"f1\": 0.45011600928074247, \"f2\": 0.33845080251221216, \"f0_5\": 0.6717451523545707, \"p4\": 0.5330983135005477, \"phi\": 0.3754725894394696}, {\"truth_threshold\": 19.6, \"match_probability\": 0.9999987416207787, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3485, \"tn\": 8049, \"fp\": 0, \"fn\": 8539, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2898369926813041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.710163007318696, \"precision\": 1.0, \"recall\": 0.2898369926813041, \"specificity\": 1.0, \"npv\": 0.4852302869544249, \"accuracy\": 0.5746027001444727, \"f1\": 0.44941646785737316, \"f2\": 0.33781818886799403, \"f0_5\": 0.6711215529194269, \"p4\": 0.5325457098998108, \"phi\": 0.37501691579015034}, {\"truth_threshold\": 19.62, \"match_probability\": 0.9999987589452358, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3481, \"tn\": 8049, \"fp\": 0, \"fn\": 8543, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2895043246839654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7104956753160346, \"precision\": 1.0, \"recall\": 0.2895043246839654, \"specificity\": 1.0, \"npv\": 0.4851133076181292, \"accuracy\": 0.5744034274896628, \"f1\": 0.4490164463076427, \"f2\": 0.33745661826007717, \"f0_5\": 0.6707646061353476, \"p4\": 0.5322295660588799, \"phi\": 0.374756454937325}, {\"truth_threshold\": 19.64, \"match_probability\": 0.9999987760311826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3477, \"tn\": 8049, \"fp\": 0, \"fn\": 8547, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28917165668662675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7108283433133733, \"precision\": 1.0, \"recall\": 0.28917165668662675, \"specificity\": 1.0, \"npv\": 0.4849963846710051, \"accuracy\": 0.5742041548348528, \"f1\": 0.44861621830849624, \"f2\": 0.33709499156535394, \"f0_5\": 0.6704072188801481, \"p4\": 0.5319131521281465, \"phi\": 0.3744959386192847}, {\"truth_threshold\": 19.66, \"match_probability\": 0.9999987928819026, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3467, \"tn\": 8049, \"fp\": 0, \"fn\": 8557, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2883399866932801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7116600133067199, \"precision\": 1.0, \"recall\": 0.2883399866932801, \"specificity\": 1.0, \"npv\": 0.4847043237384078, \"accuracy\": 0.5737059731978279, \"f1\": 0.4476147440449293, \"f2\": 0.3361906793631092, \"f0_5\": 0.6695118183222617, \"p4\": 0.5311209317528629, \"phi\": 0.37384440380579165}, {\"truth_threshold\": 19.68, \"match_probability\": 0.9999988095006345, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3459, \"tn\": 8049, \"fp\": 0, \"fn\": 8565, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2876746506986028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7123253493013972, \"precision\": 1.0, \"recall\": 0.2876746506986028, \"specificity\": 1.0, \"npv\": 0.48447092813289994, \"accuracy\": 0.573307427888208, \"f1\": 0.4468126332106181, \"f2\": 0.3354669770148385, \"f0_5\": 0.6687935034802784, \"p4\": 0.5304859311004273, \"phi\": 0.37332292325044797}, {\"truth_threshold\": 19.7, \"match_probability\": 0.9999988258905718, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3456, \"tn\": 8049, \"fp\": 0, \"fn\": 8568, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2874251497005988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7125748502994012, \"precision\": 1.0, \"recall\": 0.2874251497005988, \"specificity\": 1.0, \"npv\": 0.4843834627189023, \"accuracy\": 0.5731579733971006, \"f1\": 0.44651162790697674, \"f2\": 0.33519553072625696, \"f0_5\": 0.6685236768802229, \"p4\": 0.5302475241919463, \"phi\": 0.37312730975429137}, {\"truth_threshold\": 19.72, \"match_probability\": 0.9999988420548644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3447, \"tn\": 8049, \"fp\": 0, \"fn\": 8577, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2866766467065868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7133233532934131, \"precision\": 1.0, \"recall\": 0.2866766467065868, \"specificity\": 1.0, \"npv\": 0.48412125586430893, \"accuracy\": 0.5727096099237782, \"f1\": 0.445607911576498, \"f2\": 0.3343810022699494, \"f0_5\": 0.6677126917712691, \"p4\": 0.5295313782649674, \"phi\": 0.37254027732657524}, {\"truth_threshold\": 19.740000000000002, \"match_probability\": 0.9999988579966191, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3445, \"tn\": 8049, \"fp\": 0, \"fn\": 8579, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2865103127079175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7134896872920825, \"precision\": 1.0, \"recall\": 0.2865103127079175, \"specificity\": 1.0, \"npv\": 0.4840630262208323, \"accuracy\": 0.5726099735963732, \"f1\": 0.44540694291809424, \"f2\": 0.3341999573155352, \"f0_5\": 0.6675321655557278, \"p4\": 0.5293720457731252, \"phi\": 0.372409786408563}, {\"truth_threshold\": 19.76, \"match_probability\": 0.9999988737188994, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3443, \"tn\": 8049, \"fp\": 0, \"fn\": 8581, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28634397870924816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7136560212907518, \"precision\": 1.0, \"recall\": 0.28634397870924816, \"specificity\": 1.0, \"npv\": 0.4840048105832832, \"accuracy\": 0.5725103372689683, \"f1\": 0.44520592228615763, \"f2\": 0.33401889831001763, \"f0_5\": 0.6673515273685843, \"p4\": 0.5292126444068967, \"phi\": 0.37227928115439535}, {\"truth_threshold\": 19.78, \"match_probability\": 0.9999988892247269, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3441, \"tn\": 8049, \"fp\": 0, \"fn\": 8583, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2861776447105788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7138223552894212, \"precision\": 1.0, \"recall\": 0.2861776447105788, \"specificity\": 1.0, \"npv\": 0.48394660894660896, \"accuracy\": 0.5724107009415633, \"f1\": 0.4450048496605238, \"f2\": 0.33383782525176087, \"f0_5\": 0.6671707771056306, \"p4\": 0.5290531740902249, \"phi\": 0.37214876153765725}, {\"truth_threshold\": 19.8, \"match_probability\": 0.9999989045170816, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3433, \"tn\": 8049, \"fp\": 0, \"fn\": 8591, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28551230871590155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7144876912840985, \"precision\": 1.0, \"recall\": 0.28551230871590155, \"specificity\": 1.0, \"npv\": 0.4837139423076923, \"accuracy\": 0.5720121556319434, \"f1\": 0.4442000388173643, \"f2\": 0.33311339245861554, \"f0_5\": 0.6664466532070197, \"p4\": 0.5284146017944289, \"phi\": 0.371626538915535}, {\"truth_threshold\": 19.82, \"match_probability\": 0.9999989195989024, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3427, \"tn\": 8049, \"fp\": 0, \"fn\": 8597, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28501330671989356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7149866932801064, \"precision\": 1.0, \"recall\": 0.28501330671989356, \"specificity\": 1.0, \"npv\": 0.4835395890904722, \"accuracy\": 0.5717132466497284, \"f1\": 0.44359588376156883, \"f2\": 0.3325699202298003, \"f0_5\": 0.6659023783615732, \"p4\": 0.5279349448510849, \"phi\": 0.3712347198426543}, {\"truth_threshold\": 19.84, \"match_probability\": 0.9999989344730877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3424, \"tn\": 8049, \"fp\": 0, \"fn\": 8600, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28476380572188953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7152361942781105, \"precision\": 1.0, \"recall\": 0.28476380572188953, \"specificity\": 1.0, \"npv\": 0.48345245960718364, \"accuracy\": 0.5715637921586211, \"f1\": 0.4432936302433972, \"f2\": 0.33229813664596275, \"f0_5\": 0.6656298600311042, \"p4\": 0.5276948817354548, \"phi\": 0.3710387611602724}, {\"truth_threshold\": 19.86, \"match_probability\": 0.9999989491424962, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3422, \"tn\": 8049, \"fp\": 0, \"fn\": 8602, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28459747172322025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7154025282767797, \"precision\": 1.0, \"recall\": 0.28459747172322025, \"specificity\": 1.0, \"npv\": 0.48339439072728363, \"accuracy\": 0.571464155831216, \"f1\": 0.4430920626699469, \"f2\": 0.3321169300050468, \"f0_5\": 0.6654480398257623, \"p4\": 0.5275347525768638, \"phi\": 0.3709081037752766}, {\"truth_threshold\": 19.88, \"match_probability\": 0.999998963609947, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3419, \"tn\": 8049, \"fp\": 0, \"fn\": 8605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2843479707252162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7156520292747838, \"precision\": 1.0, \"recall\": 0.2843479707252162, \"specificity\": 1.0, \"npv\": 0.4833073135583043, \"accuracy\": 0.5713147013401086, \"f1\": 0.4427896134170822, \"f2\": 0.3318450936620402, \"f0_5\": 0.6651750972762646, \"p4\": 0.5272944280239078, \"phi\": 0.370712090235751}, {\"truth_threshold\": 19.900000000000002, \"match_probability\": 0.9999989778782205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3412, \"tn\": 8049, \"fp\": 0, \"fn\": 8612, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2837658017298736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7162341982701265, \"precision\": 1.0, \"recall\": 0.2837658017298736, \"specificity\": 1.0, \"npv\": 0.4831042554468519, \"accuracy\": 0.5709659741941912, \"f1\": 0.4420834413060378, \"f2\": 0.3312106857187233, \"f0_5\": 0.6645372390152695, \"p4\": 0.5267330589102867, \"phi\": 0.3702545966844835}, {\"truth_threshold\": 19.92, \"match_probability\": 0.9999989919500589, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3409, \"tn\": 8049, \"fp\": 0, \"fn\": 8615, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2835163007318696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7164836992681304, \"precision\": 1.0, \"recall\": 0.2835163007318696, \"specificity\": 1.0, \"npv\": 0.4830172827652424, \"accuracy\": 0.5708165197030838, \"f1\": 0.44178060001295927, \"f2\": 0.33093874381128047, \"f0_5\": 0.6642634450506625, \"p4\": 0.5264922093075007, \"phi\": 0.3700584726758205}, {\"truth_threshold\": 19.94, \"match_probability\": 0.9999990058281665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3406, \"tn\": 8049, \"fp\": 0, \"fn\": 8618, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2832667997338656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7167332002661344, \"precision\": 1.0, \"recall\": 0.2832667997338656, \"specificity\": 1.0, \"npv\": 0.48293034139317215, \"accuracy\": 0.5706670652119763, \"f1\": 0.44147764095917047, \"f2\": 0.3306667702225156, \"f0_5\": 0.6639893948845914, \"p4\": 0.5262512016219542, \"phi\": 0.36986231532940345}, {\"truth_threshold\": 19.96, \"match_probability\": 0.9999990195152105, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3403, \"tn\": 8049, \"fp\": 0, \"fn\": 8621, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2830172987358616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7169827012641384, \"precision\": 1.0, \"recall\": 0.2830172987358616, \"specificity\": 1.0, \"npv\": 0.48284343131373725, \"accuracy\": 0.5705176107208688, \"f1\": 0.4411745640759707, \"f2\": 0.3303947649468922, \"f0_5\": 0.6637150881572789, \"p4\": 0.5260100355906467, \"phi\": 0.3696661245539933}, {\"truth_threshold\": 19.98, \"match_probability\": 0.9999990330138213, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3390, \"tn\": 8049, \"fp\": 0, \"fn\": 8634, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.281936127744511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7180638722554891, \"precision\": 1.0, \"recall\": 0.281936127744511, \"specificity\": 1.0, \"npv\": 0.48246718216148177, \"accuracy\": 0.5698699745927365, \"f1\": 0.4398598676527832, \"f2\": 0.32921570912481063, \"f0_5\": 0.6625234521575984, \"p4\": 0.5249631465755513, \"phi\": 0.3688155760029852}, {\"truth_threshold\": 20.0, \"match_probability\": 0.9999990463265931, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3386, \"tn\": 8049, \"fp\": 0, \"fn\": 8638, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2816034597471723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7183965402528277, \"precision\": 1.0, \"recall\": 0.2816034597471723, \"specificity\": 1.0, \"npv\": 0.48235153113201895, \"accuracy\": 0.5696707019379266, \"f1\": 0.43945489941596366, \"f2\": 0.32885280292140945, \"f0_5\": 0.6621558197747184, \"p4\": 0.5246404243537067, \"phi\": 0.3685537409674774}, {\"truth_threshold\": 20.02, \"match_probability\": 0.9999990594560844, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3381, \"tn\": 8049, \"fp\": 0, \"fn\": 8643, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.281187624750499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.718812375249501, \"precision\": 1.0, \"recall\": 0.281187624750499, \"specificity\": 1.0, \"npv\": 0.48220704529115743, \"accuracy\": 0.5694216111194141, \"f1\": 0.4389483933787731, \"f2\": 0.3283990908561105, \"f0_5\": 0.6616956317519962, \"p4\": 0.5242366212205548, \"phi\": 0.36822636204293796}, {\"truth_threshold\": 20.04, \"match_probability\": 0.9999990724048183, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3379, \"tn\": 8049, \"fp\": 0, \"fn\": 8645, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2810212907518297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7189787092481703, \"precision\": 1.0, \"recall\": 0.2810212907518297, \"specificity\": 1.0, \"npv\": 0.48214927518869055, \"accuracy\": 0.5693219747920092, \"f1\": 0.4387456988898267, \"f2\": 0.32821758135017, \"f0_5\": 0.6615113547376664, \"p4\": 0.5240749751581691, \"phi\": 0.3680953839001312}, {\"truth_threshold\": 20.06, \"match_probability\": 0.9999990851752837, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3375, \"tn\": 8049, \"fp\": 0, \"fn\": 8649, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.280688622754491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.719311377245509, \"precision\": 1.0, \"recall\": 0.280688622754491, \"specificity\": 1.0, \"npv\": 0.48203377650017964, \"accuracy\": 0.5691227021371992, \"f1\": 0.43834015195791937, \"f2\": 0.3278545200209827, \"f0_5\": 0.6611424541607899, \"p4\": 0.5237514686384206, \"phi\": 0.36783338190950204}, {\"truth_threshold\": 20.080000000000002, \"match_probability\": 0.9999990977699345, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3371, \"tn\": 8049, \"fp\": 0, \"fn\": 8653, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.28035595475715236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7196440452428476, \"precision\": 1.0, \"recall\": 0.28035595475715236, \"specificity\": 1.0, \"npv\": 0.4819183331337564, \"accuracy\": 0.5689234294823893, \"f1\": 0.4379343942838584, \"f2\": 0.3274914022577574, \"f0_5\": 0.6607730907950446, \"p4\": 0.5234276757283058, \"phi\": 0.36757131879499205}, {\"truth_threshold\": 20.1, \"match_probability\": 0.9999991101911914, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3366, \"tn\": 8049, \"fp\": 0, \"fn\": 8658, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27994011976047906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7200598802395209, \"precision\": 1.0, \"recall\": 0.27994011976047906, \"specificity\": 1.0, \"npv\": 0.48177410666187825, \"accuracy\": 0.5686743386638768, \"f1\": 0.43742690058479533, \"f2\": 0.32703742567331234, \"f0_5\": 0.6603107344632768, \"p4\": 0.5230225308821349, \"phi\": 0.3672436536094586}, {\"truth_threshold\": 20.12, \"match_probability\": 0.9999991224414414, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3363, \"tn\": 8049, \"fp\": 0, \"fn\": 8661, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27969061876247503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.720309381237525, \"precision\": 1.0, \"recall\": 0.27969061876247503, \"specificity\": 1.0, \"npv\": 0.4816876122082585, \"accuracy\": 0.5685248841727694, \"f1\": 0.43712224605186195, \"f2\": 0.3267649973765522, \"f0_5\": 0.660032972209138, \"p4\": 0.5227792281833699, \"phi\": 0.36704700830921777}, {\"truth_threshold\": 20.14, \"match_probability\": 0.999999134523039, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3362, \"tn\": 8049, \"fp\": 0, \"fn\": 8662, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2796074517631404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7203925482368596, \"precision\": 1.0, \"recall\": 0.2796074517631404, \"specificity\": 1.0, \"npv\": 0.4816587876249177, \"accuracy\": 0.5684750660090669, \"f1\": 0.4370206681398674, \"f2\": 0.32667418088538225, \"f0_5\": 0.6599403266331658, \"p4\": 0.5226980912584924, \"phi\": 0.36698145215681793}, {\"truth_threshold\": 20.16, \"match_probability\": 0.9999991464383059, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3359, \"tn\": 8049, \"fp\": 0, \"fn\": 8665, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2793579507651364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7206420492348636, \"precision\": 1.0, \"recall\": 0.2793579507651364, \"specificity\": 1.0, \"npv\": 0.4815723345698217, \"accuracy\": 0.5683256115179595, \"f1\": 0.4367158551647923, \"f2\": 0.32640171023224174, \"f0_5\": 0.6596622152395916, \"p4\": 0.5224545722674475, \"phi\": 0.36678476049395514}, {\"truth_threshold\": 20.18, \"match_probability\": 0.9999991581895321, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3356, \"tn\": 8049, \"fp\": 0, \"fn\": 8668, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2791084497671324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7208915502328676, \"precision\": 1.0, \"recall\": 0.2791084497671324, \"specificity\": 1.0, \"npv\": 0.48148591254411677, \"accuracy\": 0.568176157026852, \"f1\": 0.4364109232769831, \"f2\": 0.3261292078053331, \"f0_5\": 0.6593838415592581, \"p4\": 0.5222108907406119, \"phi\": 0.3665880339494206}, {\"truth_threshold\": 20.2, \"match_probability\": 0.999999169778976, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3353, \"tn\": 8049, \"fp\": 0, \"fn\": 8671, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2788589487691284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7211410512308716, \"precision\": 1.0, \"recall\": 0.2788589487691284, \"specificity\": 1.0, \"npv\": 0.4813995215311005, \"accuracy\": 0.5680267025357445, \"f1\": 0.4361058724068414, \"f2\": 0.32585667359909815, \"f0_5\": 0.6591052052209467, \"p4\": 0.5219670464060209, \"phi\": 0.36639127242897596}, {\"truth_threshold\": 20.22, \"match_probability\": 0.9999991812088648, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3349, \"tn\": 8049, \"fp\": 0, \"fn\": 8675, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27852628077178976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7214737192282102, \"precision\": 1.0, \"recall\": 0.27852628077178976, \"specificity\": 1.0, \"npv\": 0.4812843817268596, \"accuracy\": 0.5678274298809346, \"f1\": 0.43569895270929554, \"f2\": 0.3254932452133346, \"f0_5\": 0.6587332808811959, \"p4\": 0.5216416668989656, \"phi\": 0.36612886916485093}, {\"truth_threshold\": 20.240000000000002, \"match_probability\": 0.9999991924813951, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3347, \"tn\": 8049, \"fp\": 0, \"fn\": 8677, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2783599467731204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7216400532268795, \"precision\": 1.0, \"recall\": 0.2783599467731204, \"specificity\": 1.0, \"npv\": 0.4812268324763841, \"accuracy\": 0.5677277935535296, \"f1\": 0.4354954134408952, \"f2\": 0.32531150982640983, \"f0_5\": 0.6585471430820085, \"p4\": 0.5214788682229629, \"phi\": 0.36599764408247715}, {\"truth_threshold\": 20.26, \"match_probability\": 0.9999992035987335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3340, \"tn\": 8049, \"fp\": 0, \"fn\": 8684, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2777777777777778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7222222222222222, \"precision\": 1.0, \"recall\": 0.2777777777777778, \"specificity\": 1.0, \"npv\": 0.4810255184366222, \"accuracy\": 0.5673790664076123, \"f1\": 0.43478260869565216, \"f2\": 0.3246753246753247, \"f0_5\": 0.6578947368421053, \"p4\": 0.5209084996294941, \"phi\": 0.36553823270039537}, {\"truth_threshold\": 20.28, \"match_probability\": 0.9999992145630165, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3333, \"tn\": 8049, \"fp\": 0, \"fn\": 8691, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27719560878243515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7228043912175649, \"precision\": 1.0, \"recall\": 0.27719560878243515, \"specificity\": 1.0, \"npv\": 0.4808243727598566, \"accuracy\": 0.5670303392616948, \"f1\": 0.43406915413166636, \"f2\": 0.3240389663419472, \"f0_5\": 0.6572408897302414, \"p4\": 0.520337236689306, \"phi\": 0.36507862814002273}, {\"truth_threshold\": 20.3, \"match_probability\": 0.9999992253763512, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3327, \"tn\": 8049, \"fp\": 0, \"fn\": 8697, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27669660678642716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7233033932135728, \"precision\": 1.0, \"recall\": 0.27669660678642716, \"specificity\": 1.0, \"npv\": 0.48065209602293085, \"accuracy\": 0.5667314302794799, \"f1\": 0.43345710377174124, \"f2\": 0.323493378449332, \"f0_5\": 0.656679298910469, \"p4\": 0.5198468682577473, \"phi\": 0.3646845266998984}, {\"truth_threshold\": 20.32, \"match_probability\": 0.9999992360408158, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3326, \"tn\": 8049, \"fp\": 0, \"fn\": 8698, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27661343978709246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7233865602129075, \"precision\": 1.0, \"recall\": 0.27661343978709246, \"specificity\": 1.0, \"npv\": 0.48062339523496744, \"accuracy\": 0.5666816121157774, \"f1\": 0.43335504885993487, \"f2\": 0.3234024347555521, \"f0_5\": 0.6565855969677827, \"p4\": 0.5197650758981326, \"phi\": 0.36461882918754435}, {\"truth_threshold\": 20.34, \"match_probability\": 0.9999992465584596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3325, \"tn\": 8049, \"fp\": 0, \"fn\": 8699, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2765302727877578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7234697272122422, \"precision\": 1.0, \"recall\": 0.2765302727877578, \"specificity\": 1.0, \"npv\": 0.48059469787437303, \"accuracy\": 0.566631793952075, \"f1\": 0.43325298065020523, \"f2\": 0.32331148752455224, \"f0_5\": 0.6564918654241036, \"p4\": 0.5196832651432012, \"phi\": 0.3645531276831272}, {\"truth_threshold\": 20.36, \"match_probability\": 0.9999992569313043, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3320, \"tn\": 8049, \"fp\": 0, \"fn\": 8704, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2761144377910845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7238855622089155, \"precision\": 1.0, \"recall\": 0.2761144377910845, \"specificity\": 1.0, \"npv\": 0.48045126246045483, \"accuracy\": 0.5663827031335625, \"f1\": 0.43274244004171014, \"f2\": 0.32285669830402985, \"f0_5\": 0.6560227631994942, \"p4\": 0.5192739350783022, \"phi\": 0.3642245601552499}, {\"truth_threshold\": 20.38, \"match_probability\": 0.9999992671613431, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3311, \"tn\": 8049, \"fp\": 0, \"fn\": 8713, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2753659347970725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7246340652029275, \"precision\": 1.0, \"recall\": 0.2753659347970725, \"specificity\": 1.0, \"npv\": 0.48019329435628205, \"accuracy\": 0.5659343396602401, \"f1\": 0.4318226279752201, \"f2\": 0.32203785476686053, \"f0_5\": 0.6551765078359981, \"p4\": 0.5185359772892228, \"phi\": 0.36363288545413963}, {\"truth_threshold\": 20.400000000000002, \"match_probability\": 0.9999992772505422, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3299, \"tn\": 8049, \"fp\": 0, \"fn\": 8725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27436793080505656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7256320691949435, \"precision\": 1.0, \"recall\": 0.27436793080505656, \"specificity\": 1.0, \"npv\": 0.4798497674973173, \"accuracy\": 0.5653365216958103, \"f1\": 0.43059453109704365, \"f2\": 0.32094561727794535, \"f0_5\": 0.6540444091990484, \"p4\": 0.5175496948962155, \"phi\": 0.3628434756276134}, {\"truth_threshold\": 20.44, \"match_probability\": 0.9999992970141501, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3297, \"tn\": 8049, \"fp\": 0, \"fn\": 8727, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2742015968063872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7257984031936128, \"precision\": 1.0, \"recall\": 0.2742015968063872, \"specificity\": 1.0, \"npv\": 0.4797925608011445, \"accuracy\": 0.5652368853684053, \"f1\": 0.4303896612492657, \"f2\": 0.32076352810694064, \"f0_5\": 0.6538553069966683, \"p4\": 0.5173850535257773, \"phi\": 0.36271185024410146}, {\"truth_threshold\": 20.46, \"match_probability\": 0.9999993066923574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3285, \"tn\": 8049, \"fp\": 0, \"fn\": 8739, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27320359281437123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7267964071856288, \"precision\": 1.0, \"recall\": 0.27320359281437123, \"specificity\": 1.0, \"npv\": 0.4794496068620443, \"accuracy\": 0.5646390674039755, \"f1\": 0.42915931804820695, \"f2\": 0.3196706953932387, \"f0_5\": 0.6527181688125894, \"p4\": 0.5163956318390934, \"phi\": 0.3619217528253149}, {\"truth_threshold\": 20.48, \"match_probability\": 0.9999993162373221, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3281, \"tn\": 8049, \"fp\": 0, \"fn\": 8743, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2728709248170326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7271290751829674, \"precision\": 1.0, \"recall\": 0.2728709248170326, \"specificity\": 1.0, \"npv\": 0.4793353978084802, \"accuracy\": 0.5644397947491655, \"f1\": 0.42874877491016006, \"f2\": 0.31930630437744517, \"f0_5\": 0.6523381581040242, \"p4\": 0.5160652231715331, \"phi\": 0.3616582548450128}, {\"truth_threshold\": 20.5, \"match_probability\": 0.9999993256508786, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3273, \"tn\": 8049, \"fp\": 0, \"fn\": 8751, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2722055888223553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7277944111776448, \"precision\": 1.0, \"recall\": 0.2722055888223553, \"specificity\": 1.0, \"npv\": 0.47910714285714284, \"accuracy\": 0.5640412494395457, \"f1\": 0.42792704451853303, \"f2\": 0.31857735209951527, \"f0_5\": 0.6515766841853798, \"p4\": 0.5154034996128513, \"phi\": 0.3611310592159374}, {\"truth_threshold\": 20.52, \"match_probability\": 0.9999993349348361, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3271, \"tn\": 8049, \"fp\": 0, \"fn\": 8753, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.27203925482368596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.727960745176314, \"precision\": 1.0, \"recall\": 0.27203925482368596, \"specificity\": 1.0, \"npv\": 0.479050113081776, \"accuracy\": 0.5639416131121406, \"f1\": 0.42772147760706114, \"f2\": 0.318395078552378, \"f0_5\": 0.6513860124263183, \"p4\": 0.5152378794303301, \"phi\": 0.3609992185392772}, {\"truth_threshold\": 20.54, \"match_probability\": 0.9999993440909787, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3268, \"tn\": 8049, \"fp\": 0, \"fn\": 8756, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.271789753825682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7282102461743181, \"precision\": 1.0, \"recall\": 0.271789753825682, \"specificity\": 1.0, \"npv\": 0.47896459387087176, \"accuracy\": 0.5637921586210333, \"f1\": 0.42741302641904266, \"f2\": 0.31812164161669654, \"f0_5\": 0.6510997768568696, \"p4\": 0.5149893068402841, \"phi\": 0.3608014260772565}, {\"truth_threshold\": 20.56, \"match_probability\": 0.9999993531210661, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3264, \"tn\": 8049, \"fp\": 0, \"fn\": 8760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2714570858283433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7285429141716567, \"precision\": 1.0, \"recall\": 0.2714570858283433, \"specificity\": 1.0, \"npv\": 0.478850615741567, \"accuracy\": 0.5635928859662233, \"f1\": 0.42700156985871274, \"f2\": 0.3177570093457944, \"f0_5\": 0.6507177033492823, \"p4\": 0.5146576106139458, \"phi\": 0.36053764393793003}, {\"truth_threshold\": 20.580000000000002, \"match_probability\": 0.9999993620268339, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3257, \"tn\": 8049, \"fp\": 0, \"fn\": 8767, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2708749168330007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7291250831669993, \"precision\": 1.0, \"recall\": 0.2708749168330007, \"specificity\": 1.0, \"npv\": 0.478651284490961, \"accuracy\": 0.5632441588203059, \"f1\": 0.426281002552189, \"f2\": 0.3171187661869803, \"f0_5\": 0.6500479003672361, \"p4\": 0.5140764084985232, \"phi\": 0.36007586267132374}, {\"truth_threshold\": 20.6, \"match_probability\": 0.9999993708099935, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3253, \"tn\": 8049, \"fp\": 0, \"fn\": 8771, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.270542248835662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.729457751164338, \"precision\": 1.0, \"recall\": 0.270542248835662, \"specificity\": 1.0, \"npv\": 0.4785374554102259, \"accuracy\": 0.563044886165496, \"f1\": 0.4258689533285331, \"f2\": 0.316753977682136, \"f0_5\": 0.6496644831442723, \"p4\": 0.5137438725523258, \"phi\": 0.35981189438201994}, {\"truth_threshold\": 20.62, \"match_probability\": 0.9999993794722328, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3247, \"tn\": 8049, \"fp\": 0, \"fn\": 8777, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.270043246839654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.729956753160346, \"precision\": 1.0, \"recall\": 0.270043246839654, \"specificity\": 1.0, \"npv\": 0.4783668132651848, \"accuracy\": 0.562745977183281, \"f1\": 0.4252504747560736, \"f2\": 0.31620668835089494, \"f0_5\": 0.649088437549976, \"p4\": 0.5132444934542291, \"phi\": 0.35941581411294216}, {\"truth_threshold\": 20.64, \"match_probability\": 0.9999993880152168, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3240, \"tn\": 8049, \"fp\": 0, \"fn\": 8784, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2694610778443114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7305389221556886, \"precision\": 1.0, \"recall\": 0.2694610778443114, \"specificity\": 1.0, \"npv\": 0.4781678845125646, \"accuracy\": 0.5623972500373636, \"f1\": 0.42452830188679247, \"f2\": 0.3155680224403927, \"f0_5\": 0.6484149855907781, \"p4\": 0.5126610093564297, \"phi\": 0.35895352561479305}, {\"truth_threshold\": 20.66, \"match_probability\": 0.999999396440587, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3239, \"tn\": 8049, \"fp\": 0, \"fn\": 8785, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2693779108449767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7306220891550232, \"precision\": 1.0, \"recall\": 0.2693779108449767, \"specificity\": 1.0, \"npv\": 0.4781394796245693, \"accuracy\": 0.5623474318736611, \"f1\": 0.42442508025945097, \"f2\": 0.31547677023473264, \"f0_5\": 0.6483186549239391, \"p4\": 0.5125775773460338, \"phi\": 0.3588874672007519}, {\"truth_threshold\": 20.68, \"match_probability\": 0.9999994047499629, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3234, \"tn\": 8049, \"fp\": 0, \"fn\": 8790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2689620758483034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7310379241516967, \"precision\": 1.0, \"recall\": 0.2689620758483034, \"specificity\": 1.0, \"npv\": 0.47799750579013006, \"accuracy\": 0.5620983410551487, \"f1\": 0.4239087691702713, \"f2\": 0.31502045587375804, \"f0_5\": 0.6478365384615384, \"p4\": 0.5121601273125039, \"phi\": 0.3585571103849773}, {\"truth_threshold\": 20.7, \"match_probability\": 0.9999994129449412, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3233, \"tn\": 8049, \"fp\": 0, \"fn\": 8791, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26887890884896876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7311210911510313, \"precision\": 1.0, \"recall\": 0.26887890884896876, \"specificity\": 1.0, \"npv\": 0.4779691211401425, \"accuracy\": 0.5620485228914462, \"f1\": 0.42380546634331784, \"f2\": 0.3149291823335736, \"f0_5\": 0.6477400224394935, \"p4\": 0.5120765792329237, \"phi\": 0.3584910260462067}, {\"truth_threshold\": 20.72, \"match_probability\": 0.999999421027097, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3228, \"tn\": 8049, \"fp\": 0, \"fn\": 8796, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2684630738522954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7315369261477046, \"precision\": 1.0, \"recall\": 0.2684630738522954, \"specificity\": 1.0, \"npv\": 0.47782724844167407, \"accuracy\": 0.5617994320729338, \"f1\": 0.4232887490165224, \"f2\": 0.31447276128127194, \"f0_5\": 0.6472569778633301, \"p4\": 0.5116585478678295, \"phi\": 0.35816053926561514}, {\"truth_threshold\": 20.740000000000002, \"match_probability\": 0.9999994289979836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3224, \"tn\": 8049, \"fp\": 0, \"fn\": 8800, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26813040585495673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7318695941450433, \"precision\": 1.0, \"recall\": 0.26813040585495673, \"specificity\": 1.0, \"npv\": 0.4777138109086593, \"accuracy\": 0.5616001594181238, \"f1\": 0.4228751311647429, \"f2\": 0.3141075604053001, \"f0_5\": 0.6468699839486356, \"p4\": 0.5113237729557986, \"phi\": 0.3578960715088346}, {\"truth_threshold\": 20.76, \"match_probability\": 0.9999994368591326, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3220, \"tn\": 8049, \"fp\": 0, \"fn\": 8804, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2677977378576181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7322022621423819, \"precision\": 1.0, \"recall\": 0.2677977378576181, \"specificity\": 1.0, \"npv\": 0.4776004272236397, \"accuracy\": 0.5614008867633139, \"f1\": 0.422461296247704, \"f2\": 0.31374230259568164, \"f0_5\": 0.6464824927722455, \"p4\": 0.510988686328969, \"phi\": 0.3576315338589743}, {\"truth_threshold\": 20.78, \"match_probability\": 0.999999444612055, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3216, \"tn\": 8049, \"fp\": 0, \"fn\": 8808, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26746506986027946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7325349301397206, \"precision\": 1.0, \"recall\": 0.26746506986027946, \"specificity\": 1.0, \"npv\": 0.4774870973482826, \"accuracy\": 0.561201614108504, \"f1\": 0.4220472440944882, \"f2\": 0.31337698783910195, \"f0_5\": 0.6460945033751205, \"p4\": 0.5106532872802914, \"phi\": 0.3573669260712867}, {\"truth_threshold\": 20.8, \"match_probability\": 0.9999994522582408, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3209, \"tn\": 8049, \"fp\": 0, \"fn\": 8815, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26688290086493677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7331170991350632, \"precision\": 1.0, \"recall\": 0.26688290086493677, \"specificity\": 1.0, \"npv\": 0.47728889943074004, \"accuracy\": 0.5608528869625865, \"f1\": 0.4213221295870807, \"f2\": 0.31273754994639896, \"f0_5\": 0.6454143201930812, \"p4\": 0.5100655850463729, \"phi\": 0.35690369293509555}, {\"truth_threshold\": 20.82, \"match_probability\": 0.9999994597991594, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3200, \"tn\": 8049, \"fp\": 0, \"fn\": 8824, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2661343978709248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7338656021290751, \"precision\": 1.0, \"recall\": 0.2661343978709248, \"specificity\": 1.0, \"npv\": 0.4770343151780952, \"accuracy\": 0.5604045234892642, \"f1\": 0.42038885969521805, \"f2\": 0.3119151590767311, \"f0_5\": 0.6445375443119562, \"p4\": 0.509308552657519, \"phi\": 0.3563077886233914}, {\"truth_threshold\": 20.84, \"match_probability\": 0.99999946723626, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3193, \"tn\": 8049, \"fp\": 0, \"fn\": 8831, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26555222887558216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7344477711244178, \"precision\": 1.0, \"recall\": 0.26555222887558216, \"specificity\": 1.0, \"npv\": 0.4768364928909953, \"accuracy\": 0.5600557963433468, \"f1\": 0.4196622198856542, \"f2\": 0.31127532219384274, \"f0_5\": 0.643853847394741, \"p4\": 0.5087186441523411, \"phi\": 0.35584405783491657}, {\"truth_threshold\": 20.86, \"match_probability\": 0.999999474570972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3187, \"tn\": 8049, \"fp\": 0, \"fn\": 8837, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26505322687957417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7349467731204258, \"precision\": 1.0, \"recall\": 0.26505322687957417, \"specificity\": 1.0, \"npv\": 0.4766670614710411, \"accuracy\": 0.5597568873611318, \"f1\": 0.41903885346131087, \"f2\": 0.3107267515550962, \"f0_5\": 0.6432665913127725, \"p4\": 0.5082122351496463, \"phi\": 0.355446399320775}, {\"truth_threshold\": 20.88, \"match_probability\": 0.999999481804705, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3182, \"tn\": 8049, \"fp\": 0, \"fn\": 8842, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26463739188290086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7353626081170991, \"precision\": 1.0, \"recall\": 0.26463739188290086, \"specificity\": 1.0, \"npv\": 0.4765259605707181, \"accuracy\": 0.5595077965426194, \"f1\": 0.41851900565566225, \"f2\": 0.310269511291392, \"f0_5\": 0.6427763413057531, \"p4\": 0.5077896806207401, \"phi\": 0.35511489319645395}, {\"truth_threshold\": 20.900000000000002, \"match_probability\": 0.999999488938849, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3178, \"tn\": 8049, \"fp\": 0, \"fn\": 8846, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2643047238855622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7356952761144377, \"precision\": 1.0, \"recall\": 0.2643047238855622, \"specificity\": 1.0, \"npv\": 0.47641313998224327, \"accuracy\": 0.5593085238878095, \"f1\": 0.4181028811998421, \"f2\": 0.3099036548738152, \"f0_5\": 0.6423835705045278, \"p4\": 0.5074512779237003, \"phi\": 0.3548496067610341}, {\"truth_threshold\": 20.92, \"match_probability\": 0.9999994959747754, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3174, \"tn\": 8049, \"fp\": 0, \"fn\": 8850, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26397205588822353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7360279441117764, \"precision\": 1.0, \"recall\": 0.26397205588822353, \"specificity\": 1.0, \"npv\": 0.4763003728031244, \"accuracy\": 0.5591092512329996, \"f1\": 0.4176865377023293, \"f2\": 0.30953774136922174, \"f0_5\": 0.6419902912621359, \"p4\": 0.5071125552613919, \"phi\": 0.35458424757618334}, {\"truth_threshold\": 20.94, \"match_probability\": 0.9999995029138362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3172, \"tn\": 8049, \"fp\": 0, \"fn\": 8852, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2638057218895542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7361942781104458, \"precision\": 1.0, \"recall\": 0.2638057218895542, \"specificity\": 1.0, \"npv\": 0.4762440092302231, \"accuracy\": 0.5590096149055945, \"f1\": 0.4174782837588839, \"f2\": 0.3093547632051182, \"f0_5\": 0.6417934606668825, \"p4\": 0.5069430737152288, \"phi\": 0.35445154062375656}, {\"truth_threshold\": 20.96, \"match_probability\": 0.999999509757365, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3171, \"tn\": 8049, \"fp\": 0, \"fn\": 8853, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26372255489021956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7362774451097804, \"precision\": 1.0, \"recall\": 0.26372255489021956, \"specificity\": 1.0, \"npv\": 0.4762158324458644, \"accuracy\": 0.5589597967418921, \"f1\": 0.4173741362290227, \"f2\": 0.3092632687693838, \"f0_5\": 0.6416949975716367, \"p4\": 0.5068583028484128, \"phi\": 0.3543851802936969}, {\"truth_threshold\": 20.98, \"match_probability\": 0.9999995165066768, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3168, \"tn\": 8049, \"fp\": 0, \"fn\": 8856, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2634730538922156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7365269461077845, \"precision\": 1.0, \"recall\": 0.2634730538922156, \"specificity\": 1.0, \"npv\": 0.476131322094055, \"accuracy\": 0.5588103422507846, \"f1\": 0.41706161137440756, \"f2\": 0.3089887640449438, \"f0_5\": 0.641399416909621, \"p4\": 0.5066038697357057, \"phi\": 0.35418607184057765}, {\"truth_threshold\": 21.0, \"match_probability\": 0.9999995231630692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3163, \"tn\": 8049, \"fp\": 0, \"fn\": 8861, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26305721889554223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7369427811044578, \"precision\": 1.0, \"recall\": 0.26305721889554223, \"specificity\": 1.0, \"npv\": 0.4759905381431106, \"accuracy\": 0.5585612514322722, \"f1\": 0.4165404622374399, \"f2\": 0.30853118476755304, \"f0_5\": 0.6409061436213325, \"p4\": 0.5061794121524078, \"phi\": 0.35385413263733295}, {\"truth_threshold\": 21.02, \"match_probability\": 0.999999529727821, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3157, \"tn\": 8049, \"fp\": 0, \"fn\": 8867, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2625582168995343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7374417831004657, \"precision\": 1.0, \"recall\": 0.2625582168995343, \"specificity\": 1.0, \"npv\": 0.4758217072593994, \"accuracy\": 0.5582623424500572, \"f1\": 0.4159146301297675, \"f2\": 0.30798197178701736, \"f0_5\": 0.6403131591757261, \"p4\": 0.5056693973296588, \"phi\": 0.3534556535410349}, {\"truth_threshold\": 21.04, \"match_probability\": 0.9999995362021941, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3150, \"tn\": 8049, \"fp\": 0, \"fn\": 8874, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2619760479041916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7380239520958084, \"precision\": 1.0, \"recall\": 0.2619760479041916, \"specificity\": 1.0, \"npv\": 0.47562488920404183, \"accuracy\": 0.5579136153041399, \"f1\": 0.4151838671411625, \"f2\": 0.3073410607657183, \"f0_5\": 0.6396198830409356, \"p4\": 0.5050734589961622, \"phi\": 0.3529905505230188}, {\"truth_threshold\": 21.06, \"match_probability\": 0.9999995425874326, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3149, \"tn\": 8049, \"fp\": 0, \"fn\": 8875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.26189288090485696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.738107119095143, \"precision\": 1.0, \"recall\": 0.26189288090485696, \"specificity\": 1.0, \"npv\": 0.47559678562987473, \"accuracy\": 0.5578637971404374, \"f1\": 0.41507941738614645, \"f2\": 0.3072494877549029, \"f0_5\": 0.6395207148659626, \"p4\": 0.5049882437618599, \"phi\": 0.3529240886333739}, {\"truth_threshold\": 21.080000000000002, \"match_probability\": 0.9999995488847637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3134, \"tn\": 8049, \"fp\": 0, \"fn\": 8890, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.260645375914837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7393546240851631, \"precision\": 1.0, \"recall\": 0.260645375914837, \"specificity\": 1.0, \"npv\": 0.4751756302024913, \"accuracy\": 0.5571165246849001, \"f1\": 0.4135110172846022, \"f2\": 0.30587546359554946, \"f0_5\": 0.6380293159609121, \"p4\": 0.503707568943464, \"phi\": 0.3519265985396641}, {\"truth_threshold\": 21.1, \"match_probability\": 0.9999995550953977, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3125, \"tn\": 8049, \"fp\": 0, \"fn\": 8899, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25989687292082503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.740103127079175, \"precision\": 1.0, \"recall\": 0.25989687292082503, \"specificity\": 1.0, \"npv\": 0.4749232947840453, \"accuracy\": 0.5566681612115777, \"f1\": 0.4125684863687372, \"f2\": 0.30505066281408016, \"f0_5\": 0.6371309737400098, \"p4\": 0.50293695184871, \"phi\": 0.3513275952606464}, {\"truth_threshold\": 21.12, \"match_probability\": 0.9999995612205282, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3119, \"tn\": 8049, \"fp\": 0, \"fn\": 8905, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25939787092481703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.740602129075183, \"precision\": 1.0, \"recall\": 0.25939787092481703, \"specificity\": 1.0, \"npv\": 0.474755220007078, \"accuracy\": 0.5563692522293628, \"f1\": 0.4119395100046226, \"f2\": 0.304500634579713, \"f0_5\": 0.6365306122448979, \"p4\": 0.5024222800734981, \"phi\": 0.350928045730573}, {\"truth_threshold\": 21.14, \"match_probability\": 0.9999995672613322, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3115, \"tn\": 8049, \"fp\": 0, \"fn\": 8909, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25906520292747837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7409347970725216, \"precision\": 1.0, \"recall\": 0.25906520292747837, \"specificity\": 1.0, \"npv\": 0.4746432362306876, \"accuracy\": 0.5561699795745528, \"f1\": 0.4115199154501618, \"f2\": 0.3041338774872586, \"f0_5\": 0.6361297173664434, \"p4\": 0.5020787520374906, \"phi\": 0.35066158374172973}, {\"truth_threshold\": 21.16, \"match_probability\": 0.9999995732189708, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3114, \"tn\": 8049, \"fp\": 0, \"fn\": 8910, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25898203592814373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7410179640718563, \"precision\": 1.0, \"recall\": 0.25898203592814373, \"specificity\": 1.0, \"npv\": 0.4746152485405979, \"accuracy\": 0.5561201614108504, \"f1\": 0.4114149821640904, \"f2\": 0.30404217926186294, \"f0_5\": 0.6360294117647058, \"p4\": 0.5019928182297242, \"phi\": 0.3505949562523482}, {\"truth_threshold\": 21.18, \"match_probability\": 0.9999995790945889, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3104, \"tn\": 8049, \"fp\": 0, \"fn\": 8920, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25815036593479707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7418496340652029, \"precision\": 1.0, \"recall\": 0.25815036593479707, \"specificity\": 1.0, \"npv\": 0.47433555306735814, \"accuracy\": 0.5556219797738255, \"f1\": 0.4103648863035431, \"f2\": 0.303125, \"f0_5\": 0.6350245499181669, \"p4\": 0.5011323373012041, \"phi\": 0.34992841639430033}, {\"truth_threshold\": 21.2, \"match_probability\": 0.9999995848893156, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3102, \"tn\": 8049, \"fp\": 0, \"fn\": 8922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25798403193612773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7420159680638723, \"precision\": 1.0, \"recall\": 0.25798403193612773, \"specificity\": 1.0, \"npv\": 0.47427965352660423, \"accuracy\": 0.5555223434464206, \"f1\": 0.4101547005156684, \"f2\": 0.30294152115317, \"f0_5\": 0.6348231827111984, \"p4\": 0.5009599911445162, \"phi\": 0.3497950503967474}, {\"truth_threshold\": 21.22, \"match_probability\": 0.9999995906042648, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3099, \"tn\": 8049, \"fp\": 0, \"fn\": 8925, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25773453093812376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7422654690618763, \"precision\": 1.0, \"recall\": 0.25773453093812376, \"specificity\": 1.0, \"npv\": 0.4741958289148109, \"accuracy\": 0.5553728889553131, \"f1\": 0.4098393175957151, \"f2\": 0.302666276003516, \"f0_5\": 0.6345208845208845, \"p4\": 0.500701315228007, \"phi\": 0.3495949649782925}, {\"truth_threshold\": 21.240000000000002, \"match_probability\": 0.9999995962405346, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3098, \"tn\": 8049, \"fp\": 0, \"fn\": 8926, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25765136393878907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7423486360612109, \"precision\": 1.0, \"recall\": 0.25765136393878907, \"specificity\": 1.0, \"npv\": 0.4741678939617084, \"accuracy\": 0.5553230707916106, \"f1\": 0.409734162147864, \"f2\": 0.3025745204516154, \"f0_5\": 0.6344200524246396, \"p4\": 0.5006150480926824, \"phi\": 0.3495282601095615}, {\"truth_threshold\": 21.26, \"match_probability\": 0.9999996017992082, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3090, \"tn\": 8049, \"fp\": 0, \"fn\": 8934, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2569860279441118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7430139720558883, \"precision\": 1.0, \"recall\": 0.2569860279441118, \"specificity\": 1.0, \"npv\": 0.4739445327680622, \"accuracy\": 0.5549245254819908, \"f1\": 0.40889241762604206, \"f2\": 0.30184034696987455, \"f0_5\": 0.6336122047244095, \"p4\": 0.49992415633762216, \"phi\": 0.348994445431288}, {\"truth_threshold\": 21.28, \"match_probability\": 0.9999996072813541, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3085, \"tn\": 8049, \"fp\": 0, \"fn\": 8939, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25657019294743844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7434298070525616, \"precision\": 1.0, \"recall\": 0.25657019294743844, \"specificity\": 1.0, \"npv\": 0.4738050388509536, \"accuracy\": 0.5546754346634784, \"f1\": 0.4083658746442518, \"f2\": 0.3013813719935132, \"f0_5\": 0.6331062222951896, \"p4\": 0.49949166585559235, \"phi\": 0.34866065197761814}, {\"truth_threshold\": 21.3, \"match_probability\": 0.9999996126880256, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3079, \"tn\": 8049, \"fp\": 0, \"fn\": 8945, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2560711909514305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7439288090485695, \"precision\": 1.0, \"recall\": 0.2560711909514305, \"specificity\": 1.0, \"npv\": 0.4736377545015888, \"accuracy\": 0.5543765256812634, \"f1\": 0.4077335628683043, \"f2\": 0.3008304836345872, \"f0_5\": 0.6324979457682827, \"p4\": 0.4989719810965888, \"phi\": 0.34825993722330895}, {\"truth_threshold\": 21.32, \"match_probability\": 0.9999996180202619, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3075, \"tn\": 8049, \"fp\": 0, \"fn\": 8949, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25573852295409183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7442614770459082, \"precision\": 1.0, \"recall\": 0.25573852295409183, \"specificity\": 1.0, \"npv\": 0.47352629721143663, \"accuracy\": 0.5541772530264535, \"f1\": 0.4073117424995033, \"f2\": 0.30046315295772996, \"f0_5\": 0.632091761223483, \"p4\": 0.4986251014447767, \"phi\": 0.3479926950796138}, {\"truth_threshold\": 21.34, \"match_probability\": 0.9999996232790879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3067, \"tn\": 8049, \"fp\": 0, \"fn\": 8957, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2550731869594145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7449268130405855, \"precision\": 1.0, \"recall\": 0.2550731869594145, \"specificity\": 1.0, \"npv\": 0.47330353992708457, \"accuracy\": 0.5537787077168336, \"f1\": 0.4064674309190908, \"f2\": 0.29972831929323923, \"f0_5\": 0.6312777869257369, \"p4\": 0.49793032306848073, \"phi\": 0.34745797203168893}, {\"truth_threshold\": 21.36, \"match_probability\": 0.999999628465514, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3062, \"tn\": 8049, \"fp\": 0, \"fn\": 8962, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2546573519627412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7453426480372588, \"precision\": 1.0, \"recall\": 0.2546573519627412, \"specificity\": 1.0, \"npv\": 0.4731644230203986, \"accuracy\": 0.5535296168983211, \"f1\": 0.4059392814530028, \"f2\": 0.29926893154540835, \"f0_5\": 0.6307679630850362, \"p4\": 0.497495394324292, \"phi\": 0.3471236076808274}, {\"truth_threshold\": 21.38, \"match_probability\": 0.9999996335805373, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3060, \"tn\": 8049, \"fp\": 0, \"fn\": 8964, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25449101796407186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7455089820359282, \"precision\": 1.0, \"recall\": 0.25449101796407186, \"specificity\": 1.0, \"npv\": 0.47310879915358844, \"accuracy\": 0.5534299805709162, \"f1\": 0.40572792362768495, \"f2\": 0.29908515130190005, \"f0_5\": 0.6305637982195845, \"p4\": 0.4973212732933646, \"phi\": 0.3469898268023954}, {\"truth_threshold\": 21.400000000000002, \"match_probability\": 0.9999996386251405, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3054, \"tn\": 8049, \"fp\": 0, \"fn\": 8970, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25399201596806387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7460079840319361, \"precision\": 1.0, \"recall\": 0.25399201596806387, \"specificity\": 1.0, \"npv\": 0.4729420059933016, \"accuracy\": 0.5531310715887012, \"f1\": 0.40509351372861124, \"f2\": 0.29853372434017594, \"f0_5\": 0.629950495049505, \"p4\": 0.4967983962287402, \"phi\": 0.3465883632469775}, {\"truth_threshold\": 21.42, \"match_probability\": 0.9999996436002931, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3045, \"tn\": 8049, \"fp\": 0, \"fn\": 8979, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2532435129740519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7467564870259481, \"precision\": 1.0, \"recall\": 0.2532435129740519, \"specificity\": 1.0, \"npv\": 0.472692036645525, \"accuracy\": 0.5526827081153789, \"f1\": 0.4041409516225363, \"f2\": 0.2977063412917229, \"f0_5\": 0.6290282597917699, \"p4\": 0.49601263033617543, \"phi\": 0.34598582617640855}, {\"truth_threshold\": 21.44, \"match_probability\": 0.9999996485069516, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3044, \"tn\": 8049, \"fp\": 0, \"fn\": 8980, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2531603459747172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7468396540252827, \"precision\": 1.0, \"recall\": 0.2531603459747172, \"specificity\": 1.0, \"npv\": 0.47266427858359267, \"accuracy\": 0.5526328899516764, \"f1\": 0.40403504114680117, \"f2\": 0.29761439186546734, \"f0_5\": 0.6289256198347107, \"p4\": 0.4959252152532679, \"phi\": 0.34591885218373464}, {\"truth_threshold\": 21.46, \"match_probability\": 0.9999996533460586, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3037, \"tn\": 8049, \"fp\": 0, \"fn\": 8987, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25257817697937457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7474218230206254, \"precision\": 1.0, \"recall\": 0.25257817697937457, \"specificity\": 1.0, \"npv\": 0.4724700633951632, \"accuracy\": 0.552284162805759, \"f1\": 0.40329327401898946, \"f2\": 0.2969706451802163, \"f0_5\": 0.628206188978984, \"p4\": 0.49531270422370627, \"phi\": 0.34544989114150815}, {\"truth_threshold\": 21.48, \"match_probability\": 0.9999996581185442, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3027, \"tn\": 8049, \"fp\": 0, \"fn\": 8997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25174650698602796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.748253493013972, \"precision\": 1.0, \"recall\": 0.25174650698602796, \"specificity\": 1.0, \"npv\": 0.4721928898275255, \"accuracy\": 0.5517859811687341, \"f1\": 0.40223240980665736, \"f2\": 0.29605070124992666, \"f0_5\": 0.6271755345599205, \"p4\": 0.49443584408601365, \"phi\": 0.34477951017674746}, {\"truth_threshold\": 21.5, \"match_probability\": 0.9999996628253256, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3017, \"tn\": 8049, \"fp\": 0, \"fn\": 9007, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2509148369926813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7490851630073186, \"precision\": 1.0, \"recall\": 0.2509148369926813, \"specificity\": 1.0, \"npv\": 0.4719160412757974, \"accuracy\": 0.5512877995317093, \"f1\": 0.40117013496443055, \"f2\": 0.29513039735488034, \"f0_5\": 0.6261414577453096, \"p4\": 0.4935568027189143, \"phi\": 0.34410861159080014}, {\"truth_threshold\": 21.52, \"match_probability\": 0.9999996674673074, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3009, \"tn\": 8049, \"fp\": 0, \"fn\": 9015, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25024950099800397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.749750499001996, \"precision\": 1.0, \"recall\": 0.25024950099800397, \"specificity\": 1.0, \"npv\": 0.4716947960618847, \"accuracy\": 0.5508892542220893, \"f1\": 0.40031929754540013, \"f2\": 0.29439389492221896, \"f0_5\": 0.6253117206982544, \"p4\": 0.4928519905977054, \"phi\": 0.343571517064267}, {\"truth_threshold\": 21.54, \"match_probability\": 0.9999996720453818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3007, \"tn\": 8049, \"fp\": 0, \"fn\": 9017, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.25008316699933464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7499168330006654, \"precision\": 1.0, \"recall\": 0.25008316699933464, \"specificity\": 1.0, \"npv\": 0.4716395171686394, \"accuracy\": 0.5507896178946844, \"f1\": 0.4001064466768678, \"f2\": 0.29420973328376027, \"f0_5\": 0.6251039414601697, \"p4\": 0.49267556740600066, \"phi\": 0.34343719096156494}, {\"truth_threshold\": 21.56, \"match_probability\": 0.9999996765604284, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2998, \"tn\": 8049, \"fp\": 0, \"fn\": 9026, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2493346640053227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7506653359946773, \"precision\": 1.0, \"recall\": 0.2493346640053227, \"specificity\": 1.0, \"npv\": 0.4713909224011713, \"accuracy\": 0.5503412544213621, \"f1\": 0.3991479163892957, \"f2\": 0.29338082749442207, \"f0_5\": 0.6241672218520986, \"p4\": 0.49188056921683687, \"phi\": 0.34283246236617554}, {\"truth_threshold\": 21.580000000000002, \"match_probability\": 0.9999996810133152, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2993, \"tn\": 8049, \"fp\": 0, \"fn\": 9031, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24891882900864937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7510811709913506, \"precision\": 1.0, \"recall\": 0.24891882900864937, \"specificity\": 1.0, \"npv\": 0.47125292740046837, \"accuracy\": 0.5500921636028496, \"f1\": 0.3986149031098089, \"f2\": 0.2929201980856936, \"f0_5\": 0.6236456076012669, \"p4\": 0.49143812773503537, \"phi\": 0.34249631655745244}, {\"truth_threshold\": 21.6, \"match_probability\": 0.9999996854048978, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2989, \"tn\": 8049, \"fp\": 0, \"fn\": 9035, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2485861610113107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7514138389886893, \"precision\": 1.0, \"recall\": 0.2485861610113107, \"specificity\": 1.0, \"npv\": 0.4711425895574807, \"accuracy\": 0.5498928909480396, \"f1\": 0.3981882368613868, \"f2\": 0.2925516296368797, \"f0_5\": 0.6232276897414513, \"p4\": 0.49108377415735344, \"phi\": 0.34222730403493784}, {\"truth_threshold\": 21.62, \"match_probability\": 0.9999996897360202, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2988, \"tn\": 8049, \"fp\": 0, \"fn\": 9036, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24850299401197604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7514970059880239, \"precision\": 1.0, \"recall\": 0.24850299401197604, \"specificity\": 1.0, \"npv\": 0.4711150131694469, \"accuracy\": 0.5498430727843372, \"f1\": 0.3980815347721823, \"f2\": 0.29245947850599013, \"f0_5\": 0.6231231231231231, \"p4\": 0.4909951300446206, \"phi\": 0.34216003755055774}, {\"truth_threshold\": 21.64, \"match_probability\": 0.9999996940075148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2981, \"tn\": 8049, \"fp\": 0, \"fn\": 9043, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2479208250166334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7520791749833666, \"precision\": 1.0, \"recall\": 0.2479208250166334, \"specificity\": 1.0, \"npv\": 0.4709220688041189, \"accuracy\": 0.5494943456384198, \"f1\": 0.39733422192602463, \"f2\": 0.29181431955674764, \"f0_5\": 0.6223901787205612, \"p4\": 0.49037399575065604, \"phi\": 0.341689022089468}, {\"truth_threshold\": 21.66, \"match_probability\": 0.9999996982202024, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2975, \"tn\": 8049, \"fp\": 0, \"fn\": 9049, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2474218230206254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7525781769793746, \"precision\": 1.0, \"recall\": 0.2474218230206254, \"specificity\": 1.0, \"npv\": 0.4707568136624167, \"accuracy\": 0.5491954366562048, \"f1\": 0.3966931128741916, \"f2\": 0.2912611854085489, \"f0_5\": 0.6217605751546564, \"p4\": 0.48984072130859274, \"phi\": 0.3412850846956778}, {\"truth_threshold\": 21.68, \"match_probability\": 0.9999997023748929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2965, \"tn\": 8049, \"fp\": 0, \"fn\": 9059, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24659015302727877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7534098469727212, \"precision\": 1.0, \"recall\": 0.24659015302727877, \"specificity\": 1.0, \"npv\": 0.4704816460135609, \"accuracy\": 0.54869725501918, \"f1\": 0.3956234572019481, \"f2\": 0.29033900628659837, \"f0_5\": 0.6207084240495729, \"p4\": 0.48895013047887664, \"phi\": 0.3406114224259222}, {\"truth_threshold\": 21.7, \"match_probability\": 0.9999997064723845, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2958, \"tn\": 8049, \"fp\": 0, \"fn\": 9066, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24600798403193613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7539920159680639, \"precision\": 1.0, \"recall\": 0.24600798403193613, \"specificity\": 1.0, \"npv\": 0.47028921998247153, \"accuracy\": 0.5483485278732626, \"f1\": 0.394873848618342, \"f2\": 0.2896932659536961, \"f0_5\": 0.6199698189134809, \"p4\": 0.48832537205570786, \"phi\": 0.3401395344852456}, {\"truth_threshold\": 21.72, \"match_probability\": 0.9999997105134647, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2946, \"tn\": 8049, \"fp\": 0, \"fn\": 9078, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24500998003992017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7549900199600799, \"precision\": 1.0, \"recall\": 0.24500998003992017, \"specificity\": 1.0, \"npv\": 0.4699597127342792, \"accuracy\": 0.5477507099088328, \"f1\": 0.3935871743486974, \"f2\": 0.2885858704596215, \"f0_5\": 0.6186995967741935, \"p4\": 0.48725176629981237, \"phi\": 0.3393299571753021}, {\"truth_threshold\": 21.740000000000002, \"match_probability\": 0.9999997144989102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2943, \"tn\": 8049, \"fp\": 0, \"fn\": 9081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24476047904191617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7552395209580839, \"precision\": 1.0, \"recall\": 0.24476047904191617, \"specificity\": 1.0, \"npv\": 0.46987740805604206, \"accuracy\": 0.5476012554177253, \"f1\": 0.39326518340348765, \"f2\": 0.28830894022218306, \"f0_5\": 0.6183812405446294, \"p4\": 0.48698285121157203, \"phi\": 0.3391274384162549}, {\"truth_threshold\": 21.76, \"match_probability\": 0.999999718429487, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2942, \"tn\": 8049, \"fp\": 0, \"fn\": 9082, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2446773120425815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7553226879574185, \"precision\": 1.0, \"recall\": 0.2446773120425815, \"specificity\": 1.0, \"npv\": 0.46984997956920205, \"accuracy\": 0.5475514372540228, \"f1\": 0.39315782440197783, \"f2\": 0.28821662290842115, \"f0_5\": 0.6182750504371217, \"p4\": 0.4868931670479524, \"phi\": 0.3390599210526868}, {\"truth_threshold\": 21.78, \"match_probability\": 0.9999997223059504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2936, \"tn\": 8049, \"fp\": 0, \"fn\": 9088, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24417831004657353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7558216899534265, \"precision\": 1.0, \"recall\": 0.24417831004657353, \"specificity\": 1.0, \"npv\": 0.4696854758709226, \"accuracy\": 0.5472525282718079, \"f1\": 0.3925133689839572, \"f2\": 0.2876626430474996, \"f0_5\": 0.6176371592056547, \"p4\": 0.4863545802138161, \"phi\": 0.3386546998811364}, {\"truth_threshold\": 21.8, \"match_probability\": 0.9999997261290454, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2926, \"tn\": 8049, \"fp\": 0, \"fn\": 9098, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24334664005322687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7566533599467731, \"precision\": 1.0, \"recall\": 0.24334664005322687, \"specificity\": 1.0, \"npv\": 0.4694115588732723, \"accuracy\": 0.5467543466347831, \"f1\": 0.391438127090301, \"f2\": 0.28673905374152325, \"f0_5\": 0.6165711395819286, \"p4\": 0.4854550937310142, \"phi\": 0.33797888344386}, {\"truth_threshold\": 21.82, \"match_probability\": 0.9999997298995067, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2915, \"tn\": 8049, \"fp\": 0, \"fn\": 9109, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24243180306054557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7575681969394544, \"precision\": 1.0, \"recall\": 0.24243180306054557, \"specificity\": 1.0, \"npv\": 0.46911061895325795, \"accuracy\": 0.5462063468340557, \"f1\": 0.3902536983733851, \"f2\": 0.2857226872635314, \"f0_5\": 0.6153943590609694, \"p4\": 0.4844629854296263, \"phi\": 0.3372348338883261}, {\"truth_threshold\": 21.84, \"match_probability\": 0.999999733618059, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2912, \"tn\": 8049, \"fp\": 0, \"fn\": 9112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24218230206254157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7578176979374585, \"precision\": 1.0, \"recall\": 0.24218230206254157, \"specificity\": 1.0, \"npv\": 0.4690286113862828, \"accuracy\": 0.5460568923429482, \"f1\": 0.3899303695768613, \"f2\": 0.28544542032622333, \"f0_5\": 0.6150726596823252, \"p4\": 0.48419192211113876, \"phi\": 0.33703179202966477}, {\"truth_threshold\": 21.86, \"match_probability\": 0.999999737285417, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2909, \"tn\": 8049, \"fp\": 0, \"fn\": 9115, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2419328010645376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7580671989354624, \"precision\": 1.0, \"recall\": 0.2419328010645376, \"specificity\": 1.0, \"npv\": 0.46894663248659985, \"accuracy\": 0.5459074378518408, \"f1\": 0.38960691086854615, \"f2\": 0.2851681207724733, \"f0_5\": 0.6147506339814032, \"p4\": 0.4839206488090488, \"phi\": 0.3368286988177602}, {\"truth_threshold\": 21.88, \"match_probability\": 0.9999997409022854, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2904, \"tn\": 8049, \"fp\": 0, \"fn\": 9120, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24151696606786427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7584830339321357, \"precision\": 1.0, \"recall\": 0.24151696606786427, \"specificity\": 1.0, \"npv\": 0.4688100646514066, \"accuracy\": 0.5456583470333284, \"f1\": 0.3890675241157556, \"f2\": 0.2847058823529412, \"f0_5\": 0.6142131979695431, \"p4\": 0.4834680589973313, \"phi\": 0.3364900956591249}, {\"truth_threshold\": 21.900000000000002, \"match_probability\": 0.9999997444693592, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2902, \"tn\": 8049, \"fp\": 0, \"fn\": 9122, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24135063206919494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7586493679308051, \"precision\": 1.0, \"recall\": 0.24135063206919494, \"specificity\": 1.0, \"npv\": 0.4687554597868499, \"accuracy\": 0.5455587107059234, \"f1\": 0.38885166822993433, \"f2\": 0.2845209616063375, \"f0_5\": 0.6139979688557887, \"p4\": 0.4832868590755389, \"phi\": 0.336354614217558}, {\"truth_threshold\": 21.92, \"match_probability\": 0.9999997479873242, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2896, \"tn\": 8049, \"fp\": 0, \"fn\": 9128, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24085163007318697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.759148369926813, \"precision\": 1.0, \"recall\": 0.24085163007318697, \"specificity\": 1.0, \"npv\": 0.46859172148803635, \"accuracy\": 0.5452598017237085, \"f1\": 0.38820375335120644, \"f2\": 0.2839661123313461, \"f0_5\": 0.6133514063029482, \"p4\": 0.4827426955924686, \"phi\": 0.3359480316346479}, {\"truth_threshold\": 21.94, \"match_probability\": 0.9999997514568563, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2894, \"tn\": 8049, \"fp\": 0, \"fn\": 9130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24068529607451764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7593147039254824, \"precision\": 1.0, \"recall\": 0.24068529607451764, \"specificity\": 1.0, \"npv\": 0.4685371674719134, \"accuracy\": 0.5451601653963035, \"f1\": 0.38798766590695805, \"f2\": 0.28378113355559914, \"f0_5\": 0.613135593220339, \"p4\": 0.4825611194881437, \"phi\": 0.3358124578911469}, {\"truth_threshold\": 21.96, \"match_probability\": 0.9999997548786224, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2892, \"tn\": 8049, \"fp\": 0, \"fn\": 9132, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2405189620758483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7594810379241517, \"precision\": 1.0, \"recall\": 0.2405189620758483, \"specificity\": 1.0, \"npv\": 0.46848262615680114, \"accuracy\": 0.5450605290688986, \"f1\": 0.38777152051488334, \"f2\": 0.28359614026829844, \"f0_5\": 0.6129196337741607, \"p4\": 0.4823794490597244, \"phi\": 0.3356768609746604}, {\"truth_threshold\": 21.98, \"match_probability\": 0.99999975825328, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2888, \"tn\": 8049, \"fp\": 0, \"fn\": 9136, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24018629407850964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7598137059214903, \"precision\": 1.0, \"recall\": 0.24018629407850964, \"specificity\": 1.0, \"npv\": 0.4683735816118708, \"accuracy\": 0.5448612564140886, \"f1\": 0.3873390557939914, \"f2\": 0.2832261101522046, \"f0_5\": 0.6124872751951137, \"p4\": 0.4820158247835901, \"phi\": 0.33540559746616283}, {\"truth_threshold\": 22.0, \"match_probability\": 0.9999997615814777, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2886, \"tn\": 8049, \"fp\": 0, \"fn\": 9138, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.24001996007984033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7599800399201597, \"precision\": 1.0, \"recall\": 0.24001996007984033, \"specificity\": 1.0, \"npv\": 0.46831907837318903, \"accuracy\": 0.5447616200866836, \"f1\": 0.3871227364185111, \"f2\": 0.2830410733199953, \"f0_5\": 0.6122708757637475, \"p4\": 0.481833870711958, \"phi\": 0.33526993079571044}, {\"truth_threshold\": 22.02, \"match_probability\": 0.9999997648638552, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2883, \"tn\": 8049, \"fp\": 0, \"fn\": 9141, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23977045908183633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7602295409181636, \"precision\": 1.0, \"recall\": 0.23977045908183633, \"specificity\": 1.0, \"npv\": 0.46823734729493893, \"accuracy\": 0.5446121655955761, \"f1\": 0.38679814852082917, \"f2\": 0.2827634908491732, \"f0_5\": 0.6119460010188487, \"p4\": 0.48156076187203267, \"phi\": 0.33506638703422453}, {\"truth_threshold\": 22.04, \"match_probability\": 0.9999997681010433, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2877, \"tn\": 8049, \"fp\": 0, \"fn\": 9147, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23927145708582834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7607285429141717, \"precision\": 1.0, \"recall\": 0.23927145708582834, \"specificity\": 1.0, \"npv\": 0.4680739706908583, \"accuracy\": 0.5443132566133613, \"f1\": 0.38614858063217233, \"f2\": 0.28220822788535105, \"f0_5\": 0.6112952575216726, \"p4\": 0.48101390296313695, \"phi\": 0.33465914150244125}, {\"truth_threshold\": 22.06, \"match_probability\": 0.999999771293664, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2874, \"tn\": 8049, \"fp\": 0, \"fn\": 9150, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23902195608782434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7609780439121756, \"precision\": 1.0, \"recall\": 0.23902195608782434, \"specificity\": 1.0, \"npv\": 0.4679923251351823, \"accuracy\": 0.5441638021222538, \"f1\": 0.38582360048328634, \"f2\": 0.28193054738081225, \"f0_5\": 0.610969387755102, \"p4\": 0.4807401521328648, \"phi\": 0.33445543946526024}, {\"truth_threshold\": 22.080000000000002, \"match_probability\": 0.999999774442331, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2871, \"tn\": 8049, \"fp\": 0, \"fn\": 9153, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23877245508982037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7612275449101796, \"precision\": 1.0, \"recall\": 0.23877245508982037, \"specificity\": 1.0, \"npv\": 0.46791070805720264, \"accuracy\": 0.5440143476311463, \"f1\": 0.38549848942598186, \"f2\": 0.2816528341868268, \"f0_5\": 0.6106431852986217, \"p4\": 0.48046618654310475, \"phi\": 0.33425168440209013}, {\"truth_threshold\": 22.1, \"match_probability\": 0.9999997775476493, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2867, \"tn\": 8049, \"fp\": 0, \"fn\": 9157, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2384397870924817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7615602129075183, \"precision\": 1.0, \"recall\": 0.2384397870924817, \"specificity\": 1.0, \"npv\": 0.467801929559456, \"accuracy\": 0.5438150749763364, \"f1\": 0.38506480424417433, \"f2\": 0.2812824990679513, \"f0_5\": 0.6102077302911629, \"p4\": 0.48010056435809345, \"phi\": 0.33397992826756645}, {\"truth_threshold\": 22.12, \"match_probability\": 0.999999780610216, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2862, \"tn\": 8049, \"fp\": 0, \"fn\": 9162, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23802395209580837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7619760479041916, \"precision\": 1.0, \"recall\": 0.23802395209580837, \"specificity\": 1.0, \"npv\": 0.4676660275405264, \"accuracy\": 0.543565984157824, \"f1\": 0.3845223700120919, \"f2\": 0.28081949841045567, \"f0_5\": 0.6096625766871165, \"p4\": 0.4796429973850503, \"phi\": 0.3336400997124645}, {\"truth_threshold\": 22.14, \"match_probability\": 0.9999997836306193, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2860, \"tn\": 8049, \"fp\": 0, \"fn\": 9164, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23785761809713907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.762142381902861, \"precision\": 1.0, \"recall\": 0.23785761809713907, \"specificity\": 1.0, \"npv\": 0.46761168883983034, \"accuracy\": 0.5434663478304189, \"f1\": 0.38430529427573235, \"f2\": 0.2806342727058639, \"f0_5\": 0.6094442550289806, \"p4\": 0.4794598024658455, \"phi\": 0.3335041266638579}, {\"truth_threshold\": 22.16, \"match_probability\": 0.9999997866094399, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2852, \"tn\": 8049, \"fp\": 0, \"fn\": 9172, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23719228210246174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7628077178975382, \"precision\": 1.0, \"recall\": 0.23719228210246174, \"specificity\": 1.0, \"npv\": 0.46739446025201786, \"accuracy\": 0.5430678025207991, \"f1\": 0.3834364076364614, \"f2\": 0.27989322446415954, \"f0_5\": 0.6085694776374189, \"p4\": 0.4787260591852129, \"phi\": 0.33295999559890743}, {\"truth_threshold\": 22.18, \"match_probability\": 0.9999997895472501, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2848, \"tn\": 8049, \"fp\": 0, \"fn\": 9176, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2368596141051231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7631403858948769, \"precision\": 1.0, \"recall\": 0.2368596141051231, \"specificity\": 1.0, \"npv\": 0.4672859216255443, \"accuracy\": 0.5428685298659891, \"f1\": 0.3830016137708445, \"f2\": 0.2795226130653266, \"f0_5\": 0.6081311923471131, \"p4\": 0.47835860777479394, \"phi\": 0.33268778617944966}, {\"truth_threshold\": 22.2, \"match_probability\": 0.9999997924446148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2842, \"tn\": 8049, \"fp\": 0, \"fn\": 9182, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2363606121091151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7636393878908849, \"precision\": 1.0, \"recall\": 0.2363606121091151, \"specificity\": 1.0, \"npv\": 0.46712320817131914, \"accuracy\": 0.5425696208837743, \"f1\": 0.38234898425938385, \"f2\": 0.2789665868310495, \"f0_5\": 0.6074726402188783, \"p4\": 0.47780670335296527, \"phi\": 0.33227929128031225}, {\"truth_threshold\": 22.22, \"match_probability\": 0.9999997953020905, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2835, \"tn\": 8049, \"fp\": 0, \"fn\": 9189, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23577844311377247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7642215568862275, \"precision\": 1.0, \"recall\": 0.23577844311377247, \"specificity\": 1.0, \"npv\": 0.4669335189697181, \"accuracy\": 0.5422208937378569, \"f1\": 0.38158691701998787, \"f2\": 0.27831772397950166, \"f0_5\": 0.6067026194144838, \"p4\": 0.47716170804746183, \"phi\": 0.3318024384182781}, {\"truth_threshold\": 22.240000000000002, \"match_probability\": 0.9999997981202265, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2833, \"tn\": 8049, \"fp\": 0, \"fn\": 9191, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23561210911510314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7643878908848969, \"precision\": 1.0, \"recall\": 0.23561210911510314, \"specificity\": 1.0, \"npv\": 0.46687935034802786, \"accuracy\": 0.5421212574104518, \"f1\": 0.3813690516254964, \"f2\": 0.27813230183196214, \"f0_5\": 0.6064822743620483, \"p4\": 0.47697720409064104, \"phi\": 0.3316661400230479}, {\"truth_threshold\": 22.26, \"match_probability\": 0.9999998008995644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2828, \"tn\": 8049, \"fp\": 0, \"fn\": 9196, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2351962741184298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7648037258815702, \"precision\": 1.0, \"recall\": 0.2351962741184298, \"specificity\": 1.0, \"npv\": 0.4667439837634097, \"accuracy\": 0.5418721665919394, \"f1\": 0.3808241314301104, \"f2\": 0.277668682742911, \"f0_5\": 0.6059307507713404, \"p4\": 0.4765155160392888, \"phi\": 0.33132528721536914}, {\"truth_threshold\": 22.28, \"match_probability\": 0.9999998036406385, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2827, \"tn\": 8049, \"fp\": 0, \"fn\": 9197, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23511310711909514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7648868928809048, \"precision\": 1.0, \"recall\": 0.23511310711909514, \"specificity\": 1.0, \"npv\": 0.46671691986547603, \"accuracy\": 0.541822348428237, \"f1\": 0.3807151033600431, \"f2\": 0.27757594799992147, \"f0_5\": 0.6058203325904338, \"p4\": 0.4764231049133097, \"phi\": 0.33125709830073957}, {\"truth_threshold\": 22.3, \"match_probability\": 0.9999998063439753, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2824, \"tn\": 8049, \"fp\": 0, \"fn\": 9200, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23486360612109114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7651363938789089, \"precision\": 1.0, \"recall\": 0.23486360612109114, \"specificity\": 1.0, \"npv\": 0.4666357469998261, \"accuracy\": 0.5416728939371295, \"f1\": 0.38038793103448276, \"f2\": 0.27729772191673213, \"f0_5\": 0.6054888507718696, \"p4\": 0.4761457242402302, \"phi\": 0.33105249475783793}, {\"truth_threshold\": 22.32, \"match_probability\": 0.9999998090100946, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2821, \"tn\": 8049, \"fp\": 0, \"fn\": 9203, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23461410512308717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7653858948769129, \"precision\": 1.0, \"recall\": 0.23461410512308717, \"specificity\": 1.0, \"npv\": 0.46655460236494317, \"accuracy\": 0.541523439446022, \"f1\": 0.38006062647356015, \"f2\": 0.2770194630477051, \"f0_5\": 0.6051570276299982, \"p4\": 0.4758681223160712, \"phi\": 0.33084783590785194}, {\"truth_threshold\": 22.34, \"match_probability\": 0.9999998116395085, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2819, \"tn\": 8049, \"fp\": 0, \"fn\": 9205, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23444777112441784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7655522288755822, \"precision\": 1.0, \"recall\": 0.23444777112441784, \"specificity\": 1.0, \"npv\": 0.4665005216181755, \"accuracy\": 0.541423803118617, \"f1\": 0.3798423499292596, \"f2\": 0.27683393891780417, \"f0_5\": 0.6049356223175966, \"p4\": 0.47568293125324895, \"phi\": 0.330711365879311}, {\"truth_threshold\": 22.36, \"match_probability\": 0.9999998142327226, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2812, \"tn\": 8049, \"fp\": 0, \"fn\": 9212, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23386560212907517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7661343978709249, \"precision\": 1.0, \"recall\": 0.23386560212907517, \"specificity\": 1.0, \"npv\": 0.4663113376977, \"accuracy\": 0.5410750759726997, \"f1\": 0.3790779185764357, \"f2\": 0.27618448966763576, \"f0_5\": 0.6041595049845307, \"p4\": 0.4750339850605722, \"phi\": 0.33023352611491025}, {\"truth_threshold\": 22.38, \"match_probability\": 0.9999998167902351, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2803, \"tn\": 8049, \"fp\": 0, \"fn\": 9221, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2331170991350632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7668829008649368, \"precision\": 1.0, \"recall\": 0.2331170991350632, \"specificity\": 1.0, \"npv\": 0.4660683265778807, \"accuracy\": 0.5406267124993773, \"f1\": 0.378094017670466, \"f2\": 0.2753492210063066, \"f0_5\": 0.6031588913754519, \"p4\": 0.4741978421923447, \"phi\": 0.32961871350178046}, {\"truth_threshold\": 22.400000000000002, \"match_probability\": 0.9999998193125376, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2799, \"tn\": 8049, \"fp\": 0, \"fn\": 9225, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23278443113772454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7672155688622755, \"precision\": 1.0, \"recall\": 0.23278443113772454, \"specificity\": 1.0, \"npv\": 0.46596040291767976, \"accuracy\": 0.5404274398445673, \"f1\": 0.37765634486945965, \"f2\": 0.2749778956675508, \"f0_5\": 0.6027131782945736, \"p4\": 0.47382557652896373, \"phi\": 0.32934530105331244}, {\"truth_threshold\": 22.42, \"match_probability\": 0.9999998218001148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2793, \"tn\": 8049, \"fp\": 0, \"fn\": 9231, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23228542914171657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7677145708582834, \"precision\": 1.0, \"recall\": 0.23228542914171657, \"specificity\": 1.0, \"npv\": 0.4657986111111111, \"accuracy\": 0.5401285308623525, \"f1\": 0.37699939258959303, \"f2\": 0.2744207982078642, \"f0_5\": 0.6020434557682359, \"p4\": 0.47326642910566, \"phi\": 0.3289349939966254}, {\"truth_threshold\": 22.44, \"match_probability\": 0.9999998242534449, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2787, \"tn\": 8049, \"fp\": 0, \"fn\": 9237, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23178642714570857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7682135728542914, \"precision\": 1.0, \"recall\": 0.23178642714570857, \"specificity\": 1.0, \"npv\": 0.4656369316209649, \"accuracy\": 0.5398296218801375, \"f1\": 0.3763419080413206, \"f2\": 0.2738635693650139, \"f0_5\": 0.6013723459347489, \"p4\": 0.4727063800863443, \"phi\": 0.32852445986184053}, {\"truth_threshold\": 22.46, \"match_probability\": 0.9999998266729992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2779, \"tn\": 8049, \"fp\": 0, \"fn\": 9245, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23112109115103127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7688789088489687, \"precision\": 1.0, \"recall\": 0.23112109115103127, \"specificity\": 1.0, \"npv\": 0.46542153347981957, \"accuracy\": 0.5394310765705176, \"f1\": 0.37546443288522596, \"f2\": 0.2731203931203931, \"f0_5\": 0.6004753673293, \"p4\": 0.4719582399485036, \"phi\": 0.3279767257947462}, {\"truth_threshold\": 22.48, \"match_probability\": 0.9999998290592429, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2770, \"tn\": 8049, \"fp\": 0, \"fn\": 9254, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2303725881570193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7696274118429807, \"precision\": 1.0, \"recall\": 0.2303725881570193, \"specificity\": 1.0, \"npv\": 0.465179448650523, \"accuracy\": 0.5389827130971953, \"f1\": 0.3744761389752602, \"f2\": 0.2722840404199269, \"f0_5\": 0.599463296398892, \"p4\": 0.4711146498198175, \"phi\": 0.3273600365699458}, {\"truth_threshold\": 22.5, \"match_probability\": 0.9999998314126344, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2766, \"tn\": 8049, \"fp\": 0, \"fn\": 9258, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.23003992015968064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7699600798403193, \"precision\": 1.0, \"recall\": 0.23003992015968064, \"specificity\": 1.0, \"npv\": 0.46507193621078174, \"accuracy\": 0.5387834404423852, \"f1\": 0.37403651115618664, \"f2\": 0.271912233101333, \"f0_5\": 0.599012474012474, \"p4\": 0.4707390613119908, \"phi\": 0.3270857854973773}, {\"truth_threshold\": 22.52, \"match_probability\": 0.9999998337336261, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2762, \"tn\": 8049, \"fp\": 0, \"fn\": 9262, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22970725216234197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.770292747837658, \"precision\": 1.0, \"recall\": 0.22970725216234197, \"specificity\": 1.0, \"npv\": 0.4649644734561839, \"accuracy\": 0.5385841677875753, \"f1\": 0.37359664547544974, \"f2\": 0.2715403672971804, \"f0_5\": 0.5985610263522885, \"p4\": 0.4703630655319236, \"phi\": 0.3268114311812398}, {\"truth_threshold\": 22.54, \"match_probability\": 0.999999836022664, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2761, \"tn\": 8049, \"fp\": 0, \"fn\": 9263, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2296240851630073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7703759148369926, \"precision\": 1.0, \"recall\": 0.2296240851630073, \"specificity\": 1.0, \"npv\": 0.46493761552680224, \"accuracy\": 0.5385343496238728, \"f1\": 0.37348664186675684, \"f2\": 0.2714473917061565, \"f0_5\": 0.5984480665857465, \"p4\": 0.47026900283540607, \"phi\": 0.32674282642961266}, {\"truth_threshold\": 22.56, \"match_probability\": 0.9999998382801881, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2757, \"tn\": 8049, \"fp\": 0, \"fn\": 9267, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22929141716566867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7707085828343313, \"precision\": 1.0, \"recall\": 0.22929141716566867, \"specificity\": 1.0, \"npv\": 0.4648302148302148, \"accuracy\": 0.5383350769690629, \"f1\": 0.37304647858737566, \"f2\": 0.27107545277564743, \"f0_5\": 0.5979958355023425, \"p4\": 0.46989249658135107, \"phi\": 0.32646834256914126}, {\"truth_threshold\": 22.580000000000002, \"match_probability\": 0.9999998405066322, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2752, \"tn\": 8049, \"fp\": 0, \"fn\": 9272, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22887558216899534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7711244178310046, \"precision\": 1.0, \"recall\": 0.22887558216899534, \"specificity\": 1.0, \"npv\": 0.46469603371629814, \"accuracy\": 0.5380859861505505, \"f1\": 0.3724959393611261, \"f2\": 0.27061044682190055, \"f0_5\": 0.5974296630774575, \"p4\": 0.46942128780280806, \"phi\": 0.32612509141193174}, {\"truth_threshold\": 22.6, \"match_probability\": 0.9999998427024241, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2742, \"tn\": 8049, \"fp\": 0, \"fn\": 9282, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2280439121756487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7719560878243513, \"precision\": 1.0, \"recall\": 0.2280439121756487, \"specificity\": 1.0, \"npv\": 0.4644279037562749, \"accuracy\": 0.5375878045135256, \"f1\": 0.37139374238114586, \"f2\": 0.2696801605098548, \"f0_5\": 0.596294363256785, \"p4\": 0.46847694301401566, \"phi\": 0.3254380987163558}, {\"truth_threshold\": 22.62, \"match_probability\": 0.999999844867986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2740, \"tn\": 8049, \"fp\": 0, \"fn\": 9284, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22787757817697937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7721224218230206, \"precision\": 1.0, \"recall\": 0.22787757817697937, \"specificity\": 1.0, \"npv\": 0.464374314890671, \"accuracy\": 0.5374881681861207, \"f1\": 0.37117312381468437, \"f2\": 0.2694940593280353, \"f0_5\": 0.5960668290985033, \"p4\": 0.4682877646410979, \"phi\": 0.32530062134106064}, {\"truth_threshold\": 22.64, \"match_probability\": 0.999999847003734, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2734, \"tn\": 8049, \"fp\": 0, \"fn\": 9290, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2273785761809714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7726214238190287, \"precision\": 1.0, \"recall\": 0.2273785761809714, \"specificity\": 1.0, \"npv\": 0.46421362246957726, \"accuracy\": 0.5371892592039057, \"f1\": 0.37051090933730857, \"f2\": 0.26893566791265, \"f0_5\": 0.5953832752613241, \"p4\": 0.4677196084416102, \"phi\": 0.3248880307443527}, {\"truth_threshold\": 22.66, \"match_probability\": 0.9999998491100784, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2727, \"tn\": 8049, \"fp\": 0, \"fn\": 9297, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22679640718562874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7732035928143712, \"precision\": 1.0, \"recall\": 0.22679640718562874, \"specificity\": 1.0, \"npv\": 0.4640262884814943, \"accuracy\": 0.5368405320579883, \"f1\": 0.36973764490543015, \"f2\": 0.26828404462546485, \"f0_5\": 0.5945839874411303, \"p4\": 0.4670555785044436, \"phi\": 0.3244063733456619}, {\"truth_threshold\": 22.68, \"match_probability\": 0.9999998511874243, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2722, \"tn\": 8049, \"fp\": 0, \"fn\": 9302, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2263805721889554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7736194278110445, \"precision\": 1.0, \"recall\": 0.2263805721889554, \"specificity\": 1.0, \"npv\": 0.46389257103336984, \"accuracy\": 0.5365914412394759, \"f1\": 0.36918486369184866, \"f2\": 0.2678184895115904, \"f0_5\": 0.5940118715083799, \"p4\": 0.46658048986315526, \"phi\": 0.3240621324140479}, {\"truth_threshold\": 22.7, \"match_probability\": 0.9999998532361707, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2711, \"tn\": 8049, \"fp\": 0, \"fn\": 9313, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2254657351962741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7745342648037259, \"precision\": 1.0, \"recall\": 0.2254657351962741, \"specificity\": 1.0, \"npv\": 0.4635986637484161, \"accuracy\": 0.5360434414387486, \"f1\": 0.367967424499491, \"f2\": 0.26679394571614146, \"f0_5\": 0.5927496938953997, \"p4\": 0.4655329916327396, \"phi\": 0.3233042120945023}, {\"truth_threshold\": 22.72, \"match_probability\": 0.9999998552567114, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2708, \"tn\": 8049, \"fp\": 0, \"fn\": 9316, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22521623419827014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7747837658017299, \"precision\": 1.0, \"recall\": 0.22521623419827014, \"specificity\": 1.0, \"npv\": 0.46351857183990786, \"accuracy\": 0.5358939869476411, \"f1\": 0.3676350800977464, \"f2\": 0.26651444768128496, \"f0_5\": 0.5924046202310116, \"p4\": 0.4652467585469249, \"phi\": 0.323097364939339}, {\"truth_threshold\": 22.740000000000002, \"match_probability\": 0.9999998572494347, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2702, \"tn\": 8049, \"fp\": 0, \"fn\": 9322, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22471723220226214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7752827677977379, \"precision\": 1.0, \"recall\": 0.22471723220226214, \"specificity\": 1.0, \"npv\": 0.4633584710149099, \"accuracy\": 0.5355950779654262, \"f1\": 0.3669699850604373, \"f2\": 0.26595535257293595, \"f0_5\": 0.5917133847231956, \"p4\": 0.46467358010158344, \"phi\": 0.32268348752909976}, {\"truth_threshold\": 22.76, \"match_probability\": 0.9999998592147237, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2699, \"tn\": 8049, \"fp\": 0, \"fn\": 9325, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22446773120425814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7755322687957419, \"precision\": 1.0, \"recall\": 0.22446773120425814, \"specificity\": 1.0, \"npv\": 0.4632784620697594, \"accuracy\": 0.5354456234743188, \"f1\": 0.36663723425932215, \"f2\": 0.26567575548774486, \"f0_5\": 0.5913672217353199, \"p4\": 0.46438663387410395, \"phi\": 0.32247645696484084}, {\"truth_threshold\": 22.78, \"match_probability\": 0.9999998611529559, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2694, \"tn\": 8049, \"fp\": 0, \"fn\": 9330, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22405189620758484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7759481037924152, \"precision\": 1.0, \"recall\": 0.22405189620758484, \"specificity\": 1.0, \"npv\": 0.4631451752114621, \"accuracy\": 0.5351965326558064, \"f1\": 0.3660823481451284, \"f2\": 0.26520968694624925, \"f0_5\": 0.5907894736842105, \"p4\": 0.4639078597605901, \"phi\": 0.32213126940041414}, {\"truth_threshold\": 22.8, \"match_probability\": 0.999999863064504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2687, \"tn\": 8049, \"fp\": 0, \"fn\": 9337, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22346972721224218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7765302727877578, \"precision\": 1.0, \"recall\": 0.22346972721224218, \"specificity\": 1.0, \"npv\": 0.4629587024042333, \"accuracy\": 0.5348478055098889, \"f1\": 0.36530487390388144, \"f2\": 0.2645570368036548, \"f0_5\": 0.5899789214825224, \"p4\": 0.46323645875954317, \"phi\": 0.32164771868739817}, {\"truth_threshold\": 22.82, \"match_probability\": 0.9999998649497351, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2678, \"tn\": 8049, \"fp\": 0, \"fn\": 9346, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2227212242182302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7772787757817698, \"precision\": 1.0, \"recall\": 0.2227212242182302, \"specificity\": 1.0, \"npv\": 0.46271917217591263, \"accuracy\": 0.5343994420365665, \"f1\": 0.36430417630254386, \"f2\": 0.2637176507661402, \"f0_5\": 0.5889338494018297, \"p4\": 0.4623713054314984, \"phi\": 0.32102551377774524}, {\"truth_threshold\": 22.84, \"match_probability\": 0.9999998668090118, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2673, \"tn\": 8049, \"fp\": 0, \"fn\": 9351, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22230538922155688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7776946107784432, \"precision\": 1.0, \"recall\": 0.22230538922155688, \"specificity\": 1.0, \"npv\": 0.4625862068965517, \"accuracy\": 0.5341503512180541, \"f1\": 0.36374770361298225, \"f2\": 0.26325119659634816, \"f0_5\": 0.588351822503962, \"p4\": 0.46188972566909003, \"phi\": 0.3206796014289989}, {\"truth_threshold\": 22.86, \"match_probability\": 0.9999998686426912, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2672, \"tn\": 8049, \"fp\": 0, \"fn\": 9352, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2222222222222222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7777777777777778, \"precision\": 1.0, \"recall\": 0.2222222222222222, \"specificity\": 1.0, \"npv\": 0.46255962301017184, \"accuracy\": 0.5341005330543516, \"f1\": 0.36363636363636365, \"f2\": 0.2631578947368421, \"f0_5\": 0.5882352941176471, \"p4\": 0.46179332898256586, \"phi\": 0.32061039804659136}, {\"truth_threshold\": 22.88, \"match_probability\": 0.9999998704511259, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2668, \"tn\": 8049, \"fp\": 0, \"fn\": 9356, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22188955422488357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7781104457751165, \"precision\": 1.0, \"recall\": 0.22188955422488357, \"specificity\": 1.0, \"npv\": 0.4624533180120655, \"accuracy\": 0.5339012603995417, \"f1\": 0.36319085216444325, \"f2\": 0.2627846505397526, \"f0_5\": 0.5877687698272823, \"p4\": 0.4614074725738446, \"phi\": 0.32033351461174886}, {\"truth_threshold\": 22.900000000000002, \"match_probability\": 0.9999998722346632, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2665, \"tn\": 8049, \"fp\": 0, \"fn\": 9359, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22164005322687957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7783599467731205, \"precision\": 1.0, \"recall\": 0.22164005322687957, \"specificity\": 1.0, \"npv\": 0.46237362132352944, \"accuracy\": 0.5337518059084342, \"f1\": 0.36285655933011096, \"f2\": 0.26250467878883393, \"f0_5\": 0.5874184447187445, \"p4\": 0.461117796659111, \"phi\": 0.3201257784697323}, {\"truth_threshold\": 22.92, \"match_probability\": 0.9999998739936462, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2660, \"tn\": 8049, \"fp\": 0, \"fn\": 9364, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22122421823020624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7787757817697938, \"precision\": 1.0, \"recall\": 0.22122421823020624, \"specificity\": 1.0, \"npv\": 0.46224085453396885, \"accuracy\": 0.5335027150899218, \"f1\": 0.36229910106238084, \"f2\": 0.26203798565686814, \"f0_5\": 0.5868337451464878, \"p4\": 0.46063446193725577, \"phi\": 0.3197794109669035}, {\"truth_threshold\": 22.94, \"match_probability\": 0.9999998757284128, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2655, \"tn\": 8049, \"fp\": 0, \"fn\": 9369, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22080838323353294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7791916167664671, \"precision\": 1.0, \"recall\": 0.22080838323353294, \"specificity\": 1.0, \"npv\": 0.46210816396830867, \"accuracy\": 0.5332536242714093, \"f1\": 0.36174126302881665, \"f2\": 0.2615712005674765, \"f0_5\": 0.5862480127186009, \"p4\": 0.4601504485025787, \"phi\": 0.31943286707046686}, {\"truth_threshold\": 22.96, \"match_probability\": 0.9999998774392962, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2653, \"tn\": 8049, \"fp\": 0, \"fn\": 9371, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2206420492348636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7793579507651364, \"precision\": 1.0, \"recall\": 0.2206420492348636, \"specificity\": 1.0, \"npv\": 0.46205510907003444, \"accuracy\": 0.5331539879440044, \"f1\": 0.36151802139401784, \"f2\": 0.2613844607775523, \"f0_5\": 0.5860134299346175, \"p4\": 0.45995665262266494, \"phi\": 0.3192941999546043}, {\"truth_threshold\": 22.98, \"match_probability\": 0.9999998791266254, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2651, \"tn\": 8049, \"fp\": 0, \"fn\": 9373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.22047571523619428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7795242847638058, \"precision\": 1.0, \"recall\": 0.22047571523619428, \"specificity\": 1.0, \"npv\": 0.46200206635288715, \"accuracy\": 0.5330543516165994, \"f1\": 0.3612947189097104, \"f2\": 0.2611977062683508, \"f0_5\": 0.5857786812798303, \"p4\": 0.4597627476817079, \"phi\": 0.31915550444846236}, {\"truth_threshold\": 23.0, \"match_probability\": 0.9999998807907247, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2644, \"tn\": 8049, \"fp\": 0, \"fn\": 9380, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21989354624085164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7801064537591483, \"precision\": 1.0, \"recall\": 0.21989354624085164, \"specificity\": 1.0, \"npv\": 0.4618165127087039, \"accuracy\": 0.532705624470682, \"f1\": 0.36051268066539405, \"f2\": 0.26054394954670873, \"f0_5\": 0.5849557522123894, \"p4\": 0.45908321959738196, \"phi\": 0.3186698459096816}, {\"truth_threshold\": 23.02, \"match_probability\": 0.9999998824319137, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2640, \"tn\": 8049, \"fp\": 0, \"fn\": 9384, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21956087824351297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780439121756487, \"precision\": 1.0, \"recall\": 0.21956087824351297, \"specificity\": 1.0, \"npv\": 0.4617105489588711, \"accuracy\": 0.532506351815872, \"f1\": 0.36006546644844517, \"f2\": 0.26017029328287605, \"f0_5\": 0.5844845908607864, \"p4\": 0.45869431504557917, \"phi\": 0.3183921695389261}, {\"truth_threshold\": 23.04, \"match_probability\": 0.9999998840505082, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2638, \"tn\": 8049, \"fp\": 0, \"fn\": 9386, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21939454424484364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7806054557551564, \"precision\": 1.0, \"recall\": 0.21939454424484364, \"specificity\": 1.0, \"npv\": 0.46165758531689133, \"accuracy\": 0.5324067154884671, \"f1\": 0.3598417678352203, \"f2\": 0.25998344305593885, \"f0_5\": 0.5842487597448618, \"p4\": 0.45849969793441775, \"phi\": 0.31825328832201305}, {\"truth_threshold\": 23.06, \"match_probability\": 0.999999885646819, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2633, \"tn\": 8049, \"fp\": 0, \"fn\": 9391, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21897870924817034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7810212907518297, \"precision\": 1.0, \"recall\": 0.21897870924817034, \"specificity\": 1.0, \"npv\": 0.46152522935779816, \"accuracy\": 0.5321576246699546, \"f1\": 0.359282254213004, \"f2\": 0.2595162530308108, \"f0_5\": 0.5836584500798014, \"p4\": 0.4580126733018623, \"phi\": 0.3179059593814441}, {\"truth_threshold\": 23.080000000000002, \"match_probability\": 0.9999998872211527, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2617, \"tn\": 8049, \"fp\": 0, \"fn\": 9407, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2176480372588157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7823519627411843, \"precision\": 1.0, \"recall\": 0.2176480372588157, \"specificity\": 1.0, \"npv\": 0.46110219981668193, \"accuracy\": 0.5313605340507149, \"f1\": 0.357489242538078, \"f2\": 0.25802062587502217, \"f0_5\": 0.581762404410457, \"p4\": 0.45644954677720206, \"phi\": 0.31679329027904474}, {\"truth_threshold\": 23.1, \"match_probability\": 0.9999998887738123, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2610, \"tn\": 8049, \"fp\": 0, \"fn\": 9414, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21706586826347304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7829341317365269, \"precision\": 1.0, \"recall\": 0.21706586826347304, \"specificity\": 1.0, \"npv\": 0.46091736814980244, \"accuracy\": 0.5310118069047974, \"f1\": 0.35670356703567035, \"f2\": 0.25736599219027334, \"f0_5\": 0.5809294871794872, \"p4\": 0.4557634390525425, \"phi\": 0.316305910022484}, {\"truth_threshold\": 23.12, \"match_probability\": 0.999999890305096, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2601, \"tn\": 8049, \"fp\": 0, \"fn\": 9423, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21631736526946108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7836826347305389, \"precision\": 1.0, \"recall\": 0.21631736526946108, \"specificity\": 1.0, \"npv\": 0.46067994505494503, \"accuracy\": 0.5305634434314751, \"f1\": 0.3556923076923077, \"f2\": 0.2565240546777916, \"f0_5\": 0.5798555377207063, \"p4\": 0.45487928396083654, \"phi\": 0.31567874801254175}, {\"truth_threshold\": 23.14, \"match_probability\": 0.9999998918152979, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2598, \"tn\": 8049, \"fp\": 0, \"fn\": 9426, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21606786427145708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7839321357285429, \"precision\": 1.0, \"recall\": 0.21606786427145708, \"specificity\": 1.0, \"npv\": 0.4606008583690987, \"accuracy\": 0.5304139889403676, \"f1\": 0.35535494460402134, \"f2\": 0.2562433424073855, \"f0_5\": 0.5794967880085653, \"p4\": 0.45458405947310987, \"phi\": 0.3154695607335374}, {\"truth_threshold\": 23.16, \"match_probability\": 0.9999998933047085, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2593, \"tn\": 8049, \"fp\": 0, \"fn\": 9431, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21565202927478377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7843479707252162, \"precision\": 1.0, \"recall\": 0.21565202927478377, \"specificity\": 1.0, \"npv\": 0.4604691075514874, \"accuracy\": 0.5301648981218552, \"f1\": 0.3547923650543887, \"f2\": 0.25577541478427274, \"f0_5\": 0.5788980175031255, \"p4\": 0.45409145432611436, \"phi\": 0.31512076647188286}, {\"truth_threshold\": 23.18, \"match_probability\": 0.999999894773614, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2588, \"tn\": 8049, \"fp\": 0, \"fn\": 9436, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21523619427811044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7847638057218895, \"precision\": 1.0, \"recall\": 0.21523619427811044, \"specificity\": 1.0, \"npv\": 0.460337432084644, \"accuracy\": 0.5299158073033428, \"f1\": 0.3542294004927457, \"f2\": 0.25530739483860787, \"f0_5\": 0.5782981766178048, \"p4\": 0.45359814186616243, \"phi\": 0.3147717855298612}, {\"truth_threshold\": 23.2, \"match_probability\": 0.9999998962222966, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2583, \"tn\": 8049, \"fp\": 0, \"fn\": 9441, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2148203592814371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7851796407185628, \"precision\": 1.0, \"recall\": 0.2148203592814371, \"specificity\": 1.0, \"npv\": 0.4602058319039451, \"accuracy\": 0.5296667164848303, \"f1\": 0.3536660505237215, \"f2\": 0.25483928254306515, \"f0_5\": 0.5776972624798712, \"p4\": 0.4531041198986722, \"phi\": 0.3144226171143198}, {\"truth_threshold\": 23.22, \"match_probability\": 0.9999998976510348, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2579, \"tn\": 8049, \"fp\": 0, \"fn\": 9445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21448769128409848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7855123087159015, \"precision\": 1.0, \"recall\": 0.21448769128409848, \"specificity\": 1.0, \"npv\": 0.4601006059220304, \"accuracy\": 0.5294674438300204, \"f1\": 0.3532150927891529, \"f2\": 0.2544647261963493, \"f0_5\": 0.5772157564905999, \"p4\": 0.45270838999901775, \"phi\": 0.3141431468656146}, {\"truth_threshold\": 23.240000000000002, \"match_probability\": 0.9999998990601031, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2574, \"tn\": 8049, \"fp\": 0, \"fn\": 9450, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21407185628742514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7859281437125748, \"precision\": 1.0, \"recall\": 0.21407185628742514, \"specificity\": 1.0, \"npv\": 0.4599691410937768, \"accuracy\": 0.529218353011508, \"f1\": 0.3526510480887793, \"f2\": 0.2539964476021314, \"f0_5\": 0.5766129032258065, \"p4\": 0.45221308536020116, \"phi\": 0.31379363898727675}, {\"truth_threshold\": 23.26, \"match_probability\": 0.9999999004497723, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2569, \"tn\": 8049, \"fp\": 0, \"fn\": 9455, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21365602129075184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7863439787092482, \"precision\": 1.0, \"recall\": 0.21365602129075184, \"specificity\": 1.0, \"npv\": 0.45983775137111516, \"accuracy\": 0.5289692621929956, \"f1\": 0.3520866168711026, \"f2\": 0.2535280765814665, \"f0_5\": 0.5760089686098655, \"p4\": 0.45171706502324127, \"phi\": 0.31344394139501}, {\"truth_threshold\": 23.28, \"match_probability\": 0.9999999018203096, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2563, \"tn\": 8049, \"fp\": 0, \"fn\": 9461, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21315701929474384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7868429807052562, \"precision\": 1.0, \"recall\": 0.21315701929474384, \"specificity\": 1.0, \"npv\": 0.4596801827527127, \"accuracy\": 0.5286703532107806, \"f1\": 0.3514087886474258, \"f2\": 0.25296590931522533, \"f0_5\": 0.5752828155862812, \"p4\": 0.45112089276053463, \"phi\": 0.31302405272507633}, {\"truth_threshold\": 23.3, \"match_probability\": 0.9999999031719783, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2558, \"tn\": 8049, \"fp\": 0, \"fn\": 9466, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2127411842980705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7872588157019295, \"precision\": 1.0, \"recall\": 0.2127411842980705, \"specificity\": 1.0, \"npv\": 0.4595489580359692, \"accuracy\": 0.5284212623922683, \"f1\": 0.350843505691949, \"f2\": 0.2524973348600308, \"f0_5\": 0.5746764917325665, \"p4\": 0.4506232900348719, \"phi\": 0.31267393491545853}, {\"truth_threshold\": 23.32, \"match_probability\": 0.9999999045050382, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2554, \"tn\": 8049, \"fp\": 0, \"fn\": 9470, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21240851630073188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7875914836992681, \"precision\": 1.0, \"recall\": 0.21240851630073188, \"specificity\": 1.0, \"npv\": 0.45944403219361835, \"accuracy\": 0.5282219897374583, \"f1\": 0.35039100013719304, \"f2\": 0.2521224086870681, \"f0_5\": 0.5741906474820144, \"p4\": 0.45022468750567035, \"phi\": 0.3123937022436146}, {\"truth_threshold\": 23.34, \"match_probability\": 0.9999999058197454, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2552, \"tn\": 8049, \"fp\": 0, \"fn\": 9472, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21224218230206254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7877578176979375, \"precision\": 1.0, \"recall\": 0.21224218230206254, \"specificity\": 1.0, \"npv\": 0.45939158723817136, \"accuracy\": 0.5281223534100533, \"f1\": 0.35016465422612514, \"f2\": 0.2519349233928289, \"f0_5\": 0.5739474631162289, \"p4\": 0.45002521239492865, \"phi\": 0.31225353962227204}, {\"truth_threshold\": 23.36, \"match_probability\": 0.9999999071163527, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2549, \"tn\": 8049, \"fp\": 0, \"fn\": 9475, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21199268130405854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7880073186959414, \"precision\": 1.0, \"recall\": 0.21199268130405854, \"specificity\": 1.0, \"npv\": 0.4593129422506277, \"accuracy\": 0.5279728989189458, \"f1\": 0.349825018870514, \"f2\": 0.2516536676868398, \"f0_5\": 0.5735823582358236, \"p4\": 0.44972578201442637, \"phi\": 0.312043237685688}, {\"truth_threshold\": 23.38, \"match_probability\": 0.9999999083951091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2540, \"tn\": 8049, \"fp\": 0, \"fn\": 9484, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21124417831004658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7887558216899534, \"precision\": 1.0, \"recall\": 0.21124417831004658, \"specificity\": 1.0, \"npv\": 0.45907716876746707, \"accuracy\": 0.5275245354456235, \"f1\": 0.34880527327657235, \"f2\": 0.2508097006082629, \"f0_5\": 0.5724846736386585, \"p4\": 0.44882591875797007, \"phi\": 0.3114119125807267}, {\"truth_threshold\": 23.400000000000002, \"match_probability\": 0.9999999096562606, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2530, \"tn\": 8049, \"fp\": 0, \"fn\": 9494, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21041250831669994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7895874916833001, \"precision\": 1.0, \"recall\": 0.21041250831669994, \"specificity\": 1.0, \"npv\": 0.458815481958616, \"accuracy\": 0.5270263538085986, \"f1\": 0.34767074343823, \"f2\": 0.24987160747442025, \"f0_5\": 0.571260838150289, \"p4\": 0.4478232922398854, \"phi\": 0.31070969797135073}, {\"truth_threshold\": 23.42, \"match_probability\": 0.9999999109000495, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2527, \"tn\": 8049, \"fp\": 0, \"fn\": 9497, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.21016300731869594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.789836992681304, \"precision\": 1.0, \"recall\": 0.21016300731869594, \"specificity\": 1.0, \"npv\": 0.458737034081842, \"accuracy\": 0.5268768993174912, \"f1\": 0.3473300804068449, \"f2\": 0.24959010726349684, \"f0_5\": 0.570892824868968, \"p4\": 0.44752193135072643, \"phi\": 0.3104988802735028}, {\"truth_threshold\": 23.44, \"match_probability\": 0.9999999121267147, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2522, \"tn\": 8049, \"fp\": 0, \"fn\": 9502, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2097471723220226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7902528276779773, \"precision\": 1.0, \"recall\": 0.2097471723220226, \"specificity\": 1.0, \"npv\": 0.4586063472166828, \"accuracy\": 0.5266278084989787, \"f1\": 0.34676199642513406, \"f2\": 0.249120866095065, \"f0_5\": 0.5702785817655571, \"p4\": 0.4470190733681122, \"phi\": 0.31014735939167837}, {\"truth_threshold\": 23.46, \"match_probability\": 0.9999999133364921, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2520, \"tn\": 8049, \"fp\": 0, \"fn\": 9504, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20958083832335328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7904191616766467, \"precision\": 1.0, \"recall\": 0.20958083832335328, \"specificity\": 1.0, \"npv\": 0.4585540933173816, \"accuracy\": 0.5265281721715738, \"f1\": 0.3465346534653465, \"f2\": 0.24893314366998578, \"f0_5\": 0.5700325732899023, \"p4\": 0.4468177233018024, \"phi\": 0.31000669556327654}, {\"truth_threshold\": 23.48, \"match_probability\": 0.9999999145296141, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2511, \"tn\": 8049, \"fp\": 0, \"fn\": 9513, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2088323353293413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7911676646706587, \"precision\": 1.0, \"recall\": 0.2088323353293413, \"specificity\": 1.0, \"npv\": 0.4583190980526136, \"accuracy\": 0.5260798086982513, \"f1\": 0.3455108359133127, \"f2\": 0.24808820914102792, \"f0_5\": 0.5689233278955954, \"p4\": 0.44591018021500944, \"phi\": 0.30937331425377446}, {\"truth_threshold\": 23.5, \"match_probability\": 0.9999999157063101, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2506, \"tn\": 8049, \"fp\": 0, \"fn\": 9518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.208416500332668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.791583499667332, \"precision\": 1.0, \"recall\": 0.208416500332668, \"specificity\": 1.0, \"npv\": 0.45818864917174246, \"accuracy\": 0.525830717879739, \"f1\": 0.34494150034411564, \"f2\": 0.24761867119876685, \"f0_5\": 0.5683055152394775, \"p4\": 0.44540494830276534, \"phi\": 0.30902115583326517}, {\"truth_threshold\": 23.52, \"match_probability\": 0.9999999168668061, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2501, \"tn\": 8049, \"fp\": 0, \"fn\": 9523, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20800066533599468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7919993346640053, \"precision\": 1.0, \"recall\": 0.20800066533599468, \"specificity\": 1.0, \"npv\": 0.4580582745276576, \"accuracy\": 0.5255816270612266, \"f1\": 0.34437177280550774, \"f2\": 0.24714904045694408, \"f0_5\": 0.5676865807154531, \"p4\": 0.4448989696361198, \"phi\": 0.308668796389286}, {\"truth_threshold\": 23.54, \"match_probability\": 0.9999999180113253, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2500, \"tn\": 8049, \"fp\": 0, \"fn\": 9524, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20791749833666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7920825016633399, \"precision\": 1.0, \"recall\": 0.20791749833666, \"specificity\": 1.0, \"npv\": 0.4580322085016787, \"accuracy\": 0.525531808897524, \"f1\": 0.3442577802258331, \"f2\": 0.2470551031702111, \"f0_5\": 0.5675626589175445, \"p4\": 0.44479768408561965, \"phi\": 0.3085983003020018}, {\"truth_threshold\": 23.56, \"match_probability\": 0.9999999191400875, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2498, \"tn\": 8049, \"fp\": 0, \"fn\": 9526, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20775116433799068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7922488356620093, \"precision\": 1.0, \"recall\": 0.20775116433799068, \"specificity\": 1.0, \"npv\": 0.4579800853485064, \"accuracy\": 0.5254321725701191, \"f1\": 0.34402974796859936, \"f2\": 0.2468672174566154, \"f0_5\": 0.5673146802325582, \"p4\": 0.4445950230167743, \"phi\": 0.3084572838737393}, {\"truth_threshold\": 23.580000000000002, \"match_probability\": 0.9999999202533097, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2493, \"tn\": 8049, \"fp\": 0, \"fn\": 9531, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20733532934131738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7926646706586826, \"precision\": 1.0, \"recall\": 0.20733532934131738, \"specificity\": 1.0, \"npv\": 0.45784982935153584, \"accuracy\": 0.5251830817516067, \"f1\": 0.3434593924364538, \"f2\": 0.2463974381782601, \"f0_5\": 0.5666939443535188, \"p4\": 0.444087844651028, \"phi\": 0.30810460100015813}, {\"truth_threshold\": 23.6, \"match_probability\": 0.9999999213512059, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2488, \"tn\": 8049, \"fp\": 0, \"fn\": 9536, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20691949434464404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7930805056553559, \"precision\": 1.0, \"recall\": 0.20691949434464404, \"specificity\": 1.0, \"npv\": 0.45771964742678417, \"accuracy\": 0.5249339909330942, \"f1\": 0.3428886438809261, \"f2\": 0.2459275660287838, \"f0_5\": 0.5660720786312341, \"p4\": 0.44357991340119596, \"phi\": 0.307751714856569}, {\"truth_threshold\": 23.62, \"match_probability\": 0.9999999224339869, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2478, \"tn\": 8049, \"fp\": 0, \"fn\": 9546, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2060878243512974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7939121756487026, \"precision\": 1.0, \"recall\": 0.2060878243512974, \"specificity\": 1.0, \"npv\": 0.45745950554134696, \"accuracy\": 0.5244358092960694, \"f1\": 0.341745966073645, \"f2\": 0.2449875430062878, \"f0_5\": 0.5648249452954048, \"p4\": 0.44256178274182023, \"phi\": 0.3070453292688825}, {\"truth_threshold\": 23.64, \"match_probability\": 0.9999999235018612, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2474, \"tn\": 8049, \"fp\": 0, \"fn\": 9550, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20575515635395875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7942448436460412, \"precision\": 1.0, \"recall\": 0.20575515635395875, \"specificity\": 1.0, \"npv\": 0.4573555315642934, \"accuracy\": 0.5242365366412594, \"f1\": 0.3412884535798041, \"f2\": 0.24461142970140398, \"f0_5\": 0.5643248175182481, \"p4\": 0.4421536803103083, \"phi\": 0.30676254482312393}, {\"truth_threshold\": 23.66, \"match_probability\": 0.9999999245550335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2465, \"tn\": 8049, \"fp\": 0, \"fn\": 9559, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20500665335994678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7949933466400533, \"precision\": 1.0, \"recall\": 0.20500665335994678, \"specificity\": 1.0, \"npv\": 0.45712176283507494, \"accuracy\": 0.523788173167937, \"f1\": 0.3402581268548554, \"f2\": 0.2437649571804355, \"f0_5\": 0.5631968561506123, \"p4\": 0.44123366497899613, \"phi\": 0.30612579567363807}, {\"truth_threshold\": 23.7, \"match_probability\": 0.99999992661808, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2462, \"tn\": 8049, \"fp\": 0, \"fn\": 9562, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20475715236194278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7952428476380572, \"precision\": 1.0, \"recall\": 0.20475715236194278, \"specificity\": 1.0, \"npv\": 0.4570438930214071, \"accuracy\": 0.5236387186768295, \"f1\": 0.3399144001104515, \"f2\": 0.24348273270303414, \"f0_5\": 0.5628200438917337, \"p4\": 0.44092644216002186, \"phi\": 0.30591339630601294}, {\"truth_threshold\": 23.72, \"match_probability\": 0.9999999276283504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2459, \"tn\": 8049, \"fp\": 0, \"fn\": 9565, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20450765136393878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7954923486360612, \"precision\": 1.0, \"recall\": 0.20450765136393878, \"specificity\": 1.0, \"npv\": 0.4569660497331668, \"accuracy\": 0.5234892641857222, \"f1\": 0.339570530967341, \"f2\": 0.24320047473049156, \"f0_5\": 0.5624428179322964, \"p4\": 0.44061894294771836, \"phi\": 0.3057009217911958}, {\"truth_threshold\": 23.740000000000002, \"match_probability\": 0.9999999286247123, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2456, \"tn\": 8049, \"fp\": 0, \"fn\": 9568, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2042581503659348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7957418496340652, \"precision\": 1.0, \"recall\": 0.2042581503659348, \"specificity\": 1.0, \"npv\": 0.4568882329568031, \"accuracy\": 0.5233398096946147, \"f1\": 0.3392265193370166, \"f2\": 0.24291818325684444, \"f0_5\": 0.5620651775906261, \"p4\": 0.4403111668167607, \"phi\": 0.3054883719353601}, {\"truth_threshold\": 23.76, \"match_probability\": 0.9999999296073568, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2450, \"tn\": 8049, \"fp\": 0, \"fn\": 9574, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2037591483699268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7962408516300732, \"precision\": 1.0, \"recall\": 0.2037591483699268, \"specificity\": 1.0, \"npv\": 0.4567326788855473, \"accuracy\": 0.5230409007123997, \"f1\": 0.33853806826032884, \"f2\": 0.24235349978237644, \"f0_5\": 0.5613086510263929, \"p4\": 0.43969478169125825, \"phi\": 0.3050630454224739}, {\"truth_threshold\": 23.78, \"match_probability\": 0.9999999305764732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2443, \"tn\": 8049, \"fp\": 0, \"fn\": 9581, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20317697937458418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7968230206254159, \"precision\": 1.0, \"recall\": 0.20317697937458418, \"specificity\": 1.0, \"npv\": 0.45655133295519, \"accuracy\": 0.5226921735664823, \"f1\": 0.33773415359093106, \"f2\": 0.24169453293496113, \"f0_5\": 0.5604239309965131, \"p4\": 0.43897425742839496, \"phi\": 0.3045664471987608}, {\"truth_threshold\": 23.8, \"match_probability\": 0.9999999315322473, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2436, \"tn\": 8049, \"fp\": 0, \"fn\": 9588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.2025948103792415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7974051896207585, \"precision\": 1.0, \"recall\": 0.2025948103792415, \"specificity\": 1.0, \"npv\": 0.45637013097465556, \"accuracy\": 0.522343446420565, \"f1\": 0.3369294605809129, \"f2\": 0.24103538351935408, \"f0_5\": 0.5595369349503859, \"p4\": 0.4382522101240751, \"phi\": 0.30406943310296736}, {\"truth_threshold\": 23.84, \"match_probability\": 0.9999999334045014, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2429, \"tn\": 8049, \"fp\": 0, \"fn\": 9595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20201264138389888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7979873586161012, \"precision\": 1.0, \"recall\": 0.20201264138389888, \"specificity\": 1.0, \"npv\": 0.45618907277261395, \"accuracy\": 0.5219947192746476, \"f1\": 0.3361239880993565, \"f2\": 0.24037605145967342, \"f0_5\": 0.5586476540938362, \"p4\": 0.43752863299124595, \"phi\": 0.30357200062138046}, {\"truth_threshold\": 23.86, \"match_probability\": 0.9999999343213413, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2427, \"tn\": 8049, \"fp\": 0, \"fn\": 9597, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20184630738522955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7981536926147704, \"precision\": 1.0, \"recall\": 0.20184630738522955, \"specificity\": 1.0, \"npv\": 0.4561373682420945, \"accuracy\": 0.5218950829472425, \"f1\": 0.33589370977787003, \"f2\": 0.24018763731369872, \"f0_5\": 0.5583931529541689, \"p4\": 0.43732161472447423, \"phi\": 0.30342979985506274}, {\"truth_threshold\": 23.88, \"match_probability\": 0.9999999352255587, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2424, \"tn\": 8049, \"fp\": 0, \"fn\": 9600, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20159680638722555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7984031936127745, \"precision\": 1.0, \"recall\": 0.20159680638722555, \"specificity\": 1.0, \"npv\": 0.45605983341832396, \"accuracy\": 0.5217456284561351, \"f1\": 0.33554817275747506, \"f2\": 0.23990498812351543, \"f0_5\": 0.5580110497237569, \"p4\": 0.4370108517730691, \"phi\": 0.3032164341499718}, {\"truth_threshold\": 23.900000000000002, \"match_probability\": 0.9999999361173275, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2419, \"tn\": 8049, \"fp\": 0, \"fn\": 9605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20118097139055222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7988190286094478, \"precision\": 1.0, \"recall\": 0.20118097139055222, \"specificity\": 1.0, \"npv\": 0.45593066727087345, \"accuracy\": 0.5214965376376227, \"f1\": 0.334971958734335, \"f2\": 0.23943383153518757, \"f0_5\": 0.5573732718894009, \"p4\": 0.4364922840491462, \"phi\": 0.3028606519974112}, {\"truth_threshold\": 23.92, \"match_probability\": 0.9999999369968191, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2415, \"tn\": 8049, \"fp\": 0, \"fn\": 9609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20084830339321358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7991516966067864, \"precision\": 1.0, \"recall\": 0.20084830339321358, \"specificity\": 1.0, \"npv\": 0.45582738702004755, \"accuracy\": 0.5212972649828127, \"f1\": 0.3345107001869936, \"f2\": 0.23905683910435352, \"f0_5\": 0.5568622025456558, \"p4\": 0.4360768618997902, \"phi\": 0.3025758703583918}, {\"truth_threshold\": 23.94, \"match_probability\": 0.9999999378642025, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2408, \"tn\": 8049, \"fp\": 0, \"fn\": 9616, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20026613439787092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7997338656021291, \"precision\": 1.0, \"recall\": 0.20026613439787092, \"specificity\": 1.0, \"npv\": 0.45564675912821967, \"accuracy\": 0.5209485378368953, \"f1\": 0.33370288248337027, \"f2\": 0.23839695865674007, \"f0_5\": 0.5559660140376801, \"p4\": 0.4353486541741782, \"phi\": 0.30207716746143914}, {\"truth_threshold\": 23.96, \"match_probability\": 0.9999999387196443, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2405, \"tn\": 8049, \"fp\": 0, \"fn\": 9619, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.20001663339986694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.799983366600133, \"precision\": 1.0, \"recall\": 0.20001663339986694, \"specificity\": 1.0, \"npv\": 0.4555693909893593, \"accuracy\": 0.5207990833457878, \"f1\": 0.3333564349573775, \"f2\": 0.2381140967505594, \"f0_5\": 0.555581223433746, \"p4\": 0.4350360888113128, \"phi\": 0.30186330659044885}, {\"truth_threshold\": 23.98, \"match_probability\": 0.999999939563309, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2399, \"tn\": 8049, \"fp\": 0, \"fn\": 9625, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19951763140385895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8004823685961411, \"precision\": 1.0, \"recall\": 0.19951763140385895, \"specificity\": 1.0, \"npv\": 0.4554147335068462, \"accuracy\": 0.520500174363573, \"f1\": 0.3326631075365735, \"f2\": 0.23754827210614912, \"f0_5\": 0.5548103607770583, \"p4\": 0.4344100977521938, \"phi\": 0.3014353478537406}, {\"truth_threshold\": 24.0, \"match_probability\": 0.9999999403953588, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2392, \"tn\": 8049, \"fp\": 0, \"fn\": 9632, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1989354624085163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8010645375914837, \"precision\": 1.0, \"recall\": 0.1989354624085163, \"specificity\": 1.0, \"npv\": 0.455234432441604, \"accuracy\": 0.5201514472176556, \"f1\": 0.3318534961154273, \"f2\": 0.23688797337981302, \"f0_5\": 0.5539088551315302, \"p4\": 0.4336783200754245, \"phi\": 0.30093566143288664}, {\"truth_threshold\": 24.02, \"match_probability\": 0.9999999412159535, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2386, \"tn\": 8049, \"fp\": 0, \"fn\": 9638, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19843646041250831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8015635395874917, \"precision\": 1.0, \"recall\": 0.19843646041250831, \"specificity\": 1.0, \"npv\": 0.45508000226154804, \"accuracy\": 0.5198525382354406, \"f1\": 0.33115891741845943, \"f2\": 0.23632185729566973, \"f0_5\": 0.5531342729970327, \"p4\": 0.43304983005282993, \"phi\": 0.3005070129852178}, {\"truth_threshold\": 24.04, \"match_probability\": 0.9999999420252508, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2381, \"tn\": 8049, \"fp\": 0, \"fn\": 9643, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19802062541583498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.801979374584165, \"precision\": 1.0, \"recall\": 0.19802062541583498, \"specificity\": 1.0, \"npv\": 0.4549513904589645, \"accuracy\": 0.5196034474169282, \"f1\": 0.3305796598403332, \"f2\": 0.23584999108504864, \"f0_5\": 0.5524874698347875, \"p4\": 0.43252520213736817, \"phi\": 0.3001495608400717}, {\"truth_threshold\": 24.060000000000002, \"match_probability\": 0.9999999428234062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2375, \"tn\": 8049, \"fp\": 0, \"fn\": 9649, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.197521623419827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.802478376580173, \"precision\": 1.0, \"recall\": 0.197521623419827, \"specificity\": 1.0, \"npv\": 0.4547971522205899, \"accuracy\": 0.5193045384347132, \"f1\": 0.32988401972359194, \"f2\": 0.23528362822214738, \"f0_5\": 0.5517097193830143, \"p4\": 0.4318945812910941, \"phi\": 0.29972032268987886}, {\"truth_threshold\": 24.080000000000002, \"match_probability\": 0.9999999436105732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2366, \"tn\": 8049, \"fp\": 0, \"fn\": 9658, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19677312042581505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8032268795741849, \"precision\": 1.0, \"recall\": 0.19677312042581505, \"specificity\": 1.0, \"npv\": 0.45456599085107585, \"accuracy\": 0.5188561749613909, \"f1\": 0.3288394718554552, \"f2\": 0.23443383139788357, \"f0_5\": 0.5505398361876396, \"p4\": 0.4309464574438955, \"phi\": 0.2990758573660179}, {\"truth_threshold\": 24.1, \"match_probability\": 0.9999999443869031, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2363, \"tn\": 8049, \"fp\": 0, \"fn\": 9661, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19652361942781105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.803476380572189, \"precision\": 1.0, \"recall\": 0.19652361942781105, \"specificity\": 1.0, \"npv\": 0.454488989271598, \"accuracy\": 0.5187067204702834, \"f1\": 0.3284909988183777, \"f2\": 0.23415049842446342, \"f0_5\": 0.550149003538834, \"p4\": 0.4306298292155499, \"phi\": 0.2988608725841207}, {\"truth_threshold\": 24.12, \"match_probability\": 0.999999945152545, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2361, \"tn\": 8049, \"fp\": 0, \"fn\": 9663, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19635728542914171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8036427145708582, \"precision\": 1.0, \"recall\": 0.19635728542914171, \"specificity\": 1.0, \"npv\": 0.4544376693766938, \"accuracy\": 0.5186070841428785, \"f1\": 0.3282586027111575, \"f2\": 0.23396159105773232, \"f0_5\": 0.5498882057015092, \"p4\": 0.4304185801994949, \"phi\": 0.2987175039323163}, {\"truth_threshold\": 24.14, \"match_probability\": 0.9999999459076461, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2357, \"tn\": 8049, \"fp\": 0, \"fn\": 9667, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19602461743180305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8039753825681969, \"precision\": 1.0, \"recall\": 0.19602461743180305, \"specificity\": 1.0, \"npv\": 0.45433506434861143, \"accuracy\": 0.5184078114880686, \"f1\": 0.32779361657742856, \"f2\": 0.23358373139357422, \"f0_5\": 0.5493660264777177, \"p4\": 0.42999568893549844, \"phi\": 0.29843065723010126}, {\"truth_threshold\": 24.16, \"match_probability\": 0.9999999466523515, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2355, \"tn\": 8049, \"fp\": 0, \"fn\": 9669, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19585828343313375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8041417165668663, \"precision\": 1.0, \"recall\": 0.19585828343313375, \"specificity\": 1.0, \"npv\": 0.4542837792075855, \"accuracy\": 0.5183081751606636, \"f1\": 0.32756102649697477, \"f2\": 0.23339477909258488, \"f0_5\": 0.5491046446558477, \"p4\": 0.429784046349594, \"phi\": 0.2982871790525272}, {\"truth_threshold\": 24.18, \"match_probability\": 0.9999999473868042, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2349, \"tn\": 8049, \"fp\": 0, \"fn\": 9675, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19535928143712575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8046407185628742, \"precision\": 1.0, \"recall\": 0.19535928143712575, \"specificity\": 1.0, \"npv\": 0.4541299932295193, \"accuracy\": 0.5180092661784487, \"f1\": 0.32686286787726987, \"f2\": 0.2328278322925959, \"f0_5\": 0.5483193277310925, \"p4\": 0.4291483287426601, \"phi\": 0.29785652444820754}, {\"truth_threshold\": 24.2, \"match_probability\": 0.9999999481111456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2342, \"tn\": 8049, \"fp\": 0, \"fn\": 9682, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1947771124417831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8052228875582169, \"precision\": 1.0, \"recall\": 0.1947771124417831, \"specificity\": 1.0, \"npv\": 0.4539507077998985, \"accuracy\": 0.5176605390325313, \"f1\": 0.3260476124182097, \"f2\": 0.23216622387882152, \"f0_5\": 0.5474008975317876, \"p4\": 0.4284051559407628, \"phi\": 0.2973536750339028}, {\"truth_threshold\": 24.22, \"match_probability\": 0.9999999488255148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2332, \"tn\": 8049, \"fp\": 0, \"fn\": 9692, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19394544244843645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8060545575515635, \"precision\": 1.0, \"recall\": 0.19394544244843645, \"specificity\": 1.0, \"npv\": 0.45369483118200776, \"accuracy\": 0.5171623573955064, \"f1\": 0.3248815826135414, \"f2\": 0.2312207503767748, \"f0_5\": 0.54608467590858, \"p4\": 0.4273406601592667, \"phi\": 0.2966345306436241}, {\"truth_threshold\": 24.240000000000002, \"match_probability\": 0.999999949530049, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2329, \"tn\": 8049, \"fp\": 0, \"fn\": 9695, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19369594145043248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8063040585495675, \"precision\": 1.0, \"recall\": 0.19369594145043248, \"specificity\": 1.0, \"npv\": 0.45361812443642924, \"accuracy\": 0.5170129029043989, \"f1\": 0.32453145683829165, \"f2\": 0.23093703520079326, \"f0_5\": 0.545688847235239, \"p4\": 0.4270206616096427, \"phi\": 0.29641860547491544}, {\"truth_threshold\": 24.26, \"match_probability\": 0.9999999502248836, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2322, \"tn\": 8049, \"fp\": 0, \"fn\": 9702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19311377245508982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8068862275449101, \"precision\": 1.0, \"recall\": 0.19311377245508982, \"specificity\": 1.0, \"npv\": 0.4534392428595572, \"accuracy\": 0.5166641757584816, \"f1\": 0.3237139272271016, \"f2\": 0.23027490182077828, \"f0_5\": 0.5447635135135135, \"p4\": 0.4262728269500956, \"phi\": 0.29591445177244846}, {\"truth_threshold\": 24.28, \"match_probability\": 0.9999999509101524, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2319, \"tn\": 8049, \"fp\": 0, \"fn\": 9705, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19286427145708582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8071357285429142, \"precision\": 1.0, \"recall\": 0.19286427145708582, \"specificity\": 1.0, \"npv\": 0.4533626225076039, \"accuracy\": 0.5165147212673741, \"f1\": 0.3233633131144112, \"f2\": 0.22999107408509373, \"f0_5\": 0.5443661971830986, \"p4\": 0.4259518229516991, \"phi\": 0.29569824466134875}, {\"truth_threshold\": 24.3, \"match_probability\": 0.9999999515859868, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2310, \"tn\": 8049, \"fp\": 0, \"fn\": 9714, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19211576846307385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8078842315369261, \"precision\": 1.0, \"recall\": 0.19211576846307385, \"specificity\": 1.0, \"npv\": 0.45313291673703765, \"accuracy\": 0.5160663577940517, \"f1\": 0.3223105902051067, \"f2\": 0.22913938816807522, \"f0_5\": 0.5431715575620768, \"p4\": 0.42498699114925004, \"phi\": 0.2950491120387419}, {\"truth_threshold\": 24.32, \"match_probability\": 0.9999999522525168, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2305, \"tn\": 8049, \"fp\": 0, \"fn\": 9719, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19169993346640055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8083000665335994, \"precision\": 1.0, \"recall\": 0.19169993346640055, \"specificity\": 1.0, \"npv\": 0.4530054029716344, \"accuracy\": 0.5158172669755393, \"f1\": 0.3217251727266383, \"f2\": 0.22866609789488304, \"f0_5\": 0.5425061193748824, \"p4\": 0.4244497896292903, \"phi\": 0.29468814976103513}, {\"truth_threshold\": 24.34, \"match_probability\": 0.9999999529098704, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2304, \"tn\": 8049, \"fp\": 0, \"fn\": 9720, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19161676646706588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8083832335329342, \"precision\": 1.0, \"recall\": 0.19161676646706588, \"specificity\": 1.0, \"npv\": 0.4529799088299848, \"accuracy\": 0.5157674488118368, \"f1\": 0.32160804020100503, \"f2\": 0.22857142857142856, \"f0_5\": 0.5423728813559322, \"p4\": 0.424342247522269, \"phi\": 0.2946159286334464}, {\"truth_threshold\": 24.36, \"match_probability\": 0.9999999535581742, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2300, \"tn\": 8049, \"fp\": 0, \"fn\": 9724, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19128409846972722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8087159015302728, \"precision\": 1.0, \"recall\": 0.19128409846972722, \"specificity\": 1.0, \"npv\": 0.45287796095200583, \"accuracy\": 0.5155681761570269, \"f1\": 0.32113934655124265, \"f2\": 0.2281927137074371, \"f0_5\": 0.5418394270637015, \"p4\": 0.42391173901451895, \"phi\": 0.29432694826928907}, {\"truth_threshold\": 24.38, \"match_probability\": 0.9999999541975525, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2297, \"tn\": 8049, \"fp\": 0, \"fn\": 9727, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19103459747172322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8089654025282768, \"precision\": 1.0, \"recall\": 0.19103459747172322, \"specificity\": 1.0, \"npv\": 0.4528015301530153, \"accuracy\": 0.5154187216659194, \"f1\": 0.3207876544934013, \"f2\": 0.22790863810449863, \"f0_5\": 0.5414388082217613, \"p4\": 0.4235884999299558, \"phi\": 0.2941101121134083}, {\"truth_threshold\": 24.400000000000002, \"match_probability\": 0.9999999548281283, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2293, \"tn\": 8049, \"fp\": 0, \"fn\": 9731, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19070192947438455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8092980705256154, \"precision\": 1.0, \"recall\": 0.19070192947438455, \"specificity\": 1.0, \"npv\": 0.45269966254218225, \"accuracy\": 0.5152194490111095, \"f1\": 0.3203185024795697, \"f2\": 0.2275298180158368, \"f0_5\": 0.5409039441404039, \"p4\": 0.42315703640585306, \"phi\": 0.2938208622940123}, {\"truth_threshold\": 24.42, \"match_probability\": 0.9999999554500227, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2290, \"tn\": 8049, \"fp\": 0, \"fn\": 9734, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19045242847638058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8095475715236194, \"precision\": 1.0, \"recall\": 0.19045242847638058, \"specificity\": 1.0, \"npv\": 0.45262329190800205, \"accuracy\": 0.515069994520002, \"f1\": 0.31996646639653487, \"f2\": 0.22724566347795022, \"f0_5\": 0.5405022658610272, \"p4\": 0.4228330794249467, \"phi\": 0.2936038234234232}, {\"truth_threshold\": 24.44, \"match_probability\": 0.9999999560633555, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2289, \"tn\": 8049, \"fp\": 0, \"fn\": 9735, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.19036926147704591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8096307385229541, \"precision\": 1.0, \"recall\": 0.19036926147704591, \"specificity\": 1.0, \"npv\": 0.4525978407557355, \"accuracy\": 0.5150201763562995, \"f1\": 0.3198490882414588, \"f2\": 0.22715093777910092, \"f0_5\": 0.5403682719546742, \"p4\": 0.4227250252003197, \"phi\": 0.293531457753296}, {\"truth_threshold\": 24.46, \"match_probability\": 0.9999999566682441, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2281, \"tn\": 8049, \"fp\": 0, \"fn\": 9743, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18970392548236858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8102960745176314, \"precision\": 1.0, \"recall\": 0.18970392548236858, \"specificity\": 1.0, \"npv\": 0.4523943345323741, \"accuracy\": 0.5146216310466796, \"f1\": 0.3189094722125131, \"f2\": 0.2263929968040971, \"f0_5\": 0.5392944959334216, \"p4\": 0.4218593540211153, \"phi\": 0.2929521823212369}, {\"truth_threshold\": 24.48, \"match_probability\": 0.9999999572648053, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2280, \"tn\": 8049, \"fp\": 0, \"fn\": 9744, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18962075848303392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.810379241516966, \"precision\": 1.0, \"recall\": 0.18962075848303392, \"specificity\": 1.0, \"npv\": 0.45236890912156463, \"accuracy\": 0.5145718128829772, \"f1\": 0.3187919463087248, \"f2\": 0.22629823725583612, \"f0_5\": 0.5391600454029511, \"p4\": 0.42175099011416406, \"phi\": 0.2928797290045416}, {\"truth_threshold\": 24.5, \"match_probability\": 0.9999999578531533, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2278, \"tn\": 8049, \"fp\": 0, \"fn\": 9746, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18945442448436461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8105455755156354, \"precision\": 1.0, \"recall\": 0.18945442448436461, \"specificity\": 1.0, \"npv\": 0.45231806687271703, \"accuracy\": 0.5144721765555722, \"f1\": 0.31855684519647604, \"f2\": 0.226108706872593, \"f0_5\": 0.538890991672975, \"p4\": 0.42153415871297467, \"phi\": 0.29273479301793104}, {\"truth_threshold\": 24.52, \"match_probability\": 0.9999999584334013, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2277, \"tn\": 8049, \"fp\": 0, \"fn\": 9747, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18937125748502995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8106287425149701, \"precision\": 1.0, \"recall\": 0.18937125748502995, \"specificity\": 1.0, \"npv\": 0.45229265003371544, \"accuracy\": 0.5144223583918697, \"f1\": 0.3184392699811202, \"f2\": 0.22601393603716277, \"f0_5\": 0.5387563884156729, \"p4\": 0.42142569117360834, \"phi\": 0.2926623103307313}, {\"truth_threshold\": 24.54, \"match_probability\": 0.999999959005661, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2267, \"tn\": 8049, \"fp\": 0, \"fn\": 9757, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1885395874916833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8114604125083167, \"precision\": 1.0, \"recall\": 0.1885395874916833, \"specificity\": 1.0, \"npv\": 0.4520386386611255, \"accuracy\": 0.5139241767548448, \"f1\": 0.3172626128332517, \"f2\": 0.22506602068979212, \"f0_5\": 0.5374075478854542, \"p4\": 0.42033910963150617, \"phi\": 0.29193694261513164}, {\"truth_threshold\": 24.560000000000002, \"match_probability\": 0.9999999595700421, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2264, \"tn\": 8049, \"fp\": 0, \"fn\": 9760, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18829008649367932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8117099135063207, \"precision\": 1.0, \"recall\": 0.18829008649367932, \"specificity\": 1.0, \"npv\": 0.4519624908754001, \"accuracy\": 0.5137747222637373, \"f1\": 0.3169092945128779, \"f2\": 0.22478157267672755, \"f0_5\": 0.5370018975332068, \"p4\": 0.42001245728640624, \"phi\": 0.2917191397540241}, {\"truth_threshold\": 24.580000000000002, \"match_probability\": 0.9999999601266533, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2261, \"tn\": 8049, \"fp\": 0, \"fn\": 9763, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18804058549567532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8119594145043247, \"precision\": 1.0, \"recall\": 0.18804058549567532, \"specificity\": 1.0, \"npv\": 0.4518863687401752, \"accuracy\": 0.5136252677726298, \"f1\": 0.3165558277913896, \"f2\": 0.2244970907718887, \"f0_5\": 0.5365957850768939, \"p4\": 0.4196854909787386, \"phi\": 0.2915012476052498}, {\"truth_threshold\": 24.6, \"match_probability\": 0.9999999606756014, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2258, \"tn\": 8049, \"fp\": 0, \"fn\": 9766, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18779108449767132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8122089155023287, \"precision\": 1.0, \"recall\": 0.18779108449767132, \"specificity\": 1.0, \"npv\": 0.45181027224249226, \"accuracy\": 0.5134758132815225, \"f1\": 0.3162022125752696, \"f2\": 0.22421257496921793, \"f0_5\": 0.5361892097264438, \"p4\": 0.41935821009083407, \"phi\": 0.29128326593130227}, {\"truth_threshold\": 24.62, \"match_probability\": 0.999999961216992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2252, \"tn\": 8049, \"fp\": 0, \"fn\": 9772, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18729208250166335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8127079174983367, \"precision\": 1.0, \"recall\": 0.18729208250166335, \"specificity\": 1.0, \"npv\": 0.4516581561079625, \"accuracy\": 0.5131769042993075, \"f1\": 0.31549453628467355, \"f2\": 0.22364344164614283, \"f0_5\": 0.5353746671738303, \"p4\": 0.41870270209588256, \"phi\": 0.29084703305401216}, {\"truth_threshold\": 24.64, \"match_probability\": 0.9999999617509291, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2250, \"tn\": 8049, \"fp\": 0, \"fn\": 9774, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18712574850299402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.812874251497006, \"precision\": 1.0, \"recall\": 0.18712574850299402, \"specificity\": 1.0, \"npv\": 0.4516074734893116, \"accuracy\": 0.5130772679719026, \"f1\": 0.31525851197982346, \"f2\": 0.22345370039327853, \"f0_5\": 0.5351027397260274, \"p4\": 0.4184839183945441, \"phi\": 0.29070154197429615}, {\"truth_threshold\": 24.66, \"match_probability\": 0.9999999622775153, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2249, \"tn\": 8049, \"fp\": 0, \"fn\": 9775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18704258150365935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8129574184963406, \"precision\": 1.0, \"recall\": 0.18704258150365935, \"specificity\": 1.0, \"npv\": 0.45158213644524237, \"accuracy\": 0.5130274498082, \"f1\": 0.31514047502277026, \"f2\": 0.22335882411361604, \"f0_5\": 0.5349666983824929, \"p4\": 0.41837447374572745, \"phi\": 0.29062878137179715}, {\"truth_threshold\": 24.68, \"match_probability\": 0.9999999627968519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2245, \"tn\": 8049, \"fp\": 0, \"fn\": 9779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18670991350632068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8132900864936793, \"precision\": 1.0, \"recall\": 0.18670991350632068, \"specificity\": 1.0, \"npv\": 0.45148081669284273, \"accuracy\": 0.5128281771533901, \"f1\": 0.3146681617492466, \"f2\": 0.2229792813015236, \"f0_5\": 0.5344220148543135, \"p4\": 0.4179363426229624, \"phi\": 0.29033763833592724}, {\"truth_threshold\": 24.7, \"match_probability\": 0.9999999633090386, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2240, \"tn\": 8049, \"fp\": 0, \"fn\": 9784, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18629407850964738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8137059214903526, \"precision\": 1.0, \"recall\": 0.18629407850964738, \"specificity\": 1.0, \"npv\": 0.4513542309202041, \"accuracy\": 0.5125790863348777, \"f1\": 0.3140773976444195, \"f2\": 0.22250476795931343, \"f0_5\": 0.5337399923751429, \"p4\": 0.4173878837930364, \"phi\": 0.2899734824612589}, {\"truth_threshold\": 24.740000000000002, \"match_probability\": 0.9999999643123548, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2237, \"tn\": 8049, \"fp\": 0, \"fn\": 9787, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18604457751164338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8139554224883566, \"precision\": 1.0, \"recall\": 0.18604457751164338, \"specificity\": 1.0, \"npv\": 0.45127831352321146, \"accuracy\": 0.5124296318437702, \"f1\": 0.31372274034078956, \"f2\": 0.2222200147020841, \"f0_5\": 0.5333301544917032, \"p4\": 0.41705838341791557, \"phi\": 0.2897548673958607}, {\"truth_threshold\": 24.76, \"match_probability\": 0.9999999648036773, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2233, \"tn\": 8049, \"fp\": 0, \"fn\": 9791, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18571190951430472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8142880904856953, \"precision\": 1.0, \"recall\": 0.18571190951430472, \"specificity\": 1.0, \"npv\": 0.45117713004484306, \"accuracy\": 0.5122303591889603, \"f1\": 0.3132496317598373, \"f2\": 0.22184029088597032, \"f0_5\": 0.5327829738499714, \"p4\": 0.41661855235423834, \"phi\": 0.2894632383391915}, {\"truth_threshold\": 24.78, \"match_probability\": 0.9999999652882353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2224, \"tn\": 8049, \"fp\": 0, \"fn\": 9800, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18496340652029275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8150365934797072, \"precision\": 1.0, \"recall\": 0.18496340652029275, \"specificity\": 1.0, \"npv\": 0.4509496330326629, \"accuracy\": 0.5117819957156379, \"f1\": 0.3121841661987647, \"f2\": 0.22098569157392686, \"f0_5\": 0.5315487571701721, \"p4\": 0.4156268474360681, \"phi\": 0.28880647550703786}, {\"truth_threshold\": 24.8, \"match_probability\": 0.9999999657661225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2217, \"tn\": 8049, \"fp\": 0, \"fn\": 9807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1843812375249501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8156187624750499, \"precision\": 1.0, \"recall\": 0.1843812375249501, \"specificity\": 1.0, \"npv\": 0.45077284946236557, \"accuracy\": 0.5114332685697205, \"f1\": 0.31135453970929006, \"f2\": 0.22032079184306244, \"f0_5\": 0.5305858701895463, \"p4\": 0.4148535166742287, \"phi\": 0.2882950846381516}, {\"truth_threshold\": 24.84, \"match_probability\": 0.9999999667022497, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2214, \"tn\": 8049, \"fp\": 0, \"fn\": 9810, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18413173652694612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8158682634730539, \"precision\": 1.0, \"recall\": 0.18413173652694612, \"specificity\": 1.0, \"npv\": 0.45069712749874014, \"accuracy\": 0.511283814078613, \"f1\": 0.3109987357774968, \"f2\": 0.22003577817531306, \"f0_5\": 0.5301724137931034, \"p4\": 0.4145215499794158, \"phi\": 0.2880757621426167}, {\"truth_threshold\": 24.86, \"match_probability\": 0.9999999671606695, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2209, \"tn\": 8049, \"fp\": 0, \"fn\": 9815, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18371590153027278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8162840984697272, \"precision\": 1.0, \"recall\": 0.18371590153027278, \"specificity\": 1.0, \"npv\": 0.4505709807433945, \"accuracy\": 0.5110347232601007, \"f1\": 0.31040539591091126, \"f2\": 0.21956067985289732, \"f0_5\": 0.5294822627037392, \"p4\": 0.41396755080873504, \"phi\": 0.28771001708430644}, {\"truth_threshold\": 24.900000000000002, \"match_probability\": 0.9999999680586628, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2203, \"tn\": 8049, \"fp\": 0, \"fn\": 9821, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18321689953426482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8167831004657352, \"precision\": 1.0, \"recall\": 0.18321689953426482, \"specificity\": 1.0, \"npv\": 0.45041969781757135, \"accuracy\": 0.5107358142778857, \"f1\": 0.30969283756238136, \"f2\": 0.21899043718562994, \"f0_5\": 0.5286523325014398, \"p4\": 0.4133015579035302, \"phi\": 0.2872707790975196}, {\"truth_threshold\": 24.92, \"match_probability\": 0.9999999684984086, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2200, \"tn\": 8049, \"fp\": 0, \"fn\": 9824, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18296739853626082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8170326014637392, \"precision\": 1.0, \"recall\": 0.18296739853626082, \"specificity\": 1.0, \"npv\": 0.4503440944441336, \"accuracy\": 0.5105863597867782, \"f1\": 0.3093363329583802, \"f2\": 0.2187052648321934, \"f0_5\": 0.5282366500192086, \"p4\": 0.41296807152646736, \"phi\": 0.2870510188217615}, {\"truth_threshold\": 24.94, \"match_probability\": 0.9999999689321003, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2196, \"tn\": 8049, \"fp\": 0, \"fn\": 9828, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18263473053892215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8173652694610778, \"precision\": 1.0, \"recall\": 0.18263473053892215, \"specificity\": 1.0, \"npv\": 0.4502433294176875, \"accuracy\": 0.5103870871319683, \"f1\": 0.30886075949367087, \"f2\": 0.21832498210450965, \"f0_5\": 0.527681660899654, \"p4\": 0.41252291349364534, \"phi\": 0.28675785803556725}, {\"truth_threshold\": 24.96, \"match_probability\": 0.9999999693598213, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2188, \"tn\": 8049, \"fp\": 0, \"fn\": 9836, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18196939454424485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8180306054557551, \"precision\": 1.0, \"recall\": 0.18196939454424485, \"specificity\": 1.0, \"npv\": 0.450041934582052, \"accuracy\": 0.5099885418223484, \"f1\": 0.30790880945679705, \"f2\": 0.21756423514437992, \"f0_5\": 0.5265691182133231, \"p4\": 0.4116308446651604, \"phi\": 0.28617102990242854}, {\"truth_threshold\": 24.98, \"match_probability\": 0.9999999697816536, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2182, \"tn\": 8049, \"fp\": 0, \"fn\": 9842, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18147039254823685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8185296074517632, \"precision\": 1.0, \"recall\": 0.18147039254823685, \"specificity\": 1.0, \"npv\": 0.449891006651389, \"accuracy\": 0.5096896328401335, \"f1\": 0.30719414331972406, \"f2\": 0.21699351605075778, \"f0_5\": 0.5257324595219738, \"p4\": 0.41096025325640373, \"phi\": 0.2857304631658112}, {\"truth_threshold\": 25.0, \"match_probability\": 0.9999999701976785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2181, \"tn\": 8049, \"fp\": 0, \"fn\": 9843, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1813872255489022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8186127744510978, \"precision\": 1.0, \"recall\": 0.1813872255489022, \"specificity\": 1.0, \"npv\": 0.44986586183769284, \"accuracy\": 0.509639814676431, \"f1\": 0.3070749736008448, \"f2\": 0.2168983829584104, \"f0_5\": 0.5255928282244072, \"p4\": 0.41084835927928537, \"phi\": 0.28565699807269707}, {\"truth_threshold\": 25.02, \"match_probability\": 0.9999999706079759, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2179, \"tn\": 8049, \"fp\": 0, \"fn\": 9845, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18122089155023285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8187791084497671, \"precision\": 1.0, \"recall\": 0.18122089155023285, \"specificity\": 1.0, \"npv\": 0.4498155806415558, \"accuracy\": 0.5095401783490261, \"f1\": 0.30683658382031964, \"f2\": 0.21670810542018895, \"f0_5\": 0.5253134040501446, \"p4\": 0.4106244607542403, \"phi\": 0.28551003582544765}, {\"truth_threshold\": 25.04, \"match_probability\": 0.9999999710126245, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2175, \"tn\": 8049, \"fp\": 0, \"fn\": 9849, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18088822355289422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8191117764471058, \"precision\": 1.0, \"recall\": 0.18088822355289422, \"specificity\": 1.0, \"npv\": 0.449715051961113, \"accuracy\": 0.5093409056942161, \"f1\": 0.3063596027889288, \"f2\": 0.21632750492331562, \"f0_5\": 0.5247539085118703, \"p4\": 0.4101762207338183, \"phi\": 0.2852159828169579}, {\"truth_threshold\": 25.060000000000002, \"match_probability\": 0.9999999714117023, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2174, \"tn\": 8049, \"fp\": 0, \"fn\": 9850, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18080505655355955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8191949434464405, \"precision\": 1.0, \"recall\": 0.18080505655355955, \"specificity\": 1.0, \"npv\": 0.44968992681155373, \"accuracy\": 0.5092910875305137, \"f1\": 0.3062403155373996, \"f2\": 0.21623234533518998, \"f0_5\": 0.5246138996138996, \"p4\": 0.4100640682998379, \"phi\": 0.28514244273473044}, {\"truth_threshold\": 25.080000000000002, \"match_probability\": 0.9999999718052858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2167, \"tn\": 8049, \"fp\": 0, \"fn\": 9857, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1802228875582169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8197771124417831, \"precision\": 1.0, \"recall\": 0.1802228875582169, \"specificity\": 1.0, \"npv\": 0.44951412934212, \"accuracy\": 0.5089423603845962, \"f1\": 0.30540483404974983, \"f2\": 0.2155661221972425, \"f0_5\": 0.5236323216702107, \"p4\": 0.4092779632972891, \"phi\": 0.2846273605756387}, {\"truth_threshold\": 25.1, \"match_probability\": 0.9999999721934507, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2166, \"tn\": 8049, \"fp\": 0, \"fn\": 9858, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.18013972055888225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8198602794411177, \"precision\": 1.0, \"recall\": 0.18013972055888225, \"specificity\": 1.0, \"npv\": 0.44948902663762774, \"accuracy\": 0.5088925422208938, \"f1\": 0.30528541226215644, \"f2\": 0.21547093231467113, \"f0_5\": 0.523491879350348, \"p4\": 0.40916551400529766, \"phi\": 0.2845537342098786}, {\"truth_threshold\": 25.12, \"match_probability\": 0.9999999725762717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2162, \"tn\": 8049, \"fp\": 0, \"fn\": 9862, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17980705256154358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8201929474384564, \"precision\": 1.0, \"recall\": 0.17980705256154358, \"specificity\": 1.0, \"npv\": 0.44938864385014793, \"accuracy\": 0.5086932695660837, \"f1\": 0.30480755674608767, \"f2\": 0.2150901349038959, \"f0_5\": 0.5229295665634675, \"p4\": 0.4087153444023278, \"phi\": 0.2842591203555734}, {\"truth_threshold\": 25.14, \"match_probability\": 0.9999999729538223, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2160, \"tn\": 8049, \"fp\": 0, \"fn\": 9864, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17964071856287425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8203592814371258, \"precision\": 1.0, \"recall\": 0.17964071856287425, \"specificity\": 1.0, \"npv\": 0.4493384692681293, \"accuracy\": 0.5085936332386788, \"f1\": 0.30456852791878175, \"f2\": 0.2148997134670487, \"f0_5\": 0.5226480836236934, \"p4\": 0.4084900357917254, \"phi\": 0.2841117482563309}, {\"truth_threshold\": 25.16, \"match_probability\": 0.999999973326175, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2156, \"tn\": 8049, \"fp\": 0, \"fn\": 9868, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1793080505655356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8206919494344644, \"precision\": 1.0, \"recall\": 0.1793080505655356, \"specificity\": 1.0, \"npv\": 0.4492381537087682, \"accuracy\": 0.5083943605838689, \"f1\": 0.30409026798307476, \"f2\": 0.2145188251213882, \"f0_5\": 0.5220844633862843, \"p4\": 0.4080389699553337, \"phi\": 0.2838168733200682}, {\"truth_threshold\": 25.18, \"match_probability\": 0.9999999736934014, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2148, \"tn\": 8049, \"fp\": 0, \"fn\": 9876, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17864271457085829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8213572854291418, \"precision\": 1.0, \"recall\": 0.17864271457085829, \"specificity\": 1.0, \"npv\": 0.4490376569037657, \"accuracy\": 0.507995815274249, \"f1\": 0.30313293818797626, \"f2\": 0.21375686649152137, \"f0_5\": 0.5209545983701979, \"p4\": 0.4071350382173637, \"phi\": 0.28322659828099905}, {\"truth_threshold\": 25.2, \"match_probability\": 0.9999999740555722, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2140, \"tn\": 8049, \"fp\": 0, \"fn\": 9884, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17797737857618098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.822022621423819, \"precision\": 1.0, \"recall\": 0.17797737857618098, \"specificity\": 1.0, \"npv\": 0.44883733898399597, \"accuracy\": 0.5075972699646291, \"f1\": 0.30217452696978253, \"f2\": 0.21299466518034876, \"f0_5\": 0.5198212203653323, \"p4\": 0.406228695667001, \"phi\": 0.28263561877350196}, {\"truth_threshold\": 25.22, \"match_probability\": 0.9999999744127567, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2138, \"tn\": 8049, \"fp\": 0, \"fn\": 9886, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17781104457751165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8221889554224884, \"precision\": 1.0, \"recall\": 0.17781104457751165, \"specificity\": 1.0, \"npv\": 0.44878728742681906, \"accuracy\": 0.5074976336372241, \"f1\": 0.30193475497811045, \"f2\": 0.21280407692001432, \"f0_5\": 0.5195373250388803, \"p4\": 0.40600173182458593, \"phi\": 0.2824877632225344}, {\"truth_threshold\": 25.240000000000002, \"match_probability\": 0.9999999747650239, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2135, \"tn\": 8049, \"fp\": 0, \"fn\": 9889, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17756154357950765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8224384564204924, \"precision\": 1.0, \"recall\": 0.17756154357950765, \"specificity\": 1.0, \"npv\": 0.4487122310179507, \"accuracy\": 0.5073481791461166, \"f1\": 0.30157496998375594, \"f2\": 0.21251816607274393, \"f0_5\": 0.5191110678856253, \"p4\": 0.4056610015828097, \"phi\": 0.2822658965630669}, {\"truth_threshold\": 25.26, \"match_probability\": 0.9999999751124412, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2134, \"tn\": 8049, \"fp\": 0, \"fn\": 9890, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.177478376580173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.822521623419827, \"precision\": 1.0, \"recall\": 0.177478376580173, \"specificity\": 1.0, \"npv\": 0.44868721779363396, \"accuracy\": 0.5072983609824142, \"f1\": 0.30145500776945894, \"f2\": 0.212422854867609, \"f0_5\": 0.5189688715953308, \"p4\": 0.40554734887292376, \"phi\": 0.2821919187473105}, {\"truth_threshold\": 25.28, \"match_probability\": 0.9999999754550756, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2123, \"tn\": 8049, \"fp\": 0, \"fn\": 9901, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17656353958749169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8234364604125083, \"precision\": 1.0, \"recall\": 0.17656353958749169, \"specificity\": 1.0, \"npv\": 0.4484122562674095, \"accuracy\": 0.5067503611816868, \"f1\": 0.3001343040927405, \"f2\": 0.21137418108683964, \"f0_5\": 0.5174010528368103, \"p4\": 0.4042946538693857, \"phi\": 0.2813774247536345}, {\"truth_threshold\": 25.3, \"match_probability\": 0.9999999757929928, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2118, \"tn\": 8049, \"fp\": 0, \"fn\": 9906, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17614770459081835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8238522954091816, \"precision\": 1.0, \"recall\": 0.17614770459081835, \"specificity\": 1.0, \"npv\": 0.4482873851294904, \"accuracy\": 0.5065012703631744, \"f1\": 0.29953330504879083, \"f2\": 0.21089735930218664, \"f0_5\": 0.5166861826697893, \"p4\": 0.40372371687517683, \"phi\": 0.2810067506085573}, {\"truth_threshold\": 25.32, \"match_probability\": 0.9999999761262578, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2117, \"tn\": 8049, \"fp\": 0, \"fn\": 9907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1760645375914837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8239354624085163, \"precision\": 1.0, \"recall\": 0.1760645375914837, \"specificity\": 1.0, \"npv\": 0.44826241924704835, \"accuracy\": 0.506451452199472, \"f1\": 0.2994130542394456, \"f2\": 0.21080198355007668, \"f0_5\": 0.5165430411868046, \"p4\": 0.4036094142755168, \"phi\": 0.2809325818846425}, {\"truth_threshold\": 25.36, \"match_probability\": 0.9999999767790866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2113, \"tn\": 8049, \"fp\": 0, \"fn\": 9911, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17573186959414505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.824268130405855, \"precision\": 1.0, \"recall\": 0.17573186959414505, \"specificity\": 1.0, \"npv\": 0.44816258351893096, \"accuracy\": 0.506252179544662, \"f1\": 0.29893188087996037, \"f2\": 0.21042044255014042, \"f0_5\": 0.5159699159992186, \"p4\": 0.4031518190119537, \"phi\": 0.2806357936613288}, {\"truth_threshold\": 25.38, \"match_probability\": 0.9999999770987757, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2109, \"tn\": 8049, \"fp\": 0, \"fn\": 9915, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1753992015968064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8246007984031936, \"precision\": 1.0, \"recall\": 0.1753992015968064, \"specificity\": 1.0, \"npv\": 0.448062792251169, \"accuracy\": 0.506052906889852, \"f1\": 0.29845043515177244, \"f2\": 0.21003884075291307, \"f0_5\": 0.5153958944281525, \"p4\": 0.40269360671919985, \"phi\": 0.28033882361544354}, {\"truth_threshold\": 25.400000000000002, \"match_probability\": 0.9999999774140637, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2107, \"tn\": 8049, \"fp\": 0, \"fn\": 9917, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17523286759813705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.824767132401863, \"precision\": 1.0, \"recall\": 0.17523286759813705, \"specificity\": 1.0, \"npv\": 0.4480129132806412, \"accuracy\": 0.5059532705624471, \"f1\": 0.29820961007713537, \"f2\": 0.20984801705077386, \"f0_5\": 0.5151085468413847, \"p4\": 0.4024642686667629, \"phi\": 0.28019027020073745}, {\"truth_threshold\": 25.42, \"match_probability\": 0.9999999777250109, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2105, \"tn\": 8049, \"fp\": 0, \"fn\": 9919, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17506653359946772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8249334664005322, \"precision\": 1.0, \"recall\": 0.17506653359946772, \"specificity\": 1.0, \"npv\": 0.44796304541406945, \"accuracy\": 0.5058536342350421, \"f1\": 0.2979687168235544, \"f2\": 0.20965717814386167, \"f0_5\": 0.514820974369008, \"p4\": 0.40223477573217264, \"phi\": 0.28004167108004135}, {\"truth_threshold\": 25.44, \"match_probability\": 0.9999999780316773, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2102, \"tn\": 8049, \"fp\": 0, \"fn\": 9922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17481703260146375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8251829673985362, \"precision\": 1.0, \"recall\": 0.17481703260146375, \"specificity\": 1.0, \"npv\": 0.4478882644260197, \"accuracy\": 0.5057041797439347, \"f1\": 0.29760724904431546, \"f2\": 0.20937089127056854, \"f0_5\": 0.514389193422083, \"p4\": 0.4018902454688853, \"phi\": 0.2798186865167809}, {\"truth_threshold\": 25.46, \"match_probability\": 0.9999999783341216, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2094, \"tn\": 8049, \"fp\": 0, \"fn\": 9930, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17415169660678642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8258483033932136, \"precision\": 1.0, \"recall\": 0.17415169660678642, \"specificity\": 1.0, \"npv\": 0.4476889704655431, \"accuracy\": 0.5053056344343148, \"f1\": 0.2966425839354016, \"f2\": 0.20860729228930067, \"f0_5\": 0.513235294117647, \"p4\": 0.4009697867139391, \"phi\": 0.2792235551645309}, {\"truth_threshold\": 25.5, \"match_probability\": 0.9999999789265762, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2089, \"tn\": 8049, \"fp\": 0, \"fn\": 9935, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17373586161011312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8262641383898869, \"precision\": 1.0, \"recall\": 0.17373586161011312, \"specificity\": 1.0, \"npv\": 0.4475645017793594, \"accuracy\": 0.5050565436158023, \"f1\": 0.29603911287465456, \"f2\": 0.2081299192985952, \"f0_5\": 0.5125122669283612, \"p4\": 0.4003932313374867, \"phi\": 0.2788512225950211}, {\"truth_threshold\": 25.52, \"match_probability\": 0.9999999792167003, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2084, \"tn\": 8049, \"fp\": 0, \"fn\": 9940, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1733200266134398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8266799733865602, \"precision\": 1.0, \"recall\": 0.1733200266134398, \"specificity\": 1.0, \"npv\": 0.4474401022847296, \"accuracy\": 0.5048074527972899, \"f1\": 0.295435214062943, \"f2\": 0.20765245117576725, \"f0_5\": 0.5117878192534381, \"p4\": 0.3998156961065147, \"phi\": 0.27847859960131505}, {\"truth_threshold\": 25.54, \"match_probability\": 0.99999997950283, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2081, \"tn\": 8049, \"fp\": 0, \"fn\": 9943, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1730705256154358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8269294743845642, \"precision\": 1.0, \"recall\": 0.1730705256154358, \"specificity\": 1.0, \"npv\": 0.4473654957759004, \"accuracy\": 0.5046579983061824, \"f1\": 0.29507266926621767, \"f2\": 0.20736592462682105, \"f0_5\": 0.511352467072931, \"p4\": 0.39946870325648565, \"phi\": 0.2782548858441575}, {\"truth_threshold\": 25.560000000000002, \"match_probability\": 0.9999999797850206, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2078, \"tn\": 8049, \"fp\": 0, \"fn\": 9946, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1728210246174318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8271789753825682, \"precision\": 1.0, \"recall\": 0.1728210246174318, \"specificity\": 1.0, \"npv\": 0.44729091414281746, \"accuracy\": 0.5045085438150749, \"f1\": 0.2947099702169905, \"f2\": 0.20707936381392753, \"f0_5\": 0.5109166011014948, \"p4\": 0.3991213557432441, \"phi\": 0.27803106676094563}, {\"truth_threshold\": 25.580000000000002, \"match_probability\": 0.9999999800633262, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2073, \"tn\": 8049, \"fp\": 0, \"fn\": 9951, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1724051896207585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8275948103792415, \"precision\": 1.0, \"recall\": 0.1724051896207585, \"specificity\": 1.0, \"npv\": 0.44716666666666666, \"accuracy\": 0.5042594529965625, \"f1\": 0.29410512875079803, \"f2\": 0.20660168630030498, \"f0_5\": 0.5101890135853514, \"p4\": 0.3985416531191673, \"phi\": 0.27765780010428154}, {\"truth_threshold\": 25.6, \"match_probability\": 0.9999999803378004, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2068, \"tn\": 8049, \"fp\": 0, \"fn\": 9956, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17198935462408516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8280106453759148, \"precision\": 1.0, \"recall\": 0.17198935462408516, \"specificity\": 1.0, \"npv\": 0.44704248819772285, \"accuracy\": 0.5040103621780501, \"f1\": 0.29349985807550383, \"f2\": 0.20612391356351167, \"f0_5\": 0.5094599921166733, \"p4\": 0.3979609599597576, \"phi\": 0.2772842387058297}, {\"truth_threshold\": 25.62, \"match_probability\": 0.9999999806084956, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2063, \"tn\": 8049, \"fp\": 0, \"fn\": 9961, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17157351962741185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8284264803725881, \"precision\": 1.0, \"recall\": 0.17157351962741185, \"specificity\": 1.0, \"npv\": 0.4469183786785119, \"accuracy\": 0.5037612713595376, \"f1\": 0.29289415773408106, \"f2\": 0.20564604557507127, \"f0_5\": 0.5087295324521602, \"p4\": 0.397379272896662, \"phi\": 0.2769103811994934}, {\"truth_threshold\": 25.64, \"match_probability\": 0.9999999808754642, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2061, \"tn\": 8049, \"fp\": 0, \"fn\": 9963, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17140718562874252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8285928143712575, \"precision\": 1.0, \"recall\": 0.17140718562874252, \"specificity\": 1.0, \"npv\": 0.4468687541638907, \"accuracy\": 0.5036616350321327, \"f1\": 0.2926517571884984, \"f2\": 0.20545487170285304, \"f0_5\": 0.5084369449378331, \"p4\": 0.39714631902108166, \"phi\": 0.27676075497919667}, {\"truth_threshold\": 25.68, \"match_probability\": 0.9999999813984256, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2057, \"tn\": 8049, \"fp\": 0, \"fn\": 9967, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17107451763140386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8289254823685961, \"precision\": 1.0, \"recall\": 0.17107451763140386, \"specificity\": 1.0, \"npv\": 0.4467695381882771, \"accuracy\": 0.5034623623773228, \"f1\": 0.29216674952063065, \"f2\": 0.20507247821665703, \"f0_5\": 0.5078510764368951, \"p4\": 0.39667993170368926, \"phi\": 0.2764613593939749}, {\"truth_threshold\": 25.7, \"match_probability\": 0.999999981654519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2051, \"tn\": 8049, \"fp\": 0, \"fn\": 9973, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17057551563539589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8294244843646041, \"precision\": 1.0, \"recall\": 0.17057551563539589, \"specificity\": 1.0, \"npv\": 0.4466207968039063, \"accuracy\": 0.5031634533951078, \"f1\": 0.29143872113676733, \"f2\": 0.20449877360559954, \"f0_5\": 0.5069705358908444, \"p4\": 0.39597914854295685, \"phi\": 0.27601190682345156}, {\"truth_threshold\": 25.740000000000002, \"match_probability\": 0.9999999821561771, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2047, \"tn\": 8049, \"fp\": 0, \"fn\": 9977, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.17024284763805722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8297571523619428, \"precision\": 1.0, \"recall\": 0.17024284763805722, \"specificity\": 1.0, \"npv\": 0.4465216908909353, \"accuracy\": 0.5029641807402979, \"f1\": 0.290953023949968, \"f2\": 0.2041162275890952, \"f0_5\": 0.5063823471205224, \"p4\": 0.395511155761196, \"phi\": 0.2757120312743591}, {\"truth_threshold\": 25.76, \"match_probability\": 0.9999999824018383, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2044, \"tn\": 8049, \"fp\": 0, \"fn\": 9980, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16999334664005322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8300066533599467, \"precision\": 1.0, \"recall\": 0.16999334664005322, \"specificity\": 1.0, \"npv\": 0.44644739031560265, \"accuracy\": 0.5028147262491904, \"f1\": 0.2905885698038101, \"f2\": 0.2038292780215397, \"f0_5\": 0.505940594059406, \"p4\": 0.3951597378222144, \"phi\": 0.2754869978392218}, {\"truth_threshold\": 25.78, \"match_probability\": 0.9999999826441174, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2039, \"tn\": 8049, \"fp\": 0, \"fn\": 9985, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16957751164337992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8304224883566201, \"precision\": 1.0, \"recall\": 0.16957751164337992, \"specificity\": 1.0, \"npv\": 0.44632361095708106, \"accuracy\": 0.502565635430678, \"f1\": 0.28998080068264237, \"f2\": 0.2033509524284432, \"f0_5\": 0.505203171456888, \"p4\": 0.3945732326674077, \"phi\": 0.2751116997399234}, {\"truth_threshold\": 25.8, \"match_probability\": 0.9999999828830609, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2036, \"tn\": 8049, \"fp\": 0, \"fn\": 9988, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16932801064537592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.830671989354624, \"precision\": 1.0, \"recall\": 0.16932801064537592, \"specificity\": 1.0, \"npv\": 0.44624937628208683, \"accuracy\": 0.5024161809395705, \"f1\": 0.2896159317211949, \"f2\": 0.203063911274236, \"f0_5\": 0.5047600158667196, \"p4\": 0.3942208432045324, \"phi\": 0.2748863749580644}, {\"truth_threshold\": 25.82, \"match_probability\": 0.9999999831187149, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2034, \"tn\": 8049, \"fp\": 0, \"fn\": 9990, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1691616766467066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8308383233532934, \"precision\": 1.0, \"recall\": 0.1691616766467066, \"specificity\": 1.0, \"npv\": 0.44619990021619826, \"accuracy\": 0.5023165446121656, \"f1\": 0.2893725992317542, \"f2\": 0.20287253141831238, \"f0_5\": 0.5044642857142857, \"p4\": 0.3939857137798316, \"phi\": 0.2747360974465592}, {\"truth_threshold\": 25.84, \"match_probability\": 0.9999999833511245, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2031, \"tn\": 8049, \"fp\": 0, \"fn\": 9993, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1689121756487026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8310878243512974, \"precision\": 1.0, \"recall\": 0.1689121756487026, \"specificity\": 1.0, \"npv\": 0.44612570668440304, \"accuracy\": 0.5021670901210581, \"f1\": 0.2890074706510139, \"f2\": 0.20258543300017953, \"f0_5\": 0.5040202501488982, \"p4\": 0.3936327144126762, \"phi\": 0.27451058946583}, {\"truth_threshold\": 25.86, \"match_probability\": 0.9999999835803345, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2026, \"tn\": 8049, \"fp\": 0, \"fn\": 9998, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1684963406520293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8315036593479708, \"precision\": 1.0, \"recall\": 0.1684963406520293, \"specificity\": 1.0, \"npv\": 0.4460021056131213, \"accuracy\": 0.5019179993025457, \"f1\": 0.28839857651245554, \"f2\": 0.2021068592633973, \"f0_5\": 0.503279014308426, \"p4\": 0.3930435663287474, \"phi\": 0.274134497498784}, {\"truth_threshold\": 25.88, \"match_probability\": 0.9999999838063889, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2020, \"tn\": 8049, \"fp\": 0, \"fn\": 10004, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1679973386560213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8320026613439787, \"precision\": 1.0, \"recall\": 0.1679973386560213, \"specificity\": 1.0, \"npv\": 0.44585387470226556, \"accuracy\": 0.5016190903203308, \"f1\": 0.28766733124465965, \"f2\": 0.2015324447282305, \"f0_5\": 0.5023875845602865, \"p4\": 0.39233523824121536, \"phi\": 0.27368278056804335}, {\"truth_threshold\": 25.900000000000002, \"match_probability\": 0.9999999840293311, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2013, \"tn\": 8049, \"fp\": 0, \"fn\": 10011, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16741516966067865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8325848303393214, \"precision\": 1.0, \"recall\": 0.16741516966067865, \"specificity\": 1.0, \"npv\": 0.4456810631229236, \"accuracy\": 0.5012703631744134, \"f1\": 0.2868134216712973, \"f2\": 0.20086212057714184, \"f0_5\": 0.5013448894202033, \"p4\": 0.3915069859031493, \"phi\": 0.27315521374719515}, {\"truth_threshold\": 25.92, \"match_probability\": 0.999999984249204, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2004, \"tn\": 8049, \"fp\": 0, \"fn\": 10020, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16666666666666666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8333333333333334, \"precision\": 1.0, \"recall\": 0.16666666666666666, \"specificity\": 1.0, \"npv\": 0.44545907355138636, \"accuracy\": 0.500821999701091, \"f1\": 0.2857142857142857, \"f2\": 0.2, \"f0_5\": 0.5, \"p4\": 0.3904391166733365, \"phi\": 0.272476015321039}, {\"truth_threshold\": 25.94, \"match_probability\": 0.9999999844660499, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1996, \"tn\": 8049, \"fp\": 0, \"fn\": 10028, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16600133067198936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8339986693280107, \"precision\": 1.0, \"recall\": 0.16600133067198936, \"specificity\": 1.0, \"npv\": 0.4452619350555955, \"accuracy\": 0.5004234543914712, \"f1\": 0.28473609129814553, \"f2\": 0.19923341052463467, \"f0_5\": 0.4988004798080768, \"p4\": 0.3894870759188326, \"phi\": 0.2718714286511434}, {\"truth_threshold\": 25.96, \"match_probability\": 0.9999999846799104, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1989, \"tn\": 8049, \"fp\": 0, \"fn\": 10035, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16541916167664672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8345808383233533, \"precision\": 1.0, \"recall\": 0.16541916167664672, \"specificity\": 1.0, \"npv\": 0.4450895819508958, \"accuracy\": 0.5000747272455537, \"f1\": 0.28387925497752087, \"f2\": 0.1985624438454627, \"f0_5\": 0.49774774774774777, \"p4\": 0.3886518481909729, \"phi\": 0.27134175041324976}, {\"truth_threshold\": 25.98, \"match_probability\": 0.9999999848908265, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1986, \"tn\": 8049, \"fp\": 0, \"fn\": 10038, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16516966067864272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8348303393213573, \"precision\": 1.0, \"recall\": 0.16516966067864272, \"specificity\": 1.0, \"npv\": 0.44501575717366065, \"accuracy\": 0.49992527275444626, \"f1\": 0.28351177730192717, \"f2\": 0.19827482927998083, \"f0_5\": 0.4972956730769231, \"p4\": 0.3882932645510285, \"phi\": 0.2711145544027889}, {\"truth_threshold\": 26.02, \"match_probability\": 0.9999999853039877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1984, \"tn\": 8049, \"fp\": 0, \"fn\": 10040, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1650033266799734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8349966733200266, \"precision\": 1.0, \"recall\": 0.1650033266799734, \"specificity\": 1.0, \"npv\": 0.4449665542594947, \"accuracy\": 0.4998256364270413, \"f1\": 0.2832667047401485, \"f2\": 0.19808306709265175, \"f0_5\": 0.4969939879759519, \"p4\": 0.38805399857883127, \"phi\": 0.27096302647066356}, {\"truth_threshold\": 26.04, \"match_probability\": 0.9999999855063121, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1982, \"tn\": 8049, \"fp\": 0, \"fn\": 10042, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16483699268130406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.835163007318696, \"precision\": 1.0, \"recall\": 0.16483699268130406, \"specificity\": 1.0, \"npv\": 0.44491736222431044, \"accuracy\": 0.4997260000996363, \"f1\": 0.28302156218763386, \"f2\": 0.19789128958824234, \"f0_5\": 0.49669206094627105, \"p4\": 0.3878145641657642, \"phi\": 0.27081144728529066}, {\"truth_threshold\": 26.060000000000002, \"match_probability\": 0.9999999857058509, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1976, \"tn\": 8049, \"fp\": 0, \"fn\": 10048, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1643379906852961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8356620093147039, \"precision\": 1.0, \"recall\": 0.1643379906852961, \"specificity\": 1.0, \"npv\": 0.4447698513565784, \"accuracy\": 0.4994270911174214, \"f1\": 0.2822857142857143, \"f2\": 0.19731586515417798, \"f0_5\": 0.49578482537133683, \"p4\": 0.38709524795106187, \"phi\": 0.2703564012361052}, {\"truth_threshold\": 26.080000000000002, \"match_probability\": 0.9999999859026427, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1972, \"tn\": 8049, \"fp\": 0, \"fn\": 10052, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16400532268795742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8359946773120426, \"precision\": 1.0, \"recall\": 0.16400532268795742, \"specificity\": 1.0, \"npv\": 0.44467156510690015, \"accuracy\": 0.4992278184626115, \"f1\": 0.2817947985138611, \"f2\": 0.19693217224574577, \"f0_5\": 0.49517878666130977, \"p4\": 0.38661485732413137, \"phi\": 0.2700527791479218}, {\"truth_threshold\": 26.1, \"match_probability\": 0.9999999860967251, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1968, \"tn\": 8049, \"fp\": 0, \"fn\": 10056, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16367265469061876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8363273453093812, \"precision\": 1.0, \"recall\": 0.16367265469061876, \"specificity\": 1.0, \"npv\": 0.44457332228666113, \"accuracy\": 0.49902854580780154, \"f1\": 0.28130360205831906, \"f2\": 0.1965484180249281, \"f0_5\": 0.4945717732207479, \"p4\": 0.38613378732067755, \"phi\": 0.26974894969820706}, {\"truth_threshold\": 26.12, \"match_probability\": 0.9999999862881357, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1963, \"tn\": 8049, \"fp\": 0, \"fn\": 10061, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16325681969394545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8367431803060545, \"precision\": 1.0, \"recall\": 0.16325681969394545, \"specificity\": 1.0, \"npv\": 0.44445057979017116, \"accuracy\": 0.4987794549892891, \"f1\": 0.28068921141059555, \"f2\": 0.19606863900597296, \"f0_5\": 0.49381163211913864, \"p4\": 0.38553149157196653, \"phi\": 0.2693688700790674}, {\"truth_threshold\": 26.14, \"match_probability\": 0.999999986476911, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1960, \"tn\": 8049, \"fp\": 0, \"fn\": 10064, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16300731869594146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8369926813040586, \"precision\": 1.0, \"recall\": 0.16300731869594146, \"specificity\": 1.0, \"npv\": 0.44437696681941147, \"accuracy\": 0.4986300004981816, \"f1\": 0.2803203661327231, \"f2\": 0.19578072558734216, \"f0_5\": 0.49335481272654047, \"p4\": 0.38516960164052144, \"phi\": 0.26914066554771615}, {\"truth_threshold\": 26.18, \"match_probability\": 0.9999999868467006, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1957, \"tn\": 8049, \"fp\": 0, \"fn\": 10067, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16275781769793746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8372421823020625, \"precision\": 1.0, \"recall\": 0.16275781769793746, \"specificity\": 1.0, \"npv\": 0.4443033782291897, \"accuracy\": 0.4984805460070742, \"f1\": 0.279951362563479, \"f2\": 0.19549277765568498, \"f0_5\": 0.4928974410638727, \"p4\": 0.3848073263688972, \"phi\": 0.2689123430346852}, {\"truth_threshold\": 26.2, \"match_probability\": 0.9999999870277859, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1952, \"tn\": 8049, \"fp\": 0, \"fn\": 10072, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16234198270126413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8376580172987359, \"precision\": 1.0, \"recall\": 0.16234198270126413, \"specificity\": 1.0, \"npv\": 0.4441807847249048, \"accuracy\": 0.49823145518856177, \"f1\": 0.27933600457927876, \"f2\": 0.19501278772378516, \"f0_5\": 0.49213392496974584, \"p4\": 0.3842026757557545, \"phi\": 0.26853154241177035}, {\"truth_threshold\": 26.22, \"match_probability\": 0.9999999872063782, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1946, \"tn\": 8049, \"fp\": 0, \"fn\": 10078, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16184298070525616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8381570192947438, \"precision\": 1.0, \"recall\": 0.16184298070525616, \"specificity\": 1.0, \"npv\": 0.44403376179180226, \"accuracy\": 0.49793254620634686, \"f1\": 0.27859699355762346, \"f2\": 0.1944366731945166, \"f0_5\": 0.4912156704361874, \"p4\": 0.3834756739050726, \"phi\": 0.2680741456055637}, {\"truth_threshold\": 26.240000000000002, \"match_probability\": 0.9999999873825117, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1943, \"tn\": 8049, \"fp\": 0, \"fn\": 10081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16159347970725216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8384065202927479, \"precision\": 1.0, \"recall\": 0.16159347970725216, \"specificity\": 1.0, \"npv\": 0.44396028681742966, \"accuracy\": 0.4977830917152394, \"f1\": 0.278227249946302, \"f2\": 0.1941485641199864, \"f0_5\": 0.4907557082238836, \"p4\": 0.3831115897254746, \"phi\": 0.2678452680161779}, {\"truth_threshold\": 26.26, \"match_probability\": 0.9999999875562204, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1937, \"tn\": 8049, \"fp\": 0, \"fn\": 10087, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1610944777112442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8389055222887558, \"precision\": 1.0, \"recall\": 0.1610944777112442, \"specificity\": 1.0, \"npv\": 0.4438134097926775, \"accuracy\": 0.49748418273302447, \"f1\": 0.27748728601103073, \"f2\": 0.19357224232006875, \"f0_5\": 0.48983410884078493, \"p4\": 0.3823822507915971, \"phi\": 0.2673871527426061}, {\"truth_threshold\": 26.28, \"match_probability\": 0.9999999877275376, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1936, \"tn\": 8049, \"fp\": 0, \"fn\": 10088, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16101131071190952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8389886892880905, \"precision\": 1.0, \"recall\": 0.16101131071190952, \"specificity\": 1.0, \"npv\": 0.44378893973645034, \"accuracy\": 0.497434364569322, \"f1\": 0.27736389684813756, \"f2\": 0.1934761752478414, \"f0_5\": 0.48968029138000807, \"p4\": 0.3822605422087959, \"phi\": 0.26731075336846155}, {\"truth_threshold\": 26.3, \"match_probability\": 0.9999999878964962, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1935, \"tn\": 8049, \"fp\": 0, \"fn\": 10089, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16092814371257486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8390718562874252, \"precision\": 1.0, \"recall\": 0.16092814371257486, \"specificity\": 1.0, \"npv\": 0.44376447237843203, \"accuracy\": 0.49738454640561947, \"f1\": 0.27724049000644746, \"f2\": 0.1933801043353121, \"f0_5\": 0.4895264116575592, \"p4\": 0.38213879008981017, \"phi\": 0.2672343405804188}, {\"truth_threshold\": 26.32, \"match_probability\": 0.9999999880631287, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1932, \"tn\": 8049, \"fp\": 0, \"fn\": 10092, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.16067864271457086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8393213572854291, \"precision\": 1.0, \"recall\": 0.16067864271457086, \"specificity\": 1.0, \"npv\": 0.44369108648916816, \"accuracy\": 0.49723509191451204, \"f1\": 0.2768701633705933, \"f2\": 0.19309186855361, \"f0_5\": 0.4890643985419198, \"p4\": 0.38177327221197127, \"phi\": 0.26700502160377587}, {\"truth_threshold\": 26.34, \"match_probability\": 0.9999999882274672, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1928, \"tn\": 8049, \"fp\": 0, \"fn\": 10096, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1603459747172322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8396540252827678, \"precision\": 1.0, \"recall\": 0.1603459747172322, \"specificity\": 1.0, \"npv\": 0.443593276384679, \"accuracy\": 0.4970358192597021, \"f1\": 0.2763761467889908, \"f2\": 0.19270750039980808, \"f0_5\": 0.488447507093636, \"p4\": 0.3812853036897408, \"phi\": 0.2666990743889298}, {\"truth_threshold\": 26.36, \"match_probability\": 0.9999999883895432, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1922, \"tn\": 8049, \"fp\": 0, \"fn\": 10102, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15984697272122422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8401530272787758, \"precision\": 1.0, \"recall\": 0.15984697272122422, \"specificity\": 1.0, \"npv\": 0.4434466420582888, \"accuracy\": 0.4967369102774872, \"f1\": 0.27563459056360246, \"f2\": 0.19213083290015595, \"f0_5\": 0.4875202922077922, \"p4\": 0.38055203689733025, \"phi\": 0.26623974777709236}, {\"truth_threshold\": 26.38, \"match_probability\": 0.9999999885493878, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1919, \"tn\": 8049, \"fp\": 0, \"fn\": 10105, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15959747172322022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8404025282767797, \"precision\": 1.0, \"recall\": 0.15959747172322022, \"specificity\": 1.0, \"npv\": 0.4433733612427013, \"accuracy\": 0.4965874557863797, \"f1\": 0.27526357311912786, \"f2\": 0.19184244726582025, \"f0_5\": 0.4870558375634518, \"p4\": 0.3801848104043127, \"phi\": 0.266009901100995}, {\"truth_threshold\": 26.400000000000002, \"match_probability\": 0.9999999887070317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1912, \"tn\": 8049, \"fp\": 0, \"fn\": 10112, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1590153027278776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8409846972721224, \"precision\": 1.0, \"recall\": 0.1590153027278776, \"specificity\": 1.0, \"npv\": 0.4432024668245141, \"accuracy\": 0.4962387286404623, \"f1\": 0.2743972445464983, \"f2\": 0.19116941289393696, \"f0_5\": 0.4859699064660431, \"p4\": 0.3793264051826453, \"phi\": 0.26547311432957243}, {\"truth_threshold\": 26.42, \"match_probability\": 0.9999999888625053, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1907, \"tn\": 8049, \"fp\": 0, \"fn\": 10117, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15859946773120426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8414005322687957, \"precision\": 1.0, \"recall\": 0.15859946773120426, \"specificity\": 1.0, \"npv\": 0.44308048001761535, \"accuracy\": 0.4959896378219499, \"f1\": 0.27377790539085495, \"f2\": 0.1906885586864788, \"f0_5\": 0.48519234683492773, \"p4\": 0.3787119310380765, \"phi\": 0.2650892836251218}, {\"truth_threshold\": 26.44, \"match_probability\": 0.9999999890158385, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1903, \"tn\": 8049, \"fp\": 0, \"fn\": 10121, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1582667997338656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8417332002661344, \"precision\": 1.0, \"recall\": 0.1582667997338656, \"specificity\": 1.0, \"npv\": 0.44298293891029167, \"accuracy\": 0.4957903651671399, \"f1\": 0.2732821138795146, \"f2\": 0.19030380607612152, \"f0_5\": 0.48456915868812384, \"p4\": 0.3782195522058398, \"phi\": 0.26478197083267274}, {\"truth_threshold\": 26.46, \"match_probability\": 0.9999999891670607, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1901, \"tn\": 8049, \"fp\": 0, \"fn\": 10123, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15810046573519626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8418995342648037, \"precision\": 1.0, \"recall\": 0.15810046573519626, \"specificity\": 1.0, \"npv\": 0.4429341844596082, \"accuracy\": 0.495690728839735, \"f1\": 0.27303411131059246, \"f2\": 0.19011140668440107, \"f0_5\": 0.4842571836152435, \"p4\": 0.37797309559803965, \"phi\": 0.26462823139851005}, {\"truth_threshold\": 26.48, \"match_probability\": 0.9999999893162009, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1899, \"tn\": 8049, \"fp\": 0, \"fn\": 10125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15793413173652696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8420658682634731, \"precision\": 1.0, \"recall\": 0.15793413173652696, \"specificity\": 1.0, \"npv\": 0.44288544073951797, \"accuracy\": 0.49559109251233, \"f1\": 0.2727860374919198, \"f2\": 0.18991899189918993, \"f0_5\": 0.48394495412844035, \"p4\": 0.37772646052879155, \"phi\": 0.264474436462099}, {\"truth_threshold\": 26.5, \"match_probability\": 0.9999999894632879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1895, \"tn\": 8049, \"fp\": 0, \"fn\": 10129, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1576014637391883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8423985362608117, \"precision\": 1.0, \"recall\": 0.1576014637391883, \"specificity\": 1.0, \"npv\": 0.44278798547695014, \"accuracy\": 0.49539181985752007, \"f1\": 0.27228967598247, \"f2\": 0.18953411614090537, \"f0_5\": 0.4833197306672108, \"p4\": 0.3772326540022495, \"phi\": 0.2641666796499774}, {\"truth_threshold\": 26.52, \"match_probability\": 0.99999998960835, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1889, \"tn\": 8049, \"fp\": 0, \"fn\": 10135, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1571024617431803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8428975382568197, \"precision\": 1.0, \"recall\": 0.1571024617431803, \"specificity\": 1.0, \"npv\": 0.4426418829740431, \"accuracy\": 0.49509291087530516, \"f1\": 0.2715445985768706, \"f2\": 0.18895668700610183, \"f0_5\": 0.4823799795709908, \"p4\": 0.37649059946648217, \"phi\": 0.2637046254540464}, {\"truth_threshold\": 26.54, \"match_probability\": 0.9999999897514149, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1881, \"tn\": 8049, \"fp\": 0, \"fn\": 10143, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.156437125748503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.843562874251497, \"precision\": 1.0, \"recall\": 0.156437125748503, \"specificity\": 1.0, \"npv\": 0.44244722955145116, \"accuracy\": 0.49469436556568525, \"f1\": 0.27055016181229774, \"f2\": 0.18818656582027732, \"f0_5\": 0.48112338858195214, \"p4\": 0.37549867260592784, \"phi\": 0.2630877665084736}, {\"truth_threshold\": 26.560000000000002, \"match_probability\": 0.9999999898925103, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1876, \"tn\": 8049, \"fp\": 0, \"fn\": 10148, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15602129075182966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8439787092481703, \"precision\": 1.0, \"recall\": 0.15602129075182966, \"specificity\": 1.0, \"npv\": 0.44232565807550694, \"accuracy\": 0.4944452747471728, \"f1\": 0.2699280575539568, \"f2\": 0.18770511486432404, \"f0_5\": 0.4803359278984023, \"p4\": 0.37487724880621476, \"phi\": 0.2627017702749509}, {\"truth_threshold\": 26.580000000000002, \"match_probability\": 0.9999999900316631, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1873, \"tn\": 8049, \"fp\": 0, \"fn\": 10151, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1557717897538257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8442282102461743, \"precision\": 1.0, \"recall\": 0.1557717897538257, \"specificity\": 1.0, \"npv\": 0.44225274725274727, \"accuracy\": 0.4942958202560654, \"f1\": 0.2695545801252069, \"f2\": 0.18741619804278653, \"f0_5\": 0.4798626767780283, \"p4\": 0.3745038498936756, \"phi\": 0.2624700020251967}, {\"truth_threshold\": 26.6, \"match_probability\": 0.9999999901689001, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1867, \"tn\": 8049, \"fp\": 0, \"fn\": 10157, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1552727877578177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8447272122421823, \"precision\": 1.0, \"recall\": 0.1552727877578177, \"specificity\": 1.0, \"npv\": 0.4421069976930682, \"accuracy\": 0.4939969112738504, \"f1\": 0.2688071413145202, \"f2\": 0.18683826031263134, \"f0_5\": 0.47891442643135645, \"p4\": 0.37375582260124596, \"phi\": 0.2620060801184617}, {\"truth_threshold\": 26.62, \"match_probability\": 0.9999999903042477, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1864, \"tn\": 8049, \"fp\": 0, \"fn\": 10160, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1550232867598137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8449767132401863, \"precision\": 1.0, \"recall\": 0.1550232867598137, \"specificity\": 1.0, \"npv\": 0.44203415893239606, \"accuracy\": 0.493847456782743, \"f1\": 0.2684331797235023, \"f2\": 0.18654923939151322, \"f0_5\": 0.4784394250513347, \"p4\": 0.3733811924815957, \"phi\": 0.2617739257027138}, {\"truth_threshold\": 26.64, \"match_probability\": 0.999999990437732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1859, \"tn\": 8049, \"fp\": 0, \"fn\": 10165, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1546074517631404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8453925482368596, \"precision\": 1.0, \"recall\": 0.1546074517631404, \"specificity\": 1.0, \"npv\": 0.441912814318656, \"accuracy\": 0.49359836596423057, \"f1\": 0.2678095512497299, \"f2\": 0.18606746071464317, \"f0_5\": 0.4776464542651593, \"p4\": 0.37275589263619396, \"phi\": 0.2613867137466731}, {\"truth_threshold\": 26.68, \"match_probability\": 0.9999999906992127, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1855, \"tn\": 8049, \"fp\": 0, \"fn\": 10169, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15427478376580173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8457252162341983, \"precision\": 1.0, \"recall\": 0.15427478376580173, \"specificity\": 1.0, \"npv\": 0.44181578658469645, \"accuracy\": 0.4933990933094206, \"f1\": 0.26731032495136536, \"f2\": 0.1856819683289624, \"f0_5\": 0.47701090310635674, \"p4\": 0.3722548257402098, \"phi\": 0.2610766840215182}, {\"truth_threshold\": 26.72, \"match_probability\": 0.9999999909535432, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1851, \"tn\": 8049, \"fp\": 0, \"fn\": 10173, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15394211576846306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8460578842315369, \"precision\": 1.0, \"recall\": 0.15394211576846306, \"specificity\": 1.0, \"npv\": 0.44171880144879816, \"accuracy\": 0.49319982065461065, \"f1\": 0.2668108108108108, \"f2\": 0.185296414199051, \"f0_5\": 0.4763743051266214, \"p4\": 0.3717530214557153, \"phi\": 0.260766422051877}, {\"truth_threshold\": 26.740000000000002, \"match_probability\": 0.9999999910780885, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1847, \"tn\": 8049, \"fp\": 0, \"fn\": 10177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15360944777112442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8463905522288756, \"precision\": 1.0, \"recall\": 0.15360944777112442, \"specificity\": 1.0, \"npv\": 0.4416218588829145, \"accuracy\": 0.49300054799980075, \"f1\": 0.2663110085790498, \"f2\": 0.18491079831007348, \"f0_5\": 0.47573665773748197, \"p4\": 0.37125047768850383, \"phi\": 0.260455926917899}, {\"truth_threshold\": 26.76, \"match_probability\": 0.9999999912009191, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1842, \"tn\": 8049, \"fp\": 0, \"fn\": 10182, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1531936127744511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8468063872255489, \"precision\": 1.0, \"recall\": 0.1531936127744511, \"specificity\": 1.0, \"npv\": 0.44150074049695576, \"accuracy\": 0.4927514571812883, \"f1\": 0.2656858502812635, \"f2\": 0.18442869157755618, \"f0_5\": 0.4749381188118812, \"p4\": 0.37062125487908354, \"phi\": 0.2600674787037473}, {\"truth_threshold\": 26.78, \"match_probability\": 0.9999999913220586, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1838, \"tn\": 8049, \"fp\": 0, \"fn\": 10186, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15286094477711243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8471390552228876, \"precision\": 1.0, \"recall\": 0.15286094477711243, \"specificity\": 1.0, \"npv\": 0.44140389361118726, \"accuracy\": 0.49255218452647836, \"f1\": 0.265185398932333, \"f2\": 0.18404293667641286, \"f0_5\": 0.47429810074318746, \"p4\": 0.370117039578953, \"phi\": 0.25975645556117005}, {\"truth_threshold\": 26.8, \"match_probability\": 0.9999999914415304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1835, \"tn\": 8049, \"fp\": 0, \"fn\": 10189, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15261144377910846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8473885562208916, \"precision\": 1.0, \"recall\": 0.15261144377910846, \"specificity\": 1.0, \"npv\": 0.441331286325255, \"accuracy\": 0.4924027300353709, \"f1\": 0.2648098708420521, \"f2\": 0.18375357994031763, \"f0_5\": 0.47381739310059906, \"p4\": 0.36973838843301465, \"phi\": 0.2595230332571432}, {\"truth_threshold\": 26.82, \"match_probability\": 0.9999999915593574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1832, \"tn\": 8049, \"fp\": 0, \"fn\": 10192, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15236194278110446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8476380572188955, \"precision\": 1.0, \"recall\": 0.15236194278110446, \"specificity\": 1.0, \"npv\": 0.44125870292198893, \"accuracy\": 0.49225327554426346, \"f1\": 0.2644341801385681, \"f2\": 0.18346418843134113, \"f0_5\": 0.47333608929309634, \"p4\": 0.3693593165728166, \"phi\": 0.259289477700628}, {\"truth_threshold\": 26.84, \"match_probability\": 0.9999999916755622, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1829, \"tn\": 8049, \"fp\": 0, \"fn\": 10195, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15211244178310046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8478875582168995, \"precision\": 1.0, \"recall\": 0.15211244178310046, \"specificity\": 1.0, \"npv\": 0.44118614338960754, \"accuracy\": 0.492103821053156, \"f1\": 0.26405832671623475, \"f2\": 0.18317476214321482, \"f0_5\": 0.47285418821096176, \"p4\": 0.3689798230989196, \"phi\": 0.25905578849325545}, {\"truth_threshold\": 26.86, \"match_probability\": 0.9999999917901672, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1826, \"tn\": 8049, \"fp\": 0, \"fn\": 10198, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15186294078509646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8481370592149036, \"precision\": 1.0, \"recall\": 0.15186294078509646, \"specificity\": 1.0, \"npv\": 0.44111360771633695, \"accuracy\": 0.49195436656204855, \"f1\": 0.26368231046931406, \"f2\": 0.1828853010696687, \"f0_5\": 0.47237168874172186, \"p4\": 0.3685999071093988, \"phi\": 0.2588219652350363}, {\"truth_threshold\": 26.88, \"match_probability\": 0.9999999919031943, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1824, \"tn\": 8049, \"fp\": 0, \"fn\": 10200, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15169660678642716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8483033932135728, \"precision\": 1.0, \"recall\": 0.15169660678642716, \"specificity\": 1.0, \"npv\": 0.441065263850074, \"accuracy\": 0.49185473023464354, \"f1\": 0.2634315424610052, \"f2\": 0.18269230769230768, \"f0_5\": 0.4720496894409938, \"p4\": 0.36834639460562607, \"phi\": 0.25866600839193465}, {\"truth_threshold\": 26.900000000000002, \"match_probability\": 0.9999999920146655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1820, \"tn\": 8049, \"fp\": 0, \"fn\": 10204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1513639387890885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8486360612109115, \"precision\": 1.0, \"recall\": 0.1513639387890885, \"specificity\": 1.0, \"npv\": 0.4409686079000712, \"accuracy\": 0.4916554575798336, \"f1\": 0.26292978907830106, \"f2\": 0.18230627454122927, \"f0_5\": 0.4714048901782014, \"p4\": 0.3678388039633096, \"phi\": 0.2583539149579428}, {\"truth_threshold\": 26.92, \"match_probability\": 0.999999992124602, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1819, \"tn\": 8049, \"fp\": 0, \"fn\": 10205, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15128077178975383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8487192282102461, \"precision\": 1.0, \"recall\": 0.15128077178975383, \"specificity\": 1.0, \"npv\": 0.44094445053139036, \"accuracy\": 0.4916056394161311, \"f1\": 0.2628043054251246, \"f2\": 0.18220975658619654, \"f0_5\": 0.4712435233160622, \"p4\": 0.36771178826580675, \"phi\": 0.2582758540645983}, {\"truth_threshold\": 26.94, \"match_probability\": 0.9999999922330249, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1817, \"tn\": 8049, \"fp\": 0, \"fn\": 10207, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1511144377910845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8488855622089155, \"precision\": 1.0, \"recall\": 0.1511144377910845, \"specificity\": 1.0, \"npv\": 0.44089614373356706, \"accuracy\": 0.49150600308872616, \"f1\": 0.2625532837222744, \"f2\": 0.1820167090737884, \"f0_5\": 0.47092058884511717, \"p4\": 0.36745761499038765, \"phi\": 0.25811968713090283}, {\"truth_threshold\": 26.96, \"match_probability\": 0.9999999923399552, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1807, \"tn\": 8049, \"fp\": 0, \"fn\": 10217, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15028276779773786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8497172322022621, \"precision\": 1.0, \"recall\": 0.15028276779773786, \"specificity\": 1.0, \"npv\": 0.4406547684222052, \"accuracy\": 0.4910078214517013, \"f1\": 0.26129708625551296, \"f2\": 0.18105123940444462, \"f0_5\": 0.4693018907126532, \"p4\": 0.3661839022009263, \"phi\": 0.2573379455924839}, {\"truth_threshold\": 26.98, \"match_probability\": 0.9999999924454133, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1805, \"tn\": 8049, \"fp\": 0, \"fn\": 10219, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.15011643379906853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8498835662009314, \"precision\": 1.0, \"recall\": 0.15011643379906853, \"specificity\": 1.0, \"npv\": 0.4406065250711627, \"accuracy\": 0.4909081851242963, \"f1\": 0.26104562875117504, \"f2\": 0.18085809903609146, \"f0_5\": 0.46897734358761173, \"p4\": 0.36592858845771203, \"phi\": 0.2571814150600366}, {\"truth_threshold\": 27.0, \"match_probability\": 0.9999999925494194, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1801, \"tn\": 8049, \"fp\": 0, \"fn\": 10223, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14978376580172986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8502162341982701, \"precision\": 1.0, \"recall\": 0.14978376580172986, \"specificity\": 1.0, \"npv\": 0.4405100700525394, \"accuracy\": 0.4907089124694864, \"f1\": 0.26054249547920433, \"f2\": 0.180471771850011, \"f0_5\": 0.46832743915123776, \"p4\": 0.36541738760221054, \"phi\": 0.2568681707920489}, {\"truth_threshold\": 27.02, \"match_probability\": 0.9999999926519938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1798, \"tn\": 8049, \"fp\": 0, \"fn\": 10226, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1495342648037259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8504657351962741, \"precision\": 1.0, \"recall\": 0.1495342648037259, \"specificity\": 1.0, \"npv\": 0.44043775649794803, \"accuracy\": 0.4905594579783789, \"f1\": 0.2601649544204891, \"f2\": 0.180181985809917, \"f0_5\": 0.4678393005828476, \"p4\": 0.36503348418309733, \"phi\": 0.2566330768036792}, {\"truth_threshold\": 27.04, \"match_probability\": 0.999999992753156, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1797, \"tn\": 8049, \"fp\": 0, \"fn\": 10227, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14945109780439123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8505489021956087, \"precision\": 1.0, \"recall\": 0.14945109780439123, \"specificity\": 1.0, \"npv\": 0.4404136572554169, \"accuracy\": 0.49050963981467643, \"f1\": 0.2600390709789451, \"f2\": 0.1800853827190187, \"f0_5\": 0.46767645221736415, \"p4\": 0.36490542042638147, \"phi\": 0.256554681432378}, {\"truth_threshold\": 27.080000000000002, \"match_probability\": 0.9999999929513212, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1796, \"tn\": 8049, \"fp\": 0, \"fn\": 10228, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14936793080505656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8506320691949435, \"precision\": 1.0, \"recall\": 0.14936793080505656, \"specificity\": 1.0, \"npv\": 0.4403895606499973, \"accuracy\": 0.49045982165097396, \"f1\": 0.25991316931982633, \"f2\": 0.17998877575563216, \"f0_5\": 0.4675135360266556, \"p4\": 0.3647773086371224, \"phi\": 0.2564762706810087}, {\"truth_threshold\": 27.1, \"match_probability\": 0.9999999930483625, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1793, \"tn\": 8049, \"fp\": 0, \"fn\": 10231, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14911842980705256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8508815701929474, \"precision\": 1.0, \"recall\": 0.14911842980705256, \"specificity\": 1.0, \"npv\": 0.44031728665207875, \"accuracy\": 0.4903103671598665, \"f1\": 0.2595353549974669, \"f2\": 0.17969893162821463, \"f0_5\": 0.4670243800791832, \"p4\": 0.3643926847292211, \"phi\": 0.2562409459911898}, {\"truth_threshold\": 27.12, \"match_probability\": 0.9999999931440678, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1788, \"tn\": 8049, \"fp\": 0, \"fn\": 10236, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14870259481037923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8512974051896207, \"precision\": 1.0, \"recall\": 0.14870259481037923, \"specificity\": 1.0, \"npv\": 0.4401968826907301, \"accuracy\": 0.49006127634135405, \"f1\": 0.25890529973935705, \"f2\": 0.17921578061101756, \"f0_5\": 0.4662077596996245, \"p4\": 0.36375068100831315, \"phi\": 0.2558484291207427}, {\"truth_threshold\": 27.14, \"match_probability\": 0.9999999932384555, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1781, \"tn\": 8049, \"fp\": 0, \"fn\": 10243, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1481204258150366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8518795741849634, \"precision\": 1.0, \"recall\": 0.1481204258150366, \"specificity\": 1.0, \"npv\": 0.4400284277279685, \"accuracy\": 0.48971254919543666, \"f1\": 0.25802245563201737, \"f2\": 0.17853920644786175, \"f0_5\": 0.4650616252350115, \"p4\": 0.3628498443767866, \"phi\": 0.255298253197682}, {\"truth_threshold\": 27.16, \"match_probability\": 0.9999999933315437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1778, \"tn\": 8049, \"fp\": 0, \"fn\": 10246, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1478709248170326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8521290751829674, \"precision\": 1.0, \"recall\": 0.1478709248170326, \"specificity\": 1.0, \"npv\": 0.43995627220552064, \"accuracy\": 0.4895630947043292, \"f1\": 0.2576438197362701, \"f2\": 0.17824918795364317, \"f0_5\": 0.46456939799331104, \"p4\": 0.3624630434137036, \"phi\": 0.255062229367824}, {\"truth_threshold\": 27.18, \"match_probability\": 0.9999999934233502, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1775, \"tn\": 8049, \"fp\": 0, \"fn\": 10249, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1476214238190286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8523785761809713, \"precision\": 1.0, \"recall\": 0.1476214238190286, \"specificity\": 1.0, \"npv\": 0.4398841403432069, \"accuracy\": 0.48941364021322176, \"f1\": 0.2572650192042902, \"f2\": 0.17795913456718332, \"f0_5\": 0.46407655302238027, \"p4\": 0.3620758042135337, \"phi\": 0.25482606442998257}, {\"truth_threshold\": 27.2, \"match_probability\": 0.9999999935138929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1773, \"tn\": 8049, \"fp\": 0, \"fn\": 10251, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1474550898203593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8525449101796407, \"precision\": 1.0, \"recall\": 0.1474550898203593, \"specificity\": 1.0, \"npv\": 0.4398360655737705, \"accuracy\": 0.48931400388581675, \"f1\": 0.25701239399869535, \"f2\": 0.1777657462551886, \"f0_5\": 0.4637476459510358, \"p4\": 0.36181740081358277, \"phi\": 0.2546685425320799}, {\"truth_threshold\": 27.22, \"match_probability\": 0.999999993603189, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1767, \"tn\": 8049, \"fp\": 0, \"fn\": 10257, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1469560878243513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8530439121756487, \"precision\": 1.0, \"recall\": 0.1469560878243513, \"specificity\": 1.0, \"npv\": 0.4396919042936742, \"accuracy\": 0.48901509490360184, \"f1\": 0.2562540787470089, \"f2\": 0.1771854882377715, \"f0_5\": 0.4627592708988058, \"p4\": 0.36104101663479954, \"phi\": 0.2541955981189239}, {\"truth_threshold\": 27.240000000000002, \"match_probability\": 0.9999999936912558, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1761, \"tn\": 8049, \"fp\": 0, \"fn\": 10263, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14645708582834333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8535429141716567, \"precision\": 1.0, \"recall\": 0.14645708582834333, \"specificity\": 1.0, \"npv\": 0.4395478374836173, \"accuracy\": 0.48871618592138694, \"f1\": 0.2554951033732318, \"f2\": 0.17660509055899873, \"f0_5\": 0.4617684078036501, \"p4\": 0.36026286554647124, \"phi\": 0.253722082917512}, {\"truth_threshold\": 27.26, \"match_probability\": 0.9999999937781102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1759, \"tn\": 8049, \"fp\": 0, \"fn\": 10265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.146290751829674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.853709248170326, \"precision\": 1.0, \"recall\": 0.146290751829674, \"specificity\": 1.0, \"npv\": 0.4394998361908922, \"accuracy\": 0.488616549593982, \"f1\": 0.25524196473917143, \"f2\": 0.17641159362150236, \"f0_5\": 0.4614375655823715, \"p4\": 0.3600030878785992, \"phi\": 0.253564117069794}, {\"truth_threshold\": 27.28, \"match_probability\": 0.9999999938637688, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1752, \"tn\": 8049, \"fp\": 0, \"fn\": 10272, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14570858283433133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8542914171656687, \"precision\": 1.0, \"recall\": 0.14570858283433133, \"specificity\": 1.0, \"npv\": 0.4393319141968233, \"accuracy\": 0.48826782244806455, \"f1\": 0.25435540069686413, \"f2\": 0.17573423206547906, \"f0_5\": 0.46027742749054223, \"p4\": 0.3590923091590457, \"phi\": 0.2530107322061916}, {\"truth_threshold\": 27.3, \"match_probability\": 0.9999999939482481, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1747, \"tn\": 8049, \"fp\": 0, \"fn\": 10277, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14529274783765803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.854707252162342, \"precision\": 1.0, \"recall\": 0.14529274783765803, \"specificity\": 1.0, \"npv\": 0.4392120484557459, \"accuracy\": 0.4880187316295521, \"f1\": 0.2537215888461259, \"f2\": 0.17525028589771885, \"f0_5\": 0.45944666526404376, \"p4\": 0.35844026516865574, \"phi\": 0.2526149746225309}, {\"truth_threshold\": 27.32, \"match_probability\": 0.9999999940315644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1744, \"tn\": 8049, \"fp\": 0, \"fn\": 10280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14504324683965403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.854956753160346, \"precision\": 1.0, \"recall\": 0.14504324683965403, \"specificity\": 1.0, \"npv\": 0.43914016040154946, \"accuracy\": 0.4878692771384447, \"f1\": 0.2533410807669959, \"f2\": 0.17495987158908508, \"f0_5\": 0.4589473684210526, \"p4\": 0.3580484415106812, \"phi\": 0.2523773260067695}, {\"truth_threshold\": 27.34, \"match_probability\": 0.9999999941137335, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1741, \"tn\": 8049, \"fp\": 0, \"fn\": 10283, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14479374584165003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8552062541583499, \"precision\": 1.0, \"recall\": 0.14479374584165003, \"specificity\": 1.0, \"npv\": 0.4390682958760637, \"accuracy\": 0.4877198226473372, \"f1\": 0.2529604068289139, \"f2\": 0.17466942231675261, \"f0_5\": 0.4584474404887297, \"p4\": 0.35765616871249284, \"phi\": 0.2521395312921105}, {\"truth_threshold\": 27.36, \"match_probability\": 0.9999999941947715, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1734, \"tn\": 8049, \"fp\": 0, \"fn\": 10290, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1442115768463074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8557884231536926, \"precision\": 1.0, \"recall\": 0.1442115768463074, \"specificity\": 1.0, \"npv\": 0.4389007034189432, \"accuracy\": 0.4873710955014198, \"f1\": 0.25207152202354993, \"f2\": 0.1739915713425647, \"f0_5\": 0.4572784810126582, \"p4\": 0.35673911335685793, \"phi\": 0.25158410625275857}, {\"truth_threshold\": 27.38, \"match_probability\": 0.9999999942746939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1732, \"tn\": 8049, \"fp\": 0, \"fn\": 10292, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14404524284763806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8559547571523619, \"precision\": 1.0, \"recall\": 0.14404524284763806, \"specificity\": 1.0, \"npv\": 0.4388528433564146, \"accuracy\": 0.4872714591740148, \"f1\": 0.2518173887758069, \"f2\": 0.1737978646544112, \"f0_5\": 0.45694385816800337, \"p4\": 0.3564766456746362, \"phi\": 0.2514252660248194}, {\"truth_threshold\": 27.400000000000002, \"match_probability\": 0.9999999943535158, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1731, \"tn\": 8049, \"fp\": 0, \"fn\": 10293, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1439620758483034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8560379241516967, \"precision\": 1.0, \"recall\": 0.1439620758483034, \"specificity\": 1.0, \"npv\": 0.4388289172391233, \"accuracy\": 0.48722164101031235, \"f1\": 0.25169029443838603, \"f2\": 0.1737010054789572, \"f0_5\": 0.45677644078530716, \"p4\": 0.35634533633983956, \"phi\": 0.25134582126625366}, {\"truth_threshold\": 27.42, \"match_probability\": 0.9999999944312526, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1719, \"tn\": 8049, \"fp\": 0, \"fn\": 10305, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14296407185628743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8570359281437125, \"precision\": 1.0, \"recall\": 0.14296407185628743, \"specificity\": 1.0, \"npv\": 0.4385420071918928, \"accuracy\": 0.48662382304588253, \"f1\": 0.2501637197118533, \"f2\": 0.17253839205058719, \"f0_5\": 0.45476190476190476, \"p4\": 0.35476568433134903, \"phi\": 0.2503911959877629}, {\"truth_threshold\": 27.44, \"match_probability\": 0.9999999945079192, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1717, \"tn\": 8049, \"fp\": 0, \"fn\": 10307, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1427977378576181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8572022621423819, \"precision\": 1.0, \"recall\": 0.1427977378576181, \"specificity\": 1.0, \"npv\": 0.4384942253214208, \"accuracy\": 0.4865241867184776, \"f1\": 0.249909031365985, \"f2\": 0.17234456868688897, \"f0_5\": 0.4544251535041287, \"p4\": 0.35450169923829167, \"phi\": 0.2502318593615281}, {\"truth_threshold\": 27.46, \"match_probability\": 0.9999999945835303, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1715, \"tn\": 8049, \"fp\": 0, \"fn\": 10309, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14263140385894876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8573685961410512, \"precision\": 1.0, \"recall\": 0.14263140385894876, \"specificity\": 1.0, \"npv\": 0.4384464538620765, \"accuracy\": 0.4864245503910726, \"f1\": 0.24965426886964118, \"f2\": 0.17215072975848708, \"f0_5\": 0.45408811692438045, \"p4\": 0.3542375105675628, \"phi\": 0.25007245596291844}, {\"truth_threshold\": 27.48, \"match_probability\": 0.9999999946581004, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1709, \"tn\": 8049, \"fp\": 0, \"fn\": 10315, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1421324018629408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8578675981370593, \"precision\": 1.0, \"recall\": 0.1421324018629408, \"specificity\": 1.0, \"npv\": 0.4383032019167937, \"accuracy\": 0.48612564140885767, \"f1\": 0.24888953615379014, \"f2\": 0.1715691195663086, \"f0_5\": 0.45307529162248145, \"p4\": 0.35344372011298747, \"phi\": 0.2495938437394869}, {\"truth_threshold\": 27.5, \"match_probability\": 0.9999999947316439, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1704, \"tn\": 8049, \"fp\": 0, \"fn\": 10320, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14171656686626746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8582834331337326, \"precision\": 1.0, \"recall\": 0.14171656686626746, \"specificity\": 1.0, \"npv\": 0.4381838967826229, \"accuracy\": 0.48587655059034524, \"f1\": 0.24825174825174826, \"f2\": 0.1710843373493976, \"f0_5\": 0.45222929936305734, \"p4\": 0.3527808206113055, \"phi\": 0.24919453747647885}, {\"truth_threshold\": 27.52, \"match_probability\": 0.999999994804175, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1701, \"tn\": 8049, \"fp\": 0, \"fn\": 10323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14146706586826346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8585329341317365, \"precision\": 1.0, \"recall\": 0.14146706586826346, \"specificity\": 1.0, \"npv\": 0.4381123448726323, \"accuracy\": 0.4857270960992378, \"f1\": 0.24786885245901638, \"f2\": 0.17079342129043917, \"f0_5\": 0.4517208413001912, \"p4\": 0.3523824646487951, \"phi\": 0.24895475080784465}, {\"truth_threshold\": 27.54, \"match_probability\": 0.9999999948757075, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1695, \"tn\": 8049, \"fp\": 0, \"fn\": 10329, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1409680638722555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8590319361277445, \"precision\": 1.0, \"recall\": 0.1409680638722555, \"specificity\": 1.0, \"npv\": 0.43796931113287624, \"accuracy\": 0.48542818711702285, \"f1\": 0.24710255849551716, \"f2\": 0.1702114840031331, \"f0_5\": 0.4507019783024888, \"p4\": 0.3515843613906728, \"phi\": 0.2484747186855577}, {\"truth_threshold\": 27.560000000000002, \"match_probability\": 0.9999999949462551, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1693, \"tn\": 8049, \"fp\": 0, \"fn\": 10331, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14080172987358616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8591982701264138, \"precision\": 1.0, \"recall\": 0.14080172987358616, \"specificity\": 1.0, \"npv\": 0.4379216539717084, \"accuracy\": 0.4853285507896179, \"f1\": 0.2468469782022308, \"f2\": 0.17001747373917933, \"f0_5\": 0.4503617791019366, \"p4\": 0.3513179136156617, \"phi\": 0.24831457151830327}, {\"truth_threshold\": 27.580000000000002, \"match_probability\": 0.9999999950158315, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1692, \"tn\": 8049, \"fp\": 0, \"fn\": 10332, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1407185628742515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8592814371257484, \"precision\": 1.0, \"recall\": 0.1407185628742515, \"specificity\": 1.0, \"npv\": 0.437897829280235, \"accuracy\": 0.4852787326259154, \"f1\": 0.24671916010498687, \"f2\": 0.16992046276211134, \"f0_5\": 0.4501915708812261, \"p4\": 0.35118461205339024, \"phi\": 0.2482344722677916}, {\"truth_threshold\": 27.6, \"match_probability\": 0.99999999508445, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1688, \"tn\": 8049, \"fp\": 0, \"fn\": 10336, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14038589487691283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8596141051230871, \"precision\": 1.0, \"recall\": 0.14038589487691283, \"specificity\": 1.0, \"npv\": 0.4378025564318738, \"accuracy\": 0.48507945997110546, \"f1\": 0.24620770128354727, \"f2\": 0.1695323798810863, \"f0_5\": 0.44951001278227526, \"p4\": 0.3506508870852853, \"phi\": 0.2479139037329063}, {\"truth_threshold\": 27.62, \"match_probability\": 0.9999999951521238, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1686, \"tn\": 8049, \"fp\": 0, \"fn\": 10338, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.14021956087824353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8597804391217565, \"precision\": 1.0, \"recall\": 0.14021956087824353, \"specificity\": 1.0, \"npv\": 0.4377549355522924, \"accuracy\": 0.4849798236437005, \"f1\": 0.24595185995623634, \"f2\": 0.16933831505363384, \"f0_5\": 0.4491687979539642, \"p4\": 0.3503837128363333, \"phi\": 0.24775351629275863}, {\"truth_threshold\": 27.64, \"match_probability\": 0.999999995218866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1684, \"tn\": 8049, \"fp\": 0, \"fn\": 10340, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1400532268795742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8599467731204258, \"precision\": 1.0, \"recall\": 0.1400532268795742, \"specificity\": 1.0, \"npv\": 0.4377073250312687, \"accuracy\": 0.4848801873162955, \"f1\": 0.24569594397432157, \"f2\": 0.16914423463238248, \"f0_5\": 0.4488272921108742, \"p4\": 0.3501163303367764, \"phi\": 0.24759305987740404}, {\"truth_threshold\": 27.66, \"match_probability\": 0.9999999952846893, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1680, \"tn\": 8049, \"fp\": 0, \"fn\": 10344, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13972055888223553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8602794411177644, \"precision\": 1.0, \"recall\": 0.13972055888223553, \"specificity\": 1.0, \"npv\": 0.43761213505137825, \"accuracy\": 0.48468091466148555, \"f1\": 0.24518388791593695, \"f2\": 0.16875602700096431, \"f0_5\": 0.44814340588988477, \"p4\": 0.3495809393603363, \"phi\": 0.24727193953828827}, {\"truth_threshold\": 27.68, \"match_probability\": 0.9999999953496064, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1679, \"tn\": 8049, \"fp\": 0, \"fn\": 10345, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13963739188290086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8603626081170991, \"precision\": 1.0, \"recall\": 0.13963739188290086, \"specificity\": 1.0, \"npv\": 0.4375883440252256, \"accuracy\": 0.4846310964977831, \"f1\": 0.24505582719112604, \"f2\": 0.16865896534404823, \"f0_5\": 0.44797225186766276, \"p4\": 0.34944696098040323, \"phi\": 0.24719161611600032}, {\"truth_threshold\": 27.7, \"match_probability\": 0.9999999954136297, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1670, \"tn\": 8049, \"fp\": 0, \"fn\": 10354, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1388888888888889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8611111111111112, \"precision\": 1.0, \"recall\": 0.1388888888888889, \"specificity\": 1.0, \"npv\": 0.43737434114003154, \"accuracy\": 0.48418273302446074, \"f1\": 0.24390243902439024, \"f2\": 0.16778523489932887, \"f0_5\": 0.44642857142857145, \"p4\": 0.3482387960256907, \"phi\": 0.24646792138014395}, {\"truth_threshold\": 27.72, \"match_probability\": 0.9999999954767717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1668, \"tn\": 8049, \"fp\": 0, \"fn\": 10356, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13872255489021956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8612774451097804, \"precision\": 1.0, \"recall\": 0.13872255489021956, \"specificity\": 1.0, \"npv\": 0.43732681336593315, \"accuracy\": 0.48408309669705574, \"f1\": 0.24364592462751972, \"f2\": 0.16759102965999517, \"f0_5\": 0.44608472400513477, \"p4\": 0.3479697364477065, \"phi\": 0.24630690788550869}, {\"truth_threshold\": 27.740000000000002, \"match_probability\": 0.9999999955390442, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1663, \"tn\": 8049, \"fp\": 0, \"fn\": 10361, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13830671989354623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8616932801064537, \"precision\": 1.0, \"recall\": 0.13830671989354623, \"specificity\": 1.0, \"npv\": 0.43720803910917977, \"accuracy\": 0.4838340058785433, \"f1\": 0.24300431065975012, \"f2\": 0.16710544826061616, \"f0_5\": 0.445223816663097, \"p4\": 0.3472961635743038, \"phi\": 0.24590406625405759}, {\"truth_threshold\": 27.76, \"match_probability\": 0.9999999956004595, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1658, \"tn\": 8049, \"fp\": 0, \"fn\": 10366, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13789088489687293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.862109115103127, \"precision\": 1.0, \"recall\": 0.13789088489687293, \"specificity\": 1.0, \"npv\": 0.4370893293510725, \"accuracy\": 0.4835849150600309, \"f1\": 0.2423622277444818, \"f2\": 0.16661976926478272, \"f0_5\": 0.44436106346483706, \"p4\": 0.3466212669004835, \"phi\": 0.24550078289732624}, {\"truth_threshold\": 27.8, \"match_probability\": 0.9999999957207651, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1654, \"tn\": 8049, \"fp\": 0, \"fn\": 10370, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13755821689953426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8624417831004657, \"precision\": 1.0, \"recall\": 0.13755821689953426, \"specificity\": 1.0, \"npv\": 0.43699440794831423, \"accuracy\": 0.4833856424052209, \"f1\": 0.24184822342447726, \"f2\": 0.16623115577889447, \"f0_5\": 0.4436695278969957, \"p4\": 0.34608039313432215, \"phi\": 0.24517783658487113}, {\"truth_threshold\": 27.82, \"match_probability\": 0.9999999957796787, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1651, \"tn\": 8049, \"fp\": 0, \"fn\": 10373, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13730871590153026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8626912840984697, \"precision\": 1.0, \"recall\": 0.13730871590153026, \"specificity\": 1.0, \"npv\": 0.43692324394745413, \"accuracy\": 0.4832361879141135, \"f1\": 0.24146252285191955, \"f2\": 0.16593965465254187, \"f0_5\": 0.44315009662873095, \"p4\": 0.3456741782417716, \"phi\": 0.2449354396039005}, {\"truth_threshold\": 27.84, \"match_probability\": 0.9999999958377811, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1649, \"tn\": 8049, \"fp\": 0, \"fn\": 10375, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13714238190286093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.862857618097139, \"precision\": 1.0, \"recall\": 0.13714238190286093, \"specificity\": 1.0, \"npv\": 0.4368758141554494, \"accuracy\": 0.48313655158670854, \"f1\": 0.24120529510714547, \"f2\": 0.16574530103527993, \"f0_5\": 0.4428034371643394, \"p4\": 0.34540310126045914, \"phi\": 0.24477375216519837}, {\"truth_threshold\": 27.88, \"match_probability\": 0.9999999959515972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1645, \"tn\": 8049, \"fp\": 0, \"fn\": 10379, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1368097139055223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8631902860944777, \"precision\": 1.0, \"recall\": 0.1368097139055223, \"specificity\": 1.0, \"npv\": 0.4367809854569134, \"accuracy\": 0.4829372789318986, \"f1\": 0.2406906137976443, \"f2\": 0.16535654691300938, \"f0_5\": 0.4421092238228338, \"p4\": 0.3448603049454602, \"phi\": 0.244450161913901}, {\"truth_threshold\": 27.900000000000002, \"match_probability\": 0.9999999960073327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1642, \"tn\": 8049, \"fp\": 0, \"fn\": 10382, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1365602129075183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8634397870924817, \"precision\": 1.0, \"recall\": 0.1365602129075183, \"specificity\": 1.0, \"npv\": 0.4367098909446042, \"accuracy\": 0.4827878244407911, \"f1\": 0.24030440509293136, \"f2\": 0.16506494028710442, \"f0_5\": 0.4415877796901893, \"p4\": 0.3444526444001404, \"phi\": 0.24420728016628465}, {\"truth_threshold\": 27.92, \"match_probability\": 0.9999999960623009, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1641, \"tn\": 8049, \"fp\": 0, \"fn\": 10383, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13647704590818363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8635229540918163, \"precision\": 1.0, \"recall\": 0.13647704590818363, \"specificity\": 1.0, \"npv\": 0.4366861979166667, \"accuracy\": 0.4827380062770886, \"f1\": 0.24017563117453347, \"f2\": 0.16496773026117378, \"f0_5\": 0.44141381536475144, \"p4\": 0.34431665004245887, \"phi\": 0.2441262834693206}, {\"truth_threshold\": 27.94, \"match_probability\": 0.9999999961165125, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1640, \"tn\": 8049, \"fp\": 0, \"fn\": 10384, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13639387890884896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.863606121091151, \"precision\": 1.0, \"recall\": 0.13639387890884896, \"specificity\": 1.0, \"npv\": 0.43666250745944774, \"accuracy\": 0.48268818811338615, \"f1\": 0.24004683840749413, \"f2\": 0.16487051632620234, \"f0_5\": 0.4412397761515282, \"p4\": 0.3441806018636767, \"phi\": 0.24404526868279636}, {\"truth_threshold\": 27.96, \"match_probability\": 0.9999999961699776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1634, \"tn\": 8049, \"fp\": 0, \"fn\": 10390, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.135894876912841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.864105123087159, \"precision\": 1.0, \"recall\": 0.135894876912841, \"specificity\": 1.0, \"npv\": 0.4365204186778025, \"accuracy\": 0.48238927913117124, \"f1\": 0.23927368575194025, \"f2\": 0.1642871506133119, \"f0_5\": 0.4401939655172414, \"p4\": 0.34336318030822044, \"phi\": 0.24355879899145869}, {\"truth_threshold\": 27.98, \"match_probability\": 0.9999999962227066, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1628, \"tn\": 8049, \"fp\": 0, \"fn\": 10396, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.135395874916833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.864604125083167, \"precision\": 1.0, \"recall\": 0.135395874916833, \"specificity\": 1.0, \"npv\": 0.4363784223366766, \"accuracy\": 0.4820903701489563, \"f1\": 0.2384998535013185, \"f2\": 0.16370364411551766, \"f0_5\": 0.4391454466983168, \"p4\": 0.34254381109363014, \"phi\": 0.2430716731482745}, {\"truth_threshold\": 28.0, \"match_probability\": 0.9999999962747097, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1626, \"tn\": 8049, \"fp\": 0, \"fn\": 10398, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13522954091816367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8647704590818364, \"precision\": 1.0, \"recall\": 0.13522954091816367, \"specificity\": 1.0, \"npv\": 0.4363311107497154, \"accuracy\": 0.48199073382155133, \"f1\": 0.23824175824175825, \"f2\": 0.16350911065524315, \"f0_5\": 0.43879533678756477, \"p4\": 0.3422702537053842, \"phi\": 0.24290915131998722}, {\"truth_threshold\": 28.02, \"match_probability\": 0.9999999963259969, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1622, \"tn\": 8049, \"fp\": 0, \"fn\": 10402, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13489687292082503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.865103127079175, \"precision\": 1.0, \"recall\": 0.13489687292082503, \"specificity\": 1.0, \"npv\": 0.4362365183458891, \"accuracy\": 0.4817914611667414, \"f1\": 0.23772534075919682, \"f2\": 0.16311999678184963, \"f0_5\": 0.4380942091616249, \"p4\": 0.34172248551223655, \"phi\": 0.24258388689014065}, {\"truth_threshold\": 28.060000000000002, \"match_probability\": 0.9999999964264626, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1614, \"tn\": 8049, \"fp\": 0, \"fn\": 10410, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1342315369261477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8657684630738522, \"precision\": 1.0, \"recall\": 0.1342315369261477, \"specificity\": 1.0, \"npv\": 0.4360474565252722, \"accuracy\": 0.4813929158571215, \"f1\": 0.23669159700835898, \"f2\": 0.1623415811707906, \"f0_5\": 0.4366883116883117, \"p4\": 0.34062432635469736, \"phi\": 0.2419324704584419}, {\"truth_threshold\": 28.080000000000002, \"match_probability\": 0.9999999964756606, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1610, \"tn\": 8049, \"fp\": 0, \"fn\": 10414, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13389886892880906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8661011310711909, \"precision\": 1.0, \"recall\": 0.13389886892880906, \"specificity\": 1.0, \"npv\": 0.4359529870551915, \"accuracy\": 0.48119364320231156, \"f1\": 0.23617427020683585, \"f2\": 0.16195227940288898, \"f0_5\": 0.4359835355285962, \"p4\": 0.3400739301649541, \"phi\": 0.24160631587941958}, {\"truth_threshold\": 28.1, \"match_probability\": 0.9999999965241813, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1607, \"tn\": 8049, \"fp\": 0, \"fn\": 10417, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13364936793080506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8663506320691949, \"precision\": 1.0, \"recall\": 0.13364936793080506, \"specificity\": 1.0, \"npv\": 0.4358821618108957, \"accuracy\": 0.4810441887112041, \"f1\": 0.23578607585650355, \"f2\": 0.16166026195601876, \"f0_5\": 0.43545415131151094, \"p4\": 0.33966055485225183, \"phi\": 0.2413615035964499}, {\"truth_threshold\": 28.12, \"match_probability\": 0.9999999965720339, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1603, \"tn\": 8049, \"fp\": 0, \"fn\": 10421, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1333166999334664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8666833000665336, \"precision\": 1.0, \"recall\": 0.1333166999334664, \"specificity\": 1.0, \"npv\": 0.4357877639415268, \"accuracy\": 0.4808449160563942, \"f1\": 0.23526821750935642, \"f2\": 0.16127085052013118, \"f0_5\": 0.43474723367324797, \"p4\": 0.33910861475982446, \"phi\": 0.24103482437205795}, {\"truth_threshold\": 28.14, \"match_probability\": 0.9999999966192277, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1599, \"tn\": 8049, \"fp\": 0, \"fn\": 10425, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13298403193612773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8670159680638723, \"precision\": 1.0, \"recall\": 0.13298403193612773, \"specificity\": 1.0, \"npv\": 0.43569340695030856, \"accuracy\": 0.4806456434015842, \"f1\": 0.23475005505395288, \"f2\": 0.16088137639601569, \"f0_5\": 0.43403908794788276, \"p4\": 0.3385557888028213, \"phi\": 0.24070784354532393}, {\"truth_threshold\": 28.16, \"match_probability\": 0.9999999966657718, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1595, \"tn\": 8049, \"fp\": 0, \"fn\": 10429, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1326513639387891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8673486360612109, \"precision\": 1.0, \"recall\": 0.1326513639387891, \"specificity\": 1.0, \"npv\": 0.4355990908106938, \"accuracy\": 0.48044637074677427, \"f1\": 0.23423158822233645, \"f2\": 0.16049183956853355, \"f0_5\": 0.433329710932406, \"p4\": 0.33800207432512164, \"phi\": 0.240380559793289}, {\"truth_threshold\": 28.18, \"match_probability\": 0.999999996711675, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1589, \"tn\": 8049, \"fp\": 0, \"fn\": 10435, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1321523619427811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8678476380572189, \"precision\": 1.0, \"recall\": 0.1321523619427811, \"specificity\": 1.0, \"npv\": 0.435457693140013, \"accuracy\": 0.48014746176455936, \"f1\": 0.23345331668258282, \"f2\": 0.15990741672536982, \"f0_5\": 0.4322633297062024, \"p4\": 0.33716983079650703, \"phi\": 0.23988906326593445}, {\"truth_threshold\": 28.2, \"match_probability\": 0.9999999967569464, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1585, \"tn\": 8049, \"fp\": 0, \"fn\": 10439, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13181969394544246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8681803060545575, \"precision\": 1.0, \"recall\": 0.13181969394544246, \"specificity\": 1.0, \"npv\": 0.4353634790134141, \"accuracy\": 0.4799481891097494, \"f1\": 0.23293408773605703, \"f2\": 0.15951772307320705, \"f0_5\": 0.4315508603790024, \"p4\": 0.3366138833284589, \"phi\": 0.23956101635819488}, {\"truth_threshold\": 28.22, \"match_probability\": 0.9999999968015946, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1582, \"tn\": 8049, \"fp\": 0, \"fn\": 10442, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13157019294743846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8684298070525616, \"precision\": 1.0, \"recall\": 0.13157019294743846, \"specificity\": 1.0, \"npv\": 0.43529284516791955, \"accuracy\": 0.479798734618642, \"f1\": 0.23254446567690726, \"f2\": 0.15922541165103266, \"f0_5\": 0.4310156931124673, \"p4\": 0.33619633362885176, \"phi\": 0.23931477937516235}, {\"truth_threshold\": 28.28, \"match_probability\": 0.9999999969318843, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1579, \"tn\": 8049, \"fp\": 0, \"fn\": 10445, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13132069194943446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8686793080505656, \"precision\": 1.0, \"recall\": 0.13132069194943446, \"specificity\": 1.0, \"npv\": 0.4352222342381313, \"accuracy\": 0.4796492801275345, \"f1\": 0.23215467176358157, \"f2\": 0.15893306492199297, \"f0_5\": 0.43047982551799346, \"p4\": 0.33577827772145385, \"phi\": 0.23906836878167353}, {\"truth_threshold\": 28.3, \"match_probability\": 0.999999996974124, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1577, \"tn\": 8049, \"fp\": 0, \"fn\": 10447, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13115435795076513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8688456420492349, \"precision\": 1.0, \"recall\": 0.13115435795076513, \"specificity\": 1.0, \"npv\": 0.4351751730103806, \"accuracy\": 0.47954964380012954, \"f1\": 0.23189471362399824, \"f2\": 0.15873814748454895, \"f0_5\": 0.43012219070477853, \"p4\": 0.33549929199224976, \"phi\": 0.23890399831792183}, {\"truth_threshold\": 28.32, \"match_probability\": 0.9999999970157821, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1569, \"tn\": 8049, \"fp\": 0, \"fn\": 10455, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.13048902195608783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8695109780439122, \"precision\": 1.0, \"recall\": 0.13048902195608783, \"specificity\": 1.0, \"npv\": 0.4349870298313878, \"accuracy\": 0.47915109849050963, \"f1\": 0.23085411608916354, \"f2\": 0.15795832074901842, \"f0_5\": 0.42868852459016393, \"p4\": 0.33438108738211575, \"phi\": 0.2382457388627998}, {\"truth_threshold\": 28.34, \"match_probability\": 0.9999999970568668, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1557, \"tn\": 8049, \"fp\": 0, \"fn\": 10467, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12949101796407186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8705089820359282, \"precision\": 1.0, \"recall\": 0.12949101796407186, \"specificity\": 1.0, \"npv\": 0.4347051198963059, \"accuracy\": 0.4785532805260798, \"f1\": 0.2292909211398277, \"f2\": 0.15678810947978974, \"f0_5\": 0.4265285996055227, \"p4\": 0.3326969577616018, \"phi\": 0.2372559977947166}, {\"truth_threshold\": 28.36, \"match_probability\": 0.9999999970973857, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1554, \"tn\": 8049, \"fp\": 0, \"fn\": 10470, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12924151696606787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8707584830339321, \"precision\": 1.0, \"recall\": 0.12924151696606787, \"specificity\": 1.0, \"npv\": 0.4346346994978131, \"accuracy\": 0.47840382603497233, \"f1\": 0.22889969067609367, \"f2\": 0.1564954682779456, \"f0_5\": 0.42598684210526316, \"p4\": 0.33227463867846024, \"phi\": 0.23700811777065445}, {\"truth_threshold\": 28.38, \"match_probability\": 0.9999999971373469, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1552, \"tn\": 8049, \"fp\": 0, \"fn\": 10472, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12907518296739853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8709248170326015, \"precision\": 1.0, \"recall\": 0.12907518296739853, \"specificity\": 1.0, \"npv\": 0.4345877652394579, \"accuracy\": 0.4783041897075674, \"f1\": 0.22863877430760166, \"f2\": 0.15630035449564939, \"f0_5\": 0.42562527424308905, \"p4\": 0.33199280546821835, \"phi\": 0.23684276495953147}, {\"truth_threshold\": 28.400000000000002, \"match_probability\": 0.9999999971767579, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1547, \"tn\": 8049, \"fp\": 0, \"fn\": 10477, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12865934797072523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8713406520292748, \"precision\": 1.0, \"recall\": 0.12865934797072523, \"specificity\": 1.0, \"npv\": 0.4344704739285329, \"accuracy\": 0.47805509888905495, \"f1\": 0.2279861469309557, \"f2\": 0.15581250125898918, \"f0_5\": 0.4247199648583352, \"p4\": 0.3312872148622074, \"phi\": 0.23642903351360425}, {\"truth_threshold\": 28.42, \"match_probability\": 0.9999999972156263, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1543, \"tn\": 8049, \"fp\": 0, \"fn\": 10481, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12832667997338656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8716733200266135, \"precision\": 1.0, \"recall\": 0.12832667997338656, \"specificity\": 1.0, \"npv\": 0.43437668645439825, \"accuracy\": 0.477855826234245, \"f1\": 0.2274636986806221, \"f2\": 0.155422147907895, \"f0_5\": 0.42399428445812265, \"p4\": 0.33072170312687027, \"phi\": 0.2360976874739218}, {\"truth_threshold\": 28.44, \"match_probability\": 0.9999999972539596, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1537, \"tn\": 8049, \"fp\": 0, \"fn\": 10487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12782767797737857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8721723220226214, \"precision\": 1.0, \"recall\": 0.12782767797737857, \"specificity\": 1.0, \"npv\": 0.43423608113940443, \"accuracy\": 0.4775569172520301, \"f1\": 0.22667944841825824, \"f2\": 0.1548364999093345, \"f0_5\": 0.42290336781862203, \"p4\": 0.3298716968618999, \"phi\": 0.23560006355272192}, {\"truth_threshold\": 28.46, \"match_probability\": 0.9999999972917651, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1534, \"tn\": 8049, \"fp\": 0, \"fn\": 10490, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1275781769793746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8724218230206254, \"precision\": 1.0, \"recall\": 0.1275781769793746, \"specificity\": 1.0, \"npv\": 0.434165812611252, \"accuracy\": 0.4774074627609226, \"f1\": 0.2262870629886414, \"f2\": 0.154543622808785, \"f0_5\": 0.4223568281938326, \"p4\": 0.3294459087547959, \"phi\": 0.23535097807256353}, {\"truth_threshold\": 28.48, \"match_probability\": 0.9999999973290502, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1533, \"tn\": 8049, \"fp\": 0, \"fn\": 10491, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12749500998003993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8725049900199601, \"precision\": 1.0, \"recall\": 0.12749500998003993, \"specificity\": 1.0, \"npv\": 0.43414239482200645, \"accuracy\": 0.47735764459722013, \"f1\": 0.2261562292542598, \"f2\": 0.154445989240162, \"f0_5\": 0.42217448777263716, \"p4\": 0.3293038627985639, \"phi\": 0.23526790890512492}, {\"truth_threshold\": 28.5, \"match_probability\": 0.999999997365822, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1532, \"tn\": 8049, \"fp\": 0, \"fn\": 10492, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12741184298070526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8725881570192947, \"precision\": 1.0, \"recall\": 0.12741184298070526, \"specificity\": 1.0, \"npv\": 0.4341189795588156, \"accuracy\": 0.47730782643351766, \"f1\": 0.2260253762171732, \"f2\": 0.1543483517369227, \"f0_5\": 0.42199206698986336, \"p4\": 0.3291617584748675, \"phi\": 0.23518481936233004}, {\"truth_threshold\": 28.52, \"match_probability\": 0.9999999974020874, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1528, \"tn\": 8049, \"fp\": 0, \"fn\": 10496, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1270791749833666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8729208250166334, \"precision\": 1.0, \"recall\": 0.1270791749833666, \"specificity\": 1.0, \"npv\": 0.43402534375842544, \"accuracy\": 0.4771085537787077, \"f1\": 0.2255017709563164, \"f2\": 0.1539577623730453, \"f0_5\": 0.42126157917953244, \"p4\": 0.32859275661707577, \"phi\": 0.23485225697593964}, {\"truth_threshold\": 28.54, \"match_probability\": 0.9999999974378537, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1526, \"tn\": 8049, \"fp\": 0, \"fn\": 10498, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12691284098469727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8730871590153028, \"precision\": 1.0, \"recall\": 0.12691284098469727, \"specificity\": 1.0, \"npv\": 0.43397854100393596, \"accuracy\": 0.47700891745130275, \"f1\": 0.22523985239852398, \"f2\": 0.1537624440772238, \"f0_5\": 0.42089585172109445, \"p4\": 0.32830790432729035, \"phi\": 0.23468585292940744}, {\"truth_threshold\": 28.560000000000002, \"match_probability\": 0.9999999974731275, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1522, \"tn\": 8049, \"fp\": 0, \"fn\": 10502, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1265801729873586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8734198270126414, \"precision\": 1.0, \"recall\": 0.1265801729873586, \"specificity\": 1.0, \"npv\": 0.4338849657700394, \"accuracy\": 0.4768096447964928, \"f1\": 0.22471578325705005, \"f2\": 0.153371760248297, \"f0_5\": 0.42016342756183744, \"p4\": 0.3277374952408407, \"phi\": 0.23435279819918034}, {\"truth_threshold\": 28.580000000000002, \"match_probability\": 0.9999999975079157, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1519, \"tn\": 8049, \"fp\": 0, \"fn\": 10505, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12633067198935463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8736693280106453, \"precision\": 1.0, \"recall\": 0.12633067198935463, \"specificity\": 1.0, \"npv\": 0.43381481082246415, \"accuracy\": 0.47666019030538537, \"f1\": 0.22432252824337295, \"f2\": 0.1530787060364809, \"f0_5\": 0.41961325966850826, \"p4\": 0.3273090705721852, \"phi\": 0.2341027906073241}, {\"truth_threshold\": 28.6, \"match_probability\": 0.999999997542225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1518, \"tn\": 8049, \"fp\": 0, \"fn\": 10506, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12624750499001997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8737524950099801, \"precision\": 1.0, \"recall\": 0.12624750499001997, \"specificity\": 1.0, \"npv\": 0.4337914308811641, \"accuracy\": 0.47661037214168284, \"f1\": 0.22419140451927339, \"f2\": 0.15298101342363044, \"f0_5\": 0.41942970822281167, \"p4\": 0.3271661444234851, \"phi\": 0.23401941337162108}, {\"truth_threshold\": 28.62, \"match_probability\": 0.999999997576062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1514, \"tn\": 8049, \"fp\": 0, \"fn\": 10510, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1259148369926813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8740851630073186, \"precision\": 1.0, \"recall\": 0.1259148369926813, \"specificity\": 1.0, \"npv\": 0.43369793631122366, \"accuracy\": 0.47641109948687294, \"f1\": 0.2236667159107697, \"f2\": 0.1525902035879863, \"f0_5\": 0.4186946902654867, \"p4\": 0.3265938489991757, \"phi\": 0.23368569694076272}, {\"truth_threshold\": 28.64, \"match_probability\": 0.999999997609433, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1513, \"tn\": 8049, \"fp\": 0, \"fn\": 10511, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12583166999334663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8741683300066534, \"precision\": 1.0, \"recall\": 0.12583166999334663, \"specificity\": 1.0, \"npv\": 0.43367456896551726, \"accuracy\": 0.4763612813231704, \"f1\": 0.2235354953091527, \"f2\": 0.15249249128182385, \"f0_5\": 0.4185107324629343, \"p4\": 0.3264506272101364, \"phi\": 0.2336022158426067}, {\"truth_threshold\": 28.66, \"match_probability\": 0.9999999976423446, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1512, \"tn\": 8049, \"fp\": 0, \"fn\": 10512, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12574850299401197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.874251497005988, \"precision\": 1.0, \"recall\": 0.12574850299401197, \"specificity\": 1.0, \"npv\": 0.4336512041377081, \"accuracy\": 0.47631146315946793, \"f1\": 0.22340425531914893, \"f2\": 0.15239477503628446, \"f0_5\": 0.41832669322709165, \"p4\": 0.3263073461575215, \"phi\": 0.2335187139007653}, {\"truth_threshold\": 28.68, \"match_probability\": 0.9999999976748032, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1511, \"tn\": 8049, \"fp\": 0, \"fn\": 10513, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1256653359946773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8743346640053227, \"precision\": 1.0, \"recall\": 0.1256653359946773, \"specificity\": 1.0, \"npv\": 0.4336278418273893, \"accuracy\": 0.47626164499576545, \"f1\": 0.22327299593646102, \"f2\": 0.15229705485112988, \"f0_5\": 0.41814257250387427, \"p4\": 0.32616400579605687, \"phi\": 0.23343519109141547}, {\"truth_threshold\": 28.7, \"match_probability\": 0.9999999977068148, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1510, \"tn\": 8049, \"fp\": 0, \"fn\": 10514, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12558216899534264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8744178310046573, \"precision\": 1.0, \"recall\": 0.12558216899534264, \"specificity\": 1.0, \"npv\": 0.43360448203415397, \"accuracy\": 0.476211826832063, \"f1\": 0.2231417171567903, \"f2\": 0.15219933072612185, \"f0_5\": 0.41795837023914967, \"p4\": 0.32602060608042344, \"phi\": 0.23335164739069475}, {\"truth_threshold\": 28.72, \"match_probability\": 0.9999999977383858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1502, \"tn\": 8049, \"fp\": 0, \"fn\": 10522, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12491683300066533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8750831669993346, \"precision\": 1.0, \"recall\": 0.12491683300066533, \"specificity\": 1.0, \"npv\": 0.4334176942544828, \"accuracy\": 0.47581328152244307, \"f1\": 0.2220907881117847, \"f2\": 0.1514173958627364, \"f0_5\": 0.4164818101153505, \"p4\": 0.3248712661520837, \"phi\": 0.23268254281901052}, {\"truth_threshold\": 28.740000000000002, \"match_probability\": 0.9999999977695221, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1497, \"tn\": 8049, \"fp\": 0, \"fn\": 10527, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12450099800399202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8754990019960079, \"precision\": 1.0, \"recall\": 0.12450099800399202, \"specificity\": 1.0, \"npv\": 0.4333010335917313, \"accuracy\": 0.47556419070393063, \"f1\": 0.22143332593743068, \"f2\": 0.15092855846591252, \"f0_5\": 0.4155562958027981, \"p4\": 0.32415098784533974, \"phi\": 0.23226366723689656}, {\"truth_threshold\": 28.76, \"match_probability\": 0.9999999978002297, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1494, \"tn\": 8049, \"fp\": 0, \"fn\": 10530, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12425149700598802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.875748502994012, \"precision\": 1.0, \"recall\": 0.12425149700598802, \"specificity\": 1.0, \"npv\": 0.4332310673340869, \"accuracy\": 0.4754147362128232, \"f1\": 0.2210386151797603, \"f2\": 0.15063520871143377, \"f0_5\": 0.415, \"p4\": 0.323718101307547, \"phi\": 0.2320120873268509}, {\"truth_threshold\": 28.78, \"match_probability\": 0.9999999978305146, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1493, \"tn\": 8049, \"fp\": 0, \"fn\": 10531, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12416833000665337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8758316699933466, \"precision\": 1.0, \"recall\": 0.12416833000665337, \"specificity\": 1.0, \"npv\": 0.4332077502691066, \"accuracy\": 0.47536491804912073, \"f1\": 0.22090700599245394, \"f2\": 0.15053741757244551, \"f0_5\": 0.4148144032007113, \"p4\": 0.3235736855933169, \"phi\": 0.23192818478325203}, {\"truth_threshold\": 28.8, \"match_probability\": 0.9999999978603826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1491, \"tn\": 8049, \"fp\": 0, \"fn\": 10533, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12400199600798403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.875998003992016, \"precision\": 1.0, \"recall\": 0.12400199600798403, \"specificity\": 1.0, \"npv\": 0.43316112366806586, \"accuracy\": 0.4752652817217157, \"f1\": 0.2206437291897891, \"f2\": 0.15034182346179442, \"f0_5\": 0.41444296197464975, \"p4\": 0.3232846735856412, \"phi\": 0.23176031568821565}, {\"truth_threshold\": 28.82, \"match_probability\": 0.9999999978898393, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1481, \"tn\": 8049, \"fp\": 0, \"fn\": 10543, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12317032601463739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8768296739853626, \"precision\": 1.0, \"recall\": 0.12317032601463739, \"specificity\": 1.0, \"npv\": 0.43292814113597244, \"accuracy\": 0.47476710008469086, \"f1\": 0.21932617549055905, \"f2\": 0.1493636161929927, \"f0_5\": 0.41258078894584355, \"p4\": 0.3218359899216687, \"phi\": 0.23091968362317813}, {\"truth_threshold\": 28.84, \"match_probability\": 0.9999999979188905, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1480, \"tn\": 8049, \"fp\": 0, \"fn\": 10544, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12308715901530273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8769128409846972, \"precision\": 1.0, \"recall\": 0.12308715901530273, \"specificity\": 1.0, \"npv\": 0.43290485666648737, \"accuracy\": 0.4747172819209884, \"f1\": 0.21919431279620852, \"f2\": 0.1492657737614975, \"f0_5\": 0.4123941150245207, \"p4\": 0.32169078828193615, \"phi\": 0.2308355018860937}, {\"truth_threshold\": 28.86, \"match_probability\": 0.9999999979475418, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1479, \"tn\": 8049, \"fp\": 0, \"fn\": 10545, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12300399201596807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.876996007984032, \"precision\": 1.0, \"recall\": 0.12300399201596807, \"specificity\": 1.0, \"npv\": 0.4328815747015166, \"accuracy\": 0.4746674637572859, \"f1\": 0.21906243057098423, \"f2\": 0.1491679273827534, \"f0_5\": 0.4122073578595318, \"p4\": 0.32154552586049934, \"phi\": 0.23075129849785253}, {\"truth_threshold\": 28.88, \"match_probability\": 0.9999999979757986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1476, \"tn\": 8049, \"fp\": 0, \"fn\": 10548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12275449101796407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8772455089820359, \"precision\": 1.0, \"recall\": 0.12275449101796407, \"specificity\": 1.0, \"npv\": 0.43281174382964993, \"accuracy\": 0.47451800926617843, \"f1\": 0.21866666666666668, \"f2\": 0.14887436456063907, \"f0_5\": 0.41164658634538154, \"p4\": 0.32110937343782725, \"phi\": 0.2304985581742457}, {\"truth_threshold\": 28.900000000000002, \"match_probability\": 0.9999999980036663, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1472, \"tn\": 8049, \"fp\": 0, \"fn\": 10552, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12242182302062542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8775781769793746, \"precision\": 1.0, \"recall\": 0.12242182302062542, \"specificity\": 1.0, \"npv\": 0.4327186710391914, \"accuracy\": 0.47431873661136853, \"f1\": 0.21813870776526378, \"f2\": 0.1484828921885087, \"f0_5\": 0.41089772219740955, \"p4\": 0.3205269830864326, \"phi\": 0.2301612664278682}, {\"truth_threshold\": 28.94, \"match_probability\": 0.9999999980582562, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1470, \"tn\": 8049, \"fp\": 0, \"fn\": 10554, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12225548902195608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.877744510978044, \"precision\": 1.0, \"recall\": 0.12225548902195608, \"specificity\": 1.0, \"npv\": 0.4326721496532817, \"accuracy\": 0.4742191002839635, \"f1\": 0.21787461093819474, \"f2\": 0.14828713230843724, \"f0_5\": 0.4105227882037534, \"p4\": 0.3202354211549955, \"phi\": 0.2299924895339909}, {\"truth_threshold\": 28.96, \"match_probability\": 0.9999999980849887, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1466, \"tn\": 8049, \"fp\": 0, \"fn\": 10558, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12192282102461743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8780771789753826, \"precision\": 1.0, \"recall\": 0.12192282102461743, \"specificity\": 1.0, \"npv\": 0.4325791368839684, \"accuracy\": 0.47401982762915357, \"f1\": 0.21734618235730171, \"f2\": 0.1478955651507203, \"f0_5\": 0.40977191413237923, \"p4\": 0.3196515618930048, \"phi\": 0.22965467268333026}, {\"truth_threshold\": 28.98, \"match_probability\": 0.9999999981113533, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1462, \"tn\": 8049, \"fp\": 0, \"fn\": 10562, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12159015302727877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8784098469727212, \"precision\": 1.0, \"recall\": 0.12159015302727877, \"specificity\": 1.0, \"npv\": 0.4324861640965021, \"accuracy\": 0.47382055497434367, \"f1\": 0.21681744030846803, \"f2\": 0.14750393478348603, \"f0_5\": 0.4090196956132498, \"p4\": 0.3190667195731424, \"phi\": 0.22931650371195372}, {\"truth_threshold\": 29.0, \"match_probability\": 0.9999999981373549, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1455, \"tn\": 8049, \"fp\": 0, \"fn\": 10569, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12100798403193613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8789920159680639, \"precision\": 1.0, \"recall\": 0.12100798403193613, \"specificity\": 1.0, \"npv\": 0.4323235578472446, \"accuracy\": 0.47347182782842623, \"f1\": 0.21589138660137994, \"f2\": 0.146818429496882, \"f0_5\": 0.40770006724949565, \"p4\": 0.3180408708750471, \"phi\": 0.22872385574008058}, {\"truth_threshold\": 29.02, \"match_probability\": 0.9999999981629984, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1449, \"tn\": 8049, \"fp\": 0, \"fn\": 10575, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.12050898203592815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8794910179640718, \"precision\": 1.0, \"recall\": 0.12050898203592815, \"specificity\": 1.0, \"npv\": 0.4321842783505155, \"accuracy\": 0.4731729188462113, \"f1\": 0.21509686038744155, \"f2\": 0.14623069936421434, \"f0_5\": 0.4065656565656566, \"p4\": 0.3171591559466378, \"phi\": 0.2282150026530965}, {\"truth_threshold\": 29.04, \"match_probability\": 0.999999998188289, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1441, \"tn\": 8049, \"fp\": 0, \"fn\": 10583, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11984364604125083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8801563539587491, \"precision\": 1.0, \"recall\": 0.11984364604125083, \"specificity\": 1.0, \"npv\": 0.4319987118935165, \"accuracy\": 0.47277437353659146, \"f1\": 0.21403639064240623, \"f2\": 0.14544683771726186, \"f0_5\": 0.4050483472003598, \"p4\": 0.3159800479892316, \"phi\": 0.2275352735697103}, {\"truth_threshold\": 29.060000000000002, \"match_probability\": 0.9999999982132314, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1436, \"tn\": 8049, \"fp\": 0, \"fn\": 10588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11942781104457752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8805721889554224, \"precision\": 1.0, \"recall\": 0.11942781104457752, \"specificity\": 1.0, \"npv\": 0.43188281375757903, \"accuracy\": 0.47252528271807903, \"f1\": 0.21337295690936106, \"f2\": 0.1449567956068804, \"f0_5\": 0.40409725348941916, \"p4\": 0.31524107123059253, \"phi\": 0.22710970713476913}, {\"truth_threshold\": 29.1, \"match_probability\": 0.9999999982620906, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1434, \"tn\": 8049, \"fp\": 0, \"fn\": 10590, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11926147704590818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8807385229540918, \"precision\": 1.0, \"recall\": 0.11926147704590818, \"specificity\": 1.0, \"npv\": 0.43183647191372926, \"accuracy\": 0.472425646390674, \"f1\": 0.21310744538564422, \"f2\": 0.14476075105996367, \"f0_5\": 0.40371621621621623, \"p4\": 0.314945040669254, \"phi\": 0.226939321147141}, {\"truth_threshold\": 29.12, \"match_probability\": 0.9999999982860169, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1430, \"tn\": 8049, \"fp\": 0, \"fn\": 10594, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11892880904856953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8810711909514305, \"precision\": 1.0, \"recall\": 0.11892880904856953, \"specificity\": 1.0, \"npv\": 0.43174381805503403, \"accuracy\": 0.47222637373586407, \"f1\": 0.21257618552103463, \"f2\": 0.1443686144651294, \"f0_5\": 0.4029531109107304, \"p4\": 0.3143522233518229, \"phi\": 0.22659827469636104}, {\"truth_threshold\": 29.14, \"match_probability\": 0.9999999983096138, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1429, \"tn\": 8049, \"fp\": 0, \"fn\": 10595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11884564204923487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8811543579507651, \"precision\": 1.0, \"recall\": 0.11884564204923487, \"specificity\": 1.0, \"npv\": 0.4317206608024029, \"accuracy\": 0.4721765555721616, \"f1\": 0.2124433211922991, \"f2\": 0.1442705704189803, \"f0_5\": 0.40276211950394586, \"p4\": 0.3142038611956304, \"phi\": 0.22651295574200941}, {\"truth_threshold\": 29.16, \"match_probability\": 0.9999999983328859, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1427, \"tn\": 8049, \"fp\": 0, \"fn\": 10597, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11867930805056554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8813206919494344, \"precision\": 1.0, \"recall\": 0.11867930805056554, \"specificity\": 1.0, \"npv\": 0.4316743537487933, \"accuracy\": 0.47207691924475664, \"f1\": 0.21217753326890193, \"f2\": 0.14407447044807464, \"f0_5\": 0.4023798781863298, \"p4\": 0.31390694714674544, \"phi\": 0.22634224883145843}, {\"truth_threshold\": 29.18, \"match_probability\": 0.9999999983558375, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1426, \"tn\": 8049, \"fp\": 0, \"fn\": 10598, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11859614105123087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8814038589487692, \"precision\": 1.0, \"recall\": 0.11859614105123087, \"specificity\": 1.0, \"npv\": 0.4316512039470156, \"accuracy\": 0.47202710108105417, \"f1\": 0.2120446096654275, \"f2\": 0.14397641452283833, \"f0_5\": 0.40218862815884476, \"p4\": 0.3137583951554822, \"phi\": 0.2262568608202498}, {\"truth_threshold\": 29.2, \"match_probability\": 0.9999999983784732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1421, \"tn\": 8049, \"fp\": 0, \"fn\": 10603, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11818030605455755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8818196939454425, \"precision\": 1.0, \"recall\": 0.11818030605455755, \"specificity\": 1.0, \"npv\": 0.4315354921724212, \"accuracy\": 0.47177801026254174, \"f1\": 0.2113796950539234, \"f2\": 0.14348607548922593, \"f0_5\": 0.4012310819968376, \"p4\": 0.3130146835550289, \"phi\": 0.2258295741003398}, {\"truth_threshold\": 29.22, \"match_probability\": 0.9999999984007972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1419, \"tn\": 8049, \"fp\": 0, \"fn\": 10605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11801397205588822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8819860279441117, \"precision\": 1.0, \"recall\": 0.11801397205588822, \"specificity\": 1.0, \"npv\": 0.4314892248311354, \"accuracy\": 0.47167837393513673, \"f1\": 0.21111359071635796, \"f2\": 0.143289912147834, \"f0_5\": 0.40084745762711865, \"p4\": 0.31271675388980363, \"phi\": 0.22565849711818628}, {\"truth_threshold\": 29.240000000000002, \"match_probability\": 0.999999998422814, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1415, \"tn\": 8049, \"fp\": 0, \"fn\": 10609, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11768130405854957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8823186959414504, \"precision\": 1.0, \"recall\": 0.11768130405854957, \"specificity\": 1.0, \"npv\": 0.43139671990567047, \"accuracy\": 0.47147910128032683, \"f1\": 0.21058114443038917, \"f2\": 0.14289753792086607, \"f0_5\": 0.4000791676091382, \"p4\": 0.312120129473564, \"phi\": 0.22531606370847188}, {\"truth_threshold\": 29.26, \"match_probability\": 0.9999999984445276, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1412, \"tn\": 8049, \"fp\": 0, \"fn\": 10612, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11743180306054557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8825681969394544, \"precision\": 1.0, \"recall\": 0.11743180306054557, \"specificity\": 1.0, \"npv\": 0.4313273672364825, \"accuracy\": 0.47132964678921935, \"f1\": 0.21018160166716285, \"f2\": 0.14260321564191647, \"f0_5\": 0.3995020371208692, \"p4\": 0.311671990140962, \"phi\": 0.22505899325274303}, {\"truth_threshold\": 29.28, \"match_probability\": 0.9999999984659422, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1409, \"tn\": 8049, \"fp\": 0, \"fn\": 10615, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11718230206254159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8828176979374585, \"precision\": 1.0, \"recall\": 0.11718230206254159, \"specificity\": 1.0, \"npv\": 0.43125803686240893, \"accuracy\": 0.47118019229811187, \"f1\": 0.20978188044368345, \"f2\": 0.14230885769114232, \"f0_5\": 0.3989241223103058, \"p4\": 0.3112232741478414, \"phi\": 0.22480171160938586}, {\"truth_threshold\": 29.3, \"match_probability\": 0.999999998487062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1405, \"tn\": 8049, \"fp\": 0, \"fn\": 10619, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11684963406520293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8831503659347971, \"precision\": 1.0, \"recall\": 0.11684963406520293, \"specificity\": 1.0, \"npv\": 0.43116563102635524, \"accuracy\": 0.47098091964330197, \"f1\": 0.20924864100081914, \"f2\": 0.14191632492272882, \"f0_5\": 0.3981523464067105, \"p4\": 0.31062408678762016, \"phi\": 0.2244583395798025}, {\"truth_threshold\": 29.32, \"match_probability\": 0.9999999985078911, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1402, \"tn\": 8049, \"fp\": 0, \"fn\": 10622, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11660013306719894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.883399866932801, \"precision\": 1.0, \"recall\": 0.11660013306719894, \"specificity\": 1.0, \"npv\": 0.43109635263242463, \"accuracy\": 0.4708314651521945, \"f1\": 0.20884850290481155, \"f2\": 0.14162188371247322, \"f0_5\": 0.39757259528130673, \"p4\": 0.31017401997813276, \"phi\": 0.2242005621797698}, {\"truth_threshold\": 29.34, \"match_probability\": 0.9999999985284334, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1400, \"tn\": 8049, \"fp\": 0, \"fn\": 10624, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1164337990685296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8835662009314704, \"precision\": 1.0, \"recall\": 0.1164337990685296, \"specificity\": 1.0, \"npv\": 0.4310501794034167, \"accuracy\": 0.47073182882478953, \"f1\": 0.20858164481525626, \"f2\": 0.14142556974300954, \"f0_5\": 0.39718565592374033, \"p4\": 0.30987365263836164, \"phi\": 0.22402859187414237}, {\"truth_threshold\": 29.36, \"match_probability\": 0.9999999985486929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1395, \"tn\": 8049, \"fp\": 0, \"fn\": 10629, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11601796407185629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8839820359281437, \"precision\": 1.0, \"recall\": 0.11601796407185629, \"specificity\": 1.0, \"npv\": 0.4309347895920334, \"accuracy\": 0.4704827380062771, \"f1\": 0.20791415157612342, \"f2\": 0.1409347154028005, \"f0_5\": 0.3962167689161554, \"p4\": 0.309121601531838, \"phi\": 0.2235982489560271}, {\"truth_threshold\": 29.38, \"match_probability\": 0.9999999985686735, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1393, \"tn\": 8049, \"fp\": 0, \"fn\": 10631, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11585163007318695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.884148369926813, \"precision\": 1.0, \"recall\": 0.11585163007318695, \"specificity\": 1.0, \"npv\": 0.4308886509635974, \"accuracy\": 0.4703831016788721, \"f1\": 0.20764701498099425, \"f2\": 0.14073834589504738, \"f0_5\": 0.39582859740850196, \"p4\": 0.30882032691870576, \"phi\": 0.22342594431750593}, {\"truth_threshold\": 29.400000000000002, \"match_probability\": 0.999999998588379, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1390, \"tn\": 8049, \"fp\": 0, \"fn\": 10634, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11560212907518297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.884397870924817, \"precision\": 1.0, \"recall\": 0.11560212907518297, \"specificity\": 1.0, \"npv\": 0.43081946154257883, \"accuracy\": 0.47023364718776467, \"f1\": 0.20724616072759802, \"f2\": 0.14044376187204463, \"f0_5\": 0.39524567788899, \"p4\": 0.30836792711276984, \"phi\": 0.2231673071965202}, {\"truth_threshold\": 29.42, \"match_probability\": 0.9999999986078132, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1388, \"tn\": 8049, \"fp\": 0, \"fn\": 10636, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11543579507651364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8845642049234863, \"precision\": 1.0, \"recall\": 0.11543579507651364, \"specificity\": 1.0, \"npv\": 0.4307733476050308, \"accuracy\": 0.47013401086035966, \"f1\": 0.2069788249328959, \"f2\": 0.14024735267965402, \"f0_5\": 0.39485662266727356, \"p4\": 0.3080660013878397, \"phi\": 0.22299476199803014}, {\"truth_threshold\": 29.44, \"match_probability\": 0.9999999986269797, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1387, \"tn\": 8049, \"fp\": 0, \"fn\": 10637, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11535262807717897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8846473719228211, \"precision\": 1.0, \"recall\": 0.11535262807717897, \"specificity\": 1.0, \"npv\": 0.43075029433800704, \"accuracy\": 0.4700841926966572, \"f1\": 0.20684512713444186, \"f2\": 0.14014914212962026, \"f0_5\": 0.39466196221261096, \"p4\": 0.3079149406153013, \"phi\": 0.2229084531750815}, {\"truth_threshold\": 29.46, \"match_probability\": 0.9999999986458826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1385, \"tn\": 8049, \"fp\": 0, \"fn\": 10639, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11518629407850965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8848137059214903, \"precision\": 1.0, \"recall\": 0.11518629407850965, \"specificity\": 1.0, \"npv\": 0.4307041952054795, \"accuracy\": 0.46998455636925224, \"f1\": 0.20657767171302857, \"f2\": 0.1399527091206726, \"f0_5\": 0.3942723753131405, \"p4\": 0.3076126229932486, \"phi\": 0.22273576293398906}, {\"truth_threshold\": 29.48, \"match_probability\": 0.9999999986645252, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1381, \"tn\": 8049, \"fp\": 0, \"fn\": 10643, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11485362608117099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.885146373918829, \"precision\": 1.0, \"recall\": 0.11485362608117099, \"specificity\": 1.0, \"npv\": 0.43061202653541625, \"accuracy\": 0.4697852837144423, \"f1\": 0.20604252144722118, \"f2\": 0.139559795460517, \"f0_5\": 0.393492135855938, \"p4\": 0.3070072019996718, \"phi\": 0.22239009124004147}, {\"truth_threshold\": 29.5, \"match_probability\": 0.999999998682911, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1379, \"tn\": 8049, \"fp\": 0, \"fn\": 10645, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11468729208250167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8853127079174984, \"precision\": 1.0, \"recall\": 0.11468729208250167, \"specificity\": 1.0, \"npv\": 0.4305659569915481, \"accuracy\": 0.46968564738703733, \"f1\": 0.20577482653137358, \"f2\": 0.1393633148054573, \"f0_5\": 0.39310148232611175, \"p4\": 0.306704097802488, \"phi\": 0.22221710931040284}, {\"truth_threshold\": 29.52, \"match_probability\": 0.9999999987010437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1377, \"tn\": 8049, \"fp\": 0, \"fn\": 10647, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11452095808383234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8854790419161677, \"precision\": 1.0, \"recall\": 0.11452095808383234, \"specificity\": 1.0, \"npv\": 0.4305198973042362, \"accuracy\": 0.4695860110596323, \"f1\": 0.20550705171255876, \"f2\": 0.1391668182645079, \"f0_5\": 0.39271047227926076, \"p4\": 0.3064007305865181, \"phi\": 0.2220440296730228}, {\"truth_threshold\": 29.54, \"match_probability\": 0.9999999987189269, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1373, \"tn\": 8049, \"fp\": 0, \"fn\": 10651, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11418829008649369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8858117099135063, \"precision\": 1.0, \"recall\": 0.11418829008649369, \"specificity\": 1.0, \"npv\": 0.430427807486631, \"accuracy\": 0.4693867384048224, \"f1\": 0.20497126222288573, \"f2\": 0.13877377751723302, \"f0_5\": 0.3919273806805207, \"p4\": 0.3057932054375371, \"phi\": 0.2216975763119139}, {\"truth_threshold\": 29.560000000000002, \"match_probability\": 0.9999999987365638, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1372, \"tn\": 8049, \"fp\": 0, \"fn\": 10652, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11410512308715902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.885894876912841, \"precision\": 1.0, \"recall\": 0.11410512308715902, \"specificity\": 1.0, \"npv\": 0.430404791187637, \"accuracy\": 0.4693369202411199, \"f1\": 0.20483726485518064, \"f2\": 0.13867550739872242, \"f0_5\": 0.39173138419369574, \"p4\": 0.3056411591141444, \"phi\": 0.22161090152735785}, {\"truth_threshold\": 29.580000000000002, \"match_probability\": 0.9999999987539578, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1364, \"tn\": 8049, \"fp\": 0, \"fn\": 10660, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1134397870924817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8865602129075183, \"precision\": 1.0, \"recall\": 0.1134397870924817, \"specificity\": 1.0, \"npv\": 0.43022074937196003, \"accuracy\": 0.46893837493150003, \"f1\": 0.2037645652823424, \"f2\": 0.1378892033966842, \"f0_5\": 0.3901601830663616, \"p4\": 0.30442240386046315, \"phi\": 0.220916613706446}, {\"truth_threshold\": 29.62, \"match_probability\": 0.9999999987880309, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1362, \"tn\": 8049, \"fp\": 0, \"fn\": 10662, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11327345309381237, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8867265469061876, \"precision\": 1.0, \"recall\": 0.11327345309381237, \"specificity\": 1.0, \"npv\": 0.43017476350809686, \"accuracy\": 0.46883873860409503, \"f1\": 0.20349619004930525, \"f2\": 0.13769258765012737, \"f0_5\": 0.3897664835164835, \"p4\": 0.30411705071759176, \"phi\": 0.22074279353214735}, {\"truth_threshold\": 29.64, \"match_probability\": 0.9999999988047165, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1352, \"tn\": 8049, \"fp\": 0, \"fn\": 10672, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11244178310046574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8875582168995343, \"precision\": 1.0, \"recall\": 0.11244178310046574, \"specificity\": 1.0, \"npv\": 0.42994498157149724, \"accuracy\": 0.4683405569670702, \"f1\": 0.2021531100478469, \"f2\": 0.13670927034460442, \"f0_5\": 0.3877925653969711, \"p4\": 0.30258627794438214, \"phi\": 0.21987219097238295}, {\"truth_threshold\": 29.66, \"match_probability\": 0.9999999988211723, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1351, \"tn\": 8049, \"fp\": 0, \"fn\": 10673, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11235861610113107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8876413838988689, \"precision\": 1.0, \"recall\": 0.11235861610113107, \"specificity\": 1.0, \"npv\": 0.4299220168785386, \"accuracy\": 0.4682907388033677, \"f1\": 0.20201869158878505, \"f2\": 0.13661091673913484, \"f0_5\": 0.3875946752352536, \"p4\": 0.3024328320903564, \"phi\": 0.2197849923172183}, {\"truth_threshold\": 29.68, \"match_probability\": 0.9999999988374015, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1350, \"tn\": 8049, \"fp\": 0, \"fn\": 10674, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1122754491017964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8877245508982036, \"precision\": 1.0, \"recall\": 0.1122754491017964, \"specificity\": 1.0, \"npv\": 0.4298990546386797, \"accuracy\": 0.4682409206396652, \"f1\": 0.2018842530282638, \"f2\": 0.1365125591554423, \"f0_5\": 0.38739669421487605, \"p4\": 0.3022793190096475, \"phi\": 0.2196977683728159}, {\"truth_threshold\": 29.7, \"match_probability\": 0.9999999988534074, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1347, \"tn\": 8049, \"fp\": 0, \"fn\": 10677, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11202594810379242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8879740518962076, \"precision\": 1.0, \"recall\": 0.11202594810379242, \"specificity\": 1.0, \"npv\": 0.4298301826337712, \"accuracy\": 0.4680914661485578, \"f1\": 0.2014808166928427, \"f2\": 0.13621746253261333, \"f0_5\": 0.38680220537560306, \"p4\": 0.3018183758735109, \"phi\": 0.2194359444876214}, {\"truth_threshold\": 29.72, \"match_probability\": 0.9999999988691929, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1336, \"tn\": 8049, \"fp\": 0, \"fn\": 10688, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1111111111111111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8888888888888888, \"precision\": 1.0, \"recall\": 0.1111111111111111, \"specificity\": 1.0, \"npv\": 0.42957784063617444, \"accuracy\": 0.4675434663478304, \"f1\": 0.2, \"f2\": 0.13513513513513514, \"f0_5\": 0.38461538461538464, \"p4\": 0.3001230470934785, \"phi\": 0.2184739599627314}, {\"truth_threshold\": 29.740000000000002, \"match_probability\": 0.9999999988847611, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1334, \"tn\": 8049, \"fp\": 0, \"fn\": 10690, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11094477711244179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8890552228875582, \"precision\": 1.0, \"recall\": 0.11094477711244179, \"specificity\": 1.0, \"npv\": 0.4295319921020332, \"accuracy\": 0.46744383002042544, \"f1\": 0.1997304985776314, \"f2\": 0.13493829658102366, \"f0_5\": 0.38421658986175117, \"p4\": 0.29981392317494493, \"phi\": 0.2182987199376652}, {\"truth_threshold\": 29.78, \"match_probability\": 0.9999999989152574, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1332, \"tn\": 8049, \"fp\": 0, \"fn\": 10692, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11077844311377245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8892215568862275, \"precision\": 1.0, \"recall\": 0.11077844311377245, \"specificity\": 1.0, \"npv\": 0.42948615335360973, \"accuracy\": 0.4673441936930205, \"f1\": 0.19946091644204852, \"f2\": 0.1347414420975965, \"f0_5\": 0.38381742738589214, \"p4\": 0.29950452669061695, \"phi\": 0.21812337657260814}, {\"truth_threshold\": 29.8, \"match_probability\": 0.9999999989301913, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1329, \"tn\": 8049, \"fp\": 0, \"fn\": 10695, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11052894211576847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8894710578842315, \"precision\": 1.0, \"recall\": 0.11052894211576847, \"specificity\": 1.0, \"npv\": 0.42941741357234314, \"accuracy\": 0.467194739201913, \"f1\": 0.19905639182206245, \"f2\": 0.13444613050075874, \"f0_5\": 0.38321799307958476, \"p4\": 0.29903991995202556, \"phi\": 0.21786016719042636}, {\"truth_threshold\": 29.82, \"match_probability\": 0.9999999989449196, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1323, \"tn\": 8049, \"fp\": 0, \"fn\": 10701, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.11002994011976049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8899700598802395, \"precision\": 1.0, \"recall\": 0.11002994011976049, \"specificity\": 1.0, \"npv\": 0.42928, \"accuracy\": 0.4668958302196981, \"f1\": 0.19824679703304113, \"f2\": 0.13385539974503732, \"f0_5\": 0.382016632016632, \"p4\": 0.29810885783176244, \"phi\": 0.2173330455651206}, {\"truth_threshold\": 29.84, \"match_probability\": 0.9999999989594452, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1317, \"tn\": 8049, \"fp\": 0, \"fn\": 10707, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10953093812375249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8904690618762475, \"precision\": 1.0, \"recall\": 0.10953093812375249, \"specificity\": 1.0, \"npv\": 0.42914267434420983, \"accuracy\": 0.4665969212374832, \"f1\": 0.19743647402743422, \"f2\": 0.1332645255297189, \"f0_5\": 0.3808119361554476, \"p4\": 0.2971753209931319, \"phi\": 0.21680498082345184}, {\"truth_threshold\": 29.86, \"match_probability\": 0.9999999989737709, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1315, \"tn\": 8049, \"fp\": 0, \"fn\": 10709, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10936460412508317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8906353958749168, \"precision\": 1.0, \"recall\": 0.10936460412508317, \"specificity\": 1.0, \"npv\": 0.4290969186480435, \"accuracy\": 0.4664972849100782, \"f1\": 0.19716620436314566, \"f2\": 0.13306753556900286, \"f0_5\": 0.38040962740106454, \"p4\": 0.29686359005518675, \"phi\": 0.21662874841358498}, {\"truth_threshold\": 29.88, \"match_probability\": 0.9999999989878993, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1309, \"tn\": 8049, \"fp\": 0, \"fn\": 10715, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10886560212907519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8911343978709249, \"precision\": 1.0, \"recall\": 0.10886560212907519, \"specificity\": 1.0, \"npv\": 0.42895971008313794, \"accuracy\": 0.4661983759278633, \"f1\": 0.1963549088727218, \"f2\": 0.1324764699929157, \"f0_5\": 0.3792004634994206, \"p4\": 0.2959267350709088, \"phi\": 0.21609941491664045}, {\"truth_threshold\": 29.900000000000002, \"match_probability\": 0.9999999990018332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1305, \"tn\": 8049, \"fp\": 0, \"fn\": 10719, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10853293413173652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8914670658682635, \"precision\": 1.0, \"recall\": 0.10853293413173652, \"specificity\": 1.0, \"npv\": 0.4288682864450128, \"accuracy\": 0.46599910327305333, \"f1\": 0.19581363943281566, \"f2\": 0.13208234651120423, \"f0_5\": 0.37839248434237993, \"p4\": 0.2953007754933034, \"phi\": 0.2157459929730499}, {\"truth_threshold\": 29.92, \"match_probability\": 0.9999999990155752, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1300, \"tn\": 8049, \"fp\": 0, \"fn\": 10724, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1081170991350632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8918829008649368, \"precision\": 1.0, \"recall\": 0.1081170991350632, \"specificity\": 1.0, \"npv\": 0.4287540616843339, \"accuracy\": 0.46575001245454095, \"f1\": 0.19513659561693186, \"f2\": 0.13158960239695522, \"f0_5\": 0.3773803994426382, \"p4\": 0.2945167564545392, \"phi\": 0.21530361211945825}, {\"truth_threshold\": 29.94, \"match_probability\": 0.9999999990291281, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1297, \"tn\": 8049, \"fp\": 0, \"fn\": 10727, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10786759813705922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8921324018629407, \"precision\": 1.0, \"recall\": 0.10786759813705922, \"specificity\": 1.0, \"npv\": 0.4286855560289732, \"accuracy\": 0.46560055796343347, \"f1\": 0.1947301253659635, \"f2\": 0.1312939080436499, \"f0_5\": 0.3767720195212642, \"p4\": 0.2940455052368043, \"phi\": 0.2150378601197823}, {\"truth_threshold\": 29.96, \"match_probability\": 0.9999999990424944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1296, \"tn\": 8049, \"fp\": 0, \"fn\": 10728, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10778443113772455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8922155688622755, \"precision\": 1.0, \"recall\": 0.10778443113772455, \"specificity\": 1.0, \"npv\": 0.42866272567502794, \"accuracy\": 0.465550739799731, \"f1\": 0.1945945945945946, \"f2\": 0.13119533527696792, \"f0_5\": 0.37656903765690375, \"p4\": 0.29388828119413796, \"phi\": 0.2149492219963342}, {\"truth_threshold\": 30.0, \"match_probability\": 0.9999999990686774, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1294, \"tn\": 8049, \"fp\": 0, \"fn\": 10730, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10761809713905522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8923819028609448, \"precision\": 1.0, \"recall\": 0.10761809713905522, \"specificity\": 1.0, \"npv\": 0.42861707226156875, \"accuracy\": 0.465451103472326, \"f1\": 0.1943234719927917, \"f2\": 0.13099817776877912, \"f0_5\": 0.37616279069767444, \"p4\": 0.2935736223150212, \"phi\": 0.21477186435402323}, {\"truth_threshold\": 30.02, \"match_probability\": 0.9999999990814992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1290, \"tn\": 8049, \"fp\": 0, \"fn\": 10734, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10728542914171657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8927145708582834, \"precision\": 1.0, \"recall\": 0.10728542914171657, \"specificity\": 1.0, \"npv\": 0.42852579460150136, \"accuracy\": 0.4652518308175161, \"f1\": 0.19378098242451555, \"f2\": 0.13060381484631273, \"f0_5\": 0.3753491620111732, \"p4\": 0.29294345979711645, \"phi\": 0.21441682250261326}, {\"truth_threshold\": 30.04, \"match_probability\": 0.9999999990941445, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1286, \"tn\": 8049, \"fp\": 0, \"fn\": 10738, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1069527611443779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8930472388556221, \"precision\": 1.0, \"recall\": 0.1069527611443779, \"specificity\": 1.0, \"npv\": 0.4284345558098685, \"accuracy\": 0.46505255816270613, \"f1\": 0.1932381667918858, \"f2\": 0.13020938803612653, \"f0_5\": 0.3745340167753961, \"p4\": 0.29231216790607356, \"phi\": 0.2140613433423478}, {\"truth_threshold\": 30.080000000000002, \"match_probability\": 0.9999999991189151, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1284, \"tn\": 8049, \"fp\": 0, \"fn\": 10740, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10678642714570859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8932135728542914, \"precision\": 1.0, \"recall\": 0.10678642714570859, \"specificity\": 1.0, \"npv\": 0.4283889509819575, \"accuracy\": 0.4649529218353011, \"f1\": 0.19296663660955815, \"f2\": 0.13001215066828675, \"f0_5\": 0.3741258741258741, \"p4\": 0.2919960973069434, \"phi\": 0.2138834390598331}, {\"truth_threshold\": 30.1, \"match_probability\": 0.9999999991310453, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1283, \"tn\": 8049, \"fp\": 0, \"fn\": 10741, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10670326014637392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8932967398536261, \"precision\": 1.0, \"recall\": 0.10670326014637392, \"specificity\": 1.0, \"npv\": 0.4283661522086216, \"accuracy\": 0.46490310367159865, \"f1\": 0.19283084091079883, \"f2\": 0.12991352599283096, \"f0_5\": 0.37392166006062016, \"p4\": 0.2918379556441289, \"phi\": 0.21379444561778904}, {\"truth_threshold\": 30.12, \"match_probability\": 0.9999999991430085, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1281, \"tn\": 8049, \"fp\": 0, \"fn\": 10743, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10653692614770459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8934630738522954, \"precision\": 1.0, \"recall\": 0.10653692614770459, \"specificity\": 1.0, \"npv\": 0.4283205619412516, \"accuracy\": 0.4648034673441937, \"f1\": 0.19255918827508456, \"f2\": 0.1297162646576341, \"f0_5\": 0.37351294611616515, \"p4\": 0.2915214593058266, \"phi\": 0.2136163759524968}, {\"truth_threshold\": 30.14, \"match_probability\": 0.999999999154807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1277, \"tn\": 8049, \"fp\": 0, \"fn\": 10747, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10620425815036594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8937957418496341, \"precision\": 1.0, \"recall\": 0.10620425815036594, \"specificity\": 1.0, \"npv\": 0.42822941051287505, \"accuracy\": 0.46460419468938374, \"f1\": 0.19201563792196075, \"f2\": 0.12932169404330301, \"f0_5\": 0.3726943731029652, \"p4\": 0.2908876129721455, \"phi\": 0.21325990448672813}, {\"truth_threshold\": 30.16, \"match_probability\": 0.999999999166443, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1276, \"tn\": 8049, \"fp\": 0, \"fn\": 10748, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10612109115103127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8938789088489687, \"precision\": 1.0, \"recall\": 0.10612109115103127, \"specificity\": 1.0, \"npv\": 0.4282066287173485, \"accuracy\": 0.46455437652568127, \"f1\": 0.1918796992481203, \"f2\": 0.1292230413999838, \"f0_5\": 0.3724894908921065, \"p4\": 0.2907289732081302, \"phi\": 0.21317071721413694}, {\"truth_threshold\": 30.18, \"match_probability\": 0.9999999991779188, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1274, \"tn\": 8049, \"fp\": 0, \"fn\": 10750, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10595475715236194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8940452428476381, \"precision\": 1.0, \"recall\": 0.10595475715236194, \"specificity\": 1.0, \"npv\": 0.4281610723974679, \"accuracy\": 0.4644547401982763, \"f1\": 0.19160776056549858, \"f2\": 0.12902572412396193, \"f0_5\": 0.37207943925233644, \"p4\": 0.2904114794599834, \"phi\": 0.21299225912687195}, {\"truth_threshold\": 30.22, \"match_probability\": 0.9999999992003986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1272, \"tn\": 8049, \"fp\": 0, \"fn\": 10752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10578842315369262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8942115768463074, \"precision\": 1.0, \"recall\": 0.10578842315369262, \"specificity\": 1.0, \"npv\": 0.42811552576990586, \"accuracy\": 0.4643551038708713, \"f1\": 0.19133574007220217, \"f2\": 0.12882839086047643, \"f0_5\": 0.37166900420757365, \"p4\": 0.290093699699908, \"phi\": 0.21281368940651443}, {\"truth_threshold\": 30.240000000000002, \"match_probability\": 0.999999999211407, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1270, \"tn\": 8049, \"fp\": 0, \"fn\": 10754, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10562208915502329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8943779108449768, \"precision\": 1.0, \"recall\": 0.10562208915502329, \"specificity\": 1.0, \"npv\": 0.42806998883156944, \"accuracy\": 0.46425546754346636, \"f1\": 0.19106363773130736, \"f2\": 0.12863104160758418, \"f0_5\": 0.3712581852198316, \"p4\": 0.2897756334649196, \"phi\": 0.2126350077596769}, {\"truth_threshold\": 30.26, \"match_probability\": 0.9999999992222638, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1269, \"tn\": 8049, \"fp\": 0, \"fn\": 10755, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10553892215568862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8944610778443114, \"precision\": 1.0, \"recall\": 0.10553892215568862, \"specificity\": 1.0, \"npv\": 0.4280472239948947, \"accuracy\": 0.4642056493797639, \"f1\": 0.1909275558564658, \"f2\": 0.12853236098450319, \"f0_5\": 0.37105263157894736, \"p4\": 0.2896164927743823, \"phi\": 0.21254562487182793}, {\"truth_threshold\": 30.28, \"match_probability\": 0.9999999992329711, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1263, \"tn\": 8049, \"fp\": 0, \"fn\": 10761, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10503992015968064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8949600798403193, \"precision\": 1.0, \"recall\": 0.10503992015968064, \"specificity\": 1.0, \"npv\": 0.42791068580542263, \"accuracy\": 0.4639067403975489, \"f1\": 0.1901106344547302, \"f2\": 0.12794019327782166, \"f0_5\": 0.36981728742094166, \"p4\": 0.2886601389451464, \"phi\": 0.21200873631168074}, {\"truth_threshold\": 30.3, \"match_probability\": 0.999999999243531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1260, \"tn\": 8049, \"fp\": 0, \"fn\": 10764, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10479041916167664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8952095808383234, \"precision\": 1.0, \"recall\": 0.10479041916167664, \"specificity\": 1.0, \"npv\": 0.4278424493701164, \"accuracy\": 0.4637572859064415, \"f1\": 0.1897018970189702, \"f2\": 0.1276440554339898, \"f0_5\": 0.3691983122362869, \"p4\": 0.2881809888930404, \"phi\": 0.21173991027827727}, {\"truth_threshold\": 30.32, \"match_probability\": 0.9999999992539456, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1256, \"tn\": 8049, \"fp\": 0, \"fn\": 10768, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10445775116433799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.895542248835662, \"precision\": 1.0, \"recall\": 0.10445775116433799, \"specificity\": 1.0, \"npv\": 0.4277515013020141, \"accuracy\": 0.46355801325163154, \"f1\": 0.1891566265060241, \"f2\": 0.12724914897065975, \"f0_5\": 0.3683716564992961, \"p4\": 0.28754110942516375, \"phi\": 0.2113810774009296}, {\"truth_threshold\": 30.34, \"match_probability\": 0.9999999992642167, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1255, \"tn\": 8049, \"fp\": 0, \"fn\": 10769, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10437458416500332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8956254158349967, \"precision\": 1.0, \"recall\": 0.10437458416500332, \"specificity\": 1.0, \"npv\": 0.42772877032628337, \"accuracy\": 0.46350819508792906, \"f1\": 0.18902025754951426, \"f2\": 0.1271504123523333, \"f0_5\": 0.36816475005867166, \"p4\": 0.28738095832144744, \"phi\": 0.21129129782888373}, {\"truth_threshold\": 30.36, \"match_probability\": 0.9999999992743465, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1254, \"tn\": 8049, \"fp\": 0, \"fn\": 10770, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10429141716566866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8957085828343313, \"precision\": 1.0, \"recall\": 0.10429141716566866, \"specificity\": 1.0, \"npv\": 0.4277060417663, \"accuracy\": 0.4634583769242266, \"f1\": 0.18888386805241753, \"f2\": 0.1270516717325228, \"f0_5\": 0.36795774647887325, \"p4\": 0.2872207346052128, \"phi\": 0.2112014896399315}, {\"truth_threshold\": 30.400000000000002, \"match_probability\": 0.9999999992941895, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1250, \"tn\": 8049, \"fp\": 0, \"fn\": 10774, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10395874916833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.89604125083167, \"precision\": 1.0, \"recall\": 0.10395874916833, \"specificity\": 1.0, \"npv\": 0.4276151516761409, \"accuracy\": 0.46325910426941663, \"f1\": 0.18833810456531566, \"f2\": 0.12665666923357516, \"f0_5\": 0.36712875939849626, \"p4\": 0.2865791124337623, \"phi\": 0.21084196995303692}, {\"truth_threshold\": 30.42, \"match_probability\": 0.9999999993039066, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1248, \"tn\": 8049, \"fp\": 0, \"fn\": 10776, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10379241516966067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8962075848303394, \"precision\": 1.0, \"recall\": 0.10379241516966067, \"specificity\": 1.0, \"npv\": 0.42756972111553787, \"accuracy\": 0.4631594679420117, \"f1\": 0.18806509945750452, \"f2\": 0.1264591439688716, \"f0_5\": 0.36671368124118475, \"p4\": 0.2862578641354388, \"phi\": 0.2106620374153823}, {\"truth_threshold\": 30.46, \"match_probability\": 0.9999999993229413, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1237, \"tn\": 8049, \"fp\": 0, \"fn\": 10787, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10287757817697937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8971224218230206, \"precision\": 1.0, \"recall\": 0.10287757817697937, \"specificity\": 1.0, \"npv\": 0.4273200254831174, \"accuracy\": 0.4626114681412843, \"f1\": 0.18656209938918633, \"f2\": 0.12537246873289684, \"f0_5\": 0.36442375677586614, \"p4\": 0.2844857642799111, \"phi\": 0.20967033487889564}, {\"truth_threshold\": 30.48, \"match_probability\": 0.9999999993322626, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1234, \"tn\": 8049, \"fp\": 0, \"fn\": 10790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10262807717897539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8973719228210246, \"precision\": 1.0, \"recall\": 0.10262807717897539, \"specificity\": 1.0, \"npv\": 0.42725197728117204, \"accuracy\": 0.46246201365017686, \"f1\": 0.18615175742947654, \"f2\": 0.12507601864990878, \"f0_5\": 0.36379716981132076, \"p4\": 0.2840009203005196, \"phi\": 0.20939925716029167}, {\"truth_threshold\": 30.52, \"match_probability\": 0.9999999993505219, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1231, \"tn\": 8049, \"fp\": 0, \"fn\": 10793, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10237857618097139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8976214238190287, \"precision\": 1.0, \"recall\": 0.10237857618097139, \"specificity\": 1.0, \"npv\": 0.4271839507483282, \"accuracy\": 0.4623125591590694, \"f1\": 0.18574122972463222, \"f2\": 0.12477953250755165, \"f0_5\": 0.3631696955392967, \"p4\": 0.28351541153377846, \"phi\": 0.20912791455225685}, {\"truth_threshold\": 30.54, \"match_probability\": 0.9999999993594634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1228, \"tn\": 8049, \"fp\": 0, \"fn\": 10796, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.1021290751829674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8978709248170326, \"precision\": 1.0, \"recall\": 0.1021290751829674, \"specificity\": 1.0, \"npv\": 0.4271159458742372, \"accuracy\": 0.46216310466796195, \"f1\": 0.18533051614850587, \"f2\": 0.1244830102992458, \"f0_5\": 0.36254133207368916, \"p4\": 0.2830292363483507, \"phi\": 0.20885630598101224}, {\"truth_threshold\": 30.560000000000002, \"match_probability\": 0.9999999993682819, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1220, \"tn\": 8049, \"fp\": 0, \"fn\": 10804, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10146373918829009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8985362608117099, \"precision\": 1.0, \"recall\": 0.10146373918829009, \"specificity\": 1.0, \"npv\": 0.4269347053519334, \"accuracy\": 0.46176455935834204, \"f1\": 0.1842343702808819, \"f2\": 0.12369210803795928, \"f0_5\": 0.36086133459536207, \"p4\": 0.28172949867752006, \"phi\": 0.20813070795598146}, {\"truth_threshold\": 30.580000000000002, \"match_probability\": 0.9999999993769789, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1219, \"tn\": 8049, \"fp\": 0, \"fn\": 10805, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10138057218895542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8986194278110445, \"precision\": 1.0, \"recall\": 0.10138057218895542, \"specificity\": 1.0, \"npv\": 0.4269120611010926, \"accuracy\": 0.46171474119463957, \"f1\": 0.18409725892924564, \"f2\": 0.12359322721281557, \"f0_5\": 0.3606508875739645, \"p4\": 0.28156669588780825, \"phi\": 0.2080398736511707}, {\"truth_threshold\": 30.6, \"match_probability\": 0.9999999993855563, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1217, \"tn\": 8049, \"fp\": 0, \"fn\": 10807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10121423819028609, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8987857618097139, \"precision\": 1.0, \"recall\": 0.10121423819028609, \"specificity\": 1.0, \"npv\": 0.42686677980483667, \"accuracy\": 0.4616151048672346, \"f1\": 0.1838229740956121, \"f2\": 0.12339545353152313, \"f0_5\": 0.360229694529955, \"p4\": 0.28124086591495845, \"phi\": 0.20785811489255632}, {\"truth_threshold\": 30.62, \"match_probability\": 0.9999999993940155, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1212, \"tn\": 8049, \"fp\": 0, \"fn\": 10812, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10079840319361277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8992015968063872, \"precision\": 1.0, \"recall\": 0.10079840319361277, \"specificity\": 1.0, \"npv\": 0.42675361857801813, \"accuracy\": 0.4613660140487222, \"f1\": 0.18313689936536717, \"f2\": 0.12290094913604284, \"f0_5\": 0.35917496443812236, \"p4\": 0.28042497915437253, \"phi\": 0.2074031902111448}, {\"truth_threshold\": 30.66, \"match_probability\": 0.9999999994105861, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1206, \"tn\": 8049, \"fp\": 0, \"fn\": 10818, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10029940119760479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8997005988023952, \"precision\": 1.0, \"recall\": 0.10029940119760479, \"specificity\": 1.0, \"npv\": 0.4266179042773096, \"accuracy\": 0.4610671050665072, \"f1\": 0.18231292517006803, \"f2\": 0.12230741146403797, \"f0_5\": 0.3579059829059829, \"p4\": 0.2794434324901705, \"phi\": 0.2068562794289582}, {\"truth_threshold\": 30.68, \"match_probability\": 0.9999999994187008, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1205, \"tn\": 8049, \"fp\": 0, \"fn\": 10819, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.10021623419827012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8997837658017299, \"precision\": 1.0, \"recall\": 0.10021623419827012, \"specificity\": 1.0, \"npv\": 0.42659529361882553, \"accuracy\": 0.46101728690280475, \"f1\": 0.18217552347116184, \"f2\": 0.12220847447313442, \"f0_5\": 0.3576941344098789, \"p4\": 0.27927957721201524, \"phi\": 0.20676502086471016}, {\"truth_threshold\": 30.7, \"match_probability\": 0.9999999994267037, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1201, \"tn\": 8049, \"fp\": 0, \"fn\": 10823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09988356620093147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9001164337990686, \"precision\": 1.0, \"recall\": 0.09988356620093147, \"specificity\": 1.0, \"npv\": 0.42650487494701145, \"accuracy\": 0.46081801424799484, \"f1\": 0.1816257088846881, \"f2\": 0.12181268637036737, \"f0_5\": 0.3568457333016401, \"p4\": 0.27862339905594274, \"phi\": 0.20639968001862263}, {\"truth_threshold\": 30.72, \"match_probability\": 0.9999999994345965, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1198, \"tn\": 8049, \"fp\": 0, \"fn\": 10826, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09963406520292747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9003659347970725, \"precision\": 1.0, \"recall\": 0.09963406520292747, \"specificity\": 1.0, \"npv\": 0.42643708609271525, \"accuracy\": 0.46066855975688736, \"f1\": 0.1812131296324308, \"f2\": 0.12151580314034162, \"f0_5\": 0.3562083729781161, \"p4\": 0.2781304687961385, \"phi\": 0.20612535128098142}, {\"truth_threshold\": 30.740000000000002, \"match_probability\": 0.9999999994423805, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1193, \"tn\": 8049, \"fp\": 0, \"fn\": 10831, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09921823020625416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9007817697937458, \"precision\": 1.0, \"recall\": 0.09921823020625416, \"specificity\": 1.0, \"npv\": 0.4263241525423729, \"accuracy\": 0.46041946893837493, \"f1\": 0.1805250813346448, \"f2\": 0.1210209174460833, \"f0_5\": 0.35514408192426766, \"p4\": 0.2773073959390493, \"phi\": 0.20566751787639043}, {\"truth_threshold\": 30.78, \"match_probability\": 0.9999999994576286, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1190, \"tn\": 8049, \"fp\": 0, \"fn\": 10834, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09896872920825017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9010312707917498, \"precision\": 1.0, \"recall\": 0.09896872920825017, \"specificity\": 1.0, \"npv\": 0.4262564211195255, \"accuracy\": 0.46027001444726745, \"f1\": 0.180112002421674, \"f2\": 0.12072393783224446, \"f0_5\": 0.35450428979980936, \"p4\": 0.27681263600404615, \"phi\": 0.20539244463966091}, {\"truth_threshold\": 30.8, \"match_probability\": 0.9999999994650957, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1189, \"tn\": 8049, \"fp\": 0, \"fn\": 10835, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0988855622089155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9011144377910845, \"precision\": 1.0, \"recall\": 0.0988855622089155, \"specificity\": 1.0, \"npv\": 0.42623384876085574, \"accuracy\": 0.460220196283565, \"f1\": 0.1799742677665935, \"f2\": 0.12062493659328397, \"f0_5\": 0.3542908224076281, \"p4\": 0.2766475629438065, \"phi\": 0.20530069110255594}, {\"truth_threshold\": 30.82, \"match_probability\": 0.9999999994724599, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1185, \"tn\": 8049, \"fp\": 0, \"fn\": 10839, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09855289421157684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9014471057884231, \"precision\": 1.0, \"recall\": 0.09855289421157684, \"specificity\": 1.0, \"npv\": 0.426143583227446, \"accuracy\": 0.460020923628755, \"f1\": 0.1794231205995912, \"f2\": 0.12022889145918306, \"f0_5\": 0.35343593414459556, \"p4\": 0.27598650360541443, \"phi\": 0.20493336350325386}, {\"truth_threshold\": 30.84, \"match_probability\": 0.9999999994797226, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1181, \"tn\": 8049, \"fp\": 0, \"fn\": 10843, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09822022621423819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9017797737857618, \"precision\": 1.0, \"recall\": 0.09822022621423819, \"specificity\": 1.0, \"npv\": 0.4260533559178488, \"accuracy\": 0.4598216509739451, \"f1\": 0.17887163953048088, \"f2\": 0.11983278202812671, \"f0_5\": 0.35257941246716024, \"p4\": 0.2753242138630143, \"phi\": 0.20456553228143406}, {\"truth_threshold\": 30.86, \"match_probability\": 0.9999999994868854, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1179, \"tn\": 8049, \"fp\": 0, \"fn\": 10845, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09805389221556886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9019461077844312, \"precision\": 1.0, \"recall\": 0.09805389221556886, \"specificity\": 1.0, \"npv\": 0.42600825658939345, \"accuracy\": 0.4597220146465401, \"f1\": 0.17859577368779822, \"f2\": 0.11963470319634703, \"f0_5\": 0.3521505376344086, \"p4\": 0.2749926063164747, \"phi\": 0.20438142693150663}, {\"truth_threshold\": 30.88, \"match_probability\": 0.9999999994939497, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1174, \"tn\": 8049, \"fp\": 0, \"fn\": 10850, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09763805721889554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9023619427811045, \"precision\": 1.0, \"recall\": 0.09763805721889554, \"specificity\": 1.0, \"npv\": 0.42589555002910207, \"accuracy\": 0.4594729238280277, \"f1\": 0.17790574329443856, \"f2\": 0.11913943576212706, \"f0_5\": 0.35107655502392343, \"p4\": 0.2741622338768454, \"phi\": 0.20392060730346617}, {\"truth_threshold\": 30.900000000000002, \"match_probability\": 0.9999999995009166, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1173, \"tn\": 8049, \"fp\": 0, \"fn\": 10851, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09755489021956087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9024451097804391, \"precision\": 1.0, \"recall\": 0.09755489021956087, \"specificity\": 1.0, \"npv\": 0.42587301587301585, \"accuracy\": 0.4594231056643252, \"f1\": 0.1777676744714708, \"f2\": 0.11904037021250685, \"f0_5\": 0.35086145010768127, \"p4\": 0.2739959268345079, \"phi\": 0.2038283476628444}, {\"truth_threshold\": 30.92, \"match_probability\": 0.9999999995077876, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1167, \"tn\": 8049, \"fp\": 0, \"fn\": 10857, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09705588822355289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9029441117764471, \"precision\": 1.0, \"recall\": 0.09705588822355289, \"specificity\": 1.0, \"npv\": 0.42573786099650907, \"accuracy\": 0.4591241966821103, \"f1\": 0.17693882192403912, \"f2\": 0.11844589245478351, \"f0_5\": 0.349568655643422, \"p4\": 0.2729964512896542, \"phi\": 0.20327411603401865}, {\"truth_threshold\": 30.94, \"match_probability\": 0.9999999995145641, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1165, \"tn\": 8049, \"fp\": 0, \"fn\": 10859, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09688955422488357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9031104457751165, \"precision\": 1.0, \"recall\": 0.09688955422488357, \"specificity\": 1.0, \"npv\": 0.4256928284324096, \"accuracy\": 0.45902456035470535, \"f1\": 0.17666237015694897, \"f2\": 0.11824770102109174, \"f0_5\": 0.3491368976264685, \"p4\": 0.2726626690170827, \"phi\": 0.20308911438958516}, {\"truth_threshold\": 30.96, \"match_probability\": 0.9999999995212472, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1162, \"tn\": 8049, \"fp\": 0, \"fn\": 10862, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09664005322687957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9033599467731205, \"precision\": 1.0, \"recall\": 0.09664005322687957, \"specificity\": 1.0, \"npv\": 0.4256252974459309, \"accuracy\": 0.45887510586359787, \"f1\": 0.17624753526467465, \"f2\": 0.11795038369401925, \"f0_5\": 0.34848848368522073, \"p4\": 0.2721614090517795, \"phi\": 0.20281136901042116}, {\"truth_threshold\": 30.98, \"match_probability\": 0.9999999995278384, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1158, \"tn\": 8049, \"fp\": 0, \"fn\": 10866, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09630738522954092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.903692614770459, \"precision\": 1.0, \"recall\": 0.09630738522954092, \"specificity\": 1.0, \"npv\": 0.4255352894528152, \"accuracy\": 0.4586758332087879, \"f1\": 0.17569412835685025, \"f2\": 0.11755390425143136, \"f0_5\": 0.34762247838616717, \"p4\": 0.27149196479070314, \"phi\": 0.20244058646945398}, {\"truth_threshold\": 31.0, \"match_probability\": 0.9999999995343387, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1155, \"tn\": 8049, \"fp\": 0, \"fn\": 10869, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09605788423153692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039421157684631, \"precision\": 1.0, \"recall\": 0.09605788423153692, \"specificity\": 1.0, \"npv\": 0.42546780843640974, \"accuracy\": 0.4585263787176805, \"f1\": 0.17527885272023674, \"f2\": 0.11725650240604252, \"f0_5\": 0.3469718817591925, \"p4\": 0.27098905607750257, \"phi\": 0.20216215641665078}, {\"truth_threshold\": 31.02, \"match_probability\": 0.9999999995407496, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1152, \"tn\": 8049, \"fp\": 0, \"fn\": 10872, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09580838323353294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9041916167664671, \"precision\": 1.0, \"recall\": 0.09580838323353294, \"specificity\": 1.0, \"npv\": 0.4254003488187728, \"accuracy\": 0.458376924226573, \"f1\": 0.17486338797814208, \"f2\": 0.11695906432748537, \"f0_5\": 0.3463203463203463, \"p4\": 0.270485437810812, \"phi\": 0.2018834308389561}, {\"truth_threshold\": 31.04, \"match_probability\": 0.9999999995470722, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1148, \"tn\": 8049, \"fp\": 0, \"fn\": 10876, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09547571523619428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9045242847638058, \"precision\": 1.0, \"recall\": 0.09547571523619428, \"specificity\": 1.0, \"npv\": 0.4253104359313078, \"accuracy\": 0.45817765157176304, \"f1\": 0.17430914060127542, \"f2\": 0.1165624238485907, \"f0_5\": 0.34545016851227733, \"p4\": 0.26981283996695177, \"phi\": 0.20151133483742098}, {\"truth_threshold\": 31.060000000000002, \"match_probability\": 0.9999999995533079, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1146, \"tn\": 8049, \"fp\": 0, \"fn\": 10878, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09530938123752496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.904690618762475, \"precision\": 1.0, \"recall\": 0.09530938123752496, \"specificity\": 1.0, \"npv\": 0.4252654937391029, \"accuracy\": 0.4580780152443581, \"f1\": 0.17403189066059224, \"f2\": 0.11636407944437675, \"f0_5\": 0.345014450867052, \"p4\": 0.26947606550420244, \"phi\": 0.2013250880291486}, {\"truth_threshold\": 31.080000000000002, \"match_probability\": 0.9999999995594576, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1141, \"tn\": 8049, \"fp\": 0, \"fn\": 10883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09489354624085163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9051064537591483, \"precision\": 1.0, \"recall\": 0.09489354624085163, \"specificity\": 1.0, \"npv\": 0.42515317980139444, \"accuracy\": 0.45782892442584566, \"f1\": 0.17333839726547665, \"f2\": 0.11586814793752666, \"f0_5\": 0.3439233180612491, \"p4\": 0.2686327380995125, \"phi\": 0.20085888809542068}, {\"truth_threshold\": 31.1, \"match_probability\": 0.9999999995655227, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1139, \"tn\": 8049, \"fp\": 0, \"fn\": 10885, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09472721224218231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9052727877578177, \"precision\": 1.0, \"recall\": 0.09472721224218231, \"specificity\": 1.0, \"npv\": 0.425108270835534, \"accuracy\": 0.4577292880984407, \"f1\": 0.17306085238927296, \"f2\": 0.11566974713110592, \"f0_5\": 0.34348612786489746, \"p4\": 0.2682948492414076, \"phi\": 0.20067217394881817}, {\"truth_threshold\": 31.12, \"match_probability\": 0.9999999995715042, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1131, \"tn\": 8049, \"fp\": 0, \"fn\": 10893, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09406187624750499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.905938123752495, \"precision\": 1.0, \"recall\": 0.09406187624750499, \"specificity\": 1.0, \"npv\": 0.4249287298067786, \"accuracy\": 0.4573307427888208, \"f1\": 0.1719498289623717, \"f2\": 0.11487598269242488, \"f0_5\": 0.3417331399564902, \"p4\": 0.26694009246264255, \"phi\": 0.19992396954116004}, {\"truth_threshold\": 31.14, \"match_probability\": 0.9999999995774035, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1125, \"tn\": 8049, \"fp\": 0, \"fn\": 10899, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09356287425149701, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.906437125748503, \"precision\": 1.0, \"recall\": 0.09356287425149701, \"specificity\": 1.0, \"npv\": 0.42479417352754906, \"accuracy\": 0.4570318338066059, \"f1\": 0.17111567419575632, \"f2\": 0.11428049003474126, \"f0_5\": 0.3404139433551198, \"p4\": 0.2659206484063196, \"phi\": 0.19936139004462894}, {\"truth_threshold\": 31.16, \"match_probability\": 0.9999999995832215, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1121, \"tn\": 8049, \"fp\": 0, \"fn\": 10903, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09323020625415834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9067697937458417, \"precision\": 1.0, \"recall\": 0.09323020625415834, \"specificity\": 1.0, \"npv\": 0.42470451667370196, \"accuracy\": 0.45683256115179594, \"f1\": 0.1705591479650057, \"f2\": 0.11388341426742792, \"f0_5\": 0.33953234795250786, \"p4\": 0.2652394030799496, \"phi\": 0.1989856519615469}, {\"truth_threshold\": 31.18, \"match_probability\": 0.9999999995889594, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1117, \"tn\": 8049, \"fp\": 0, \"fn\": 10907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09289753825681969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9071024617431803, \"precision\": 1.0, \"recall\": 0.09289753825681969, \"specificity\": 1.0, \"npv\": 0.4246148976577337, \"accuracy\": 0.456633288496986, \"f1\": 0.17000228293128378, \"f2\": 0.11348627395200456, \"f0_5\": 0.33864904195973805, \"p4\": 0.2645568599113642, \"phi\": 0.1986093620642665}, {\"truth_threshold\": 31.2, \"match_probability\": 0.9999999995946183, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1110, \"tn\": 8049, \"fp\": 0, \"fn\": 10914, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09231536926147704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9076846307385229, \"precision\": 1.0, \"recall\": 0.09231536926147704, \"specificity\": 1.0, \"npv\": 0.42445815535516535, \"accuracy\": 0.4562845613510686, \"f1\": 0.16902695294655093, \"f2\": 0.11279112303377636, \"f0_5\": 0.3370991253644315, \"p4\": 0.26335927326625214, \"phi\": 0.19794951716954876}, {\"truth_threshold\": 31.220000000000002, \"match_probability\": 0.9999999996001994, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1107, \"tn\": 8049, \"fp\": 0, \"fn\": 10917, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09206586826347306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9079341317365269, \"precision\": 1.0, \"recall\": 0.09206586826347306, \"specificity\": 1.0, \"npv\": 0.4243910155014236, \"accuracy\": 0.4561351068599611, \"f1\": 0.16860863605209048, \"f2\": 0.11249314066215475, \"f0_5\": 0.3364332603938731, \"p4\": 0.2628447951778057, \"phi\": 0.19766620177803693}, {\"truth_threshold\": 31.240000000000002, \"match_probability\": 0.9999999996057035, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1106, \"tn\": 8049, \"fp\": 0, \"fn\": 10918, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09198270126413839, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9080172987358616, \"precision\": 1.0, \"recall\": 0.09198270126413839, \"specificity\": 1.0, \"npv\": 0.42436864026994253, \"accuracy\": 0.45608528869625864, \"f1\": 0.16846915460776846, \"f2\": 0.11239380512987276, \"f0_5\": 0.33621108949416345, \"p4\": 0.2626731384195751, \"phi\": 0.19757169297199115}, {\"truth_threshold\": 31.28, \"match_probability\": 0.9999999996164856, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1103, \"tn\": 8049, \"fp\": 0, \"fn\": 10921, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0917332002661344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9082667997338656, \"precision\": 1.0, \"recall\": 0.0917332002661344, \"specificity\": 1.0, \"npv\": 0.424301528729573, \"accuracy\": 0.4559358342051512, \"f1\": 0.16805058276834006, \"f2\": 0.11209577430435579, \"f0_5\": 0.335543927963008, \"p4\": 0.2621576749885096, \"phi\": 0.19728795479749112}, {\"truth_threshold\": 31.32, \"match_probability\": 0.9999999996269727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1102, \"tn\": 8049, \"fp\": 0, \"fn\": 10922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09165003326679973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9083499667332002, \"precision\": 1.0, \"recall\": 0.09165003326679973, \"specificity\": 1.0, \"npv\": 0.4242791629328976, \"accuracy\": 0.45588601604144874, \"f1\": 0.16791101630351973, \"f2\": 0.11199642261880564, \"f0_5\": 0.33532132424537486, \"p4\": 0.2619856892278682, \"phi\": 0.19719330464599963}, {\"truth_threshold\": 31.34, \"match_probability\": 0.9999999996321084, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1100, \"tn\": 8049, \"fp\": 0, \"fn\": 10924, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09148369926813041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9085163007318696, \"precision\": 1.0, \"recall\": 0.09148369926813041, \"specificity\": 1.0, \"npv\": 0.4242344384124809, \"accuracy\": 0.45578637971404373, \"f1\": 0.16763181956720513, \"f2\": 0.11179770713066103, \"f0_5\": 0.3348757915245982, \"p4\": 0.2616414703636565, \"phi\": 0.1970038978876093}, {\"truth_threshold\": 31.36, \"match_probability\": 0.9999999996371732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1094, \"tn\": 8049, \"fp\": 0, \"fn\": 10930, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09098469727212243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9090153027278776, \"precision\": 1.0, \"recall\": 0.09098469727212243, \"specificity\": 1.0, \"npv\": 0.42410032140787185, \"accuracy\": 0.4554874707318288, \"f1\": 0.16679371855465772, \"f2\": 0.11120146371213661, \"f0_5\": 0.3335365853658537, \"p4\": 0.26060683000090545, \"phi\": 0.1964348221581526}, {\"truth_threshold\": 31.38, \"match_probability\": 0.9999999996421683, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1091, \"tn\": 8049, \"fp\": 0, \"fn\": 10933, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09073519627411843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9092648037258816, \"precision\": 1.0, \"recall\": 0.09073519627411843, \"specificity\": 1.0, \"npv\": 0.4240332947002423, \"accuracy\": 0.45533801624072134, \"f1\": 0.16637438048036599, \"f2\": 0.11090328745400208, \"f0_5\": 0.3328655113497681, \"p4\": 0.2600883904814698, \"phi\": 0.19614980046226813}, {\"truth_threshold\": 31.400000000000002, \"match_probability\": 0.9999999996470947, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1086, \"tn\": 8049, \"fp\": 0, \"fn\": 10938, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09031936127744511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9096806387225549, \"precision\": 1.0, \"recall\": 0.09031936127744511, \"specificity\": 1.0, \"npv\": 0.4239216305893506, \"accuracy\": 0.4550889254222089, \"f1\": 0.165675057208238, \"f2\": 0.11040624618762962, \"f0_5\": 0.3317448680351906, \"p4\": 0.2592226597702257, \"phi\": 0.1956740424954807}, {\"truth_threshold\": 31.42, \"match_probability\": 0.9999999996519533, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1084, \"tn\": 8049, \"fp\": 0, \"fn\": 10940, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.09015302727877578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9098469727212242, \"precision\": 1.0, \"recall\": 0.09015302727877578, \"specificity\": 1.0, \"npv\": 0.4238769814102902, \"accuracy\": 0.45498928909480396, \"f1\": 0.16539517851693622, \"f2\": 0.11020740138267589, \"f0_5\": 0.3312958435207824, \"p4\": 0.25887578314075554, \"phi\": 0.19548348540970673}, {\"truth_threshold\": 31.44, \"match_probability\": 0.9999999996567449, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1076, \"tn\": 8049, \"fp\": 0, \"fn\": 10948, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08948769128409848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9105123087159015, \"precision\": 1.0, \"recall\": 0.08948769128409848, \"specificity\": 1.0, \"npv\": 0.4236984787071643, \"accuracy\": 0.4545907437851841, \"f1\": 0.16427480916030535, \"f2\": 0.10941186040836248, \"f0_5\": 0.3294953454189123, \"p4\": 0.25748492330311035, \"phi\": 0.19471979524457417}, {\"truth_threshold\": 31.46, \"match_probability\": 0.9999999996614707, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1072, \"tn\": 8049, \"fp\": 0, \"fn\": 10952, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08915502328675981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9108449767132402, \"precision\": 1.0, \"recall\": 0.08915502328675981, \"specificity\": 1.0, \"npv\": 0.42360928372190937, \"accuracy\": 0.45439147113037415, \"f1\": 0.16371411117898596, \"f2\": 0.10901399284087211, \"f0_5\": 0.3285924472780775, \"p4\": 0.25678747339504704, \"phi\": 0.1943370668573406}, {\"truth_threshold\": 31.5, \"match_probability\": 0.9999999996707277, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1068, \"tn\": 8049, \"fp\": 0, \"fn\": 10956, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08882235528942116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9111776447105788, \"precision\": 1.0, \"recall\": 0.08882235528942116, \"specificity\": 1.0, \"npv\": 0.4235201262825572, \"accuracy\": 0.4541921984755642, \"f1\": 0.16315307057745188, \"f2\": 0.10861606053209666, \"f0_5\": 0.3276877761413844, \"p4\": 0.25608867070357166, \"phi\": 0.19395374481790706}, {\"truth_threshold\": 31.52, \"match_probability\": 0.999999999675261, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1066, \"tn\": 8049, \"fp\": 0, \"fn\": 10958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08865602129075183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9113439787092482, \"precision\": 1.0, \"recall\": 0.08865602129075183, \"specificity\": 1.0, \"npv\": 0.423475561635187, \"accuracy\": 0.45409256214815924, \"f1\": 0.16287242169595112, \"f2\": 0.10841707009478865, \"f0_5\": 0.32723477406679763, \"p4\": 0.2557387606215314, \"phi\": 0.19376186004588786}, {\"truth_threshold\": 31.54, \"match_probability\": 0.9999999996797317, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1063, \"tn\": 8049, \"fp\": 0, \"fn\": 10961, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08840652029274784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9115934797072521, \"precision\": 1.0, \"recall\": 0.08840652029274784, \"specificity\": 1.0, \"npv\": 0.4234087322461862, \"accuracy\": 0.45394310765705176, \"f1\": 0.16245128753725072, \"f2\": 0.10811855407961919, \"f0_5\": 0.32655443597935613, \"p4\": 0.25521325794934535, \"phi\": 0.19347375191340324}, {\"truth_threshold\": 31.560000000000002, \"match_probability\": 0.999999999684141, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1062, \"tn\": 8049, \"fp\": 0, \"fn\": 10962, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08832335329341318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9116766467065869, \"precision\": 1.0, \"recall\": 0.08832335329341318, \"specificity\": 1.0, \"npv\": 0.4233864604702541, \"accuracy\": 0.4538932894933493, \"f1\": 0.1623108665749656, \"f2\": 0.10801904064445259, \"f0_5\": 0.32632743362831856, \"p4\": 0.2550379200884836, \"phi\": 0.19337764071309269}, {\"truth_threshold\": 31.580000000000002, \"match_probability\": 0.9999999996884895, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1060, \"tn\": 8049, \"fp\": 0, \"fn\": 10964, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08815701929474384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9118429807052562, \"precision\": 1.0, \"recall\": 0.08815701929474384, \"specificity\": 1.0, \"npv\": 0.4233419239467733, \"accuracy\": 0.4537936531659443, \"f1\": 0.1620299602568022, \"f2\": 0.10782000162747173, \"f0_5\": 0.32587309394982783, \"p4\": 0.25468698847503424, \"phi\": 0.1931853052321777}, {\"truth_threshold\": 31.6, \"match_probability\": 0.9999999996927781, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1056, \"tn\": 8049, \"fp\": 0, \"fn\": 10968, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08782435129740519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9121756487025948, \"precision\": 1.0, \"recall\": 0.08782435129740519, \"specificity\": 1.0, \"npv\": 0.4232528790029973, \"accuracy\": 0.4535943805111344, \"f1\": 0.1614678899082569, \"f2\": 0.107421875, \"f0_5\": 0.3249630723781389, \"p4\": 0.25398409963839347, \"phi\": 0.19280018032459764}, {\"truth_threshold\": 31.62, \"match_probability\": 0.9999999996970077, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1052, \"tn\": 8049, \"fp\": 0, \"fn\": 10972, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08749168330006653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9125083166999335, \"precision\": 1.0, \"recall\": 0.08749168330006653, \"specificity\": 1.0, \"npv\": 0.42316387151043583, \"accuracy\": 0.4533951078563244, \"f1\": 0.1609054756806363, \"f2\": 0.1070236835679987, \"f0_5\": 0.3240512567767373, \"p4\": 0.2532798394189496, \"phi\": 0.19241444704133082}, {\"truth_threshold\": 31.64, \"match_probability\": 0.9999999997011791, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1047, \"tn\": 8049, \"fp\": 0, \"fn\": 10977, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08707584830339321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9129241516966068, \"precision\": 1.0, \"recall\": 0.08707584830339321, \"specificity\": 1.0, \"npv\": 0.4230526647745191, \"accuracy\": 0.453146017037812, \"f1\": 0.1602019738352077, \"f2\": 0.10652585312252, \"f0_5\": 0.32290895632864547, \"p4\": 0.2523975784720244, \"phi\": 0.19193141916385728}, {\"truth_threshold\": 31.66, \"match_probability\": 0.9999999997052931, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1046, \"tn\": 8049, \"fp\": 0, \"fn\": 10978, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08699268130405854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9130073186959414, \"precision\": 1.0, \"recall\": 0.08699268130405854, \"specificity\": 1.0, \"npv\": 0.42303043044095234, \"accuracy\": 0.4530961988741095, \"f1\": 0.1600612088752869, \"f2\": 0.10642627487688738, \"f0_5\": 0.32268015794669297, \"p4\": 0.25222086745513245, \"phi\": 0.19183469815773285}, {\"truth_threshold\": 31.68, \"match_probability\": 0.9999999997093504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1043, \"tn\": 8049, \"fp\": 0, \"fn\": 10981, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08674318030605456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9132568196939455, \"precision\": 1.0, \"recall\": 0.08674318030605456, \"specificity\": 1.0, \"npv\": 0.4229637414608513, \"accuracy\": 0.45294674438300203, \"f1\": 0.15963878472487947, \"f2\": 0.10612751582246281, \"f0_5\": 0.3219930847122746, \"p4\": 0.2516902154164963, \"phi\": 0.1915443032002311}, {\"truth_threshold\": 31.720000000000002, \"match_probability\": 0.9999999997172982, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1036, \"tn\": 8049, \"fp\": 0, \"fn\": 10988, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08616101131071191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9138389886892881, \"precision\": 1.0, \"recall\": 0.08616101131071191, \"specificity\": 1.0, \"npv\": 0.42280821558018594, \"accuracy\": 0.45259801723708465, \"f1\": 0.15865237366003063, \"f2\": 0.10543026947814052, \"f0_5\": 0.3203859475507175, \"p4\": 0.25044899035024776, \"phi\": 0.19086535422875028}, {\"truth_threshold\": 31.740000000000002, \"match_probability\": 0.9999999997211902, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1031, \"tn\": 8049, \"fp\": 0, \"fn\": 10993, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0857451763140386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9142548236859614, \"precision\": 1.0, \"recall\": 0.0857451763140386, \"specificity\": 1.0, \"npv\": 0.42269719567272346, \"accuracy\": 0.4523489264185722, \"f1\": 0.15794714668709306, \"f2\": 0.10493211472306471, \"f0_5\": 0.3192345801337627, \"p4\": 0.2495597866863399, \"phi\": 0.19037921517436546}, {\"truth_threshold\": 31.76, \"match_probability\": 0.9999999997250287, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1029, \"tn\": 8049, \"fp\": 0, \"fn\": 10995, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08557884231536926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9144211576846307, \"precision\": 1.0, \"recall\": 0.08557884231536926, \"specificity\": 1.0, \"npv\": 0.4226528040327662, \"accuracy\": 0.45224929009116727, \"f1\": 0.15766490461962768, \"f2\": 0.10473282442748091, \"f0_5\": 0.3187732342007435, \"p4\": 0.24920349275754186, \"phi\": 0.19018448325367862}, {\"truth_threshold\": 31.78, \"match_probability\": 0.9999999997288144, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1027, \"tn\": 8049, \"fp\": 0, \"fn\": 10997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08541250831669993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9145874916833001, \"precision\": 1.0, \"recall\": 0.08541250831669993, \"specificity\": 1.0, \"npv\": 0.42260842171584584, \"accuracy\": 0.45214965376376226, \"f1\": 0.15738257604781242, \"f2\": 0.10453351790403681, \"f0_5\": 0.3183114306967518, \"p4\": 0.24884684794468243, \"phi\": 0.18998959270052693}, {\"truth_threshold\": 31.82, \"match_probability\": 0.9999999997362299, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1025, \"tn\": 8049, \"fp\": 0, \"fn\": 10999, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08524617431803061, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9147538256819694, \"precision\": 1.0, \"recall\": 0.08524617431803061, \"specificity\": 1.0, \"npv\": 0.42256404871902564, \"accuracy\": 0.4520500174363573, \"f1\": 0.15710016093187218, \"f2\": 0.1043341951507502, \"f0_5\": 0.3178491689407095, \"p4\": 0.24848985164250248, \"phi\": 0.1897945430133196}, {\"truth_threshold\": 31.84, \"match_probability\": 0.9999999997398613, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1023, \"tn\": 8049, \"fp\": 0, \"fn\": 11001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08507984031936128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9149201596806387, \"precision\": 1.0, \"recall\": 0.08507984031936128, \"specificity\": 1.0, \"npv\": 0.4225196850393701, \"accuracy\": 0.4519503811089523, \"f1\": 0.15681765923200736, \"f2\": 0.10413485616563856, \"f0_5\": 0.31738644825018614, \"p4\": 0.24813250324437133, \"phi\": 0.18959933368800752}, {\"truth_threshold\": 31.86, \"match_probability\": 0.9999999997434427, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1020, \"tn\": 8049, \"fp\": 0, \"fn\": 11004, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08483033932135728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9151696606786427, \"precision\": 1.0, \"recall\": 0.08483033932135728, \"specificity\": 1.0, \"npv\": 0.4224531569831523, \"accuracy\": 0.4518009266178449, \"f1\": 0.15639374425023, \"f2\": 0.10383581724896164, \"f0_5\": 0.3166915052160954, \"p4\": 0.24759581913687526, \"phi\": 0.18930621926988933}, {\"truth_threshold\": 31.88, \"match_probability\": 0.9999999997469748, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1017, \"tn\": 8049, \"fp\": 0, \"fn\": 11007, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0845808383233533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9154191616766467, \"precision\": 1.0, \"recall\": 0.0845808383233533, \"specificity\": 1.0, \"npv\": 0.42238664987405544, \"accuracy\": 0.4516514721267374, \"f1\": 0.1559696342305038, \"f2\": 0.10353674179952355, \"f0_5\": 0.31599552572706935, \"p4\": 0.24705833938730667, \"phi\": 0.1890127428057175}, {\"truth_threshold\": 31.900000000000002, \"match_probability\": 0.9999999997504583, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1014, \"tn\": 8049, \"fp\": 0, \"fn\": 11010, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0843313373253493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9156686626746507, \"precision\": 1.0, \"recall\": 0.0843313373253493, \"specificity\": 1.0, \"npv\": 0.42232016370218795, \"accuracy\": 0.45150201763562997, \"f1\": 0.15554532903819604, \"f2\": 0.1032376298106292, \"f0_5\": 0.31529850746268656, \"p4\": 0.2465200619308075, \"phi\": 0.18871890256268964}, {\"truth_threshold\": 31.92, \"match_probability\": 0.9999999997538939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1010, \"tn\": 8049, \"fp\": 0, \"fn\": 11014, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08399866932801064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9160013306719893, \"precision\": 1.0, \"recall\": 0.08399866932801064, \"specificity\": 1.0, \"npv\": 0.4222315480249698, \"accuracy\": 0.45130274498082, \"f1\": 0.15497928494706154, \"f2\": 0.10283875697470778, \"f0_5\": 0.3143675298804781, \"p4\": 0.2458011141959457, \"phi\": 0.1883265466746616}, {\"truth_threshold\": 31.94, \"match_probability\": 0.999999999757282, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1006, \"tn\": 8049, \"fp\": 0, \"fn\": 11018, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.083666001330672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.916333998669328, \"precision\": 1.0, \"recall\": 0.083666001330672, \"specificity\": 1.0, \"npv\": 0.4221429695285047, \"accuracy\": 0.45110347232601006, \"f1\": 0.15441289332310054, \"f2\": 0.10243981915196937, \"f0_5\": 0.3134346959122632, \"p4\": 0.2450807397004866, \"phi\": 0.1879335367897537}, {\"truth_threshold\": 31.96, \"match_probability\": 0.9999999997606236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 999, \"tn\": 8049, \"fp\": 0, \"fn\": 11025, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08308383233532934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9169161676646707, \"precision\": 1.0, \"recall\": 0.08308383233532934, \"specificity\": 1.0, \"npv\": 0.4219880465555206, \"accuracy\": 0.4507547451800927, \"f1\": 0.15342087076710437, \"f2\": 0.10174152153987168, \"f0_5\": 0.31179775280898875, \"p4\": 0.24381663627960895, \"phi\": 0.18724418310733187}, {\"truth_threshold\": 31.98, \"match_probability\": 0.9999999997639192, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 995, \"tn\": 8049, \"fp\": 0, \"fn\": 11029, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08275116433799068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9172488356620093, \"precision\": 1.0, \"recall\": 0.08275116433799068, \"specificity\": 1.0, \"npv\": 0.421899570185554, \"accuracy\": 0.4505554725252827, \"f1\": 0.15285352177586603, \"f2\": 0.10134240492147237, \"f0_5\": 0.31085978505373657, \"p4\": 0.24309231258432912, \"phi\": 0.18684935286629287}, {\"truth_threshold\": 32.0, \"match_probability\": 0.9999999997671694, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 991, \"tn\": 8049, \"fp\": 0, \"fn\": 11033, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08241849634065203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917581503659348, \"precision\": 1.0, \"recall\": 0.08241849634065203, \"specificity\": 1.0, \"npv\": 0.42181113090870975, \"accuracy\": 0.45035619987047276, \"f1\": 0.15228582404917404, \"f2\": 0.10094322325666673, \"f0_5\": 0.30991993995496625, \"p4\": 0.24236654343685887, \"phi\": 0.18645385259963335}, {\"truth_threshold\": 32.02, \"match_probability\": 0.9999999997703748, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 990, \"tn\": 8049, \"fp\": 0, \"fn\": 11034, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08233532934131736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9176646706586826, \"precision\": 1.0, \"recall\": 0.08233532934131736, \"specificity\": 1.0, \"npv\": 0.42178902688256564, \"accuracy\": 0.4503063817067703, \"f1\": 0.15214384508990317, \"f2\": 0.10084341767510084, \"f0_5\": 0.3096846846846847, \"p4\": 0.2421848747081214, \"phi\": 0.18635487232946127}, {\"truth_threshold\": 32.04, \"match_probability\": 0.9999999997735362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 989, \"tn\": 8049, \"fp\": 0, \"fn\": 11035, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0822521623419827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9177478376580173, \"precision\": 1.0, \"recall\": 0.0822521623419827, \"specificity\": 1.0, \"npv\": 0.42176692517291975, \"accuracy\": 0.4502565635430678, \"f1\": 0.15200184430953662, \"f2\": 0.10074360802689213, \"f0_5\": 0.3094493116395494, \"p4\": 0.24200311524486187, \"phi\": 0.18625584984048651}, {\"truth_threshold\": 32.06, \"match_probability\": 0.9999999997766539, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 988, \"tn\": 8049, \"fp\": 0, \"fn\": 11036, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08216899534264804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917831004657352, \"precision\": 1.0, \"recall\": 0.08216899534264804, \"specificity\": 1.0, \"npv\": 0.4217448257794079, \"accuracy\": 0.45020674537936534, \"f1\": 0.15185982170304335, \"f2\": 0.10064379431179203, \"f0_5\": 0.30921382073109666, \"p4\": 0.2418212649680353, \"phi\": 0.18615678506370398}, {\"truth_threshold\": 32.1, \"match_probability\": 0.9999999997827613, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 987, \"tn\": 8049, \"fp\": 0, \"fn\": 11037, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08208582834331338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9179141716566867, \"precision\": 1.0, \"recall\": 0.08208582834331338, \"specificity\": 1.0, \"npv\": 0.42172272870166616, \"accuracy\": 0.4501569272156628, \"f1\": 0.15171777726539082, \"f2\": 0.10054397652955198, \"f0_5\": 0.30897821187077384, \"p4\": 0.2416393237985061, \"phi\": 0.18605767792993302}, {\"truth_threshold\": 32.12, \"match_probability\": 0.9999999997857522, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 984, \"tn\": 8049, \"fp\": 0, \"fn\": 11040, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08183632734530938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9181636726546906, \"precision\": 1.0, \"recall\": 0.08183632734530938, \"specificity\": 1.0, \"npv\": 0.42165645135942165, \"accuracy\": 0.4500074727245554, \"f1\": 0.15129151291512916, \"f2\": 0.10024449877750612, \"f0_5\": 0.3082706766917293, \"p4\": 0.2410929541409873, \"phi\": 0.18576010169223947}, {\"truth_threshold\": 32.14, \"match_probability\": 0.9999999997887017, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 982, \"tn\": 8049, \"fp\": 0, \"fn\": 11042, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08166999334664006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91833000665336, \"precision\": 1.0, \"recall\": 0.08166999334664006, \"specificity\": 1.0, \"npv\": 0.42161227803677126, \"accuracy\": 0.4499078363971504, \"f1\": 0.15100722743349224, \"f2\": 0.10004482660255104, \"f0_5\": 0.3077983951855567, \"p4\": 0.2407282517842261, \"phi\": 0.18556150447257336}, {\"truth_threshold\": 32.160000000000004, \"match_probability\": 0.9999999997916107, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 980, \"tn\": 8049, \"fp\": 0, \"fn\": 11044, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08150365934797073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9184963406520292, \"precision\": 1.0, \"recall\": 0.08150365934797073, \"specificity\": 1.0, \"npv\": 0.4215681139684701, \"accuracy\": 0.4498082000697454, \"f1\": 0.15072285450630576, \"f2\": 0.09984513815306871, \"f0_5\": 0.30732563973908683, \"p4\": 0.2403631839496794, \"phi\": 0.18536273614956347}, {\"truth_threshold\": 32.2, \"match_probability\": 0.9999999997973091, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 978, \"tn\": 8049, \"fp\": 0, \"fn\": 11046, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0813373253493014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9186626746506986, \"precision\": 1.0, \"recall\": 0.0813373253493014, \"specificity\": 1.0, \"npv\": 0.4215239591516104, \"accuracy\": 0.4497085637423405, \"f1\": 0.15043839409321644, \"f2\": 0.09964543342706933, \"f0_5\": 0.3068524096385542, \"p4\": 0.23999774999879955, \"phi\": 0.18516379615907685}, {\"truth_threshold\": 32.22, \"match_probability\": 0.9999999998000997, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 974, \"tn\": 8049, \"fp\": 0, \"fn\": 11050, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08100465735196274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9189953426480373, \"precision\": 1.0, \"recall\": 0.08100465735196274, \"specificity\": 1.0, \"npv\": 0.42143567726058956, \"accuracy\": 0.4495092910875305, \"f1\": 0.14986921064779196, \"f2\": 0.09924597513755859, \"f0_5\": 0.30590452261306533, \"p4\": 0.23926578118651196, \"phi\": 0.1847653989046283}, {\"truth_threshold\": 32.24, \"match_probability\": 0.9999999998028517, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 973, \"tn\": 8049, \"fp\": 0, \"fn\": 11051, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08092149035262808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9190785096473719, \"precision\": 1.0, \"recall\": 0.08092149035262808, \"specificity\": 1.0, \"npv\": 0.421413612565445, \"accuracy\": 0.44945947292382804, \"f1\": 0.14972686004462568, \"f2\": 0.09914610038924779, \"f0_5\": 0.305667253078663, \"p4\": 0.2390825591589271, \"phi\": 0.1846656914093162}, {\"truth_threshold\": 32.26, \"match_probability\": 0.999999999805566, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 971, \"tn\": 8049, \"fp\": 0, \"fn\": 11053, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08075515635395875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9192448436460412, \"precision\": 1.0, \"recall\": 0.08075515635395875, \"specificity\": 1.0, \"npv\": 0.4213694901057481, \"accuracy\": 0.44935983659642303, \"f1\": 0.14944209311273568, \"f2\": 0.0989463386797644, \"f0_5\": 0.3051923560472718, \"p4\": 0.2387158387511044, \"phi\": 0.18446614609807827}, {\"truth_threshold\": 32.28, \"match_probability\": 0.9999999998082427, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 970, \"tn\": 8049, \"fp\": 0, \"fn\": 11054, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08067198935462408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.919328010645376, \"precision\": 1.0, \"recall\": 0.08067198935462408, \"specificity\": 1.0, \"npv\": 0.42134743234047006, \"accuracy\": 0.44931001843272056, \"f1\": 0.14929967677389563, \"f2\": 0.098846451718094, \"f0_5\": 0.3049547283702213, \"p4\": 0.2385323402095713, \"phi\": 0.1843663081378173}, {\"truth_threshold\": 32.3, \"match_probability\": 0.9999999998108827, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 969, \"tn\": 8049, \"fp\": 0, \"fn\": 11055, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08058882235528943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9194111776447106, \"precision\": 1.0, \"recall\": 0.08058882235528943, \"specificity\": 1.0, \"npv\": 0.4213253768844221, \"accuracy\": 0.4492602002690181, \"f1\": 0.1491572385130455, \"f2\": 0.09874656068480588, \"f0_5\": 0.30471698113207546, \"p4\": 0.23834874933527214, \"phi\": 0.18426642654459344}, {\"truth_threshold\": 32.34, \"match_probability\": 0.9999999998160541, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 968, \"tn\": 8049, \"fp\": 0, \"fn\": 11056, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08050565535595476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9194943446440452, \"precision\": 1.0, \"recall\": 0.08050565535595476, \"specificity\": 1.0, \"npv\": 0.42130332373724155, \"accuracy\": 0.4492103821053156, \"f1\": 0.14901477832512317, \"f2\": 0.09864666557965107, \"f0_5\": 0.30447911424257673, \"p4\": 0.23816506604732715, \"phi\": 0.18416650124577108}, {\"truth_threshold\": 32.36, \"match_probability\": 0.9999999998185866, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 967, \"tn\": 8049, \"fp\": 0, \"fn\": 11057, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0804224883566201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9195775116433799, \"precision\": 1.0, \"recall\": 0.0804224883566201, \"specificity\": 1.0, \"npv\": 0.4212812728985659, \"accuracy\": 0.44916056394161313, \"f1\": 0.14887229620506504, \"f2\": 0.09854676640238061, \"f0_5\": 0.3042411276113768, \"p4\": 0.23798129026476325, \"phi\": 0.18406653216852598}, {\"truth_threshold\": 32.38, \"match_probability\": 0.9999999998210842, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 963, \"tn\": 8049, \"fp\": 0, \"fn\": 11061, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08008982035928144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9199101796407185, \"precision\": 1.0, \"recall\": 0.08008982035928144, \"specificity\": 1.0, \"npv\": 0.42119309262166404, \"accuracy\": 0.4489612912868032, \"f1\": 0.1483021483021483, \"f2\": 0.09814712896716199, \"f0_5\": 0.3032879818594104, \"p4\": 0.23724526056559178, \"phi\": 0.18366621661219915}, {\"truth_threshold\": 32.4, \"match_probability\": 0.9999999998235474, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 962, \"tn\": 8049, \"fp\": 0, \"fn\": 11062, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.08000665335994678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9199933466400533, \"precision\": 1.0, \"recall\": 0.08000665335994678, \"specificity\": 1.0, \"npv\": 0.4211710533200774, \"accuracy\": 0.4489114731231007, \"f1\": 0.14815955644540274, \"f2\": 0.09804720942557789, \"f0_5\": 0.3030493951612903, \"p4\": 0.2370610210920695, \"phi\": 0.18356602754383258}, {\"truth_threshold\": 32.42, \"match_probability\": 0.9999999998259766, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 959, \"tn\": 8049, \"fp\": 0, \"fn\": 11065, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07975715236194278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9202428476380572, \"precision\": 1.0, \"recall\": 0.07975715236194278, \"specificity\": 1.0, \"npv\": 0.42110494925185726, \"accuracy\": 0.4487620186319932, \"f1\": 0.1477316490795656, \"f2\": 0.0977474263581694, \"f0_5\": 0.30233291298865067, \"p4\": 0.23650774445037254, \"phi\": 0.1832651947256995}, {\"truth_threshold\": 32.44, \"match_probability\": 0.9999999998283725, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 957, \"tn\": 8049, \"fp\": 0, \"fn\": 11067, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07959081836327345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9204091816367266, \"precision\": 1.0, \"recall\": 0.07959081836327345, \"specificity\": 1.0, \"npv\": 0.42106089139987446, \"accuracy\": 0.44866238230458827, \"f1\": 0.14744626762190893, \"f2\": 0.09754755060852548, \"f0_5\": 0.3018546555639667, \"p4\": 0.23613842735416735, \"phi\": 0.18306441742535717}, {\"truth_threshold\": 32.46, \"match_probability\": 0.9999999998307353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 951, \"tn\": 8049, \"fp\": 0, \"fn\": 11073, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07909181636726546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9209081836327345, \"precision\": 1.0, \"recall\": 0.07909181636726546, \"specificity\": 1.0, \"npv\": 0.42092877314088484, \"accuracy\": 0.44836347332237336, \"f1\": 0.14658959537572255, \"f2\": 0.09694782555507982, \"f0_5\": 0.3004169825625474, \"p4\": 0.23502823203853473, \"phi\": 0.18246101290126943}, {\"truth_threshold\": 32.480000000000004, \"match_probability\": 0.9999999998330656, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 949, \"tn\": 8049, \"fp\": 0, \"fn\": 11075, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07892548236859614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9210745176314039, \"precision\": 1.0, \"recall\": 0.07892548236859614, \"specificity\": 1.0, \"npv\": 0.420884752143903, \"accuracy\": 0.44826383699496836, \"f1\": 0.14630386186695443, \"f2\": 0.09674788459577939, \"f0_5\": 0.299936788874842, \"p4\": 0.23465741672861554, \"phi\": 0.1822595185019004}, {\"truth_threshold\": 32.5, \"match_probability\": 0.9999999998353639, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 946, \"tn\": 8049, \"fp\": 0, \"fn\": 11078, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07867598137059215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9213240186294078, \"precision\": 1.0, \"recall\": 0.07867598137059215, \"specificity\": 1.0, \"npv\": 0.4208187379097611, \"accuracy\": 0.44811438250386093, \"f1\": 0.1458750963762529, \"f2\": 0.09644794257982954, \"f0_5\": 0.29921558704453444, \"p4\": 0.23410048817397858, \"phi\": 0.1819569377192979}, {\"truth_threshold\": 32.52, \"match_probability\": 0.9999999998376304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 943, \"tn\": 8049, \"fp\": 0, \"fn\": 11081, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07842648037258816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9215735196274119, \"precision\": 1.0, \"recall\": 0.07842648037258816, \"specificity\": 1.0, \"npv\": 0.4207527443805541, \"accuracy\": 0.44796492801275345, \"f1\": 0.14544613249016736, \"f2\": 0.0961479638654948, \"f0_5\": 0.29849328944036463, \"p4\": 0.23354271092000858, \"phi\": 0.1816539480685023}, {\"truth_threshold\": 32.54, \"match_probability\": 0.9999999998398659, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 940, \"tn\": 8049, \"fp\": 0, \"fn\": 11084, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07817697937458416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9218230206254159, \"precision\": 1.0, \"recall\": 0.07817697937458416, \"specificity\": 1.0, \"npv\": 0.4206867715465426, \"accuracy\": 0.44781547352164597, \"f1\": 0.14501697007096576, \"f2\": 0.09584794844603964, \"f0_5\": 0.29776989356310185, \"p4\": 0.23298408271897844, \"phi\": 0.1813505474553481}, {\"truth_threshold\": 32.56, \"match_probability\": 0.9999999998420704, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 939, \"tn\": 8049, \"fp\": 0, \"fn\": 11085, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0780938123752495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9219061876247505, \"precision\": 1.0, \"recall\": 0.0780938123752495, \"specificity\": 1.0, \"npv\": 0.420664785199122, \"accuracy\": 0.4477656553579435, \"f1\": 0.14487387178893774, \"f2\": 0.09574793514836341, \"f0_5\": 0.2975285171102662, \"p4\": 0.2327976838296648, \"phi\": 0.18124932222829102}, {\"truth_threshold\": 32.58, \"match_probability\": 0.9999999998442447, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 938, \"tn\": 8049, \"fp\": 0, \"fn\": 11086, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07801064537591483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9219893546240852, \"precision\": 1.0, \"recall\": 0.07801064537591483, \"specificity\": 1.0, \"npv\": 0.42064280114972563, \"accuracy\": 0.447715837194241, \"f1\": 0.1447307514272489, \"f2\": 0.09564791777134234, \"f0_5\": 0.2972870182555781, \"p4\": 0.23261119005639155, \"phi\": 0.18114805102573614}, {\"truth_threshold\": 32.6, \"match_probability\": 0.9999999998463891, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 935, \"tn\": 8049, \"fp\": 0, \"fn\": 11089, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07776114437791085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9222388556220892, \"precision\": 1.0, \"recall\": 0.07776114437791085, \"specificity\": 1.0, \"npv\": 0.42057686278608003, \"accuracy\": 0.44756638270313354, \"f1\": 0.14430125781310285, \"f2\": 0.09534784116171402, \"f0_5\": 0.2965617863486425, \"p4\": 0.2320511385940223, \"phi\": 0.18084396077590528}, {\"truth_threshold\": 32.62, \"match_probability\": 0.9999999998485039, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 929, \"tn\": 8049, \"fp\": 0, \"fn\": 11095, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07726214238190286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9227378576180971, \"precision\": 1.0, \"recall\": 0.07726214238190286, \"specificity\": 1.0, \"npv\": 0.4204450480568324, \"accuracy\": 0.44726747372091863, \"f1\": 0.1434416737435343, \"f2\": 0.09474757776644568, \"f0_5\": 0.2951080050825921, \"p4\": 0.23092846245451143, \"phi\": 0.18023452823122704}, {\"truth_threshold\": 32.64, \"match_probability\": 0.9999999998505895, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 925, \"tn\": 8049, \"fp\": 0, \"fn\": 11099, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07692947438456421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9230705256154358, \"precision\": 1.0, \"recall\": 0.07692947438456421, \"specificity\": 1.0, \"npv\": 0.4203572174639649, \"accuracy\": 0.44706820106610873, \"f1\": 0.14286817514866013, \"f2\": 0.09434732053609678, \"f0_5\": 0.2941363520732638, \"p4\": 0.23017809828726063, \"phi\": 0.1798273054718353}, {\"truth_threshold\": 32.660000000000004, \"match_probability\": 0.9999999998526465, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 923, \"tn\": 8049, \"fp\": 0, \"fn\": 11101, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07676314038589488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9232368596141052, \"precision\": 1.0, \"recall\": 0.07676314038589488, \"specificity\": 1.0, \"npv\": 0.42031331592689297, \"accuracy\": 0.4469685647387037, \"f1\": 0.1425812929636209, \"f2\": 0.09414716742487607, \"f0_5\": 0.29364978365996436, \"p4\": 0.22980234014470702, \"phi\": 0.17962341182751504}, {\"truth_threshold\": 32.68, \"match_probability\": 0.9999999998546752, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 922, \"tn\": 8049, \"fp\": 0, \"fn\": 11102, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07667997338656021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9233200266134398, \"precision\": 1.0, \"recall\": 0.07667997338656021, \"specificity\": 1.0, \"npv\": 0.4202913685969401, \"accuracy\": 0.44691874657500125, \"f1\": 0.14243781863123745, \"f2\": 0.09404708474437962, \"f0_5\": 0.2934063136456212, \"p4\": 0.22961431676055974, \"phi\": 0.17952139415293747}, {\"truth_threshold\": 32.7, \"match_probability\": 0.999999999856676, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 920, \"tn\": 8049, \"fp\": 0, \"fn\": 11104, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07651363938789088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9234863606121091, \"precision\": 1.0, \"recall\": 0.07651363938789088, \"specificity\": 1.0, \"npv\": 0.42024748081240537, \"accuracy\": 0.4468191102475963, \"f1\": 0.14215080346106304, \"f2\": 0.09384690713236495, \"f0_5\": 0.29291900152827305, \"p4\": 0.22923798093949346, \"phi\": 0.17931721668749484}, {\"truth_threshold\": 32.72, \"match_probability\": 0.9999999998586491, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 918, \"tn\": 8049, \"fp\": 0, \"fn\": 11106, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07634730538922156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9236526946107785, \"precision\": 1.0, \"recall\": 0.07634730538922156, \"specificity\": 1.0, \"npv\": 0.420203602192639, \"accuracy\": 0.4467194739201913, \"f1\": 0.14186369958275383, \"f2\": 0.09364671318398825, \"f0_5\": 0.29243119266055045, \"p4\": 0.2288612591441934, \"phi\": 0.17911284918244244}, {\"truth_threshold\": 32.74, \"match_probability\": 0.9999999998605952, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 917, \"tn\": 8049, \"fp\": 0, \"fn\": 11107, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0762641383898869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9237358616101131, \"precision\": 1.0, \"recall\": 0.0762641383898869, \"specificity\": 1.0, \"npv\": 0.4201816663186469, \"accuracy\": 0.4466696557564888, \"f1\": 0.14172011436519588, \"f2\": 0.09354661008303919, \"f0_5\": 0.29218710170787665, \"p4\": 0.2286727532918789, \"phi\": 0.17901059395750454}, {\"truth_threshold\": 32.76, \"match_probability\": 0.9999999998625143, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 914, \"tn\": 8049, \"fp\": 0, \"fn\": 11110, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0760146373918829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9239853626081171, \"precision\": 1.0, \"recall\": 0.0760146373918829, \"specificity\": 1.0, \"npv\": 0.4201158724359309, \"accuracy\": 0.44652020126538133, \"f1\": 0.14128922553717732, \"f2\": 0.09324627627014895, \"f0_5\": 0.2914540816326531, \"p4\": 0.22810665488510254, \"phi\": 0.1787035413912993}, {\"truth_threshold\": 32.78, \"match_probability\": 0.9999999998644071, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 910, \"tn\": 8049, \"fp\": 0, \"fn\": 11114, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07568196939454425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9243180306054558, \"precision\": 1.0, \"recall\": 0.07568196939454425, \"specificity\": 1.0, \"npv\": 0.4200281793038668, \"accuracy\": 0.44632092861057143, \"f1\": 0.14071439616514614, \"f2\": 0.09284577398685875, \"f0_5\": 0.2904749744637385, \"p4\": 0.22735049847563435, \"phi\": 0.17829346541845384}, {\"truth_threshold\": 32.8, \"match_probability\": 0.9999999998662739, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 907, \"tn\": 8049, \"fp\": 0, \"fn\": 11117, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07543246839654025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9245675316034597, \"precision\": 1.0, \"recall\": 0.07543246839654025, \"specificity\": 1.0, \"npv\": 0.419962433475947, \"accuracy\": 0.44617147411946395, \"f1\": 0.14028304075477535, \"f2\": 0.09254535436605922, \"f0_5\": 0.28973933043700484, \"p4\": 0.2267823592420909, \"phi\": 0.17798540106117836}, {\"truth_threshold\": 32.82, \"match_probability\": 0.9999999998681149, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 905, \"tn\": 8049, \"fp\": 0, \"fn\": 11119, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07526613439787093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9247338656021291, \"precision\": 1.0, \"recall\": 0.07526613439787093, \"specificity\": 1.0, \"npv\": 0.4199186143572621, \"accuracy\": 0.446071837792059, \"f1\": 0.13999535926985845, \"f2\": 0.0923450541825677, \"f0_5\": 0.28924827409869597, \"p4\": 0.22640311181995315, \"phi\": 0.17777978193366484}, {\"truth_threshold\": 32.84, \"match_probability\": 0.9999999998699307, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 902, \"tn\": 8049, \"fp\": 0, \"fn\": 11122, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07501663339986693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.924983366600133, \"precision\": 1.0, \"recall\": 0.07501663339986693, \"specificity\": 1.0, \"npv\": 0.4198529028219707, \"accuracy\": 0.4459223833009515, \"f1\": 0.13956367012223425, \"f2\": 0.09204457324788767, \"f0_5\": 0.288510747185261, \"p4\": 0.22583350704568106, \"phi\": 0.17747098718626017}, {\"truth_threshold\": 32.9, \"match_probability\": 0.9999999998752291, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 899, \"tn\": 8049, \"fp\": 0, \"fn\": 11125, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07476713240186295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.925232867598137, \"precision\": 1.0, \"recall\": 0.07476713240186295, \"specificity\": 1.0, \"npv\": 0.4197872118493794, \"accuracy\": 0.4457729288098441, \"f1\": 0.13913178054631278, \"f2\": 0.09174405551586896, \"f0_5\": 0.2877720870678617, \"p4\": 0.22526301980569738, \"phi\": 0.17716175108908647}, {\"truth_threshold\": 32.92, \"match_probability\": 0.9999999998769469, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 897, \"tn\": 8049, \"fp\": 0, \"fn\": 11127, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07460079840319361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9253992015968064, \"precision\": 1.0, \"recall\": 0.07460079840319361, \"specificity\": 1.0, \"npv\": 0.41974342928660824, \"accuracy\": 0.4456732924824391, \"f1\": 0.13884374274436964, \"f2\": 0.0915436899148858, \"f0_5\": 0.28727901614142964, \"p4\": 0.22488220355220573, \"phi\": 0.17695534733167975}, {\"truth_threshold\": 32.94, \"match_probability\": 0.999999999878641, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 894, \"tn\": 8049, \"fp\": 0, \"fn\": 11130, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07435129740518961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9256487025948104, \"precision\": 1.0, \"recall\": 0.07435129740518961, \"specificity\": 1.0, \"npv\": 0.4196777725637416, \"accuracy\": 0.44552383799133166, \"f1\": 0.13841151881096145, \"f2\": 0.09124311083894672, \"f0_5\": 0.2865384615384615, \"p4\": 0.22431024027388533, \"phi\": 0.17664537039570066}, {\"truth_threshold\": 32.96, \"match_probability\": 0.9999999998803119, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 891, \"tn\": 8049, \"fp\": 0, \"fn\": 11133, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07410179640718563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9258982035928144, \"precision\": 1.0, \"recall\": 0.07410179640718563, \"specificity\": 1.0, \"npv\": 0.4196121363778542, \"accuracy\": 0.4453743835002242, \"f1\": 0.13797909407665504, \"f2\": 0.09094249494763917, \"f0_5\": 0.28579676674364896, \"p4\": 0.22373738820164052, \"phi\": 0.1763349457704172}, {\"truth_threshold\": 32.980000000000004, \"match_probability\": 0.9999999998819595, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 889, \"tn\": 8049, \"fp\": 0, \"fn\": 11135, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0739354624085163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9260645375914837, \"precision\": 1.0, \"recall\": 0.0739354624085163, \"specificity\": 1.0, \"npv\": 0.41956839032527105, \"accuracy\": 0.44527474717281923, \"f1\": 0.13769069929528382, \"f2\": 0.09074206389711136, \"f0_5\": 0.28530166880616176, \"p4\": 0.22335499186659832, \"phi\": 0.17612774611257528}, {\"truth_threshold\": 33.0, \"match_probability\": 0.9999999998835847, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 888, \"tn\": 8049, \"fp\": 0, \"fn\": 11136, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07385229540918163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9261477045908184, \"precision\": 1.0, \"recall\": 0.07385229540918163, \"specificity\": 1.0, \"npv\": 0.419546520719312, \"accuracy\": 0.4452249290091167, \"f1\": 0.137546468401487, \"f2\": 0.09064184223419892, \"f0_5\": 0.2850539291217257, \"p4\": 0.22316364494700283, \"phi\": 0.1760240710415964}, {\"truth_threshold\": 33.02, \"match_probability\": 0.9999999998851874, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 880, \"tn\": 8049, \"fp\": 0, \"fn\": 11144, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07318695941450433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9268130405854956, \"precision\": 1.0, \"recall\": 0.07318695941450433, \"specificity\": 1.0, \"npv\": 0.4193716459125723, \"accuracy\": 0.44482638369949684, \"f1\": 0.13639181649101054, \"f2\": 0.08983992159425025, \"f0_5\": 0.28306742151312403, \"p4\": 0.22162928778759144, \"phi\": 0.17519285267669255}, {\"truth_threshold\": 33.04, \"match_probability\": 0.999999999886768, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 877, \"tn\": 8049, \"fp\": 0, \"fn\": 11147, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07293745841650033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9270625415834997, \"precision\": 1.0, \"recall\": 0.07293745841650033, \"specificity\": 1.0, \"npv\": 0.41930610543863306, \"accuracy\": 0.44467692920838936, \"f1\": 0.13595845283311372, \"f2\": 0.08953913380842506, \"f0_5\": 0.282320370847283, \"p4\": 0.22105225629251735, \"phi\": 0.17488030657914289}, {\"truth_threshold\": 33.06, \"match_probability\": 0.999999999888327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 875, \"tn\": 8049, \"fp\": 0, \"fn\": 11149, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.072771124417831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.927228875582169, \"precision\": 1.0, \"recall\": 0.072771124417831, \"specificity\": 1.0, \"npv\": 0.41926242316908013, \"accuracy\": 0.4445772928809844, \"f1\": 0.13566943173889448, \"f2\": 0.0893385881440036, \"f0_5\": 0.2818216954393198, \"p4\": 0.22066706742330422, \"phi\": 0.174671686200593}, {\"truth_threshold\": 33.08, \"match_probability\": 0.9999999998898644, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 874, \"tn\": 8049, \"fp\": 0, \"fn\": 11150, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07268795741849635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9273120425815037, \"precision\": 1.0, \"recall\": 0.07268795741849635, \"specificity\": 1.0, \"npv\": 0.4192405854471587, \"accuracy\": 0.44452747471728193, \"f1\": 0.13552488757946968, \"f2\": 0.0892383091688789, \"f0_5\": 0.2815721649484536, \"p4\": 0.22047432235650666, \"phi\": 0.1745672988365477}, {\"truth_threshold\": 33.1, \"match_probability\": 0.9999999998913807, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 873, \"tn\": 8049, \"fp\": 0, \"fn\": 11151, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07260479041916168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9273952095808383, \"precision\": 1.0, \"recall\": 0.07260479041916168, \"specificity\": 1.0, \"npv\": 0.41921875, \"accuracy\": 0.44447765655357946, \"f1\": 0.13538032100488487, \"f2\": 0.08913802609814372, \"f0_5\": 0.28132250580046403, \"p4\": 0.22028147674780302, \"phi\": 0.17446285989726562}, {\"truth_threshold\": 33.12, \"match_probability\": 0.999999999892876, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 872, \"tn\": 8049, \"fp\": 0, \"fn\": 11152, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07252162341982701, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.927478376580173, \"precision\": 1.0, \"recall\": 0.07252162341982701, \"specificity\": 1.0, \"npv\": 0.4191969168272486, \"accuracy\": 0.44442783838987693, \"f1\": 0.13523573200992556, \"f2\": 0.08903773893154714, \"f0_5\": 0.2810727178958226, \"p4\": 0.22008853050672558, \"phi\": 0.17435836928836615}, {\"truth_threshold\": 33.14, \"match_probability\": 0.9999999998943508, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 870, \"tn\": 8049, \"fp\": 0, \"fn\": 11154, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07235528942115768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9276447105788423, \"precision\": 1.0, \"recall\": 0.07235528942115768, \"specificity\": 1.0, \"npv\": 0.4191532573035463, \"accuracy\": 0.444328202062472, \"f1\": 0.13494648673801768, \"f2\": 0.08883715230976597, \"f0_5\": 0.2805727554179567, \"p4\": 0.21970233576504244, \"phi\": 0.17414923268283172}, {\"truth_threshold\": 33.160000000000004, \"match_probability\": 0.9999999998958053, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 869, \"tn\": 8049, \"fp\": 0, \"fn\": 11155, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07227212242182302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.927727877578177, \"precision\": 1.0, \"recall\": 0.07227212242182302, \"specificity\": 1.0, \"npv\": 0.41913143095188504, \"accuracy\": 0.4442783838987695, \"f1\": 0.13480183045063213, \"f2\": 0.08873685285407945, \"f0_5\": 0.2803225806451613, \"p4\": 0.21950908708296482, \"phi\": 0.17404458649607144}, {\"truth_threshold\": 33.2, \"match_probability\": 0.9999999998986546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 864, \"tn\": 8049, \"fp\": 0, \"fn\": 11160, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0718562874251497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281437125748503, \"precision\": 1.0, \"recall\": 0.0718562874251497, \"specificity\": 1.0, \"npv\": 0.4190223332812744, \"accuracy\": 0.44402929308025707, \"f1\": 0.1340782122905028, \"f2\": 0.08823529411764706, \"f0_5\": 0.27906976744186046, \"p4\": 0.21854132692108627, \"phi\": 0.1735205728950205}, {\"truth_threshold\": 33.22, \"match_probability\": 0.9999999999000498, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 854, \"tn\": 8049, \"fp\": 0, \"fn\": 11170, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07102461743180306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9289753825681969, \"precision\": 1.0, \"recall\": 0.07102461743180306, \"specificity\": 1.0, \"npv\": 0.41880430823664083, \"accuracy\": 0.4435311114432322, \"f1\": 0.13262929026246312, \"f2\": 0.08723186925434116, \"f0_5\": 0.2765544041450777, \"p4\": 0.21659818625362562, \"phi\": 0.172468593579522}, {\"truth_threshold\": 33.26, \"match_probability\": 0.999999999902783, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 850, \"tn\": 8049, \"fp\": 0, \"fn\": 11174, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0706919494344644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9293080505655356, \"precision\": 1.0, \"recall\": 0.0706919494344644, \"specificity\": 1.0, \"npv\": 0.4187171617333403, \"accuracy\": 0.44333183878842225, \"f1\": 0.13204909119154887, \"f2\": 0.08683038450537327, \"f0_5\": 0.27554460580912865, \"p4\": 0.2158180687417606, \"phi\": 0.1720463089537109}, {\"truth_threshold\": 33.28, \"match_probability\": 0.9999999999041214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 847, \"tn\": 8049, \"fp\": 0, \"fn\": 11177, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07044244843646041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9295575515635396, \"precision\": 1.0, \"recall\": 0.07044244843646041, \"specificity\": 1.0, \"npv\": 0.4186518256527619, \"accuracy\": 0.4431823842973148, \"f1\": 0.13161370522880894, \"f2\": 0.08652922787732668, \"f0_5\": 0.27478588113158575, \"p4\": 0.21523190213047444, \"phi\": 0.17172902969904272}, {\"truth_threshold\": 33.3, \"match_probability\": 0.9999999999054414, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 844, \"tn\": 8049, \"fp\": 0, \"fn\": 11180, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.07019294743845642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9298070525615436, \"precision\": 1.0, \"recall\": 0.07019294743845642, \"specificity\": 1.0, \"npv\": 0.4185865099589162, \"accuracy\": 0.44303292980620734, \"f1\": 0.13117811625738265, \"f2\": 0.08622803432774827, \"f0_5\": 0.274025974025974, \"p4\": 0.2146448083149793, \"phi\": 0.171411262442096}, {\"truth_threshold\": 33.32, \"match_probability\": 0.9999999999067432, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 838, \"tn\": 8049, \"fp\": 0, \"fn\": 11186, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06969394544244843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9303060545575516, \"precision\": 1.0, \"recall\": 0.06969394544244843, \"specificity\": 1.0, \"npv\": 0.4184559396932675, \"accuracy\": 0.44273402082399244, \"f1\": 0.13030632872026124, \"f2\": 0.08562553643683328, \"f0_5\": 0.2725026014568158, \"p4\": 0.21346782896114677, \"phi\": 0.17077425283411746}, {\"truth_threshold\": 33.34, \"match_probability\": 0.9999999999080271, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 832, \"tn\": 8049, \"fp\": 0, \"fn\": 11192, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06919494344644045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9308050565535595, \"precision\": 1.0, \"recall\": 0.06919494344644045, \"specificity\": 1.0, \"npv\": 0.4183254508601424, \"accuracy\": 0.44243511184177753, \"f1\": 0.12943372744243933, \"f2\": 0.08502289077828647, \"f0_5\": 0.2709744658676394, \"p4\": 0.21228711036896633, \"phi\": 0.1701352577053747}, {\"truth_threshold\": 33.36, \"match_probability\": 0.9999999999092933, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 831, \"tn\": 8049, \"fp\": 0, \"fn\": 11193, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06911177644710578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9308882235528942, \"precision\": 1.0, \"recall\": 0.06911177644710578, \"specificity\": 1.0, \"npv\": 0.4183037106329903, \"accuracy\": 0.44238529367807505, \"f1\": 0.12928821470245042, \"f2\": 0.08492243546508063, \"f0_5\": 0.2707193119624707, \"p4\": 0.2120899589655752, \"phi\": 0.17002856388343124}, {\"truth_threshold\": 33.38, \"match_probability\": 0.9999999999105421, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 826, \"tn\": 8049, \"fp\": 0, \"fn\": 11198, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06869594145043247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9313040585495675, \"precision\": 1.0, \"recall\": 0.06869594145043247, \"specificity\": 1.0, \"npv\": 0.4181950433833844, \"accuracy\": 0.4421362028595626, \"f1\": 0.12856031128404669, \"f2\": 0.08442009729773926, \"f0_5\": 0.26944154488517746, \"p4\": 0.21110263208083854, \"phi\": 0.16949425422451947}, {\"truth_threshold\": 33.4, \"match_probability\": 0.9999999999117737, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 822, \"tn\": 8049, \"fp\": 0, \"fn\": 11202, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06836327345309381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9316367265469062, \"precision\": 1.0, \"recall\": 0.06836327345309381, \"specificity\": 1.0, \"npv\": 0.41810815022596226, \"accuracy\": 0.44193693020475266, \"f1\": 0.1279775805698272, \"f2\": 0.08401815282718018, \"f0_5\": 0.2684169278996865, \"p4\": 0.2103108809994789, \"phi\": 0.16906579135610103}, {\"truth_threshold\": 33.42, \"match_probability\": 0.9999999999129883, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 820, \"tn\": 8049, \"fp\": 0, \"fn\": 11204, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06819693945442448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9318030605455755, \"precision\": 1.0, \"recall\": 0.06819693945442448, \"specificity\": 1.0, \"npv\": 0.4180647171869319, \"accuracy\": 0.44183729387734766, \"f1\": 0.12768607910308316, \"f2\": 0.08381715594079647, \"f0_5\": 0.2679038159958181, \"p4\": 0.20991437349154, \"phi\": 0.16885121914285456}, {\"truth_threshold\": 33.46, \"match_probability\": 0.9999999999153677, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 817, \"tn\": 8049, \"fp\": 0, \"fn\": 11207, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0679474384564205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9320525615435795, \"precision\": 1.0, \"recall\": 0.0679474384564205, \"specificity\": 1.0, \"npv\": 0.41799958454507685, \"accuracy\": 0.44168783938624023, \"f1\": 0.12724865664667862, \"f2\": 0.08351562979167093, \"f0_5\": 0.26713314151190165, \"p4\": 0.2093188201041251, \"phi\": 0.1685289323697446}, {\"truth_threshold\": 33.480000000000004, \"match_probability\": 0.9999999999165328, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 815, \"tn\": 8049, \"fp\": 0, \"fn\": 11209, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06778110445775117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9322188955422488, \"precision\": 1.0, \"recall\": 0.06778110445775117, \"specificity\": 1.0, \"npv\": 0.41795617405753455, \"accuracy\": 0.4415882030588352, \"f1\": 0.12695692810966586, \"f2\": 0.08331459180961338, \"f0_5\": 0.266618686207799, \"p4\": 0.20892125530178768, \"phi\": 0.16831378758900228}, {\"truth_threshold\": 33.5, \"match_probability\": 0.999999999917682, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 814, \"tn\": 8049, \"fp\": 0, \"fn\": 11210, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0676979374584165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9323020625415835, \"precision\": 1.0, \"recall\": 0.0676979374584165, \"specificity\": 1.0, \"npv\": 0.417934472194818, \"accuracy\": 0.44153838489513275, \"f1\": 0.1268110297554136, \"f2\": 0.08321406665303618, \"f0_5\": 0.2663612565445026, \"p4\": 0.20872231384688783, \"phi\": 0.16820612878358832}, {\"truth_threshold\": 33.52, \"match_probability\": 0.9999999999188153, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 808, \"tn\": 8049, \"fp\": 0, \"fn\": 11216, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06719893546240852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9328010645375915, \"precision\": 1.0, \"recall\": 0.06719893546240852, \"specificity\": 1.0, \"npv\": 0.4178043083311705, \"accuracy\": 0.44123947591291784, \"f1\": 0.1259351620947631, \"f2\": 0.08261082938000981, \"f0_5\": 0.264813843733613, \"p4\": 0.20752643224238973, \"phi\": 0.1675589590307321}, {\"truth_threshold\": 33.54, \"match_probability\": 0.9999999999199329, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 807, \"tn\": 8049, \"fp\": 0, \"fn\": 11217, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06711576846307385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9328842315369261, \"precision\": 1.0, \"recall\": 0.06711576846307385, \"specificity\": 1.0, \"npv\": 0.41778262223606355, \"accuracy\": 0.44118965774921537, \"f1\": 0.12578910451250877, \"f2\": 0.08251027544322434, \"f0_5\": 0.2645554681353265, \"p4\": 0.20732674558596126, \"phi\": 0.16745089352371786}, {\"truth_threshold\": 33.56, \"match_probability\": 0.9999999999210353, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 806, \"tn\": 8049, \"fp\": 0, \"fn\": 11218, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06703260146373918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9329673985362608, \"precision\": 1.0, \"recall\": 0.06703260146373918, \"specificity\": 1.0, \"npv\": 0.41776093839206935, \"accuracy\": 0.4411398395855129, \"f1\": 0.12564302416212003, \"f2\": 0.08240971739397161, \"f0_5\": 0.26429695697796435, \"p4\": 0.2071269520815384, \"phi\": 0.16734276945943402}, {\"truth_threshold\": 33.58, \"match_probability\": 0.9999999999221224, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 802, \"tn\": 8049, \"fp\": 0, \"fn\": 11222, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06669993346640053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9333000665335994, \"precision\": 1.0, \"recall\": 0.06669993346640053, \"specificity\": 1.0, \"npv\": 0.4176742255202117, \"accuracy\": 0.44094056693070294, \"f1\": 0.1250584749727117, \"f2\": 0.08200744406724202, \"f0_5\": 0.26326155462184875, \"p4\": 0.20632670762187932, \"phi\": 0.16690968531762468}, {\"truth_threshold\": 33.6, \"match_probability\": 0.9999999999231945, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 798, \"tn\": 8049, \"fp\": 0, \"fn\": 11226, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06636726546906188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9336327345309381, \"precision\": 1.0, \"recall\": 0.06636726546906188, \"specificity\": 1.0, \"npv\": 0.4175875486381323, \"accuracy\": 0.440741294275893, \"f1\": 0.12447356106691623, \"f2\": 0.08160510492084919, \"f0_5\": 0.2622239747634069, \"p4\": 0.2055247457319615, \"phi\": 0.16647565496805147}, {\"truth_threshold\": 33.62, \"match_probability\": 0.9999999999242519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 794, \"tn\": 8049, \"fp\": 0, \"fn\": 11230, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06603459747172322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9339654025282768, \"precision\": 1.0, \"recall\": 0.06603459747172322, \"specificity\": 1.0, \"npv\": 0.4175009077234296, \"accuracy\": 0.440542021621083, \"f1\": 0.12388828210329225, \"f2\": 0.08120269993863775, \"f0_5\": 0.2611842105263158, \"p4\": 0.20472106008949398, \"phi\": 0.16604067087793803}, {\"truth_threshold\": 33.64, \"match_probability\": 0.9999999999252948, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 793, \"tn\": 8049, \"fp\": 0, \"fn\": 11231, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06595143047238855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9340485695276114, \"precision\": 1.0, \"recall\": 0.06595143047238855, \"specificity\": 1.0, \"npv\": 0.4174792531120332, \"accuracy\": 0.44049220345738055, \"f1\": 0.12374190528204729, \"f2\": 0.08110208840434453, \"f0_5\": 0.2609239273493024, \"p4\": 0.20451986859872795, \"phi\": 0.1659317749416397}, {\"truth_threshold\": 33.660000000000004, \"match_probability\": 0.9999999999263233, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 791, \"tn\": 8049, \"fp\": 0, \"fn\": 11233, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06578509647371923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9342149035262808, \"precision\": 1.0, \"recall\": 0.06578509647371923, \"specificity\": 1.0, \"npv\": 0.41743595062752825, \"accuracy\": 0.4403925671299756, \"f1\": 0.12344908310573546, \"f2\": 0.08090085298750178, \"f0_5\": 0.2604029496971293, \"p4\": 0.20411716082447476, \"phi\": 0.1657138023329096}, {\"truth_threshold\": 33.68, \"match_probability\": 0.9999999999273376, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 786, \"tn\": 8049, \"fp\": 0, \"fn\": 11238, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06536926147704591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9346307385229541, \"precision\": 1.0, \"recall\": 0.06536926147704591, \"specificity\": 1.0, \"npv\": 0.4173277337066418, \"accuracy\": 0.44014347631146317, \"f1\": 0.12271662763466042, \"f2\": 0.08039769240211121, \"f0_5\": 0.2590981012658228, \"p4\": 0.20310849210409257, \"phi\": 0.16516781086607782}, {\"truth_threshold\": 33.72, \"match_probability\": 0.9999999999293245, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 784, \"tn\": 8049, \"fp\": 0, \"fn\": 11240, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06520292747837658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9347970725216235, \"precision\": 1.0, \"recall\": 0.06520292747837658, \"specificity\": 1.0, \"npv\": 0.41728446264710456, \"accuracy\": 0.44004383998405816, \"f1\": 0.12242348532167395, \"f2\": 0.08019639934533551, \"f0_5\": 0.25857519788918204, \"p4\": 0.2027042627984206, \"phi\": 0.1649489877381262}, {\"truth_threshold\": 33.74, \"match_probability\": 0.9999999999302975, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 781, \"tn\": 8049, \"fp\": 0, \"fn\": 11243, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06495342648037258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9350465735196274, \"precision\": 1.0, \"recall\": 0.06495342648037258, \"specificity\": 1.0, \"npv\": 0.41721957287995026, \"accuracy\": 0.43989438549295073, \"f1\": 0.12198360015618899, \"f2\": 0.0798944288724758, \"f0_5\": 0.2577898072352786, \"p4\": 0.202097100093404, \"phi\": 0.16462029295694472}, {\"truth_threshold\": 33.78, \"match_probability\": 0.9999999999322036, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 780, \"tn\": 8049, \"fp\": 0, \"fn\": 11244, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06487025948103792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.935129740518962, \"precision\": 1.0, \"recall\": 0.06487025948103792, \"specificity\": 1.0, \"npv\": 0.41719794744207744, \"accuracy\": 0.43984456732924826, \"f1\": 0.1218369259606373, \"f2\": 0.07979376381045912, \"f0_5\": 0.25752773375594296, \"p4\": 0.20189449378916413, \"phi\": 0.16451060484213162}, {\"truth_threshold\": 33.8, \"match_probability\": 0.9999999999331369, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 779, \"tn\": 8049, \"fp\": 0, \"fn\": 11245, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06478709248170327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9352129075182968, \"precision\": 1.0, \"recall\": 0.06478709248170327, \"specificity\": 1.0, \"npv\": 0.4171763242458795, \"accuracy\": 0.4397947491655458, \"f1\": 0.12169022885261267, \"f2\": 0.07969309462915601, \"f0_5\": 0.25726552179656537, \"p4\": 0.20169177794849094, \"phi\": 0.16440085492507275}, {\"truth_threshold\": 33.82, \"match_probability\": 0.9999999999340575, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 776, \"tn\": 8049, \"fp\": 0, \"fn\": 11248, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06453759148369927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9354624085163007, \"precision\": 1.0, \"recall\": 0.06453759148369927, \"specificity\": 1.0, \"npv\": 0.41711146810385036, \"accuracy\": 0.4396452946744383, \"f1\": 0.12125, \"f2\": 0.07939106236699951, \"f0_5\": 0.25647805393971446, \"p4\": 0.20108297219451055, \"phi\": 0.16407123310212657}, {\"truth_threshold\": 33.84, \"match_probability\": 0.9999999999349654, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 773, \"tn\": 8049, \"fp\": 0, \"fn\": 11251, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06428809048569528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9357119095143047, \"precision\": 1.0, \"recall\": 0.06428809048569528, \"specificity\": 1.0, \"npv\": 0.41704663212435233, \"accuracy\": 0.4394958401833308, \"f1\": 0.12080956474173635, \"f2\": 0.07908899302216128, \"f0_5\": 0.25568933580312253, \"p4\": 0.20047317695933822, \"phi\": 0.16374105051197405}, {\"truth_threshold\": 33.86, \"match_probability\": 0.9999999999358606, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 768, \"tn\": 8049, \"fp\": 0, \"fn\": 11256, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06387225548902195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936127744510978, \"precision\": 1.0, \"recall\": 0.06387225548902195, \"specificity\": 1.0, \"npv\": 0.41693861693861695, \"accuracy\": 0.4392467493648184, \"f1\": 0.1200750469043152, \"f2\": 0.07858546168958742, \"f0_5\": 0.2543720190779014, \"p4\": 0.19945464524353662, \"phi\": 0.16318949066757577}, {\"truth_threshold\": 33.88, \"match_probability\": 0.9999999999367437, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 765, \"tn\": 8049, \"fp\": 0, \"fn\": 11259, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06362275449101797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936377245508982, \"precision\": 1.0, \"recall\": 0.06362275449101797, \"specificity\": 1.0, \"npv\": 0.4168738346799254, \"accuracy\": 0.43909729487371096, \"f1\": 0.11963406052076003, \"f2\": 0.07828329342420336, \"f0_5\": 0.2535799522673031, \"p4\": 0.19884219791449145, \"phi\": 0.16285779575313583}, {\"truth_threshold\": 33.9, \"match_probability\": 0.9999999999376146, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 764, \"tn\": 8049, \"fp\": 0, \"fn\": 11260, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0635395874916833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9364604125083167, \"precision\": 1.0, \"recall\": 0.0635395874916833, \"specificity\": 1.0, \"npv\": 0.4168522450670672, \"accuracy\": 0.4390474767100085, \"f1\": 0.11948701908038786, \"f2\": 0.0781825624232501, \"f0_5\": 0.253315649867374, \"p4\": 0.1986378268049412, \"phi\": 0.1627471034966322}, {\"truth_threshold\": 33.92, \"match_probability\": 0.9999999999384734, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 762, \"tn\": 8049, \"fp\": 0, \"fn\": 11262, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06337325349301397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9366267465069861, \"precision\": 1.0, \"recall\": 0.06337325349301397, \"specificity\": 1.0, \"npv\": 0.4168090725493242, \"accuracy\": 0.4389478403826035, \"f1\": 0.11919286719849835, \"f2\": 0.07798108805108682, \"f0_5\": 0.25278662420382164, \"p4\": 0.19822875096735423, \"phi\": 0.16252552726527725}, {\"truth_threshold\": 33.94, \"match_probability\": 0.9999999999393205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 760, \"tn\": 8049, \"fp\": 0, \"fn\": 11264, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06320691949434465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9367930805056554, \"precision\": 1.0, \"recall\": 0.06320691949434465, \"specificity\": 1.0, \"npv\": 0.41676590897323046, \"accuracy\": 0.43884820405519853, \"f1\": 0.11889862327909888, \"f2\": 0.07777959718355985, \"f0_5\": 0.25225703664365373, \"p4\": 0.1978192296160084, \"phi\": 0.162303694524981}, {\"truth_threshold\": 33.96, \"match_probability\": 0.9999999999401559, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 759, \"tn\": 8049, \"fp\": 0, \"fn\": 11265, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06312375249500998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.93687624750499, \"precision\": 1.0, \"recall\": 0.06312375249500998, \"specificity\": 1.0, \"npv\": 0.416744330537434, \"accuracy\": 0.43879838589149606, \"f1\": 0.1187514667918329, \"f2\": 0.0776788455634019, \"f0_5\": 0.25199203187250996, \"p4\": 0.19761430161378457, \"phi\": 0.16219268163065684}, {\"truth_threshold\": 33.980000000000004, \"match_probability\": 0.9999999999409798, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 757, \"tn\": 8049, \"fp\": 0, \"fn\": 11267, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06295741849634065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9370425815036594, \"precision\": 1.0, \"recall\": 0.06295741849634065, \"specificity\": 1.0, \"npv\": 0.4167011803686063, \"accuracy\": 0.43869874956409105, \"f1\": 0.11845708473515375, \"f2\": 0.07747732994903077, \"f0_5\": 0.2514615997874037, \"p4\": 0.1972041104373416, \"phi\": 0.161970462123146}, {\"truth_threshold\": 34.0, \"match_probability\": 0.9999999999417923, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 754, \"tn\": 8049, \"fp\": 0, \"fn\": 11270, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06270791749833667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9372920825016633, \"precision\": 1.0, \"recall\": 0.06270791749833667, \"specificity\": 1.0, \"npv\": 0.41663647186707387, \"accuracy\": 0.4385492950729836, \"f1\": 0.11801533886367194, \"f2\": 0.07717502558853634, \"f0_5\": 0.25066489361702127, \"p4\": 0.1965879841821873, \"phi\": 0.16163664653981946}, {\"truth_threshold\": 34.02, \"match_probability\": 0.9999999999425937, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 748, \"tn\": 8049, \"fp\": 0, \"fn\": 11276, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.062208915502328675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9377910844976713, \"precision\": 1.0, \"recall\": 0.062208915502328675, \"specificity\": 1.0, \"npv\": 0.41650711513583444, \"accuracy\": 0.4382503860907687, \"f1\": 0.11713122455371125, \"f2\": 0.0765703054622881, \"f0_5\": 0.2490676611614278, \"p4\": 0.19535269916881887, \"phi\": 0.16096725111526194}, {\"truth_threshold\": 34.04, \"match_probability\": 0.9999999999433841, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 745, \"tn\": 8049, \"fp\": 0, \"fn\": 11279, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.061959414504324684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9380405854956753, \"precision\": 1.0, \"recall\": 0.061959414504324684, \"specificity\": 1.0, \"npv\": 0.4164424668874172, \"accuracy\": 0.43810093159966124, \"f1\": 0.11668885582269559, \"f2\": 0.07626788968284842, \"f0_5\": 0.24826712876566248, \"p4\": 0.19473353474779398, \"phi\": 0.16063166382466748}, {\"truth_threshold\": 34.06, \"match_probability\": 0.9999999999441634, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 744, \"tn\": 8049, \"fp\": 0, \"fn\": 11280, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06187624750499002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.93812375249501, \"precision\": 1.0, \"recall\": 0.06187624750499002, \"specificity\": 1.0, \"npv\": 0.41642092193077757, \"accuracy\": 0.43805111343595876, \"f1\": 0.11654135338345864, \"f2\": 0.07616707616707617, \"f0_5\": 0.248, \"p4\": 0.1945269204367518, \"phi\": 0.16051966867535242}, {\"truth_threshold\": 34.08, \"match_probability\": 0.9999999999449322, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 742, \"tn\": 8049, \"fp\": 0, \"fn\": 11282, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06170991350632069, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9382900864936793, \"precision\": 1.0, \"recall\": 0.06170991350632069, \"specificity\": 1.0, \"npv\": 0.41637783870467127, \"accuracy\": 0.43795147710855376, \"f1\": 0.1162462791790694, \"f2\": 0.07596543675007167, \"f0_5\": 0.24746531483457845, \"p4\": 0.19411335192456386, \"phi\": 0.16029547845280606}, {\"truth_threshold\": 34.12, \"match_probability\": 0.9999999999464381, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 739, \"tn\": 8049, \"fp\": 0, \"fn\": 11285, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0614604125083167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9385395874916833, \"precision\": 1.0, \"recall\": 0.0614604125083167, \"specificity\": 1.0, \"npv\": 0.4163132305782559, \"accuracy\": 0.43780202261744633, \"f1\": 0.11580349447622032, \"f2\": 0.07566294665711068, \"f0_5\": 0.2466622162883845, \"p4\": 0.19349214784149404, \"phi\": 0.15995869117997175}, {\"truth_threshold\": 34.14, \"match_probability\": 0.9999999999471755, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 738, \"tn\": 8049, \"fp\": 0, \"fn\": 11286, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.061377245508982034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.938622754491018, \"precision\": 1.0, \"recall\": 0.061377245508982034, \"specificity\": 1.0, \"npv\": 0.41629169899146623, \"accuracy\": 0.43775220445374385, \"f1\": 0.1156558533145275, \"f2\": 0.07556210836712127, \"f0_5\": 0.24639423076923078, \"p4\": 0.19328485237173812, \"phi\": 0.1598462943341211}, {\"truth_threshold\": 34.160000000000004, \"match_probability\": 0.9999999999479027, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 737, \"tn\": 8049, \"fp\": 0, \"fn\": 11287, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.061294078509647375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9387059214903526, \"precision\": 1.0, \"recall\": 0.061294078509647375, \"specificity\": 1.0, \"npv\": 0.41627016963177493, \"accuracy\": 0.4377023862900413, \"f1\": 0.11550818901340021, \"f2\": 0.07546126594720783, \"f0_5\": 0.2461261020571734, \"p4\": 0.19307744300357163, \"phi\": 0.15973383003808003}, {\"truth_threshold\": 34.18, \"match_probability\": 0.9999999999486199, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 736, \"tn\": 8049, \"fp\": 0, \"fn\": 11288, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06121091151031271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9387890884896873, \"precision\": 1.0, \"recall\": 0.06121091151031271, \"specificity\": 1.0, \"npv\": 0.4162486424988364, \"accuracy\": 0.43765256812633885, \"f1\": 0.11536050156739812, \"f2\": 0.07536041939711664, \"f0_5\": 0.24585783003741316, \"p4\": 0.19286991963037095, \"phi\": 0.15962129814747175}, {\"truth_threshold\": 34.2, \"match_probability\": 0.9999999999493273, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 734, \"tn\": 8049, \"fp\": 0, \"fn\": 11290, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06104457751164338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9389554224883566, \"precision\": 1.0, \"recall\": 0.06104457751164338, \"specificity\": 1.0, \"npv\": 0.4162055949118362, \"accuracy\": 0.4375529317989339, \"f1\": 0.11506505721899984, \"f2\": 0.07515871390538603, \"f0_5\": 0.24532085561497327, \"p4\": 0.1924545304417145, \"phi\": 0.15939603100257935}, {\"truth_threshold\": 34.22, \"match_probability\": 0.9999999999500249, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 733, \"tn\": 8049, \"fp\": 0, \"fn\": 11291, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06096141051230872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9390385894876913, \"precision\": 1.0, \"recall\": 0.06096141051230872, \"specificity\": 1.0, \"npv\": 0.4161840744570838, \"accuracy\": 0.4375031136352314, \"f1\": 0.11491730030571451, \"f2\": 0.07505785496323907, \"f0_5\": 0.24505215298208077, \"p4\": 0.19224666441235275, \"phi\": 0.15928329545706774}, {\"truth_threshold\": 34.24, \"match_probability\": 0.999999999950713, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 731, \"tn\": 8049, \"fp\": 0, \"fn\": 11293, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.060795076513639384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9392049234863606, \"precision\": 1.0, \"recall\": 0.060795076513639384, \"specificity\": 1.0, \"npv\": 0.41614104022334814, \"accuracy\": 0.4374034773078264, \"f1\": 0.11462171697373578, \"f2\": 0.07485612468511274, \"f0_5\": 0.2445143162964945, \"p4\": 0.19183058894780555, \"phi\": 0.15905761968809898}, {\"truth_threshold\": 34.26, \"match_probability\": 0.9999999999513914, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 729, \"tn\": 8049, \"fp\": 0, \"fn\": 11295, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.06062874251497006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9393712574850299, \"precision\": 1.0, \"recall\": 0.06062874251497006, \"specificity\": 1.0, \"npv\": 0.4160980148883375, \"accuracy\": 0.43730384098042147, \"f1\": 0.11432604093154553, \"f2\": 0.07465437788018434, \"f0_5\": 0.24397590361445784, \"p4\": 0.1914140548929388, \"phi\": 0.15883167003357734}, {\"truth_threshold\": 34.28, \"match_probability\": 0.9999999999520607, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 727, \"tn\": 8049, \"fp\": 0, \"fn\": 11297, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.060462408516300734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9395375914836993, \"precision\": 1.0, \"recall\": 0.060462408516300734, \"specificity\": 1.0, \"npv\": 0.41605499844929184, \"accuracy\": 0.4372042046530165, \"f1\": 0.11403027213551878, \"f2\": 0.0744526145464228, \"f0_5\": 0.24343691401017947, \"p4\": 0.19099706138682657, \"phi\": 0.1586054453084444}, {\"truth_threshold\": 34.300000000000004, \"match_probability\": 0.9999999999527207, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 725, \"tn\": 8049, \"fp\": 0, \"fn\": 11299, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0602960745176314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9397039254823686, \"precision\": 1.0, \"recall\": 0.0602960745176314, \"specificity\": 1.0, \"npv\": 0.41601199090345253, \"accuracy\": 0.4371045683256115, \"f1\": 0.1137344105420033, \"f2\": 0.07425083468179677, \"f0_5\": 0.24289734655588313, \"p4\": 0.19057960756641074, \"phi\": 0.15837894431944788}, {\"truth_threshold\": 34.32, \"match_probability\": 0.9999999999533716, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 721, \"tn\": 8049, \"fp\": 0, \"fn\": 11303, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05996340652029275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9400365934797072, \"precision\": 1.0, \"recall\": 0.05996340652029275, \"specificity\": 1.0, \"npv\": 0.41592600248036377, \"accuracy\": 0.43690529567080155, \"f1\": 0.11314240878775991, \"f2\": 0.07384722535182416, \"f0_5\": 0.24181647437617387, \"p4\": 0.18974331551973586, \"phi\": 0.1579251087354077}, {\"truth_threshold\": 34.34, \"match_probability\": 0.9999999999540136, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 719, \"tn\": 8049, \"fp\": 0, \"fn\": 11305, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05979707252162342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9402029274783765, \"precision\": 1.0, \"recall\": 0.05979707252162342, \"specificity\": 1.0, \"npv\": 0.41588302159760254, \"accuracy\": 0.4368056593433966, \"f1\": 0.11284626853959036, \"f2\": 0.07364539588241319, \"f0_5\": 0.2412751677852349, \"p4\": 0.18932447555664064, \"phi\": 0.15769777171217012}, {\"truth_threshold\": 34.36, \"match_probability\": 0.9999999999546466, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 715, \"tn\": 8049, \"fp\": 0, \"fn\": 11309, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05946440452428477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9405355954757152, \"precision\": 1.0, \"recall\": 0.05946440452428477, \"specificity\": 1.0, \"npv\": 0.4157970864758756, \"accuracy\": 0.43660638668858665, \"f1\": 0.11225370908234555, \"f2\": 0.07324168732457847, \"f0_5\": 0.24019080892233272, \"p4\": 0.18848540339266423, \"phi\": 0.157242253069016}, {\"truth_threshold\": 34.38, \"match_probability\": 0.999999999955271, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 713, \"tn\": 8049, \"fp\": 0, \"fn\": 11311, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.059298070525615434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9407019294743846, \"precision\": 1.0, \"recall\": 0.059298070525615434, \"specificity\": 1.0, \"npv\": 0.41575413223140495, \"accuracy\": 0.4365067503611817, \"f1\": 0.11195728978566381, \"f2\": 0.07303980823208835, \"f0_5\": 0.23964775477278838, \"p4\": 0.18806516944197463, \"phi\": 0.15701406896954775}, {\"truth_threshold\": 34.4, \"match_probability\": 0.9999999999558868, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 710, \"tn\": 8049, \"fp\": 0, \"fn\": 11314, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05904856952761144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9409514304723886, \"precision\": 1.0, \"recall\": 0.05904856952761144, \"specificity\": 1.0, \"npv\": 0.41568971750245315, \"accuracy\": 0.4363572958700742, \"f1\": 0.11151248625726402, \"f2\": 0.07273695857066755, \"f0_5\": 0.23883207750269106, \"p4\": 0.18743394371097719, \"phi\": 0.15667125832729106}, {\"truth_threshold\": 34.46, \"match_probability\": 0.9999999999576838, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 706, \"tn\": 8049, \"fp\": 0, \"fn\": 11318, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.058715901530272785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9412840984697272, \"precision\": 1.0, \"recall\": 0.058715901530272785, \"specificity\": 1.0, \"npv\": 0.4156038622398926, \"accuracy\": 0.4361580232152643, \"f1\": 0.11091908876669285, \"f2\": 0.07233310110241384, \"f0_5\": 0.2377424568965517, \"p4\": 0.18659067180609706, \"phi\": 0.15621317310290636}, {\"truth_threshold\": 34.480000000000004, \"match_probability\": 0.9999999999582664, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 705, \"tn\": 8049, \"fp\": 0, \"fn\": 11319, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.058632734530938126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9413672654690619, \"precision\": 1.0, \"recall\": 0.058632734530938126, \"specificity\": 1.0, \"npv\": 0.4155824039653036, \"accuracy\": 0.4361082050515618, \"f1\": 0.11077068112184775, \"f2\": 0.07223212639085265, \"f0_5\": 0.23746968472109944, \"p4\": 0.18637956066503128, \"phi\": 0.15609847138081376}, {\"truth_threshold\": 34.5, \"match_probability\": 0.9999999999588409, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 703, \"tn\": 8049, \"fp\": 0, \"fn\": 11321, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05846640053226879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9415335994677312, \"precision\": 1.0, \"recall\": 0.05846640053226879, \"specificity\": 1.0, \"npv\": 0.415539494062984, \"accuracy\": 0.43600856872415683, \"f1\": 0.11047379586705429, \"f2\": 0.0720301645525523, \"f0_5\": 0.2369236991102723, \"p4\": 0.18595698580900097, \"phi\": 0.15586885030968423}, {\"truth_threshold\": 34.52, \"match_probability\": 0.9999999999594076, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 701, \"tn\": 8049, \"fp\": 0, \"fn\": 11323, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05830006653359947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9416999334664006, \"precision\": 1.0, \"recall\": 0.05830006653359947, \"specificity\": 1.0, \"npv\": 0.41549659302085484, \"accuracy\": 0.4359089323967519, \"f1\": 0.11017681728880158, \"f2\": 0.07182818615898519, \"f0_5\": 0.2363771243593202, \"p4\": 0.18553394011323676, \"phi\": 0.1556389379866097}, {\"truth_threshold\": 34.54, \"match_probability\": 0.9999999999599665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 698, \"tn\": 8049, \"fp\": 0, \"fn\": 11326, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.058050565535595476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9419494344644045, \"precision\": 1.0, \"recall\": 0.058050565535595476, \"specificity\": 1.0, \"npv\": 0.4154322580645161, \"accuracy\": 0.4357594779056444, \"f1\": 0.10973117434365666, \"f2\": 0.07152518752305612, \"f0_5\": 0.2355561555075594, \"p4\": 0.18489848679457432, \"phi\": 0.1552935205421482}, {\"truth_threshold\": 34.56, \"match_probability\": 0.9999999999605176, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 697, \"tn\": 8049, \"fp\": 0, \"fn\": 11327, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05796739853626081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9420326014637392, \"precision\": 1.0, \"recall\": 0.05796739853626081, \"specificity\": 1.0, \"npv\": 0.41541081750619324, \"accuracy\": 0.4357096597419419, \"f1\": 0.10958257998585016, \"f2\": 0.07142417969790749, \"f0_5\": 0.23528220361868754, \"p4\": 0.18468643263473672, \"phi\": 0.1551782343457207}, {\"truth_threshold\": 34.58, \"match_probability\": 0.9999999999610611, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 695, \"tn\": 8049, \"fp\": 0, \"fn\": 11329, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.057801064537591484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9421989354624085, \"precision\": 1.0, \"recall\": 0.057801064537591484, \"specificity\": 1.0, \"npv\": 0.41536794302817626, \"accuracy\": 0.4356100234145369, \"f1\": 0.10928532117304819, \"f2\": 0.07122215162632453, \"f0_5\": 0.2347338557146717, \"p4\": 0.1842619690625417, \"phi\": 0.15494744038485514}, {\"truth_threshold\": 34.6, \"match_probability\": 0.9999999999615973, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 686, \"tn\": 8049, \"fp\": 0, \"fn\": 11338, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05705256154357951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9429474384564205, \"precision\": 1.0, \"recall\": 0.05705256154357951, \"specificity\": 1.0, \"npv\": 0.4151751173466756, \"accuracy\": 0.4351616599412146, \"f1\": 0.1079464988198269, \"f2\": 0.07031282030257062, \"f0_5\": 0.23225893824485375, \"p4\": 0.1823459990377125, \"phi\": 0.15390517838521242}, {\"truth_threshold\": 34.62, \"match_probability\": 0.999999999962126, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 684, \"tn\": 8049, \"fp\": 0, \"fn\": 11340, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05688622754491018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9431137724550899, \"precision\": 1.0, \"recall\": 0.05688622754491018, \"specificity\": 1.0, \"npv\": 0.4151322915054928, \"accuracy\": 0.4350620236138096, \"f1\": 0.10764872521246459, \"f2\": 0.07011070110701106, \"f0_5\": 0.23170731707317074, \"p4\": 0.18191891498858478, \"phi\": 0.15367273667056708}, {\"truth_threshold\": 34.64, \"match_probability\": 0.9999999999626474, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 681, \"tn\": 8049, \"fp\": 0, \"fn\": 11343, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.056636726546906185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9433632734530938, \"precision\": 1.0, \"recall\": 0.056636726546906185, \"specificity\": 1.0, \"npv\": 0.4150680693069307, \"accuracy\": 0.43491256912270215, \"f1\": 0.10720188902007084, \"f2\": 0.06980749123562335, \"f0_5\": 0.23087876322213183, \"p4\": 0.181277389757505, \"phi\": 0.15332350354622393}, {\"truth_threshold\": 34.7, \"match_probability\": 0.999999999964169, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 680, \"tn\": 8049, \"fp\": 0, \"fn\": 11344, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.056553559547571526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9434464404524284, \"precision\": 1.0, \"recall\": 0.056553559547571526, \"specificity\": 1.0, \"npv\": 0.4150466663229, \"accuracy\": 0.4348627509589997, \"f1\": 0.1070528967254408, \"f2\": 0.06970641298999508, \"f0_5\": 0.23060227889310905, \"p4\": 0.18106330778195232, \"phi\": 0.15320693965650897}, {\"truth_threshold\": 34.72, \"match_probability\": 0.9999999999646623, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 679, \"tn\": 8049, \"fp\": 0, \"fn\": 11345, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05647039254823686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9435296074517632, \"precision\": 1.0, \"recall\": 0.05647039254823686, \"specificity\": 1.0, \"npv\": 0.4150252655460452, \"accuracy\": 0.43481293279529715, \"f1\": 0.10690388097299851, \"f2\": 0.06960533059969247, \"f0_5\": 0.230325644504749, \"p4\": 0.18084910549982014, \"phi\": 0.15309029904870333}, {\"truth_threshold\": 34.74, \"match_probability\": 0.9999999999651488, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 678, \"tn\": 8049, \"fp\": 0, \"fn\": 11346, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.056387225548902194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9436127744510978, \"precision\": 1.0, \"recall\": 0.056387225548902194, \"specificity\": 1.0, \"npv\": 0.41500386697602476, \"accuracy\": 0.43476311463159467, \"f1\": 0.1067548417572036, \"f2\": 0.06950424406446057, \"f0_5\": 0.2300488599348534, \"p4\": 0.18063478279650294, \"phi\": 0.15297358154545415}, {\"truth_threshold\": 34.76, \"match_probability\": 0.9999999999656286, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 675, \"tn\": 8049, \"fp\": 0, \"fn\": 11349, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0561377245508982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9438622754491018, \"precision\": 1.0, \"recall\": 0.0561377245508982, \"specificity\": 1.0, \"npv\": 0.41493968450355706, \"accuracy\": 0.43461366014048725, \"f1\": 0.10630758327427356, \"f2\": 0.0692009595866396, \"f0_5\": 0.22921760391198043, \"p4\": 0.1799910910112239, \"phi\": 0.15262296587963847}, {\"truth_threshold\": 34.78, \"match_probability\": 0.9999999999661018, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 674, \"tn\": 8049, \"fp\": 0, \"fn\": 11350, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05605455755156354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9439454424484365, \"precision\": 1.0, \"recall\": 0.05605455755156354, \"specificity\": 1.0, \"npv\": 0.4149182947574617, \"accuracy\": 0.4345638419767847, \"f1\": 0.10615845014962987, \"f2\": 0.06909985646914087, \"f0_5\": 0.22894021739130435, \"p4\": 0.17977628547422694, \"phi\": 0.15250593900789158}, {\"truth_threshold\": 34.800000000000004, \"match_probability\": 0.9999999999665685, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 671, \"tn\": 8049, \"fp\": 0, \"fn\": 11353, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.055805056553559544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9441949434464405, \"precision\": 1.0, \"recall\": 0.055805056553559544, \"specificity\": 1.0, \"npv\": 0.4148541387485826, \"accuracy\": 0.4344143874856773, \"f1\": 0.10571090980701063, \"f2\": 0.06879652223839891, \"f0_5\": 0.22810715257002992, \"p4\": 0.17913114242292952, \"phi\": 0.1521543909137784}, {\"truth_threshold\": 34.82, \"match_probability\": 0.9999999999670287, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 666, \"tn\": 8049, \"fp\": 0, \"fn\": 11358, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05538922155688623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9446107784431138, \"precision\": 1.0, \"recall\": 0.05538922155688623, \"specificity\": 1.0, \"npv\": 0.41474725614469005, \"accuracy\": 0.43416529666716486, \"f1\": 0.1049645390070922, \"f2\": 0.06829088224437062, \"f0_5\": 0.2267156862745098, \"p4\": 0.17805347559053494, \"phi\": 0.15156690819802612}, {\"truth_threshold\": 34.86, \"match_probability\": 0.9999999999679303, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 662, \"tn\": 8049, \"fp\": 0, \"fn\": 11362, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05505655355954757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9449434464404525, \"precision\": 1.0, \"recall\": 0.05505655355954757, \"specificity\": 1.0, \"npv\": 0.41466178970686723, \"accuracy\": 0.4339660240123549, \"f1\": 0.10436701876083872, \"f2\": 0.06788629558226342, \"f0_5\": 0.22559978189749183, \"p4\": 0.177189148183145, \"phi\": 0.15109549640573006}, {\"truth_threshold\": 34.9, \"match_probability\": 0.9999999999688073, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 661, \"tn\": 8049, \"fp\": 0, \"fn\": 11363, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05497338656021291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9450266134397871, \"precision\": 1.0, \"recall\": 0.05497338656021291, \"specificity\": 1.0, \"npv\": 0.4146404286008654, \"accuracy\": 0.4339162058486524, \"f1\": 0.10421757981868349, \"f2\": 0.06778513854420903, \"f0_5\": 0.22532042541587127, \"p4\": 0.17697276064456152, \"phi\": 0.15097744389466838}, {\"truth_threshold\": 34.94, \"match_probability\": 0.9999999999696603, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 659, \"tn\": 8049, \"fp\": 0, \"fn\": 11365, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05480705256154358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9451929474384564, \"precision\": 1.0, \"recall\": 0.05480705256154358, \"specificity\": 1.0, \"npv\": 0.4145977129906253, \"accuracy\": 0.4338165695212474, \"f1\": 0.10391863123866593, \"f2\": 0.06758281201928007, \"f0_5\": 0.2247612551159618, \"p4\": 0.17653961792319323, \"phi\": 0.15074109807140507}, {\"truth_threshold\": 34.980000000000004, \"match_probability\": 0.9999999999704899, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 658, \"tn\": 8049, \"fp\": 0, \"fn\": 11366, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05472388556220892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9452761144377911, \"precision\": 1.0, \"recall\": 0.05472388556220892, \"specificity\": 1.0, \"npv\": 0.41457635848570695, \"accuracy\": 0.43376675135754494, \"f1\": 0.10376912158965462, \"f2\": 0.06748164253189481, \"f0_5\": 0.22448144104803494, \"p4\": 0.1763228625054963, \"phi\": 0.15062280437758793}, {\"truth_threshold\": 35.0, \"match_probability\": 0.9999999999708962, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 653, \"tn\": 8049, \"fp\": 0, \"fn\": 11371, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.054308050565535594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9456919494344644, \"precision\": 1.0, \"recall\": 0.054308050565535594, \"specificity\": 1.0, \"npv\": 0.41446961894953654, \"accuracy\": 0.4335176605390325, \"f1\": 0.10302121953143488, \"f2\": 0.06697573283554535, \"f0_5\": 0.22308007652364034, \"p4\": 0.17523724013525216, \"phi\": 0.15003012038850633}, {\"truth_threshold\": 35.02, \"match_probability\": 0.9999999999712968, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 648, \"tn\": 8049, \"fp\": 0, \"fn\": 11376, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05389221556886228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9461077844311377, \"precision\": 1.0, \"recall\": 0.05389221556886228, \"specificity\": 1.0, \"npv\": 0.41436293436293437, \"accuracy\": 0.4332685697205201, \"f1\": 0.10227272727272728, \"f2\": 0.06646971935007386, \"f0_5\": 0.22167487684729065, \"p4\": 0.17414853145340137, \"phi\": 0.1494353926699883}, {\"truth_threshold\": 35.04, \"match_probability\": 0.999999999971692, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 642, \"tn\": 8049, \"fp\": 0, \"fn\": 11382, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.053393213572854294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9466067864271457, \"precision\": 1.0, \"recall\": 0.053393213572854294, \"specificity\": 1.0, \"npv\": 0.41423498533271574, \"accuracy\": 0.4329696607383052, \"f1\": 0.10137375651350071, \"f2\": 0.0658623661208913, \"f0_5\": 0.21998355263157895, \"p4\": 0.17283798617475524, \"phi\": 0.1487189868215147}, {\"truth_threshold\": 35.06, \"match_probability\": 0.9999999999720818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 639, \"tn\": 8049, \"fp\": 0, \"fn\": 11385, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0531437125748503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9468562874251497, \"precision\": 1.0, \"recall\": 0.0531437125748503, \"specificity\": 1.0, \"npv\": 0.41417104044458164, \"accuracy\": 0.43282020624719775, \"f1\": 0.10092395167022032, \"f2\": 0.06555863342566944, \"f0_5\": 0.2191358024691358, \"p4\": 0.1721810308283161, \"phi\": 0.148359653309832}, {\"truth_threshold\": 35.08, \"match_probability\": 0.9999999999724661, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 637, \"tn\": 8049, \"fp\": 0, \"fn\": 11387, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05297737857618097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.947022621423819, \"precision\": 1.0, \"recall\": 0.05297737857618097, \"specificity\": 1.0, \"npv\": 0.41412842148590245, \"accuracy\": 0.43272056991979274, \"f1\": 0.1006239633520259, \"f2\": 0.06535612418689594, \"f0_5\": 0.21856986000548997, \"p4\": 0.17174243516803991, \"phi\": 0.1481196751421461}, {\"truth_threshold\": 35.1, \"match_probability\": 0.9999999999728452, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 636, \"tn\": 8049, \"fp\": 0, \"fn\": 11388, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05289421157684631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9471057884231537, \"precision\": 1.0, \"recall\": 0.05289421157684631, \"specificity\": 1.0, \"npv\": 0.4141071152955703, \"accuracy\": 0.43267075175609027, \"f1\": 0.1004739336492891, \"f2\": 0.06525486333415415, \"f0_5\": 0.21828665568369027, \"p4\": 0.17152294934699897, \"phi\": 0.14799955868826564}, {\"truth_threshold\": 35.12, \"match_probability\": 0.999999999973219, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 632, \"tn\": 8049, \"fp\": 0, \"fn\": 11392, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05256154357950765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9474384564204924, \"precision\": 1.0, \"recall\": 0.05256154357950765, \"specificity\": 1.0, \"npv\": 0.41402191245306313, \"accuracy\": 0.4324714791012803, \"f1\": 0.09987357774968394, \"f2\": 0.064849778361517, \"f0_5\": 0.217152281473337, \"p4\": 0.17064374996477746, \"phi\": 0.14751823885293905}, {\"truth_threshold\": 35.14, \"match_probability\": 0.9999999999735877, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 625, \"tn\": 8049, \"fp\": 0, \"fn\": 11399, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.051979374584165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948020625415835, \"precision\": 1.0, \"recall\": 0.051979374584165, \"specificity\": 1.0, \"npv\": 0.4138728918140683, \"accuracy\": 0.4321227519553629, \"f1\": 0.09882204126808443, \"f2\": 0.06414071960756142, \"f0_5\": 0.21516111264114568, \"p4\": 0.1691002963375023, \"phi\": 0.1466726084646859}, {\"truth_threshold\": 35.160000000000004, \"match_probability\": 0.9999999999739514, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 624, \"tn\": 8049, \"fp\": 0, \"fn\": 11400, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05189620758483034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9481037924151696, \"precision\": 1.0, \"recall\": 0.05189620758483034, \"specificity\": 1.0, \"npv\": 0.41385161190806724, \"accuracy\": 0.43207293379166045, \"f1\": 0.09867172675521822, \"f2\": 0.06403940886699508, \"f0_5\": 0.21487603305785125, \"p4\": 0.1688792966227409, \"phi\": 0.14655145567648825}, {\"truth_threshold\": 35.18, \"match_probability\": 0.99999999997431, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 623, \"tn\": 8049, \"fp\": 0, \"fn\": 11401, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05181304058549568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9481869594145044, \"precision\": 1.0, \"recall\": 0.05181304058549568, \"specificity\": 1.0, \"npv\": 0.41383033419023135, \"accuracy\": 0.432023115627958, \"f1\": 0.09852138847157428, \"f2\": 0.06393809396744597, \"f0_5\": 0.21459079636263434, \"p4\": 0.1686581699551946, \"phi\": 0.1464302151227939}, {\"truth_threshold\": 35.2, \"match_probability\": 0.9999999999746636, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 622, \"tn\": 8049, \"fp\": 0, \"fn\": 11402, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05172987358616101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948270126413839, \"precision\": 1.0, \"recall\": 0.05172987358616101, \"specificity\": 1.0, \"npv\": 0.4138090586602231, \"accuracy\": 0.43197329746425545, \"f1\": 0.09837102641151352, \"f2\": 0.063836774908658, \"f0_5\": 0.21430540242557883, \"p4\": 0.1684369162118292, \"phi\": 0.1463088865834937}, {\"truth_threshold\": 35.24, \"match_probability\": 0.9999999999753565, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 619, \"tn\": 8049, \"fp\": 0, \"fn\": 11405, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05148037258815702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948519627411843, \"precision\": 1.0, \"recall\": 0.05148037258815702, \"specificity\": 1.0, \"npv\": 0.41374524519379047, \"accuracy\": 0.431823842973148, \"f1\": 0.09791979751641225, \"f2\": 0.06353279277429949, \"f0_5\": 0.21344827586206896, \"p4\": 0.16777239129411403, \"phi\": 0.14594437083750342}, {\"truth_threshold\": 35.26, \"match_probability\": 0.9999999999756958, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 612, \"tn\": 8049, \"fp\": 0, \"fn\": 11412, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05089820359281437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9491017964071856, \"precision\": 1.0, \"recall\": 0.05089820359281437, \"specificity\": 1.0, \"npv\": 0.4135964236164637, \"accuracy\": 0.4314751158272306, \"f1\": 0.09686609686609686, \"f2\": 0.06282335550628233, \"f0_5\": 0.21144278606965175, \"p4\": 0.1662173624277188, \"phi\": 0.14509071291606043}, {\"truth_threshold\": 35.28, \"match_probability\": 0.9999999999760304, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 608, \"tn\": 8049, \"fp\": 0, \"fn\": 11416, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05056553559547571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9494344644045243, \"precision\": 1.0, \"recall\": 0.05056553559547571, \"specificity\": 1.0, \"npv\": 0.41351143077318264, \"accuracy\": 0.4312758431724207, \"f1\": 0.09626345788473717, \"f2\": 0.06241787122207622, \"f0_5\": 0.21029330381848368, \"p4\": 0.1653259515683154, \"phi\": 0.14460092313639447}, {\"truth_threshold\": 35.300000000000004, \"match_probability\": 0.9999999999763604, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 606, \"tn\": 8049, \"fp\": 0, \"fn\": 11418, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05039920159680639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9496007984031936, \"precision\": 1.0, \"recall\": 0.05039920159680639, \"specificity\": 1.0, \"npv\": 0.41346894744953, \"accuracy\": 0.4311762068450157, \"f1\": 0.09596199524940617, \"f2\": 0.062215104102500925, \"f0_5\": 0.20971760797342193, \"p4\": 0.16487947299754324, \"phi\": 0.14435548079836874}, {\"truth_threshold\": 35.34, \"match_probability\": 0.9999999999770067, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 604, \"tn\": 8049, \"fp\": 0, \"fn\": 11420, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.05023286759813706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.949767132401863, \"precision\": 1.0, \"recall\": 0.05023286759813706, \"specificity\": 1.0, \"npv\": 0.4134264728542812, \"accuracy\": 0.4310765705176107, \"f1\": 0.09566043712385176, \"f2\": 0.06201232032854209, \"f0_5\": 0.20914127423822715, \"p4\": 0.16443247765982924, \"phi\": 0.14410967098863944}, {\"truth_threshold\": 35.36, \"match_probability\": 0.9999999999773234, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 598, \"tn\": 8049, \"fp\": 0, \"fn\": 11426, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04973386560212908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9502661343978709, \"precision\": 1.0, \"recall\": 0.04973386560212908, \"specificity\": 1.0, \"npv\": 0.41329910141206677, \"accuracy\": 0.4307776615353958, \"f1\": 0.09475518935192521, \"f2\": 0.0614038690598431, \"f0_5\": 0.20740843507214207, \"p4\": 0.16308838095299408, \"phi\": 0.14337001765748808}, {\"truth_threshold\": 35.38, \"match_probability\": 0.9999999999776356, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 594, \"tn\": 8049, \"fp\": 0, \"fn\": 11430, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04940119760479042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9505988023952096, \"precision\": 1.0, \"recall\": 0.04940119760479042, \"specificity\": 1.0, \"npv\": 0.41321423070999536, \"accuracy\": 0.43057838888058586, \"f1\": 0.09415121255349501, \"f2\": 0.06099815157116451, \"f0_5\": 0.20625, \"p4\": 0.16218971409938948, \"phi\": 0.1428750428325953}, {\"truth_threshold\": 35.4, \"match_probability\": 0.9999999999779434, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 590, \"tn\": 8049, \"fp\": 0, \"fn\": 11434, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04906852960745176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9509314703925482, \"precision\": 1.0, \"recall\": 0.04906852960745176, \"specificity\": 1.0, \"npv\": 0.41312939485705485, \"accuracy\": 0.4303791162257759, \"f1\": 0.09354685270334549, \"f2\": 0.06059236741568418, \"f0_5\": 0.2050889877641824, \"p4\": 0.16128895582916855, \"phi\": 0.14237855155623697}, {\"truth_threshold\": 35.42, \"match_probability\": 0.9999999999782471, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 587, \"tn\": 8049, \"fp\": 0, \"fn\": 11437, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04881902860944777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9511809713905522, \"precision\": 1.0, \"recall\": 0.04881902860944777, \"specificity\": 1.0, \"npv\": 0.4130657908241815, \"accuracy\": 0.4302296617346685, \"f1\": 0.09309333121877726, \"f2\": 0.06028798553909989, \"f0_5\": 0.20421653214583912, \"p4\": 0.16061200970342362, \"phi\": 0.14200517828526493}, {\"truth_threshold\": 35.46, \"match_probability\": 0.9999999999788419, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 586, \"tn\": 8049, \"fp\": 0, \"fn\": 11438, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.048735861610113104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9512641383898869, \"precision\": 1.0, \"recall\": 0.048735861610113104, \"specificity\": 1.0, \"npv\": 0.41304459383178527, \"accuracy\": 0.43017984357096595, \"f1\": 0.0929421094369548, \"f2\": 0.0601865165769689, \"f0_5\": 0.20392538975501115, \"p4\": 0.1603860979428173, \"phi\": 0.1418805277823256}, {\"truth_threshold\": 35.480000000000004, \"match_probability\": 0.9999999999791332, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 583, \"tn\": 8049, \"fp\": 0, \"fn\": 11441, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04848636061210911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9515136393878909, \"precision\": 1.0, \"recall\": 0.04848636061210911, \"specificity\": 1.0, \"npv\": 0.4129810159055926, \"accuracy\": 0.4300303890798585, \"f1\": 0.09248830015070993, \"f2\": 0.059882084677170856, \"f0_5\": 0.20305098913346337, \"p4\": 0.15970757169848662, \"phi\": 0.14150599444247489}, {\"truth_threshold\": 35.5, \"match_probability\": 0.9999999999794205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 582, \"tn\": 8049, \"fp\": 0, \"fn\": 11442, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04840319361277445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9515968063872255, \"precision\": 1.0, \"recall\": 0.04840319361277445, \"specificity\": 1.0, \"npv\": 0.41295982761274436, \"accuracy\": 0.42998057091615605, \"f1\": 0.0923369823893384, \"f2\": 0.05978059903858006, \"f0_5\": 0.20275919732441472, \"p4\": 0.15948113219832022, \"phi\": 0.14138095518929567}, {\"truth_threshold\": 35.52, \"match_probability\": 0.9999999999797038, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 581, \"tn\": 8049, \"fp\": 0, \"fn\": 11443, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04832002661343979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9516799733865602, \"precision\": 1.0, \"recall\": 0.04832002661343979, \"specificity\": 1.0, \"npv\": 0.4129386414939462, \"accuracy\": 0.42993075275245357, \"f1\": 0.09218564061880206, \"f2\": 0.05967910923023194, \"f0_5\": 0.20246724282129913, \"p4\": 0.1592545604394304, \"phi\": 0.14125581809860135}, {\"truth_threshold\": 35.56, \"match_probability\": 0.9999999999802588, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 577, \"tn\": 8049, \"fp\": 0, \"fn\": 11447, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04798735861610113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9520126413838988, \"precision\": 1.0, \"recall\": 0.04798735861610113, \"specificity\": 1.0, \"npv\": 0.4128539187525646, \"accuracy\": 0.4297314800976436, \"f1\": 0.09158003333068804, \"f2\": 0.05927310829412611, \"f0_5\": 0.2012977951437343, \"p4\": 0.15834694821672146, \"phi\": 0.14075428609901014}, {\"truth_threshold\": 35.58, \"match_probability\": 0.9999999999805306, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 570, \"tn\": 8049, \"fp\": 0, \"fn\": 11454, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04740518962075848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9525948103792415, \"precision\": 1.0, \"recall\": 0.04740518962075848, \"specificity\": 1.0, \"npv\": 0.41270573757883405, \"accuracy\": 0.4293827529517262, \"f1\": 0.09051929490233444, \"f2\": 0.058562446060904945, \"f0_5\": 0.19924496644295303, \"p4\": 0.15675350475246602, \"phi\": 0.1398727770064626}, {\"truth_threshold\": 35.6, \"match_probability\": 0.9999999999807986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 566, \"tn\": 8049, \"fp\": 0, \"fn\": 11458, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04707252162341983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9529274783765802, \"precision\": 1.0, \"recall\": 0.04707252162341983, \"specificity\": 1.0, \"npv\": 0.4126211103706362, \"accuracy\": 0.4291834802969163, \"f1\": 0.08991262907069103, \"f2\": 0.058156261559327606, \"f0_5\": 0.1980683090705487, \"p4\": 0.15584002429549637, \"phi\": 0.13936684017441622}, {\"truth_threshold\": 35.62, \"match_probability\": 0.999999999981063, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 562, \"tn\": 8049, \"fp\": 0, \"fn\": 11462, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04673985362608117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9532601463739189, \"precision\": 1.0, \"recall\": 0.04673985362608117, \"specificity\": 1.0, \"npv\": 0.412536517861719, \"accuracy\": 0.4289842076421063, \"f1\": 0.08930557762593358, \"f2\": 0.05775001027580254, \"f0_5\": 0.1968890134529148, \"p4\": 0.15492439412304634, \"phi\": 0.1388592685429027}, {\"truth_threshold\": 35.64, \"match_probability\": 0.9999999999813237, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 560, \"tn\": 8049, \"fp\": 0, \"fn\": 11464, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.046573519627411845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9534264803725881, \"precision\": 1.0, \"recall\": 0.046573519627411845, \"specificity\": 1.0, \"npv\": 0.4124942346128222, \"accuracy\": 0.4288845713147013, \"f1\": 0.08900190718372536, \"f2\": 0.057546859585662614, \"f0_5\": 0.1962983735277622, \"p4\": 0.15446577023809532, \"phi\": 0.13860486402696875}, {\"truth_threshold\": 35.660000000000004, \"match_probability\": 0.9999999999815808, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 557, \"tn\": 8049, \"fp\": 0, \"fn\": 11467, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.046324018629407854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9536759813705922, \"precision\": 1.0, \"recall\": 0.046324018629407854, \"specificity\": 1.0, \"npv\": 0.41243082598893216, \"accuracy\": 0.4287351168235939, \"f1\": 0.08854622049121691, \"f2\": 0.05724210223418905, \"f0_5\": 0.19541117036205444, \"p4\": 0.15377682041222837, \"phi\": 0.13822247742843188}, {\"truth_threshold\": 35.68, \"match_probability\": 0.9999999999818344, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 556, \"tn\": 8049, \"fp\": 0, \"fn\": 11468, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04624085163007319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9537591483699268, \"precision\": 1.0, \"recall\": 0.04624085163007319, \"specificity\": 1.0, \"npv\": 0.41240969411282474, \"accuracy\": 0.4286852986598914, \"f1\": 0.08839427662957075, \"f2\": 0.057140508098331, \"f0_5\": 0.19511510387422795, \"p4\": 0.15354689953560685, \"phi\": 0.13809480611621494}, {\"truth_threshold\": 35.7, \"match_probability\": 0.9999999999820844, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 555, \"tn\": 8049, \"fp\": 0, \"fn\": 11469, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04615768463073852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9538423153692615, \"precision\": 1.0, \"recall\": 0.04615768463073852, \"specificity\": 1.0, \"npv\": 0.4123885644020904, \"accuracy\": 0.42863548049618894, \"f1\": 0.08824230860958741, \"f2\": 0.057038909786027006, \"f0_5\": 0.1948188711036226, \"p4\": 0.1533168429681916, \"phi\": 0.13796702976071742}, {\"truth_threshold\": 35.72, \"match_probability\": 0.9999999999823311, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 554, \"tn\": 8049, \"fp\": 0, \"fn\": 11470, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04607451763140386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9539254823685961, \"precision\": 1.0, \"recall\": 0.04607451763140386, \"specificity\": 1.0, \"npv\": 0.4123674368563963, \"accuracy\": 0.4285856623324864, \"f1\": 0.08809031642550486, \"f2\": 0.05693730729701953, \"f0_5\": 0.19452247191011235, \"p4\": 0.15308665057564308, \"phi\": 0.13783914806779984}, {\"truth_threshold\": 35.76, \"match_probability\": 0.9999999999828143, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 551, \"tn\": 8049, \"fp\": 0, \"fn\": 11473, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.045825016633399863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9541749833666001, \"precision\": 1.0, \"recall\": 0.045825016633399863, \"specificity\": 1.0, \"npv\": 0.41230406720622886, \"accuracy\": 0.428436207841379, \"f1\": 0.08763419483101392, \"f2\": 0.056632474767200444, \"f0_5\": 0.19363227438852965, \"p4\": 0.15239525710116528, \"phi\": 0.13745486800307893}, {\"truth_threshold\": 35.78, \"match_probability\": 0.9999999999830509, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 545, \"tn\": 8049, \"fp\": 0, \"fn\": 11479, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04532601463739188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9546739853626082, \"precision\": 1.0, \"recall\": 0.04532601463739188, \"specificity\": 1.0, \"npv\": 0.41217738631708317, \"accuracy\": 0.4281372988591641, \"f1\": 0.08672129843265176, \"f2\": 0.056022696901790674, \"f0_5\": 0.19184736693889046, \"p4\": 0.1510087846584723, \"phi\": 0.13668342344779794}, {\"truth_threshold\": 35.800000000000004, \"match_probability\": 0.9999999999832843, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 543, \"tn\": 8049, \"fp\": 0, \"fn\": 11481, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.045159680638722555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9548403193612774, \"precision\": 1.0, \"recall\": 0.045159680638722555, \"specificity\": 1.0, \"npv\": 0.41213517665130567, \"accuracy\": 0.42803766253175907, \"f1\": 0.08641680592026736, \"f2\": 0.055819404181829395, \"f0_5\": 0.19125105663567202, \"p4\": 0.15054553120122266, \"phi\": 0.13642541170015385}, {\"truth_threshold\": 35.82, \"match_probability\": 0.9999999999835144, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 540, \"tn\": 8049, \"fp\": 0, \"fn\": 11484, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04491017964071856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9550898203592815, \"precision\": 1.0, \"recall\": 0.04491017964071856, \"specificity\": 1.0, \"npv\": 0.412071878359699, \"accuracy\": 0.42788820804065164, \"f1\": 0.08595988538681948, \"f2\": 0.05551443375277572, \"f0_5\": 0.19035532994923857, \"p4\": 0.14984961979079883, \"phi\": 0.13603757599289398}, {\"truth_threshold\": 35.84, \"match_probability\": 0.9999999999837413, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 538, \"tn\": 8049, \"fp\": 0, \"fn\": 11486, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04474384564204924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9552561543579507, \"precision\": 1.0, \"recall\": 0.04474384564204924, \"specificity\": 1.0, \"npv\": 0.4120296902994625, \"accuracy\": 0.42778857171324663, \"f1\": 0.0856551504537494, \"f2\": 0.05531109923099067, \"f0_5\": 0.18975733634311512, \"p4\": 0.14938498977117462, \"phi\": 0.13577846980541688}, {\"truth_threshold\": 35.86, \"match_probability\": 0.9999999999839652, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 537, \"tn\": 8049, \"fp\": 0, \"fn\": 11487, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04466067864271457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9553393213572854, \"precision\": 1.0, \"recall\": 0.04466067864271457, \"specificity\": 1.0, \"npv\": 0.4120085995085995, \"accuracy\": 0.42773875354954416, \"f1\": 0.08550274659660854, \"f2\": 0.05520942569859972, \"f0_5\": 0.18945808636748518, \"p4\": 0.14915246762600093, \"phi\": 0.13564875104728555}, {\"truth_threshold\": 35.88, \"match_probability\": 0.9999999999841859, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 535, \"tn\": 8049, \"fp\": 0, \"fn\": 11489, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.044494344644045246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9555056553559548, \"precision\": 1.0, \"recall\": 0.044494344644045246, \"specificity\": 1.0, \"npv\": 0.41196642440372605, \"accuracy\": 0.4276391172221392, \"f1\": 0.0851978660721395, \"f2\": 0.05500606608953137, \"f0_5\": 0.1888590793561141, \"p4\": 0.1486870083771934, \"phi\": 0.1353889806047538}, {\"truth_threshold\": 35.9, \"match_probability\": 0.9999999999844037, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 533, \"tn\": 8049, \"fp\": 0, \"fn\": 11491, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04432801064537591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.955671989354624, \"precision\": 1.0, \"recall\": 0.04432801064537591, \"specificity\": 1.0, \"npv\": 0.41192425793244625, \"accuracy\": 0.4275394808947342, \"f1\": 0.08489288842876483, \"f2\": 0.05480268975302803, \"f0_5\": 0.18825939530940944, \"p4\": 0.148220994931343, \"phi\": 0.13512876411304164}, {\"truth_threshold\": 35.980000000000004, \"match_probability\": 0.9999999999852449, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 532, \"tn\": 8049, \"fp\": 0, \"fn\": 11492, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.044244843646041254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9557551563539588, \"precision\": 1.0, \"recall\": 0.044244843646041254, \"specificity\": 1.0, \"npv\": 0.41190317793357556, \"accuracy\": 0.4274896627310317, \"f1\": 0.08474036317298503, \"f2\": 0.05470099531134326, \"f0_5\": 0.1879592990390051, \"p4\": 0.1479877800391847, \"phi\": 0.1349984877877473}, {\"truth_threshold\": 36.0, \"match_probability\": 0.9999999999854481, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 529, \"tn\": 8049, \"fp\": 0, \"fn\": 11495, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.043995342648037256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9560046573519627, \"precision\": 1.0, \"recall\": 0.043995342648037256, \"specificity\": 1.0, \"npv\": 0.4118399508800655, \"accuracy\": 0.4273402082399243, \"f1\": 0.08428264159961762, \"f2\": 0.054395886889460156, \"f0_5\": 0.18705799151343705, \"p4\": 0.14728730102376433, \"phi\": 0.1346069825644989}, {\"truth_threshold\": 36.02, \"match_probability\": 0.9999999999856485, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 523, \"tn\": 8049, \"fp\": 0, \"fn\": 11501, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04349634065202927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9565036593479708, \"precision\": 1.0, \"recall\": 0.04349634065202927, \"specificity\": 1.0, \"npv\": 0.4117135549872123, \"accuracy\": 0.42704129925770934, \"f1\": 0.0833665418028214, \"f2\": 0.05378555708673564, \"f0_5\": 0.18525077925758004, \"p4\": 0.14588257595316373, \"phi\": 0.1338208991106463}, {\"truth_threshold\": 36.04, \"match_probability\": 0.999999999985846, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 521, \"tn\": 8049, \"fp\": 0, \"fn\": 11503, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04333000665335995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.95666999334664, \"precision\": 1.0, \"recall\": 0.04333000665335995, \"specificity\": 1.0, \"npv\": 0.4116714402618658, \"accuracy\": 0.4269416629303044, \"f1\": 0.0830609804703069, \"f2\": 0.05358208034226711, \"f0_5\": 0.18464700878933937, \"p4\": 0.14541321400805546, \"phi\": 0.13355795088853722}, {\"truth_threshold\": 36.06, \"match_probability\": 0.9999999999860408, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 520, \"tn\": 8049, \"fp\": 0, \"fn\": 11504, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04324683965402528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9567531603459747, \"precision\": 1.0, \"recall\": 0.04324683965402528, \"specificity\": 1.0, \"npv\": 0.41165038613000565, \"accuracy\": 0.4268918447666019, \"f1\": 0.08290816326530612, \"f2\": 0.05348033569195327, \"f0_5\": 0.184344866704481, \"p4\": 0.14517832235700656, \"phi\": 0.13342630266361255}, {\"truth_threshold\": 36.08, \"match_probability\": 0.999999999986233, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 516, \"tn\": 8049, \"fp\": 0, \"fn\": 11508, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04291417165668663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9570858283433133, \"precision\": 1.0, \"recall\": 0.04291417165668663, \"specificity\": 1.0, \"npv\": 0.4115661911336094, \"accuracy\": 0.42669257211179196, \"f1\": 0.08229665071770335, \"f2\": 0.05307331523080721, \"f0_5\": 0.18313458262350937, \"p4\": 0.1442373479451438, \"phi\": 0.13289854090394074}, {\"truth_threshold\": 36.1, \"match_probability\": 0.9999999999864225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 514, \"tn\": 8049, \"fp\": 0, \"fn\": 11510, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0427478376580173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9572521623419827, \"precision\": 1.0, \"recall\": 0.0427478376580173, \"specificity\": 1.0, \"npv\": 0.41152410654941457, \"accuracy\": 0.426592935784387, \"f1\": 0.08199074812569788, \"f2\": 0.05286977988068299, \"f0_5\": 0.1825284090909091, \"p4\": 0.1437660140781153, \"phi\": 0.13263395379439982}, {\"truth_threshold\": 36.12, \"match_probability\": 0.9999999999866095, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 509, \"tn\": 8049, \"fp\": 0, \"fn\": 11515, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04233200266134398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.957667997338656, \"precision\": 1.0, \"recall\": 0.04233200266134398, \"specificity\": 1.0, \"npv\": 0.4114189327335923, \"accuracy\": 0.4263438449658746, \"f1\": 0.08122556450969441, \"f2\": 0.052360868223433804, \"f0_5\": 0.1810099573257468, \"p4\": 0.14258520088732637, \"phi\": 0.1319704033312232}, {\"truth_threshold\": 36.160000000000004, \"match_probability\": 0.9999999999869756, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 508, \"tn\": 8049, \"fp\": 0, \"fn\": 11516, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.042248835662009314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9577511643379907, \"precision\": 1.0, \"recall\": 0.042248835662009314, \"specificity\": 1.0, \"npv\": 0.41139790442116025, \"accuracy\": 0.4262940268021721, \"f1\": 0.08107245451643792, \"f2\": 0.052259073327298164, \"f0_5\": 0.1807057484348321, \"p4\": 0.14234861222103296, \"phi\": 0.13183733331490216}, {\"truth_threshold\": 36.18, \"match_probability\": 0.9999999999871549, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 507, \"tn\": 8049, \"fp\": 0, \"fn\": 11517, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04216566866267465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9578343313373253, \"precision\": 1.0, \"recall\": 0.04216566866267465, \"specificity\": 1.0, \"npv\": 0.411376878258203, \"accuracy\": 0.42624420863846957, \"f1\": 0.08091932008618626, \"f2\": 0.05215727424233072, \"f0_5\": 0.18040136635354398, \"p4\": 0.14211188121232332, \"phi\": 0.13170414247137724}, {\"truth_threshold\": 36.22, \"match_probability\": 0.9999999999875062, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 506, \"tn\": 8049, \"fp\": 0, \"fn\": 11518, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04208250166333999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9579174983366601, \"precision\": 1.0, \"recall\": 0.04208250166333999, \"specificity\": 1.0, \"npv\": 0.4113558542443911, \"accuracy\": 0.4261943904747671, \"f1\": 0.08076616121308859, \"f2\": 0.05205547096827291, \"f0_5\": 0.18009681093394078, \"p4\": 0.14187500771808773, \"phi\": 0.13157083043161288}, {\"truth_threshold\": 36.24, \"match_probability\": 0.9999999999876782, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 504, \"tn\": 8049, \"fp\": 0, \"fn\": 11520, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.041916167664670656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9580838323353293, \"precision\": 1.0, \"recall\": 0.041916167664670656, \"specificity\": 1.0, \"npv\": 0.4113138126628852, \"accuracy\": 0.42609475414736214, \"f1\": 0.08045977011494253, \"f2\": 0.05185185185185185, \"f0_5\": 0.1794871794871795, \"p4\": 0.1414008326996484, \"phi\": 0.13130384127805414}, {\"truth_threshold\": 36.28, \"match_probability\": 0.9999999999880151, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 501, \"tn\": 8049, \"fp\": 0, \"fn\": 11523, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.041666666666666664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9583333333333334, \"precision\": 1.0, \"recall\": 0.041666666666666664, \"specificity\": 1.0, \"npv\": 0.411250766400981, \"accuracy\": 0.42594529965625466, \"f1\": 0.08, \"f2\": 0.05154639175257732, \"f0_5\": 0.17857142857142858, \"p4\": 0.14068849794184735, \"phi\": 0.13090243924404493}, {\"truth_threshold\": 36.300000000000004, \"match_probability\": 0.9999999999881801, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 499, \"tn\": 8049, \"fp\": 0, \"fn\": 11525, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04150033266799734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9584996673320026, \"precision\": 1.0, \"recall\": 0.04150033266799734, \"specificity\": 1.0, \"npv\": 0.4112087462961071, \"accuracy\": 0.4258456633288497, \"f1\": 0.07969336420985387, \"f2\": 0.05134273073361457, \"f0_5\": 0.17796005706134094, \"p4\": 0.14021289160247016, \"phi\": 0.13063422127175775}, {\"truth_threshold\": 36.32, \"match_probability\": 0.9999999999883429, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 498, \"tn\": 8049, \"fp\": 0, \"fn\": 11526, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04141716566866267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9585828343313373, \"precision\": 1.0, \"recall\": 0.04141716566866267, \"specificity\": 1.0, \"npv\": 0.41118773946360154, \"accuracy\": 0.42579584516514724, \"f1\": 0.07954000958313369, \"f2\": 0.05124089393752315, \"f0_5\": 0.1776541095890411, \"p4\": 0.13997487304918454, \"phi\": 0.130499926154335}, {\"truth_threshold\": 36.36, \"match_probability\": 0.9999999999886616, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 496, \"tn\": 8049, \"fp\": 0, \"fn\": 11528, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04125083166999335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9587491683300067, \"precision\": 1.0, \"recall\": 0.04125083166999335, \"specificity\": 1.0, \"npv\": 0.4111457322368085, \"accuracy\": 0.42569620883774223, \"f1\": 0.0792332268370607, \"f2\": 0.05103720777082647, \"f0_5\": 0.1770416904625928, \"p4\": 0.1394984044512536, \"phi\": 0.13023096172699006}, {\"truth_threshold\": 36.38, \"match_probability\": 0.9999999999888177, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 494, \"tn\": 8049, \"fp\": 0, \"fn\": 11530, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04108449767132402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.958915502328676, \"precision\": 1.0, \"recall\": 0.04108449767132402, \"specificity\": 1.0, \"npv\": 0.411103733592114, \"accuracy\": 0.4255965725103373, \"f1\": 0.07892634606167119, \"f2\": 0.05083350483638609, \"f0_5\": 0.17642857142857143, \"p4\": 0.13902135956370112, \"phi\": 0.12996149578024183}, {\"truth_threshold\": 36.4, \"match_probability\": 0.9999999999889717, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 491, \"tn\": 8049, \"fp\": 0, \"fn\": 11533, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04083499667332003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.95916500332668, \"precision\": 1.0, \"recall\": 0.04083499667332003, \"specificity\": 1.0, \"npv\": 0.41104075171075477, \"accuracy\": 0.4254471180192298, \"f1\": 0.07846584099081103, \"f2\": 0.05052791899067652, \"f0_5\": 0.1755075779239348, \"p4\": 0.13830470914204976, \"phi\": 0.1295563496271319}, {\"truth_threshold\": 36.42, \"match_probability\": 0.9999999999891236, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 490, \"tn\": 8049, \"fp\": 0, \"fn\": 11534, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.040751829673985364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9592481703260146, \"precision\": 1.0, \"recall\": 0.040751829673985364, \"specificity\": 1.0, \"npv\": 0.41101976203850277, \"accuracy\": 0.4253972998555273, \"f1\": 0.07831229023493687, \"f2\": 0.050426048655991436, \"f0_5\": 0.17520022883295194, \"p4\": 0.13806553626028845, \"phi\": 0.1294210467243835}, {\"truth_threshold\": 36.44, \"match_probability\": 0.9999999999892732, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 489, \"tn\": 8049, \"fp\": 0, \"fn\": 11535, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0406686626746507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9593313373253493, \"precision\": 1.0, \"recall\": 0.0406686626746507, \"specificity\": 1.0, \"npv\": 0.41099877450980393, \"accuracy\": 0.42534748169182485, \"f1\": 0.07815871493646608, \"f2\": 0.05032417412781723, \"f0_5\": 0.17489270386266095, \"p4\": 0.13782621843077308, \"phi\": 0.12928561606085204}, {\"truth_threshold\": 36.480000000000004, \"match_probability\": 0.9999999999895666, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 484, \"tn\": 8049, \"fp\": 0, \"fn\": 11540, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04025282767797738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9597471723220227, \"precision\": 1.0, \"recall\": 0.04025282767797738, \"specificity\": 1.0, \"npv\": 0.4108938690081168, \"accuracy\": 0.4250983908733124, \"f1\": 0.07739047009913655, \"f2\": 0.04981473857554549, \"f0_5\": 0.17335243553008595, \"p4\": 0.13662744992963138, \"phi\": 0.1286065321168452}, {\"truth_threshold\": 36.5, \"match_probability\": 0.9999999999897102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 481, \"tn\": 8049, \"fp\": 0, \"fn\": 11543, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.04000332667997339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9599966733200266, \"precision\": 1.0, \"recall\": 0.04000332667997339, \"specificity\": 1.0, \"npv\": 0.41083095140873827, \"accuracy\": 0.42494893638220493, \"f1\": 0.07692922830867653, \"f2\": 0.04950902690573728, \"f0_5\": 0.17242615428735303, \"p4\": 0.13590644004436198, \"phi\": 0.12819752243880544}, {\"truth_threshold\": 36.52, \"match_probability\": 0.9999999999898519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 479, \"tn\": 8049, \"fp\": 0, \"fn\": 11545, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.039836992681304056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.960163007318696, \"precision\": 1.0, \"recall\": 0.039836992681304056, \"specificity\": 1.0, \"npv\": 0.4107890170460345, \"accuracy\": 0.4248493000548, \"f1\": 0.07662161081340478, \"f2\": 0.049305198147195056, \"f0_5\": 0.1718077474892396, \"p4\": 0.13542503566371641, \"phi\": 0.12792419265183175}, {\"truth_threshold\": 36.54, \"match_probability\": 0.9999999999899916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 478, \"tn\": 8049, \"fp\": 0, \"fn\": 11546, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0397538256819694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9602461743180306, \"precision\": 1.0, \"recall\": 0.0397538256819694, \"specificity\": 1.0, \"npv\": 0.410768053074764, \"accuracy\": 0.4247994818910975, \"f1\": 0.0764677651575748, \"f2\": 0.04920327747354552, \"f0_5\": 0.17149827784156144, \"p4\": 0.13518411369117825, \"phi\": 0.1277873294879274}, {\"truth_threshold\": 36.56, \"match_probability\": 0.9999999999901295, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 476, \"tn\": 8049, \"fp\": 0, \"fn\": 11548, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.039587491683300065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9604125083166999, \"precision\": 1.0, \"recall\": 0.039587491683300065, \"specificity\": 1.0, \"npv\": 0.41072613155074755, \"accuracy\": 0.4246998455636925, \"f1\": 0.07616, \"f2\": 0.048999423536193694, \"f0_5\": 0.17087880528431937, \"p4\": 0.13470182943788733, \"phi\": 0.1275132044804742}, {\"truth_threshold\": 36.58, \"match_probability\": 0.9999999999902653, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 474, \"tn\": 8049, \"fp\": 0, \"fn\": 11550, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03942115768463074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9605788423153693, \"precision\": 1.0, \"recall\": 0.03942115768463074, \"specificity\": 1.0, \"npv\": 0.41068421858258075, \"accuracy\": 0.42460020923628755, \"f1\": 0.07585213634181469, \"f2\": 0.04879555281037678, \"f0_5\": 0.17025862068965517, \"p4\": 0.13421895711293444, \"phi\": 0.12723854502206974}, {\"truth_threshold\": 36.6, \"match_probability\": 0.9999999999903993, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 472, \"tn\": 8049, \"fp\": 0, \"fn\": 11552, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.039254823685961414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9607451763140386, \"precision\": 1.0, \"recall\": 0.039254823685961414, \"specificity\": 1.0, \"npv\": 0.4106423141676445, \"accuracy\": 0.4245005729088826, \"f1\": 0.07554417413572344, \"f2\": 0.04859166529402075, \"f0_5\": 0.1696377228292122, \"p4\": 0.13373549552066308, \"phi\": 0.12696334762696698}, {\"truth_threshold\": 36.62, \"match_probability\": 0.9999999999905315, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 471, \"tn\": 8049, \"fp\": 0, \"fn\": 11553, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03917165668662675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9608283433133733, \"precision\": 1.0, \"recall\": 0.03917165668662675, \"specificity\": 1.0, \"npv\": 0.4106213651668197, \"accuracy\": 0.42445075474518007, \"f1\": 0.07539015606242497, \"f2\": 0.048489715238742355, \"f0_5\": 0.1693270060396894, \"p4\": 0.13349354337476124, \"phi\": 0.1268255461037273}, {\"truth_threshold\": 36.64, \"match_probability\": 0.9999999999906618, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 468, \"tn\": 8049, \"fp\": 0, \"fn\": 11556, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.038922155688622756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9610778443113772, \"precision\": 1.0, \"recall\": 0.038922155688622756, \"specificity\": 1.0, \"npv\": 0.41055853098699313, \"accuracy\": 0.42430130025407264, \"f1\": 0.07492795389048991, \"f2\": 0.048183839881393624, \"f0_5\": 0.16839378238341968, \"p4\": 0.13276679973544847, \"phi\": 0.12641132489760556}, {\"truth_threshold\": 36.660000000000004, \"match_probability\": 0.9999999999907904, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 467, \"tn\": 8049, \"fp\": 0, \"fn\": 11557, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03883898868928809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9611610113107119, \"precision\": 1.0, \"recall\": 0.03883898868928809, \"specificity\": 1.0, \"npv\": 0.41053759053351013, \"accuracy\": 0.42425148209037017, \"f1\": 0.07477383716275718, \"f2\": 0.04808187303090831, \"f0_5\": 0.16808234955369997, \"p4\": 0.13252425561992257, \"phi\": 0.1262729774546343}, {\"truth_threshold\": 36.68, \"match_probability\": 0.9999999999909172, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 465, \"tn\": 8049, \"fp\": 0, \"fn\": 11559, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.038672654690618764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9613273453093812, \"precision\": 1.0, \"recall\": 0.038672654690618764, \"specificity\": 1.0, \"npv\": 0.4104957160342717, \"accuracy\": 0.42415184576296516, \"f1\": 0.07446552966610617, \"f2\": 0.04787792673132761, \"f0_5\": 0.1674589455488332, \"p4\": 0.13203872212971396, \"phi\": 0.12599586929011478}, {\"truth_threshold\": 36.7, \"match_probability\": 0.9999999999910423, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 464, \"tn\": 8049, \"fp\": 0, \"fn\": 11560, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0385894876912841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9614105123087159, \"precision\": 1.0, \"recall\": 0.0385894876912841, \"specificity\": 1.0, \"npv\": 0.4104747819878627, \"accuracy\": 0.4241020275992627, \"f1\": 0.07431133888532991, \"f2\": 0.047775947281713346, \"f0_5\": 0.16714697406340057, \"p4\": 0.13179573245247803, \"phi\": 0.12585710765428845}, {\"truth_threshold\": 36.76, \"match_probability\": 0.9999999999914071, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 462, \"tn\": 8049, \"fp\": 0, \"fn\": 11562, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03842315369261477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9615768463073853, \"precision\": 1.0, \"recall\": 0.03842315369261477, \"specificity\": 1.0, \"npv\": 0.41043292029983175, \"accuracy\": 0.42400239127185774, \"f1\": 0.07400288322921672, \"f2\": 0.0475719757815396, \"f0_5\": 0.16652249134948097, \"p4\": 0.13130930647582978, \"phi\": 0.1255791669712343}, {\"truth_threshold\": 36.800000000000004, \"match_probability\": 0.9999999999916421, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 461, \"tn\": 8049, \"fp\": 0, \"fn\": 11563, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.038339986693280106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9616600133067199, \"precision\": 1.0, \"recall\": 0.038339986693280106, \"specificity\": 1.0, \"npv\": 0.4104119926575566, \"accuracy\": 0.4239525731081552, \"f1\": 0.07384861834201041, \"f2\": 0.04746998373046111, \"f0_5\": 0.1662099798096337, \"p4\": 0.13106586987263885, \"phi\": 0.12543998699479084}, {\"truth_threshold\": 36.82, \"match_probability\": 0.9999999999917571, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 458, \"tn\": 8049, \"fp\": 0, \"fn\": 11566, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.038090485695276115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9619095143047239, \"precision\": 1.0, \"recall\": 0.038090485695276115, \"specificity\": 1.0, \"npv\": 0.41034922253377515, \"accuracy\": 0.4238031186170478, \"f1\": 0.07338567537253646, \"f2\": 0.04716398237014458, \"f0_5\": 0.16527136258660508, \"p4\": 0.13033466377661987, \"phi\": 0.12502160289722108}, {\"truth_threshold\": 36.86, \"match_probability\": 0.9999999999919826, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 456, \"tn\": 8049, \"fp\": 0, \"fn\": 11568, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03792415169660679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9620758483033932, \"precision\": 1.0, \"recall\": 0.03792415169660679, \"specificity\": 1.0, \"npv\": 0.4103073864505276, \"accuracy\": 0.42370348228964283, \"f1\": 0.07307692307692308, \"f2\": 0.04695996045477014, \"f0_5\": 0.16464471403812825, \"p4\": 0.12984644461397193, \"phi\": 0.12474197195005406}, {\"truth_threshold\": 36.88, \"match_probability\": 0.999999999992093, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 449, \"tn\": 8049, \"fp\": 0, \"fn\": 11575, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03734198270126414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9626580172987359, \"precision\": 1.0, \"recall\": 0.03734198270126414, \"specificity\": 1.0, \"npv\": 0.4101610273134937, \"accuracy\": 0.4233547551437254, \"f1\": 0.07199551030225286, \"f2\": 0.04624575136471315, \"f0_5\": 0.16244573082489147, \"p4\": 0.12813294310351128, \"phi\": 0.12375874105158476}, {\"truth_threshold\": 36.9, \"match_probability\": 0.9999999999922018, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 445, \"tn\": 8049, \"fp\": 0, \"fn\": 11579, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03700931470392548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629906852960746, \"precision\": 1.0, \"recall\": 0.03700931470392548, \"specificity\": 1.0, \"npv\": 0.41007744039127775, \"accuracy\": 0.42315548248891544, \"f1\": 0.07137701499719304, \"f2\": 0.04583753939968274, \"f0_5\": 0.1611851637206607, \"p4\": 0.12715047809247854, \"phi\": 0.12319368914202157}, {\"truth_threshold\": 36.94, \"match_probability\": 0.9999999999924151, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 444, \"tn\": 8049, \"fp\": 0, \"fn\": 11580, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.036926147704590816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9630738522954092, \"precision\": 1.0, \"recall\": 0.036926147704590816, \"specificity\": 1.0, \"npv\": 0.41005654898364663, \"accuracy\": 0.42310566432521296, \"f1\": 0.0712223291626564, \"f2\": 0.04573547589616811, \"f0_5\": 0.1608695652173913, \"p4\": 0.1269044828713592, \"phi\": 0.12305205684995646}, {\"truth_threshold\": 36.96, \"match_probability\": 0.9999999999925195, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 437, \"tn\": 8049, \"fp\": 0, \"fn\": 11587, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03634397870924817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9636560212907518, \"precision\": 1.0, \"recall\": 0.03634397870924817, \"specificity\": 1.0, \"npv\": 0.40991036871053166, \"accuracy\": 0.4227569371792956, \"f1\": 0.07013883315945751, \"f2\": 0.04502091360517586, \"f0_5\": 0.15865524252105723, \"p4\": 0.1251782544175093, \"phi\": 0.12205643659027421}, {\"truth_threshold\": 36.980000000000004, \"match_probability\": 0.9999999999926225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 436, \"tn\": 8049, \"fp\": 0, \"fn\": 11588, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03626081170991351, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9637391882900865, \"precision\": 1.0, \"recall\": 0.03626081170991351, \"specificity\": 1.0, \"npv\": 0.40988949432194327, \"accuracy\": 0.4227071190155931, \"f1\": 0.06998394863563404, \"f2\": 0.0449188164510014, \"f0_5\": 0.15833817547937246, \"p4\": 0.12493103962993206, \"phi\": 0.12191359963301734}, {\"truth_threshold\": 37.0, \"match_probability\": 0.999999999992724, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 434, \"tn\": 8049, \"fp\": 0, \"fn\": 11590, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03609447771124418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9639055222887558, \"precision\": 1.0, \"recall\": 0.03609447771124418, \"specificity\": 1.0, \"npv\": 0.40984775192219564, \"accuracy\": 0.4226074826881881, \"f1\": 0.06967410499277572, \"f2\": 0.04471460951988461, \"f0_5\": 0.15770348837209303, \"p4\": 0.12443615044100494, \"phi\": 0.12162746625149776}, {\"truth_threshold\": 37.02, \"match_probability\": 0.9999999999928242, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 431, \"tn\": 8049, \"fp\": 0, \"fn\": 11593, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03584497671324019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9641550232867598, \"precision\": 1.0, \"recall\": 0.03584497671324019, \"specificity\": 1.0, \"npv\": 0.4097851542612769, \"accuracy\": 0.42245802819708067, \"f1\": 0.06920915295062224, \"f2\": 0.04440826756238795, \"f0_5\": 0.15675007273785277, \"p4\": 0.1236926652551663, \"phi\": 0.12119710933816452}, {\"truth_threshold\": 37.04, \"match_probability\": 0.999999999992923, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 429, \"tn\": 8049, \"fp\": 0, \"fn\": 11595, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03567864271457086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9643213572854291, \"precision\": 1.0, \"recall\": 0.03567864271457086, \"specificity\": 1.0, \"npv\": 0.40974343310934636, \"accuracy\": 0.42235839186967566, \"f1\": 0.06889906046735726, \"f2\": 0.04420401854714065, \"f0_5\": 0.15611353711790393, \"p4\": 0.12319623901616146, \"phi\": 0.12090942707063843}, {\"truth_threshold\": 37.06, \"match_probability\": 0.9999999999930205, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 426, \"tn\": 8049, \"fp\": 0, \"fn\": 11598, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.035429141716566866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9645708582834331, \"precision\": 1.0, \"recall\": 0.035429141716566866, \"specificity\": 1.0, \"npv\": 0.409680867307986, \"accuracy\": 0.42220893737856824, \"f1\": 0.06843373493975903, \"f2\": 0.04389761345369111, \"f0_5\": 0.15515734265734266, \"p4\": 0.12245044230821459, \"phi\": 0.12047672599477734}, {\"truth_threshold\": 37.08, \"match_probability\": 0.9999999999931165, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 424, \"tn\": 8049, \"fp\": 0, \"fn\": 11600, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03526280771789754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9647371922821024, \"precision\": 1.0, \"recall\": 0.03526280771789754, \"specificity\": 1.0, \"npv\": 0.4096391673876533, \"accuracy\": 0.42210930105116323, \"f1\": 0.06812339331619537, \"f2\": 0.043693322341302555, \"f0_5\": 0.15451895043731778, \"p4\": 0.12195247107717865, \"phi\": 0.12018746687284187}, {\"truth_threshold\": 37.1, \"match_probability\": 0.9999999999932113, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 423, \"tn\": 8049, \"fp\": 0, \"fn\": 11601, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.035179640718562874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9648203592814372, \"precision\": 1.0, \"recall\": 0.035179640718562874, \"specificity\": 1.0, \"npv\": 0.40961832061068704, \"accuracy\": 0.42205948288746076, \"f1\": 0.06796818510484454, \"f2\": 0.04359117046930069, \"f0_5\": 0.1541994750656168, \"p4\": 0.12170325295448953, \"phi\": 0.12004259806762375}, {\"truth_threshold\": 37.160000000000004, \"match_probability\": 0.9999999999934879, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 419, \"tn\": 8049, \"fp\": 0, \"fn\": 11605, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.034846972721224216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9651530272787758, \"precision\": 1.0, \"recall\": 0.034846972721224216, \"specificity\": 1.0, \"npv\": 0.4095349547165971, \"accuracy\": 0.4218602102326508, \"f1\": 0.06734710278871654, \"f2\": 0.043182520869834075, \"f0_5\": 0.15291970802919708, \"p4\": 0.12070482667411492, \"phi\": 0.11946151428555163}, {\"truth_threshold\": 37.18, \"match_probability\": 0.9999999999935775, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 416, \"tn\": 8049, \"fp\": 0, \"fn\": 11608, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.034597471723220224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9654025282767797, \"precision\": 1.0, \"recall\": 0.034597471723220224, \"specificity\": 1.0, \"npv\": 0.4094724525614285, \"accuracy\": 0.4217107557415434, \"f1\": 0.06688102893890675, \"f2\": 0.04287598944591029, \"f0_5\": 0.15195791934541203, \"p4\": 0.11995437097918615, \"phi\": 0.11902399589549857}, {\"truth_threshold\": 37.2, \"match_probability\": 0.999999999993666, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 414, \"tn\": 8049, \"fp\": 0, \"fn\": 11610, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0344311377245509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9655688622754491, \"precision\": 1.0, \"recall\": 0.0344311377245509, \"specificity\": 1.0, \"npv\": 0.4094307950556997, \"accuracy\": 0.42161111941413837, \"f1\": 0.06657018813314038, \"f2\": 0.04267161410018553, \"f0_5\": 0.1513157894736842, \"p4\": 0.11945328572030037, \"phi\": 0.11873149579296627}, {\"truth_threshold\": 37.22, \"match_probability\": 0.9999999999937531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 413, \"tn\": 8049, \"fp\": 0, \"fn\": 11611, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03434797072521623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9656520292747838, \"precision\": 1.0, \"recall\": 0.03434797072521623, \"specificity\": 1.0, \"npv\": 0.4094099694811801, \"accuracy\": 0.4215613012504359, \"f1\": 0.06641473024041167, \"f2\": 0.0425694201076089, \"f0_5\": 0.1509944428195379, \"p4\": 0.11920250816612539, \"phi\": 0.11858499756019412}, {\"truth_threshold\": 37.24, \"match_probability\": 0.9999999999938392, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 412, \"tn\": 8049, \"fp\": 0, \"fn\": 11612, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.034264803725881574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9657351962741184, \"precision\": 1.0, \"recall\": 0.034264803725881574, \"specificity\": 1.0, \"npv\": 0.4093891460251259, \"accuracy\": 0.4215114830867334, \"f1\": 0.06625924734641364, \"f2\": 0.042467221901542014, \"f0_5\": 0.15067290813341136, \"p4\": 0.11895157377892066, \"phi\": 0.11843833305166537}, {\"truth_threshold\": 37.26, \"match_probability\": 0.999999999993924, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 411, \"tn\": 8049, \"fp\": 0, \"fn\": 11613, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03418163672654691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.965818363273453, \"precision\": 1.0, \"recall\": 0.03418163672654691, \"specificity\": 1.0, \"npv\": 0.4093683246872139, \"accuracy\": 0.42146166492303094, \"f1\": 0.06610373944511459, \"f2\": 0.04236501948172429, \"f0_5\": 0.15035118525021948, \"p4\": 0.11870048239600133, \"phi\": 0.11829150164662486}, {\"truth_threshold\": 37.300000000000004, \"match_probability\": 0.9999999999940901, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 409, \"tn\": 8049, \"fp\": 0, \"fn\": 11615, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.034015302727877575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9659846972721224, \"precision\": 1.0, \"recall\": 0.034015302727877575, \"specificity\": 1.0, \"npv\": 0.409326688364524, \"accuracy\": 0.421362028595626, \"f1\": 0.06579264859647711, \"f2\": 0.04216060199979384, \"f0_5\": 0.14970717423133237, \"p4\": 0.11819782799116263, \"phi\": 0.11799733564500044}, {\"truth_threshold\": 37.32, \"match_probability\": 0.9999999999941714, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 408, \"tn\": 8049, \"fp\": 0, \"fn\": 11616, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.033932135728542916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660678642714571, \"precision\": 1.0, \"recall\": 0.033932135728542916, \"specificity\": 1.0, \"npv\": 0.4093058733790999, \"accuracy\": 0.42131221043192346, \"f1\": 0.06563706563706563, \"f2\": 0.042058386937159825, \"f0_5\": 0.14938488576449913, \"p4\": 0.11794626464275555, \"phi\": 0.11784999978782104}, {\"truth_threshold\": 37.34, \"match_probability\": 0.9999999999942517, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 404, \"tn\": 8049, \"fp\": 0, \"fn\": 11620, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03359946773120426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9664005322687957, \"precision\": 1.0, \"recall\": 0.03359946773120426, \"specificity\": 1.0, \"npv\": 0.4092226346026743, \"accuracy\": 0.42111293777711356, \"f1\": 0.06501448342452526, \"f2\": 0.04164948453608248, \"f0_5\": 0.14809384164222875, \"p4\": 0.11693843312304072, \"phi\": 0.11725895576121657}, {\"truth_threshold\": 37.38, \"match_probability\": 0.9999999999944089, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 403, \"tn\": 8049, \"fp\": 0, \"fn\": 11621, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03351630073186959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9664836992681304, \"precision\": 1.0, \"recall\": 0.03351630073186959, \"specificity\": 1.0, \"npv\": 0.4092018301982715, \"accuracy\": 0.42106311961341103, \"f1\": 0.06485877524744509, \"f2\": 0.04154724839687416, \"f0_5\": 0.14777060721619242, \"p4\": 0.11668607989087346, \"phi\": 0.11711076637507205}, {\"truth_threshold\": 37.4, \"match_probability\": 0.9999999999944859, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 399, \"tn\": 8049, \"fp\": 0, \"fn\": 11625, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03318363273453094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.966816367265469, \"precision\": 1.0, \"recall\": 0.03318363273453094, \"specificity\": 1.0, \"npv\": 0.4091186337297957, \"accuracy\": 0.42086384695860113, \"f1\": 0.06423569186186912, \"f2\": 0.04113826167646149, \"f0_5\": 0.14647577092511013, \"p4\": 0.11567508061198656, \"phi\": 0.11651627562938417}, {\"truth_threshold\": 37.42, \"match_probability\": 0.9999999999945618, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 398, \"tn\": 8049, \"fp\": 0, \"fn\": 11626, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.033100465735196274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9668995342648037, \"precision\": 1.0, \"recall\": 0.033100465735196274, \"specificity\": 1.0, \"npv\": 0.40909783989834814, \"accuracy\": 0.4208140287948986, \"f1\": 0.06407985831589116, \"f2\": 0.04103600445415928, \"f0_5\": 0.14615158636897768, \"p4\": 0.1154219333783287, \"phi\": 0.11636721631068643}, {\"truth_threshold\": 37.44, \"match_probability\": 0.9999999999946366, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 395, \"tn\": 8049, \"fp\": 0, \"fn\": 11629, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03285096473719228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9671490352628077, \"precision\": 1.0, \"recall\": 0.03285096473719228, \"specificity\": 1.0, \"npv\": 0.4090354710844598, \"accuracy\": 0.42066457430379117, \"f1\": 0.06361220710202109, \"f2\": 0.04072920748180075, \"f0_5\": 0.14517788885621877, \"p4\": 0.11466153523127776, \"phi\": 0.11591897962308167}, {\"truth_threshold\": 37.46, \"match_probability\": 0.9999999999947105, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 394, \"tn\": 8049, \"fp\": 0, \"fn\": 11630, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03276779773785762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9672322022621423, \"precision\": 1.0, \"recall\": 0.03276779773785762, \"specificity\": 1.0, \"npv\": 0.4090146857055745, \"accuracy\": 0.4206147561400887, \"f1\": 0.06345627315187631, \"f2\": 0.04062693338832749, \"f0_5\": 0.1448529411764706, \"p4\": 0.11440774981255408, \"phi\": 0.11576921219829418}, {\"truth_threshold\": 37.5, \"match_probability\": 0.9999999999948551, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 393, \"tn\": 8049, \"fp\": 0, \"fn\": 11631, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03268463073852296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9673153692614771, \"precision\": 1.0, \"recall\": 0.03268463073852296, \"specificity\": 1.0, \"npv\": 0.4089939024390244, \"accuracy\": 0.42056493797638617, \"f1\": 0.0633003140855279, \"f2\": 0.04052465507640908, \"f0_5\": 0.1445278022947926, \"p4\": 0.11415380443122923, \"phi\": 0.11561926602226376}, {\"truth_threshold\": 37.52, \"match_probability\": 0.999999999994926, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 390, \"tn\": 8049, \"fp\": 0, \"fn\": 11634, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03243512974051896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.967564870259481, \"precision\": 1.0, \"recall\": 0.03243512974051896, \"specificity\": 1.0, \"npv\": 0.4089315653101661, \"accuracy\": 0.42041548348527874, \"f1\": 0.06283228612856452, \"f2\": 0.04021779482737285, \"f0_5\": 0.1435512367491166, \"p4\": 0.11339100684055411, \"phi\": 0.11516834797733595}, {\"truth_threshold\": 37.54, \"match_probability\": 0.9999999999949958, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 389, \"tn\": 8049, \"fp\": 0, \"fn\": 11635, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0323519627411843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9676480372588157, \"precision\": 1.0, \"recall\": 0.0323519627411843, \"specificity\": 1.0, \"npv\": 0.4089107904897379, \"accuracy\": 0.42036566532157627, \"f1\": 0.0626762265366954, \"f2\": 0.04011549963906363, \"f0_5\": 0.14322533136966126, \"p4\": 0.11313641993657582, \"phi\": 0.11501767976442673}, {\"truth_threshold\": 37.58, \"match_probability\": 0.9999999999951327, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 386, \"tn\": 8049, \"fp\": 0, \"fn\": 11638, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03210246174318031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9678975382568197, \"precision\": 1.0, \"recall\": 0.03210246174318031, \"specificity\": 1.0, \"npv\": 0.4088484786915223, \"accuracy\": 0.4202162108304688, \"f1\": 0.06220789685737309, \"f2\": 0.039808588754589334, \"f0_5\": 0.14224646226415094, \"p4\": 0.11237169375250883, \"phi\": 0.11456457849593854}, {\"truth_threshold\": 37.6, \"match_probability\": 0.9999999999951996, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 384, \"tn\": 8049, \"fp\": 0, \"fn\": 11640, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.031936127744510975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9680638722554891, \"precision\": 1.0, \"recall\": 0.031936127744510975, \"specificity\": 1.0, \"npv\": 0.4088069480420539, \"accuracy\": 0.42011657450306383, \"f1\": 0.061895551257253385, \"f2\": 0.039603960396039604, \"f0_5\": 0.1415929203539823, \"p4\": 0.11186107005192675, \"phi\": 0.11426158985203512}, {\"truth_threshold\": 37.62, \"match_probability\": 0.9999999999952658, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 382, \"tn\": 8049, \"fp\": 0, \"fn\": 11642, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03176979374584165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9682302062541583, \"precision\": 1.0, \"recall\": 0.03176979374584165, \"specificity\": 1.0, \"npv\": 0.40876542582905895, \"accuracy\": 0.4200169381756588, \"f1\": 0.06158310494921812, \"f2\": 0.0393993151532654, \"f0_5\": 0.14093860684769777, \"p4\": 0.1113497997792247, \"phi\": 0.11395785742554279}, {\"truth_threshold\": 37.64, \"match_probability\": 0.999999999995331, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 380, \"tn\": 8049, \"fp\": 0, \"fn\": 11644, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.031603459747172324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9683965402528277, \"precision\": 1.0, \"recall\": 0.031603459747172324, \"specificity\": 1.0, \"npv\": 0.408723912049967, \"accuracy\": 0.4199173018482539, \"f1\": 0.06127055788455337, \"f2\": 0.03919465302417691, \"f0_5\": 0.14028352037802716, \"p4\": 0.11083788157890874, \"phi\": 0.11365337523442906}, {\"truth_threshold\": 37.660000000000004, \"match_probability\": 0.9999999999953952, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 379, \"tn\": 8049, \"fp\": 0, \"fn\": 11645, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03152029274783766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684797072521624, \"precision\": 1.0, \"recall\": 0.03152029274783766, \"specificity\": 1.0, \"npv\": 0.40870315832233167, \"accuracy\": 0.4198674836845514, \"f1\": 0.061114246553253246, \"f2\": 0.039092315626611654, \"f0_5\": 0.1399556868537666, \"p4\": 0.11058167908127522, \"phi\": 0.11350085108617353}, {\"truth_threshold\": 37.68, \"match_probability\": 0.9999999999954586, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 378, \"tn\": 8049, \"fp\": 0, \"fn\": 11646, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03143712574850299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.968562874251497, \"precision\": 1.0, \"recall\": 0.03143712574850299, \"specificity\": 1.0, \"npv\": 0.4086824067022087, \"accuracy\": 0.4198176655208489, \"f1\": 0.06095791001451379, \"f2\": 0.038989974006684, \"f0_5\": 0.13962765957446807, \"p4\": 0.11032531409172237, \"phi\": 0.11334813721759249}, {\"truth_threshold\": 37.7, \"match_probability\": 0.9999999999955211, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 374, \"tn\": 8049, \"fp\": 0, \"fn\": 11650, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.031104457751164338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9688955422488357, \"precision\": 1.0, \"recall\": 0.031104457751164338, \"specificity\": 1.0, \"npv\": 0.4085994212904208, \"accuracy\": 0.41961839286603897, \"f1\": 0.06033231166317148, \"f2\": 0.03858056529812255, \"f0_5\": 0.13831360946745563, \"p4\": 0.10929822580082098, \"phi\": 0.1127353690581536}, {\"truth_threshold\": 37.72, \"match_probability\": 0.9999999999955828, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 372, \"tn\": 8049, \"fp\": 0, \"fn\": 11652, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03093812375249501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969061876247505, \"precision\": 1.0, \"recall\": 0.03093812375249501, \"specificity\": 1.0, \"npv\": 0.4085579412212578, \"accuracy\": 0.41951875653863396, \"f1\": 0.060019361084220714, \"f2\": 0.038375835602872, \"f0_5\": 0.13765541740674955, \"p4\": 0.10878370225966219, \"phi\": 0.11242782638460933}, {\"truth_threshold\": 37.76, \"match_probability\": 0.9999999999957035, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 369, \"tn\": 8049, \"fp\": 0, \"fn\": 11655, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.030688622754491017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969311377245509, \"precision\": 1.0, \"recall\": 0.030688622754491017, \"specificity\": 1.0, \"npv\": 0.40849573690621194, \"accuracy\": 0.41936930204752654, \"f1\": 0.05954974582425563, \"f2\": 0.03806870937790158, \"f0_5\": 0.13666666666666666, \"p4\": 0.10801068883901986, \"phi\": 0.11196504618287152}, {\"truth_threshold\": 37.800000000000004, \"match_probability\": 0.999999999995821, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 368, \"tn\": 8049, \"fp\": 0, \"fn\": 11656, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.030605455755156354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9693945442448436, \"precision\": 1.0, \"recall\": 0.030605455755156354, \"specificity\": 1.0, \"npv\": 0.40847500634356765, \"accuracy\": 0.41931948388382406, \"f1\": 0.05939315687540349, \"f2\": 0.03796632551997359, \"f0_5\": 0.13633669235328985, \"p4\": 0.10775268951372485, \"phi\": 0.11181039188615371}, {\"truth_threshold\": 37.92, \"match_probability\": 0.9999999999961546, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 367, \"tn\": 8049, \"fp\": 0, \"fn\": 11657, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.03052228875582169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9694777112441784, \"precision\": 1.0, \"recall\": 0.03052228875582169, \"specificity\": 1.0, \"npv\": 0.4084542778849081, \"accuracy\": 0.41926966572012153, \"f1\": 0.05923654265192478, \"f2\": 0.03786393743680746, \"f0_5\": 0.13600652238363475, \"p4\": 0.10749452580795028, \"phi\": 0.11165553910645812}, {\"truth_threshold\": 37.94, \"match_probability\": 0.9999999999962075, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 366, \"tn\": 8049, \"fp\": 0, \"fn\": 11658, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.030439121756487025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969560878243513, \"precision\": 1.0, \"recall\": 0.030439121756487025, \"specificity\": 1.0, \"npv\": 0.40843355152991323, \"accuracy\": 0.41921984755641906, \"f1\": 0.05907990314769976, \"f2\": 0.03776154512814164, \"f0_5\": 0.1356761565836299, \"p4\": 0.10723619754857147, \"phi\": 0.11150048701442271}, {\"truth_threshold\": 37.96, \"match_probability\": 0.9999999999962598, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 365, \"tn\": 8049, \"fp\": 0, \"fn\": 11659, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.030355954757152363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9696440452428476, \"precision\": 1.0, \"recall\": 0.030355954757152363, \"specificity\": 1.0, \"npv\": 0.4084128272782626, \"accuracy\": 0.4191700293927166, \"f1\": 0.05892323835660667, \"f2\": 0.03765914859371453, \"f0_5\": 0.13534559477899732, \"p4\": 0.1069777045622224, \"phi\": 0.11134523477499889}, {\"truth_threshold\": 38.0, \"match_probability\": 0.999999999996362, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 364, \"tn\": 8049, \"fp\": 0, \"fn\": 11660, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.030272787757817696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9697272122421823, \"precision\": 1.0, \"recall\": 0.030272787757817696, \"specificity\": 1.0, \"npv\": 0.4083921051296362, \"accuracy\": 0.4191202112290141, \"f1\": 0.0587665482725218, \"f2\": 0.03755674783326455, \"f0_5\": 0.13501483679525222, \"p4\": 0.10671904667529525, \"phi\": 0.11118978154739692}, {\"truth_threshold\": 38.02, \"match_probability\": 0.9999999999964121, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 360, \"tn\": 8049, \"fp\": 0, \"fn\": 11664, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.029940119760479042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9700598802395209, \"precision\": 1.0, \"recall\": 0.029940119760479042, \"specificity\": 1.0, \"npv\": 0.40830923755897125, \"accuracy\": 0.41892093857420415, \"f1\": 0.05813953488372093, \"f2\": 0.03714710252600297, \"f0_5\": 0.13368983957219252, \"p4\": 0.1056827626411631, \"phi\": 0.11056594173535304}, {\"truth_threshold\": 38.06, \"match_probability\": 0.9999999999965102, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 357, \"tn\": 8049, \"fp\": 0, \"fn\": 11667, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02969061876247505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970309381237525, \"precision\": 1.0, \"recall\": 0.02969061876247505, \"specificity\": 1.0, \"npv\": 0.4082471089470481, \"accuracy\": 0.4187714840830967, \"f1\": 0.057669008965350134, \"f2\": 0.036839824159494765, \"f0_5\": 0.13269402319357718, \"p4\": 0.10490380961659052, \"phi\": 0.11009590942732352}, {\"truth_threshold\": 38.08, \"match_probability\": 0.9999999999965583, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 355, \"tn\": 8049, \"fp\": 0, \"fn\": 11669, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02952428476380572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9704757152361942, \"precision\": 1.0, \"recall\": 0.02952428476380572, \"specificity\": 1.0, \"npv\": 0.40820570037529164, \"accuracy\": 0.4186718477556917, \"f1\": 0.05735519831973503, \"f2\": 0.036634950775009806, \"f0_5\": 0.13202915798869383, \"p4\": 0.10438367640141559, \"phi\": 0.10978151638636108}, {\"truth_threshold\": 38.1, \"match_probability\": 0.9999999999966056, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 354, \"tn\": 8049, \"fp\": 0, \"fn\": 11670, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02944111776447106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970558882235529, \"precision\": 1.0, \"recall\": 0.02944111776447106, \"specificity\": 1.0, \"npv\": 0.40818499923931234, \"accuracy\": 0.41862202959198924, \"f1\": 0.057198254968492485, \"f2\": 0.03653250773993808, \"f0_5\": 0.13169642857142858, \"p4\": 0.10412335990678052, \"phi\": 0.10962400573001847}, {\"truth_threshold\": 38.12, \"match_probability\": 0.9999999999966523, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 348, \"tn\": 8049, \"fp\": 0, \"fn\": 11676, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.028942115768463075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9710578842315369, \"precision\": 1.0, \"recall\": 0.028942115768463075, \"specificity\": 1.0, \"npv\": 0.4080608365019011, \"accuracy\": 0.41832312060977433, \"f1\": 0.05625606207565471, \"f2\": 0.03591776071340104, \"f0_5\": 0.129695885509839, \"p4\": 0.10255795139809962, \"phi\": 0.10867448629100533}, {\"truth_threshold\": 38.14, \"match_probability\": 0.9999999999966984, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 345, \"tn\": 8049, \"fp\": 0, \"fn\": 11679, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02869261477045908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.971307385229541, \"precision\": 1.0, \"recall\": 0.02869261477045908, \"specificity\": 1.0, \"npv\": 0.40799878345498786, \"accuracy\": 0.41817366611866685, \"f1\": 0.055784622847441186, \"f2\": 0.0356103300922772, \"f0_5\": 0.12869292748433303, \"p4\": 0.10177298303244864, \"phi\": 0.10819682028825948}, {\"truth_threshold\": 38.160000000000004, \"match_probability\": 0.9999999999967439, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 340, \"tn\": 8049, \"fp\": 0, \"fn\": 11684, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.028276779773785763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9717232202262143, \"precision\": 1.0, \"recall\": 0.028276779773785763, \"specificity\": 1.0, \"npv\": 0.40789540363857496, \"accuracy\": 0.4179245753001544, \"f1\": 0.05499838240051763, \"f2\": 0.035097861095053265, \"f0_5\": 0.12701733413030483, \"p4\": 0.10046133155003635, \"phi\": 0.107396315111029}, {\"truth_threshold\": 38.2, \"match_probability\": 0.999999999996833, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 339, \"tn\": 8049, \"fp\": 0, \"fn\": 11685, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.028193612774451097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9718063872255489, \"precision\": 1.0, \"recall\": 0.028193612774451097, \"specificity\": 1.0, \"npv\": 0.4078747339616905, \"accuracy\": 0.41787475713645195, \"f1\": 0.05484105799563213, \"f2\": 0.034995354598947044, \"f0_5\": 0.1266816143497758, \"p4\": 0.10019849401014745, \"phi\": 0.10723554592483855}, {\"truth_threshold\": 38.22, \"match_probability\": 0.9999999999968766, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 338, \"tn\": 8049, \"fp\": 0, \"fn\": 11686, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.028110445775116434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9718895542248835, \"precision\": 1.0, \"recall\": 0.028110445775116434, \"specificity\": 1.0, \"npv\": 0.40785406637952876, \"accuracy\": 0.41782493897274947, \"f1\": 0.05468370813784177, \"f2\": 0.03489284387000867, \"f0_5\": 0.12634569377990432, \"p4\": 0.0999354869696076, \"phi\": 0.10707455167836324}, {\"truth_threshold\": 38.24, \"match_probability\": 0.9999999999969196, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 334, \"tn\": 8049, \"fp\": 0, \"fn\": 11690, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.027777777777777776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9722222222222222, \"precision\": 1.0, \"recall\": 0.027777777777777776, \"specificity\": 1.0, \"npv\": 0.40777141699174224, \"accuracy\": 0.4176256663179395, \"f1\": 0.05405405405405406, \"f2\": 0.034482758620689655, \"f0_5\": 0.125, \"p4\": 0.0988817601911542, \"phi\": 0.10642830359131998}, {\"truth_threshold\": 38.28, \"match_probability\": 0.9999999999970038, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 333, \"tn\": 8049, \"fp\": 0, \"fn\": 11691, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.027694610778443114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9723053892215568, \"precision\": 1.0, \"recall\": 0.027694610778443114, \"specificity\": 1.0, \"npv\": 0.40775075987841947, \"accuracy\": 0.41757584815423704, \"f1\": 0.053896576839038604, \"f2\": 0.034380226723657314, \"f0_5\": 0.12466307277628032, \"p4\": 0.09861790293779446, \"phi\": 0.10626616860246373}, {\"truth_threshold\": 38.32, \"match_probability\": 0.9999999999970858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 330, \"tn\": 8049, \"fp\": 0, \"fn\": 11694, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.027445109780439122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9725548902195609, \"precision\": 1.0, \"recall\": 0.027445109780439122, \"specificity\": 1.0, \"npv\": 0.40768880109405864, \"accuracy\": 0.41742639366312956, \"f1\": 0.053423992229237494, \"f2\": 0.03407260562507744, \"f0_5\": 0.12365107913669064, \"p4\": 0.09782530693257684, \"phi\": 0.1057783716185972}, {\"truth_threshold\": 38.36, \"match_probability\": 0.9999999999971654, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 327, \"tn\": 8049, \"fp\": 0, \"fn\": 11697, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02719560878243513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9728043912175649, \"precision\": 1.0, \"recall\": 0.02719560878243513, \"specificity\": 1.0, \"npv\": 0.4076268611364327, \"accuracy\": 0.41727693917202213, \"f1\": 0.052951178042263784, \"f2\": 0.033764946409763956, \"f0_5\": 0.12263726372637264, \"p4\": 0.09703117073314778, \"phi\": 0.10528846396770367}, {\"truth_threshold\": 38.38, \"match_probability\": 0.9999999999972045, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 325, \"tn\": 8049, \"fp\": 0, \"fn\": 11699, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0270292747837658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9729707252162342, \"precision\": 1.0, \"recall\": 0.0270292747837658, \"specificity\": 1.0, \"npv\": 0.40758557828640873, \"accuracy\": 0.4171773028446171, \"f1\": 0.052635840958782085, \"f2\": 0.033559819086759875, \"f0_5\": 0.12196037226058241, \"p4\": 0.09650088849948861, \"phi\": 0.10496067165087802}, {\"truth_threshold\": 38.42, \"match_probability\": 0.9999999999972808, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 324, \"tn\": 8049, \"fp\": 0, \"fn\": 11700, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02694610778443114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9730538922155688, \"precision\": 1.0, \"recall\": 0.02694610778443114, \"specificity\": 1.0, \"npv\": 0.40756493999696186, \"accuracy\": 0.41712748468091465, \"f1\": 0.052478134110787174, \"f2\": 0.03345724907063197, \"f0_5\": 0.12162162162162163, \"p4\": 0.09623548940231931, \"phi\": 0.10479641598028697}, {\"truth_threshold\": 38.46, \"match_probability\": 0.9999999999973552, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 322, \"tn\": 8049, \"fp\": 0, \"fn\": 11702, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02677977378576181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9732202262142382, \"precision\": 1.0, \"recall\": 0.02677977378576181, \"specificity\": 1.0, \"npv\": 0.4075236696876108, \"accuracy\": 0.4170278483535097, \"f1\": 0.052162643771261945, \"f2\": 0.033252096327811974, \"f0_5\": 0.12094350961538461, \"p4\": 0.09570417432782599, \"phi\": 0.1044671799493876}, {\"truth_threshold\": 38.480000000000004, \"match_probability\": 0.9999999999973916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 318, \"tn\": 8049, \"fp\": 0, \"fn\": 11706, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.026447105788423155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9735528942115769, \"precision\": 1.0, \"recall\": 0.026447105788423155, \"specificity\": 1.0, \"npv\": 0.4074411541381929, \"accuracy\": 0.41682857569869974, \"f1\": 0.051531356344190565, \"f2\": 0.03284173999256414, \"f0_5\": 0.11958483754512636, \"p4\": 0.09463947149273685, \"phi\": 0.10380577684334341}, {\"truth_threshold\": 38.5, \"match_probability\": 0.9999999999974276, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 316, \"tn\": 8049, \"fp\": 0, \"fn\": 11708, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.026280771789753826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9737192282102461, \"precision\": 1.0, \"recall\": 0.026280771789753826, \"specificity\": 1.0, \"npv\": 0.40739990889305056, \"accuracy\": 0.4167289393712948, \"f1\": 0.05121555915721232, \"f2\": 0.03263653639593489, \"f0_5\": 0.11890427453341361, \"p4\": 0.0941060807710154, \"phi\": 0.10347359099202444}, {\"truth_threshold\": 38.54, \"match_probability\": 0.9999999999974979, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 315, \"tn\": 8049, \"fp\": 0, \"fn\": 11709, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02619760479041916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9738023952095808, \"precision\": 1.0, \"recall\": 0.02619760479041916, \"specificity\": 1.0, \"npv\": 0.4073792894017613, \"accuracy\": 0.41667912120759226, \"f1\": 0.05105762217359591, \"f2\": 0.032533928239449714, \"f0_5\": 0.11856368563685638, \"p4\": 0.09383912493429612, \"phi\": 0.10330712281130057}, {\"truth_threshold\": 38.56, \"match_probability\": 0.9999999999975323, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 313, \"tn\": 8049, \"fp\": 0, \"fn\": 11711, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.026031270791749835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9739687292082502, \"precision\": 1.0, \"recall\": 0.026031270791749835, \"specificity\": 1.0, \"npv\": 0.40733805668016193, \"accuracy\": 0.4165794848801873, \"f1\": 0.05074167139499068, \"f2\": 0.03232869920882481, \"f0_5\": 0.11788189213618559, \"p4\": 0.09330469137786836, \"phi\": 0.1029734298604569}, {\"truth_threshold\": 38.58, \"match_probability\": 0.9999999999975663, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 312, \"tn\": 8049, \"fp\": 0, \"fn\": 11712, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02594810379241517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9740518962075848, \"precision\": 1.0, \"recall\": 0.02594810379241517, \"specificity\": 1.0, \"npv\": 0.40731744344921816, \"accuracy\": 0.41652966671648484, \"f1\": 0.05058365758754864, \"f2\": 0.03222607833415964, \"f0_5\": 0.11754068716094032, \"p4\": 0.09303721328485728, \"phi\": 0.10280620262942071}, {\"truth_threshold\": 38.6, \"match_probability\": 0.9999999999975998, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 309, \"tn\": 8049, \"fp\": 0, \"fn\": 11715, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.025698602794411177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9743013972055888, \"precision\": 1.0, \"recall\": 0.025698602794411177, \"specificity\": 1.0, \"npv\": 0.40725561627200974, \"accuracy\": 0.41638021222537736, \"f1\": 0.050109462417903185, \"f2\": 0.03191819026960025, \"f0_5\": 0.1165158371040724, \"p4\": 0.09223373150124584, \"phi\": 0.10230298293973406}, {\"truth_threshold\": 38.64, \"match_probability\": 0.9999999999976654, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 303, \"tn\": 8049, \"fp\": 0, \"fn\": 11721, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.025199600798403193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9748003992015968, \"precision\": 1.0, \"recall\": 0.025199600798403193, \"specificity\": 1.0, \"npv\": 0.4071320182094082, \"accuracy\": 0.41608130324316245, \"f1\": 0.049160379654417136, \"f2\": 0.031302299634289966, \"f0_5\": 0.1144605621033545, \"p4\": 0.09062203725100368, \"phi\": 0.10128950750756618}, {\"truth_threshold\": 38.660000000000004, \"match_probability\": 0.9999999999976976, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 301, \"tn\": 8049, \"fp\": 0, \"fn\": 11723, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.025033266799733864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9749667332002662, \"precision\": 1.0, \"recall\": 0.025033266799733864, \"specificity\": 1.0, \"npv\": 0.4070908355249848, \"accuracy\": 0.4159816669157575, \"f1\": 0.04884381338742393, \"f2\": 0.03109696882038143, \"f0_5\": 0.11377381312367704, \"p4\": 0.09008339861462068, \"phi\": 0.10094955917399305}, {\"truth_threshold\": 38.7, \"match_probability\": 0.9999999999977606, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 300, \"tn\": 8049, \"fp\": 0, \"fn\": 11724, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0249500998003992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9750499001996008, \"precision\": 1.0, \"recall\": 0.0249500998003992, \"specificity\": 1.0, \"npv\": 0.4070702473069337, \"accuracy\": 0.415931848752055, \"f1\": 0.04868549172346641, \"f2\": 0.030994297049342923, \"f0_5\": 0.11343012704174228, \"p4\": 0.08981381458987424, \"phi\": 0.10077918086629392}, {\"truth_threshold\": 38.72, \"match_probability\": 0.9999999999977914, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 299, \"tn\": 8049, \"fp\": 0, \"fn\": 11725, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02486693280106454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9751330671989354, \"precision\": 1.0, \"recall\": 0.02486693280106454, \"specificity\": 1.0, \"npv\": 0.407049661171235, \"accuracy\": 0.4158820305883525, \"f1\": 0.04852714436419703, \"f2\": 0.030891621035230913, \"f0_5\": 0.11308623298033282, \"p4\": 0.08954405384048637, \"phi\": 0.10060853130346943}, {\"truth_threshold\": 38.74, \"match_probability\": 0.9999999999978219, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 296, \"tn\": 8049, \"fp\": 0, \"fn\": 11728, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.024617431803060547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753825681969395, \"precision\": 1.0, \"recall\": 0.024617431803060547, \"specificity\": 1.0, \"npv\": 0.4069879152550943, \"accuracy\": 0.41573257609724507, \"f1\": 0.048051948051948054, \"f2\": 0.030583567531823442, \"f0_5\": 0.11205330102967898, \"p4\": 0.08873370933768303, \"phi\": 0.10009494117317852}, {\"truth_threshold\": 38.78, \"match_probability\": 0.9999999999978814, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 292, \"tn\": 8049, \"fp\": 0, \"fn\": 11732, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02428476380572189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9757152361942781, \"precision\": 1.0, \"recall\": 0.02428476380572189, \"specificity\": 1.0, \"npv\": 0.40690561650068247, \"accuracy\": 0.4155333034424351, \"f1\": 0.047417992854822996, \"f2\": 0.03017277010829131, \"f0_5\": 0.11067313523347483, \"p4\": 0.08765076426484948, \"phi\": 0.09940627137128083}, {\"truth_threshold\": 38.86, \"match_probability\": 0.9999999999979956, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 291, \"tn\": 8049, \"fp\": 0, \"fn\": 11733, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.024201596806387227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9757984031936128, \"precision\": 1.0, \"recall\": 0.024201596806387227, \"specificity\": 1.0, \"npv\": 0.40688504701243555, \"accuracy\": 0.41548348527873263, \"f1\": 0.047259439707673566, \"f2\": 0.03007006014012028, \"f0_5\": 0.11032757051865331, \"p4\": 0.08737958283586199, \"phi\": 0.09923340090082007}, {\"truth_threshold\": 38.88, \"match_probability\": 0.9999999999980232, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 290, \"tn\": 8049, \"fp\": 0, \"fn\": 11734, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02411842980705256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9758815701929474, \"precision\": 1.0, \"recall\": 0.02411842980705256, \"specificity\": 1.0, \"npv\": 0.40686447960370015, \"accuracy\": 0.41543366711503016, \"f1\": 0.04710086080883547, \"f2\": 0.02996734592650767, \"f0_5\": 0.10998179611650485, \"p4\": 0.08710822295750854, \"phi\": 0.09906024627621725}, {\"truth_threshold\": 38.9, \"match_probability\": 0.9999999999980504, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 289, \"tn\": 8049, \"fp\": 0, \"fn\": 11735, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.024035262807717898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.975964737192282, \"precision\": 1.0, \"recall\": 0.024035262807717898, \"specificity\": 1.0, \"npv\": 0.40684391427416094, \"accuracy\": 0.4153838489513276, \"f1\": 0.046942256152034435, \"f2\": 0.029864627467190246, \"f0_5\": 0.10963581183611533, \"p4\": 0.08683668443677942, \"phi\": 0.09888680600211593}, {\"truth_threshold\": 38.92, \"match_probability\": 0.9999999999980773, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 288, \"tn\": 8049, \"fp\": 0, \"fn\": 11736, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.023952095808383235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9760479041916168, \"precision\": 1.0, \"recall\": 0.023952095808383235, \"specificity\": 1.0, \"npv\": 0.40682335102350264, \"accuracy\": 0.41533403078762515, \"f1\": 0.04678362573099415, \"f2\": 0.02976190476190476, \"f0_5\": 0.1092896174863388, \"p4\": 0.08656496708038838, \"phi\": 0.09871307857017964}, {\"truth_threshold\": 38.94, \"match_probability\": 0.9999999999981037, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 285, \"tn\": 8049, \"fp\": 0, \"fn\": 11739, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02370259481037924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9762974051896207, \"precision\": 1.0, \"recall\": 0.02370259481037924, \"specificity\": 1.0, \"npv\": 0.4067616737416616, \"accuracy\": 0.4151845762965177, \"f1\": 0.04630757981964416, \"f2\": 0.02945371116760712, \"f0_5\": 0.10824977210574294, \"p4\": 0.08574874006022278, \"phi\": 0.09819015804595838}, {\"truth_threshold\": 38.96, \"match_probability\": 0.9999999999981298, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 283, \"tn\": 8049, \"fp\": 0, \"fn\": 11741, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.023536260811709914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9764637391882901, \"precision\": 1.0, \"recall\": 0.023536260811709914, \"specificity\": 1.0, \"npv\": 0.40672056594239514, \"accuracy\": 0.4150849399691127, \"f1\": 0.04599008694239051, \"f2\": 0.02924822753674115, \"f0_5\": 0.10755548799027059, \"p4\": 0.08520369097906552, \"phi\": 0.09784008032246536}, {\"truth_threshold\": 38.980000000000004, \"match_probability\": 0.9999999999981556, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 281, \"tn\": 8049, \"fp\": 0, \"fn\": 11743, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.023369926813040585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9766300731869594, \"precision\": 1.0, \"recall\": 0.023369926813040585, \"specificity\": 1.0, \"npv\": 0.4066794664510914, \"accuracy\": 0.41498530364170777, \"f1\": 0.04567249085737505, \"f2\": 0.029042726915683072, \"f0_5\": 0.10686035898996045, \"p4\": 0.08465792189277016, \"phi\": 0.09748881662697727}, {\"truth_threshold\": 39.0, \"match_probability\": 0.999999999998181, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 278, \"tn\": 8049, \"fp\": 0, \"fn\": 11746, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.023120425815036594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9768795741849634, \"precision\": 1.0, \"recall\": 0.023120425815036594, \"specificity\": 1.0, \"npv\": 0.40661783278605707, \"accuracy\": 0.4148358491506003, \"f1\": 0.04519590310518615, \"f2\": 0.028734444122875926, \"f0_5\": 0.10581607795371498, \"p4\": 0.08383791483337819, \"phi\": 0.09695966913104122}, {\"truth_threshold\": 39.1, \"match_probability\": 0.9999999999983028, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 277, \"tn\": 8049, \"fp\": 0, \"fn\": 11747, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02303725881570193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.976962741184298, \"precision\": 1.0, \"recall\": 0.02303725881570193, \"specificity\": 1.0, \"npv\": 0.40659729238229947, \"accuracy\": 0.4147860309868978, \"f1\": 0.04503698886269409, \"f2\": 0.028631674694561016, \"f0_5\": 0.10546756015839172, \"p4\": 0.08356421744822576, \"phi\": 0.09678267953706729}, {\"truth_threshold\": 39.14, \"match_probability\": 0.9999999999983492, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 273, \"tn\": 8049, \"fp\": 0, \"fn\": 11751, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.022704590818363273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9772954091816367, \"precision\": 1.0, \"recall\": 0.022704590818363273, \"specificity\": 1.0, \"npv\": 0.4065151515151515, \"accuracy\": 0.41458675833208786, \"f1\": 0.04440107343254452, \"f2\": 0.02822055448737828, \"f0_5\": 0.10407136322049405, \"p4\": 0.0824676141684477, \"phi\": 0.09607164085523086}, {\"truth_threshold\": 39.160000000000004, \"match_probability\": 0.999999999998372, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 272, \"tn\": 8049, \"fp\": 0, \"fn\": 11752, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02262142381902861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9773785761809713, \"precision\": 1.0, \"recall\": 0.02262142381902861, \"specificity\": 1.0, \"npv\": 0.4064946214837634, \"accuracy\": 0.4145369401683854, \"f1\": 0.04424202992843201, \"f2\": 0.02811776381078399, \"f0_5\": 0.10372178157413056, \"p4\": 0.08219300892694838, \"phi\": 0.09589310252953454}, {\"truth_threshold\": 39.18, \"match_probability\": 0.9999999999983944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 271, \"tn\": 8049, \"fp\": 0, \"fn\": 11753, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.022538256819693944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9774617431803061, \"precision\": 1.0, \"recall\": 0.022538256819693944, \"specificity\": 1.0, \"npv\": 0.40647409352590647, \"accuracy\": 0.4144871220046829, \"f1\": 0.04408296055307035, \"f2\": 0.02801496888374305, \"f0_5\": 0.10337198657308513, \"p4\": 0.08191822152112632, \"phi\": 0.0957142492549525}, {\"truth_threshold\": 39.24, \"match_probability\": 0.9999999999984598, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 270, \"tn\": 8049, \"fp\": 0, \"fn\": 11754, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02245508982035928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9775449101796407, \"precision\": 1.0, \"recall\": 0.02245508982035928, \"specificity\": 1.0, \"npv\": 0.4064535676412665, \"accuracy\": 0.41443730384098043, \"f1\": 0.043923865300146414, \"f2\": 0.02791216970599181, \"f0_5\": 0.10302197802197802, \"p4\": 0.0816432517526318, \"phi\": 0.09553507925987248}, {\"truth_threshold\": 39.28, \"match_probability\": 0.9999999999985019, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 267, \"tn\": 8049, \"fp\": 0, \"fn\": 11757, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02220558882235529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9777944111776448, \"precision\": 1.0, \"recall\": 0.02220558882235529, \"specificity\": 1.0, \"npv\": 0.40639200242350804, \"accuracy\": 0.41428784934987295, \"f1\": 0.04344642421283866, \"f2\": 0.027603746665839587, \"f0_5\": 0.10197066911090742, \"p4\": 0.08081724628332115, \"phi\": 0.09499565098734801}, {\"truth_threshold\": 39.300000000000004, \"match_probability\": 0.9999999999985225, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 266, \"tn\": 8049, \"fp\": 0, \"fn\": 11758, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.022122421823020627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9778775781769794, \"precision\": 1.0, \"recall\": 0.022122421823020627, \"specificity\": 1.0, \"npv\": 0.406371484828596, \"accuracy\": 0.4142380311861705, \"f1\": 0.043287225386493086, \"f2\": 0.027500930482610313, \"f0_5\": 0.101619804400978, \"p4\": 0.08054154507490913, \"phi\": 0.09481519606173594}, {\"truth_threshold\": 39.34, \"match_probability\": 0.9999999999985629, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 254, \"tn\": 8049, \"fp\": 0, \"fn\": 11770, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.021124417831004657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9788755821689954, \"precision\": 1.0, \"recall\": 0.021124417831004657, \"specificity\": 1.0, \"npv\": 0.4061254351884555, \"accuracy\": 0.41364021322174066, \"f1\": 0.04137481674539827, \"f2\": 0.02626680455015512, \"f0_5\": 0.09739263803680982, \"p4\": 0.07721877116478613, \"phi\": 0.09262377332369663}, {\"truth_threshold\": 39.38, \"match_probability\": 0.9999999999986022, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 252, \"tn\": 8049, \"fp\": 0, \"fn\": 11772, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.020958083832335328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9790419161676647, \"precision\": 1.0, \"recall\": 0.020958083832335328, \"specificity\": 1.0, \"npv\": 0.40608445588012715, \"accuracy\": 0.41354057689433565, \"f1\": 0.04105571847507331, \"f2\": 0.026061057334326135, \"f0_5\": 0.09668508287292818, \"p4\": 0.0766623840609511, \"phi\": 0.09225373742751013}, {\"truth_threshold\": 39.4, \"match_probability\": 0.9999999999986214, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 249, \"tn\": 8049, \"fp\": 0, \"fn\": 11775, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.020708582834331336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9792914171656687, \"precision\": 1.0, \"recall\": 0.020708582834331336, \"specificity\": 1.0, \"npv\": 0.4060230024213075, \"accuracy\": 0.41339112240322823, \"f1\": 0.04057687606942068, \"f2\": 0.025752404591995036, \"f0_5\": 0.0956221198156682, \"p4\": 0.07582640649694491, \"phi\": 0.09169602487722987}, {\"truth_threshold\": 39.42, \"match_probability\": 0.9999999999986404, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 245, \"tn\": 8049, \"fp\": 0, \"fn\": 11779, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.020375914836992682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9796240851630074, \"precision\": 1.0, \"recall\": 0.020375914836992682, \"specificity\": 1.0, \"npv\": 0.4059410934032681, \"accuracy\": 0.41319184974841827, \"f1\": 0.039938055261227484, \"f2\": 0.025340808009763967, \"f0_5\": 0.0942017840664411, \"p4\": 0.07470915358891995, \"phi\": 0.09094735371642586}, {\"truth_threshold\": 39.44, \"match_probability\": 0.9999999999986592, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 242, \"tn\": 8049, \"fp\": 0, \"fn\": 11782, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.02012641383898869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798735861610113, \"precision\": 1.0, \"recall\": 0.02012641383898869, \"specificity\": 1.0, \"npv\": 0.4058796833240885, \"accuracy\": 0.4130423952573108, \"f1\": 0.03945866623186043, \"f2\": 0.025032065869502254, \"f0_5\": 0.09313423645320197, \"p4\": 0.07386924459796984, \"phi\": 0.09038198092218537}, {\"truth_threshold\": 39.52, \"match_probability\": 0.9999999999987315, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 241, \"tn\": 8049, \"fp\": 0, \"fn\": 11783, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.020043246839654024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979956753160346, \"precision\": 1.0, \"recall\": 0.020043246839654024, \"specificity\": 1.0, \"npv\": 0.4058592174263816, \"accuracy\": 0.4129925770936083, \"f1\": 0.039298817774154095, \"f2\": 0.02492914330636986, \"f0_5\": 0.09277794887588543, \"p4\": 0.07358889872720968, \"phi\": 0.09019277397344966}, {\"truth_threshold\": 39.56, \"match_probability\": 0.9999999999987662, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 238, \"tn\": 8049, \"fp\": 0, \"fn\": 11786, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.019793745841650032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9802062541583499, \"precision\": 1.0, \"recall\": 0.019793745841650032, \"specificity\": 1.0, \"npv\": 0.4057978321149483, \"accuracy\": 0.4128431226025009, \"f1\": 0.038819115968031316, \"f2\": 0.024620350064137046, \"f0_5\": 0.09170776818742293, \"p4\": 0.07274672959331067, \"phi\": 0.0896228718128127}, {\"truth_threshold\": 39.58, \"match_probability\": 0.9999999999987832, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 237, \"tn\": 8049, \"fp\": 0, \"fn\": 11787, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01971057884231537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9802894211576846, \"precision\": 1.0, \"recall\": 0.01971057884231537, \"specificity\": 1.0, \"npv\": 0.4057773744706594, \"accuracy\": 0.41279330443879836, \"f1\": 0.038659163200391485, \"f2\": 0.024517410464899757, \"f0_5\": 0.09135060129509713, \"p4\": 0.07246562868224435, \"phi\": 0.0894321359016526}, {\"truth_threshold\": 39.62, \"match_probability\": 0.9999999999988164, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 236, \"tn\": 8049, \"fp\": 0, \"fn\": 11788, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.019627411842980707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803725881570193, \"precision\": 1.0, \"recall\": 0.019627411842980707, \"specificity\": 1.0, \"npv\": 0.4057569188889449, \"accuracy\": 0.4127434862750959, \"f1\": 0.038499184339314846, \"f2\": 0.02441446660597534, \"f0_5\": 0.09099321406539174, \"p4\": 0.07218433849092278, \"phi\": 0.08924101162118367}, {\"truth_threshold\": 39.660000000000004, \"match_probability\": 0.9999999999988488, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 235, \"tn\": 8049, \"fp\": 0, \"fn\": 11789, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01954424484364604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.980455755156354, \"precision\": 1.0, \"recall\": 0.01954424484364604, \"specificity\": 1.0, \"npv\": 0.40573646536949287, \"accuracy\": 0.4126936681113934, \"f1\": 0.038339179378415855, \"f2\": 0.02431151848709938, \"f0_5\": 0.09063560629435359, \"p4\": 0.07190285881066658, \"phi\": 0.08904949646784581}, {\"truth_threshold\": 39.68, \"match_probability\": 0.9999999999988647, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 234, \"tn\": 8049, \"fp\": 0, \"fn\": 11790, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.019461077844311378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9805389221556886, \"precision\": 1.0, \"recall\": 0.019461077844311378, \"specificity\": 1.0, \"npv\": 0.4057160139119915, \"accuracy\": 0.41264384994769093, \"f1\": 0.0381791483113069, \"f2\": 0.024208566108007448, \"f0_5\": 0.09027777777777778, \"p4\": 0.07162118943249156, \"phi\": 0.08885758791135952}, {\"truth_threshold\": 39.7, \"match_probability\": 0.9999999999988802, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 233, \"tn\": 8049, \"fp\": 0, \"fn\": 11791, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.019377910844976712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9806220891550232, \"precision\": 1.0, \"recall\": 0.019377910844976712, \"specificity\": 1.0, \"npv\": 0.40569556451612904, \"accuracy\": 0.41259403178398846, \"f1\": 0.03801909113159827, \"f2\": 0.0241056094684351, \"f0_5\": 0.08991972831120716, \"p4\": 0.07133933014710798, \"phi\": 0.08866528339432547}, {\"truth_threshold\": 39.72, \"match_probability\": 0.9999999999988957, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 231, \"tn\": 8049, \"fp\": 0, \"fn\": 11793, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.019211576846307386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9807884231536926, \"precision\": 1.0, \"recall\": 0.019211576846307386, \"specificity\": 1.0, \"npv\": 0.4056546719080738, \"accuracy\": 0.41249439545658345, \"f1\": 0.03769889840881273, \"f2\": 0.023899683406791234, \"f0_5\": 0.0892029657089898, \"p4\": 0.0707750410160258, \"phi\": 0.08827947611096006}, {\"truth_threshold\": 39.78, \"match_probability\": 0.9999999999989407, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 230, \"tn\": 8049, \"fp\": 0, \"fn\": 11794, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01912840984697272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9808715901530273, \"precision\": 1.0, \"recall\": 0.01912840984697272, \"specificity\": 1.0, \"npv\": 0.4056342286952578, \"accuracy\": 0.412444577292881, \"f1\": 0.037538762852945974, \"f2\": 0.023796713984190705, \"f0_5\": 0.0888442521631644, \"p4\": 0.07049261075021548, \"phi\": 0.08808596809051686}, {\"truth_threshold\": 39.800000000000004, \"match_probability\": 0.9999999999989553, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 228, \"tn\": 8049, \"fp\": 0, \"fn\": 11796, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.018962075848303395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810379241516967, \"precision\": 1.0, \"recall\": 0.018962075848303395, \"specificity\": 1.0, \"npv\": 0.40559334845049133, \"accuracy\": 0.412344940965476, \"f1\": 0.03721841332027424, \"f2\": 0.02359076235410976, \"f0_5\": 0.08812615955473098, \"p4\": 0.06992717776547022, \"phi\": 0.08769772994146179}, {\"truth_threshold\": 39.84, \"match_probability\": 0.9999999999989838, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 227, \"tn\": 8049, \"fp\": 0, \"fn\": 11797, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01887890884896873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9811210911510313, \"precision\": 1.0, \"recall\": 0.01887890884896873, \"specificity\": 1.0, \"npv\": 0.40557291141791796, \"accuracy\": 0.41229512280177355, \"f1\": 0.03705819933066688, \"f2\": 0.0234877801461002, \"f0_5\": 0.08776678008042066, \"p4\": 0.0696441746245757, \"phi\": 0.08750299438459087}, {\"truth_threshold\": 39.88, \"match_probability\": 0.9999999999990116, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 225, \"tn\": 8049, \"fp\": 0, \"fn\": 11799, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0187125748502994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9812874251497006, \"precision\": 1.0, \"recall\": 0.0187125748502994, \"specificity\": 1.0, \"npv\": 0.40553204353083433, \"accuracy\": 0.41219548647436854, \"f1\": 0.036737692872887584, \"f2\": 0.023281802942819892, \"f0_5\": 0.08704735376044569, \"p4\": 0.06907759398852431, \"phi\": 0.08711227651006265}, {\"truth_threshold\": 39.9, \"match_probability\": 0.9999999999990252, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 224, \"tn\": 8049, \"fp\": 0, \"fn\": 11800, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.018629407850964737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9813705921490352, \"precision\": 1.0, \"recall\": 0.018629407850964737, \"specificity\": 1.0, \"npv\": 0.40551161267570157, \"accuracy\": 0.41214566831066607, \"f1\": 0.036577400391900716, \"f2\": 0.023178807947019868, \"f0_5\": 0.08668730650154799, \"p4\": 0.06879401606954981, \"phi\": 0.08691628858181925}, {\"truth_threshold\": 39.94, \"match_probability\": 0.9999999999990519, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 223, \"tn\": 8049, \"fp\": 0, \"fn\": 11801, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.018546240851630074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.98145375914837, \"precision\": 1.0, \"recall\": 0.018546240851630074, \"specificity\": 1.0, \"npv\": 0.4054911838790932, \"accuracy\": 0.4120958501469636, \"f1\": 0.036417081734302276, \"f2\": 0.02307580868809371, \"f0_5\": 0.08632703623412821, \"p4\": 0.06851024613354621, \"phi\": 0.08671987753355212}, {\"truth_threshold\": 39.96, \"match_probability\": 0.999999999999065, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 220, \"tn\": 8049, \"fp\": 0, \"fn\": 11804, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.018296739853626082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9817032601463739, \"precision\": 1.0, \"recall\": 0.018296739853626082, \"specificity\": 1.0, \"npv\": 0.4054299098373042, \"accuracy\": 0.4119463956558561, \"f1\": 0.0359359686377001, \"f2\": 0.022766785329911415, \"f0_5\": 0.08524488530688158, \"p4\": 0.06765778209493066, \"phi\": 0.0861280766601242}, {\"truth_threshold\": 40.02, \"match_probability\": 0.999999999999103, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 217, \"tn\": 8049, \"fp\": 0, \"fn\": 11807, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01804723885562209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9819527611443779, \"precision\": 1.0, \"recall\": 0.01804723885562209, \"specificity\": 1.0, \"npv\": 0.40536865431103947, \"accuracy\": 0.4117969411647487, \"f1\": 0.035454619720611064, \"f2\": 0.02245772359406371, \"f0_5\": 0.08416071982624884, \"p4\": 0.06680358222756135, \"phi\": 0.08553236188094791}, {\"truth_threshold\": 40.04, \"match_probability\": 0.9999999999991154, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 216, \"tn\": 8049, \"fp\": 0, \"fn\": 11808, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.017964071856287425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9820359281437125, \"precision\": 1.0, \"recall\": 0.017964071856287425, \"specificity\": 1.0, \"npv\": 0.4053482399153951, \"accuracy\": 0.41174712300104616, \"f1\": 0.03529411764705882, \"f2\": 0.022354694485842028, \"f0_5\": 0.08379888268156424, \"p4\": 0.0665184621995967, \"phi\": 0.08533290636477696}, {\"truth_threshold\": 40.06, \"match_probability\": 0.9999999999991276, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 215, \"tn\": 8049, \"fp\": 0, \"fn\": 11809, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.017880904856952762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9821190951430473, \"precision\": 1.0, \"recall\": 0.017880904856952762, \"specificity\": 1.0, \"npv\": 0.4053278275757881, \"accuracy\": 0.4116973048373437, \"f1\": 0.03513358934553477, \"f2\": 0.022251661112376062, \"f0_5\": 0.083436820863086, \"p4\": 0.06623314844433327, \"phi\": 0.08513300371041785}, {\"truth_threshold\": 40.08, \"match_probability\": 0.9999999999991396, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 212, \"tn\": 8049, \"fp\": 0, \"fn\": 11812, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01763140385894877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9823685961410512, \"precision\": 1.0, \"recall\": 0.01763140385894877, \"specificity\": 1.0, \"npv\": 0.4052666028900861, \"accuracy\": 0.41154785034623625, \"f1\": 0.03465184700882641, \"f2\": 0.021942535397863706, \"f0_5\": 0.08234928527035426, \"p4\": 0.0653760426611562, \"phi\": 0.08453058112954934}, {\"truth_threshold\": 40.12, \"match_probability\": 0.9999999999991631, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 208, \"tn\": 8049, \"fp\": 0, \"fn\": 11816, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.017298735861610112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9827012641383899, \"precision\": 1.0, \"recall\": 0.017298735861610112, \"specificity\": 1.0, \"npv\": 0.40518499874150515, \"accuracy\": 0.4113485776914263, \"f1\": 0.034009156311314584, \"f2\": 0.021530308049022857, \"f0_5\": 0.08089607965152458, \"p4\": 0.0642305096762486, \"phi\": 0.08372089505204852}, {\"truth_threshold\": 40.14, \"match_probability\": 0.9999999999991747, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 207, \"tn\": 8049, \"fp\": 0, \"fn\": 11817, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01721556886227545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9827844311377245, \"precision\": 1.0, \"recall\": 0.01721556886227545, \"specificity\": 1.0, \"npv\": 0.40516460283902145, \"accuracy\": 0.4112987595277238, \"f1\": 0.03384841795437822, \"f2\": 0.021427240544065584, \"f0_5\": 0.08053221288515407, \"p4\": 0.0639436383286721, \"phi\": 0.08351729833233147}, {\"truth_threshold\": 40.160000000000004, \"match_probability\": 0.999999999999186, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 205, \"tn\": 8049, \"fp\": 0, \"fn\": 11819, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01704923486360612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9829507651363939, \"precision\": 1.0, \"recall\": 0.01704923486360612, \"specificity\": 1.0, \"npv\": 0.40512381719347695, \"accuracy\": 0.4111991232003188, \"f1\": 0.033526862376318585, \"f2\": 0.02122109273099936, \"f0_5\": 0.07980379943942698, \"p4\": 0.0633693083887558, \"phi\": 0.08310867047530132}, {\"truth_threshold\": 40.28, \"match_probability\": 0.9999999999992509, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 202, \"tn\": 8049, \"fp\": 0, \"fn\": 11822, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01679973386560213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9832002661343978, \"precision\": 1.0, \"recall\": 0.01679973386560213, \"specificity\": 1.0, \"npv\": 0.405062654119068, \"accuracy\": 0.4110496687092114, \"f1\": 0.03304433175200393, \"f2\": 0.020911838999544494, \"f0_5\": 0.07870947630922694, \"p4\": 0.0625063420910302, \"phi\": 0.08249208924554395}, {\"truth_threshold\": 40.36, \"match_probability\": 0.9999999999992913, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 201, \"tn\": 8049, \"fp\": 0, \"fn\": 11823, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.016716566866267466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9832834331337326, \"precision\": 1.0, \"recall\": 0.016716566866267466, \"specificity\": 1.0, \"npv\": 0.40504227053140096, \"accuracy\": 0.4109998505455089, \"f1\": 0.032883435582822085, \"f2\": 0.020808745884837568, \"f0_5\": 0.07834424695977549, \"p4\": 0.06221829341251562, \"phi\": 0.08228557710196216}, {\"truth_threshold\": 40.38, \"match_probability\": 0.9999999999993011, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 200, \"tn\": 8049, \"fp\": 0, \"fn\": 11824, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0166333998669328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9833666001330672, \"precision\": 1.0, \"recall\": 0.0166333998669328, \"specificity\": 1.0, \"npv\": 0.405021888995119, \"accuracy\": 0.4109500323818064, \"f1\": 0.032722513089005235, \"f2\": 0.02070564850091105, \"f0_5\": 0.07797878976918278, \"p4\": 0.061930047745150735, \"phi\": 0.08207856623087591}, {\"truth_threshold\": 40.42, \"match_probability\": 0.9999999999993202, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 198, \"tn\": 8049, \"fp\": 0, \"fn\": 11826, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.016467065868263474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9835329341317365, \"precision\": 1.0, \"recall\": 0.016467065868263474, \"specificity\": 1.0, \"npv\": 0.4049811320754717, \"accuracy\": 0.41085039605440143, \"f1\": 0.03240058910162003, \"f2\": 0.020499440924338426, \"f0_5\": 0.07724719101123595, \"p4\": 0.061352964563481445, \"phi\": 0.0816630331134639}, {\"truth_threshold\": 40.46, \"match_probability\": 0.9999999999993389, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 197, \"tn\": 8049, \"fp\": 0, \"fn\": 11827, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01638389886892881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836161011310712, \"precision\": 1.0, \"recall\": 0.01638389886892881, \"specificity\": 1.0, \"npv\": 0.40496075669148723, \"accuracy\": 0.41080057789069896, \"f1\": 0.032239587595123145, \"f2\": 0.020396330731161864, \"f0_5\": 0.07688104901654699, \"p4\": 0.06106412660816771, \"phi\": 0.08145450315064362}, {\"truth_threshold\": 40.480000000000004, \"match_probability\": 0.999999999999348, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 196, \"tn\": 8049, \"fp\": 0, \"fn\": 11828, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.016300731869594146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836992681304059, \"precision\": 1.0, \"recall\": 0.016300731869594146, \"specificity\": 1.0, \"npv\": 0.40494038335764954, \"accuracy\": 0.4107507597269965, \"f1\": 0.032078559738134206, \"f2\": 0.020293216267704795, \"f0_5\": 0.07651467832604622, \"p4\": 0.06077509078198382, \"phi\": 0.08124545902562007}, {\"truth_threshold\": 40.52, \"match_probability\": 0.9999999999993657, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 194, \"tn\": 8049, \"fp\": 0, \"fn\": 11830, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.016134397870924817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9838656021290751, \"precision\": 1.0, \"recall\": 0.016134397870924817, \"specificity\": 1.0, \"npv\": 0.404899642839177, \"accuracy\": 0.4106511233995915, \"f1\": 0.031756424946799804, \"f2\": 0.02008697452888797, \"f0_5\": 0.07578125, \"p4\": 0.06019642463138795, \"phi\": 0.08082581230870887}, {\"truth_threshold\": 40.54, \"match_probability\": 0.9999999999993745, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 190, \"tn\": 8049, \"fp\": 0, \"fn\": 11834, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015801729873586162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9841982701264138, \"precision\": 1.0, \"recall\": 0.015801729873586162, \"specificity\": 1.0, \"npv\": 0.40481818639038375, \"accuracy\": 0.4104518507447815, \"f1\": 0.03111183887342394, \"f2\": 0.019674439796214225, \"f0_5\": 0.0743116395494368, \"p4\": 0.05903670811954799, \"phi\": 0.07998017022522456}, {\"truth_threshold\": 40.6, \"match_probability\": 0.9999999999993999, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 189, \"tn\": 8049, \"fp\": 0, \"fn\": 11835, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015718562874251496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9842814371257484, \"precision\": 1.0, \"recall\": 0.015718562874251496, \"specificity\": 1.0, \"npv\": 0.4047978273989137, \"accuracy\": 0.41040203258107905, \"f1\": 0.030950626381724394, \"f2\": 0.0195712954333644, \"f0_5\": 0.07394366197183098, \"p4\": 0.058746280981826014, \"phi\": 0.07976741252748662}, {\"truth_threshold\": 40.62, \"match_probability\": 0.9999999999994083, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 188, \"tn\": 8049, \"fp\": 0, \"fn\": 11836, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015635395874916833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9843646041250832, \"precision\": 1.0, \"recall\": 0.015635395874916833, \"specificity\": 1.0, \"npv\": 0.4047774704551169, \"accuracy\": 0.41035221441737657, \"f1\": 0.030789387487717, \"f2\": 0.019468146798111177, \"f0_5\": 0.07357545397620538, \"p4\": 0.058455654193431746, \"phi\": 0.07955410732208115}, {\"truth_threshold\": 40.660000000000004, \"match_probability\": 0.9999999999994243, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 187, \"tn\": 8049, \"fp\": 0, \"fn\": 11837, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015552228875582169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9844477711244178, \"precision\": 1.0, \"recall\": 0.015552228875582169, \"specificity\": 1.0, \"npv\": 0.4047571155586845, \"accuracy\": 0.4103023962536741, \"f1\": 0.03062812218491524, \"f2\": 0.019364993890189093, \"f0_5\": 0.07320701534606952, \"p4\": 0.058164827530400295, \"phi\": 0.07934025018985712}, {\"truth_threshold\": 40.72, \"match_probability\": 0.9999999999994479, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 186, \"tn\": 8049, \"fp\": 0, \"fn\": 11838, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015469061876247504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9845309381237525, \"precision\": 1.0, \"recall\": 0.015469061876247504, \"specificity\": 1.0, \"npv\": 0.4047367627093076, \"accuracy\": 0.4102525780899716, \"f1\": 0.030466830466830467, \"f2\": 0.01926183670933267, \"f0_5\": 0.07283834586466166, \"p4\": 0.057873800768433646, \"phi\": 0.0791258366524006}, {\"truth_threshold\": 40.78, \"match_probability\": 0.9999999999994703, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 183, \"tn\": 8049, \"fp\": 0, \"fn\": 11841, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.015219560878243513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847804391217565, \"precision\": 1.0, \"recall\": 0.015219560878243513, \"specificity\": 1.0, \"npv\": 0.40467571644042233, \"accuracy\": 0.41010312359886414, \"f1\": 0.029982796755959697, \"f2\": 0.018952339526502205, \"f0_5\": 0.07173095014111007, \"p4\": 0.056999517640933306, \"phi\": 0.07847921191189305}, {\"truth_threshold\": 40.800000000000004, \"match_probability\": 0.9999999999994776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 177, \"tn\": 8049, \"fp\": 0, \"fn\": 11847, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01472055888223553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9852794411177644, \"precision\": 1.0, \"recall\": 0.01472055888223553, \"specificity\": 1.0, \"npv\": 0.4045536791314837, \"accuracy\": 0.40980421461664923, \"f1\": 0.029014015244652077, \"f2\": 0.018333229755764093, \"f0_5\": 0.06950989632422243, \"p4\": 0.05524551828380366, \"phi\": 0.07717030681991634}, {\"truth_threshold\": 40.82, \"match_probability\": 0.9999999999994849, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 176, \"tn\": 8049, \"fp\": 0, \"fn\": 11848, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.014637391882900865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9853626081170991, \"precision\": 1.0, \"recall\": 0.014637391882900865, \"specificity\": 1.0, \"npv\": 0.4045333467356888, \"accuracy\": 0.40975439645294676, \"f1\": 0.028852459016393443, \"f2\": 0.018230029830957905, \"f0_5\": 0.06913890634820867, \"p4\": 0.054952478122371654, \"phi\": 0.07695006904396963}, {\"truth_threshold\": 40.86, \"match_probability\": 0.999999999999499, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 175, \"tn\": 8049, \"fp\": 0, \"fn\": 11849, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0145542248835662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9854457751164338, \"precision\": 1.0, \"recall\": 0.0145542248835662, \"specificity\": 1.0, \"npv\": 0.40451301638355613, \"accuracy\": 0.4097045782892443, \"f1\": 0.028690876301336175, \"f2\": 0.018126825630295624, \"f0_5\": 0.06876768311851619, \"p4\": 0.05465923537256463, \"phi\": 0.0767292213486881}, {\"truth_threshold\": 40.9, \"match_probability\": 0.9999999999995126, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 173, \"tn\": 8049, \"fp\": 0, \"fn\": 11851, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.014387890884896873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856121091151031, \"precision\": 1.0, \"recall\": 0.014387890884896873, \"specificity\": 1.0, \"npv\": 0.4044723618090452, \"accuracy\": 0.4096049419618393, \"f1\": 0.028367631384766747, \"f2\": 0.017920404400339762, \"f0_5\": 0.0680245360176156, \"p4\": 0.05407214119410928, \"phi\": 0.07628567498334843}, {\"truth_threshold\": 40.92, \"match_probability\": 0.9999999999995193, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 172, \"tn\": 8049, \"fp\": 0, \"fn\": 11852, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.014304723885562209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856952761144377, \"precision\": 1.0, \"recall\": 0.014304723885562209, \"specificity\": 1.0, \"npv\": 0.40445203758605097, \"accuracy\": 0.4095551237981368, \"f1\": 0.028205969170219745, \"f2\": 0.017817187370514628, \"f0_5\": 0.06765261170547514, \"p4\": 0.05377828930774905, \"phi\": 0.07606296551293203}, {\"truth_threshold\": 40.94, \"match_probability\": 0.9999999999995259, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 171, \"tn\": 8049, \"fp\": 0, \"fn\": 11853, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.014221556886227544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9857784431137725, \"precision\": 1.0, \"recall\": 0.014221556886227544, \"specificity\": 1.0, \"npv\": 0.4044317154054869, \"accuracy\": 0.4095053056344343, \"f1\": 0.028044280442804426, \"f2\": 0.01771396606377028, \"f0_5\": 0.06728045325779036, \"p4\": 0.053484233917588726, \"phi\": 0.07583962451933501}, {\"truth_threshold\": 41.02, \"match_probability\": 0.9999999999995515, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 166, \"tn\": 8049, \"fp\": 0, \"fn\": 11858, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.013805721889554225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9861942781104458, \"precision\": 1.0, \"recall\": 0.013805721889554225, \"specificity\": 1.0, \"npv\": 0.4043301351283468, \"accuracy\": 0.4092562148159219, \"f1\": 0.027235438884331418, \"f2\": 0.017197795366955367, \"f0_5\": 0.06541614123581337, \"p4\": 0.052010896357798146, \"phi\": 0.07471324780216582}, {\"truth_threshold\": 41.06, \"match_probability\": 0.9999999999995638, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 162, \"tn\": 8049, \"fp\": 0, \"fn\": 11862, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01347305389221557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9865269461077845, \"precision\": 1.0, \"recall\": 0.01347305389221557, \"specificity\": 1.0, \"npv\": 0.4042489076389935, \"accuracy\": 0.40905694216111194, \"f1\": 0.026587887740029542, \"f2\": 0.01678478179783663, \"f0_5\": 0.06392045454545454, \"p4\": 0.050828539718808526, \"phi\": 0.07380018508438467}, {\"truth_threshold\": 41.14, \"match_probability\": 0.9999999999995873, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 161, \"tn\": 8049, \"fp\": 0, \"fn\": 11863, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.013389886892880905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9866101131071191, \"precision\": 1.0, \"recall\": 0.013389886892880905, \"specificity\": 1.0, \"npv\": 0.40422860586580955, \"accuracy\": 0.40900712399740946, \"f1\": 0.026425933524825605, \"f2\": 0.016681517707275627, \"f0_5\": 0.06354594253236501, \"p4\": 0.050532436599512884, \"phi\": 0.07357020668320924}, {\"truth_threshold\": 41.160000000000004, \"match_probability\": 0.999999999999593, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 159, \"tn\": 8049, \"fp\": 0, \"fn\": 11865, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.013223552894211578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9867764471057884, \"precision\": 1.0, \"recall\": 0.013223552894211578, \"specificity\": 1.0, \"npv\": 0.404188008436276, \"accuracy\": 0.4089074876700045, \"f1\": 0.02610194533366166, \"f2\": 0.016474976686353747, \"f0_5\": 0.06279620853080568, \"p4\": 0.04993961197842678, \"phi\": 0.07310814940048155}, {\"truth_threshold\": 41.2, \"match_probability\": 0.9999999999996041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 158, \"tn\": 8049, \"fp\": 0, \"fn\": 11866, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.013140385894876913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868596141051231, \"precision\": 1.0, \"recall\": 0.013140385894876913, \"specificity\": 1.0, \"npv\": 0.40416771277931207, \"accuracy\": 0.408857669506302, \"f1\": 0.025939911344606797, \"f2\": 0.016371699755460687, \"f0_5\": 0.06242098609355246, \"p4\": 0.049642890009225026, \"phi\": 0.07287605719418372}, {\"truth_threshold\": 41.22, \"match_probability\": 0.9999999999996095, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 157, \"tn\": 8049, \"fp\": 0, \"fn\": 11867, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.013057218895542249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9869427811044578, \"precision\": 1.0, \"recall\": 0.013057218895542249, \"specificity\": 1.0, \"npv\": 0.404147419160474, \"accuracy\": 0.4088078513425995, \"f1\": 0.025777850751169853, \"f2\": 0.01626841854392473, \"f0_5\": 0.062045526398988304, \"p4\": 0.049345961288724344, \"phi\": 0.07264324688535594}, {\"truth_threshold\": 41.26, \"match_probability\": 0.9999999999996202, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 154, \"tn\": 8049, \"fp\": 0, \"fn\": 11870, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.012807717897538257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9871922821024618, \"precision\": 1.0, \"recall\": 0.012807717897538257, \"specificity\": 1.0, \"npv\": 0.40408655052964504, \"accuracy\": 0.4086583968514921, \"f1\": 0.025291509279027756, \"f2\": 0.01595854922279793, \"f0_5\": 0.06091772151898734, \"p4\": 0.04845393227181268, \"phi\": 0.07194043748388684}, {\"truth_threshold\": 41.300000000000004, \"match_probability\": 0.9999999999996306, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 150, \"tn\": 8049, \"fp\": 0, \"fn\": 11874, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0124750499001996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9875249500998003, \"precision\": 1.0, \"recall\": 0.0124750499001996, \"specificity\": 1.0, \"npv\": 0.40400542087035085, \"accuracy\": 0.4084591241966821, \"f1\": 0.02464268112370626, \"f2\": 0.015545330182813084, \"f0_5\": 0.0594106463878327, \"p4\": 0.04726165145914844, \"phi\": 0.07099287136965773}, {\"truth_threshold\": 41.36, \"match_probability\": 0.9999999999996457, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 149, \"tn\": 8049, \"fp\": 0, \"fn\": 11875, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.012391882900864936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876081170991351, \"precision\": 1.0, \"recall\": 0.012391882900864936, \"specificity\": 1.0, \"npv\": 0.40398514354547277, \"accuracy\": 0.40840930603297965, \"f1\": 0.024480407459130864, \"f2\": 0.015442014716550937, \"f0_5\": 0.05903328050713154, \"p4\": 0.046963060253462086, \"phi\": 0.07075405707452126}, {\"truth_threshold\": 41.4, \"match_probability\": 0.9999999999996554, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 146, \"tn\": 8049, \"fp\": 0, \"fn\": 11878, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.012142381902860945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.987857618097139, \"precision\": 1.0, \"recall\": 0.012142381902860945, \"specificity\": 1.0, \"npv\": 0.4039243237818036, \"accuracy\": 0.40825985154187217, \"f1\": 0.02399342645850452, \"f2\": 0.015132042618465237, \"f0_5\": 0.0578997461928934, \"p4\": 0.04606603243294013, \"phi\": 0.07003287370380797}, {\"truth_threshold\": 41.52, \"match_probability\": 0.9999999999996829, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 141, \"tn\": 8049, \"fp\": 0, \"fn\": 11883, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011726546906187624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9882734530938124, \"precision\": 1.0, \"recall\": 0.011726546906187624, \"specificity\": 1.0, \"npv\": 0.40382299819385914, \"accuracy\": 0.40801076072335973, \"f1\": 0.023181257706535143, \"f2\": 0.014615336774675042, \"f0_5\": 0.05600571973307912, \"p4\": 0.04456679107688735, \"phi\": 0.06881460114043829}, {\"truth_threshold\": 41.56, \"match_probability\": 0.9999999999996916, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 139, \"tn\": 8049, \"fp\": 0, \"fn\": 11885, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011560212907518297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884397870924817, \"precision\": 1.0, \"recall\": 0.011560212907518297, \"specificity\": 1.0, \"npv\": 0.4037824821912311, \"accuracy\": 0.4079111243959548, \"f1\": 0.022856203239332403, \"f2\": 0.014408624442831969, \"f0_5\": 0.055246422893481716, \"p4\": 0.04396562070020025, \"phi\": 0.06832138363980085}, {\"truth_threshold\": 41.6, \"match_probability\": 0.9999999999997, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 138, \"tn\": 8049, \"fp\": 0, \"fn\": 11886, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011477045908183632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9885229540918163, \"precision\": 1.0, \"recall\": 0.011477045908183632, \"specificity\": 1.0, \"npv\": 0.40376222723852523, \"accuracy\": 0.40786130623225225, \"f1\": 0.022693635915145536, \"f2\": 0.014305261848488618, \"f0_5\": 0.05486641221374046, \"p4\": 0.043664718728247114, \"phi\": 0.06807347220472176}, {\"truth_threshold\": 41.62, \"match_probability\": 0.9999999999997041, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 137, \"tn\": 8049, \"fp\": 0, \"fn\": 11887, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011393878908848968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.988606121091151, \"precision\": 1.0, \"recall\": 0.011393878908848968, \"specificity\": 1.0, \"npv\": 0.403741974317817, \"accuracy\": 0.4078114880685498, \"f1\": 0.0225310418551106, \"f2\": 0.014201894968175316, \"f0_5\": 0.05448615972001273, \"p4\": 0.043363605245467576, \"phi\": 0.06782467962177792}, {\"truth_threshold\": 41.660000000000004, \"match_probability\": 0.9999999999997122, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 136, \"tn\": 8049, \"fp\": 0, \"fn\": 11888, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011310711909514305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9886892880904857, \"precision\": 1.0, \"recall\": 0.011310711909514305, \"specificity\": 1.0, \"npv\": 0.40372172342880075, \"accuracy\": 0.4077616699048473, \"f1\": 0.02236842105263158, \"f2\": 0.014098523801625476, \"f0_5\": 0.05410566518141311, \"p4\": 0.0430622800100895, \"phi\": 0.0675749961547596}, {\"truth_threshold\": 41.68, \"match_probability\": 0.9999999999997161, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 135, \"tn\": 8049, \"fp\": 0, \"fn\": 11889, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01122754491017964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887724550898204, \"precision\": 1.0, \"recall\": 0.01122754491017964, \"specificity\": 1.0, \"npv\": 0.4037014745711706, \"accuracy\": 0.4077118517411448, \"f1\": 0.02220577350111029, \"f2\": 0.013995148348572494, \"f0_5\": 0.053724928366762174, \"p4\": 0.04276074277997422, \"phi\": 0.06732441188791449}, {\"truth_threshold\": 41.7, \"match_probability\": 0.9999999999997201, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 134, \"tn\": 8049, \"fp\": 0, \"fn\": 11890, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011144377910844976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.988855622089155, \"precision\": 1.0, \"recall\": 0.011144377910844976, \"specificity\": 1.0, \"npv\": 0.4036812277446211, \"accuracy\": 0.40766203357744235, \"f1\": 0.022043099193946373, \"f2\": 0.01389176860874974, \"f0_5\": 0.05334394904458599, \"p4\": 0.04245899331261584, \"phi\": 0.0670729167212813}, {\"truth_threshold\": 41.78, \"match_probability\": 0.9999999999997352, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 133, \"tn\": 8049, \"fp\": 0, \"fn\": 11891, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.011061210911510314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9889387890884896, \"precision\": 1.0, \"recall\": 0.011061210911510314, \"specificity\": 1.0, \"npv\": 0.40366098294884656, \"accuracy\": 0.4076122154137399, \"f1\": 0.021880398124537303, \"f2\": 0.013788384581890564, \"f0_5\": 0.05296272698311564, \"p4\": 0.04215703136514055, \"phi\": 0.06682050036586647}, {\"truth_threshold\": 41.84, \"match_probability\": 0.999999999999746, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 131, \"tn\": 8049, \"fp\": 0, \"fn\": 11893, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.010894876912840985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989105123087159, \"precision\": 1.0, \"recall\": 0.010894876912840985, \"specificity\": 1.0, \"npv\": 0.40362049944840034, \"accuracy\": 0.40751257908633487, \"f1\": 0.021554915672562732, \"f2\": 0.013581603665996226, \"f0_5\": 0.052199553713739244, \"p4\": 0.04155246905650009, \"phi\": 0.06631286195746437}, {\"truth_threshold\": 41.86, \"match_probability\": 0.9999999999997494, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 130, \"tn\": 8049, \"fp\": 0, \"fn\": 11894, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.01081170991350632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891882900864937, \"precision\": 1.0, \"recall\": 0.01081170991350632, \"specificity\": 1.0, \"npv\": 0.4036002607431179, \"accuracy\": 0.4074627609226324, \"f1\": 0.021392134276781306, \"f2\": 0.013478206776427653, \"f0_5\": 0.05181760204081633, \"p4\": 0.04124986820774138, \"phi\": 0.06605761833558718}, {\"truth_threshold\": 41.9, \"match_probability\": 0.9999999999997563, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 129, \"tn\": 8049, \"fp\": 0, \"fn\": 11895, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.010728542914171657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9892714570858283, \"precision\": 1.0, \"recall\": 0.010728542914171657, \"specificity\": 1.0, \"npv\": 0.4035800240673887, \"accuracy\": 0.4074129427589299, \"f1\": 0.02122932609232288, \"f2\": 0.013374805598755831, \"f0_5\": 0.05143540669856459, \"p4\": 0.04094705390367723, \"phi\": 0.06580141037629368}, {\"truth_threshold\": 41.94, \"match_probability\": 0.999999999999763, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 127, \"tn\": 8049, \"fp\": 0, \"fn\": 11897, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.010562208915502328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9894377910844977, \"precision\": 1.0, \"recall\": 0.010562208915502328, \"specificity\": 1.0, \"npv\": 0.4035395568033691, \"accuracy\": 0.4073133064315249, \"f1\": 0.020903629330919264, \"f2\": 0.013167990378035377, \"f0_5\": 0.0506702840727737, \"p4\": 0.04034078395036467, \"phi\": 0.06528605597389386}, {\"truth_threshold\": 41.96, \"match_probability\": 0.9999999999997662, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 124, \"tn\": 8049, \"fp\": 0, \"fn\": 11900, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.010312707917498337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9896872920825016, \"precision\": 1.0, \"recall\": 0.010312707917498337, \"specificity\": 1.0, \"npv\": 0.40347887112135944, \"accuracy\": 0.4071638519404175, \"f1\": 0.02041488310833059, \"f2\": 0.012857735379510576, \"f0_5\": 0.04952076677316294, \"p4\": 0.039429771975396904, \"phi\": 0.06450550169370466}, {\"truth_threshold\": 41.980000000000004, \"match_probability\": 0.9999999999997694, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 123, \"tn\": 8049, \"fp\": 0, \"fn\": 11901, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.010229540918163672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897704590818364, \"precision\": 1.0, \"recall\": 0.010229540918163672, \"specificity\": 1.0, \"npv\": 0.40345864661654135, \"accuracy\": 0.407114033776715, \"f1\": 0.020251914052852555, \"f2\": 0.0127543084676165, \"f0_5\": 0.04913710450623202, \"p4\": 0.03912567178724751, \"phi\": 0.06424326217083662}, {\"truth_threshold\": 42.0, \"match_probability\": 0.9999999999997726, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 119, \"tn\": 8049, \"fp\": 0, \"fn\": 11905, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009896872920825016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990103127079175, \"precision\": 1.0, \"recall\": 0.009896872920825016, \"specificity\": 1.0, \"npv\": 0.4033777688683973, \"accuracy\": 0.40691476112190506, \"f1\": 0.019599769414477476, \"f2\": 0.012340557917660479, \"f0_5\": 0.0476, \"p4\": 0.03790711679719688, \"phi\": 0.0631836886987176}, {\"truth_threshold\": 42.06, \"match_probability\": 0.9999999999997818, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 117, \"tn\": 8049, \"fp\": 0, \"fn\": 11907, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009730538922155689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9902694610778443, \"precision\": 1.0, \"recall\": 0.009730538922155689, \"specificity\": 1.0, \"npv\": 0.40333734215273603, \"accuracy\": 0.40681512479450005, \"f1\": 0.01927353595255745, \"f2\": 0.012133656897517267, \"f0_5\": 0.0468299711815562, \"p4\": 0.03729654328763271, \"phi\": 0.06264734397064271}, {\"truth_threshold\": 42.12, \"match_probability\": 0.9999999999997907, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 116, \"tn\": 8049, \"fp\": 0, \"fn\": 11908, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009647371922821025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9903526280771789, \"precision\": 1.0, \"recall\": 0.009647371922821025, \"specificity\": 1.0, \"npv\": 0.4033171318334419, \"accuracy\": 0.4067653066307976, \"f1\": 0.019110378912685338, \"f2\": 0.012030199950219863, \"f0_5\": 0.046444586803331196, \"p4\": 0.03699093165854816, \"phi\": 0.06237748290563393}, {\"truth_threshold\": 42.14, \"match_probability\": 0.9999999999997936, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 115, \"tn\": 8049, \"fp\": 0, \"fn\": 11909, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00956420492348636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9904357950765137, \"precision\": 1.0, \"recall\": 0.00956420492348636, \"specificity\": 1.0, \"npv\": 0.4032969235394328, \"accuracy\": 0.4067154884670951, \"f1\": 0.018947194991350193, \"f2\": 0.011926738711082532, \"f0_5\": 0.04605895546299263, \"p4\": 0.03668510311389898, \"phi\": 0.06210647648790539}, {\"truth_threshold\": 42.160000000000004, \"match_probability\": 0.9999999999997965, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 114, \"tn\": 8049, \"fp\": 0, \"fn\": 11910, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009481037924151697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905189620758483, \"precision\": 1.0, \"recall\": 0.009481037924151697, \"specificity\": 1.0, \"npv\": 0.4032767172704043, \"accuracy\": 0.4066656703033926, \"f1\": 0.018783984181908058, \"f2\": 0.011823273179838207, \"f0_5\": 0.04567307692307692, \"p4\": 0.03637905740368626, \"phi\": 0.06183430965384917}, {\"truth_threshold\": 42.22, \"match_probability\": 0.9999999999998048, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 112, \"tn\": 8049, \"fp\": 0, \"fn\": 11912, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009314703925482368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906852960745176, \"precision\": 1.0, \"recall\": 0.009314703925482368, \"specificity\": 1.0, \"npv\": 0.40323631080607186, \"accuracy\": 0.4065660339759876, \"f1\": 0.01845748187211602, \"f2\": 0.011616329239960173, \"f0_5\": 0.04490057729313662, \"p4\": 0.035766313484662894, \"phi\": 0.061286432814794706}, {\"truth_threshold\": 42.24, \"match_probability\": 0.9999999999998075, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 111, \"tn\": 8049, \"fp\": 0, \"fn\": 11913, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009231536926147704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9907684630738522, \"precision\": 1.0, \"recall\": 0.009231536926147704, \"specificity\": 1.0, \"npv\": 0.40321611061015933, \"accuracy\": 0.40651621581228514, \"f1\": 0.018294190358467244, \"f2\": 0.01151285083079221, \"f0_5\": 0.044513955726660254, \"p4\": 0.03545961477394054, \"phi\": 0.06101069098375582}, {\"truth_threshold\": 42.36, \"match_probability\": 0.9999999999998228, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 110, \"tn\": 8049, \"fp\": 0, \"fn\": 11914, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009148369926813041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990851630073187, \"precision\": 1.0, \"recall\": 0.009148369926813041, \"specificity\": 1.0, \"npv\": 0.40319591243801034, \"accuracy\": 0.40646639764858267, \"f1\": 0.01813087193011373, \"f2\": 0.01140936812844874, \"f0_5\": 0.04412708600770218, \"p4\": 0.03515269789382975, \"phi\": 0.060733725062454696}, {\"truth_threshold\": 42.4, \"match_probability\": 0.9999999999998277, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 109, \"tn\": 8049, \"fp\": 0, \"fn\": 11915, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.009065202927478377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909347970725216, \"precision\": 1.0, \"recall\": 0.009065202927478377, \"specificity\": 1.0, \"npv\": 0.40317571628932075, \"accuracy\": 0.4064165794848802, \"f1\": 0.017967526580400562, \"f2\": 0.011305881132662586, \"f0_5\": 0.04373996789727127, \"p4\": 0.03484556259241333, \"phi\": 0.060455518222856566}, {\"truth_threshold\": 42.5, \"match_probability\": 0.9999999999998392, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 107, \"tn\": 8049, \"fp\": 0, \"fn\": 11917, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008898868928809048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9911011310711909, \"precision\": 1.0, \"recall\": 0.008898868928809048, \"specificity\": 1.0, \"npv\": 0.40313533006110386, \"accuracy\": 0.40631694315747524, \"f1\": 0.017640755090264613, \"f2\": 0.01109889425969338, \"f0_5\": 0.042964985544490845, \"p4\": 0.03423063571606461, \"phi\": 0.05989531252765894}, {\"truth_threshold\": 42.54, \"match_probability\": 0.9999999999998436, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 104, \"tn\": 8049, \"fp\": 0, \"fn\": 11920, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008649367930805056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9913506320691949, \"precision\": 1.0, \"recall\": 0.008649367930805056, \"specificity\": 1.0, \"npv\": 0.40307476588712504, \"accuracy\": 0.40616748866636776, \"f1\": 0.017150395778364115, \"f2\": 0.010788381742738589, \"f0_5\": 0.04180064308681672, \"p4\": 0.0333066009215918, \"phi\": 0.05904525343989011}, {\"truth_threshold\": 42.62, \"match_probability\": 0.999999999999852, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 102, \"tn\": 8049, \"fp\": 0, \"fn\": 11922, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008483033932135729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9915169660678643, \"precision\": 1.0, \"recall\": 0.008483033932135729, \"specificity\": 1.0, \"npv\": 0.40303439987982576, \"accuracy\": 0.4060678523389628, \"f1\": 0.01682335477486393, \"f2\": 0.01058135192331632, \"f0_5\": 0.041023166023166024, \"p4\": 0.03268947844367522, \"phi\": 0.0584718264636784}, {\"truth_threshold\": 42.68, \"match_probability\": 0.9999999999998581, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 101, \"tn\": 8049, \"fp\": 0, \"fn\": 11923, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008399866932801064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991600133067199, \"precision\": 1.0, \"recall\": 0.008399866932801064, \"specificity\": 1.0, \"npv\": 0.403014219907871, \"accuracy\": 0.4060180341752603, \"f1\": 0.01665979381443299, \"f2\": 0.01047783057036745, \"f0_5\": 0.04063405214032829, \"p4\": 0.03238058665633397, \"phi\": 0.05818303721234173}, {\"truth_threshold\": 42.7, \"match_probability\": 0.99999999999986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 99, \"tn\": 8049, \"fp\": 0, \"fn\": 11925, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008233532934131737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9917664670658682, \"precision\": 1.0, \"recall\": 0.008233532934131737, \"specificity\": 1.0, \"npv\": 0.40297386602583357, \"accuracy\": 0.40591839784785533, \"f1\": 0.016332590942835932, \"f2\": 0.01027077497665733, \"f0_5\": 0.03985507246376811, \"p4\": 0.03176214070780079, \"phi\": 0.05760120309089117}, {\"truth_threshold\": 42.72, \"match_probability\": 0.999999999999862, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 98, \"tn\": 8049, \"fp\": 0, \"fn\": 11926, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.008150365934797073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9918496340652029, \"precision\": 1.0, \"recall\": 0.008150365934797073, \"specificity\": 1.0, \"npv\": 0.4029536921151439, \"accuracy\": 0.40586857968415285, \"f1\": 0.01616894901831381, \"f2\": 0.010167240735361249, \"f0_5\": 0.03946520618556701, \"p4\": 0.03145258603459676, \"phi\": 0.057308115005782354}, {\"truth_threshold\": 42.76, \"match_probability\": 0.9999999999998658, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 96, \"tn\": 8049, \"fp\": 0, \"fn\": 11928, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007984031936127744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9920159680638723, \"precision\": 1.0, \"recall\": 0.007984031936127744, \"specificity\": 1.0, \"npv\": 0.4029133503529058, \"accuracy\": 0.40576894335674785, \"f1\": 0.015841584158415842, \"f2\": 0.0099601593625498, \"f0_5\": 0.03868471953578337, \"p4\": 0.03083281200732897, \"phi\": 0.05671748457671432}, {\"truth_threshold\": 42.800000000000004, \"match_probability\": 0.9999999999998694, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 95, \"tn\": 8049, \"fp\": 0, \"fn\": 11929, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007900864936793081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9920991350632069, \"precision\": 1.0, \"recall\": 0.007900864936793081, \"specificity\": 1.0, \"npv\": 0.40289318250075085, \"accuracy\": 0.40571912519304537, \"f1\": 0.015677861209670765, \"f2\": 0.009856612230499471, \"f0_5\": 0.038294098677845854, \"p4\": 0.030522592138886247, \"phi\": 0.05641989559449005}, {\"truth_threshold\": 42.86, \"match_probability\": 0.9999999999998748, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 94, \"tn\": 8049, \"fp\": 0, \"fn\": 11930, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007817697937458417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921823020625415, \"precision\": 1.0, \"recall\": 0.007817697937458417, \"specificity\": 1.0, \"npv\": 0.40287301666750086, \"accuracy\": 0.4056693070293429, \"f1\": 0.015514111239478462, \"f2\": 0.009753060800996057, \"f0_5\": 0.03790322580645161, \"p4\": 0.03021215002365821, \"phi\": 0.0561207586500679}, {\"truth_threshold\": 42.92, \"match_probability\": 0.9999999999998799, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 93, \"tn\": 8049, \"fp\": 0, \"fn\": 11931, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007734530938123752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9922654690618763, \"precision\": 1.0, \"recall\": 0.007734530938123752, \"specificity\": 1.0, \"npv\": 0.4028528528528528, \"accuracy\": 0.4056194888656404, \"f1\": 0.015350334241148799, \"f2\": 0.009649505073772022, \"f0_5\": 0.037512100677637945, \"p4\": 0.029901485403464052, \"phi\": 0.055820048852556606}, {\"truth_threshold\": 42.94, \"match_probability\": 0.9999999999998815, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 92, \"tn\": 8049, \"fp\": 0, \"fn\": 11932, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007651363938789089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923486360612109, \"precision\": 1.0, \"recall\": 0.007651363938789089, \"specificity\": 1.0, \"npv\": 0.40283269105650366, \"accuracy\": 0.40556967070193795, \"f1\": 0.015186530207989435, \"f2\": 0.009545945048559807, \"f0_5\": 0.03712072304712718, \"p4\": 0.029590598019725068, \"phi\": 0.05551774063950277}, {\"truth_threshold\": 43.1, \"match_probability\": 0.999999999999894, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 91, \"tn\": 8049, \"fp\": 0, \"fn\": 11933, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007568196939454424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924318030605456, \"precision\": 1.0, \"recall\": 0.007568196939454424, \"specificity\": 1.0, \"npv\": 0.4028125312781503, \"accuracy\": 0.4055198525382354, \"f1\": 0.01502269913330582, \"f2\": 0.00944238072509183, \"f0_5\": 0.03672909267032612, \"p4\": 0.029279487613463866, \"phi\": 0.0552138077512608}, {\"truth_threshold\": 43.26, \"match_probability\": 0.9999999999999051, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 90, \"tn\": 8049, \"fp\": 0, \"fn\": 11934, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0074850299401197605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925149700598802, \"precision\": 1.0, \"recall\": 0.0074850299401197605, \"specificity\": 1.0, \"npv\": 0.40279237351748987, \"accuracy\": 0.40547003437453294, \"f1\": 0.014858841010401188, \"f2\": 0.009338812103100485, \"f0_5\": 0.036337209302325583, \"p4\": 0.028968153925303622, \"phi\": 0.05490822320409133}, {\"truth_threshold\": 43.28, \"match_probability\": 0.9999999999999064, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 89, \"tn\": 8049, \"fp\": 0, \"fn\": 11935, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007401862940785097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.992598137059215, \"precision\": 1.0, \"recall\": 0.007401862940785097, \"specificity\": 1.0, \"npv\": 0.4027722177742194, \"accuracy\": 0.40542021621083046, \"f1\": 0.014694955832576571, \"f2\": 0.00923523918231815, \"f0_5\": 0.03594507269789984, \"p4\": 0.0286565966954673, \"phi\": 0.05460095926191058}, {\"truth_threshold\": 43.300000000000004, \"match_probability\": 0.9999999999999076, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 88, \"tn\": 8049, \"fp\": 0, \"fn\": 11936, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007318695941450432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926813040585496, \"precision\": 1.0, \"recall\": 0.007318695941450432, \"specificity\": 1.0, \"npv\": 0.40275206404803604, \"accuracy\": 0.405370398047128, \"f1\": 0.01453104359313078, \"f2\": 0.00913166196247717, \"f0_5\": 0.03555268261150614, \"p4\": 0.028344815663776876, \"phi\": 0.05429198740660675}, {\"truth_threshold\": 43.36, \"match_probability\": 0.9999999999999114, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 87, \"tn\": 8049, \"fp\": 0, \"fn\": 11937, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007235528942115769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927644710578842, \"precision\": 1.0, \"recall\": 0.007235528942115769, \"specificity\": 1.0, \"npv\": 0.40273191233863703, \"accuracy\": 0.4053205798834255, \"f1\": 0.014367104285360416, \"f2\": 0.009028080443309881, \"f0_5\": 0.03516003879728419, \"p4\": 0.028032810569652566, \"phi\": 0.05398127830683374}, {\"truth_threshold\": 43.42, \"match_probability\": 0.9999999999999151, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 86, \"tn\": 8049, \"fp\": 0, \"fn\": 11938, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.007152361942781104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928476380572189, \"precision\": 1.0, \"recall\": 0.007152361942781104, \"specificity\": 1.0, \"npv\": 0.40271176264571973, \"accuracy\": 0.40527076171972304, \"f1\": 0.014203137902559868, \"f2\": 0.008924494624548586, \"f0_5\": 0.034767141009055626, \"p4\": 0.02772058115211205, \"phi\": 0.05366880178518562}, {\"truth_threshold\": 43.56, \"match_probability\": 0.9999999999999228, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 84, \"tn\": 8049, \"fp\": 0, \"fn\": 11940, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.006986027944111776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930139720558883, \"precision\": 1.0, \"recall\": 0.006986027944111776, \"specificity\": 1.0, \"npv\": 0.4026714693081195, \"accuracy\": 0.40517112539231803, \"f1\": 0.013875123885034688, \"f2\": 0.008717310087173101, \"f0_5\": 0.03398058252427184, \"p4\": 0.027095448300835795, \"phi\": 0.053038421327214015}, {\"truth_threshold\": 43.660000000000004, \"match_probability\": 0.9999999999999281, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 83, \"tn\": 8049, \"fp\": 0, \"fn\": 11941, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.006902860944777113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930971390552229, \"precision\": 1.0, \"recall\": 0.006902860944777113, \"specificity\": 1.0, \"npv\": 0.4026513256628314, \"accuracy\": 0.40512130722861556, \"f1\": 0.013711076236887752, \"f2\": 0.008613711368023413, \"f0_5\": 0.03358692133376497, \"p4\": 0.026782544343115732, \"phi\": 0.05272045248554577}, {\"truth_threshold\": 43.7, \"match_probability\": 0.9999999999999301, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 80, \"tn\": 8049, \"fp\": 0, \"fn\": 11944, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00665335994677312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9933466400532269, \"precision\": 1.0, \"recall\": 0.00665335994677312, \"specificity\": 1.0, \"npv\": 0.4025909068173861, \"accuracy\": 0.4049718527375081, \"f1\": 0.013218770654329148, \"f2\": 0.008302889405513119, \"f0_5\": 0.03240440699935191, \"p4\": 0.02584247918920305, \"phi\": 0.05175502115112954}, {\"truth_threshold\": 43.76, \"match_probability\": 0.9999999999999328, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 79, \"tn\": 8049, \"fp\": 0, \"fn\": 11945, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0065701929474384566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9934298070525616, \"precision\": 1.0, \"recall\": 0.0065701929474384566, \"specificity\": 1.0, \"npv\": 0.4025707712313694, \"accuracy\": 0.4049220345738056, \"f1\": 0.013054614558373957, \"f2\": 0.008199273482096522, \"f0_5\": 0.0320097244732577, \"p4\": 0.025528672166267447, \"phi\": 0.051429248895829734}, {\"truth_threshold\": 43.86, \"match_probability\": 0.9999999999999374, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 76, \"tn\": 8049, \"fp\": 0, \"fn\": 11948, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.006320691949434464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9936793080505656, \"precision\": 1.0, \"recall\": 0.006320691949434464, \"specificity\": 1.0, \"npv\": 0.4025103765564835, \"accuracy\": 0.4047725800826982, \"f1\": 0.01256198347107438, \"f2\": 0.007888399900357054, \"f0_5\": 0.03082414016872161, \"p4\": 0.024585891483330378, \"phi\": 0.050439509282549526}, {\"truth_threshold\": 43.9, \"match_probability\": 0.999999999999939, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 73, \"tn\": 8049, \"fp\": 0, \"fn\": 11951, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.006071190951430472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939288090485695, \"precision\": 1.0, \"recall\": 0.006071190951430472, \"specificity\": 1.0, \"npv\": 0.40245, \"accuracy\": 0.4046231255915907, \"f1\": 0.012069108043316524, \"f2\": 0.007577487595756607, \"f0_5\": 0.02963624553426437, \"p4\": 0.02364106580880626, \"phi\": 0.04943026196980139}, {\"truth_threshold\": 43.92, \"match_probability\": 0.9999999999999399, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 72, \"tn\": 8049, \"fp\": 0, \"fn\": 11952, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005988023952095809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940119760479041, \"precision\": 1.0, \"recall\": 0.005988023952095809, \"specificity\": 1.0, \"npv\": 0.4024298785060747, \"accuracy\": 0.4045733074278882, \"f1\": 0.011904761904761904, \"f2\": 0.007473841554559043, \"f0_5\": 0.029239766081871343, \"p4\": 0.023325668233013255, \"phi\": 0.04908930384038239}, {\"truth_threshold\": 44.02, \"match_probability\": 0.9999999999999439, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 71, \"tn\": 8049, \"fp\": 0, \"fn\": 11953, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005904856952761144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940951430472389, \"precision\": 1.0, \"recall\": 0.005904856952761144, \"specificity\": 1.0, \"npv\": 0.4024097590240976, \"accuracy\": 0.40452348926418574, \"f1\": 0.011740388590326582, \"f2\": 0.007370191209749414, \"f0_5\": 0.028843028924276894, \"p4\": 0.023010042370231777, \"phi\": 0.048745995357899696}, {\"truth_threshold\": 44.1, \"match_probability\": 0.9999999999999469, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 70, \"tn\": 8049, \"fp\": 0, \"fn\": 11954, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005821689953426481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941783100465735, \"precision\": 1.0, \"recall\": 0.005821689953426481, \"specificity\": 1.0, \"npv\": 0.40238964155376694, \"accuracy\": 0.4044736711004832, \"f1\": 0.01157598809326939, \"f2\": 0.007266536561059669, \"f0_5\": 0.028446033810143042, \"p4\": 0.022694187952931925, \"phi\": 0.048400286503247555}, {\"truth_threshold\": 44.24, \"match_probability\": 0.9999999999999518, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 68, \"tn\": 8049, \"fp\": 0, \"fn\": 11956, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005655355954757153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943446440452428, \"precision\": 1.0, \"recall\": 0.005655355954757153, \"specificity\": 1.0, \"npv\": 0.40234941264683827, \"accuracy\": 0.40437403477307826, \"f1\": 0.011247105524313596, \"f2\": 0.007059214350967528, \"f0_5\": 0.027651268705270005, \"p4\": 0.022061792382576596, \"phi\": 0.04770145853855351}, {\"truth_threshold\": 44.28, \"match_probability\": 0.9999999999999531, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 67, \"tn\": 8049, \"fp\": 0, \"fn\": 11957, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005572188955422488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9944278110445776, \"precision\": 1.0, \"recall\": 0.005572188955422488, \"specificity\": 1.0, \"npv\": 0.4023293012096371, \"accuracy\": 0.4043242166093758, \"f1\": 0.011082623438921512, \"f2\": 0.006955546789028923, \"f0_5\": 0.027253498210218028, \"p4\": 0.021745250692378027, \"phi\": 0.04734823004762889}, {\"truth_threshold\": 44.34, \"match_probability\": 0.999999999999955, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 66, \"tn\": 8049, \"fp\": 0, \"fn\": 11958, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0054890219560878245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945109780439122, \"precision\": 1.0, \"recall\": 0.0054890219560878245, \"specificity\": 1.0, \"npv\": 0.402309191782876, \"accuracy\": 0.4042743984456733, \"f1\": 0.010918114143920596, \"f2\": 0.006851874922137785, \"f0_5\": 0.02685546875, \"p4\": 0.021428479373373263, \"phi\": 0.04699238222129363}, {\"truth_threshold\": 44.36, \"match_probability\": 0.9999999999999557, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 65, \"tn\": 8049, \"fp\": 0, \"fn\": 11959, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00540585495675316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945941450432468, \"precision\": 1.0, \"recall\": 0.00540585495675316, \"specificity\": 1.0, \"npv\": 0.4022890843662535, \"accuracy\": 0.4042245802819708, \"f1\": 0.010753577632558525, \"f2\": 0.006748198750025955, \"f0_5\": 0.026457180071637904, \"p4\": 0.02111147815594425, \"phi\": 0.04663385509229321}, {\"truth_threshold\": 44.4, \"match_probability\": 0.9999999999999569, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 64, \"tn\": 8049, \"fp\": 0, \"fn\": 11960, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0053226879574184965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946773120425815, \"precision\": 1.0, \"recall\": 0.0053226879574184965, \"specificity\": 1.0, \"npv\": 0.4022689789594682, \"accuracy\": 0.4041747621182683, \"f1\": 0.010589013898080741, \"f2\": 0.006644518272425249, \"f0_5\": 0.026058631921824105, \"p4\": 0.020794246770052854, \"phi\": 0.04627258637628327}, {\"truth_threshold\": 44.480000000000004, \"match_probability\": 0.9999999999999593, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 63, \"tn\": 8049, \"fp\": 0, \"fn\": 11961, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005239520958083832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947604790419161, \"precision\": 1.0, \"recall\": 0.005239520958083832, \"specificity\": 1.0, \"npv\": 0.4022488755622189, \"accuracy\": 0.40412494395456583, \"f1\": 0.010424422933730455, \"f2\": 0.006540833489067464, \"f0_5\": 0.025659824046920823, \"p4\": 0.020476784945240054, \"phi\": 0.04590851134456335}, {\"truth_threshold\": 44.7, \"match_probability\": 0.999999999999965, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 62, \"tn\": 8049, \"fp\": 0, \"fn\": 11962, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005156353958749168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9948436460412509, \"precision\": 1.0, \"recall\": 0.005156353958749168, \"specificity\": 1.0, \"npv\": 0.40222877417420416, \"accuracy\": 0.40407512579086335, \"f1\": 0.010259804732748635, \"f2\": 0.006437144399684372, \"f0_5\": 0.02526075619295958, \"p4\": 0.020159092410625117, \"phi\": 0.04554156268768105}, {\"truth_threshold\": 44.72, \"match_probability\": 0.9999999999999655, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 61, \"tn\": 8049, \"fp\": 0, \"fn\": 11963, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.005073186959414504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949268130405855, \"precision\": 1.0, \"recall\": 0.005073186959414504, \"specificity\": 1.0, \"npv\": 0.4022086747951229, \"accuracy\": 0.4040253076271609, \"f1\": 0.010095159288374017, \"f2\": 0.006333451004007725, \"f0_5\": 0.024861428105640692, \"p4\": 0.01984116889490477, \"phi\": 0.045171670369093135}, {\"truth_threshold\": 44.76, \"match_probability\": 0.9999999999999665, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 60, \"tn\": 8049, \"fp\": 0, \"fn\": 11964, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00499001996007984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950099800399201, \"precision\": 1.0, \"recall\": 0.00499001996007984, \"specificity\": 1.0, \"npv\": 0.40218857742467395, \"accuracy\": 0.4039754894634584, \"f1\": 0.009930486593843098, \"f2\": 0.0062297533017692495, \"f0_5\": 0.02446183953033268, \"p4\": 0.019523014126352396, \"phi\": 0.044798761467983006}, {\"truth_threshold\": 44.84, \"match_probability\": 0.9999999999999682, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 58, \"tn\": 8049, \"fp\": 0, \"fn\": 11966, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004823685961410512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951763140385895, \"precision\": 1.0, \"recall\": 0.004823685961410512, \"specificity\": 1.0, \"npv\": 0.40214838870846864, \"accuracy\": 0.4038758531360534, \"f1\": 0.009601059427247144, \"f2\": 0.006022344976533621, \"f0_5\": 0.023661879895561358, \"p4\": 0.018886009741723272, \"phi\": 0.044043586786465264}, {\"truth_threshold\": 44.9, \"match_probability\": 0.9999999999999696, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 57, \"tn\": 8049, \"fp\": 0, \"fn\": 11967, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004740518962075849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952594810379242, \"precision\": 1.0, \"recall\": 0.004740518962075849, \"specificity\": 1.0, \"npv\": 0.4021282973621103, \"accuracy\": 0.4038260349723509, \"f1\": 0.009436304941643903, \"f2\": 0.005918634352999813, \"f0_5\": 0.0232615083251714, \"p4\": 0.01856715958006903, \"phi\": 0.0436611591558488}, {\"truth_threshold\": 44.94, \"match_probability\": 0.9999999999999704, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 56, \"tn\": 8049, \"fp\": 0, \"fn\": 11968, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004657351962741184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9953426480372588, \"precision\": 1.0, \"recall\": 0.004657351962741184, \"specificity\": 1.0, \"npv\": 0.4021082080231803, \"accuracy\": 0.40377621680864845, \"f1\": 0.009271523178807948, \"f2\": 0.005814919421830869, \"f0_5\": 0.022860875244937948, \"p4\": 0.018248077074426102, \"phi\": 0.04327539083441187}, {\"truth_threshold\": 45.0, \"match_probability\": 0.9999999999999716, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 54, \"tn\": 8049, \"fp\": 0, \"fn\": 11970, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004491017964071856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955089820359282, \"precision\": 1.0, \"recall\": 0.004491017964071856, \"specificity\": 1.0, \"npv\": 0.4020680353664019, \"accuracy\": 0.40367658048124344, \"f1\": 0.00894187779433681, \"f2\": 0.005607476635514018, \"f0_5\": 0.022058823529411766, \"p4\": 0.0176092139353224, \"phi\": 0.04249346737569893}, {\"truth_threshold\": 45.02, \"match_probability\": 0.999999999999972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 53, \"tn\": 8049, \"fp\": 0, \"fn\": 11971, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0044078509647371925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955921490352628, \"precision\": 1.0, \"recall\": 0.0044078509647371925, \"specificity\": 1.0, \"npv\": 0.4020479520479521, \"accuracy\": 0.40362676231754097, \"f1\": 0.008777014159145483, \"f2\": 0.00550374877982928, \"f0_5\": 0.02165740438051651, \"p4\": 0.01728943275286404, \"phi\": 0.04209711929936748}, {\"truth_threshold\": 45.06, \"match_probability\": 0.9999999999999727, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 52, \"tn\": 8049, \"fp\": 0, \"fn\": 11972, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004324683965402528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956753160345975, \"precision\": 1.0, \"recall\": 0.004324683965402528, \"specificity\": 1.0, \"npv\": 0.4020278707357275, \"accuracy\": 0.4035769441538385, \"f1\": 0.008612123219609143, \"f2\": 0.00540001661543574, \"f0_5\": 0.021255722694571617, \"p4\": 0.016969418128420125, \"phi\": 0.04169704409446455}, {\"truth_threshold\": 45.28, \"match_probability\": 0.9999999999999766, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 50, \"tn\": 8049, \"fp\": 0, \"fn\": 11974, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0041583499667332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958416500332667, \"precision\": 1.0, \"recall\": 0.0041583499667332, \"specificity\": 1.0, \"npv\": 0.40198771412875195, \"accuracy\": 0.40347730782643354, \"f1\": 0.008282259400364419, \"f2\": 0.005192539359448345, \"f0_5\": 0.02045157068062827, \"p4\": 0.016328687450846827, \"phi\": 0.04088527360400626}, {\"truth_threshold\": 45.300000000000004, \"match_probability\": 0.9999999999999769, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 49, \"tn\": 8049, \"fp\": 0, \"fn\": 11975, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.004075182967398536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9959248170326015, \"precision\": 1.0, \"recall\": 0.004075182967398536, \"specificity\": 1.0, \"npv\": 0.4019676388333999, \"accuracy\": 0.403427489662731, \"f1\": 0.008117286507081918, \"f2\": 0.005088794267317479, \"f0_5\": 0.020049099836333878, \"p4\": 0.016007970845272904, \"phi\": 0.04047334524374378}, {\"truth_threshold\": 45.34, \"match_probability\": 0.9999999999999776, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 48, \"tn\": 8049, \"fp\": 0, \"fn\": 11976, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003992015968063872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960079840319361, \"precision\": 1.0, \"recall\": 0.003992015968063872, \"specificity\": 1.0, \"npv\": 0.40194756554307115, \"accuracy\": 0.40337767149902853, \"f1\": 0.007952286282306162, \"f2\": 0.004985044865403789, \"f0_5\": 0.019646365422396856, \"p4\": 0.015687019692822664, \"phi\": 0.040057222819016546}, {\"truth_threshold\": 45.4, \"match_probability\": 0.9999999999999785, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 47, \"tn\": 8049, \"fp\": 0, \"fn\": 11977, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003908848968729208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960911510312708, \"precision\": 1.0, \"recall\": 0.003908848968729208, \"specificity\": 1.0, \"npv\": 0.40192749425746527, \"accuracy\": 0.40332785333532606, \"f1\": 0.00778725871924447, \"f2\": 0.004881291153438713, \"f0_5\": 0.019243367179823126, \"p4\": 0.0153658337161899, \"phi\": 0.03963677423091098}, {\"truth_threshold\": 45.42, \"match_probability\": 0.9999999999999788, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 46, \"tn\": 8049, \"fp\": 0, \"fn\": 11978, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0038256819693945443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961743180306054, \"precision\": 1.0, \"recall\": 0.0038256819693945443, \"specificity\": 1.0, \"npv\": 0.401907424976282, \"accuracy\": 0.4032780351716236, \"f1\": 0.007622203811101905, \"f2\": 0.00477753313115367, \"f0_5\": 0.01884010484927916, \"p4\": 0.015044412637633302, \"phi\": 0.0392118603116143}, {\"truth_threshold\": 45.5, \"match_probability\": 0.9999999999999799, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 45, \"tn\": 8049, \"fp\": 0, \"fn\": 11979, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0037425149700598802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962574850299402, \"precision\": 1.0, \"recall\": 0.0037425149700598802, \"specificity\": 1.0, \"npv\": 0.40188735769922107, \"accuracy\": 0.4032282170079211, \"f1\": 0.007457121551081283, \"f2\": 0.004673770798280052, \"f0_5\": 0.018436578171091445, \"p4\": 0.014722756178975597, \"phi\": 0.03878233428337115}, {\"truth_threshold\": 45.76, \"match_probability\": 0.9999999999999832, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 43, \"tn\": 8049, \"fp\": 0, \"fn\": 11981, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003576180971390552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964238190286094, \"precision\": 1.0, \"recall\": 0.003576180971390552, \"specificity\": 1.0, \"npv\": 0.4018472291562656, \"accuracy\": 0.4031285806805161, \"f1\": 0.007126874948205851, \"f2\": 0.004466233199692557, \"f0_5\": 0.017628730731387342, \"p4\": 0.014078736006462826, \"phi\": 0.03790881710518881}, {\"truth_threshold\": 45.78, \"match_probability\": 0.9999999999999835, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 42, \"tn\": 8049, \"fp\": 0, \"fn\": 11982, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003493013972055888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965069860279441, \"precision\": 1.0, \"recall\": 0.003493013972055888, \"specificity\": 1.0, \"npv\": 0.40182716788977085, \"accuracy\": 0.4030787625168136, \"f1\": 0.0069617105917454, \"f2\": 0.0043624579334413565, \"f0_5\": 0.0172244094488189, \"p4\": 0.013756371734065697, \"phi\": 0.03746448867648692}, {\"truth_threshold\": 45.82, \"match_probability\": 0.9999999999999839, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 41, \"tn\": 8049, \"fp\": 0, \"fn\": 11983, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003409846972721224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965901530272788, \"precision\": 1.0, \"recall\": 0.003409846972721224, \"specificity\": 1.0, \"npv\": 0.40180710862619806, \"accuracy\": 0.40302894435311115, \"f1\": 0.006796518856195607, \"f2\": 0.0042586783555269335, \"f0_5\": 0.016819822776501476, \"p4\": 0.01343377096448161, \"phi\": 0.03701487205120274}, {\"truth_threshold\": 45.980000000000004, \"match_probability\": 0.9999999999999856, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 40, \"tn\": 8049, \"fp\": 0, \"fn\": 11984, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00332667997338656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966733200266135, \"precision\": 1.0, \"recall\": 0.00332667997338656, \"specificity\": 1.0, \"npv\": 0.40178705136524734, \"accuracy\": 0.4029791261894087, \"f1\": 0.006631299734748011, \"f2\": 0.0041548944656805715, \"f0_5\": 0.016414970453053186, \"p4\": 0.013110933417340606, \"phi\": 0.03655977211831066}, {\"truth_threshold\": 46.0, \"match_probability\": 0.9999999999999858, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 39, \"tn\": 8049, \"fp\": 0, \"fn\": 11985, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.003243512974051896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967564870259481, \"precision\": 1.0, \"recall\": 0.003243512974051896, \"specificity\": 1.0, \"npv\": 0.40176699610661876, \"accuracy\": 0.40292930802570615, \"f1\": 0.006466053220591892, \"f2\": 0.0040511062636335304, \"f0_5\": 0.01600985221674877, \"p4\": 0.012787858811831601, \"phi\": 0.03609898148726187}, {\"truth_threshold\": 46.04, \"match_probability\": 0.9999999999999862, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 36, \"tn\": 8049, \"fp\": 0, \"fn\": 11988, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0029940119760479044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970059880239521, \"precision\": 1.0, \"recall\": 0.0029940119760479044, \"specificity\": 1.0, \"npv\": 0.4017068423416679, \"accuracy\": 0.4027798535345987, \"f1\": 0.005970149253731343, \"f2\": 0.0037397157816005983, \"f0_5\": 0.014792899408284023, \"p4\": 0.011817209830350586, \"phi\": 0.03468018305648546}, {\"truth_threshold\": 46.14, \"match_probability\": 0.9999999999999871, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 35, \"tn\": 8049, \"fp\": 0, \"fn\": 11989, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0029108449767132403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970891550232868, \"precision\": 1.0, \"recall\": 0.0029108449767132403, \"specificity\": 1.0, \"npv\": 0.40168679508933025, \"accuracy\": 0.40273003537089624, \"f1\": 0.005804793100588772, \"f2\": 0.0036359103280629947, \"f0_5\": 0.014386714896415654, \"p4\": 0.01149318417440576, \"phi\": 0.03419426837494579}, {\"truth_threshold\": 46.36, \"match_probability\": 0.9999999999999889, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 34, \"tn\": 8049, \"fp\": 0, \"fn\": 11990, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0028276779773785763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971723220226214, \"precision\": 1.0, \"recall\": 0.0028276779773785763, \"specificity\": 1.0, \"npv\": 0.40166674983781625, \"accuracy\": 0.40268021720719377, \"f1\": 0.005639409520650191, \"f2\": 0.0035321005609806775, \"f0_5\": 0.013980263157894737, \"p4\": 0.011168920049390145, \"phi\": 0.033701397934827904}, {\"truth_threshold\": 46.38, \"match_probability\": 0.9999999999999891, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 33, \"tn\": 8049, \"fp\": 0, \"fn\": 11991, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0027445109780439123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997255489021956, \"precision\": 1.0, \"recall\": 0.0027445109780439123, \"specificity\": 1.0, \"npv\": 0.40164670658682633, \"accuracy\": 0.40263039904349124, \"f1\": 0.005473998507091316, \"f2\": 0.0034282864800847723, \"f0_5\": 0.013573543928923988, \"p4\": 0.01084441717182759, \"phi\": 0.03320126195678}, {\"truth_threshold\": 46.800000000000004, \"match_probability\": 0.9999999999999918, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 32, \"tn\": 8049, \"fp\": 0, \"fn\": 11992, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0026613439787092482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973386560212908, \"precision\": 1.0, \"recall\": 0.0026613439787092482, \"specificity\": 1.0, \"npv\": 0.40162666533606106, \"accuracy\": 0.40258058087978876, \"f1\": 0.0053085600530856005, \"f2\": 0.003324468085106383, \"f0_5\": 0.013166556945358789, \"p4\": 0.010519675257794696, \"phi\": 0.03269352699665792}, {\"truth_threshold\": 46.82, \"match_probability\": 0.9999999999999919, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 31, \"tn\": 8049, \"fp\": 0, \"fn\": 11993, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.002578176979374584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974218230206254, \"precision\": 1.0, \"recall\": 0.002578176979374584, \"specificity\": 1.0, \"npv\": 0.401606626085221, \"accuracy\": 0.4025307627160863, \"f1\": 0.005143094151804231, \"f2\": 0.003220645375776591, \"f0_5\": 0.012759301942706618, \"p4\": 0.01019469402291993, \"phi\": 0.032177833335033816}, {\"truth_threshold\": 46.86, \"match_probability\": 0.9999999999999921, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 30, \"tn\": 8049, \"fp\": 0, \"fn\": 11994, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00249500998003992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975049900199601, \"precision\": 1.0, \"recall\": 0.00249500998003992, \"specificity\": 1.0, \"npv\": 0.4015865888340069, \"accuracy\": 0.4024809445523838, \"f1\": 0.004977600796416127, \"f2\": 0.0031168183518264555, \"f0_5\": 0.012351778656126482, \"p4\": 0.009869473182382751, \"phi\": 0.03165379198439004}, {\"truth_threshold\": 47.18, \"match_probability\": 0.9999999999999938, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 29, \"tn\": 8049, \"fp\": 0, \"fn\": 11995, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.002411842980705256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975881570192947, \"precision\": 1.0, \"recall\": 0.002411842980705256, \"specificity\": 1.0, \"npv\": 0.40156655358211935, \"accuracy\": 0.40243112638868134, \"f1\": 0.004812079980087945, \"f2\": 0.003012987012987013, \"f0_5\": 0.011943986820428337, \"p4\": 0.00954401245091271, \"phi\": 0.0311209812432551}, {\"truth_threshold\": 47.28, \"match_probability\": 0.9999999999999941, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 28, \"tn\": 8049, \"fp\": 0, \"fn\": 11996, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.002328675981370592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976713240186295, \"precision\": 1.0, \"recall\": 0.002328675981370592, \"specificity\": 1.0, \"npv\": 0.4015465203292592, \"accuracy\": 0.4023813082249788, \"f1\": 0.004646531695984069, \"f2\": 0.0029091513589892776, \"f0_5\": 0.011535926170072512, \"p4\": 0.009218311542788567, \"phi\": 0.030578942710526864}, {\"truth_threshold\": 47.36, \"match_probability\": 0.9999999999999944, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 27, \"tn\": 8049, \"fp\": 0, \"fn\": 11997, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.002245508982035928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977544910179641, \"precision\": 1.0, \"recall\": 0.002245508982035928, \"specificity\": 1.0, \"npv\": 0.4015264890751272, \"accuracy\": 0.40233149006127633, \"f1\": 0.004480955937266617, \"f2\": 0.0028053113895642415, \"f0_5\": 0.01112759643916914, \"p4\": 0.008892370171837404, \"phi\": 0.030027176652884784}, {\"truth_threshold\": 47.58, \"match_probability\": 0.9999999999999952, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 25, \"tn\": 8049, \"fp\": 0, \"fn\": 11999, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0020791749833666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979208250166334, \"precision\": 1.0, \"recall\": 0.0020791749833666, \"specificity\": 1.0, \"npv\": 0.40148643256185157, \"accuracy\": 0.4022318537338714, \"f1\": 0.004149721968628102, \"f2\": 0.002597618503356123, \"f0_5\": 0.010310128670405807, \"p4\": 0.008239764894498559, \"phi\": 0.028892222945694285}, {\"truth_threshold\": 47.7, \"match_probability\": 0.9999999999999957, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 24, \"tn\": 8049, \"fp\": 0, \"fn\": 12000, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.001996007984031936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998003992015968, \"precision\": 1.0, \"recall\": 0.001996007984031936, \"specificity\": 1.0, \"npv\": 0.4014664073021098, \"accuracy\": 0.4021820355701689, \"f1\": 0.00398406374501992, \"f2\": 0.0024937655860349127, \"f0_5\": 0.009900990099009901, \"p4\": 0.007913100413498575, \"phi\": 0.028307775509489055}, {\"truth_threshold\": 48.24, \"match_probability\": 0.999999999999997, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 23, \"tn\": 8049, \"fp\": 0, \"fn\": 12001, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0019128409846972721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980871590153028, \"precision\": 1.0, \"recall\": 0.0019128409846972721, \"specificity\": 1.0, \"npv\": 0.40144638403990024, \"accuracy\": 0.4021322174064664, \"f1\": 0.003818378019423923, \"f2\": 0.0023899083522101456, \"f0_5\": 0.009491581379993397, \"p4\": 0.007586194320445172, \"phi\": 0.027711064514919705}, {\"truth_threshold\": 48.34, \"match_probability\": 0.9999999999999972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 22, \"tn\": 8049, \"fp\": 0, \"fn\": 12002, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.001829673985362608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981703260146374, \"precision\": 1.0, \"recall\": 0.001829673985362608, \"specificity\": 1.0, \"npv\": 0.40142636277492394, \"accuracy\": 0.4020823992427639, \"f1\": 0.0036526647849908682, \"f2\": 0.002286046801612702, \"f0_5\": 0.009081902245706737, \"p4\": 0.007259046326893576, \"phi\": 0.027101279914572507}, {\"truth_threshold\": 48.38, \"match_probability\": 0.9999999999999972, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 20, \"tn\": 8049, \"fp\": 0, \"fn\": 12004, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00166333998669328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983366600133067, \"precision\": 1.0, \"recall\": 0.00166333998669328, \"specificity\": 1.0, \"npv\": 0.401386326235476, \"accuracy\": 0.40198276291535895, \"f1\": 0.0033211557622052474, \"f2\": 0.002078310749023194, \"f0_5\": 0.008261731658955718, \"p4\": 0.006604023482230447, \"phi\": 0.025838767899019125}, {\"truth_threshold\": 48.5, \"match_probability\": 0.9999999999999974, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 19, \"tn\": 8049, \"fp\": 0, \"fn\": 12005, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.001580172987358616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984198270126414, \"precision\": 1.0, \"recall\": 0.001580172987358616, \"specificity\": 1.0, \"npv\": 0.4013663109604069, \"accuracy\": 0.4019329447516565, \"f1\": 0.0031553599601428215, \"f2\": 0.0019744362464927776, \"f0_5\": 0.007851239669421488, \"p4\": 0.006276148051940377, \"phi\": 0.025183887758156276}, {\"truth_threshold\": 48.6, \"match_probability\": 0.9999999999999977, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 18, \"tn\": 8049, \"fp\": 0, \"fn\": 12006, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0014970059880239522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985029940119761, \"precision\": 1.0, \"recall\": 0.0014970059880239522, \"specificity\": 1.0, \"npv\": 0.4013462976813762, \"accuracy\": 0.40188312658795394, \"f1\": 0.0029895366218236174, \"f2\": 0.0018705574261129816, \"f0_5\": 0.00744047619047619, \"p4\": 0.005948029562793224, \"phi\": 0.024511585238418666}, {\"truth_threshold\": 49.08, \"match_probability\": 0.9999999999999983, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 16, \"tn\": 8049, \"fp\": 0, \"fn\": 12008, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0013306719893546241, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986693280106453, \"precision\": 1.0, \"recall\": 0.0013306719893546241, \"specificity\": 1.0, \"npv\": 0.4013062771102358, \"accuracy\": 0.401783490260549, \"f1\": 0.0026578073089701, \"f2\": 0.0016627868307283007, \"f0_5\": 0.0066181336863004635, \"p4\": 0.005291062244509163, \"phi\": 0.023108591954136358}, {\"truth_threshold\": 49.1, \"match_probability\": 0.9999999999999983, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 15, \"tn\": 8049, \"fp\": 0, \"fn\": 12009, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00124750499001996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987524950099801, \"precision\": 1.0, \"recall\": 0.00124750499001996, \"specificity\": 1.0, \"npv\": 0.4012862698175292, \"accuracy\": 0.4017336720968465, \"f1\": 0.0024919013207077, \"f2\": 0.001558895055184885, \"f0_5\": 0.006206554121151936, \"p4\": 0.004962212832508024, \"phi\": 0.022374240188749735}, {\"truth_threshold\": 49.24, \"match_probability\": 0.9999999999999984, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 14, \"tn\": 8049, \"fp\": 0, \"fn\": 12010, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.001164337990685296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988356620093147, \"precision\": 1.0, \"recall\": 0.001164337990685296, \"specificity\": 1.0, \"npv\": 0.40126626451966696, \"accuracy\": 0.40168385393314404, \"f1\": 0.0023259677687323477, \"f2\": 0.001454998960715028, \"f0_5\": 0.005794701986754967, \"p4\": 0.0046331191959195035, \"phi\": 0.021615030792497693}, {\"truth_threshold\": 49.28, \"match_probability\": 0.9999999999999986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 13, \"tn\": 8049, \"fp\": 0, \"fn\": 12011, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.001081170991350632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989188290086494, \"precision\": 1.0, \"recall\": 0.001081170991350632, \"specificity\": 1.0, \"npv\": 0.40124626121635093, \"accuracy\": 0.4016340357694415, \"f1\": 0.002160006646174296, \"f2\": 0.0013510985470494086, \"f0_5\": 0.005382577012255714, \"p4\": 0.0043037810421523714, \"phi\": 0.020828245677805342}, {\"truth_threshold\": 49.34, \"match_probability\": 0.9999999999999986, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 12, \"tn\": 8049, \"fp\": 0, \"fn\": 12012, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.000998003992015968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999001996007984, \"precision\": 1.0, \"recall\": 0.000998003992015968, \"specificity\": 1.0, \"npv\": 0.4012262599072828, \"accuracy\": 0.40158421760573904, \"f1\": 0.0019940179461615153, \"f2\": 0.001247193813918683, \"f0_5\": 0.004970178926441352, \"p4\": 0.003974198078150095, \"phi\": 0.020010632401028825}, {\"truth_threshold\": 49.44, \"match_probability\": 0.9999999999999987, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 11, \"tn\": 8049, \"fp\": 0, \"fn\": 12013, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.000914836992681304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990851630073186, \"precision\": 1.0, \"recall\": 0.000914836992681304, \"specificity\": 1.0, \"npv\": 0.4012062605921643, \"accuracy\": 0.40153439944203656, \"f1\": 0.0018280016618196925, \"f2\": 0.001143284761053485, \"f0_5\": 0.004557507457739476, \"p4\": 0.003644370010389906, \"phi\": 0.01915824441030668}, {\"truth_threshold\": 49.78, \"match_probability\": 0.999999999999999, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 8, \"tn\": 8049, \"fp\": 0, \"fn\": 12016, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.0006653359946773121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993346640053227, \"precision\": 1.0, \"recall\": 0.0006653359946773121, \"specificity\": 1.0, \"npv\": 0.40114627460752555, \"accuracy\": 0.40138494495092913, \"f1\": 0.0013297872340425532, \"f2\": 0.0008315316813570597, \"f0_5\": 0.0033178500331785005, \"p4\": 0.0026534122423212494, \"phi\": 0.016336984288022566}, {\"truth_threshold\": 50.120000000000005, \"match_probability\": 0.9999999999999992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 7, \"tn\": 8049, \"fp\": 0, \"fn\": 12017, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.000582168995342648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994178310046573, \"precision\": 1.0, \"recall\": 0.000582168995342648, \"specificity\": 1.0, \"npv\": 0.40112628326522476, \"accuracy\": 0.4013351267872266, \"f1\": 0.0011636605435957112, \"f2\": 0.0007276053468598632, \"f0_5\": 0.0029040823099900433, \"p4\": 0.0023226008149446167, \"phi\": 0.015281468690346696}, {\"truth_threshold\": 50.22, \"match_probability\": 0.9999999999999992, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 6, \"tn\": 8049, \"fp\": 0, \"fn\": 12018, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.000499001996007984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995009980039921, \"precision\": 1.0, \"recall\": 0.000499001996007984, \"specificity\": 1.0, \"npv\": 0.40110629391538344, \"accuracy\": 0.40128530862352413, \"f1\": 0.000997506234413965, \"f2\": 0.0006236746912810278, \"f0_5\": 0.00249003984063745, \"p4\": 0.001991542809170227, \"phi\": 0.014147538346834104}, {\"truth_threshold\": 50.76, \"match_probability\": 0.9999999999999994, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 5, \"tn\": 8049, \"fp\": 0, \"fn\": 12019, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00041583499667332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995841650033267, \"precision\": 1.0, \"recall\": 0.00041583499667332, \"specificity\": 1.0, \"npv\": 0.40108630655770383, \"accuracy\": 0.40123549045982165, \"f1\": 0.0008313242996092775, \"f2\": 0.000519739714351053, \"f0_5\": 0.0020757223513782797, \"p4\": 0.0016602379286583654, \"phi\": 0.012914554694341458}, {\"truth_threshold\": 52.26, \"match_probability\": 0.9999999999999998, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 4, \"tn\": 8049, \"fp\": 0, \"fn\": 12020, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00033266799733865603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996673320026613, \"precision\": 1.0, \"recall\": 0.00033266799733865603, \"specificity\": 1.0, \"npv\": 0.401066321191888, \"accuracy\": 0.4011856722961192, \"f1\": 0.0006651147322913202, \"f2\": 0.0004158004158004158, \"f0_5\": 0.0016611295681063123, \"p4\": 0.0013286858765965454, \"phi\": 0.011550841089327113}, {\"truth_threshold\": 53.78, \"match_probability\": 1.0, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 3, \"tn\": 8049, \"fp\": 0, \"fn\": 12021, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.000249500998003992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999750499001996, \"precision\": 1.0, \"recall\": 0.000249500998003992, \"specificity\": 1.0, \"npv\": 0.40104633781763827, \"accuracy\": 0.4011358541324167, \"f1\": 0.0004988775255674732, \"f2\": 0.0003118567953595709, \"f0_5\": 0.0012462612163509472, \"p4\": 0.0009968863556985635, \"phi\": 0.010003072604522417}, {\"truth_threshold\": 55.660000000000004, \"match_probability\": 1.0, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 2, \"tn\": 8049, \"fp\": 0, \"fn\": 12022, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 0.00016633399866932801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998336660013307, \"precision\": 1.0, \"recall\": 0.00016633399866932801, \"specificity\": 1.0, \"npv\": 0.40102635643465695, \"accuracy\": 0.40108603596871417, \"f1\": 0.0003326126725428239, \"f2\": 0.00020790885275895048, \"f0_5\": 0.0008311170212765958, \"p4\": 0.0006648390682035553, \"phi\": 0.008167271113264681}, {\"truth_threshold\": 56.82, \"match_probability\": 1.0, \"row_count\": 20073, \"p\": 12024, \"n\": 8049, \"tp\": 1, \"tn\": 8049, \"fp\": 0, \"fn\": 12023, \"P_rate\": 0, \"N_rate\": 0.4009863996413092, \"tp_rate\": 8.316699933466401e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999168330006654, \"precision\": 1.0, \"recall\": 8.316699933466401e-05, \"specificity\": 1.0, \"npv\": 0.40100637704264647, \"accuracy\": 0.4010362178050117, \"f1\": 0.00016632016632016632, \"f2\": 0.00010395658772896438, \"f0_5\": 0.00041569670768207517, \"p4\": 0.0003325437158750458, \"phi\": 0.0057749889257644295}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.roc_chart_from_labels_column(\"cluster\",match_weight_round_to_nearest=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92.vega-embed details,\n",
       "  #altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2bba0ad37b524e8f9aeb8c9d6173bd92\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-d3d6e59fac9c9c0c0fb88d54cfb5178e\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 1, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-d3d6e59fac9c9c0c0fb88d54cfb5178e\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7335637333544217, \"bayes_factor\": 0.601416463485429, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.66 times less likely to be a match\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 8.378994717855353, \"bayes_factor\": 332.9114586242343, \"comparison_vector_value\": 3, \"m_probability\": 0.623315558644858, \"u_probability\": 0.001872316324648982, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 332.91 times more likely to be a match\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Term freq adjustment on dob with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 1.2650948187931816, \"bayes_factor\": 2.403430055407743, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on dob makes comparison 2.40 times more likely to be a match\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 7.329277578014943, \"bayes_factor\": 160.8171634211113, \"comparison_vector_value\": 1, \"m_probability\": 0.8305787965393059, \"u_probability\": 0.005164739750845969, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 160.82 times more likely to be a match\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 0.9566658592622518, \"bayes_factor\": 1.940819376807031, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.94 times more likely to be a match\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.846778747080837, \"bayes_factor\": 3683.288651009507, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.0701518032093222, \"bayes_factor\": 0.4762688824369195, \"comparison_vector_value\": 0, \"m_probability\": 0.3252259699421662, \"u_probability\": 0.6828621015046925, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.10 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"will\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.3252259699421662, \"u_probability\": 0.6828621015046925, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.10 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7335637333544217, \"bayes_factor\": 0.601416463485429, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.66 times less likely to be a match\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 8.378994717855353, \"bayes_factor\": 332.9114586242343, \"comparison_vector_value\": 3, \"m_probability\": 0.623315558644858, \"u_probability\": 0.001872316324648982, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 332.91 times more likely to be a match\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Term freq adjustment on dob with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"log2_bayes_factor\": 1.2650948187931816, \"bayes_factor\": 2.403430055407743, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on dob makes comparison 2.40 times more likely to be a match\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.42539448385424, \"bayes_factor\": 21.487034556570954, \"comparison_vector_value\": 1, \"m_probability\": 0.9139268395242015, \"u_probability\": 0.04253387488711016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 21.49 times more likely to be a match\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 0.584599764632281, \"bayes_factor\": 1.499622903162684, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 1.50 times more likely to be a match\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.042288935162706, \"bayes_factor\": 1054.460205879654, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.999,\n",
    "    include_false_negatives=False,\n",
    "    include_false_positives=True,\n",
    ").as_record_dict()\n",
    "linker.waterfall_chart(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cf2e4c02c04543caa55b2f44a314fc79.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cf2e4c02c04543caa55b2f44a314fc79.vega-embed details,\n",
       "  #altair-viz-cf2e4c02c04543caa55b2f44a314fc79.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cf2e4c02c04543caa55b2f44a314fc79\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cf2e4c02c04543caa55b2f44a314fc79\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cf2e4c02c04543caa55b2f44a314fc79\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-fbc1b7d91e66fa2bfc1c3064ba6a370b\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 49, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-fbc1b7d91e66fa2bfc1c3064ba6a370b\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"sunderland\", \"value_r\": \"sunderland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5294706724793722, \"bayes_factor\": 1.4433995123650296, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.44 times more likely to be a match\", \"value_l\": \"sunderland\", \"value_r\": \"sunderland\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1610-12-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"nn6 udr\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"althorp\", \"value_r\": \"west northamptonshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.3048752696989704, \"bayes_factor\": 0.8095122010784475, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.6244067383226173, \"bayes_factor\": 0.6486864738197896, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.54 times less likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"richardson\", \"value_r\": \"richardson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.470529327520628, \"bayes_factor\": 0.3608498780912574, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.77 times less likely to be a match\", \"value_l\": \"richardson\", \"value_r\": \"richardson\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1818-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ne8 2jr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"newcastle upon tyne\", \"value_r\": \"gateshead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.9215466301474646, \"bayes_factor\": 0.2639713699168851, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.1669339727233767, \"bayes_factor\": 0.4453668327717959, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.25 times less likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.04404384530913053, \"bayes_factor\": 1.030999651689307, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.03 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1860-16-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"dt6 5lb\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"symondsbury\", \"value_r\": \"dorset\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 2}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 2}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"printmaker\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -4.425086789021886, \"bayes_factor\": 0.04654962032650391, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"tn5 6qh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"wadhurst\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 3}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 3}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.6040296576067767, \"bayes_factor\": 0.16447843439646553, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"tn5 6qh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"wadhurst\", \"value_r\": \"wealden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 4}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 4}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.157872857312287, \"bayes_factor\": 0.028010802805482606, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"marie\", \"value_r\": \"marie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.8991552177343958, \"bayes_factor\": 7.459894448927582, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 7.46 times more likely to be a match\", \"value_l\": \"marie\", \"value_r\": \"marie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wight\", \"value_r\": \"wight\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.055491828241784, \"bayes_factor\": 0.4811331707883432, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.08 times less likely to be a match\", \"value_l\": \"wight\", \"value_r\": \"wight\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.0859225980401308, \"bayes_factor\": 0.47109091074943404, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"1861-12-15\", \"value_r\": \"1861-15-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 5}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"cm19 5fz\", \"value_r\": \"e16 2hj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"woolwich\", \"value_r\": \"newham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 5}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 5}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.5331884096209878, \"bayes_factor\": 0.3455129262185492, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"spender\", \"value_r\": \"spender\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2664362666455782, \"bayes_factor\": 2.405665853941716, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.41 times more likely to be a match\", \"value_l\": \"spender\", \"value_r\": \"spender\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1862-12-23\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 6}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ba2 6an\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"bath and north east somerset\", \"value_r\": \"bath\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 6}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 6}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.6694477019948263, \"bayes_factor\": 0.6287473406434544, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.1669339727233767, \"bayes_factor\": 0.4453668327717959, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.25 times less likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"burney\", \"value_r\": \"burney\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"burney\", \"value_r\": \"burney\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1726-04-07\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 7}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"sy3 7ar\", \"value_r\": \"tf3 3at\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"shrewsbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 7}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 7}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"historian\", \"value_r\": \"composer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.528207304028022, \"bayes_factor\": 0.08667697986969226, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 4.097648583892912, \"bayes_factor\": 17.120448415261805, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"1846-09-17\", \"value_r\": \"1846-06-17\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 8}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ne5 1ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"newcastle upon tyne\", \"value_r\": \"woolsington\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 8}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 8}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.060224273419375, \"bayes_factor\": 0.47955750450133555, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.3445663660567584, \"bayes_factor\": 2.539538535805134, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.54 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.5409186554120258, \"bayes_factor\": 0.3436665505631023, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.91 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1677-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 9}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ne26 4pu\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"northumberland\", \"value_r\": \"seaton valley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 9}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 9}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"poet\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.4985489509629075, \"bayes_factor\": 0.0884772925354826, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"griffiths\", \"value_r\": \"griffiths\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7335637333544217, \"bayes_factor\": 0.601416463485429, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.66 times less likely to be a match\", \"value_l\": \"griffiths\", \"value_r\": \"griffiths\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1859-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 10}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sa9 2rs\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"cwmllynfell\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 10}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 10}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.14334949277222034, \"bayes_factor\": 0.9054146198205437, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"walter\", \"value_r\": \"walter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.5416032131163119, \"bayes_factor\": 1.4555891607663571, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.46 times more likely to be a match\", \"value_l\": \"walter\", \"value_r\": \"walter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bryant\", \"value_r\": \"bryant\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.04404384530913053, \"bayes_factor\": 1.030999651689307, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.03 times more likely to be a match\", \"value_l\": \"bryant\", \"value_r\": \"bryant\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1843-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 11}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"s64 5wh\", \"value_r\": \"s80 3fy\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"sheffield\", \"value_r\": \"bradfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 11}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 11}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.7052821426480267, \"bayes_factor\": 0.30666126581480635, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.6244067383226173, \"bayes_factor\": 0.6486864738197896, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.54 times less likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"richardson\", \"value_r\": \"richardson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.470529327520628, \"bayes_factor\": 0.3608498780912574, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.77 times less likely to be a match\", \"value_l\": \"richardson\", \"value_r\": \"richardson\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1818-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 12}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ne61 4ps\", \"value_r\": \"ne8 2jr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"newcastle upon tyne\", \"value_r\": \"gateshead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 12}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 12}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.42539448385424, \"bayes_factor\": 21.487034556570954, \"comparison_vector_value\": 1, \"m_probability\": 0.9139268395242015, \"u_probability\": 0.04253387488711016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 21.49 times more likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.2286317237619924, \"bayes_factor\": 0.42672196431458487, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.34 times less likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.1891025068244663, \"bayes_factor\": 0.43857561144623003, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"carter\", \"value_r\": \"carter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.396528746076851, \"bayes_factor\": 0.3798419769381657, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.63 times less likely to be a match\", \"value_l\": \"carter\", \"value_r\": \"carter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1822-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 13}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"rg26 5qn\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"pamber\", \"value_r\": \"basingstoke and deane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 13}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 13}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.42539448385424, \"bayes_factor\": 21.487034556570954, \"comparison_vector_value\": 1, \"m_probability\": 0.9139268395242015, \"u_probability\": 0.04253387488711016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 21.49 times more likely to be a match\", \"value_l\": \"cricketer\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.5340447318663377, \"bayes_factor\": 0.3453079053335128, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.90 times less likely to be a match\", \"value_l\": \"cricketer\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.46880795321225716, \"bayes_factor\": 0.7225613775386431, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.2301277992105708, \"bayes_factor\": 0.42627968279586176, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"andrews\", \"value_r\": \"andrews\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.4705293275206278, \"bayes_factor\": 0.7216997561825148, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"value_l\": \"andrews\", \"value_r\": \"andrews\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1101-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 14}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"le3 1js\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"leicester\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 14}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 14}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"canon\", \"value_r\": \"monk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.449010588633329, \"bayes_factor\": 0.1831362651962839, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"roach\", \"value_r\": \"roach\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5294706724793722, \"bayes_factor\": 1.4433995123650296, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.44 times more likely to be a match\", \"value_l\": \"roach\", \"value_r\": \"roach\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1862-21-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 15}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"le8 0xb\", \"value_r\": \"le17 6qu\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"harborough\", \"value_r\": \"kibworth beauchamp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 15}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 15}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.8707319329302816, \"bayes_factor\": 0.06835866663211607, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.12321259529405881, \"bayes_factor\": 0.9181408552526253, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.09 times less likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.236064073883605, \"bayes_factor\": 0.42452926834265575, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.36 times less likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1558-11-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 16}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sw1a 2ad\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 16}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 16}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"playwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.1858872334818835, \"bayes_factor\": 0.43955413633218865, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.12321259529405881, \"bayes_factor\": 0.9181408552526253, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.09 times less likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.236064073883605, \"bayes_factor\": 0.42452926834265575, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.36 times less likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1558-11-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 17}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sw1a 2ad\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 17}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 17}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.1858872334818835, \"bayes_factor\": 0.43955413633218865, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.12321259529405881, \"bayes_factor\": 0.9181408552526253, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.09 times less likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.236064073883605, \"bayes_factor\": 0.42452926834265575, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.36 times less likely to be a match\", \"value_l\": \"kidd\", \"value_r\": \"kidd\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1558-11-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 18}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sw1a 2ad\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 18}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 18}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.1858872334818835, \"bayes_factor\": 0.43955413633218865, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"cozens\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"cozens\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 19}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"w1t 2ra\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 19}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 19}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.08448520127367, \"bayes_factor\": 0.4715605054825908, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1846-05-29\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 20}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"nw3 5dd\", \"value_r\": \"ox14 3en\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"hampstead\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 20}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 20}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"botanist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.6171908130231696, \"bayes_factor\": 0.08149239193411985, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.2301277992105708, \"bayes_factor\": 0.42627968279586176, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"hoccleve\", \"value_r\": \"hoccleve\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"hoccleve\", \"value_r\": \"hoccleve\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1369-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 21}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"w1d 3bs\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 21}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 21}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"poet\", \"value_r\": \"clerk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.1270824937459665, \"bayes_factor\": 0.4578406629907098, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.8490409507743577, \"bayes_factor\": 0.2775768293009672, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.60 times less likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.0859225980401308, \"bayes_factor\": 0.47109091074943404, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"1858-03-28\", \"value_r\": \"1828-03-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 22}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"sa32 8bt\", \"value_r\": \"sa18 2ga\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"carmarthenshire\", \"value_r\": \"llandybie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 22}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 22}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"auctioneer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -7.362911144707047, \"bayes_factor\": 0.006074952548897567, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 4.097648583892912, \"bayes_factor\": 17.120448415261805, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"1857-02-16\", \"value_r\": \"1857-02-76\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 23}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ol1 3ju\", \"value_r\": \"ol7 9hz\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"oldham\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 23}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 23}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"barrister\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -4.446285807786535, \"bayes_factor\": 0.04587061919148022, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1846-05-29\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 24}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ox14 3en\", \"value_r\": \"nw3 5ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"hampstead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 24}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 24}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"botanist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.6171908130231696, \"bayes_factor\": 0.08149239193411985, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1846-05-29\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 25}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ox14 3en\", \"value_r\": \"nw3 5dd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"hampstead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 25}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 25}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"botanist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.6171908130231696, \"bayes_factor\": 0.08149239193411985, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1846-05-29\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 26}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ox14 3en\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"hampstead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 26}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 26}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"botanist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.15287217625392, \"bayes_factor\": 0.4497290005991376, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0077353778741227, \"bayes_factor\": 0.4973262965951721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.01 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"wickham\", \"value_r\": \"wickham\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1876-05-29\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 27}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ox14 3en\", \"value_r\": \"nw3 5dd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"hampstead\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 27}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 27}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.6171908130231696, \"bayes_factor\": 0.08149239193411985, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"white\", \"value_r\": \"white\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.4705293275206278, \"bayes_factor\": 0.7216997561825148, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"value_l\": \"white\", \"value_r\": \"white\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1855-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 28}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"ng6 7al\", \"value_r\": \"ng6 9en\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"nottingham\", \"value_r\": \"bulwell\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 28}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 28}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.42539448385424, \"bayes_factor\": 21.487034556570954, \"comparison_vector_value\": 1, \"m_probability\": 0.9139268395242015, \"u_probability\": 0.04253387488711016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 21.49 times more likely to be a match\", \"value_l\": \"cricketer\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.5340447318663377, \"bayes_factor\": 0.3453079053335128, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.90 times less likely to be a match\", \"value_l\": \"cricketer\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.979382180942379, \"bayes_factor\": 0.2535984475792305, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"james\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.117653069952158, \"bayes_factor\": 0.4608429003198506, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.17 times less likely to be a match\", \"value_l\": \"james\", \"value_r\": \"james\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"wolfe-murray\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"wolfe-murray\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1853-03-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 29}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"bl6 6br\", \"value_r\": \"st7 3sw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ireland\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 29}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 29}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"military personnel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.0033403039533826027, \"bayes_factor\": 0.9976873560236663, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bladensburg\", \"value_r\": \"bladensburg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"bladensburg\", \"value_r\": \"bladensburg\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1848-01-81\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 30}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ca8 2ay\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"carlisle\", \"value_r\": \"walton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 30}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 30}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.07041001606194751, \"bayes_factor\": 0.9523672953864087, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.2301277992105708, \"bayes_factor\": 0.42627968279586176, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"ackroyd\", \"value_r\": \"ackroyd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"ackroyd\", \"value_r\": \"ackroyd\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1861-08-07\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 31}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"kt24 5pj\", \"value_r\": \"gu11 3ru\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"rushmoor\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 31}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 31}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.11581503321179519, \"bayes_factor\": 0.9228608043218913, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.1669339727233767, \"bayes_factor\": 0.4453668327717959, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.25 times less likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"rothesay\", \"value_r\": \"rothesay\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5294706724793722, \"bayes_factor\": 1.4433995123650296, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.44 times more likely to be a match\", \"value_l\": \"rothesay\", \"value_r\": \"rothesay\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1779-01-02\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 32}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"pl15 8ls\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"north petherwin\", \"value_r\": \"cornwall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 32}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 32}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.46407386454822425, \"bayes_factor\": 0.7249362994732366, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.12321259529405881, \"bayes_factor\": 0.9181408552526253, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.09 times less likely to be a match\", \"value_l\": \"tom\", \"value_r\": \"tom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"vicars\", \"value_r\": \"vicars\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"vicars\", \"value_r\": \"vicars\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1589-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 33}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"rh17 5ed\", \"value_r\": \"rh13 9hg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"mid sussex\", \"value_r\": \"cuckfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 33}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 33}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.5627430290007933, \"bayes_factor\": 0.33850685880326703, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"robertson\", \"value_r\": \"robertson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.396528746076851, \"bayes_factor\": 0.3798419769381657, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.63 times less likely to be a match\", \"value_l\": \"robertson\", \"value_r\": \"robertson\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1860-01-29\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 34}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ln5 0qq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"welbourn\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 34}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 34}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.8063145054946497, \"bayes_factor\": 0.5718408125182382, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bladensburg\", \"value_r\": \"bladensburg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"bladensburg\", \"value_r\": \"bladensburg\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1848-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 35}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ca8 2ay\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"walton\", \"value_r\": \"carlisle\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 35}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 35}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"police officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.07041001606194751, \"bayes_factor\": 0.9523672953864087, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"carter\", \"value_r\": \"carter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.396528746076851, \"bayes_factor\": 0.3798419769381657, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.63 times less likely to be a match\", \"value_l\": \"carter\", \"value_r\": \"carter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 36}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"rg26 5qn\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"pamber\", \"value_r\": \"basingstoke and deane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 36}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 36}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.3601577052001597, \"bayes_factor\": 0.09738492644552754, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.1669339727233767, \"bayes_factor\": 0.4453668327717959, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.25 times less likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.04404384530913053, \"bayes_factor\": 1.030999651689307, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.03 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 4.097648583892912, \"bayes_factor\": 17.120448415261805, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"1860-86-01\", \"value_r\": \"1860-06-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3400321931109991, \"u_probability\": 0.01986117330944917, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 17.12 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 37}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"dt6 5lb\", \"value_r\": \"dt6 3je\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"bridport\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 37}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 37}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"printmaker\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.23791364219271346, \"bayes_factor\": 0.8479707215141444, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"ross\", \"value_r\": \"ross\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.04404384530913053, \"bayes_factor\": 1.030999651689307, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.03 times more likely to be a match\", \"value_l\": \"ross\", \"value_r\": \"ross\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1852-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 38}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"pl19 0pg\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"west devon\", \"value_r\": \"stowford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 38}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 38}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.9195851138141784, \"bayes_factor\": 0.26433051463786045, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"cozens\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"cozens\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1752-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 39}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"w1t 2rf\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"camden\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 39}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 39}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.08448520127367, \"bayes_factor\": 0.4715605054825908, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"albert\", \"value_r\": \"albert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.8547610983759424, \"bayes_factor\": 3.6169185206921606, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 3.62 times more likely to be a match\", \"value_l\": \"albert\", \"value_r\": \"albert\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"clarke\", \"value_r\": \"clarke\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.236064073883605, \"bayes_factor\": 0.42452926834265575, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.36 times less likely to be a match\", \"value_l\": \"clarke\", \"value_r\": \"clarke\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.0859225980401308, \"bayes_factor\": 0.47109091074943404, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"1859-02-31\", \"value_r\": \"1859-01-21\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036370058692935366, \"u_probability\": 0.07720390664102632, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 40}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sp1 3gb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"wiltshire\", \"value_r\": \"salisbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 40}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 40}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"university teacher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.2938361378520131, \"bayes_factor\": 0.815730139184652, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.109273404336185, \"bayes_factor\": 0.23176371103464333, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.31 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"timbs\", \"value_r\": \"timbs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.8513987673667346, \"bayes_factor\": 1.804249390456287, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.80 times more likely to be a match\", \"value_l\": \"timbs\", \"value_r\": \"timbs\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1801-08-17\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 41}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ec2y 9ht\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"clerkenwell\", \"value_r\": \"city of london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 41}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 41}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.08448520127367, \"bayes_factor\": 0.4715605054825908, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 42}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"wealden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 42}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 42}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.6040296576067767, \"bayes_factor\": 0.16447843439646553, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.236064073883605, \"bayes_factor\": 0.05306615854283197, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  18.84 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 43}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"tn5 6qg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"wealden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 43}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 43}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.6040296576067767, \"bayes_factor\": 0.16447843439646553, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0951982191244622, \"bayes_factor\": 0.46807180856016195, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.14 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"leveson\", \"value_r\": \"leveson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2664362666455782, \"bayes_factor\": 2.405665853941716, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.41 times more likely to be a match\", \"value_l\": \"leveson\", \"value_r\": \"leveson\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1858-05-19\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 44}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4643186367692493, \"bayes_factor\": 0.18120332872808764, \"comparison_vector_value\": 0, \"m_probability\": 0.18106239754224004, \"u_probability\": 0.9992222483613472, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.52 times less likely to be a match\", \"value_l\": \"br6 7qj\", \"value_r\": \"tn14 7ax\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"shoreham\", \"value_r\": \"sevenoaks\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 44}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 44}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.119691153552353, \"bayes_factor\": 0.23009616546104422, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"arthur\", \"value_r\": \"arthur\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.29066934114562143, \"bayes_factor\": 0.8175226793345295, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.22 times less likely to be a match\", \"value_l\": \"arthur\", \"value_r\": \"arthur\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"dorward\", \"value_r\": \"dorward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5294706724793722, \"bayes_factor\": 1.4433995123650296, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.44 times more likely to be a match\", \"value_l\": \"dorward\", \"value_r\": \"dorward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1848-07-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 45}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ooty\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 45}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 45}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.4755860973034207, \"bayes_factor\": 0.08989682059576795, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"military personnel\", \"value_r\": \"engineer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.08607316047579858, \"u_probability\": 0.9574661251128899, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  11.12 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.5095521305683796, \"bayes_factor\": 0.7024404692460205, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.1370183948190893, \"bayes_factor\": 0.22734916415779297, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.40 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.8490409507743577, \"bayes_factor\": 0.2775768293009672, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.60 times less likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1861-07-27\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 46}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sa31 1lw\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"carmarthenshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 46}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 46}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.2588267101921562, \"bayes_factor\": 0.4178836706864048, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"1st\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.7698722007894292, \"bayes_factor\": 3.410237462366894, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 3.41 times more likely to be a match\", \"value_l\": \"1st\", \"value_r\": \"1st\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"bt.\", \"value_r\": \"bt.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.0065822277608376, \"bayes_factor\": 0.24886198489052233, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.02 times less likely to be a match\", \"value_l\": \"bt.\", \"value_r\": \"bt.\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1602-08-23\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 47}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"london\", \"value_r\": \"westminster\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 47}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 47}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.06332059127562824, \"bayes_factor\": 0.9570587598957013, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.6244067383226173, \"bayes_factor\": 0.6486864738197896, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.54 times less likely to be a match\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"holmes\", \"value_r\": \"holmes\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.04404384530913053, \"bayes_factor\": 1.030999651689307, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.03 times more likely to be a match\", \"value_l\": \"holmes\", \"value_r\": \"holmes\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1843-81-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 48}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"hp22 5rx\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"wendover\", \"value_r\": \"buckinghamshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 48}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 48}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"bryologist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.40697345731770634, \"bayes_factor\": 0.754203914048243, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.763631440366042, \"bayes_factor\": 0.00014380172073279066, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.535311948809896, \"bayes_factor\": 46.376175616965774, \"comparison_vector_value\": 3, \"m_probability\": 0.5545919247329825, \"u_probability\": 0.011958552367782918, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 46.38 times more likely to be a match\", \"value_l\": \"frederick\", \"value_r\": \"frederick\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.05366516679002077, \"bayes_factor\": 1.0378983581116636, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.04 times more likely to be a match\", \"value_l\": \"frederick\", \"value_r\": \"frederick\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.955552126957437, \"bayes_factor\": 992.9327003879175, \"comparison_vector_value\": 3, \"m_probability\": 0.7905121762554949, \"u_probability\": 0.0007961387271732099, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 992.93 times more likely to be a match\", \"value_l\": \"stanley\", \"value_r\": \"stanley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.31852623407557773, \"bayes_factor\": 0.8018886179805721, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"value_l\": \"stanley\", \"value_r\": \"stanley\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1841-01-15\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 49}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.55384319970551, \"bayes_factor\": 0.1703007625787842, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"london\", \"value_r\": \"westminster\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 49}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.16942120346069417, \"u_probability\": 0.994835260249154, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 49}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.09147163158977659, \"bayes_factor\": 0.9385648708155916, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 49}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the false negatives will be because they weren't detected by the blocking rules\n",
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.5,\n",
    "    include_false_negatives=True,\n",
    "    include_false_positives=False,\n",
    ").as_record_dict(limit=50)\n",
    "\n",
    "linker.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
