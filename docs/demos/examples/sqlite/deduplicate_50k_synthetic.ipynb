{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking a dataset of real historical persons \n",
    "\n",
    "In this example, we deduplicate a more realistic dataset.  The data is based on historical persons scraped from wikidata.  Duplicate records are introduced with a variety of errors introduced.\n",
    "\n",
    "Note, as explained in the [backends topic guide](https://moj-analytical-services.github.io/splink/topic_guides/backends.html#sqlite), SQLite does not natively support string fuzzy matching functions such as `damareau-levenshtein` and `jaro-winkler` (as used in this example). Instead, these have been imported as python User Defined Functions (UDFs). One drawback of python UDFs is that they are considerably slower than native-SQL comparisons. As such, if you are hitting issues with large run times, consider switching to DuckDB (or some other backend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.sqlite.linker import SQLiteLinker\n",
    "import altair as alt\n",
    "\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 1000\n",
    "df = splink_datasets.historical_50k.sample(10000) # reduce size of dataset to reduce CI runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-03123eea603b4f52971310bc345400db.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-03123eea603b4f52971310bc345400db.vega-embed details,\n",
       "  #altair-viz-03123eea603b4f52971310bc345400db.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-03123eea603b4f52971310bc345400db\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-03123eea603b4f52971310bc345400db\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-03123eea603b4f52971310bc345400db\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.942825673375388, \"percentile_inc_nulls\": 0.9429, \"value_count\": 571, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 571, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.8880544708120557, \"percentile_inc_nulls\": 0.8882, \"value_count\": 547, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 547, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.8576148993691799, \"percentile_inc_nulls\": 0.8578, \"value_count\": 304, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 304, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.8274757184339642, \"percentile_inc_nulls\": 0.8277, \"value_count\": 301, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 301, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.8007409632522279, \"percentile_inc_nulls\": 0.8009999999999999, \"value_count\": 267, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 267, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.7746069890858116, \"percentile_inc_nulls\": 0.7749, \"value_count\": 261, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 261, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.7493741864423751, \"percentile_inc_nulls\": 0.7497, \"value_count\": 252, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 252, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.7260438570141183, \"percentile_inc_nulls\": 0.7263999999999999, \"value_count\": 233, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 233, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.707019124862321, \"percentile_inc_nulls\": 0.7074, \"value_count\": 190, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 190, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6886953038950636, \"percentile_inc_nulls\": 0.6891, \"value_count\": 183, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 183, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6754781215580254, \"percentile_inc_nulls\": 0.6759, \"value_count\": 132, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 132, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6635626314208471, \"percentile_inc_nulls\": 0.6639999999999999, \"value_count\": 119, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 119, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6525483128066487, \"percentile_inc_nulls\": 0.653, \"value_count\": 110, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 110, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.64253529588465, \"percentile_inc_nulls\": 0.643, \"value_count\": 100, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 100, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6229097827175327, \"percentile_inc_nulls\": 0.6234, \"value_count\": 98, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 196, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.6040853109041755, \"percentile_inc_nulls\": 0.6046, \"value_count\": 94, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 188, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5952738560128167, \"percentile_inc_nulls\": 0.5958, \"value_count\": 88, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 88, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5873635726444377, \"percentile_inc_nulls\": 0.5879, \"value_count\": 79, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 79, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5799539401221587, \"percentile_inc_nulls\": 0.5805, \"value_count\": 74, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 74, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5669370181235607, \"percentile_inc_nulls\": 0.5675, \"value_count\": 65, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 130, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5605286872934816, \"percentile_inc_nulls\": 0.5610999999999999, \"value_count\": 64, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 64, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5543206168018424, \"percentile_inc_nulls\": 0.5549, \"value_count\": 62, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5488134574947432, \"percentile_inc_nulls\": 0.5494, \"value_count\": 55, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 55, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5434064283568639, \"percentile_inc_nulls\": 0.544, \"value_count\": 54, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 54, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5380995293882047, \"percentile_inc_nulls\": 0.5387, \"value_count\": 53, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 53, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5282867728046461, \"percentile_inc_nulls\": 0.5288999999999999, \"value_count\": 49, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 98, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5236807850205267, \"percentile_inc_nulls\": 0.5243, \"value_count\": 46, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 46, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5191749274056273, \"percentile_inc_nulls\": 0.5198, \"value_count\": 45, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 45, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5105637328527085, \"percentile_inc_nulls\": 0.5112, \"value_count\": 43, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 86, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5064583959146891, \"percentile_inc_nulls\": 0.5071, \"value_count\": 41, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 41, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.5028537098227697, \"percentile_inc_nulls\": 0.5035000000000001, \"value_count\": 36, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.49934915390007006, \"percentile_inc_nulls\": 0.5, \"value_count\": 35, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 35, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.485731450886152, \"percentile_inc_nulls\": 0.48640000000000005, \"value_count\": 34, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 136, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.4793231200560729, \"percentile_inc_nulls\": 0.48, \"value_count\": 32, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 64, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.47311504956443373, \"percentile_inc_nulls\": 0.4738, \"value_count\": 31, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.4701111444878342, \"percentile_inc_nulls\": 0.4708, \"value_count\": 30, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 30, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.46139981976569544, \"percentile_inc_nulls\": 0.46209999999999996, \"value_count\": 29, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 87, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.45298888555121664, \"percentile_inc_nulls\": 0.4537, \"value_count\": 28, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 84, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.442575347952338, \"percentile_inc_nulls\": 0.4433, \"value_count\": 26, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 104, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.43756883949133873, \"percentile_inc_nulls\": 0.4383, \"value_count\": 25, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 50, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.4351657154300591, \"percentile_inc_nulls\": 0.43589999999999995, \"value_count\": 24, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 24, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.4259537398618204, \"percentile_inc_nulls\": 0.42669999999999997, \"value_count\": 23, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 92, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.4193451486933013, \"percentile_inc_nulls\": 0.42010000000000003, \"value_count\": 22, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 66, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.40672874737158304, \"percentile_inc_nulls\": 0.4075, \"value_count\": 21, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 126, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.40072093721838387, \"percentile_inc_nulls\": 0.40149999999999997, \"value_count\": 20, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 60, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.3969159907880244, \"percentile_inc_nulls\": 0.39770000000000005, \"value_count\": 19, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 38, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.393311304696105, \"percentile_inc_nulls\": 0.3941, \"value_count\": 18, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.38820466606588566, \"percentile_inc_nulls\": 0.389, \"value_count\": 17, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 51, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.37859216982076704, \"percentile_inc_nulls\": 0.37939999999999996, \"value_count\": 16, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 96, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.3665765495143687, \"percentile_inc_nulls\": 0.36739999999999995, \"value_count\": 15, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 120, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.35676379293081006, \"percentile_inc_nulls\": 0.35760000000000003, \"value_count\": 14, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 98, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.34895363973165117, \"percentile_inc_nulls\": 0.3498, \"value_count\": 13, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 78, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.335736457394613, \"percentile_inc_nulls\": 0.3366, \"value_count\": 12, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 132, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.3170121157504756, \"percentile_inc_nulls\": 0.31789999999999996, \"value_count\": 11, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 187, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.3019925903674777, \"percentile_inc_nulls\": 0.30289999999999995, \"value_count\": 10, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 150, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.292980875137679, \"percentile_inc_nulls\": 0.29390000000000005, \"value_count\": 9, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 90, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.28176629618504057, \"percentile_inc_nulls\": 0.28269999999999995, \"value_count\": 8, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 112, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.27195353960148194, \"percentile_inc_nulls\": 0.27290000000000003, \"value_count\": 7, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 98, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.25032542304996497, \"percentile_inc_nulls\": 0.25129999999999997, \"value_count\": 6, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 216, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.2247922298988685, \"percentile_inc_nulls\": 0.2258, \"value_count\": 5, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 255, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.19515369980975272, \"percentile_inc_nulls\": 0.19620000000000004, \"value_count\": 4, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 296, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.15730449584459794, \"percentile_inc_nulls\": 0.15839999999999999, \"value_count\": 3, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 378, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.10503654751176528, \"percentile_inc_nulls\": 0.10619999999999996, \"value_count\": 2, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 522, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0012999999999999678, \"value_count\": 1, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1049, \"distinct_value_count\": 1787}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 571, \"group_name\": \"first_name\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 571, \"distinct_value_count\": 1787}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column first_name\", \"subtitle\": \"In this col, 13 values (0.1%) are null and there are 1787 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 571, \"group_name\": \"first_name\", \"value\": \"william\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 547, \"group_name\": \"first_name\", \"value\": \"john\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 304, \"group_name\": \"first_name\", \"value\": \"george\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 301, \"group_name\": \"first_name\", \"value\": \"thomas\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 267, \"group_name\": \"first_name\", \"value\": \"sir\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 261, \"group_name\": \"first_name\", \"value\": \"henry\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 252, \"group_name\": \"first_name\", \"value\": \"charles\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 233, \"group_name\": \"first_name\", \"value\": \"james\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 190, \"group_name\": \"first_name\", \"value\": \"edward\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 183, \"group_name\": \"first_name\", \"value\": \"robert\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u2033sandford\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6tyelburh\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6thelfl\\u00e6d\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6tgelfrith\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"\\u00e6kfgifu\", \"total_non_null_rows\": 9987, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 1787}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 571]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9988363072148952, \"percentile_inc_nulls\": 0.9991, \"value_count\": 9, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 9, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.9952159296612361, \"percentile_inc_nulls\": 0.9963, \"value_count\": 7, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 28, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.9812516162399794, \"percentile_inc_nulls\": 0.9855, \"value_count\": 6, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 108, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.9482803206620118, \"percentile_inc_nulls\": 0.96, \"value_count\": 5, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 255, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.8582880786139127, \"percentile_inc_nulls\": 0.8904, \"value_count\": 4, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 696, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.687225239203517, \"percentile_inc_nulls\": 0.7581, \"value_count\": 3, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1323, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.43198862167054564, \"percentile_inc_nulls\": 0.5607, \"value_count\": 2, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 1974, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.22660000000000002, \"value_count\": 1, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 3341, \"distinct_value_count\": 5017}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 9, \"group_name\": \"postcode_fake\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 9, \"distinct_value_count\": 5017}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column postcode_fake\", \"subtitle\": \"In this col, 2,266 values (22.7%) are null and there are 5017 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 9, \"group_name\": \"postcode_fake\", \"value\": \"sw1a 2jh\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"sw1h 9aa\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"sw1h 0ne\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"se1 7sg\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 7, \"group_name\": \"postcode_fake\", \"value\": \"bn3 7au\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"yo25 3dy\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"wc2r 0qs\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"ub5 5hf\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"tr13 9es\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 6, \"group_name\": \"postcode_fake\", \"value\": \"ta2 8dn\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"zeq 0xy\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo7 3nn\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo7 1bw\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo62 4lh\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}, {\"value_count\": 1, \"group_name\": \"postcode_fake\", \"value\": \"yo62 4ax\", \"total_non_null_rows\": 7734, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 5017}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 9]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.942450653678544, \"percentile_inc_nulls\": 0.9551, \"value_count\": 449, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 449, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.8961804665470392, \"percentile_inc_nulls\": 0.919, \"value_count\": 361, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 361, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.8529864137400667, \"percentile_inc_nulls\": 0.8853, \"value_count\": 337, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 337, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.811971289412971, \"percentile_inc_nulls\": 0.8533, \"value_count\": 320, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 320, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.7713406818764419, \"percentile_inc_nulls\": 0.8216, \"value_count\": 317, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 317, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.7309664188669571, \"percentile_inc_nulls\": 0.7901, \"value_count\": 315, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 315, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.6975134580876698, \"percentile_inc_nulls\": 0.764, \"value_count\": 261, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 261, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.6650858754165598, \"percentile_inc_nulls\": 0.7387, \"value_count\": 253, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 253, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.6332991540630608, \"percentile_inc_nulls\": 0.7139, \"value_count\": 248, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 248, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.6031786721353499, \"percentile_inc_nulls\": 0.6904, \"value_count\": 235, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 235, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.5754934632145603, \"percentile_inc_nulls\": 0.6688000000000001, \"value_count\": 216, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 216, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.55011535503717, \"percentile_inc_nulls\": 0.649, \"value_count\": 198, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 198, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.527300692130223, \"percentile_inc_nulls\": 0.6312, \"value_count\": 178, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 178, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.5055114073314535, \"percentile_inc_nulls\": 0.6142000000000001, \"value_count\": 170, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 170, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.48987439118174825, \"percentile_inc_nulls\": 0.602, \"value_count\": 122, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 122, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4761599589848756, \"percentile_inc_nulls\": 0.5912999999999999, \"value_count\": 107, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 107, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.463855421686747, \"percentile_inc_nulls\": 0.5817, \"value_count\": 96, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 96, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4524480902332735, \"percentile_inc_nulls\": 0.5728, \"value_count\": 89, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 89, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4415534478338887, \"percentile_inc_nulls\": 0.5643, \"value_count\": 85, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 85, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4307869776980261, \"percentile_inc_nulls\": 0.5559000000000001, \"value_count\": 84, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 84, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4209177134068187, \"percentile_inc_nulls\": 0.5482, \"value_count\": 77, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 77, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4115611381697001, \"percentile_inc_nulls\": 0.5408999999999999, \"value_count\": 73, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 73, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.4023327351961036, \"percentile_inc_nulls\": 0.5337000000000001, \"value_count\": 72, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 72, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3938733658036401, \"percentile_inc_nulls\": 0.5271, \"value_count\": 66, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 66, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3859266854652653, \"percentile_inc_nulls\": 0.5208999999999999, \"value_count\": 62, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.37951807228915657, \"percentile_inc_nulls\": 0.5159, \"value_count\": 50, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 50, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3736221481671367, \"percentile_inc_nulls\": 0.5113, \"value_count\": 46, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 46, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3681107408356832, \"percentile_inc_nulls\": 0.507, \"value_count\": 43, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 43, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.36285567803127405, \"percentile_inc_nulls\": 0.5029, \"value_count\": 41, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 41, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3531145860035888, \"percentile_inc_nulls\": 0.49529999999999996, \"value_count\": 38, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 76, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.33888746475262754, \"percentile_inc_nulls\": 0.48419999999999996, \"value_count\": 37, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 111, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3342732632658293, \"percentile_inc_nulls\": 0.4806, \"value_count\": 36, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.32530120481927716, \"percentile_inc_nulls\": 0.4736, \"value_count\": 35, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 70, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.32094334785952316, \"percentile_inc_nulls\": 0.47019999999999995, \"value_count\": 34, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 34, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.308254293770828, \"percentile_inc_nulls\": 0.46030000000000004, \"value_count\": 33, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 99, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.3041527813381184, \"percentile_inc_nulls\": 0.45709999999999995, \"value_count\": 32, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 32, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.29620610099974365, \"percentile_inc_nulls\": 0.45089999999999997, \"value_count\": 31, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 62, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.2887721097154575, \"percentile_inc_nulls\": 0.44510000000000005, \"value_count\": 29, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 58, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.28518328633683676, \"percentile_inc_nulls\": 0.4423, \"value_count\": 28, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 28, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.27480133299154064, \"percentile_inc_nulls\": 0.43420000000000003, \"value_count\": 27, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 81, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.2648038964368111, \"percentile_inc_nulls\": 0.4264, \"value_count\": 26, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 78, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.24942322481415025, \"percentile_inc_nulls\": 0.4144, \"value_count\": 24, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 120, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.23468341450910024, \"percentile_inc_nulls\": 0.40290000000000004, \"value_count\": 23, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 115, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.23186362471161237, \"percentile_inc_nulls\": 0.40069999999999995, \"value_count\": 22, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 22, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.22930017944116898, \"percentile_inc_nulls\": 0.39870000000000005, \"value_count\": 20, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 20, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.22468597795437062, \"percentile_inc_nulls\": 0.3951, \"value_count\": 18, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 36, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.22250704947449373, \"percentile_inc_nulls\": 0.39339999999999997, \"value_count\": 17, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 17, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.20815175596001023, \"percentile_inc_nulls\": 0.3822, \"value_count\": 16, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 112, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.2043065880543451, \"percentile_inc_nulls\": 0.3792, \"value_count\": 15, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 30, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.19174570622917197, \"percentile_inc_nulls\": 0.36939999999999995, \"value_count\": 14, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 98, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.18674698795180722, \"percentile_inc_nulls\": 0.36550000000000005, \"value_count\": 13, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 39, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.17751858497821071, \"percentile_inc_nulls\": 0.35829999999999995, \"value_count\": 12, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 72, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.1620097410920277, \"percentile_inc_nulls\": 0.34619999999999995, \"value_count\": 11, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 121, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.14406562419892333, \"percentile_inc_nulls\": 0.33220000000000005, \"value_count\": 10, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 140, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.12676236862342993, \"percentile_inc_nulls\": 0.3187, \"value_count\": 9, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 135, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.11240707510894643, \"percentile_inc_nulls\": 0.3075, \"value_count\": 8, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 112, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.09715457574980779, \"percentile_inc_nulls\": 0.2956, \"value_count\": 7, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 119, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.08023583696488079, \"percentile_inc_nulls\": 0.2824, \"value_count\": 6, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 132, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.06229172007177641, \"percentile_inc_nulls\": 0.26839999999999997, \"value_count\": 5, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 140, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.04332222507049477, \"percentile_inc_nulls\": 0.25360000000000005, \"value_count\": 4, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 148, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.026403486285567768, \"percentile_inc_nulls\": 0.24039999999999995, \"value_count\": 3, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 132, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.01127915918995126, \"percentile_inc_nulls\": 0.22860000000000003, \"value_count\": 2, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 118, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.2198, \"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 88, \"distinct_value_count\": 442}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 449, \"group_name\": \"substr_dob_1_4_\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"sum_tokens_in_value_count_group\": 449, \"distinct_value_count\": 442}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column substr(dob, 1,4)\", \"subtitle\": \"In this col, 2,198 values (22.0%) are null and there are 442 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 449, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1862\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 361, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1860\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 337, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1858\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 320, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1861\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 317, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1857\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 315, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1859\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 261, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1856\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 253, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1854\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 248, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1855\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 235, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1851\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1886\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1885\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1873\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1872\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}, {\"value_count\": 1, \"group_name\": \"substr_dob_1_4_\", \"value\": \"1871\", \"total_non_null_rows\": 7802, \"total_rows_inc_nulls\": 10000, \"distinct_value_count\": 442}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 449]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 5 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple settings dictionary will be used for exploratory analysis\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname\",\n",
    "        \"l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"l.first_name = r.first_name and l.dob = r.dob\",\n",
    "        \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\",\n",
    "    ],\n",
    "}\n",
    "linker = SQLiteLinker(df, settings)\n",
    "\n",
    "linker.profile_columns(\n",
    "    [\"first_name\", \"postcode_fake\", \"substr(dob, 1,4)\"], top_n=10, bottom_n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cf55a71fc6e843a1b029b227e022c780.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cf55a71fc6e843a1b029b227e022c780.vega-embed details,\n",
       "  #altair-viz-cf55a71fc6e843a1b029b227e022c780.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cf55a71fc6e843a1b029b227e022c780\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cf55a71fc6e843a1b029b227e022c780\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cf55a71fc6e843a1b029b227e022c780\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6c2e5e9921987757eba1773c0257a949\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"rule\", \"legend\": null, \"scale\": {\"scheme\": \"category20c\"}}, \"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Cartesian Product of Input Data\", \"type\": \"quantitative\"}, {\"field\": \"reduction_ratio\", \"title\": \"Reduction Ratio (cumulative rows/cartesian product)\", \"type\": \"nominal\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-6c2e5e9921987757eba1773c0257a949\": [{\"row_count\": 9764, \"rule\": \"l.first_name = r.first_name and l.surname = r.surname\", \"cumulative_rows\": 9764, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999805. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 0}, {\"row_count\": 943, \"rule\": \"l.surname = r.surname and l.dob = r.dob\", \"cumulative_rows\": 10707, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999786. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 9764}, {\"row_count\": 1198, \"rule\": \"l.first_name = r.first_name and l.dob = r.dob\", \"cumulative_rows\": 11905, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999762. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 10707}, {\"row_count\": 301, \"rule\": \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\", \"cumulative_rows\": 12206, \"cartesian\": 49995000, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999756. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 11905}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.cumulative_num_comparisons_from_blocking_rules_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splink.sqlite.comparison_template_library as ctl\n",
    "import splink.sqlite.comparison_library as cl\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname\",\n",
    "        \"l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"l.first_name = r.first_name and l.dob = r.dob\",\n",
    "        \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\",\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\", jaro_winkler_thresholds=[0.9], term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"surname\", jaro_winkler_thresholds=[0.9], term_frequency_adjustments=True),\n",
    "        cl.damerau_levenshtein_at_thresholds(\"dob\", [1, 2], term_frequency_adjustments=True),\n",
    "        cl.damerau_levenshtein_at_thresholds(\"postcode_fake\", [1,2]),\n",
    "        cl.exact_match(\"birth_place\", term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"occupation\",  term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n",
    "\n",
    "linker = SQLiteLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000134.\n",
      "This means that amongst all possible pairwise record comparisons, one in 7,450.82 are expected to match.  With 49,995,000 total possible comparisons, we expect a total of around 6,710.00 matching pairs\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_probability_two_random_records_match(\n",
    "    [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"substr(l.first_name,1,2) = substr(r.first_name,1,2) and l.surname = r.surname and substr(l.postcode_fake,1,2) = substr(r.postcode_fake,1,2)\",\n",
    "        \"l.dob = r.dob and l.postcode_fake = r.postcode_fake\",\n",
    "    ],\n",
    "    recall=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - postcode_fake (no m values are trained).\n",
      "    - birth_place (no m values are trained).\n",
      "    - occupation (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=5e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.first_name = r.first_name and l.surname = r.surname\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - dob\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n",
      "\n",
      "Iteration 1: Largest change in params was -0.526 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was 0.0367 in the m_probability of birth_place, level `Exact match`\n",
      "Iteration 3: Largest change in params was -0.0136 in the m_probability of birth_place, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was -0.00542 in the m_probability of dob, level `All other comparisons`\n",
      "\n",
      "EM converged after 4 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_names = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.dob = r.dob\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n",
      "\n",
      "Iteration 1: Largest change in params was -0.345 in the m_probability of first_name, level `Exact match first_name`\n",
      "Iteration 2: Largest change in params was -0.0392 in the m_probability of first_name, level `Exact match first_name`\n",
      "Iteration 3: Largest change in params was -0.00539 in the m_probability of surname, level `Exact match surname`\n",
      "\n",
      "EM converged after 3 iterations\n",
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final match weights can be viewed in the match weights chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-baaec270603745d9b7339f0bcd070666.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-baaec270603745d9b7339f0bcd070666.vega-embed details,\n",
       "  #altair-viz-baaec270603745d9b7339f0bcd070666.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-baaec270603745d9b7339f0bcd070666\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-baaec270603745d9b7339f0bcd070666\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-baaec270603745d9b7339f0bcd070666\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"range\": [\"red\", \"orange\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"range\": [\"red\", \"orange\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-ac50003d71cf22279211226933e55dc6\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-ac50003d71cf22279211226933e55dc6\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.000134231437002546, \"log2_bayes_factor\": -12.862989789260947, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.000 or one in  7,450.8 records.This is equivalent to a starting match weight of -12.863.\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match first_name\", \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"m_probability_description\": \"Amongst matching record comparisons, 56.08% of records are in the exact match first_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.27% of records are in the exact match first_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 44.0343701977073, \"log2_bayes_factor\": 5.460558126754405, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"damerau_levenshtein(\\\"first_name_l\\\", \\\"first_name_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.08595980904217919, \"u_probability\": 0.003051466379035028, \"m_probability_description\": \"Amongst matching record comparisons, 8.60% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.31% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 28.170000375151588, \"log2_bayes_factor\": 4.816087677813175, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 28.17 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler >= 0.9\", \"m_probability\": 0.037819420718648085, \"u_probability\": 0.2982478974970825, \"m_probability_description\": \"Amongst matching record comparisons, 3.78% of records are in the jaro_winkler >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 29.82% of records are in the jaro_winkler >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.12680532213648896, \"log2_bayes_factor\": -2.9793127968959547, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro_winkler >= 0.9` then comparison is  7.89 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.31541072627977285, \"u_probability\": 0.6859649017091184, \"m_probability_description\": \"Amongst matching record comparisons, 31.54% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 68.60% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4598059251922512, \"log2_bayes_factor\": -1.1209030377255726, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.17 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match surname\", \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"m_probability_description\": \"Amongst matching record comparisons, 78.00% of records are in the exact match surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.08% of records are in the exact match surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 997.3107596190212, \"log2_bayes_factor\": 9.961899304733734, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"damerau_levenshtein(\\\"surname_l\\\", \\\"surname_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.1308939008429692, \"u_probability\": 0.00036059073289042737, \"m_probability_description\": \"Amongst matching record comparisons, 13.09% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 362.99851577922806, \"log2_bayes_factor\": 8.50381983914637, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 363.00 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler >= 0.9\", \"m_probability\": 0.01037896307984722, \"u_probability\": 0.20154444599943008, \"m_probability_description\": \"Amongst matching record comparisons, 1.04% of records are in the jaro_winkler >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 20.15% of records are in the jaro_winkler >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.051497142619730485, \"log2_bayes_factor\": -4.2793638049101075, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro_winkler >= 0.9` then comparison is  19.42 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.07870746702505514, \"u_probability\": 0.7973128402819112, \"m_probability_description\": \"Amongst matching record comparisons, 7.87% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 79.73% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.0987159155711402, \"log2_bayes_factor\": -3.3405734864053414, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  10.13 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.6288044483816653, \"u_probability\": 0.001981863126725239, \"m_probability_description\": \"Amongst matching record comparisons, 62.88% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.20% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"dob\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 317.2794528049369, \"log2_bayes_factor\": 8.309610284316564, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 317.28 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"m_probability_description\": \"Amongst matching record comparisons, 32.95% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.08% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 15.858927540970248, \"log2_bayes_factor\": 3.9872233070617686, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"m_probability_description\": \"Amongst matching record comparisons, 3.66% of records are in the damerau_levenshtein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 8.09% of records are in the damerau_levenshtein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.45268536642780777, \"log2_bayes_factor\": -1.1434194243149958, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0050748169841719325, \"u_probability\": 0.8963494029239464, \"m_probability_description\": \"Amongst matching record comparisons, 0.51% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 89.63% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.005661650431871289, \"log2_bayes_factor\": -7.464561609204118, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  176.63 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 2}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.6782020576745722, \"u_probability\": 0.00014869362033562275, \"m_probability_description\": \"Amongst matching record comparisons, 67.82% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 4561.070314541897, \"log2_bayes_factor\": 12.155156695958162, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,561.07 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"damerau_levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.0886947524549063, \"u_probability\": 7.485257078119784e-05, \"m_probability_description\": \"Amongst matching record comparisons, 8.87% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1184.9259354654719, \"log2_bayes_factor\": 10.210581170050565, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 1,184.93 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"damerau_levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"m_probability\": 0.05353563318262226, \"u_probability\": 0.00044102325487300353, \"m_probability_description\": \"Amongst matching record comparisons, 5.35% of records are in the damerau_levenshtein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the damerau_levenshtein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 121.38959247860593, \"log2_bayes_factor\": 6.9235009250162065, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is 121.39 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"m_probability_description\": \"Amongst matching record comparisons, 17.96% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.93% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.17968697115877388, \"log2_bayes_factor\": -2.4764422899686545, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 3}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.8446977877170962, \"u_probability\": 0.005029702907339964, \"m_probability_description\": \"Amongst matching record comparisons, 84.47% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.50% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"birth_place\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 167.9418850931352, \"log2_bayes_factor\": 7.391818276393672, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 167.94 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 4}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"m_probability_description\": \"Amongst matching record comparisons, 15.53% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.50% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.15608728495383487, \"log2_bayes_factor\": -2.679575076349155, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 4}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.8904967227894447, \"u_probability\": 0.03871894368754565, \"m_probability_description\": \"Amongst matching record comparisons, 89.05% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 3.87% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"occupation\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 22.998993205382362, \"log2_bayes_factor\": 4.523498802605118, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 23.00 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 5}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"m_probability_description\": \"Amongst matching record comparisons, 10.95% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 96.13% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.11391390321433996, \"log2_bayes_factor\": -3.1339842558809914, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013421342134213422, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-993c6610e4bc400aafd7c6cb0b95e306.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-993c6610e4bc400aafd7c6cb0b95e306.vega-embed details,\n",
       "  #altair-viz-993c6610e4bc400aafd7c6cb0b95e306.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-993c6610e4bc400aafd7c6cb0b95e306\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-993c6610e4bc400aafd7c6cb0b95e306\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-993c6610e4bc400aafd7c6cb0b95e306\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"axis\": {\"format\": \"+\", \"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"point\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"match_weight\", \"format\": \"+.5\", \"title\": \"Match weight\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".5\", \"title\": \"Match probability\", \"type\": \"quantitative\"}, {\"field\": \"cum_prop\", \"format\": \".3%\", \"title\": \"Proportion of unlinkable records\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"name\": \"mouse_coords\"}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"match_weight\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"y\": {\"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}], \"data\": {\"name\": \"data-fe2a987a592b00fb2b894e8377a24fb3\"}, \"height\": 400, \"params\": [{\"name\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"select\": {\"type\": \"point\", \"fields\": [\"match_weight\", \"cum_prop\"], \"nearest\": true, \"on\": \"mouseover\"}, \"views\": [\"mouse_coords\"]}], \"title\": {\"text\": \"Unlinkable records\", \"subtitle\": \"Records with insufficient information to exceed a given match threshold\"}, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-fe2a987a592b00fb2b894e8377a24fb3\": [{\"match_weight\": -9.51, \"match_probability\": 0.00137, \"prop\": 0.0002, \"cum_prop\": 0.0002}, {\"match_weight\": -7.93, \"match_probability\": 0.00409, \"prop\": 0.0001, \"cum_prop\": 0.00030000000000000003}, {\"match_weight\": -6.62, \"match_probability\": 0.01006, \"prop\": 0.0001, \"cum_prop\": 0.0004}, {\"match_weight\": -6.43, \"match_probability\": 0.01143, \"prop\": 0.0001, \"cum_prop\": 0.0005}, {\"match_weight\": -4.8, \"match_probability\": 0.03456, \"prop\": 0.0001, \"cum_prop\": 0.0006000000000000001}, {\"match_weight\": -4.32, \"match_probability\": 0.04773, \"prop\": 0.0001, \"cum_prop\": 0.0007000000000000001}, {\"match_weight\": -3.77, \"match_probability\": 0.06829, \"prop\": 0.0001, \"cum_prop\": 0.0008000000000000001}, {\"match_weight\": -3.73, \"match_probability\": 0.06992, \"prop\": 0.0001, \"cum_prop\": 0.0009000000000000002}, {\"match_weight\": -2.73, \"match_probability\": 0.13071, \"prop\": 0.0002, \"cum_prop\": 0.0011000000000000003}, {\"match_weight\": -1.81, \"match_probability\": 0.22172, \"prop\": 0.0001, \"cum_prop\": 0.0012000000000000003}, {\"match_weight\": -1.7, \"match_probability\": 0.23572, \"prop\": 0.0001, \"cum_prop\": 0.0013000000000000004}, {\"match_weight\": -1.42, \"match_probability\": 0.2722, \"prop\": 0.0001, \"cum_prop\": 0.0014000000000000004}, {\"match_weight\": -1.23, \"match_probability\": 0.29907, \"prop\": 0.0001, \"cum_prop\": 0.0015000000000000005}, {\"match_weight\": -1.1, \"match_probability\": 0.31763, \"prop\": 0.0001, \"cum_prop\": 0.0016000000000000005}, {\"match_weight\": -0.6, \"match_probability\": 0.39706, \"prop\": 0.0001, \"cum_prop\": 0.0017000000000000006}, {\"match_weight\": -0.59, \"match_probability\": 0.39936, \"prop\": 0.0001, \"cum_prop\": 0.0018000000000000006}, {\"match_weight\": -0.47, \"match_probability\": 0.41968, \"prop\": 0.0001, \"cum_prop\": 0.0019000000000000006}, {\"match_weight\": -0.41, \"match_probability\": 0.42916, \"prop\": 0.0011, \"cum_prop\": 0.003000000000000001}, {\"match_weight\": -0.07, \"match_probability\": 0.48796, \"prop\": 0.0001, \"cum_prop\": 0.0031000000000000008}, {\"match_weight\": 0.1, \"match_probability\": 0.51785, \"prop\": 0.0001, \"cum_prop\": 0.0032000000000000006}, {\"match_weight\": 0.2, \"match_probability\": 0.53531, \"prop\": 0.0001, \"cum_prop\": 0.0033000000000000004}, {\"match_weight\": 0.71, \"match_probability\": 0.62101, \"prop\": 0.0001, \"cum_prop\": 0.0034000000000000002}, {\"match_weight\": 0.83, \"match_probability\": 0.63928, \"prop\": 0.0001, \"cum_prop\": 0.0035}, {\"match_weight\": 0.95, \"match_probability\": 0.65946, \"prop\": 0.0001, \"cum_prop\": 0.0036}, {\"match_weight\": 0.97, \"match_probability\": 0.66248, \"prop\": 0.0001, \"cum_prop\": 0.0036999999999999997}, {\"match_weight\": 1.14, \"match_probability\": 0.68821, \"prop\": 0.0001, \"cum_prop\": 0.0037999999999999996}, {\"match_weight\": 1.24, \"match_probability\": 0.70299, \"prop\": 0.0002, \"cum_prop\": 0.003999999999999999}, {\"match_weight\": 1.29, \"match_probability\": 0.70987, \"prop\": 0.0001, \"cum_prop\": 0.0040999999999999995}, {\"match_weight\": 1.5, \"match_probability\": 0.73858, \"prop\": 0.0001, \"cum_prop\": 0.0042}, {\"match_weight\": 1.65, \"match_probability\": 0.75809, \"prop\": 0.0001, \"cum_prop\": 0.0043}, {\"match_weight\": 1.65, \"match_probability\": 0.75841, \"prop\": 0.0001, \"cum_prop\": 0.0044}, {\"match_weight\": 1.69, \"match_probability\": 0.76315, \"prop\": 0.0001, \"cum_prop\": 0.0045000000000000005}, {\"match_weight\": 1.82, \"match_probability\": 0.77933, \"prop\": 0.0002, \"cum_prop\": 0.0047}, {\"match_weight\": 1.83, \"match_probability\": 0.78103, \"prop\": 0.0001, \"cum_prop\": 0.0048000000000000004}, {\"match_weight\": 2.02, \"match_probability\": 0.80263, \"prop\": 0.0001, \"cum_prop\": 0.004900000000000001}, {\"match_weight\": 2.09, \"match_probability\": 0.8099, \"prop\": 0.0001, \"cum_prop\": 0.005000000000000001}, {\"match_weight\": 2.23, \"match_probability\": 0.82458, \"prop\": 0.0001, \"cum_prop\": 0.005100000000000001}, {\"match_weight\": 2.29, \"match_probability\": 0.82993, \"prop\": 0.0001, \"cum_prop\": 0.0052000000000000015}, {\"match_weight\": 2.3, \"match_probability\": 0.83145, \"prop\": 0.0001, \"cum_prop\": 0.005300000000000002}, {\"match_weight\": 2.33, \"match_probability\": 0.83406, \"prop\": 0.0001, \"cum_prop\": 0.005400000000000002}, {\"match_weight\": 2.34, \"match_probability\": 0.83484, \"prop\": 0.0001, \"cum_prop\": 0.005500000000000002}, {\"match_weight\": 2.5, \"match_probability\": 0.85, \"prop\": 0.0001, \"cum_prop\": 0.0056000000000000025}, {\"match_weight\": 2.54, \"match_probability\": 0.8533, \"prop\": 0.0001, \"cum_prop\": 0.005700000000000003}, {\"match_weight\": 2.55, \"match_probability\": 0.854, \"prop\": 0.0001, \"cum_prop\": 0.005800000000000003}, {\"match_weight\": 2.57, \"match_probability\": 0.85601, \"prop\": 0.0001, \"cum_prop\": 0.005900000000000003}, {\"match_weight\": 2.62, \"match_probability\": 0.85968, \"prop\": 0.0001, \"cum_prop\": 0.006000000000000004}, {\"match_weight\": 2.62, \"match_probability\": 0.86003, \"prop\": 0.0001, \"cum_prop\": 0.006100000000000004}, {\"match_weight\": 2.75, \"match_probability\": 0.87085, \"prop\": 0.0002, \"cum_prop\": 0.0063000000000000035}, {\"match_weight\": 2.76, \"match_probability\": 0.87144, \"prop\": 0.0001, \"cum_prop\": 0.006400000000000004}, {\"match_weight\": 2.78, \"match_probability\": 0.87271, \"prop\": 0.0001, \"cum_prop\": 0.006500000000000004}, {\"match_weight\": 2.81, \"match_probability\": 0.87484, \"prop\": 0.0001, \"cum_prop\": 0.006600000000000004}, {\"match_weight\": 2.84, \"match_probability\": 0.87713, \"prop\": 0.0001, \"cum_prop\": 0.0067000000000000046}, {\"match_weight\": 2.92, \"match_probability\": 0.88321, \"prop\": 0.0001, \"cum_prop\": 0.006800000000000005}, {\"match_weight\": 2.97, \"match_probability\": 0.88703, \"prop\": 0.0001, \"cum_prop\": 0.006900000000000005}, {\"match_weight\": 3.16, \"match_probability\": 0.89916, \"prop\": 0.0001, \"cum_prop\": 0.007000000000000005}, {\"match_weight\": 3.24, \"match_probability\": 0.90409, \"prop\": 0.0001, \"cum_prop\": 0.007100000000000006}, {\"match_weight\": 3.28, \"match_probability\": 0.90694, \"prop\": 0.0001, \"cum_prop\": 0.007200000000000006}, {\"match_weight\": 3.29, \"match_probability\": 0.90722, \"prop\": 0.0001, \"cum_prop\": 0.007300000000000006}, {\"match_weight\": 3.33, \"match_probability\": 0.90952, \"prop\": 0.0001, \"cum_prop\": 0.007400000000000006}, {\"match_weight\": 3.4, \"match_probability\": 0.91339, \"prop\": 0.0001, \"cum_prop\": 0.007500000000000007}, {\"match_weight\": 3.51, \"match_probability\": 0.9193, \"prop\": 0.0001, \"cum_prop\": 0.007600000000000007}, {\"match_weight\": 3.51, \"match_probability\": 0.91949, \"prop\": 0.0002, \"cum_prop\": 0.007800000000000007}, {\"match_weight\": 3.58, \"match_probability\": 0.92297, \"prop\": 0.0001, \"cum_prop\": 0.007900000000000006}, {\"match_weight\": 3.66, \"match_probability\": 0.92664, \"prop\": 0.0001, \"cum_prop\": 0.008000000000000005}, {\"match_weight\": 3.78, \"match_probability\": 0.93195, \"prop\": 0.0001, \"cum_prop\": 0.008100000000000005}, {\"match_weight\": 3.8, \"match_probability\": 0.93308, \"prop\": 0.0001, \"cum_prop\": 0.008200000000000004}, {\"match_weight\": 4.11, \"match_probability\": 0.94532, \"prop\": 0.0001, \"cum_prop\": 0.008300000000000004}, {\"match_weight\": 4.14, \"match_probability\": 0.9464, \"prop\": 0.0001, \"cum_prop\": 0.008400000000000003}, {\"match_weight\": 4.35, \"match_probability\": 0.95313, \"prop\": 0.0001, \"cum_prop\": 0.008500000000000002}, {\"match_weight\": 4.35, \"match_probability\": 0.95325, \"prop\": 0.0001, \"cum_prop\": 0.008600000000000002}, {\"match_weight\": 4.41, \"match_probability\": 0.95516, \"prop\": 0.0001, \"cum_prop\": 0.008700000000000001}, {\"match_weight\": 4.64, \"match_probability\": 0.96132, \"prop\": 0.0001, \"cum_prop\": 0.0088}, {\"match_weight\": 4.64, \"match_probability\": 0.96152, \"prop\": 0.0001, \"cum_prop\": 0.0089}, {\"match_weight\": 4.78, \"match_probability\": 0.96477, \"prop\": 0.0001, \"cum_prop\": 0.009}, {\"match_weight\": 4.78, \"match_probability\": 0.96495, \"prop\": 0.0001, \"cum_prop\": 0.009099999999999999}, {\"match_weight\": 4.8, \"match_probability\": 0.96545, \"prop\": 0.0001, \"cum_prop\": 0.009199999999999998}, {\"match_weight\": 4.87, \"match_probability\": 0.96697, \"prop\": 0.0001, \"cum_prop\": 0.009299999999999998}, {\"match_weight\": 4.87, \"match_probability\": 0.96703, \"prop\": 0.0002, \"cum_prop\": 0.009499999999999998}, {\"match_weight\": 4.93, \"match_probability\": 0.96834, \"prop\": 0.0001, \"cum_prop\": 0.009599999999999997}, {\"match_weight\": 4.95, \"match_probability\": 0.96874, \"prop\": 0.0001, \"cum_prop\": 0.009699999999999997}, {\"match_weight\": 4.96, \"match_probability\": 0.96892, \"prop\": 0.0001, \"cum_prop\": 0.009799999999999996}, {\"match_weight\": 5.02, \"match_probability\": 0.97018, \"prop\": 0.0001, \"cum_prop\": 0.009899999999999996}, {\"match_weight\": 5.05, \"match_probability\": 0.97071, \"prop\": 0.0001, \"cum_prop\": 0.009999999999999995}, {\"match_weight\": 5.07, \"match_probability\": 0.971, \"prop\": 0.0001, \"cum_prop\": 0.010099999999999994}, {\"match_weight\": 5.09, \"match_probability\": 0.97156, \"prop\": 0.0001, \"cum_prop\": 0.010199999999999994}, {\"match_weight\": 5.16, \"match_probability\": 0.97282, \"prop\": 0.0001, \"cum_prop\": 0.010299999999999993}, {\"match_weight\": 5.2, \"match_probability\": 0.9736, \"prop\": 0.0001, \"cum_prop\": 0.010399999999999993}, {\"match_weight\": 5.25, \"match_probability\": 0.97435, \"prop\": 0.0001, \"cum_prop\": 0.010499999999999992}, {\"match_weight\": 5.28, \"match_probability\": 0.97498, \"prop\": 0.0001, \"cum_prop\": 0.010599999999999991}, {\"match_weight\": 5.31, \"match_probability\": 0.97547, \"prop\": 0.0001, \"cum_prop\": 0.01069999999999999}, {\"match_weight\": 5.45, \"match_probability\": 0.9776, \"prop\": 0.0001, \"cum_prop\": 0.01079999999999999}, {\"match_weight\": 5.45, \"match_probability\": 0.97762, \"prop\": 0.0001, \"cum_prop\": 0.01089999999999999}, {\"match_weight\": 5.48, \"match_probability\": 0.97813, \"prop\": 0.0001, \"cum_prop\": 0.010999999999999989}, {\"match_weight\": 5.5, \"match_probability\": 0.97831, \"prop\": 0.0002, \"cum_prop\": 0.01119999999999999}, {\"match_weight\": 5.5, \"match_probability\": 0.9784, \"prop\": 0.0001, \"cum_prop\": 0.011299999999999989}, {\"match_weight\": 5.54, \"match_probability\": 0.97903, \"prop\": 0.0001, \"cum_prop\": 0.011399999999999988}, {\"match_weight\": 5.56, \"match_probability\": 0.9793, \"prop\": 0.0001, \"cum_prop\": 0.011499999999999988}, {\"match_weight\": 5.59, \"match_probability\": 0.97968, \"prop\": 0.0001, \"cum_prop\": 0.011599999999999987}, {\"match_weight\": 5.59, \"match_probability\": 0.97971, \"prop\": 0.0001, \"cum_prop\": 0.011699999999999986}, {\"match_weight\": 5.6, \"match_probability\": 0.97975, \"prop\": 0.0001, \"cum_prop\": 0.011799999999999986}, {\"match_weight\": 5.67, \"match_probability\": 0.98073, \"prop\": 0.0001, \"cum_prop\": 0.011899999999999985}, {\"match_weight\": 5.74, \"match_probability\": 0.98168, \"prop\": 0.0001, \"cum_prop\": 0.011999999999999985}, {\"match_weight\": 5.75, \"match_probability\": 0.98171, \"prop\": 0.0001, \"cum_prop\": 0.012099999999999984}, {\"match_weight\": 5.78, \"match_probability\": 0.98207, \"prop\": 0.0002, \"cum_prop\": 0.012299999999999985}, {\"match_weight\": 5.79, \"match_probability\": 0.98225, \"prop\": 0.0001, \"cum_prop\": 0.012399999999999984}, {\"match_weight\": 5.81, \"match_probability\": 0.98243, \"prop\": 0.0001, \"cum_prop\": 0.012499999999999983}, {\"match_weight\": 5.84, \"match_probability\": 0.98279, \"prop\": 0.0001, \"cum_prop\": 0.012599999999999983}, {\"match_weight\": 5.87, \"match_probability\": 0.98321, \"prop\": 0.0001, \"cum_prop\": 0.012699999999999982}, {\"match_weight\": 5.96, \"match_probability\": 0.9842, \"prop\": 0.0001, \"cum_prop\": 0.012799999999999982}, {\"match_weight\": 6.0, \"match_probability\": 0.98462, \"prop\": 0.0001, \"cum_prop\": 0.012899999999999981}, {\"match_weight\": 6.02, \"match_probability\": 0.98479, \"prop\": 0.0001, \"cum_prop\": 0.01299999999999998}, {\"match_weight\": 6.07, \"match_probability\": 0.98532, \"prop\": 0.0001, \"cum_prop\": 0.01309999999999998}, {\"match_weight\": 6.12, \"match_probability\": 0.98586, \"prop\": 0.0001, \"cum_prop\": 0.013199999999999979}, {\"match_weight\": 6.22, \"match_probability\": 0.98676, \"prop\": 0.0001, \"cum_prop\": 0.013299999999999979}, {\"match_weight\": 6.22, \"match_probability\": 0.98677, \"prop\": 0.0001, \"cum_prop\": 0.013399999999999978}, {\"match_weight\": 6.26, \"match_probability\": 0.98715, \"prop\": 0.0001, \"cum_prop\": 0.013499999999999977}, {\"match_weight\": 6.29, \"match_probability\": 0.98736, \"prop\": 0.0002, \"cum_prop\": 0.013699999999999978}, {\"match_weight\": 6.32, \"match_probability\": 0.98761, \"prop\": 0.0001, \"cum_prop\": 0.013799999999999977}, {\"match_weight\": 6.35, \"match_probability\": 0.98785, \"prop\": 0.0001, \"cum_prop\": 0.013899999999999977}, {\"match_weight\": 6.36, \"match_probability\": 0.98795, \"prop\": 0.0001, \"cum_prop\": 0.013999999999999976}, {\"match_weight\": 6.39, \"match_probability\": 0.98821, \"prop\": 0.0001, \"cum_prop\": 0.014099999999999975}, {\"match_weight\": 6.46, \"match_probability\": 0.98873, \"prop\": 0.0001, \"cum_prop\": 0.014199999999999975}, {\"match_weight\": 6.48, \"match_probability\": 0.98895, \"prop\": 0.0001, \"cum_prop\": 0.014299999999999974}, {\"match_weight\": 6.51, \"match_probability\": 0.98911, \"prop\": 0.0001, \"cum_prop\": 0.014399999999999974}, {\"match_weight\": 6.54, \"match_probability\": 0.9894, \"prop\": 0.0002, \"cum_prop\": 0.014599999999999974}, {\"match_weight\": 6.61, \"match_probability\": 0.98986, \"prop\": 0.0001, \"cum_prop\": 0.014699999999999974}, {\"match_weight\": 6.62, \"match_probability\": 0.98993, \"prop\": 0.0001, \"cum_prop\": 0.014799999999999973}, {\"match_weight\": 6.66, \"match_probability\": 0.99018, \"prop\": 0.0001, \"cum_prop\": 0.014899999999999972}, {\"match_weight\": 6.74, \"match_probability\": 0.99076, \"prop\": 0.0001, \"cum_prop\": 0.014999999999999972}, {\"match_weight\": 6.75, \"match_probability\": 0.99077, \"prop\": 0.0001, \"cum_prop\": 0.015099999999999971}, {\"match_weight\": 6.79, \"match_probability\": 0.99103, \"prop\": 0.0001, \"cum_prop\": 0.01519999999999997}, {\"match_weight\": 6.84, \"match_probability\": 0.99137, \"prop\": 0.0001, \"cum_prop\": 0.01529999999999997}, {\"match_weight\": 6.87, \"match_probability\": 0.9915, \"prop\": 0.0003, \"cum_prop\": 0.01559999999999997}, {\"match_weight\": 6.88, \"match_probability\": 0.99158, \"prop\": 0.0001, \"cum_prop\": 0.01569999999999997}, {\"match_weight\": 6.9, \"match_probability\": 0.99169, \"prop\": 0.0003, \"cum_prop\": 0.015999999999999973}, {\"match_weight\": 6.93, \"match_probability\": 0.99189, \"prop\": 0.0001, \"cum_prop\": 0.016099999999999972}, {\"match_weight\": 7.02, \"match_probability\": 0.99236, \"prop\": 0.0001, \"cum_prop\": 0.01619999999999997}, {\"match_weight\": 7.07, \"match_probability\": 0.9926, \"prop\": 0.0001, \"cum_prop\": 0.01629999999999997}, {\"match_weight\": 7.09, \"match_probability\": 0.99273, \"prop\": 0.0001, \"cum_prop\": 0.01639999999999997}, {\"match_weight\": 7.14, \"match_probability\": 0.99297, \"prop\": 0.0001, \"cum_prop\": 0.01649999999999997}, {\"match_weight\": 7.15, \"match_probability\": 0.993, \"prop\": 0.0001, \"cum_prop\": 0.01659999999999997}, {\"match_weight\": 7.18, \"match_probability\": 0.99316, \"prop\": 0.0001, \"cum_prop\": 0.01669999999999997}, {\"match_weight\": 7.22, \"match_probability\": 0.99334, \"prop\": 0.0001, \"cum_prop\": 0.016799999999999968}, {\"match_weight\": 7.25, \"match_probability\": 0.99347, \"prop\": 0.0001, \"cum_prop\": 0.016899999999999967}, {\"match_weight\": 7.26, \"match_probability\": 0.99352, \"prop\": 0.0001, \"cum_prop\": 0.016999999999999967}, {\"match_weight\": 7.33, \"match_probability\": 0.9938, \"prop\": 0.0001, \"cum_prop\": 0.017099999999999966}, {\"match_weight\": 7.35, \"match_probability\": 0.9939, \"prop\": 0.0001, \"cum_prop\": 0.017199999999999965}, {\"match_weight\": 7.39, \"match_probability\": 0.99407, \"prop\": 0.0002, \"cum_prop\": 0.017399999999999964}, {\"match_weight\": 7.43, \"match_probability\": 0.99422, \"prop\": 0.0003, \"cum_prop\": 0.017699999999999966}, {\"match_weight\": 7.45, \"match_probability\": 0.9943, \"prop\": 0.0001, \"cum_prop\": 0.017799999999999965}, {\"match_weight\": 7.52, \"match_probability\": 0.99458, \"prop\": 0.0003, \"cum_prop\": 0.018099999999999967}, {\"match_weight\": 7.53, \"match_probability\": 0.99461, \"prop\": 0.0001, \"cum_prop\": 0.018199999999999966}, {\"match_weight\": 7.53, \"match_probability\": 0.99462, \"prop\": 0.0001, \"cum_prop\": 0.018299999999999966}, {\"match_weight\": 7.56, \"match_probability\": 0.99472, \"prop\": 0.0002, \"cum_prop\": 0.018499999999999964}, {\"match_weight\": 7.6, \"match_probability\": 0.99489, \"prop\": 0.0001, \"cum_prop\": 0.018599999999999964}, {\"match_weight\": 7.66, \"match_probability\": 0.99508, \"prop\": 0.0001, \"cum_prop\": 0.018699999999999963}, {\"match_weight\": 7.68, \"match_probability\": 0.99514, \"prop\": 0.0001, \"cum_prop\": 0.018799999999999963}, {\"match_weight\": 7.69, \"match_probability\": 0.99518, \"prop\": 0.0001, \"cum_prop\": 0.018899999999999962}, {\"match_weight\": 7.69, \"match_probability\": 0.99519, \"prop\": 0.0001, \"cum_prop\": 0.01899999999999996}, {\"match_weight\": 7.7, \"match_probability\": 0.99521, \"prop\": 0.0001, \"cum_prop\": 0.01909999999999996}, {\"match_weight\": 7.7, \"match_probability\": 0.99523, \"prop\": 0.0001, \"cum_prop\": 0.01919999999999996}, {\"match_weight\": 7.74, \"match_probability\": 0.99534, \"prop\": 0.0001, \"cum_prop\": 0.01929999999999996}, {\"match_weight\": 7.78, \"match_probability\": 0.99548, \"prop\": 0.0001, \"cum_prop\": 0.01939999999999996}, {\"match_weight\": 7.8, \"match_probability\": 0.99553, \"prop\": 0.0001, \"cum_prop\": 0.01949999999999996}, {\"match_weight\": 7.81, \"match_probability\": 0.99555, \"prop\": 0.0001, \"cum_prop\": 0.019599999999999958}, {\"match_weight\": 7.83, \"match_probability\": 0.99562, \"prop\": 0.0001, \"cum_prop\": 0.019699999999999957}, {\"match_weight\": 7.84, \"match_probability\": 0.99566, \"prop\": 0.0002, \"cum_prop\": 0.019899999999999956}, {\"match_weight\": 7.87, \"match_probability\": 0.99573, \"prop\": 0.0001, \"cum_prop\": 0.019999999999999955}, {\"match_weight\": 7.9, \"match_probability\": 0.99584, \"prop\": 0.0001, \"cum_prop\": 0.020099999999999955}, {\"match_weight\": 7.94, \"match_probability\": 0.99594, \"prop\": 0.0001, \"cum_prop\": 0.020199999999999954}, {\"match_weight\": 7.97, \"match_probability\": 0.99602, \"prop\": 0.0001, \"cum_prop\": 0.020299999999999953}, {\"match_weight\": 7.98, \"match_probability\": 0.99605, \"prop\": 0.0001, \"cum_prop\": 0.020399999999999953}, {\"match_weight\": 8.0, \"match_probability\": 0.9961, \"prop\": 0.0002, \"cum_prop\": 0.02059999999999995}, {\"match_weight\": 8.02, \"match_probability\": 0.99615, \"prop\": 0.0001, \"cum_prop\": 0.02069999999999995}, {\"match_weight\": 8.03, \"match_probability\": 0.9962, \"prop\": 0.0001, \"cum_prop\": 0.02079999999999995}, {\"match_weight\": 8.1, \"match_probability\": 0.99638, \"prop\": 0.0003, \"cum_prop\": 0.021099999999999952}, {\"match_weight\": 8.12, \"match_probability\": 0.99643, \"prop\": 0.0001, \"cum_prop\": 0.02119999999999995}, {\"match_weight\": 8.13, \"match_probability\": 0.99645, \"prop\": 0.0001, \"cum_prop\": 0.02129999999999995}, {\"match_weight\": 8.14, \"match_probability\": 0.99647, \"prop\": 0.0001, \"cum_prop\": 0.02139999999999995}, {\"match_weight\": 8.16, \"match_probability\": 0.99653, \"prop\": 0.0001, \"cum_prop\": 0.02149999999999995}, {\"match_weight\": 8.18, \"match_probability\": 0.99656, \"prop\": 0.0002, \"cum_prop\": 0.02169999999999995}, {\"match_weight\": 8.26, \"match_probability\": 0.99674, \"prop\": 0.0001, \"cum_prop\": 0.021799999999999948}, {\"match_weight\": 8.29, \"match_probability\": 0.99681, \"prop\": 0.0001, \"cum_prop\": 0.021899999999999947}, {\"match_weight\": 8.34, \"match_probability\": 0.99692, \"prop\": 0.0001, \"cum_prop\": 0.021999999999999947}, {\"match_weight\": 8.35, \"match_probability\": 0.99696, \"prop\": 0.0001, \"cum_prop\": 0.022099999999999946}, {\"match_weight\": 8.37, \"match_probability\": 0.99699, \"prop\": 0.0001, \"cum_prop\": 0.022199999999999945}, {\"match_weight\": 8.39, \"match_probability\": 0.99703, \"prop\": 0.0003, \"cum_prop\": 0.022499999999999947}, {\"match_weight\": 8.43, \"match_probability\": 0.9971, \"prop\": 0.0001, \"cum_prop\": 0.022599999999999947}, {\"match_weight\": 8.45, \"match_probability\": 0.99714, \"prop\": 0.0001, \"cum_prop\": 0.022699999999999946}, {\"match_weight\": 8.48, \"match_probability\": 0.99721, \"prop\": 0.0003, \"cum_prop\": 0.022999999999999948}, {\"match_weight\": 8.49, \"match_probability\": 0.99722, \"prop\": 0.0001, \"cum_prop\": 0.023099999999999947}, {\"match_weight\": 8.5, \"match_probability\": 0.99725, \"prop\": 0.0001, \"cum_prop\": 0.023199999999999946}, {\"match_weight\": 8.52, \"match_probability\": 0.99728, \"prop\": 0.0003, \"cum_prop\": 0.023499999999999948}, {\"match_weight\": 8.56, \"match_probability\": 0.99735, \"prop\": 0.0001, \"cum_prop\": 0.023599999999999947}, {\"match_weight\": 8.58, \"match_probability\": 0.99739, \"prop\": 0.0001, \"cum_prop\": 0.023699999999999947}, {\"match_weight\": 8.59, \"match_probability\": 0.9974, \"prop\": 0.0001, \"cum_prop\": 0.023799999999999946}, {\"match_weight\": 8.62, \"match_probability\": 0.99746, \"prop\": 0.0001, \"cum_prop\": 0.023899999999999946}, {\"match_weight\": 8.73, \"match_probability\": 0.99766, \"prop\": 0.0001, \"cum_prop\": 0.023999999999999945}, {\"match_weight\": 8.81, \"match_probability\": 0.99777, \"prop\": 0.0004, \"cum_prop\": 0.024399999999999946}, {\"match_weight\": 8.84, \"match_probability\": 0.99782, \"prop\": 0.0002, \"cum_prop\": 0.024599999999999945}, {\"match_weight\": 8.89, \"match_probability\": 0.99789, \"prop\": 0.0001, \"cum_prop\": 0.024699999999999944}, {\"match_weight\": 8.97, \"match_probability\": 0.99801, \"prop\": 0.0002, \"cum_prop\": 0.024899999999999943}, {\"match_weight\": 8.99, \"match_probability\": 0.99803, \"prop\": 0.0002, \"cum_prop\": 0.025099999999999942}, {\"match_weight\": 9.06, \"match_probability\": 0.99813, \"prop\": 0.0002, \"cum_prop\": 0.02529999999999994}, {\"match_weight\": 9.07, \"match_probability\": 0.99814, \"prop\": 0.0001, \"cum_prop\": 0.02539999999999994}, {\"match_weight\": 9.1, \"match_probability\": 0.99818, \"prop\": 0.0001, \"cum_prop\": 0.02549999999999994}, {\"match_weight\": 9.1, \"match_probability\": 0.99819, \"prop\": 0.0001, \"cum_prop\": 0.02559999999999994}, {\"match_weight\": 9.15, \"match_probability\": 0.99825, \"prop\": 0.0001, \"cum_prop\": 0.025699999999999938}, {\"match_weight\": 9.22, \"match_probability\": 0.99833, \"prop\": 0.0002, \"cum_prop\": 0.025899999999999937}, {\"match_weight\": 9.26, \"match_probability\": 0.99838, \"prop\": 0.0002, \"cum_prop\": 0.026099999999999936}, {\"match_weight\": 9.29, \"match_probability\": 0.9984, \"prop\": 0.0001, \"cum_prop\": 0.026199999999999935}, {\"match_weight\": 9.39, \"match_probability\": 0.99851, \"prop\": 0.0001, \"cum_prop\": 0.026299999999999935}, {\"match_weight\": 9.42, \"match_probability\": 0.99854, \"prop\": 0.0001, \"cum_prop\": 0.026399999999999934}, {\"match_weight\": 9.43, \"match_probability\": 0.99855, \"prop\": 0.0002, \"cum_prop\": 0.026599999999999933}, {\"match_weight\": 9.45, \"match_probability\": 0.99857, \"prop\": 0.0001, \"cum_prop\": 0.026699999999999932}, {\"match_weight\": 9.46, \"match_probability\": 0.99858, \"prop\": 0.0001, \"cum_prop\": 0.02679999999999993}, {\"match_weight\": 9.52, \"match_probability\": 0.99864, \"prop\": 0.0001, \"cum_prop\": 0.02689999999999993}, {\"match_weight\": 9.53, \"match_probability\": 0.99865, \"prop\": 0.0001, \"cum_prop\": 0.02699999999999993}, {\"match_weight\": 9.58, \"match_probability\": 0.9987, \"prop\": 0.0003, \"cum_prop\": 0.027299999999999932}, {\"match_weight\": 9.61, \"match_probability\": 0.99872, \"prop\": 0.0002, \"cum_prop\": 0.02749999999999993}, {\"match_weight\": 9.61, \"match_probability\": 0.99873, \"prop\": 0.0001, \"cum_prop\": 0.02759999999999993}, {\"match_weight\": 9.71, \"match_probability\": 0.99881, \"prop\": 0.0001, \"cum_prop\": 0.02769999999999993}, {\"match_weight\": 9.73, \"match_probability\": 0.99882, \"prop\": 0.0001, \"cum_prop\": 0.02779999999999993}, {\"match_weight\": 9.74, \"match_probability\": 0.99883, \"prop\": 0.0001, \"cum_prop\": 0.02789999999999993}, {\"match_weight\": 9.75, \"match_probability\": 0.99884, \"prop\": 0.0001, \"cum_prop\": 0.027999999999999928}, {\"match_weight\": 9.77, \"match_probability\": 0.99886, \"prop\": 0.0001, \"cum_prop\": 0.028099999999999927}, {\"match_weight\": 9.79, \"match_probability\": 0.99887, \"prop\": 0.0001, \"cum_prop\": 0.028199999999999927}, {\"match_weight\": 9.81, \"match_probability\": 0.99888, \"prop\": 0.0003, \"cum_prop\": 0.028499999999999928}, {\"match_weight\": 9.83, \"match_probability\": 0.9989, \"prop\": 0.0001, \"cum_prop\": 0.028599999999999928}, {\"match_weight\": 9.84, \"match_probability\": 0.99891, \"prop\": 0.0002, \"cum_prop\": 0.028799999999999926}, {\"match_weight\": 9.88, \"match_probability\": 0.99894, \"prop\": 0.0001, \"cum_prop\": 0.028899999999999926}, {\"match_weight\": 9.94, \"match_probability\": 0.99898, \"prop\": 0.0001, \"cum_prop\": 0.028999999999999925}, {\"match_weight\": 9.98, \"match_probability\": 0.99901, \"prop\": 0.0001, \"cum_prop\": 0.029099999999999925}, {\"match_weight\": 10.0, \"match_probability\": 0.99902, \"prop\": 0.0004, \"cum_prop\": 0.029499999999999926}, {\"match_weight\": 10.02, \"match_probability\": 0.99904, \"prop\": 0.0001, \"cum_prop\": 0.029599999999999925}, {\"match_weight\": 10.05, \"match_probability\": 0.99905, \"prop\": 0.0001, \"cum_prop\": 0.029699999999999924}, {\"match_weight\": 10.06, \"match_probability\": 0.99906, \"prop\": 0.0002, \"cum_prop\": 0.029899999999999923}, {\"match_weight\": 10.07, \"match_probability\": 0.99907, \"prop\": 0.0001, \"cum_prop\": 0.029999999999999923}, {\"match_weight\": 10.1, \"match_probability\": 0.99909, \"prop\": 0.0002, \"cum_prop\": 0.03019999999999992}, {\"match_weight\": 10.12, \"match_probability\": 0.9991, \"prop\": 0.0001, \"cum_prop\": 0.03029999999999992}, {\"match_weight\": 10.15, \"match_probability\": 0.99912, \"prop\": 0.0001, \"cum_prop\": 0.03039999999999992}, {\"match_weight\": 10.16, \"match_probability\": 0.99913, \"prop\": 0.0003, \"cum_prop\": 0.030699999999999922}, {\"match_weight\": 10.18, \"match_probability\": 0.99914, \"prop\": 0.0002, \"cum_prop\": 0.03089999999999992}, {\"match_weight\": 10.2, \"match_probability\": 0.99915, \"prop\": 0.0001, \"cum_prop\": 0.03099999999999992}, {\"match_weight\": 10.33, \"match_probability\": 0.99922, \"prop\": 0.0001, \"cum_prop\": 0.03109999999999992}, {\"match_weight\": 10.39, \"match_probability\": 0.99926, \"prop\": 0.0002, \"cum_prop\": 0.03129999999999992}, {\"match_weight\": 10.43, \"match_probability\": 0.99927, \"prop\": 0.0002, \"cum_prop\": 0.03149999999999992}, {\"match_weight\": 10.43, \"match_probability\": 0.99928, \"prop\": 0.0001, \"cum_prop\": 0.03159999999999992}, {\"match_weight\": 10.48, \"match_probability\": 0.9993, \"prop\": 0.0001, \"cum_prop\": 0.03169999999999992}, {\"match_weight\": 10.52, \"match_probability\": 0.99932, \"prop\": 0.0001, \"cum_prop\": 0.031799999999999926}, {\"match_weight\": 10.54, \"match_probability\": 0.99933, \"prop\": 0.0001, \"cum_prop\": 0.03189999999999993}, {\"match_weight\": 10.6, \"match_probability\": 0.99936, \"prop\": 0.0001, \"cum_prop\": 0.03199999999999993}, {\"match_weight\": 10.63, \"match_probability\": 0.99937, \"prop\": 0.0001, \"cum_prop\": 0.032099999999999934}, {\"match_weight\": 10.7, \"match_probability\": 0.9994, \"prop\": 0.0001, \"cum_prop\": 0.03219999999999994}, {\"match_weight\": 10.76, \"match_probability\": 0.99942, \"prop\": 0.0002, \"cum_prop\": 0.032399999999999936}, {\"match_weight\": 10.81, \"match_probability\": 0.99944, \"prop\": 0.0004, \"cum_prop\": 0.03279999999999993}, {\"match_weight\": 10.84, \"match_probability\": 0.99945, \"prop\": 0.0003, \"cum_prop\": 0.033099999999999935}, {\"match_weight\": 10.87, \"match_probability\": 0.99946, \"prop\": 0.0005, \"cum_prop\": 0.033599999999999935}, {\"match_weight\": 10.91, \"match_probability\": 0.99948, \"prop\": 0.0002, \"cum_prop\": 0.033799999999999934}, {\"match_weight\": 10.96, \"match_probability\": 0.9995, \"prop\": 0.0003, \"cum_prop\": 0.034099999999999936}, {\"match_weight\": 10.98, \"match_probability\": 0.99951, \"prop\": 0.0001, \"cum_prop\": 0.03419999999999994}, {\"match_weight\": 11.03, \"match_probability\": 0.99952, \"prop\": 0.0005, \"cum_prop\": 0.03469999999999994}, {\"match_weight\": 11.09, \"match_probability\": 0.99954, \"prop\": 0.0001, \"cum_prop\": 0.03479999999999994}, {\"match_weight\": 11.16, \"match_probability\": 0.99956, \"prop\": 0.0001, \"cum_prop\": 0.034899999999999945}, {\"match_weight\": 11.2, \"match_probability\": 0.99957, \"prop\": 0.0002, \"cum_prop\": 0.035099999999999944}, {\"match_weight\": 11.23, \"match_probability\": 0.99958, \"prop\": 0.0004, \"cum_prop\": 0.03549999999999994}, {\"match_weight\": 11.26, \"match_probability\": 0.99959, \"prop\": 0.0004, \"cum_prop\": 0.03589999999999994}, {\"match_weight\": 11.3, \"match_probability\": 0.9996, \"prop\": 0.0002, \"cum_prop\": 0.03609999999999994}, {\"match_weight\": 11.33, \"match_probability\": 0.99961, \"prop\": 0.0002, \"cum_prop\": 0.036299999999999936}, {\"match_weight\": 11.37, \"match_probability\": 0.99962, \"prop\": 0.0003, \"cum_prop\": 0.03659999999999994}, {\"match_weight\": 11.42, \"match_probability\": 0.99963, \"prop\": 0.0013, \"cum_prop\": 0.03789999999999994}, {\"match_weight\": 11.5, \"match_probability\": 0.99965, \"prop\": 0.0005, \"cum_prop\": 0.03839999999999994}, {\"match_weight\": 11.51, \"match_probability\": 0.99966, \"prop\": 0.0002, \"cum_prop\": 0.03859999999999994}, {\"match_weight\": 11.57, \"match_probability\": 0.99967, \"prop\": 0.0001, \"cum_prop\": 0.03869999999999994}, {\"match_weight\": 11.62, \"match_probability\": 0.99968, \"prop\": 0.0001, \"cum_prop\": 0.038799999999999946}, {\"match_weight\": 11.65, \"match_probability\": 0.99969, \"prop\": 0.0001, \"cum_prop\": 0.03889999999999995}, {\"match_weight\": 11.71, \"match_probability\": 0.9997, \"prop\": 0.0003, \"cum_prop\": 0.03919999999999995}, {\"match_weight\": 11.75, \"match_probability\": 0.99971, \"prop\": 0.0018, \"cum_prop\": 0.04099999999999995}, {\"match_weight\": 11.82, \"match_probability\": 0.99972, \"prop\": 0.0007, \"cum_prop\": 0.04169999999999995}, {\"match_weight\": 11.85, \"match_probability\": 0.99973, \"prop\": 0.0012, \"cum_prop\": 0.04289999999999995}, {\"match_weight\": 11.91, \"match_probability\": 0.99974, \"prop\": 0.0004, \"cum_prop\": 0.04329999999999995}, {\"match_weight\": 11.99, \"match_probability\": 0.99975, \"prop\": 0.0001, \"cum_prop\": 0.04339999999999995}, {\"match_weight\": 12.04, \"match_probability\": 0.99976, \"prop\": 0.0006, \"cum_prop\": 0.043999999999999956}, {\"match_weight\": 12.1, \"match_probability\": 0.99977, \"prop\": 0.0003, \"cum_prop\": 0.04429999999999996}, {\"match_weight\": 12.18, \"match_probability\": 0.99978, \"prop\": 0.0003, \"cum_prop\": 0.04459999999999996}, {\"match_weight\": 12.25, \"match_probability\": 0.99979, \"prop\": 0.0004, \"cum_prop\": 0.04499999999999996}, {\"match_weight\": 12.31, \"match_probability\": 0.9998, \"prop\": 0.0005, \"cum_prop\": 0.04549999999999996}, {\"match_weight\": 12.39, \"match_probability\": 0.99981, \"prop\": 0.0011, \"cum_prop\": 0.046599999999999954}, {\"match_weight\": 12.46, \"match_probability\": 0.99982, \"prop\": 0.0008, \"cum_prop\": 0.047399999999999956}, {\"match_weight\": 12.56, \"match_probability\": 0.99983, \"prop\": 0.0009, \"cum_prop\": 0.048299999999999954}, {\"match_weight\": 12.6, \"match_probability\": 0.99984, \"prop\": 0.0004, \"cum_prop\": 0.04869999999999995}, {\"match_weight\": 12.73, \"match_probability\": 0.99985, \"prop\": 0.0007, \"cum_prop\": 0.04939999999999995}, {\"match_weight\": 12.85, \"match_probability\": 0.99986, \"prop\": 0.0012, \"cum_prop\": 0.05059999999999995}, {\"match_weight\": 12.96, \"match_probability\": 0.99987, \"prop\": 0.001, \"cum_prop\": 0.05159999999999995}, {\"match_weight\": 13.08, \"match_probability\": 0.99988, \"prop\": 0.0006, \"cum_prop\": 0.052199999999999955}, {\"match_weight\": 13.21, \"match_probability\": 0.99989, \"prop\": 0.0012, \"cum_prop\": 0.053399999999999954}, {\"match_weight\": 13.36, \"match_probability\": 0.9999, \"prop\": 0.001, \"cum_prop\": 0.054399999999999955}, {\"match_weight\": 13.52, \"match_probability\": 0.99991, \"prop\": 0.0015, \"cum_prop\": 0.05589999999999996}, {\"match_weight\": 13.7, \"match_probability\": 0.99992, \"prop\": 0.0019, \"cum_prop\": 0.057799999999999956}, {\"match_weight\": 13.91, \"match_probability\": 0.99993, \"prop\": 0.0015, \"cum_prop\": 0.05929999999999996}, {\"match_weight\": 14.13, \"match_probability\": 0.99994, \"prop\": 0.0018, \"cum_prop\": 0.06109999999999996}, {\"match_weight\": 14.41, \"match_probability\": 0.99995, \"prop\": 0.0023, \"cum_prop\": 0.06339999999999996}, {\"match_weight\": 14.8, \"match_probability\": 0.99996, \"prop\": 0.004, \"cum_prop\": 0.06739999999999996}, {\"match_weight\": 15.28, \"match_probability\": 0.99997, \"prop\": 0.0049, \"cum_prop\": 0.07229999999999996}, {\"match_weight\": 16.01, \"match_probability\": 0.99998, \"prop\": 0.0079, \"cum_prop\": 0.08019999999999997}, {\"match_weight\": 17.61, \"match_probability\": 0.99999, \"prop\": 0.0193, \"cum_prop\": 0.09949999999999996}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.unlinkables_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_name_l</th>\n",
       "      <th>first_name_r</th>\n",
       "      <th>gamma_first_name</th>\n",
       "      <th>tf_first_name_l</th>\n",
       "      <th>tf_first_name_r</th>\n",
       "      <th>bf_first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>bf_birth_place</th>\n",
       "      <th>bf_tf_adj_birth_place</th>\n",
       "      <th>occupation_l</th>\n",
       "      <th>occupation_r</th>\n",
       "      <th>gamma_occupation</th>\n",
       "      <th>tf_occupation_l</th>\n",
       "      <th>tf_occupation_r</th>\n",
       "      <th>bf_occupation</th>\n",
       "      <th>bf_tf_adj_occupation</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.016358</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>Q18530059-11</td>\n",
       "      <td>Q18530059-14</td>\n",
       "      <td>jessie</td>\n",
       "      <td>jessie</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>44.03437</td>\n",
       "      <td>...</td>\n",
       "      <td>167.941885</td>\n",
       "      <td>1.406532</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.016358</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>Q18530059-11</td>\n",
       "      <td>Q18530059-5</td>\n",
       "      <td>jessie</td>\n",
       "      <td>jessie</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>44.03437</td>\n",
       "      <td>...</td>\n",
       "      <td>167.941885</td>\n",
       "      <td>1.406532</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.780044</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>Q559411-1</td>\n",
       "      <td>Q8017419-2</td>\n",
       "      <td>william</td>\n",
       "      <td>william</td>\n",
       "      <td>3</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>44.03437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>lexicographer</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.534864</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>Q6222556-21</td>\n",
       "      <td>Q6222556-4</td>\n",
       "      <td>jean</td>\n",
       "      <td>jean</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>44.03437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.731764</td>\n",
       "      <td>0.990679</td>\n",
       "      <td>Q7527724-6</td>\n",
       "      <td>Q7527724-8</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>44.03437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>politician</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.088809</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_weight  match_probability   unique_id_l   unique_id_r first_name_l  \\\n",
       "0     12.016358           0.999759  Q18530059-11  Q18530059-14       jessie   \n",
       "1     12.016358           0.999759  Q18530059-11   Q18530059-5       jessie   \n",
       "2    -14.780044           0.000036     Q559411-1    Q8017419-2      william   \n",
       "3     13.534864           0.999916   Q6222556-21    Q6222556-4         jean   \n",
       "4      6.731764           0.990679    Q7527724-6    Q7527724-8          sir   \n",
       "\n",
       "  first_name_r  gamma_first_name  tf_first_name_l  tf_first_name_r  \\\n",
       "0       jessie                 3         0.001101         0.001101   \n",
       "1       jessie                 3         0.001101         0.001101   \n",
       "2      william                 3         0.057174         0.057174   \n",
       "3         jean                 3         0.004606         0.004606   \n",
       "4          sir                 3         0.026735         0.026735   \n",
       "\n",
       "   bf_first_name  ...  bf_birth_place bf_tf_adj_birth_place   occupation_l  \\\n",
       "0       44.03437  ...      167.941885              1.406532           None   \n",
       "1       44.03437  ...      167.941885              1.406532           None   \n",
       "2       44.03437  ...        0.156087              1.000000  lexicographer   \n",
       "3       44.03437  ...        0.156087              1.000000           None   \n",
       "4       44.03437  ...        1.000000              1.000000     politician   \n",
       "\n",
       "   occupation_r  gamma_occupation  tf_occupation_l  tf_occupation_r  \\\n",
       "0          None                -1              NaN             None   \n",
       "1          None                -1              NaN             None   \n",
       "2          None                -1         0.000398             None   \n",
       "3          None                -1              NaN             None   \n",
       "4          None                -1         0.088809             None   \n",
       "\n",
       "   bf_occupation bf_tf_adj_occupation match_key  \n",
       "0            1.0                  1.0         0  \n",
       "1            1.0                  1.0         0  \n",
       "2            1.0                  1.0         0  \n",
       "3            1.0                  1.0         0  \n",
       "4            1.0                  1.0         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = linker.predict()\n",
    "df_e = df_predict.as_pandas_dataframe(limit=5)\n",
    "df_e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view rows in this dataset as a waterfall chart as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7bd8ff5a65e2484e9540de24a879f261.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7bd8ff5a65e2484e9540de24a879f261.vega-embed details,\n",
       "  #altair-viz-7bd8ff5a65e2484e9540de24a879f261.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7bd8ff5a65e2484e9540de24a879f261\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7bd8ff5a65e2484e9540de24a879f261\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7bd8ff5a65e2484e9540de24a879f261\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-949e9ab09b54fc2cbadcf5d044afea95\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 4, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-949e9ab09b54fc2cbadcf5d044afea95\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"jessie\", \"value_r\": \"jessie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 3.531430003448468, \"bayes_factor\": 11.562889054568025, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 11.56 times more likely to be a match\", \"value_l\": \"jessie\", \"value_r\": \"jessie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"pigott\", \"value_r\": \"pigott\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"pigott\", \"value_r\": \"pigott\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1851-11-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"wn6 8aj\", \"value_r\": \"wn5 9at\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 7.391818276393672, \"bayes_factor\": 167.9418850931352, \"comparison_vector_value\": 1, \"m_probability\": 0.8446977877170962, \"u_probability\": 0.005029702907339964, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 167.94 times more likely to be a match\", \"value_l\": \"wigan\", \"value_r\": \"wigan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 0.49214245861312195, \"bayes_factor\": 1.4065320807654886, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.41 times more likely to be a match\", \"value_l\": \"wigan\", \"value_r\": \"wigan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.01635767637857, \"bayes_factor\": 4142.705865330973, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"jessie\", \"value_r\": \"jessie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 3.531430003448468, \"bayes_factor\": 11.562889054568025, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 11.56 times more likely to be a match\", \"value_l\": \"jessie\", \"value_r\": \"jessie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"pigott\", \"value_r\": \"pigott\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"pigott\", \"value_r\": \"pigott\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"wn6 8aj\", \"value_r\": \"wn5 9at\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 7.391818276393672, \"bayes_factor\": 167.9418850931352, \"comparison_vector_value\": 1, \"m_probability\": 0.8446977877170962, \"u_probability\": 0.005029702907339964, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 167.94 times more likely to be a match\", \"value_l\": \"wigan\", \"value_r\": \"wigan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 0.49214245861312195, \"bayes_factor\": 1.4065320807654886, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.41 times more likely to be a match\", \"value_l\": \"wigan\", \"value_r\": \"wigan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.01635767637857, \"bayes_factor\": 4142.705865330973, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"smith\", \"value_r\": \"smith\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.5524477422266285, \"bayes_factor\": 0.1704655669457967, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  5.87 times less likely to be a match\", \"value_l\": \"smith\", \"value_r\": \"smith\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -7.464561609204118, \"bayes_factor\": 0.005661650431871289, \"comparison_vector_value\": 0, \"m_probability\": 0.0050748169841719325, \"u_probability\": 0.8963494029239464, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  176.63 times less likely to be a match\", \"value_l\": \"1813-05-20\", \"value_r\": \"1856-08-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.0050748169841719325, \"u_probability\": 0.8963494029239464, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  176.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"en1 3uh\", \"value_r\": \"co16 0hp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"london | municipal borough of enfield\", \"value_r\": \"colchester\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 2}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 2}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"lexicographer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -14.780044388798443, \"bayes_factor\": 3.55437545938459e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"jean\", \"value_r\": \"jean\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.4672996660287525, \"bayes_factor\": 2.765038686961919, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.77 times more likely to be a match\", \"value_l\": \"jean\", \"value_r\": \"jean\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"boucher\", \"value_r\": \"boucher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.03251475849452756, \"bayes_factor\": 1.0227934016747802, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.02 times more likely to be a match\", \"value_l\": \"boucher\", \"value_r\": \"boucher\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1819-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"log2_bayes_factor\": 12.155156695958162, \"bayes_factor\": 4561.070314541897, \"comparison_vector_value\": 3, \"m_probability\": 0.6782020576745722, \"u_probability\": 0.00014869362033562275, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,561.07 times more likely to be a match\", \"value_l\": \"bt23 6bn\", \"value_r\": \"bt23 6bn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"lisburn and castlereagh\", \"value_r\": \"moneyreagh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 3}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 3}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.53486368635948, \"bayes_factor\": 11868.612666333056, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"dillwyn-llewelyn\", \"value_r\": \"dillwyn-llewelyn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"dillwyn-llewelyn\", \"value_r\": \"dillwyn-llewelyn\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1866-05-26\", \"value_r\": \"1836-05-26\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sa1 2up\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"swansea\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 4}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 4}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 6.731763819518147, \"bayes_factor\": 106.28276233842328, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.charts import waterfall_chart\n",
    "records_to_plot = df_e.to_dict(orient=\"records\")\n",
    "linker.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 1, root rows count 20\n",
      "Completed iteration 2, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "clusters = linker.cluster_pairwise_predictions_at_threshold(df_predict, threshold_match_probability=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"./dashboards/50k_cluster.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe9a1242f40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.cluster_studio_dashboard(df_predict, clusters, \"dashboards/50k_cluster.html\", sampling_method='by_cluster_size', overwrite=True)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\n",
    "    src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1c609fa7beb14a8e9176ea3f41a48491.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1c609fa7beb14a8e9176ea3f41a48491.vega-embed details,\n",
       "  #altair-viz-1c609fa7beb14a8e9176ea3f41a48491.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1c609fa7beb14a8e9176ea3f41a48491\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1c609fa7beb14a8e9176ea3f41a48491\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1c609fa7beb14a8e9176ea3f41a48491\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e4c0bfb670ecbe05c6269d4f007bb0e8\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-e4c0bfb670ecbe05c6269d4f007bb0e8\": [{\"truth_threshold\": -26.76, \"match_probability\": 8.799080930932456e-09, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11781, \"tn\": 0, \"fp\": 7018, \"fn\": 0, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 1.0, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0, \"precision\": 0.6266822703335284, \"recall\": 1.0, \"specificity\": 0.0, \"npv\": 1, \"accuracy\": 0.6266822703335284, \"f1\": 0.7705035971223022, \"f2\": 0.893542466210579, \"f0_5\": 0.6772480080940938, \"p4\": 0.0, \"phi\": 0}, {\"truth_threshold\": -24.080000000000002, \"match_probability\": 5.638942679035343e-08, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11780, \"tn\": 0, \"fp\": 7018, \"fn\": 1, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9999151175621764, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 8.48824378236143e-05, \"precision\": 0.626662410894776, \"recall\": 0.9999151175621764, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6266290760146817, \"f1\": 0.7704633899081069, \"f2\": 0.8934801735384242, \"f0_5\": 0.6772216664941993, \"p4\": 0.0, \"phi\": -0.005629369831023917}, {\"truth_threshold\": -23.42, \"match_probability\": 8.909995051884308e-08, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11779, \"tn\": 0, \"fp\": 7018, \"fn\": 2, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9998302351243528, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0001697648756472286, \"precision\": 0.6266425493429802, \"recall\": 0.9998302351243528, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6265758816958349, \"f1\": 0.7704231800640984, \"f2\": 0.8934178789763505, \"f0_5\": 0.6771953224712254, \"p4\": 0.0, \"phi\": -0.007961342925835769}, {\"truth_threshold\": -23.0, \"match_probability\": 1.1920927533992823e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11778, \"tn\": 0, \"fp\": 7018, \"fn\": 3, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9997453526865292, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.00025464731347084286, \"precision\": 0.6266226856778038, \"recall\": 0.9997453526865292, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6265226873769881, \"f1\": 0.7703829675900187, \"f2\": 0.8933555825242718, \"f0_5\": 0.6771689760248376, \"p4\": 0.0, \"phi\": -0.009750873294382699}, {\"truth_threshold\": -22.6, \"match_probability\": 1.5729757585734097e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11777, \"tn\": 0, \"fp\": 7018, \"fn\": 4, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9996604702487055, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0003395297512944572, \"precision\": 0.6266028198989093, \"recall\": 0.9996604702487055, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6264694930581414, \"f1\": 0.7703427524856097, \"f2\": 0.8932932841821023, \"f0_5\": 0.6771426271547015, \"p4\": 0.0, \"phi\": -0.011259638168865596}, {\"truth_threshold\": -22.28, \"match_probability\": 1.963593615407386e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11774, \"tn\": 0, \"fp\": 7018, \"fn\": 7, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9994058229352347, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0005941770647653001, \"precision\": 0.6265432098765432, \"recall\": 0.9994058229352347, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6263099101016012, \"f1\": 0.7702220913878258, \"f2\": 0.8931063778141878, \"f0_5\": 0.6770635659984588, \"p4\": 0.0, \"phi\": -0.014896290121108217}, {\"truth_threshold\": -21.86, \"match_probability\": 2.6271458301307396e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11773, \"tn\": 0, \"fp\": 7018, \"fn\": 8, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.999320940497411, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0006790595025889144, \"precision\": 0.6265233356394019, \"recall\": 0.999320940497411, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6262567157827544, \"f1\": 0.7701818657595185, \"f2\": 0.8930440719107942, \"f0_5\": 0.6770372074299845, \"p4\": 0.0, \"phi\": -0.01592522771985615}, {\"truth_threshold\": -21.66, \"match_probability\": 3.0177979755175377e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11768, \"tn\": 0, \"fp\": 7018, \"fn\": 13, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.998896528308293, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.001103471691706986, \"precision\": 0.6264239327158523, \"recall\": 0.998896528308293, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6259907441885206, \"f1\": 0.7699806981385154, \"f2\": 0.8927325140342892, \"f0_5\": 0.6769053781995974, \"p4\": 0.0, \"phi\": -0.020303463126946628}, {\"truth_threshold\": -21.46, \"match_probability\": 3.466539414632334e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11764, \"tn\": 0, \"fp\": 7018, \"fn\": 17, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9985569985569985, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.001443001443001443, \"precision\": 0.6263443722713236, \"recall\": 0.9985569985569985, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6257779669131337, \"f1\": 0.7698197166508524, \"f2\": 0.8924832336964768, \"f0_5\": 0.6767998711295723, \"p4\": 0.0, \"phi\": -0.02322037058270367}, {\"truth_threshold\": -21.400000000000002, \"match_probability\": 3.613748595162712e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11763, \"tn\": 0, \"fp\": 7018, \"fn\": 18, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.998472116119175, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0015278838808250573, \"precision\": 0.6263244768649167, \"recall\": 0.998472116119175, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6257247725942869, \"f1\": 0.7697794646947189, \"f2\": 0.8924209088839997, \"f0_5\": 0.6767734882918129, \"p4\": 0.0, \"phi\": -0.02389420031005358}, {\"truth_threshold\": -21.14, \"match_probability\": 4.3273866777349967e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11762, \"tn\": 0, \"fp\": 7018, \"fn\": 19, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9983872336813513, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0016127663186486715, \"precision\": 0.626304579339723, \"recall\": 0.9983872336813513, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6256715782754402, \"f1\": 0.7697392101043814, \"f2\": 0.8923585821801409, \"f0_5\": 0.6767471030252816, \"p4\": 0.0, \"phi\": -0.024549610747914955}, {\"truth_threshold\": -21.0, \"match_probability\": 4.76836930829558e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11761, \"tn\": 0, \"fp\": 7018, \"fn\": 20, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9983023512435277, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0016976487564722858, \"precision\": 0.6262846796954045, \"recall\": 0.9983023512435277, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6256183839565934, \"f1\": 0.7696989528795811, \"f2\": 0.892296253584814, \"f0_5\": 0.6767207153296432, \"p4\": 0.0, \"phi\": -0.025188039796493467}, {\"truth_threshold\": -20.94, \"match_probability\": 4.970861638287614e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11760, \"tn\": 0, \"fp\": 7018, \"fn\": 21, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9982174688057041, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0017825311942959, \"precision\": 0.6262647779316222, \"recall\": 0.9982174688057041, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6255651896377467, \"f1\": 0.7696586930200595, \"f2\": 0.8922339230979333, \"f0_5\": 0.676694325204562, \"p4\": 0.0, \"phi\": -0.025810747601415752}, {\"truth_threshold\": -20.740000000000002, \"match_probability\": 5.710020164757595e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11755, \"tn\": 0, \"fp\": 7018, \"fn\": 26, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.997793056616586, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.002206943383413972, \"precision\": 0.6261652373089011, \"recall\": 0.997793056616586, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.625299218043513, \"f1\": 0.7694573541925771, \"f2\": 0.8919222422872057, \"f0_5\": 0.6765623381257698, \"p4\": 0.0, \"phi\": -0.028723372991542147}, {\"truth_threshold\": -20.46, \"match_probability\": 6.933076425886398e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11753, \"tn\": 0, \"fp\": 7018, \"fn\": 28, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9976232917409388, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0023767082590612004, \"precision\": 0.6261254062117095, \"recall\": 0.9976232917409388, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6251928294058194, \"f1\": 0.769376800209479, \"f2\": 0.8917975567190227, \"f0_5\": 0.6765095262764059, \"p4\": 0.0, \"phi\": -0.029809240763725958}, {\"truth_threshold\": -20.32, \"match_probability\": 7.639591842698399e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11750, \"tn\": 0, \"fp\": 7018, \"fn\": 31, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.997368644427468, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.002631355572532043, \"precision\": 0.6260656436487638, \"recall\": 0.997368644427468, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6250332464492793, \"f1\": 0.7692559494582474, \"f2\": 0.8916105141747102, \"f0_5\": 0.6764302902605552, \"p4\": 0.0, \"phi\": -0.03136804508326918}, {\"truth_threshold\": -20.12, \"match_probability\": 8.775585585654507e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11747, \"tn\": 0, \"fp\": 7018, \"fn\": 34, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9971139971139971, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.002886002886002886, \"precision\": 0.626005861977085, \"recall\": 0.9971139971139971, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.624873663492739, \"f1\": 0.7691350749688993, \"f2\": 0.8914234545978843, \"f0_5\": 0.6763510323464723, \"p4\": 0.0, \"phi\": -0.03285343454925671}, {\"truth_threshold\": -20.080000000000002, \"match_probability\": 9.022300655021115e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11745, \"tn\": 0, \"fp\": 7018, \"fn\": 36, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9969442322383499, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0030557677616501145, \"precision\": 0.6259659969088099, \"recall\": 0.9969442322383499, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6247672748550455, \"f1\": 0.769054478784704, \"f2\": 0.8912987387496775, \"f0_5\": 0.6762981815669158, \"p4\": 0.0, \"phi\": -0.033807706938019294}, {\"truth_threshold\": -20.0, \"match_probability\": 9.536734069124156e-07, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11744, \"tn\": 0, \"fp\": 7018, \"fn\": 37, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9968593498005263, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.003140650199473729, \"precision\": 0.6259460611875066, \"recall\": 0.9968593498005263, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6247140805361987, \"f1\": 0.76901417673444, \"f2\": 0.8912363779862186, \"f0_5\": 0.676271752525078, \"p4\": 0.0, \"phi\": -0.03427495554403231}, {\"truth_threshold\": -19.8, \"match_probability\": 1.0954829183746414e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11735, \"tn\": 0, \"fp\": 7018, \"fn\": 46, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9960954078601137, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0039045921398862577, \"precision\": 0.6257665440196235, \"recall\": 0.9960954078601137, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.624235331666578, \"f1\": 0.7686513394904041, \"f2\": 0.8906750459189094, \"f0_5\": 0.6760337815261599, \"p4\": 0.0, \"phi\": -0.03822602530611111}, {\"truth_threshold\": -19.66, \"match_probability\": 1.20711809735545e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11730, \"tn\": 0, \"fp\": 7018, \"fn\": 51, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9956709956709957, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.004329004329004329, \"precision\": 0.6256667377853637, \"recall\": 0.9956709956709957, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6239693600723443, \"f1\": 0.7684496708048085, \"f2\": 0.8903631284916201, \"f0_5\": 0.6759014900948451, \"p4\": 0.0, \"phi\": -0.040255314091650965}, {\"truth_threshold\": -19.46, \"match_probability\": 1.3866143238269718e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11729, \"tn\": 0, \"fp\": 7018, \"fn\": 52, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.995586113233172, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.004413886766827944, \"precision\": 0.6256467701498907, \"recall\": 0.995586113233172, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6239161657534975, \"f1\": 0.7684093291404612, \"f2\": 0.8903007393238299, \"f0_5\": 0.6758750244903133, \"p4\": 0.0, \"phi\": -0.04064914227083638}, {\"truth_threshold\": -19.400000000000002, \"match_probability\": 1.4454978709653148e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11728, \"tn\": 0, \"fp\": 7018, \"fn\": 53, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9955012307953485, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0044987692046515575, \"precision\": 0.6256268003840819, \"recall\": 0.9955012307953485, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6238629714346507, \"f1\": 0.7683689848330986, \"f2\": 0.8902383482617277, \"f0_5\": 0.6758485564455714, \"p4\": 0.0, \"phi\": -0.04103923271065095}, {\"truth_threshold\": -19.18, \"match_probability\": 1.6836195185750226e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11727, \"tn\": 0, \"fp\": 7018, \"fn\": 54, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9954163483575248, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.004583651642475172, \"precision\": 0.6256068284875967, \"recall\": 0.9954163483575248, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.623809777115804, \"f1\": 0.7683286378824609, \"f2\": 0.8901759553052271, \"f0_5\": 0.6758220859602817, \"p4\": 0.0, \"phi\": -0.041425691008531364}, {\"truth_threshold\": -19.16, \"match_probability\": 1.7071219310971163e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11716, \"tn\": 0, \"fp\": 7018, \"fn\": 65, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.994482641541465, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.005517358458534929, \"precision\": 0.6253869969040248, \"recall\": 0.994482641541465, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6232246396084898, \"f1\": 0.7678846468949697, \"f2\": 0.8894895077287497, \"f0_5\": 0.6755307494493582, \"p4\": 0.0, \"phi\": -0.04546288839601759}, {\"truth_threshold\": -19.14, \"match_probability\": 1.7309524239438608e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11715, \"tn\": 0, \"fp\": 7018, \"fn\": 66, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9943977591036415, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0056022408963585435, \"precision\": 0.6253669994128009, \"recall\": 0.9943977591036415, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6231714452896431, \"f1\": 0.7678442682047585, \"f2\": 0.8894270920327376, \"f0_5\": 0.6755042496511481, \"p4\": 0.0, \"phi\": -0.0458124908405461}, {\"truth_threshold\": -18.98, \"match_probability\": 1.9339704872557063e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11702, \"tn\": 0, \"fp\": 7018, \"fn\": 79, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9932942874119345, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.006705712588065529, \"precision\": 0.6251068376068376, \"recall\": 0.9932942874119345, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6224799191446354, \"f1\": 0.7673191042916626, \"f2\": 0.8886155154607861, \"f0_5\": 0.6751595296615548, \"p4\": 0.0, \"phi\": -0.05013906459278557}, {\"truth_threshold\": -18.6, \"match_probability\": 2.5167552755248973e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11701, \"tn\": 0, \"fp\": 7018, \"fn\": 80, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9932094049741108, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.006790595025889143, \"precision\": 0.6250868101928522, \"recall\": 0.9932094049741108, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6224267248257886, \"f1\": 0.7672786885245901, \"f2\": 0.8885530732196285, \"f0_5\": 0.6751329956033557, \"p4\": 0.0, \"phi\": -0.05045675021089498}, {\"truth_threshold\": -18.54, \"match_probability\": 2.623630922747984e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11700, \"tn\": 0, \"fp\": 7018, \"fn\": 81, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9931245225362872, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.006875477463712758, \"precision\": 0.6250667806389572, \"recall\": 0.9931245225362872, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6223735305069419, \"f1\": 0.7672382701072167, \"f2\": 0.8884906290817411, \"f0_5\": 0.6751064590954727, \"p4\": 0.0, \"phi\": -0.050772481721047695}, {\"truth_threshold\": -18.52, \"match_probability\": 2.660255348159996e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11699, \"tn\": 0, \"fp\": 7018, \"fn\": 82, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9930396400984637, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.006960359901536372, \"precision\": 0.6250467489448095, \"recall\": 0.9930396400984637, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6223203361880951, \"f1\": 0.7671978490392812, \"f2\": 0.8884281830470375, \"f0_5\": 0.6750799201375665, \"p4\": 0.0, \"phi\": -0.051086295359863865}, {\"truth_threshold\": -18.5, \"match_probability\": 2.6973910287592302e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11689, \"tn\": 0, \"fp\": 7018, \"fn\": 92, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9921908157202275, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.007809184279772515, \"precision\": 0.6248463142139307, \"recall\": 0.9921908157202275, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6217883929996276, \"f1\": 0.7667934925216479, \"f2\": 0.8878036183560937, \"f0_5\": 0.6748143957325451, \"p4\": 0.0, \"phi\": -0.054126188352213486}, {\"truth_threshold\": -18.46, \"match_probability\": 2.77322480226071e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11685, \"tn\": 0, \"fp\": 7018, \"fn\": 96, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.991851285968933, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.008148714031066972, \"precision\": 0.624766080307972, \"recall\": 0.991851285968933, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6215756157242407, \"f1\": 0.766631675633119, \"f2\": 0.8875537393470764, \"f0_5\": 0.674708117284307, \"p4\": 0.0, \"phi\": -0.055296237723073766}, {\"truth_threshold\": -18.400000000000002, \"match_probability\": 2.8909915630084804e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11683, \"tn\": 0, \"fp\": 7018, \"fn\": 98, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9916815210932858, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.008318478906714201, \"precision\": 0.6247259504839313, \"recall\": 0.9916815210932858, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.6214692270865472, \"f1\": 0.7665507512630405, \"f2\": 0.8874287884542347, \"f0_5\": 0.674654963330831, \"p4\": 0.0, \"phi\": -0.05587225845745488}, {\"truth_threshold\": -18.32, \"match_probability\": 3.0558297334917884e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11683, \"tn\": 1016, \"fp\": 6002, \"fn\": 98, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9916815210932858, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.008318478906714201, \"precision\": 0.660616341532372, \"recall\": 0.9916815210932858, \"specificity\": 0.14477058991165576, \"npv\": 0.9120287253141831, \"accuracy\": 0.6755146550348423, \"f1\": 0.7929817416683635, \"f2\": 0.9013408631517228, \"f0_5\": 0.7078804183177615, \"p4\": 0.3800091196339033, \"phi\": 0.2795328750393741}, {\"truth_threshold\": -18.26, \"match_probability\": 3.185597454736396e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11680, \"tn\": 1016, \"fp\": 6002, \"fn\": 101, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.991426873779815, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.008573126220185044, \"precision\": 0.6605587603212306, \"recall\": 0.991426873779815, \"specificity\": 0.14477058991165576, \"npv\": 0.909579230080573, \"accuracy\": 0.675355072078302, \"f1\": 0.7928588399008927, \"f2\": 0.9011511279819769, \"f0_5\": 0.7078015731617157, \"p4\": 0.37988844413573014, \"phi\": 0.2786599150342182}, {\"truth_threshold\": -18.06, \"match_probability\": 3.6592888225585765e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11673, \"tn\": 1016, \"fp\": 6002, \"fn\": 108, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9908326967150497, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.009167303284950344, \"precision\": 0.6604243281471004, \"recall\": 0.9908326967150497, \"specificity\": 0.14477058991165576, \"npv\": 0.9039145907473309, \"accuracy\": 0.6749827118463748, \"f1\": 0.7925719717544812, \"f2\": 0.900708344264572, \"f0_5\": 0.7076175119118342, \"p4\": 0.3796071376564188, \"phi\": 0.27663371481698795}, {\"truth_threshold\": -18.02, \"match_probability\": 3.7621650471616754e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11672, \"tn\": 1016, \"fp\": 6002, \"fn\": 109, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.990747814277226, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.009252185722773958, \"precision\": 0.6604051148579835, \"recall\": 0.990747814277226, \"specificity\": 0.14477058991165576, \"npv\": 0.9031111111111111, \"accuracy\": 0.6749295175275281, \"f1\": 0.7925309794601935, \"f2\": 0.9006450816383221, \"f0_5\": 0.7075912072456564, \"p4\": 0.37956698180229687, \"phi\": 0.27634547160732165}, {\"truth_threshold\": -17.96, \"match_probability\": 3.921927621719554e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11671, \"tn\": 1016, \"fp\": 6002, \"fn\": 110, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9906629318394025, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.009337068160597572, \"precision\": 0.6603858993945567, \"recall\": 0.9906629318394025, \"specificity\": 0.14477058991165576, \"npv\": 0.9023090586145648, \"accuracy\": 0.6748763232086813, \"f1\": 0.7924899843824268, \"f2\": 0.9005818170594317, \"f0_5\": 0.707564900027888, \"p4\": 0.37952683363743955, \"phi\": 0.27605752993667665}, {\"truth_threshold\": -17.88, \"match_probability\": 4.145547322903667e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11670, \"tn\": 1016, \"fp\": 6002, \"fn\": 111, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9905780494015788, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.009421950598421186, \"precision\": 0.6603666817564509, \"recall\": 0.9905780494015788, \"specificity\": 0.14477058991165576, \"npv\": 0.90150842945874, \"accuracy\": 0.6748231288898345, \"f1\": 0.7924489865208977, \"f2\": 0.9005185505278104, \"f0_5\": 0.7075385902581576, \"p4\": 0.3794866931594556, \"phi\": 0.27576988915932865}, {\"truth_threshold\": -17.8, \"match_probability\": 4.381917272552001e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11665, \"tn\": 1016, \"fp\": 6002, \"fn\": 116, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9901536372124607, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.009846362787539259, \"precision\": 0.6602705609328126, \"recall\": 0.9901536372124607, \"specificity\": 0.14477058991165576, \"npv\": 0.8975265017667845, \"accuracy\": 0.6745571572956008, \"f1\": 0.7922439554468894, \"f2\": 0.9002021885755738, \"f0_5\": 0.7074070031170784, \"p4\": 0.3792861059890126, \"phi\": 0.274336176208763}, {\"truth_threshold\": -17.68, \"match_probability\": 4.761980454925296e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11660, \"tn\": 1016, \"fp\": 6002, \"fn\": 121, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9897292250233427, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.01027077497665733, \"precision\": 0.6601743856867852, \"recall\": 0.9897292250233427, \"specificity\": 0.14477058991165576, \"npv\": 0.8935795954265612, \"accuracy\": 0.6742911857013671, \"f1\": 0.7920388547362701, \"f2\": 0.8998857777914981, \"f0_5\": 0.7072753521212195, \"p4\": 0.37908571063226915, \"phi\": 0.27290988985242676}, {\"truth_threshold\": -17.6, \"match_probability\": 5.033497882967444e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11656, \"tn\": 1016, \"fp\": 6002, \"fn\": 125, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9893896952720482, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.010610304727951787, \"precision\": 0.6600974062747763, \"recall\": 0.9893896952720482, \"specificity\": 0.14477058991165576, \"npv\": 0.8904469763365469, \"accuracy\": 0.6740784084259801, \"f1\": 0.7918747240055708, \"f2\": 0.8996326139977154, \"f0_5\": 0.7071699853178504, \"p4\": 0.37892553225256514, \"phi\": 0.2717741550946693}, {\"truth_threshold\": -17.5, \"match_probability\": 5.394767505720988e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11655, \"tn\": 1016, \"fp\": 6002, \"fn\": 126, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9893048128342246, \"tn_rate\": 0.14477058991165576, \"fp_rate\": 0.8552294100883443, \"fn_rate\": 0.0106951871657754, \"precision\": 0.6600781559721357, \"recall\": 0.9893048128342246, \"specificity\": 0.14477058991165576, \"npv\": 0.8896672504378283, \"accuracy\": 0.6740252141071333, \"f1\": 0.7918336843535566, \"f2\": 0.8995693181642765, \"f0_5\": 0.7071436372240896, \"p4\": 0.3788855067913778, \"phi\": 0.27149095154740166}, {\"truth_threshold\": -17.400000000000002, \"match_probability\": 5.78196641040085e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11655, \"tn\": 1019, \"fp\": 5999, \"fn\": 126, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9893048128342246, \"tn_rate\": 0.1451980621259618, \"fp_rate\": 0.8548019378740382, \"fn_rate\": 0.0106951871657754, \"precision\": 0.6601903251387787, \"recall\": 0.9893048128342246, \"specificity\": 0.1451980621259618, \"npv\": 0.8899563318777293, \"accuracy\": 0.6741847970636736, \"f1\": 0.7919143876337693, \"f2\": 0.8996109790360926, \"f0_5\": 0.7072466230566646, \"p4\": 0.3796391756902579, \"phi\": 0.272022622254944}, {\"truth_threshold\": -17.32, \"match_probability\": 6.111640790849928e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11654, \"tn\": 1019, \"fp\": 5999, \"fn\": 127, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.989219930396401, \"tn_rate\": 0.1451980621259618, \"fp_rate\": 0.8548019378740382, \"fn_rate\": 0.010780069603599016, \"precision\": 0.660171075737835, \"recall\": 0.989219930396401, \"specificity\": 0.1451980621259618, \"npv\": 0.8891797556719022, \"accuracy\": 0.6741316027448269, \"f1\": 0.7918733437521234, \"f2\": 0.8995476789601248, \"f0_5\": 0.7072202735669292, \"p4\": 0.3795991037051683, \"phi\": 0.27174001536135206}, {\"truth_threshold\": -17.2, \"match_probability\": 6.641729593923075e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11609, \"tn\": 1019, \"fp\": 5999, \"fn\": 172, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9854002206943383, \"tn_rate\": 0.1451980621259618, \"fp_rate\": 0.8548019378740382, \"fn_rate\": 0.01459977930566166, \"precision\": 0.65930258973194, \"recall\": 0.9854002206943383, \"specificity\": 0.1451980621259618, \"npv\": 0.855583543240974, \"accuracy\": 0.6717378583967232, \"f1\": 0.7900234781721052, \"f2\": 0.8966971513316443, \"f0_5\": 0.7060318927663508, \"p4\": 0.3778037455857157, \"phi\": 0.25931302476784174}, {\"truth_threshold\": -17.12, \"match_probability\": 7.020425342683196e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11608, \"tn\": 1019, \"fp\": 5999, \"fn\": 173, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9853153382565147, \"tn_rate\": 0.1451980621259618, \"fp_rate\": 0.8548019378740382, \"fn_rate\": 0.014684661743485273, \"precision\": 0.6592832396206054, \"recall\": 0.9853153382565147, \"specificity\": 0.1451980621259618, \"npv\": 0.8548657718120806, \"accuracy\": 0.6716846640778765, \"f1\": 0.789982305703008, \"f2\": 0.8966337612581298, \"f0_5\": 0.7060054251967546, \"p4\": 0.37776402302847795, \"phi\": 0.2590431156880426}, {\"truth_threshold\": -17.04, \"match_probability\": 7.42071326918649e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11606, \"tn\": 1019, \"fp\": 5999, \"fn\": 175, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9851455733808675, \"tn_rate\": 0.1451980621259618, \"fp_rate\": 0.8548019378740382, \"fn_rate\": 0.014854426619132501, \"precision\": 0.659244532803181, \"recall\": 0.9851455733808675, \"specificity\": 0.1451980621259618, \"npv\": 0.8534338358458962, \"accuracy\": 0.671578275440183, \"f1\": 0.7898999523582658, \"f2\": 0.8965069752352114, \"f0_5\": 0.7059524823298987, \"p4\": 0.3776846005350172, \"phi\": 0.25850408587763396}, {\"truth_threshold\": -17.0, \"match_probability\": 7.629336324033172e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11606, \"tn\": 1021, \"fp\": 5997, \"fn\": 175, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9851455733808675, \"tn_rate\": 0.14548304360216585, \"fp_rate\": 0.8545169563978341, \"fn_rate\": 0.014854426619132501, \"precision\": 0.6593194341873544, \"recall\": 0.9851455733808675, \"specificity\": 0.14548304360216585, \"npv\": 0.8536789297658863, \"accuracy\": 0.6716846640778765, \"f1\": 0.7899537163081949, \"f2\": 0.8965346764101534, \"f0_5\": 0.7060211940189554, \"p4\": 0.37818451088298166, \"phi\": 0.25886727641355256}, {\"truth_threshold\": -16.96, \"match_probability\": 7.843824480527219e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11605, \"tn\": 1021, \"fp\": 5997, \"fn\": 176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9850606909430439, \"tn_rate\": 0.14548304360216585, \"fp_rate\": 0.8545169563978341, \"fn_rate\": 0.014939309056956116, \"precision\": 0.6593000795364163, \"recall\": 0.9850606909430439, \"specificity\": 0.14548304360216585, \"npv\": 0.8529657477025898, \"accuracy\": 0.6716314697590298, \"f1\": 0.7899125344587006, \"f2\": 0.8964712789296418, \"f0_5\": 0.7059947194880093, \"p4\": 0.3781447750342406, \"phi\": 0.2585983259181526}, {\"truth_threshold\": -16.92, \"match_probability\": 8.064342623945162e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11604, \"tn\": 1021, \"fp\": 5997, \"fn\": 177, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9849758085052203, \"tn_rate\": 0.14548304360216585, \"fp_rate\": 0.8545169563978341, \"fn_rate\": 0.01502419149477973, \"precision\": 0.659280722686211, \"recall\": 0.9849758085052203, \"specificity\": 0.14548304360216585, \"npv\": 0.8522537562604341, \"accuracy\": 0.671578275440183, \"f1\": 0.7898713498060037, \"f2\": 0.8964078794901507, \"f0_5\": 0.7059682423799963, \"p4\": 0.3781050467216169, \"phi\": 0.25832963619517063}, {\"truth_threshold\": -16.86, \"match_probability\": 8.406798190175455e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11603, \"tn\": 1021, \"fp\": 5997, \"fn\": 178, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9848909260673967, \"tn_rate\": 0.14548304360216585, \"fp_rate\": 0.8545169563978341, \"fn_rate\": 0.015109073932603344, \"precision\": 0.6592613636363637, \"recall\": 0.9848909260673967, \"specificity\": 0.14548304360216585, \"npv\": 0.8515429524603837, \"accuracy\": 0.6715250811213362, \"f1\": 0.789830162349818, \"f2\": 0.8963444780915889, \"f0_5\": 0.7059417626945401, \"p4\": 0.3780653259427815, \"phi\": 0.25806120672018673}, {\"truth_threshold\": -16.7, \"match_probability\": 9.392798228865447e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11603, \"tn\": 1026, \"fp\": 5992, \"fn\": 178, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9848909260673967, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.015109073932603344, \"precision\": 0.6594487070190395, \"recall\": 0.9848909260673967, \"specificity\": 0.14619549729267597, \"npv\": 0.8521594684385382, \"accuracy\": 0.6717910527155699, \"f1\": 0.7899645969498911, \"f2\": 0.8964137270353374, \"f0_5\": 0.7061136062121931, \"p4\": 0.3793121538453965, \"phi\": 0.258968889796644}, {\"truth_threshold\": -16.68, \"match_probability\": 9.523915557150856e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11602, \"tn\": 1026, \"fp\": 5992, \"fn\": 179, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.984806043629573, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.015193956370426958, \"precision\": 0.6594293509150847, \"recall\": 0.984806043629573, \"specificity\": 0.14619549729267597, \"npv\": 0.8514522821576763, \"accuracy\": 0.6717378583967232, \"f1\": 0.7899234042553192, \"f2\": 0.8963503198491919, \"f0_5\": 0.7060871258687634, \"p4\": 0.37927235122181746, \"phi\": 0.25870114255914434}, {\"truth_threshold\": -16.66, \"match_probability\": 9.656863180023442e-06, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11601, \"tn\": 1026, \"fp\": 5992, \"fn\": 180, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9847211611917495, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.015278838808250574, \"precision\": 0.6594099926106974, \"recall\": 0.9847211611917495, \"specificity\": 0.14619549729267597, \"npv\": 0.8507462686567164, \"accuracy\": 0.6716846640778765, \"f1\": 0.7898822087560428, \"f2\": 0.8962869107035246, \"f0_5\": 0.706060642946697, \"p4\": 0.3792325561322761, \"phi\": 0.2584336530524562}, {\"truth_threshold\": -16.48, \"match_probability\": 1.0940090640376583e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11571, \"tn\": 1026, \"fp\": 5992, \"fn\": 210, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.982174688057041, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.017825311942959002, \"precision\": 0.6588282184137106, \"recall\": 0.982174688057041, \"specificity\": 0.14619549729267597, \"npv\": 0.8300970873786407, \"accuracy\": 0.670088834512474, \"f1\": 0.788645038167939, \"f2\": 0.8943837247051185, \"f0_5\": 0.7052649543476406, \"p4\": 0.3780421952722491, \"phi\": 0.250526310248507}, {\"truth_threshold\": -16.46, \"match_probability\": 1.1092806920501003e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11568, \"tn\": 1026, \"fp\": 5992, \"fn\": 213, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9819200407435702, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.018079959256429846, \"precision\": 0.6587699316628701, \"recall\": 0.9819200407435702, \"specificity\": 0.14619549729267597, \"npv\": 0.8280871670702179, \"accuracy\": 0.6699292515559339, \"f1\": 0.7885211819638049, \"f2\": 0.8941933090099561, \"f0_5\": 0.7051852574340718, \"p4\": 0.3779235296002872, \"phi\": 0.2497477910832354}, {\"truth_threshold\": -16.36, \"match_probability\": 1.1888966616803339e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11546, \"tn\": 1026, \"fp\": 5992, \"fn\": 235, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9800526271114507, \"tn_rate\": 0.14619549729267597, \"fp_rate\": 0.853804502707324, \"fn_rate\": 0.01994737288854936, \"precision\": 0.6583418861899875, \"recall\": 0.9800526271114507, \"specificity\": 0.14619549729267597, \"npv\": 0.8136399682791435, \"accuracy\": 0.6687589765413053, \"f1\": 0.7876121286537741, \"f2\": 0.8927963873681606, \"f0_5\": 0.7046001000817741, \"p4\": 0.37705536093923236, \"phi\": 0.2441041250767984}, {\"truth_threshold\": -16.34, \"match_probability\": 1.2054928405333336e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11546, \"tn\": 1027, \"fp\": 5991, \"fn\": 235, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9800526271114507, \"tn_rate\": 0.146337988030778, \"fp_rate\": 0.853662011969222, \"fn_rate\": 0.01994737288854936, \"precision\": 0.6583794263557051, \"recall\": 0.9800526271114507, \"specificity\": 0.146337988030778, \"npv\": 0.8137876386687797, \"accuracy\": 0.6688121708601521, \"f1\": 0.7876389931100348, \"f2\": 0.8928101947077837, \"f0_5\": 0.7046345006041816, \"p4\": 0.3773032549254889, \"phi\": 0.24428975786623822}, {\"truth_threshold\": -16.32, \"match_probability\": 1.2223206877850105e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11546, \"tn\": 1030, \"fp\": 5988, \"fn\": 235, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9800526271114507, \"tn_rate\": 0.14676546024508408, \"fp_rate\": 0.8532345397549159, \"fn_rate\": 0.01994737288854936, \"precision\": 0.6584920725447702, \"recall\": 0.9800526271114507, \"specificity\": 0.14676546024508408, \"npv\": 0.8142292490118577, \"accuracy\": 0.6689717538166924, \"f1\": 0.7877195974756951, \"f2\": 0.8928516192891831, \"f0_5\": 0.7047377223286986, \"p4\": 0.37804603113306046, \"phi\": 0.2448461023836503}, {\"truth_threshold\": -16.3, \"match_probability\": 1.2393834372475679e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11546, \"tn\": 1031, \"fp\": 5987, \"fn\": 235, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9800526271114507, \"tn_rate\": 0.1469079509831861, \"fp_rate\": 0.8530920490168139, \"fn_rate\": 0.01994737288854936, \"precision\": 0.6585296298408715, \"recall\": 0.9800526271114507, \"specificity\": 0.1469079509831861, \"npv\": 0.8143759873617693, \"accuracy\": 0.6690249481355391, \"f1\": 0.787746469263833, \"f2\": 0.8928654283372257, \"f0_5\": 0.7047721362909428, \"p4\": 0.37829332180226427, \"phi\": 0.24503136644978388}, {\"truth_threshold\": -16.240000000000002, \"match_probability\": 1.2920141178795591e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11545, \"tn\": 1032, \"fp\": 5986, \"fn\": 236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.979967744673627, \"tn_rate\": 0.14705044172128812, \"fp_rate\": 0.8529495582787119, \"fn_rate\": 0.020032255326372973, \"precision\": 0.6585477154754436, \"recall\": 0.979967744673627, \"specificity\": 0.14705044172128812, \"npv\": 0.8138801261829653, \"accuracy\": 0.6690249481355391, \"f1\": 0.7877319868995634, \"f2\": 0.8928157141752378, \"f0_5\": 0.7047799279653257, \"p4\": 0.37850097894674795, \"phi\": 0.2449631148763324}, {\"truth_threshold\": -16.14, \"match_probability\": 1.384745160659142e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11545, \"tn\": 1037, \"fp\": 5981, \"fn\": 236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.979967744673627, \"tn_rate\": 0.14776289541179824, \"fp_rate\": 0.8522371045882018, \"fn_rate\": 0.020032255326372973, \"precision\": 0.6587355928335045, \"recall\": 0.979967744673627, \"specificity\": 0.14776289541179824, \"npv\": 0.8146111547525531, \"accuracy\": 0.6692909197297728, \"f1\": 0.7878663800457228, \"f2\": 0.8928847641144625, \"f0_5\": 0.7049520669231238, \"p4\": 0.37973434092013925, \"phi\": 0.24588794816241272}, {\"truth_threshold\": -16.080000000000002, \"match_probability\": 1.4435485686095844e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11544, \"tn\": 1037, \"fp\": 5981, \"fn\": 237, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9798828622358035, \"tn_rate\": 0.14776289541179824, \"fp_rate\": 0.8522371045882018, \"fn_rate\": 0.020117137764196588, \"precision\": 0.658716119828816, \"recall\": 0.9798828622358035, \"specificity\": 0.14776289541179824, \"npv\": 0.8139717425431711, \"accuracy\": 0.6692377254109261, \"f1\": 0.7878250187674879, \"f2\": 0.8928212346672029, \"f0_5\": 0.7049254405784003, \"p4\": 0.3796947773178646, \"phi\": 0.2456350958704752}, {\"truth_threshold\": -16.02, \"match_probability\": 1.5048490343933547e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11543, \"tn\": 1037, \"fp\": 5981, \"fn\": 238, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9797979797979798, \"tn_rate\": 0.14776289541179824, \"fp_rate\": 0.8522371045882018, \"fn_rate\": 0.020202020202020204, \"precision\": 0.6586966446016891, \"recall\": 0.9797979797979798, \"specificity\": 0.14776289541179824, \"npv\": 0.8133333333333334, \"accuracy\": 0.6691845310920793, \"f1\": 0.7877836546664392, \"f2\": 0.8927577032545477, \"f0_5\": 0.7048988116320822, \"p4\": 0.37965522112671046, \"phi\": 0.24538247107453226}, {\"truth_threshold\": -15.94, \"match_probability\": 1.5906512128400478e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11533, \"tn\": 1037, \"fp\": 5981, \"fn\": 248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9789491554197437, \"tn_rate\": 0.14776289541179824, \"fp_rate\": 0.8522371045882018, \"fn_rate\": 0.021050844580256346, \"precision\": 0.6585017700125614, \"recall\": 0.9789491554197437, \"specificity\": 0.14776289541179824, \"npv\": 0.8070038910505837, \"accuracy\": 0.6686525879036119, \"f1\": 0.7873698583376003, \"f2\": 0.8921222810111699, \"f0_5\": 0.704632378997275, \"p4\": 0.37926006632734677, \"phi\": 0.24286864142372055}, {\"truth_threshold\": -15.92, \"match_probability\": 1.612855518169533e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11533, \"tn\": 1039, \"fp\": 5979, \"fn\": 248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9789491554197437, \"tn_rate\": 0.14804787688800228, \"fp_rate\": 0.8519521231119978, \"fn_rate\": 0.021050844580256346, \"precision\": 0.6585769757880311, \"recall\": 0.9789491554197437, \"specificity\": 0.14804787688800228, \"npv\": 0.8073038073038074, \"accuracy\": 0.6687589765413053, \"f1\": 0.7874236165636842, \"f2\": 0.8921498855127173, \"f0_5\": 0.7047012672768823, \"p4\": 0.3797519433833441, \"phi\": 0.2432395462540419}, {\"truth_threshold\": -15.860000000000001, \"match_probability\": 1.6813455033027547e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11533, \"tn\": 1379, \"fp\": 5639, \"fn\": 248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9789491554197437, \"tn_rate\": 0.19649472784269023, \"fp_rate\": 0.8035052721573098, \"fn_rate\": 0.021050844580256346, \"precision\": 0.6716165851385977, \"recall\": 0.9789491554197437, \"specificity\": 0.19649472784269023, \"npv\": 0.8475722188076213, \"accuracy\": 0.6868450449491994, \"f1\": 0.7966704659275378, \"f2\": 0.8968676122931442, \"f0_5\": 0.7166113658676012, \"p4\": 0.4556076513977343, \"phi\": 0.3018087141066393}, {\"truth_threshold\": -15.84, \"match_probability\": 1.7048158117438166e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11533, \"tn\": 1383, \"fp\": 5635, \"fn\": 248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9789491554197437, \"tn_rate\": 0.1970646907950983, \"fp_rate\": 0.8029353092049016, \"fn_rate\": 0.021050844580256346, \"precision\": 0.6717730661696178, \"recall\": 0.9789491554197437, \"specificity\": 0.1970646907950983, \"npv\": 0.8479460453709381, \"accuracy\": 0.6870578222245864, \"f1\": 0.796780545096549, \"f2\": 0.8969234119330555, \"f0_5\": 0.7167538811479994, \"p4\": 0.45641793279331694, \"phi\": 0.3024529050507099}, {\"truth_threshold\": -15.82, \"match_probability\": 1.728613742232168e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11510, \"tn\": 1383, \"fp\": 5635, \"fn\": 271, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9769968593498005, \"tn_rate\": 0.1970646907950983, \"fp_rate\": 0.8029353092049016, \"fn_rate\": 0.023003140650199472, \"precision\": 0.6713327500729076, \"recall\": 0.9769968593498005, \"specificity\": 0.1970646907950983, \"npv\": 0.8361547762998791, \"accuracy\": 0.6858343528911113, \"f1\": 0.7958238263154256, \"f2\": 0.8954550405327607, \"f0_5\": 0.7161434028944389, \"p4\": 0.45539696221506576, \"phi\": 0.2972104734353207}, {\"truth_threshold\": -15.8, \"match_probability\": 1.7527438678849133e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11507, \"tn\": 1383, \"fp\": 5635, \"fn\": 274, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9767422120363297, \"tn_rate\": 0.1970646907950983, \"fp_rate\": 0.8029353092049016, \"fn_rate\": 0.023257787963670316, \"precision\": 0.671275230428188, \"recall\": 0.9767422120363297, \"specificity\": 0.1970646907950983, \"npv\": 0.8346409173204586, \"accuracy\": 0.685674769934571, \"f1\": 0.7956989247311828, \"f2\": 0.8952634363427007, \"f0_5\": 0.7160636722298971, \"p4\": 0.45526408270573004, \"phi\": 0.2965328290975544}, {\"truth_threshold\": -15.72, \"match_probability\": 1.8526800373059223e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11502, \"tn\": 1383, \"fp\": 5635, \"fn\": 279, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9763177998472116, \"tn_rate\": 0.1970646907950983, \"fp_rate\": 0.8029353092049016, \"fn_rate\": 0.023682200152788387, \"precision\": 0.6711793196008636, \"recall\": 0.9763177998472116, \"specificity\": 0.1970646907950983, \"npv\": 0.8321299638989169, \"accuracy\": 0.6854087983403373, \"f1\": 0.7954906978352583, \"f2\": 0.8949440562705218, \"f0_5\": 0.7159307348529174, \"p4\": 0.45504276542374156, \"phi\": 0.2954065285950675}, {\"truth_threshold\": -15.700000000000001, \"match_probability\": 1.878542001007107e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11502, \"tn\": 1431, \"fp\": 5587, \"fn\": 279, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9763177998472116, \"tn_rate\": 0.20390424622399544, \"fp_rate\": 0.7960957537760046, \"fn_rate\": 0.023682200152788387, \"precision\": 0.6730645444437943, \"recall\": 0.9763177998472116, \"specificity\": 0.20390424622399544, \"npv\": 0.8368421052631579, \"accuracy\": 0.6879621256449812, \"f1\": 0.796813301004503, \"f2\": 0.8956130378583775, \"f0_5\": 0.7176460311716186, \"p4\": 0.46461764881851775, \"phi\": 0.3031442226325634}, {\"truth_threshold\": -15.64, \"match_probability\": 1.958314154131918e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11502, \"tn\": 1432, \"fp\": 5586, \"fn\": 279, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9763177998472116, \"tn_rate\": 0.20404673696209746, \"fp_rate\": 0.7959532630379025, \"fn_rate\": 0.023682200152788387, \"precision\": 0.6731039325842697, \"recall\": 0.9763177998472116, \"specificity\": 0.20404673696209746, \"npv\": 0.836937463471654, \"accuracy\": 0.6880153199638278, \"f1\": 0.7968409020056115, \"f2\": 0.8956269856101663, \"f0_5\": 0.7176818539178615, \"p4\": 0.4648145975960187, \"phi\": 0.3033041050714613}, {\"truth_threshold\": -15.58, \"match_probability\": 2.0414737569369415e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11502, \"tn\": 1438, \"fp\": 5580, \"fn\": 279, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9763177998472116, \"tn_rate\": 0.2049016813907096, \"fp_rate\": 0.7950983186092904, \"fn_rate\": 0.023682200152788387, \"precision\": 0.6733403582718651, \"recall\": 0.9763177998472116, \"specificity\": 0.2049016813907096, \"npv\": 0.8375072801397787, \"accuracy\": 0.6883344858769084, \"f1\": 0.7970065481758652, \"f2\": 0.8957106812447435, \"f0_5\": 0.717896865520728, \"p4\": 0.4659941593646046, \"phi\": 0.30426229477964445}, {\"truth_threshold\": -15.540000000000001, \"match_probability\": 2.0988661916466824e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11501, \"tn\": 1445, \"fp\": 5573, \"fn\": 280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.976232917409388, \"tn_rate\": 0.20589911655742377, \"fp_rate\": 0.7941008834425762, \"fn_rate\": 0.023767082590612002, \"precision\": 0.6735972824177111, \"recall\": 0.976232917409388, \"specificity\": 0.20589911655742377, \"npv\": 0.8376811594202899, \"accuracy\": 0.6886536517899888, \"f1\": 0.7971582048171894, \"f2\": 0.8957444157138852, \"f0_5\": 0.7181213082408182, \"p4\": 0.46732076699629727, \"phi\": 0.3051559970496031}, {\"truth_threshold\": -15.5, \"match_probability\": 2.1578720786338814e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11501, \"tn\": 1449, \"fp\": 5569, \"fn\": 280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.976232917409388, \"tn_rate\": 0.20646907950983187, \"fp_rate\": 0.7935309204901682, \"fn_rate\": 0.023767082590612002, \"precision\": 0.6737551259519625, \"recall\": 0.976232917409388, \"specificity\": 0.20646907950983187, \"npv\": 0.8380566801619433, \"accuracy\": 0.6888664290653758, \"f1\": 0.7972687255207792, \"f2\": 0.8958002305511419, \"f0_5\": 0.7182648230724072, \"p4\": 0.4681022586206744, \"phi\": 0.30579247705567114}, {\"truth_threshold\": -15.48, \"match_probability\": 2.187994191220544e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11501, \"tn\": 1453, \"fp\": 5565, \"fn\": 280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.976232917409388, \"tn_rate\": 0.20703904246223995, \"fp_rate\": 0.7929609575377601, \"fn_rate\": 0.023767082590612002, \"precision\": 0.6739130434782609, \"recall\": 0.976232917409388, \"specificity\": 0.20703904246223995, \"npv\": 0.8384304673975764, \"accuracy\": 0.6890792063407628, \"f1\": 0.797379276874545, \"f2\": 0.895856052344602, \"f0_5\": 0.7184083952776563, \"p4\": 0.4688821492365646, \"phi\": 0.3064281308328683}, {\"truth_threshold\": -15.44, \"match_probability\": 2.2495056969010486e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1455, \"fp\": 5563, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.207324023938444, \"fp_rate\": 0.792675976061556, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6739729238703628, \"recall\": 0.9761480349715644, \"specificity\": 0.207324023938444, \"npv\": 0.8381336405529954, \"accuracy\": 0.6891324006596096, \"f1\": 0.7973928720011094, \"f2\": 0.8958200258619347, \"f0_5\": 0.7184536378743768, \"p4\": 0.46922644308689165, \"phi\": 0.3065244619212052}, {\"truth_threshold\": -15.4, \"match_probability\": 2.3127464474935175e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1456, \"fp\": 5562, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.20746651467654603, \"fp_rate\": 0.792533485323454, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6740124252725355, \"recall\": 0.9761480349715644, \"specificity\": 0.20746651467654603, \"npv\": 0.8382268278641336, \"accuracy\": 0.6891855949784563, \"f1\": 0.7974205179766322, \"f2\": 0.8958339824883931, \"f0_5\": 0.7184895475390171, \"p4\": 0.4694209561861532, \"phi\": 0.306683191219822}, {\"truth_threshold\": -15.38, \"match_probability\": 2.345030427699851e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1462, \"fp\": 5556, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.20832145910515817, \"fp_rate\": 0.7916785408948418, \"fn_rate\": 0.023851965028435618, \"precision\": 0.674249530956848, \"recall\": 0.9761480349715644, \"specificity\": 0.20832145910515817, \"npv\": 0.8387837062535858, \"accuracy\": 0.6895047608915368, \"f1\": 0.7975864340950862, \"f2\": 0.8959177313804924, \"f0_5\": 0.7187050809324417, \"p4\": 0.47058595004111436, \"phi\": 0.30763449369788154}, {\"truth_threshold\": -15.36, \"match_probability\": 2.3777650541913158e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1467, \"fp\": 5551, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.20903391279566827, \"fp_rate\": 0.7909660872043317, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6744472464958067, \"recall\": 0.9761480349715644, \"specificity\": 0.20903391279566827, \"npv\": 0.8392448512585813, \"accuracy\": 0.6897707324857705, \"f1\": 0.7977247502774695, \"f2\": 0.8959875340864822, \"f0_5\": 0.7188847908982934, \"p4\": 0.47155405803146244, \"phi\": 0.3084258471898768}, {\"truth_threshold\": -15.32, \"match_probability\": 2.4446114945779867e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1472, \"fp\": 5546, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.2097463664861784, \"fp_rate\": 0.7902536335138216, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6746450780241698, \"recall\": 0.9761480349715644, \"specificity\": 0.2097463664861784, \"npv\": 0.8397033656588705, \"accuracy\": 0.6900367040800043, \"f1\": 0.7978631144413224, \"f2\": 0.8960573476702509, \"f0_5\": 0.7190645907584569, \"p4\": 0.4725197049063082, \"phi\": 0.3092159376215597}, {\"truth_threshold\": -15.3, \"match_probability\": 2.478736153449797e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1476, \"fp\": 5542, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.2103163294385865, \"fp_rate\": 0.7896836705614135, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6748034268278371, \"recall\": 0.9761480349715644, \"specificity\": 0.2103163294385865, \"npv\": 0.8400682982356289, \"accuracy\": 0.6902494813553912, \"f1\": 0.797973840335843, \"f2\": 0.8961132063709752, \"f0_5\": 0.7192084954158275, \"p4\": 0.47329045780186446, \"phi\": 0.3098471057904481}, {\"truth_threshold\": -15.26, \"match_probability\": 2.5484211360819274e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 1480, \"fp\": 5538, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.21088629239099457, \"fp_rate\": 0.7891137076090055, \"fn_rate\": 0.023851965028435618, \"precision\": 0.6749618499823923, \"recall\": 0.9761480349715644, \"specificity\": 0.21088629239099457, \"npv\": 0.8404315729699035, \"accuracy\": 0.6904622586307783, \"f1\": 0.7980845969672785, \"f2\": 0.8961690720364078, \"f0_5\": 0.7193524576833098, \"p4\": 0.4740596482349286, \"phi\": 0.3104774745274921}, {\"truth_threshold\": -15.200000000000001, \"match_probability\": 2.6566389035375488e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11500, \"tn\": 2327, \"fp\": 4691, \"fn\": 281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9761480349715644, \"tn_rate\": 0.33157594756340836, \"fp_rate\": 0.6684240524365916, \"fn_rate\": 0.023851965028435618, \"precision\": 0.7102711382867025, \"recall\": 0.9761480349715644, \"specificity\": 0.33157594756340836, \"npv\": 0.8922546012269938, \"accuracy\": 0.7355178466939731, \"f1\": 0.8222508222508222, \"f2\": 0.9081576245755351, \"f0_5\": 0.7511921092168006, \"p4\": 0.6089202741427997, \"phi\": 0.4305944961828753}, {\"truth_threshold\": -15.18, \"match_probability\": 2.693723201645637e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11496, \"tn\": 2327, \"fp\": 4691, \"fn\": 285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.97580850522027, \"tn_rate\": 0.33157594756340836, \"fp_rate\": 0.6684240524365916, \"fn_rate\": 0.024191494779730073, \"precision\": 0.7101995428430222, \"recall\": 0.97580850522027, \"specificity\": 0.33157594756340836, \"npv\": 0.8908882082695253, \"accuracy\": 0.7353050694185861, \"f1\": 0.8220823798627003, \"f2\": 0.907899101262024, \"f0_5\": 0.7510878229168028, \"p4\": 0.608714805678221, \"phi\": 0.42984302884972114}, {\"truth_threshold\": -15.16, \"match_probability\": 2.7313251491794388e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11496, \"tn\": 2329, \"fp\": 4689, \"fn\": 285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.97580850522027, \"tn_rate\": 0.33186092903961245, \"fp_rate\": 0.6681390709603876, \"fn_rate\": 0.024191494779730073, \"precision\": 0.7102873030583874, \"recall\": 0.97580850522027, \"specificity\": 0.33186092903961245, \"npv\": 0.8909716908951798, \"accuracy\": 0.7354114580562796, \"f1\": 0.8221411714224416, \"f2\": 0.9079277827796995, \"f0_5\": 0.7511663464931195, \"p4\": 0.6089806884461857, \"phi\": 0.4301034927937229}, {\"truth_threshold\": -15.14, \"match_probability\": 2.7694519714661317e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11492, \"tn\": 2329, \"fp\": 4689, \"fn\": 289, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9754689754689755, \"tn_rate\": 0.33186092903961245, \"fp_rate\": 0.6681390709603876, \"fn_rate\": 0.024531024531024532, \"precision\": 0.7102156850627279, \"recall\": 0.9754689754689755, \"specificity\": 0.33186092903961245, \"npv\": 0.8896103896103896, \"accuracy\": 0.7351986807808926, \"f1\": 0.821972677204778, \"f2\": 0.9076692204407235, \"f0_5\": 0.7510620220900595, \"p4\": 0.6087752894468971, \"phi\": 0.4293535725378913}, {\"truth_threshold\": -15.120000000000001, \"match_probability\": 2.808110994672502e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11492, \"tn\": 2334, \"fp\": 4684, \"fn\": 289, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9754689754689755, \"tn_rate\": 0.33257338273012255, \"fp_rate\": 0.6674266172698775, \"fn_rate\": 0.024531024531024532, \"precision\": 0.710435212660732, \"recall\": 0.9754689754689755, \"specificity\": 0.33257338273012255, \"npv\": 0.8898208158597026, \"accuracy\": 0.7354646523751264, \"f1\": 0.8221196838001216, \"f2\": 0.9077409162717219, \"f0_5\": 0.7512584166830097, \"p4\": 0.6094390438045145, \"phi\": 0.4300049796789099}, {\"truth_threshold\": -15.040000000000001, \"match_probability\": 2.9682192287631416e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11485, \"tn\": 2335, \"fp\": 4683, \"fn\": 296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9748747984042102, \"tn_rate\": 0.33271587346822457, \"fp_rate\": 0.6672841265317755, \"fn_rate\": 0.02512520159578983, \"precision\": 0.7103537852548244, \"recall\": 0.9748747984042102, \"specificity\": 0.33271587346822457, \"npv\": 0.88749524895477, \"accuracy\": 0.7351454864620458, \"f1\": 0.8218540913807292, \"f2\": 0.9073026606838147, \"f0_5\": 0.7511150641570639, \"p4\": 0.6092122611763038, \"phi\": 0.4288272217464924}, {\"truth_threshold\": -15.02, \"match_probability\": 3.0096527780559407e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11485, \"tn\": 2343, \"fp\": 4675, \"fn\": 296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9748747984042102, \"tn_rate\": 0.3338557993730408, \"fp_rate\": 0.6661442006269592, \"fn_rate\": 0.02512520159578983, \"precision\": 0.7107054455445545, \"recall\": 0.9748747984042102, \"specificity\": 0.3338557993730408, \"npv\": 0.8878363016294051, \"accuracy\": 0.7355710410128198, \"f1\": 0.8220894026699116, \"f2\": 0.9074173566778333, \"f0_5\": 0.751429580874367, \"p4\": 0.6102710743491272, \"phi\": 0.4298699238137703}, {\"truth_threshold\": -15.0, \"match_probability\": 3.0516646830846227e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11484, \"tn\": 2345, \"fp\": 4673, \"fn\": 297, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9747899159663865, \"tn_rate\": 0.3341407808492448, \"fp_rate\": 0.6658592191507552, \"fn_rate\": 0.025210084033613446, \"precision\": 0.7107755152565451, \"recall\": 0.9747899159663865, \"specificity\": 0.3341407808492448, \"npv\": 0.8875851627554883, \"accuracy\": 0.7356242353316665, \"f1\": 0.8221060920609922, \"f2\": 0.9073813624942716, \"f0_5\": 0.7514821552434923, \"p4\": 0.6104839301547379, \"phi\": 0.4299441605666149}, {\"truth_threshold\": -14.94, \"match_probability\": 3.181251823059389e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11483, \"tn\": 2348, \"fp\": 4670, \"fn\": 298, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.974705033528563, \"tn_rate\": 0.33456825306355087, \"fp_rate\": 0.6654317469364491, \"fn_rate\": 0.025294966471437058, \"precision\": 0.710889618027611, \"recall\": 0.974705033528563, \"specificity\": 0.33456825306355087, \"npv\": 0.8873771730914588, \"accuracy\": 0.7357306239693601, \"f1\": 0.8221522159375672, \"f2\": 0.9073597041579089, \"f0_5\": 0.7515740971031377, \"p4\": 0.6108285089691285, \"phi\": 0.43014873793644026}, {\"truth_threshold\": -14.92, \"match_probability\": 3.225659011119708e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2348, \"fp\": 4670, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.33456825306355087, \"fp_rate\": 0.6654317469364491, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7108717186726102, \"recall\": 0.9746201510907393, \"specificity\": 0.33456825306355087, \"npv\": 0.887041934265206, \"accuracy\": 0.7356774296505133, \"f1\": 0.8221100490459313, \"f2\": 0.9072950249699728, \"f0_5\": 0.7515479977483669, \"p4\": 0.6107771482424688, \"phi\": 0.429962752077323}, {\"truth_threshold\": -14.9, \"match_probability\": 3.270686060153373e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2350, \"fp\": 4668, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.3348532345397549, \"fp_rate\": 0.6651467654602451, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7109597523219814, \"recall\": 0.9746201510907393, \"specificity\": 0.3348532345397549, \"npv\": 0.8871272178180446, \"accuracy\": 0.7357838182882068, \"f1\": 0.8221689162579213, \"f2\": 0.9073237032588425, \"f0_5\": 0.7516267134496799, \"p4\": 0.6110408517156777, \"phi\": 0.4302231973647146}, {\"truth_threshold\": -14.86, \"match_probability\": 3.362634469102074e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2353, \"fp\": 4665, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.33528070675406096, \"fp_rate\": 0.664719293245939, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7110918436861337, \"recall\": 0.9746201510907393, \"specificity\": 0.33528070675406096, \"npv\": 0.8872549019607843, \"accuracy\": 0.7359434012447471, \"f1\": 0.8222572328845603, \"f2\": 0.9073667240916059, \"f0_5\": 0.751744817923503, \"p4\": 0.6114360440607254, \"phi\": 0.4306137129314676}, {\"truth_threshold\": -14.82, \"match_probability\": 3.457167723387977e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2356, \"fp\": 4662, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.3357081789683671, \"fp_rate\": 0.664291821031633, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7112239841427156, \"recall\": 0.9746201510907393, \"specificity\": 0.3357081789683671, \"npv\": 0.8873822975517891, \"accuracy\": 0.7361029842012873, \"f1\": 0.8223455684870188, \"f2\": 0.907409749004236, \"f0_5\": 0.7518629595191011, \"p4\": 0.6118308018052537, \"phi\": 0.4310040461076284}, {\"truth_threshold\": -14.780000000000001, \"match_probability\": 3.5543584828534594e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2357, \"fp\": 4661, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.3358506697064691, \"fp_rate\": 0.664149330293531, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7112680418757357, \"recall\": 0.9746201510907393, \"specificity\": 0.3358506697064691, \"npv\": 0.8874246987951807, \"accuracy\": 0.736156178520134, \"f1\": 0.8223750179057442, \"f2\": 0.9074240915485166, \"f0_5\": 0.7519023483032756, \"p4\": 0.6119622913046509, \"phi\": 0.43113411672173385}, {\"truth_threshold\": -14.74, \"match_probability\": 3.65428144951405e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2361, \"fp\": 4657, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.3364206326588772, \"fp_rate\": 0.6635793673411228, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7114443274056633, \"recall\": 0.9746201510907393, \"specificity\": 0.3364206326588772, \"npv\": 0.887593984962406, \"accuracy\": 0.7363689557955211, \"f1\": 0.8224928366762178, \"f2\": 0.9074814662598991, \"f0_5\": 0.7520599447188127, \"p4\": 0.612487768150905, \"phi\": 0.4316541974486196}, {\"truth_threshold\": -14.68, \"match_probability\": 3.809457380009125e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11482, \"tn\": 2364, \"fp\": 4654, \"fn\": 299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9746201510907393, \"tn_rate\": 0.33684810487318323, \"fp_rate\": 0.6631518951268167, \"fn_rate\": 0.025379848909260674, \"precision\": 0.7115765989092712, \"recall\": 0.9746201510907393, \"specificity\": 0.33684810487318323, \"npv\": 0.8877206158467893, \"accuracy\": 0.7365285387520613, \"f1\": 0.8225812229107712, \"f2\": 0.9075245020550111, \"f0_5\": 0.7521781853914182, \"p4\": 0.6128813715463969, \"phi\": 0.43204404669443897}, {\"truth_threshold\": -14.56, \"match_probability\": 4.1398564635490015e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11481, \"tn\": 2364, \"fp\": 4654, \"fn\": 300, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9745352686529157, \"tn_rate\": 0.33684810487318323, \"fp_rate\": 0.6631518951268167, \"fn_rate\": 0.02546473134708429, \"precision\": 0.7115587232723892, \"recall\": 0.9745352686529157, \"specificity\": 0.33684810487318323, \"npv\": 0.8873873873873874, \"accuracy\": 0.7364753444332145, \"f1\": 0.8225390457085542, \"f2\": 0.9074598080905484, \"f0_5\": 0.752152094443207, \"p4\": 0.6128299450259981, \"phi\": 0.43185861169783035}, {\"truth_threshold\": -14.540000000000001, \"match_probability\": 4.197644280356719e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11481, \"tn\": 2369, \"fp\": 4649, \"fn\": 300, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9745352686529157, \"tn_rate\": 0.3375605585636934, \"fp_rate\": 0.6624394414363066, \"fn_rate\": 0.02546473134708429, \"precision\": 0.7117792932424054, \"recall\": 0.9745352686529157, \"specificity\": 0.3375605585636934, \"npv\": 0.8875983514424878, \"accuracy\": 0.7367413160274483, \"f1\": 0.8226863960445703, \"f2\": 0.907531539507383, \"f0_5\": 0.752349248371581, \"p4\": 0.6134849705820434, \"phi\": 0.4325081060894403}, {\"truth_threshold\": -14.52, \"match_probability\": 4.2562387168288515e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11471, \"tn\": 2375, \"fp\": 4643, \"fn\": 310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9736864442746795, \"tn_rate\": 0.3384155029923055, \"fp_rate\": 0.6615844970076945, \"fn_rate\": 0.02631355572532043, \"precision\": 0.7118654586074221, \"recall\": 0.9736864442746795, \"specificity\": 0.3384155029923055, \"npv\": 0.8845437616387337, \"accuracy\": 0.7365285387520613, \"f1\": 0.8224412977236064, \"f2\": 0.9069704924254404, \"f0_5\": 0.7523249865550848, \"p4\": 0.6137550311669586, \"phi\": 0.4314400062660038}, {\"truth_threshold\": -14.5, \"match_probability\": 4.315651031039153e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11471, \"tn\": 2377, \"fp\": 4641, \"fn\": 310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9736864442746795, \"tn_rate\": 0.33870048446850953, \"fp_rate\": 0.6612995155314905, \"fn_rate\": 0.02631355572532043, \"precision\": 0.7119538232373386, \"recall\": 0.9736864442746795, \"specificity\": 0.33870048446850953, \"npv\": 0.8846296985485672, \"accuracy\": 0.7366349273897548, \"f1\": 0.8225002688846664, \"f2\": 0.906999177683598, \"f0_5\": 0.7524039407574545, \"p4\": 0.6140160469101568, \"phi\": 0.43170000475966475}, {\"truth_threshold\": -14.46, \"match_probability\": 4.4369751126756925e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11468, \"tn\": 2377, \"fp\": 4641, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9734317969612087, \"tn_rate\": 0.33870048446850953, \"fp_rate\": 0.6612995155314905, \"fn_rate\": 0.026568203038791274, \"precision\": 0.7119001800235893, \"recall\": 0.9734317969612087, \"specificity\": 0.33870048446850953, \"npv\": 0.88364312267658, \"accuracy\": 0.7364753444332145, \"f1\": 0.822373610613123, \"f2\": 0.9068049910647921, \"f0_5\": 0.7523255966516657, \"p4\": 0.6138618296116026, \"phi\": 0.4311476426492358}, {\"truth_threshold\": -14.44, \"match_probability\": 4.4989101905610624e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11468, \"tn\": 2392, \"fp\": 4626, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9734317969612087, \"tn_rate\": 0.3408378455400399, \"fp_rate\": 0.6591621544599601, \"fn_rate\": 0.026568203038791274, \"precision\": 0.7125636883310551, \"recall\": 0.9734317969612087, \"specificity\": 0.3408378455400399, \"npv\": 0.8842883548983365, \"accuracy\": 0.7372732592159157, \"f1\": 0.8228161434977579, \"f2\": 0.9070201524882154, \"f0_5\": 0.7529183134839871, \"p4\": 0.6158132217083135, \"phi\": 0.4330963844825314}, {\"truth_threshold\": -14.4, \"match_probability\": 4.625385921538452e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11468, \"tn\": 2408, \"fp\": 4610, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9734317969612087, \"tn_rate\": 0.3431176973496723, \"fp_rate\": 0.6568823026503278, \"fn_rate\": 0.026568203038791274, \"precision\": 0.7132727951237716, \"recall\": 0.9734317969612087, \"specificity\": 0.3431176973496723, \"npv\": 0.8849687614847482, \"accuracy\": 0.7381243683174636, \"f1\": 0.8232887038300011, \"f2\": 0.9072497705768805, \"f0_5\": 0.7535515750463249, \"p4\": 0.61788307838454, \"phi\": 0.43517015318169655}, {\"truth_threshold\": -14.38, \"match_probability\": 4.6899508746246485e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11468, \"tn\": 2410, \"fp\": 4608, \"fn\": 313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9734317969612087, \"tn_rate\": 0.34340267882587633, \"fp_rate\": 0.6565973211741237, \"fn_rate\": 0.026568203038791274, \"precision\": 0.713361532719582, \"recall\": 0.9734317969612087, \"specificity\": 0.34340267882587633, \"npv\": 0.8850532500918105, \"accuracy\": 0.7382307569551572, \"f1\": 0.8233478120400617, \"f2\": 0.9072784810126582, \"f0_5\": 0.7536308076493395, \"p4\": 0.6181409730980807, \"phi\": 0.43542902293633334}, {\"truth_threshold\": -14.34, \"match_probability\": 4.821796982881093e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11467, \"tn\": 2416, \"fp\": 4602, \"fn\": 314, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9733469145233851, \"tn_rate\": 0.34425762325448844, \"fp_rate\": 0.6557423767455115, \"fn_rate\": 0.02665308547661489, \"precision\": 0.7136100566307798, \"recall\": 0.9733469145233851, \"specificity\": 0.34425762325448844, \"npv\": 0.884981684981685, \"accuracy\": 0.738496728549391, \"f1\": 0.8234829443447038, \"f2\": 0.907299859161616, \"f0_5\": 0.7538425128522029, \"p4\": 0.6188619837624487, \"phi\": 0.4360223083885493}, {\"truth_threshold\": -14.32, \"match_probability\": 4.8891034695705744e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11466, \"tn\": 2418, \"fp\": 4600, \"fn\": 315, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9732620320855615, \"tn_rate\": 0.3445426047306925, \"fp_rate\": 0.6554573952693075, \"fn_rate\": 0.026737967914438502, \"precision\": 0.7136810656043819, \"recall\": 0.9732620320855615, \"specificity\": 0.3445426047306925, \"npv\": 0.884742041712404, \"accuracy\": 0.7385499228682376, \"f1\": 0.8234998384027005, \"f2\": 0.9072638075644881, \"f0_5\": 0.753895719639687, \"p4\": 0.6190675652492713, \"phi\": 0.4360981979821349}, {\"truth_threshold\": -14.3, \"match_probability\": 4.9573494272870864e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11466, \"tn\": 2422, \"fp\": 4596, \"fn\": 315, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9732620320855615, \"tn_rate\": 0.3451125676831006, \"fp_rate\": 0.6548874323168994, \"fn_rate\": 0.026737967914438502, \"precision\": 0.7138587971610011, \"recall\": 0.9732620320855615, \"specificity\": 0.3451125676831006, \"npv\": 0.8849104859335039, \"accuracy\": 0.7387627001436247, \"f1\": 0.8236181445964874, \"f2\": 0.9073212420472889, \"f0_5\": 0.7540543739888727, \"p4\": 0.6195812897893705, \"phi\": 0.4366153122131446}, {\"truth_threshold\": -14.280000000000001, \"match_probability\": 5.026547967956725e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11464, \"tn\": 2422, \"fp\": 4596, \"fn\": 317, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9730922672099143, \"tn_rate\": 0.3451125676831006, \"fp_rate\": 0.6548874323168994, \"fn_rate\": 0.02690773279008573, \"precision\": 0.7138231631382317, \"recall\": 0.9730922672099143, \"specificity\": 0.3451125676831006, \"npv\": 0.8842643300474626, \"accuracy\": 0.7386563115059311, \"f1\": 0.8235336374411839, \"f2\": 0.9071916940997721, \"f0_5\": 0.7540021836071612, \"p4\": 0.6194781441742386, \"phi\": 0.43625030890617256}, {\"truth_threshold\": -14.26, \"match_probability\": 5.096712386468152e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11457, \"tn\": 2423, \"fp\": 4595, \"fn\": 324, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.972498090145149, \"tn_rate\": 0.34525505842120263, \"fp_rate\": 0.6547449415787974, \"fn_rate\": 0.02750190985485103, \"precision\": 0.713742835783703, \"recall\": 0.972498090145149, \"specificity\": 0.34525505842120263, \"npv\": 0.8820531488896979, \"accuracy\": 0.7383371455928507, \"f1\": 0.823267344519096, \"f2\": 0.9067525642649107, \"f0_5\": 0.7538591111871455, \"p4\": 0.6192456169400682, \"phi\": 0.43510464262423454}, {\"truth_threshold\": -14.22, \"match_probability\": 5.2399929667313805e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11456, \"tn\": 2423, \"fp\": 4595, \"fn\": 325, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9724132077073253, \"tn_rate\": 0.34525505842120263, \"fp_rate\": 0.6547449415787974, \"fn_rate\": 0.027586792292674647, \"precision\": 0.7137250015575354, \"recall\": 0.9724132077073253, \"specificity\": 0.34525505842120263, \"npv\": 0.8817321688500728, \"accuracy\": 0.7382839512740039, \"f1\": 0.8232250646737568, \"f2\": 0.9066877720617332, \"f0_5\": 0.7538329933539515, \"p4\": 0.6191940950443349, \"phi\": 0.43492280565312313}, {\"truth_threshold\": -14.14, \"match_probability\": 5.538750549895966e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11455, \"tn\": 2423, \"fp\": 4595, \"fn\": 326, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9723283252695017, \"tn_rate\": 0.34525505842120263, \"fp_rate\": 0.6547449415787974, \"fn_rate\": 0.02767167473049826, \"precision\": 0.7137071651090343, \"recall\": 0.9723283252695017, \"specificity\": 0.34525505842120263, \"npv\": 0.8814114223353947, \"accuracy\": 0.7382307569551572, \"f1\": 0.8231827817900902, \"f2\": 0.9066229778073258, \"f0_5\": 0.7538068727708243, \"p4\": 0.6191425796335797, \"phi\": 0.43474104326349733}, {\"truth_threshold\": -14.06, \"match_probability\": 5.8545407642600166e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11455, \"tn\": 2424, \"fp\": 4594, \"fn\": 326, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9723283252695017, \"tn_rate\": 0.34539754915930465, \"fp_rate\": 0.6546024508406953, \"fn_rate\": 0.02767167473049826, \"precision\": 0.7137516356159262, \"recall\": 0.9723283252695017, \"specificity\": 0.34539754915930465, \"npv\": 0.8814545454545455, \"accuracy\": 0.7382839512740039, \"f1\": 0.8232123607617678, \"f2\": 0.9066373292387571, \"f0_5\": 0.7538465588270135, \"p4\": 0.619270803015918, \"phi\": 0.4348705604499413}, {\"truth_threshold\": -14.040000000000001, \"match_probability\": 5.936262256248524e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11450, \"tn\": 2424, \"fp\": 4594, \"fn\": 331, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9719039130803837, \"tn_rate\": 0.34539754915930465, \"fp_rate\": 0.6546024508406953, \"fn_rate\": 0.02809608691961633, \"precision\": 0.7136624283221142, \"recall\": 0.9719039130803837, \"specificity\": 0.34539754915930465, \"npv\": 0.8798548094373866, \"accuracy\": 0.7380179796797702, \"f1\": 0.8230008984725966, \"f2\": 0.9063133232016211, \"f0_5\": 0.7537159182168859, \"p4\": 0.6190133017449532, \"phi\": 0.4339630023464562}, {\"truth_threshold\": -14.02, \"match_probability\": 6.01912440136712e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11449, \"tn\": 2428, \"fp\": 4590, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.97181903064256, \"tn_rate\": 0.3459675121117127, \"fp_rate\": 0.6540324878882873, \"fn_rate\": 0.028180969357439946, \"precision\": 0.7138225575160546, \"recall\": 0.97181903064256, \"specificity\": 0.3459675121117127, \"npv\": 0.8797101449275362, \"accuracy\": 0.7381775626363104, \"f1\": 0.823076923076923, \"f2\": 0.9063059069391891, \"f0_5\": 0.7538485850112593, \"p4\": 0.6194741542008887, \"phi\": 0.4343002481246692}, {\"truth_threshold\": -14.0, \"match_probability\": 6.1031431187061336e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11449, \"tn\": 2429, \"fp\": 4589, \"fn\": 332, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.97181903064256, \"tn_rate\": 0.34611000284981475, \"fp_rate\": 0.6538899971501853, \"fn_rate\": 0.028180969357439946, \"precision\": 0.7138670657189176, \"recall\": 0.97181903064256, \"specificity\": 0.34611000284981475, \"npv\": 0.8797537124230351, \"accuracy\": 0.7382307569551572, \"f1\": 0.8231065099392502, \"f2\": 0.9063202558500364, \"f0_5\": 0.7538882962611776, \"p4\": 0.6196021233459269, \"phi\": 0.4344298335239679}, {\"truth_threshold\": -13.98, \"match_probability\": 6.188334549470357e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11446, \"tn\": 2430, \"fp\": 4588, \"fn\": 335, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9715643833290892, \"tn_rate\": 0.34625249358791677, \"fp_rate\": 0.6537475064120832, \"fn_rate\": 0.02843561667091079, \"precision\": 0.7138580516402644, \"recall\": 0.9715643833290892, \"specificity\": 0.34625249358791677, \"npv\": 0.8788426763110307, \"accuracy\": 0.7381243683174636, \"f1\": 0.8230091677152616, \"f2\": 0.9061401564330727, \"f0_5\": 0.7538495989040663, \"p4\": 0.6195755662181135, \"phi\": 0.43401646777964153}, {\"truth_threshold\": -13.92, \"match_probability\": 6.451109931430596e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11380, \"tn\": 2430, \"fp\": 4588, \"fn\": 401, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9659621424327307, \"tn_rate\": 0.34625249358791677, \"fp_rate\": 0.6537475064120832, \"fn_rate\": 0.03403785756726933, \"precision\": 0.7126753507014028, \"recall\": 0.9659621424327307, \"specificity\": 0.34625249358791677, \"npv\": 0.8583539385376192, \"accuracy\": 0.7346135432735784, \"f1\": 0.8202097372878302, \"f2\": 0.9018576047676409, \"f0_5\": 0.7521182239964046, \"p4\": 0.6161916251805105, \"phi\": 0.42223654708811065}, {\"truth_threshold\": -13.86, \"match_probability\": 6.725042799596908e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11380, \"tn\": 2441, \"fp\": 4577, \"fn\": 401, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9659621424327307, \"tn_rate\": 0.34781989170703903, \"fp_rate\": 0.6521801082929609, \"fn_rate\": 0.03403785756726933, \"precision\": 0.713166635332456, \"recall\": 0.9659621424327307, \"specificity\": 0.34781989170703903, \"npv\": 0.85890218156228, \"accuracy\": 0.7351986807808926, \"f1\": 0.8205350061287764, \"f2\": 0.9020148697706124, \"f0_5\": 0.7525559126559007, \"p4\": 0.6175925334804011, \"phi\": 0.4236802060908224}, {\"truth_threshold\": -13.84, \"match_probability\": 6.818914497177655e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11376, \"tn\": 2449, \"fp\": 4569, \"fn\": 405, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9656226126814362, \"tn_rate\": 0.34895981761185524, \"fp_rate\": 0.6510401823881448, \"fn_rate\": 0.03437738731856379, \"precision\": 0.7134524929444968, \"recall\": 0.9656226126814362, \"specificity\": 0.34895981761185524, \"npv\": 0.858093903293623, \"accuracy\": 0.7354114580562796, \"f1\": 0.8206016013849816, \"f2\": 0.9018693811539742, \"f0_5\": 0.752769285742645, \"p4\": 0.61840343627607, \"phi\": 0.42402647836421753}, {\"truth_threshold\": -13.82, \"match_probability\": 6.914096414866335e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11376, \"tn\": 2452, \"fp\": 4566, \"fn\": 405, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9656226126814362, \"tn_rate\": 0.3493872898261613, \"fp_rate\": 0.6506127101738387, \"fn_rate\": 0.03437738731856379, \"precision\": 0.7135867519759127, \"recall\": 0.9656226126814362, \"specificity\": 0.3493872898261613, \"npv\": 0.8582429121456073, \"accuracy\": 0.7355710410128198, \"f1\": 0.8206904014717022, \"f2\": 0.9019122823708496, \"f0_5\": 0.7528888535917087, \"p4\": 0.6187834302848891, \"phi\": 0.42441961164144176}, {\"truth_threshold\": -13.780000000000001, \"match_probability\": 7.10846430540288e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11374, \"tn\": 2456, \"fp\": 4562, \"fn\": 407, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.965452847805789, \"tn_rate\": 0.34995725277856937, \"fp_rate\": 0.6500427472214306, \"fn_rate\": 0.03454715219421102, \"precision\": 0.7137299196787149, \"recall\": 0.965452847805789, \"specificity\": 0.34995725277856937, \"npv\": 0.8578414250785888, \"accuracy\": 0.7356774296505133, \"f1\": 0.8207237435508894, \"f2\": 0.9018395179194418, \"f0_5\": 0.7529956967891427, \"p4\": 0.6191871829197569, \"phi\": 0.4245931880530329}, {\"truth_threshold\": -13.76, \"match_probability\": 7.207687616990448e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11374, \"tn\": 2459, \"fp\": 4559, \"fn\": 407, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.965452847805789, \"tn_rate\": 0.3503847249928755, \"fp_rate\": 0.6496152750071246, \"fn_rate\": 0.03454715219421102, \"precision\": 0.7138643067846607, \"recall\": 0.965452847805789, \"specificity\": 0.3503847249928755, \"npv\": 0.8579902302861131, \"accuracy\": 0.7358370126070536, \"f1\": 0.8208125856967597, \"f2\": 0.9018824238387491, \"f0_5\": 0.7531153576205422, \"p4\": 0.6195662162849328, \"phi\": 0.42498605739757755}, {\"truth_threshold\": -13.74, \"match_probability\": 7.308295833329186e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11372, \"tn\": 2459, \"fp\": 4559, \"fn\": 409, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9652830829301418, \"tn_rate\": 0.3503847249928755, \"fp_rate\": 0.6496152750071246, \"fn_rate\": 0.034716917069858244, \"precision\": 0.7138283849099241, \"recall\": 0.9652830829301418, \"specificity\": 0.3503847249928755, \"npv\": 0.8573919107391911, \"accuracy\": 0.7357306239693601, \"f1\": 0.8207274826789839, \"f2\": 0.9017524383474744, \"f0_5\": 0.7530627110787365, \"p4\": 0.6194639342428367, \"phi\": 0.4246361484479318}, {\"truth_threshold\": -13.72, \"match_probability\": 7.410308281316996e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11372, \"tn\": 2461, \"fp\": 4557, \"fn\": 409, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9652830829301418, \"tn_rate\": 0.3506697064690795, \"fp_rate\": 0.6493302935309205, \"fn_rate\": 0.034716917069858244, \"precision\": 0.7139180111745872, \"recall\": 0.9652830829301418, \"specificity\": 0.3506697064690795, \"npv\": 0.8574912891986063, \"accuracy\": 0.7358370126070536, \"f1\": 0.8207867195958138, \"f2\": 0.9017810413461691, \"f0_5\": 0.7531425089738665, \"p4\": 0.6197163843180676, \"phi\": 0.424898061117685}, {\"truth_threshold\": -13.58, \"match_probability\": 8.165394944562937e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11372, \"tn\": 2473, \"fp\": 4545, \"fn\": 409, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9652830829301418, \"tn_rate\": 0.3523795953263038, \"fp_rate\": 0.6476204046736962, \"fn_rate\": 0.034716917069858244, \"precision\": 0.7144562417540994, \"recall\": 0.9652830829301418, \"specificity\": 0.3523795953263038, \"npv\": 0.8580846634281749, \"accuracy\": 0.7364753444332145, \"f1\": 0.8211423207451801, \"f2\": 0.9019526974508653, \"f0_5\": 0.7536216517117523, \"p4\": 0.6212273723020716, \"phi\": 0.4264679089352104}, {\"truth_threshold\": -13.56, \"match_probability\": 8.279370173056753e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11371, \"tn\": 2473, \"fp\": 4545, \"fn\": 410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9651982004923182, \"tn_rate\": 0.3523795953263038, \"fp_rate\": 0.6476204046736962, \"fn_rate\": 0.03480179950768186, \"precision\": 0.7144383010806735, \"recall\": 0.9651982004923182, \"specificity\": 0.3523795953263038, \"npv\": 0.8577870274020118, \"accuracy\": 0.7364221501143677, \"f1\": 0.8210997580965448, \"f2\": 0.9018876903553299, \"f0_5\": 0.7535953343495262, \"p4\": 0.6211761817574469, \"phi\": 0.42629339489501605}, {\"truth_threshold\": -13.540000000000001, \"match_probability\": 8.39493617115541e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11371, \"tn\": 2474, \"fp\": 4544, \"fn\": 410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9651982004923182, \"tn_rate\": 0.3525220860644058, \"fp_rate\": 0.6474779139355942, \"fn_rate\": 0.03480179950768186, \"precision\": 0.7144831919572731, \"recall\": 0.9651982004923182, \"specificity\": 0.3525220860644058, \"npv\": 0.8578363384188626, \"accuracy\": 0.7364753444332145, \"f1\": 0.8211294049682265, \"f2\": 0.9019019971763511, \"f0_5\": 0.7536352911546772, \"p4\": 0.6213018069691267, \"phi\": 0.4264241142256328}, {\"truth_threshold\": -13.52, \"match_probability\": 8.51211513771759e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11370, \"tn\": 2474, \"fp\": 4544, \"fn\": 411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9651133180544945, \"tn_rate\": 0.3525220860644058, \"fp_rate\": 0.6474779139355942, \"fn_rate\": 0.034886681945505475, \"precision\": 0.7144652507226341, \"recall\": 0.9651133180544945, \"specificity\": 0.3525220860644058, \"npv\": 0.8575389948006933, \"accuracy\": 0.7364221501143677, \"f1\": 0.8210868387795631, \"f2\": 0.9018369872140614, \"f0_5\": 0.7536089717247505, \"p4\": 0.6212506185312344, \"phi\": 0.4262496917119457}, {\"truth_threshold\": -13.5, \"match_probability\": 8.630929581276842e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11370, \"tn\": 2475, \"fp\": 4543, \"fn\": 411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9651133180544945, \"tn_rate\": 0.35266457680250785, \"fp_rate\": 0.6473354231974922, \"fn_rate\": 0.034886681945505475, \"precision\": 0.7145101489348331, \"recall\": 0.9651133180544945, \"specificity\": 0.35266457680250785, \"npv\": 0.8575883575883576, \"accuracy\": 0.7364753444332145, \"f1\": 0.8211164873257746, \"f2\": 0.9018512936846614, \"f0_5\": 0.7536489334906473, \"p4\": 0.6213761956660165, \"phi\": 0.4263804158891149}, {\"truth_threshold\": -13.44, \"match_probability\": 8.997415595475012e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11368, \"tn\": 2475, \"fp\": 4543, \"fn\": 413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9649435531788473, \"tn_rate\": 0.35266457680250785, \"fp_rate\": 0.6473354231974922, \"fn_rate\": 0.035056446821152706, \"precision\": 0.7144742630884294, \"recall\": 0.9649435531788473, \"specificity\": 0.35266457680250785, \"npv\": 0.856994459833795, \"accuracy\": 0.7363689557955211, \"f1\": 0.8210313447927199, \"f2\": 0.9017212659633537, \"f0_5\": 0.7535962877030162, \"p4\": 0.6212738292920548, \"phi\": 0.4260318209126648}, {\"truth_threshold\": -13.4, \"match_probability\": 9.250343978968807e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11368, \"tn\": 2494, \"fp\": 4524, \"fn\": 413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9649435531788473, \"tn_rate\": 0.35537190082644626, \"fp_rate\": 0.6446280991735537, \"fn_rate\": 0.035056446821152706, \"precision\": 0.7153284671532847, \"recall\": 0.9649435531788473, \"specificity\": 0.35537190082644626, \"npv\": 0.8579291365669075, \"accuracy\": 0.7373796478536092, \"f1\": 0.8215950565533191, \"f2\": 0.9019931445981972, \"f0_5\": 0.7543563949090234, \"p4\": 0.6236513388612479, \"phi\": 0.4285128581473606}, {\"truth_threshold\": -13.38, \"match_probability\": 9.379461857095894e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11368, \"tn\": 2495, \"fp\": 4523, \"fn\": 413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9649435531788473, \"tn_rate\": 0.3555143915645483, \"fp_rate\": 0.6444856084354517, \"fn_rate\": 0.035056446821152706, \"precision\": 0.7153734818450695, \"recall\": 0.9649435531788473, \"specificity\": 0.3555143915645483, \"npv\": 0.8579779917469051, \"accuracy\": 0.737432842172456, \"f1\": 0.8216247470367158, \"f2\": 0.9020074585416171, \"f0_5\": 0.7543964430287345, \"p4\": 0.6237760363942003, \"phi\": 0.42864324891788674}, {\"truth_threshold\": -13.34, \"match_probability\": 9.643128993659314e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11368, \"tn\": 2498, \"fp\": 4520, \"fn\": 413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9649435531788473, \"tn_rate\": 0.3559418637788544, \"fp_rate\": 0.6440581362211456, \"fn_rate\": 0.035056446821152706, \"precision\": 0.7155085599194361, \"recall\": 0.9649435531788473, \"specificity\": 0.3559418637788544, \"npv\": 0.8581243558914462, \"accuracy\": 0.7375924251289963, \"f1\": 0.82171383136362, \"f2\": 0.9020504030978226, \"f0_5\": 0.7545166129053669, \"p4\": 0.6241498696571484, \"phi\": 0.4290343079179533}, {\"truth_threshold\": -13.32, \"match_probability\": 9.777728895858458e-05, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11353, \"tn\": 2500, \"fp\": 4518, \"fn\": 428, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.963670316611493, \"tn_rate\": 0.35622684525505843, \"fp_rate\": 0.6437731547449416, \"fn_rate\": 0.036329683388506916, \"precision\": 0.7153298468905551, \"recall\": 0.963670316611493, \"specificity\": 0.35622684525505843, \"npv\": 0.8538251366120219, \"accuracy\": 0.7369008989839885, \"f1\": 0.8211340951829885, \"f2\": 0.9011032621636638, \"f0_5\": 0.754201820235169, \"p4\": 0.6236303738324893, \"phi\": 0.42669786018291483}, {\"truth_threshold\": -13.24, \"match_probability\": 0.00010335178219304575, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11335, \"tn\": 2500, \"fp\": 4518, \"fn\": 446, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.962142432730668, \"tn_rate\": 0.35622684525505843, \"fp_rate\": 0.6437731547449416, \"fn_rate\": 0.037857567269331975, \"precision\": 0.7150066233520469, \"recall\": 0.962142432730668, \"specificity\": 0.35622684525505843, \"npv\": 0.8486082824168364, \"accuracy\": 0.7359434012447471, \"f1\": 0.8203662155315915, \"f2\": 0.8999317211045302, \"f0_5\": 0.7537270756586384, \"p4\": 0.6227100230328544, \"phi\": 0.4236008387758842}, {\"truth_threshold\": -13.22, \"match_probability\": 0.00010479436811710874, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11335, \"tn\": 2561, \"fp\": 4457, \"fn\": 446, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.962142432730668, \"tn_rate\": 0.3649187802792819, \"fp_rate\": 0.6350812197207182, \"fn_rate\": 0.037857567269331975, \"precision\": 0.7177684903748733, \"recall\": 0.962142432730668, \"specificity\": 0.3649187802792819, \"npv\": 0.8516794146990356, \"accuracy\": 0.7391882546943986, \"f1\": 0.8221811192108222, \"f2\": 0.9008042469324178, \"f0_5\": 0.7561808696580341, \"p4\": 0.6302149732804448, \"phi\": 0.4315603348078313}, {\"truth_threshold\": -13.200000000000001, \"match_probability\": 0.00010625708754012587, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11335, \"tn\": 2570, \"fp\": 4448, \"fn\": 446, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.962142432730668, \"tn_rate\": 0.36620119692220005, \"fp_rate\": 0.6337988030777999, \"fn_rate\": 0.037857567269331975, \"precision\": 0.7181777862256858, \"recall\": 0.962142432730668, \"specificity\": 0.36620119692220005, \"npv\": 0.8521220159151194, \"accuracy\": 0.7396670035640194, \"f1\": 0.8224495719053838, \"f2\": 0.9009331234997695, \"f0_5\": 0.7565442580059536, \"p4\": 0.6313091267516536, \"phi\": 0.43272890708297324}, {\"truth_threshold\": -13.18, \"match_probability\": 0.00010774022139580177, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11332, \"tn\": 2571, \"fp\": 4447, \"fn\": 449, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9618877854171972, \"tn_rate\": 0.36634368766030206, \"fp_rate\": 0.6336563123396979, \"fn_rate\": 0.03811221458280282, \"precision\": 0.7181697192471006, \"recall\": 0.9618877854171972, \"specificity\": 0.36634368766030206, \"npv\": 0.8513245033112583, \"accuracy\": 0.7395606149263259, \"f1\": 0.8223512336719884, \"f2\": 0.9007519514172615, \"f0_5\": 0.7565056010254082, \"p4\": 0.6312764447721743, \"phi\": 0.4323493119914213}, {\"truth_threshold\": -13.16, \"match_probability\": 0.00010924405453617098, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11331, \"tn\": 2574, \"fp\": 4444, \"fn\": 450, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9618029029793735, \"tn_rate\": 0.3667711598746082, \"fp_rate\": 0.6332288401253918, \"fn_rate\": 0.03819709702062643, \"precision\": 0.7182884310618066, \"recall\": 0.9618029029793735, \"specificity\": 0.3667711598746082, \"npv\": 0.8511904761904762, \"accuracy\": 0.7396670035640194, \"f1\": 0.8223980258382929, \"f2\": 0.9007297413313408, \"f0_5\": 0.7566004727500968, \"p4\": 0.6315889177755449, \"phi\": 0.43256906762449904}, {\"truth_threshold\": -13.14, \"match_probability\": 0.0001107688757862026, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11331, \"tn\": 2576, \"fp\": 4442, \"fn\": 450, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9618029029793735, \"tn_rate\": 0.3670561413508122, \"fp_rate\": 0.6329438586491878, \"fn_rate\": 0.03819709702062643, \"precision\": 0.7183795092880239, \"recall\": 0.9618029029793735, \"specificity\": 0.3670561413508122, \"npv\": 0.8512888301387971, \"accuracy\": 0.7397733922017129, \"f1\": 0.8224577193873848, \"f2\": 0.9007583827527545, \"f0_5\": 0.7566813136911837, \"p4\": 0.6318312540206958, \"phi\": 0.4328285869591659}, {\"truth_threshold\": -13.120000000000001, \"match_probability\": 0.00011231497799916251, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11330, \"tn\": 2576, \"fp\": 4442, \"fn\": 451, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.96171802054155, \"tn_rate\": 0.3670561413508122, \"fp_rate\": 0.6329438586491878, \"fn_rate\": 0.03828197945845005, \"precision\": 0.7183616535632767, \"recall\": 0.96171802054155, \"specificity\": 0.3670561413508122, \"npv\": 0.8510075982821275, \"accuracy\": 0.7397201978828661, \"f1\": 0.8224149820346242, \"f2\": 0.9006932078351565, \"f0_5\": 0.7566549573254618, \"p4\": 0.6317799031701352, \"phi\": 0.4326591020454256}, {\"truth_threshold\": -13.1, \"match_probability\": 0.00011388265811274712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11329, \"tn\": 2576, \"fp\": 4442, \"fn\": 452, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9616331381037263, \"tn_rate\": 0.3670561413508122, \"fp_rate\": 0.6329438586491878, \"fn_rate\": 0.03836686189627366, \"precision\": 0.7183437955741551, \"recall\": 0.9616331381037263, \"specificity\": 0.3670561413508122, \"npv\": 0.8507265521796565, \"accuracy\": 0.7396670035640194, \"f1\": 0.8223722415795587, \"f2\": 0.9006280308450593, \"f0_5\": 0.7566285981433246, \"p4\": 0.6317285584400464, \"phi\": 0.4324896791394496}, {\"truth_threshold\": -13.08, \"match_probability\": 0.00011547221720599655, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11328, \"tn\": 2577, \"fp\": 4441, \"fn\": 453, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9615482556659027, \"tn_rate\": 0.36719863208891423, \"fp_rate\": 0.6328013679110858, \"fn_rate\": 0.038451744334097274, \"precision\": 0.7183714883632444, \"recall\": 0.9615482556659027, \"specificity\": 0.36719863208891423, \"npv\": 0.8504950495049505, \"accuracy\": 0.7396670035640194, \"f1\": 0.8223593466424682, \"f2\": 0.900577170750322, \"f0_5\": 0.756642665348598, \"p4\": 0.6317983151767037, \"phi\": 0.43245011720662857}, {\"truth_threshold\": -13.06, \"match_probability\": 0.00011708396055700113, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11326, \"tn\": 2577, \"fp\": 4441, \"fn\": 455, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9613784907902555, \"tn_rate\": 0.36719863208891423, \"fp_rate\": 0.6328013679110858, \"fn_rate\": 0.038621509209744505, \"precision\": 0.7183357645715736, \"recall\": 0.9613784907902555, \"specificity\": 0.36719863208891423, \"npv\": 0.849934036939314, \"accuracy\": 0.7395606149263259, \"f1\": 0.8222738492812546, \"f2\": 0.9004468047892386, \"f0_5\": 0.7565899344012612, \"p4\": 0.6316956485548316, \"phi\": 0.43211162492990657}, {\"truth_threshold\": -13.02, \"match_probability\": 0.00012037524249174837, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11324, \"tn\": 2581, \"fp\": 4437, \"fn\": 457, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9612087259146083, \"tn_rate\": 0.3677685950413223, \"fp_rate\": 0.6322314049586777, \"fn_rate\": 0.03879127408539173, \"precision\": 0.7184823298014086, \"recall\": 0.9612087259146083, \"specificity\": 0.3677685950413223, \"npv\": 0.8495720868992759, \"accuracy\": 0.7396670035640194, \"f1\": 0.8223077481664367, \"f2\": 0.9003736980201956, \"f0_5\": 0.7566989642499165, \"p4\": 0.6320769189255068, \"phi\": 0.4322927482197394}, {\"truth_threshold\": -13.0, \"match_probability\": 0.00012205541315757354, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11324, \"tn\": 2602, \"fp\": 4416, \"fn\": 457, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9612087259146083, \"tn_rate\": 0.3707609005414648, \"fp_rate\": 0.6292390994585352, \"fn_rate\": 0.03879127408539173, \"precision\": 0.7194409148665819, \"recall\": 0.9612087259146083, \"specificity\": 0.3707609005414648, \"npv\": 0.8506047728015691, \"accuracy\": 0.740784084259801, \"f1\": 0.8229352131099887, \"f2\": 0.9006744718757954, \"f0_5\": 0.7575494039416117, \"p4\": 0.634606843501609, \"phi\": 0.435014774459548}, {\"truth_threshold\": -12.98, \"match_probability\": 0.00012375903236644915, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11323, \"tn\": 2602, \"fp\": 4416, \"fn\": 458, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9611238434767847, \"tn_rate\": 0.3707609005414648, \"fp_rate\": 0.6292390994585352, \"fn_rate\": 0.03887615652321535, \"precision\": 0.7194230891416227, \"recall\": 0.9611238434767847, \"specificity\": 0.3707609005414648, \"npv\": 0.8503267973856209, \"accuracy\": 0.7407308899409543, \"f1\": 0.8228924418604651, \"f2\": 0.9006092614097323, \"f0_5\": 0.7575230474865194, \"p4\": 0.6345554356775148, \"phi\": 0.43484628921553525}, {\"truth_threshold\": -12.96, \"match_probability\": 0.00012548642728578072, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11323, \"tn\": 2607, \"fp\": 4411, \"fn\": 458, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9611238434767847, \"tn_rate\": 0.3714733542319749, \"fp_rate\": 0.6285266457680251, \"fn_rate\": 0.03887615652321535, \"precision\": 0.7196517096733189, \"recall\": 0.9611238434767847, \"specificity\": 0.3714733542319749, \"npv\": 0.8505709624796085, \"accuracy\": 0.7409968615351881, \"f1\": 0.8230419771033981, \"f2\": 0.9006808998059117, \"f0_5\": 0.7577258187561063, \"p4\": 0.6351551688574031, \"phi\": 0.4354933556646581}, {\"truth_threshold\": -12.94, \"match_probability\": 0.0001272379296455061, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11322, \"tn\": 2607, \"fp\": 4411, \"fn\": 459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.961038961038961, \"tn_rate\": 0.3714733542319749, \"fp_rate\": 0.6285266457680251, \"fn_rate\": 0.03896103896103896, \"precision\": 0.7196338905485286, \"recall\": 0.961038961038961, \"specificity\": 0.3714733542319749, \"npv\": 0.850293542074364, \"accuracy\": 0.7409436672163413, \"f1\": 0.8229992004070655, \"f2\": 0.9006156832174619, \"f0_5\": 0.7576994632794828, \"p4\": 0.635103748172284, \"phi\": 0.4353250396633054}, {\"truth_threshold\": -12.92, \"match_probability\": 0.00012901387580165717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11322, \"tn\": 2610, \"fp\": 4408, \"fn\": 459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.961038961038961, \"tn_rate\": 0.371900826446281, \"fp_rate\": 0.628099173553719, \"fn_rate\": 0.03896103896103896, \"precision\": 0.7197711379529561, \"recall\": 0.961038961038961, \"specificity\": 0.371900826446281, \"npv\": 0.8504398826979472, \"accuracy\": 0.7411032501728816, \"f1\": 0.823088946239686, \"f2\": 0.9006586692971013, \"f0_5\": 0.7578211804393515, \"p4\": 0.6354630979566314, \"phi\": 0.4357131350295223}, {\"truth_threshold\": -12.9, \"match_probability\": 0.0001308146068008071, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11321, \"tn\": 2613, \"fp\": 4405, \"fn\": 460, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9609540786011375, \"tn_rate\": 0.3723282986605871, \"fp_rate\": 0.627671701339413, \"fn_rate\": 0.03904592139886257, \"precision\": 0.719890626987155, \"recall\": 0.9609540786011375, \"specificity\": 0.3723282986605871, \"npv\": 0.8503091441588024, \"accuracy\": 0.741209638810575, \"f1\": 0.8231359290362453, \"f2\": 0.9006364359586316, \"f0_5\": 0.7579165829818572, \"p4\": 0.6357706523268214, \"phi\": 0.43593294810282}, {\"truth_threshold\": -12.86, \"match_probability\": 0.00013449181136006226, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11319, \"tn\": 2615, \"fp\": 4403, \"fn\": 462, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9607843137254902, \"tn_rate\": 0.3726132801367911, \"fp_rate\": 0.6273867198632089, \"fn_rate\": 0.0392156862745098, \"precision\": 0.719946571682992, \"recall\": 0.9607843137254902, \"specificity\": 0.3726132801367911, \"npv\": 0.8498537536561586, \"accuracy\": 0.741209638810575, \"f1\": 0.8231102061593281, \"f2\": 0.9005346402316774, \"f0_5\": 0.7579450642167432, \"p4\": 0.6359069025996364, \"phi\": 0.4358555465403852}, {\"truth_threshold\": -12.84, \"match_probability\": 0.00013636899105865216, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11318, \"tn\": 2617, \"fp\": 4401, \"fn\": 463, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9606994312876665, \"tn_rate\": 0.37289826161299516, \"fp_rate\": 0.6271017383870049, \"fn_rate\": 0.039300568712333415, \"precision\": 0.7200203575291049, \"recall\": 0.9606994312876665, \"specificity\": 0.37289826161299516, \"npv\": 0.8496753246753247, \"accuracy\": 0.7412628331294218, \"f1\": 0.8231272727272727, \"f2\": 0.9004980666104418, \"f0_5\": 0.7579999196324524, \"p4\": 0.6360944164660868, \"phi\": 0.4359462871029713}, {\"truth_threshold\": -12.82, \"match_probability\": 0.00013827236801248723, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11317, \"tn\": 2617, \"fp\": 4401, \"fn\": 464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.960614548849843, \"tn_rate\": 0.37289826161299516, \"fp_rate\": 0.6271017383870049, \"fn_rate\": 0.039385451150157035, \"precision\": 0.7200025448530347, \"recall\": 0.960614548849843, \"specificity\": 0.37289826161299516, \"npv\": 0.8493995456020772, \"accuracy\": 0.741209638810575, \"f1\": 0.8230844757991199, \"f2\": 0.9004328315457815, \"f0_5\": 0.7579735576601074, \"p4\": 0.6360429884436126, \"phi\": 0.4357784889953835}, {\"truth_threshold\": -12.8, \"match_probability\": 0.00014020230771933477, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11317, \"tn\": 2620, \"fp\": 4398, \"fn\": 464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.960614548849843, \"tn_rate\": 0.3733257338273012, \"fp_rate\": 0.6266742661726987, \"fn_rate\": 0.039385451150157035, \"precision\": 0.7201399936366529, \"recall\": 0.960614548849843, \"specificity\": 0.3733257338273012, \"npv\": 0.8495460440985733, \"accuracy\": 0.7413692217671153, \"f1\": 0.8231742798952575, \"f2\": 0.900475819156893, \"f0_5\": 0.7580954167280717, \"p4\": 0.6364010909540431, \"phi\": 0.43616638623181825}, {\"truth_threshold\": -12.780000000000001, \"match_probability\": 0.00014215918077343544, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11317, \"tn\": 2622, \"fp\": 4396, \"fn\": 464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.960614548849843, \"tn_rate\": 0.37361071530350526, \"fp_rate\": 0.6263892846964947, \"fn_rate\": 0.039385451150157035, \"precision\": 0.7202316553172532, \"recall\": 0.960614548849843, \"specificity\": 0.37361071530350526, \"npv\": 0.8496435515230071, \"accuracy\": 0.7414756104048088, \"f1\": 0.823234160180403, \"f2\": 0.9005044798446775, \"f0_5\": 0.7581766778770785, \"p4\": 0.6366396283606583, \"phi\": 0.43642489793849987}, {\"truth_threshold\": -12.76, \"match_probability\": 0.0001441433629364879, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11316, \"tn\": 3436, \"fp\": 3582, \"fn\": 465, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9605296664120193, \"tn_rate\": 0.4895981761185523, \"fp_rate\": 0.5104018238814477, \"fn_rate\": 0.03947033358798065, \"precision\": 0.7595650422875554, \"recall\": 0.9605296664120193, \"specificity\": 0.4895981761185523, \"npv\": 0.8807997949243783, \"accuracy\": 0.7847225916272142, \"f1\": 0.84830765770831, \"f2\": 0.9122569410854213, \"f0_5\": 0.7927367491908704, \"p4\": 0.7226140663338333, \"phi\": 0.5368855023248891}, {\"truth_threshold\": -12.72, \"match_probability\": 0.00014819518390635442, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11315, \"tn\": 3436, \"fp\": 3582, \"fn\": 466, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9604447839741957, \"tn_rate\": 0.4895981761185523, \"fp_rate\": 0.5104018238814477, \"fn_rate\": 0.03955521602580426, \"precision\": 0.7595489024635833, \"recall\": 0.9604447839741957, \"specificity\": 0.4895981761185523, \"npv\": 0.8805740645822655, \"accuracy\": 0.7846693973083675, \"f1\": 0.8482644875927731, \"f2\": 0.9121910320697828, \"f0_5\": 0.7927111210749765, \"p4\": 0.7225604144283931, \"phi\": 0.5367334859245009}, {\"truth_threshold\": -12.68, \"match_probability\": 0.00015236088283167914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11315, \"tn\": 3450, \"fp\": 3568, \"fn\": 466, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9604447839741957, \"tn_rate\": 0.4915930464519806, \"fp_rate\": 0.5084069535480193, \"fn_rate\": 0.03955521602580426, \"precision\": 0.7602633877578445, \"recall\": 0.9604447839741957, \"specificity\": 0.4915930464519806, \"npv\": 0.8810010214504597, \"accuracy\": 0.7854141177722219, \"f1\": 0.8487098709870987, \"f2\": 0.9123969874369023, \"f0_5\": 0.7933336137871075, \"p4\": 0.7238779687505867, \"phi\": 0.5384011258049574}, {\"truth_threshold\": -12.64, \"match_probability\": 0.00015664365930589128, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11297, \"tn\": 3451, \"fp\": 3567, \"fn\": 484, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9589169000933707, \"tn_rate\": 0.49173553719008267, \"fp_rate\": 0.5082644628099173, \"fn_rate\": 0.04108309990662932, \"precision\": 0.760024219590958, \"recall\": 0.9589169000933707, \"specificity\": 0.49173553719008267, \"npv\": 0.8770012706480305, \"accuracy\": 0.7845098143518272, \"f1\": 0.8479639707262151, \"f2\": 0.9112247531780344, \"f0_5\": 0.7929166023274422, \"p4\": 0.7230065384834504, \"phi\": 0.5357957537979252}, {\"truth_threshold\": -12.620000000000001, \"match_probability\": 0.00015882997599441802, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11295, \"tn\": 3457, \"fp\": 3561, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9587471352177235, \"tn_rate\": 0.4925904816186948, \"fp_rate\": 0.5074095183813052, \"fn_rate\": 0.04125286478227655, \"precision\": 0.7602988691437803, \"recall\": 0.9587471352177235, \"specificity\": 0.4925904816186948, \"npv\": 0.8767435962465128, \"accuracy\": 0.7847225916272142, \"f1\": 0.84806847617975, \"f2\": 0.9111810261374637, \"f0_5\": 0.7931325047398357, \"p4\": 0.7234622722373989, \"phi\": 0.5362100597273901}, {\"truth_threshold\": -12.6, \"match_probability\": 0.00016104680276399447, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11295, \"tn\": 3459, \"fp\": 3559, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9587471352177235, \"tn_rate\": 0.4928754630948988, \"fp_rate\": 0.5071245369051012, \"fn_rate\": 0.04125286478227655, \"precision\": 0.7604012387235761, \"recall\": 0.9587471352177235, \"specificity\": 0.4928754630948988, \"npv\": 0.8768060836501901, \"accuracy\": 0.7848289802649077, \"f1\": 0.8481321569363619, \"f2\": 0.9112104295072445, \"f0_5\": 0.7932216245066506, \"p4\": 0.7236497172708247, \"phi\": 0.5364487175809716}, {\"truth_threshold\": -12.58, \"match_probability\": 0.00016329456524508346, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11295, \"tn\": 3471, \"fp\": 3547, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9587471352177235, \"tn_rate\": 0.4945853519521231, \"fp_rate\": 0.5054146480478768, \"fn_rate\": 0.04125286478227655, \"precision\": 0.7610160355747204, \"recall\": 0.9587471352177235, \"specificity\": 0.4945853519521231, \"npv\": 0.8771796815769523, \"accuracy\": 0.7854673120910687, \"f1\": 0.8485144423994291, \"f2\": 0.9113868895846109, \"f0_5\": 0.793756763974195, \"p4\": 0.7247724416081563, \"phi\": 0.5378799603605917}, {\"truth_threshold\": -12.56, \"match_probability\": 0.00016557369500201663, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11295, \"tn\": 3899, \"fp\": 3119, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9587471352177235, \"tn_rate\": 0.5555713878597891, \"fp_rate\": 0.4444286121402109, \"fn_rate\": 0.04125286478227655, \"precision\": 0.783613153878174, \"recall\": 0.9587471352177235, \"specificity\": 0.5555713878597891, \"npv\": 0.8891676168757127, \"accuracy\": 0.8082344805574765, \"f1\": 0.8623783164726093, \"f2\": 0.9177256329422471, \"f0_5\": 0.813327188674626, \"p4\": 0.7628108615384522, \"phi\": 0.5882377175675575}, {\"truth_threshold\": -12.540000000000001, \"match_probability\": 0.0001678846296156108, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11295, \"tn\": 3903, \"fp\": 3115, \"fn\": 486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9587471352177235, \"tn_rate\": 0.5561413508121972, \"fp_rate\": 0.44385864918780277, \"fn_rate\": 0.04125286478227655, \"precision\": 0.7838306731436503, \"recall\": 0.9587471352177235, \"specificity\": 0.5561413508121972, \"npv\": 0.8892686261107313, \"accuracy\": 0.8084472578328634, \"f1\": 0.8625100225268222, \"f2\": 0.9177852894334839, \"f0_5\": 0.8135146425433226, \"p4\": 0.7631494576227114, \"phi\": 0.5887028784887067}, {\"truth_threshold\": -12.5, \"match_probability\": 0.00017260369432222522, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11294, \"tn\": 3903, \"fp\": 3115, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9586622527798998, \"tn_rate\": 0.5561413508121972, \"fp_rate\": 0.44385864918780277, \"fn_rate\": 0.04133774722010016, \"precision\": 0.7838156707613297, \"recall\": 0.9586622527798998, \"specificity\": 0.5561413508121972, \"npv\": 0.8890660592255125, \"accuracy\": 0.8083940635140167, \"f1\": 0.8624665903016419, \"f2\": 0.9177189475565957, \"f0_5\": 0.8134894910468617, \"p4\": 0.7630951552374869, \"phi\": 0.5885592063577892}, {\"truth_threshold\": -12.48, \"match_probability\": 0.00017501273041901525, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11294, \"tn\": 3918, \"fp\": 3100, \"fn\": 487, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9586622527798998, \"tn_rate\": 0.5582787118837276, \"fp_rate\": 0.4417212881162724, \"fn_rate\": 0.04133774722010016, \"precision\": 0.7846324857579547, \"recall\": 0.9586622527798998, \"specificity\": 0.5582787118837276, \"npv\": 0.8894438138479002, \"accuracy\": 0.809191978296718, \"f1\": 0.8629608404966571, \"f2\": 0.9179427159530544, \"f0_5\": 0.8141932321178829, \"p4\": 0.7643623122132112, \"phi\": 0.5903030175893894}, {\"truth_threshold\": -12.46, \"match_probability\": 0.00017745538355341462, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11284, \"tn\": 3918, \"fp\": 3100, \"fn\": 497, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9578134284016637, \"tn_rate\": 0.5582787118837276, \"fp_rate\": 0.4417212881162724, \"fn_rate\": 0.0421865715983363, \"precision\": 0.7844827586206896, \"recall\": 0.9578134284016637, \"specificity\": 0.5582787118837276, \"npv\": 0.8874292185730465, \"accuracy\": 0.8086600351082505, \"f1\": 0.8625262755589528, \"f2\": 0.9172790531313, \"f0_5\": 0.8139417458920611, \"p4\": 0.7638193465552117, \"phi\": 0.5888705209070193}, {\"truth_threshold\": -12.44, \"match_probability\": 0.00017993212266863398, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11283, \"tn\": 3918, \"fp\": 3100, \"fn\": 498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.95772854596384, \"tn_rate\": 0.5582787118837276, \"fp_rate\": 0.4417212881162724, \"fn_rate\": 0.042271454036159915, \"precision\": 0.784467774455955, \"recall\": 0.95772854596384, \"specificity\": 0.5582787118837276, \"npv\": 0.8872282608695652, \"accuracy\": 0.8086068407894037, \"f1\": 0.8624828007949855, \"f2\": 0.9172126749800835, \"f0_5\": 0.8139165813050943, \"p4\": 0.7637650758114273, \"phi\": 0.5887274660616783}, {\"truth_threshold\": -12.42, \"match_probability\": 0.00018244342324472447, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11283, \"tn\": 3935, \"fp\": 3083, \"fn\": 498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.95772854596384, \"tn_rate\": 0.560701054431462, \"fp_rate\": 0.43929894556853805, \"fn_rate\": 0.042271454036159915, \"precision\": 0.7853960740637617, \"recall\": 0.95772854596384, \"specificity\": 0.560701054431462, \"npv\": 0.8876607263704038, \"accuracy\": 0.8095111442097984, \"f1\": 0.8630435614028378, \"f2\": 0.917466254675557, \"f0_5\": 0.8147158639612968, \"p4\": 0.7651960890805509, \"phi\": 0.5907051447993532}, {\"truth_threshold\": -12.4, \"match_probability\": 0.00018498976738956673, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3935, \"fp\": 3083, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.560701054431462, \"fp_rate\": 0.43929894556853805, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7853811347024017, \"recall\": 0.9576436635260165, \"specificity\": 0.560701054431462, \"npv\": 0.8874605322507894, \"accuracy\": 0.8094579498909517, \"f1\": 0.8630000764935363, \"f2\": 0.9173998601375856, \"f0_5\": 0.8146907179272397, \"p4\": 0.7651418004260783, \"phi\": 0.5905623795052403}, {\"truth_threshold\": -12.38, \"match_probability\": 0.00018757164393112065, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3936, \"fp\": 3082, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.560843545169564, \"fp_rate\": 0.439156454830436, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7854358117516013, \"recall\": 0.9576436635260165, \"specificity\": 0.560843545169564, \"npv\": 0.8874859075535513, \"accuracy\": 0.8095111442097984, \"f1\": 0.8630330847198318, \"f2\": 0.9174147801196981, \"f0_5\": 0.8147377847104872, \"p4\": 0.765225816950656, \"phi\": 0.5906786807674367}, {\"truth_threshold\": -12.36, \"match_probability\": 0.00019018954851095674, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3942, \"fp\": 3076, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.5616984895981761, \"fp_rate\": 0.43830151040182386, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7857640339880206, \"recall\": 0.9576436635260165, \"specificity\": 0.5616984895981761, \"npv\": 0.8876379193875253, \"accuracy\": 0.8098303101228789, \"f1\": 0.8632311871150389, \"f2\": 0.9175043102046128, \"f0_5\": 0.8150202996546891, \"p4\": 0.7657295458233935, \"phi\": 0.5913763779388665}, {\"truth_threshold\": -12.34, \"match_probability\": 0.0001928439836790836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3943, \"fp\": 3075, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.5618409803362782, \"fp_rate\": 0.43815901966372184, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7858187643658145, \"recall\": 0.9576436635260165, \"specificity\": 0.5618409803362782, \"npv\": 0.8876632147681225, \"accuracy\": 0.8098835044417256, \"f1\": 0.8632642130231847, \"f2\": 0.9175192335843594, \"f0_5\": 0.8150674045283128, \"p4\": 0.7658134390144439, \"phi\": 0.5914926424547194}, {\"truth_threshold\": -12.32, \"match_probability\": 0.0001955354589900938, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3945, \"fp\": 3073, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.5621259618124822, \"fp_rate\": 0.4378740381875178, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7859282479972135, \"recall\": 0.9576436635260165, \"specificity\": 0.5621259618124822, \"npv\": 0.8877137713771377, \"accuracy\": 0.8099898930794192, \"f1\": 0.8633302724211815, \"f2\": 0.9175490818002895, \"f0_5\": 0.8151616306122744, \"p4\": 0.7659811726664537, \"phi\": 0.5917251558134707}, {\"truth_threshold\": -12.3, \"match_probability\": 0.00019826449110064116, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3958, \"fp\": 3060, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.5639783414078084, \"fp_rate\": 0.4360216585921915, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7866406358945753, \"recall\": 0.9576436635260165, \"specificity\": 0.5639783414078084, \"npv\": 0.8880412833744671, \"accuracy\": 0.8106814192244268, \"f1\": 0.8637599050645025, \"f2\": 0.917743142550353, \"f0_5\": 0.8157746315926477, \"p4\": 0.7670697327406735, \"phi\": 0.593235986283468}, {\"truth_threshold\": -12.280000000000001, \"match_probability\": 0.00020103160386827137, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11282, \"tn\": 3959, \"fp\": 3059, \"fn\": 499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9576436635260165, \"tn_rate\": 0.5641208321459105, \"fp_rate\": 0.4358791678540895, \"fn_rate\": 0.042356336473983534, \"precision\": 0.7866954884596611, \"recall\": 0.9576436635260165, \"specificity\": 0.5641208321459105, \"npv\": 0.8880663974876626, \"accuracy\": 0.8107346135432736, \"f1\": 0.8637929714416966, \"f2\": 0.9177580737004799, \"f0_5\": 0.8158218237038108, \"p4\": 0.7671533458202425, \"phi\": 0.593352167873299}, {\"truth_threshold\": -12.26, \"match_probability\": 0.00020383732845162376, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11281, \"tn\": 3960, \"fp\": 3058, \"fn\": 500, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9575587810881928, \"tn_rate\": 0.5642633228840125, \"fp_rate\": 0.43573667711598746, \"fn_rate\": 0.042441218911807146, \"precision\": 0.7867354766720134, \"recall\": 0.9575587810881928, \"specificity\": 0.5642633228840125, \"npv\": 0.8878923766816144, \"accuracy\": 0.8107346135432736, \"f1\": 0.8637825421133232, \"f2\": 0.917706587703171, \"f0_5\": 0.8158439041323748, \"p4\": 0.767182624783831, \"phi\": 0.5933259861452577}, {\"truth_threshold\": -12.24, \"match_probability\": 0.0002066822034120213, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11280, \"tn\": 3966, \"fp\": 3052, \"fn\": 501, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9574738986503692, \"tn_rate\": 0.5651182673126247, \"fp_rate\": 0.43488173268737534, \"fn_rate\": 0.04252610134963076, \"precision\": 0.7870499581356405, \"recall\": 0.9574738986503692, \"specificity\": 0.5651182673126247, \"npv\": 0.8878441907320349, \"accuracy\": 0.8110005851375073, \"f1\": 0.8639375023934439, \"f2\": 0.9177297578755532, \"f0_5\": 0.81610209958182, \"p4\": 0.767629505782293, \"phi\": 0.5938807919545048}, {\"truth_threshold\": -12.22, \"match_probability\": 0.00020956677481647222, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11280, \"tn\": 3977, \"fp\": 3041, \"fn\": 501, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9574738986503692, \"tn_rate\": 0.5666856654317469, \"fp_rate\": 0.4333143345682531, \"fn_rate\": 0.04252610134963076, \"precision\": 0.7876544934012988, \"recall\": 0.9574738986503692, \"specificity\": 0.5666856654317469, \"npv\": 0.8881196962929879, \"accuracy\": 0.8115857226448215, \"f1\": 0.8643015860853575, \"f2\": 0.9178940515908536, \"f0_5\": 0.8166220227322087, \"p4\": 0.768546738489655, \"phi\": 0.5951583862200907}, {\"truth_threshold\": -12.200000000000001, \"match_probability\": 0.0002124915963420977, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 3977, \"fp\": 3041, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.5666856654317469, \"fp_rate\": 0.4333143345682531, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7876396648044692, \"recall\": 0.9573890162125456, \"specificity\": 0.5666856654317469, \"npv\": 0.8879214110292476, \"accuracy\": 0.8115325283259748, \"f1\": 0.8642580744032796, \"f2\": 0.9178276153896231, \"f0_5\": 0.8165969215620973, \"p4\": 0.7684924091887925, \"phi\": 0.5950163491441482}, {\"truth_threshold\": -12.18, \"match_probability\": 0.0002154572293820086, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 3981, \"fp\": 3037, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.567255628384155, \"fp_rate\": 0.43274437161584495, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7878597373568036, \"recall\": 0.9573890162125456, \"specificity\": 0.567255628384155, \"npv\": 0.8880214142315414, \"accuracy\": 0.8117453056013618, \"f1\": 0.8643905429742882, \"f2\": 0.9178873697916666, \"f0_5\": 0.8167861539575639, \"p4\": 0.7688254250844443, \"phi\": 0.5954808364378118}, {\"truth_threshold\": -12.16, \"match_probability\": 0.00021846424315264881, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 3985, \"fp\": 3033, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.5678255913365631, \"fp_rate\": 0.43217440866343687, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7880799329234209, \"recall\": 0.9573890162125456, \"specificity\": 0.5678255913365631, \"npv\": 0.8881212391352797, \"accuracy\": 0.8119580828767488, \"f1\": 0.864523052159583, \"f2\": 0.917947131974738, \"f0_5\": 0.8169754740761129, \"p4\": 0.7691581656117444, \"phi\": 0.5959452434637412}, {\"truth_threshold\": -12.14, \"match_probability\": 0.00022151321480262968, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 3993, \"fp\": 3025, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.5689655172413793, \"fp_rate\": 0.43103448275862066, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7885206935123042, \"recall\": 0.9573890162125456, \"specificity\": 0.5689655172413793, \"npv\": 0.8883203559510567, \"accuracy\": 0.8123836374275227, \"f1\": 0.864788192447767, \"f2\": 0.9180666796900436, \"f0_5\": 0.8173543777265678, \"p4\": 0.7698228229930866, \"phi\": 0.5968738181665806}, {\"truth_threshold\": -12.1, \"match_probability\": 0.00022773938065946784, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 3998, \"fp\": 3020, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.5696779709318894, \"fp_rate\": 0.43032202906811057, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7887964193300231, \"recall\": 0.9573890162125456, \"specificity\": 0.5696779709318894, \"npv\": 0.8884444444444445, \"accuracy\": 0.8126496090217564, \"f1\": 0.8649539877300614, \"f2\": 0.9181414128258144, \"f0_5\": 0.8175913710367224, \"p4\": 0.7702376779043407, \"phi\": 0.5974540163399217}, {\"truth_threshold\": -12.08, \"match_probability\": 0.00023091776982511915, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11279, \"tn\": 4003, \"fp\": 3015, \"fn\": 502, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9573890162125456, \"tn_rate\": 0.5703904246223995, \"fp_rate\": 0.42960957537760047, \"fn_rate\": 0.04261098378745438, \"precision\": 0.7890723380439345, \"recall\": 0.9573890162125456, \"specificity\": 0.5703904246223995, \"npv\": 0.8885682574916759, \"accuracy\": 0.8129155806159902, \"f1\": 0.8651198465963567, \"f2\": 0.9182161581295386, \"f0_5\": 0.8178285018199748, \"p4\": 0.7706521065748972, \"phi\": 0.5980340915021849}, {\"truth_threshold\": -12.06, \"match_probability\": 0.000234140507016114, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11277, \"tn\": 4003, \"fp\": 3015, \"fn\": 504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9572192513368984, \"tn_rate\": 0.5703904246223995, \"fp_rate\": 0.42960957537760047, \"fn_rate\": 0.0427807486631016, \"precision\": 0.7890428211586902, \"recall\": 0.9572192513368984, \"specificity\": 0.5703904246223995, \"npv\": 0.8881739516307965, \"accuracy\": 0.8128091919782967, \"f1\": 0.865032792544011, \"f2\": 0.9180832356389215, \"f0_5\": 0.817778357916721, \"p4\": 0.770543395921485, \"phi\": 0.5977508862776053}, {\"truth_threshold\": -12.040000000000001, \"match_probability\": 0.00023740821072792089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11277, \"tn\": 4035, \"fp\": 2983, \"fn\": 504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9572192513368984, \"tn_rate\": 0.5749501282416642, \"fp_rate\": 0.4250498717583357, \"fn_rate\": 0.0427807486631016, \"precision\": 0.7908134642356242, \"recall\": 0.9572192513368984, \"specificity\": 0.5749501282416642, \"npv\": 0.8889623265036352, \"accuracy\": 0.8145114101813926, \"f1\": 0.8660957720517646, \"f2\": 0.9185618402189496, \"f0_5\": 0.8192993417706804, \"p4\": 0.7731856442508955, \"phi\": 0.6014614375088718}, {\"truth_threshold\": -12.02, \"match_probability\": 0.00024072150807358944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11276, \"tn\": 4035, \"fp\": 2983, \"fn\": 505, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9571343688990748, \"tn_rate\": 0.5749501282416642, \"fp_rate\": 0.4250498717583357, \"fn_rate\": 0.04286563110092522, \"precision\": 0.7907987937443018, \"recall\": 0.9571343688990748, \"specificity\": 0.5749501282416642, \"npv\": 0.8887665198237885, \"accuracy\": 0.8144582158625459, \"f1\": 0.8660522273425499, \"f2\": 0.9184953488750958, \"f0_5\": 0.8192743072205996, \"p4\": 0.7731312561329806, \"phi\": 0.6013203540078832}, {\"truth_threshold\": -12.0, \"match_probability\": 0.000244081034903588, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11276, \"tn\": 4043, \"fp\": 2975, \"fn\": 505, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9571343688990748, \"tn_rate\": 0.5760900541464805, \"fp_rate\": 0.42390994585351954, \"fn_rate\": 0.04286563110092522, \"precision\": 0.7912427198091362, \"recall\": 0.9571343688990748, \"specificity\": 0.5760900541464805, \"npv\": 0.88896218117854, \"accuracy\": 0.8148837704133198, \"f1\": 0.866318377381684, \"f2\": 0.9186150712830957, \"f0_5\": 0.8196554481354946, \"p4\": 0.7737891240397962, \"phi\": 0.6022473460978576}, {\"truth_threshold\": -11.98, \"match_probability\": 0.00024748743592730506, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11275, \"tn\": 4044, \"fp\": 2974, \"fn\": 506, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9570494864612512, \"tn_rate\": 0.5762325448845825, \"fp_rate\": 0.4237674551154175, \"fn_rate\": 0.04295051353874883, \"precision\": 0.7912835988490421, \"recall\": 0.9570494864612512, \"specificity\": 0.5762325448845825, \"npv\": 0.8887912087912088, \"accuracy\": 0.8148837704133198, \"f1\": 0.8663081060315021, \"f2\": 0.9185635377120231, \"f0_5\": 0.8196780900591768, \"p4\": 0.7738168880634136, \"phi\": 0.6022222802965033}, {\"truth_threshold\": -11.94, \"match_probability\": 0.00025444348442884174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11273, \"tn\": 4048, \"fp\": 2970, \"fn\": 508, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.956879721585604, \"tn_rate\": 0.5768025078369906, \"fp_rate\": 0.4231974921630094, \"fn_rate\": 0.043120278414396064, \"precision\": 0.7914765147791898, \"recall\": 0.956879721585604, \"specificity\": 0.5768025078369906, \"npv\": 0.8884986830553117, \"accuracy\": 0.8149901590510134, \"f1\": 0.8663541346449432, \"f2\": 0.9184903938598922, \"f0_5\": 0.8198187715445144, \"p4\": 0.7740365662195949, \"phi\": 0.6024040832633744}, {\"truth_threshold\": -11.92, \"match_probability\": 0.00025799446673722515, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11271, \"tn\": 4493, \"fp\": 2525, \"fn\": 510, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9567099567099567, \"tn_rate\": 0.640210886292391, \"fp_rate\": 0.359789113707609, \"fn_rate\": 0.04329004329004329, \"precision\": 0.8169759350536387, \"recall\": 0.9567099567099567, \"specificity\": 0.640210886292391, \"npv\": 0.8980611633020188, \"accuracy\": 0.8385552423001223, \"f1\": 0.8813387027407437, \"f2\": 0.9250656598818122, \"f0_5\": 0.8415590233704174, \"p4\": 0.808935445004562, \"phi\": 0.6533150446212086}, {\"truth_threshold\": -11.9, \"match_probability\": 0.0002615949931554435, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11270, \"tn\": 4501, \"fp\": 2517, \"fn\": 511, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9566250742721331, \"tn_rate\": 0.6413508121972071, \"fp_rate\": 0.3586491878027928, \"fn_rate\": 0.04337492572786691, \"precision\": 0.817436715746718, \"recall\": 0.9566250742721331, \"specificity\": 0.6413508121972071, \"npv\": 0.8980446927374302, \"accuracy\": 0.8389276025320496, \"f1\": 0.8815707133917396, \"f2\": 0.9251202574247673, \"f0_5\": 0.841936977991603, \"p4\": 0.8094843562946074, \"phi\": 0.6540952755452684}, {\"truth_threshold\": -11.88, \"match_probability\": 0.00026524575456968495, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11269, \"tn\": 4503, \"fp\": 2515, \"fn\": 512, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9565401918343095, \"tn_rate\": 0.6416357936734113, \"fp_rate\": 0.3583642063265888, \"fn_rate\": 0.04345980816569052, \"precision\": 0.817542077771329, \"recall\": 0.9565401918343095, \"specificity\": 0.6416357936734113, \"npv\": 0.8979062811565304, \"accuracy\": 0.8389807968508963, \"f1\": 0.8815959319381967, \"f2\": 0.9250837328429763, \"f0_5\": 0.8420132402827383, \"p4\": 0.8095803258237969, \"phi\": 0.6541895957454182}, {\"truth_threshold\": -11.86, \"match_probability\": 0.0002689474514902129, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11269, \"tn\": 4505, \"fp\": 2513, \"fn\": 512, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9565401918343095, \"tn_rate\": 0.6419207751496153, \"fp_rate\": 0.35807922485038474, \"fn_rate\": 0.04345980816569052, \"precision\": 0.8176607168770861, \"recall\": 0.9565401918343095, \"specificity\": 0.6419207751496153, \"npv\": 0.8979469802670919, \"accuracy\": 0.8390871854885898, \"f1\": 0.881664906309901, \"f2\": 0.9251141102682823, \"f0_5\": 0.8421139159156467, \"p4\": 0.8097310778494282, \"phi\": 0.6544182717605341}, {\"truth_threshold\": -11.82, \"match_probability\": 0.0002765065028160592, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11262, \"tn\": 4505, \"fp\": 2513, \"fn\": 519, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9559460147695442, \"tn_rate\": 0.6419207751496153, \"fp_rate\": 0.35807922485038474, \"fn_rate\": 0.04405398523045582, \"precision\": 0.817568058076225, \"recall\": 0.9559460147695442, \"specificity\": 0.6419207751496153, \"npv\": 0.8966958598726115, \"accuracy\": 0.8387148252566626, \"f1\": 0.8813585850680857, \"f2\": 0.9246457248887502, \"f0_5\": 0.8419431527638642, \"p4\": 0.8093473294556791, \"phi\": 0.6534789023213777}, {\"truth_threshold\": -11.8, \"match_probability\": 0.00028036530757554303, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11257, \"tn\": 4505, \"fp\": 2513, \"fn\": 524, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9555216025804261, \"tn_rate\": 0.6419207751496153, \"fp_rate\": 0.35807922485038474, \"fn_rate\": 0.04447839741957389, \"precision\": 0.8175018155410312, \"recall\": 0.9555216025804261, \"specificity\": 0.6419207751496153, \"npv\": 0.8958043348578246, \"accuracy\": 0.8384488536624288, \"f1\": 0.8811396814214708, \"f2\": 0.9243110979735277, \"f0_5\": 0.8418210915182244, \"p4\": 0.809073347836239, \"phi\": 0.6528087947812552}, {\"truth_threshold\": -11.78, \"match_probability\": 0.0002842779488265541, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11256, \"tn\": 4505, \"fp\": 2513, \"fn\": 525, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9554367201426025, \"tn_rate\": 0.6419207751496153, \"fp_rate\": 0.35807922485038474, \"fn_rate\": 0.044563279857397504, \"precision\": 0.8174885612608033, \"recall\": 0.9554367201426025, \"specificity\": 0.6419207751496153, \"npv\": 0.8956262425447317, \"accuracy\": 0.8383956593435821, \"f1\": 0.8810958904109589, \"f2\": 0.9242441659960915, \"f0_5\": 0.8417966705057062, \"p4\": 0.8090185639363204, \"phi\": 0.6526748601387031}, {\"truth_threshold\": -11.76, \"match_probability\": 0.0002882451772437776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11255, \"tn\": 4508, \"fp\": 2510, \"fn\": 526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9553518377047788, \"tn_rate\": 0.6423482473639214, \"fp_rate\": 0.3576517526360787, \"fn_rate\": 0.04464816229522112, \"precision\": 0.8176534689429713, \"recall\": 0.9553518377047788, \"specificity\": 0.6423482473639214, \"npv\": 0.8955105284068335, \"accuracy\": 0.8385020479812756, \"f1\": 0.8811555625146794, \"f2\": 0.9242227660168504, \"f0_5\": 0.8419233703864395, \"p4\": 0.8091897794662747, \"phi\": 0.6528845088405091}, {\"truth_threshold\": -11.72, \"match_probability\": 0.00029634645069594797, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11255, \"tn\": 4512, \"fp\": 2506, \"fn\": 526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9553518377047788, \"tn_rate\": 0.6429182103163295, \"fp_rate\": 0.35708178968367055, \"fn_rate\": 0.04464816229522112, \"precision\": 0.8178911416321488, \"recall\": 0.9553518377047788, \"specificity\": 0.6429182103163295, \"npv\": 0.8955934894799523, \"accuracy\": 0.8387148252566626, \"f1\": 0.8812935557121604, \"f2\": 0.924283485259095, \"f0_5\": 0.8421249532360644, \"p4\": 0.8094909253755534, \"phi\": 0.6533425476101794}, {\"truth_threshold\": -11.700000000000001, \"match_probability\": 0.0003004820499384334, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11252, \"tn\": 4514, \"fp\": 2504, \"fn\": 529, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.955097190391308, \"tn_rate\": 0.6432031917925335, \"fp_rate\": 0.3567968082074665, \"fn_rate\": 0.04490280960869196, \"precision\": 0.8179703402151788, \"recall\": 0.955097190391308, \"specificity\": 0.6432031917925335, \"npv\": 0.8951021217529248, \"accuracy\": 0.8386616309378159, \"f1\": 0.8812311547950034, \"f2\": 0.9241130091984231, \"f0_5\": 0.842152533493002, \"p4\": 0.8094770834154268, \"phi\": 0.6531703656170336}, {\"truth_threshold\": -11.68, \"match_probability\": 0.00030467534505880815, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11249, \"tn\": 4533, \"fp\": 2485, \"fn\": 532, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9548425430778372, \"tn_rate\": 0.645910515816472, \"fp_rate\": 0.3540894841835281, \"fn_rate\": 0.0451574569221628, \"precision\": 0.8190621814475025, \"recall\": 0.9548425430778372, \"specificity\": 0.645910515816472, \"npv\": 0.8949654491609081, \"accuracy\": 0.8395127400393638, \"f1\": 0.881755829903978, \"f2\": 0.9242005981136416, \"f0_5\": 0.8430385059280243, \"p4\": 0.8107398279685185, \"phi\": 0.6549460155028493}, {\"truth_threshold\": -11.66, \"match_probability\": 0.00030892714047977567, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11249, \"tn\": 4535, \"fp\": 2483, \"fn\": 532, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9548425430778372, \"tn_rate\": 0.646195497292676, \"fp_rate\": 0.353804502707324, \"fn_rate\": 0.0451574569221628, \"precision\": 0.8191814739295077, \"recall\": 0.9548425430778372, \"specificity\": 0.646195497292676, \"npv\": 0.8950069074403, \"accuracy\": 0.8396191286770572, \"f1\": 0.8818249519852625, \"f2\": 0.9242309714736427, \"f0_5\": 0.8431396063499678, \"p4\": 0.8108897742786065, \"phi\": 0.6551750798022602}, {\"truth_threshold\": -11.64, \"match_probability\": 0.00031323825182578204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11248, \"tn\": 4542, \"fp\": 2476, \"fn\": 533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9547576606400136, \"tn_rate\": 0.6471929324593901, \"fp_rate\": 0.35280706754060986, \"fn_rate\": 0.04524233935998642, \"precision\": 0.8195861264937336, \"recall\": 0.9547576606400136, \"specificity\": 0.6471929324593901, \"npv\": 0.8949753694581281, \"accuracy\": 0.8399382945901378, \"f1\": 0.8820231327190747, \"f2\": 0.9242703129108598, \"f0_5\": 0.843469262264349, \"p4\": 0.8113594028857609, \"phi\": 0.6558435150965665}, {\"truth_threshold\": -11.6, \"match_probability\": 0.000322041741735126, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11248, \"tn\": 4544, \"fp\": 2474, \"fn\": 533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9547576606400136, \"tn_rate\": 0.6474779139355942, \"fp_rate\": 0.3525220860644058, \"fn_rate\": 0.04524233935998642, \"precision\": 0.819705582276636, \"recall\": 0.9547576606400136, \"specificity\": 0.6474779139355942, \"npv\": 0.8950167421705731, \"accuracy\": 0.8400446832278312, \"f1\": 0.8820923028663294, \"f2\": 0.9243006935542188, \"f0_5\": 0.8435704750333738, \"p4\": 0.8115091183672023, \"phi\": 0.6560725643749166}, {\"truth_threshold\": -11.56, \"match_probability\": 0.0003310925697838664, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11243, \"tn\": 4553, \"fp\": 2465, \"fn\": 538, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9543332484508955, \"tn_rate\": 0.6487603305785123, \"fp_rate\": 0.3512396694214876, \"fn_rate\": 0.04566675154910449, \"precision\": 0.8201779982491976, \"recall\": 0.9543332484508955, \"specificity\": 0.6487603305785123, \"npv\": 0.8943233156550776, \"accuracy\": 0.8402574605032183, \"f1\": 0.8821844717329044, \"f2\": 0.92410244608101, \"f0_5\": 0.8439043429961118, \"p4\": 0.8119083160246253, \"phi\": 0.6564382336699651}, {\"truth_threshold\": -11.540000000000001, \"match_probability\": 0.0003357128981956508, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11242, \"tn\": 4553, \"fp\": 2465, \"fn\": 539, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.954248366013072, \"tn_rate\": 0.6487603305785123, \"fp_rate\": 0.3512396694214876, \"fn_rate\": 0.0457516339869281, \"precision\": 0.8201648792587729, \"recall\": 0.954248366013072, \"specificity\": 0.6487603305785123, \"npv\": 0.8941476826394344, \"accuracy\": 0.8402042661843715, \"f1\": 0.8821406151914627, \"f2\": 0.9240354424553271, \"f0_5\": 0.8438799561620802, \"p4\": 0.8118535494013652, \"phi\": 0.656305330550677}, {\"truth_threshold\": -11.48, \"match_probability\": 0.00034996421264562645, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11242, \"tn\": 4554, \"fp\": 2464, \"fn\": 539, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.954248366013072, \"tn_rate\": 0.6489028213166145, \"fp_rate\": 0.3510971786833856, \"fn_rate\": 0.0457516339869281, \"precision\": 0.8202247191011236, \"recall\": 0.954248366013072, \"specificity\": 0.6489028213166145, \"npv\": 0.8941684665226782, \"accuracy\": 0.8402574605032183, \"f1\": 0.8821752265861027, \"f2\": 0.9240506329113924, \"f0_5\": 0.8439306358381503, \"p4\": 0.811928269192021, \"phi\": 0.6564199099122703}, {\"truth_threshold\": -11.46, \"match_probability\": 0.00035484779745482883, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11239, \"tn\": 4554, \"fp\": 2464, \"fn\": 542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.953993718699601, \"tn_rate\": 0.6489028213166145, \"fp_rate\": 0.3510971786833856, \"fn_rate\": 0.046006281300398945, \"precision\": 0.8201853608698825, \"recall\": 0.953993718699601, \"specificity\": 0.6489028213166145, \"npv\": 0.8936420722135008, \"accuracy\": 0.840097877546678, \"f1\": 0.8820436352221002, \"f2\": 0.9238496062603778, \"f0_5\": 0.8438574624960582, \"p4\": 0.8117639913329949, \"phi\": 0.6560214093873982}, {\"truth_threshold\": -11.44, \"match_probability\": 0.00035979950584844554, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11239, \"tn\": 4555, \"fp\": 2463, \"fn\": 542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.953993718699601, \"tn_rate\": 0.6490453120547165, \"fp_rate\": 0.35095468794528356, \"fn_rate\": 0.046006281300398945, \"precision\": 0.8202452196759598, \"recall\": 0.953993718699601, \"specificity\": 0.6490453120547165, \"npv\": 0.893662938983716, \"accuracy\": 0.8401510718655247, \"f1\": 0.8820782482439273, \"f2\": 0.9238647946601782, \"f0_5\": 0.843908152998243, \"p4\": 0.8118386960125169, \"phi\": 0.6561360255661399}, {\"truth_threshold\": -11.42, \"match_probability\": 0.00036482028742734155, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11238, \"tn\": 4555, \"fp\": 2463, \"fn\": 543, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9539088362617775, \"tn_rate\": 0.6490453120547165, \"fp_rate\": 0.35095468794528356, \"fn_rate\": 0.046091163738222564, \"precision\": 0.8202320998467265, \"recall\": 0.9539088362617775, \"specificity\": 0.6490453120547165, \"npv\": 0.8934876422126324, \"accuracy\": 0.840097877546678, \"f1\": 0.8820343772074406, \"f2\": 0.9237977805178792, \"f0_5\": 0.8438837576030638, \"p4\": 0.8117839440569901, \"phi\": 0.6560032615849318}, {\"truth_threshold\": -11.4, \"match_probability\": 0.00036991110500986284, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11238, \"tn\": 4558, \"fp\": 2460, \"fn\": 543, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9539088362617775, \"tn_rate\": 0.6494727842690226, \"fp_rate\": 0.3505272157309775, \"fn_rate\": 0.046091163738222564, \"precision\": 0.8204117389399912, \"recall\": 0.9539088362617775, \"specificity\": 0.6494727842690226, \"npv\": 0.8935502842579887, \"accuracy\": 0.8402574605032183, \"f1\": 0.8821382314847521, \"f2\": 0.9238433461576403, \"f0_5\": 0.8440358703979091, \"p4\": 0.8120079799433277, \"phi\": 0.6563471357099425}, {\"truth_threshold\": -11.38, \"match_probability\": 0.0003750729348152639, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11238, \"tn\": 4561, \"fp\": 2457, \"fn\": 543, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9539088362617775, \"tn_rate\": 0.6499002564833286, \"fp_rate\": 0.3500997435166714, \"fn_rate\": 0.046091163738222564, \"precision\": 0.8205914567360351, \"recall\": 0.9539088362617775, \"specificity\": 0.6499002564833286, \"npv\": 0.8936128526645768, \"accuracy\": 0.8404170434597585, \"f1\": 0.8822421102213849, \"f2\": 0.9238889162926059, \"f0_5\": 0.8441880380402939, \"p4\": 0.8122319024783915, \"phi\": 0.6566909898070998}, {\"truth_threshold\": -11.36, \"match_probability\": 0.0003803067666496687, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11229, \"tn\": 4567, \"fp\": 2451, \"fn\": 552, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.953144894321365, \"tn_rate\": 0.6507552009119407, \"fp_rate\": 0.3492447990880593, \"fn_rate\": 0.046855105678635094, \"precision\": 0.8208333333333333, \"recall\": 0.953144894321365, \"specificity\": 0.6507552009119407, \"npv\": 0.8921664387575698, \"accuracy\": 0.8402574605032183, \"f1\": 0.8820549075055968, \"f2\": 0.9233767515295046, \"f0_5\": 0.8442730184508503, \"p4\": 0.8121867343113559, \"phi\": 0.656186429505382}, {\"truth_threshold\": -11.34, \"match_probability\": 0.0003856136040945928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11228, \"tn\": 4570, \"fp\": 2448, \"fn\": 553, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9530600118835413, \"tn_rate\": 0.6511826731262468, \"fp_rate\": 0.3488173268737532, \"fn_rate\": 0.046939988116458706, \"precision\": 0.8210002924831822, \"recall\": 0.9530600118835413, \"specificity\": 0.6511826731262468, \"npv\": 0.8920554362678118, \"accuracy\": 0.8403638491409118, \"f1\": 0.8821149389166044, \"f2\": 0.9233552631578947, \"f0_5\": 0.8444009927051215, \"p4\": 0.8123555718509488, \"phi\": 0.656398284658112}, {\"truth_threshold\": -11.32, \"match_probability\": 0.0003909944646980703, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11227, \"tn\": 4570, \"fp\": 2448, \"fn\": 554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9529751294457177, \"tn_rate\": 0.6511826731262468, \"fp_rate\": 0.3488173268737532, \"fn_rate\": 0.04702487055428232, \"precision\": 0.8209872029250457, \"recall\": 0.9529751294457177, \"specificity\": 0.6511826731262468, \"npv\": 0.8918813427010148, \"accuracy\": 0.840310654822065, \"f1\": 0.882071024512885, \"f2\": 0.9232882119771707, \"f0_5\": 0.8443765887998075, \"p4\": 0.8123008521827207, \"phi\": 0.6562660238410282}, {\"truth_threshold\": -11.3, \"match_probability\": 0.00039645038016841163, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11227, \"tn\": 4575, \"fp\": 2443, \"fn\": 554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9529751294457177, \"tn_rate\": 0.6518951268167569, \"fp_rate\": 0.34810487318324307, \"fn_rate\": 0.04702487055428232, \"precision\": 0.8212874908558888, \"recall\": 0.9529751294457177, \"specificity\": 0.6518951268167569, \"npv\": 0.8919867420549815, \"accuracy\": 0.8405766264162987, \"f1\": 0.8822443126006837, \"f2\": 0.9233641477777412, \"f0_5\": 0.8446306856652773, \"p4\": 0.8126731959115945, \"phi\": 0.656839682149471}, {\"truth_threshold\": -11.28, \"match_probability\": 0.00040198239657063386, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11227, \"tn\": 4577, \"fp\": 2441, \"fn\": 554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9529751294457177, \"tn_rate\": 0.6521801082929609, \"fp_rate\": 0.34781989170703903, \"fn_rate\": 0.04702487055428232, \"precision\": 0.8214076675446298, \"recall\": 0.9529751294457177, \"specificity\": 0.6521801082929609, \"npv\": 0.8920288442798675, \"accuracy\": 0.8406830150539922, \"f1\": 0.8823136469016464, \"f2\": 0.9233945255954731, \"f0_5\": 0.8447323672369945, \"p4\": 0.8128220460282777, \"phi\": 0.6570691302478052}, {\"truth_threshold\": -11.26, \"match_probability\": 0.0004075915745255968, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11226, \"tn\": 4579, \"fp\": 2439, \"fn\": 555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.952890247007894, \"tn_rate\": 0.652465089769165, \"fp_rate\": 0.347534910230835, \"fn_rate\": 0.04710975299210593, \"precision\": 0.8215148188803513, \"recall\": 0.952890247007894, \"specificity\": 0.652465089769165, \"npv\": 0.8918971562134788, \"accuracy\": 0.840736209372839, \"f1\": 0.8823390709738269, \"f2\": 0.9233578443468391, \"f0_5\": 0.8448096807694044, \"p4\": 0.8129161232377954, \"phi\": 0.6571664526158592}, {\"truth_threshold\": -11.24, \"match_probability\": 0.000413278989411887, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11221, \"tn\": 4580, \"fp\": 2438, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.952465834818776, \"tn_rate\": 0.6526075805072671, \"fp_rate\": 0.347392419492733, \"fn_rate\": 0.047534165181224004, \"precision\": 0.8215096273519291, \"recall\": 0.952465834818776, \"specificity\": 0.6526075805072671, \"npv\": 0.8910505836575876, \"accuracy\": 0.840523432097452, \"f1\": 0.8821540880503145, \"f2\": 0.9230376914597832, \"f0_5\": 0.844738545854224, \"p4\": 0.8127169451229559, \"phi\": 0.6566210783252195}, {\"truth_threshold\": -11.22, \"match_probability\": 0.0004190457315704786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11221, \"tn\": 4586, \"fp\": 2432, \"fn\": 560, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.952465834818776, \"tn_rate\": 0.6534625249358792, \"fp_rate\": 0.34653747506412086, \"fn_rate\": 0.047534165181224004, \"precision\": 0.8218706511389439, \"recall\": 0.952465834818776, \"specificity\": 0.6534625249358792, \"npv\": 0.8911776136805286, \"accuracy\": 0.8408425980105325, \"f1\": 0.8823621923409609, \"f2\": 0.9231288151767939, \"f0_5\": 0.8450439052309732, \"p4\": 0.8131629431421088, \"phi\": 0.6573097941822911}, {\"truth_threshold\": -11.200000000000001, \"match_probability\": 0.00042489290651221616, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11219, \"tn\": 4587, \"fp\": 2431, \"fn\": 562, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9522960699431288, \"tn_rate\": 0.6536050156739812, \"fp_rate\": 0.3463949843260188, \"fn_rate\": 0.047703930056871235, \"precision\": 0.8219047619047619, \"recall\": 0.9522960699431288, \"specificity\": 0.6536050156739812, \"npv\": 0.8908525927364537, \"accuracy\": 0.8407894036916858, \"f1\": 0.8823089929613464, \"f2\": 0.9230098397340968, \"f0_5\": 0.845046022205149, \"p4\": 0.8131278259279535, \"phi\": 0.657160904922601}, {\"truth_threshold\": -11.16, \"match_probability\": 0.0004368330539027926, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11218, \"tn\": 4589, \"fp\": 2429, \"fn\": 563, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9522111875053052, \"tn_rate\": 0.6538899971501853, \"fp_rate\": 0.34611000284981475, \"fn_rate\": 0.04778881249469485, \"precision\": 0.8220121638455338, \"recall\": 0.9522111875053052, \"specificity\": 0.6538899971501853, \"npv\": 0.890722049689441, \"accuracy\": 0.8408425980105325, \"f1\": 0.8823344344816737, \"f2\": 0.9229731286304322, \"f0_5\": 0.8451234763217768, \"p4\": 0.8132216656015783, \"phi\": 0.6572587398947598}, {\"truth_threshold\": -11.14, \"match_probability\": 0.00044292831513024784, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11216, \"tn\": 4590, \"fp\": 2428, \"fn\": 565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.952041422629658, \"tn_rate\": 0.6540324878882873, \"fp_rate\": 0.3459675121117127, \"fn_rate\": 0.04795857737034208, \"precision\": 0.8220463207270595, \"recall\": 0.952041422629658, \"specificity\": 0.6540324878882873, \"npv\": 0.8903976721629486, \"accuracy\": 0.8407894036916858, \"f1\": 0.8822812192723697, \"f2\": 0.9228541337546077, \"f0_5\": 0.8451256084512561, \"p4\": 0.8131865279959156, \"phi\": 0.6571101253183261}, {\"truth_threshold\": -11.120000000000001, \"match_probability\": 0.0004491085871334007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11213, \"tn\": 4593, \"fp\": 2425, \"fn\": 568, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.951786775316187, \"tn_rate\": 0.6544599601025933, \"fp_rate\": 0.34554003989740667, \"fn_rate\": 0.04821322468381292, \"precision\": 0.8221880041061739, \"recall\": 0.951786775316187, \"specificity\": 0.6544599601025933, \"npv\": 0.8899438093392753, \"accuracy\": 0.8407894036916858, \"f1\": 0.8822534324717731, \"f2\": 0.9226983970244561, \"f0_5\": 0.8452052522876999, \"p4\": 0.8132451401133257, \"phi\": 0.6570598048040677}, {\"truth_threshold\": -11.1, \"match_probability\": 0.00045537505448605916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11210, \"tn\": 4593, \"fp\": 2425, \"fn\": 571, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9515321280027162, \"tn_rate\": 0.6544599601025933, \"fp_rate\": 0.34554003989740667, \"fn_rate\": 0.048467871997283765, \"precision\": 0.8221488815548221, \"recall\": 0.9515321280027162, \"specificity\": 0.6544599601025933, \"npv\": 0.889426800929512, \"accuracy\": 0.8406298207351455, \"f1\": 0.882121498268807, \"f2\": 0.9224970786220972, \"f0_5\": 0.8451320094690973, \"p4\": 0.8130811177573386, \"phi\": 0.6566652371441953}, {\"truth_threshold\": -11.08, \"match_probability\": 0.000461728918238175, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11210, \"tn\": 4600, \"fp\": 2418, \"fn\": 571, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9515321280027162, \"tn_rate\": 0.6554573952693075, \"fp_rate\": 0.3445426047306925, \"fn_rate\": 0.048467871997283765, \"precision\": 0.822571176988553, \"recall\": 0.9515321280027162, \"specificity\": 0.6554573952693075, \"npv\": 0.8895764842390254, \"accuracy\": 0.8410021809670727, \"f1\": 0.8823645165098981, \"f2\": 0.9226033710824335, \"f0_5\": 0.8454889656524822, \"p4\": 0.8136002160617725, \"phi\": 0.6574695197405082}, {\"truth_threshold\": -11.06, \"match_probability\": 0.00046817139614416427, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11209, \"tn\": 4601, \"fp\": 2417, \"fn\": 572, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9514472455648926, \"tn_rate\": 0.6555998860074095, \"fp_rate\": 0.34440011399259046, \"fn_rate\": 0.04855275443510738, \"precision\": 0.8226185234111257, \"recall\": 0.9514472455648926, \"specificity\": 0.6555998860074095, \"npv\": 0.8894258650686255, \"accuracy\": 0.8410021809670727, \"f1\": 0.8823552564253946, \"f2\": 0.9225514403292181, \"f0_5\": 0.8455155766764728, \"p4\": 0.8136196510142679, \"phi\": 0.6574530428698213}, {\"truth_threshold\": -11.040000000000001, \"match_probability\": 0.0004747037228943636, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11207, \"tn\": 4603, \"fp\": 2415, \"fn\": 574, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9512774806892454, \"tn_rate\": 0.6558848674836135, \"fp_rate\": 0.3441151325163864, \"fn_rate\": 0.0487225193107546, \"precision\": 0.8227132579650566, \"recall\": 0.9512774806892454, \"specificity\": 0.6558848674836135, \"npv\": 0.8891249758547422, \"accuracy\": 0.8410021809670727, \"f1\": 0.8823367318820612, \"f2\": 0.9224475685641853, \"f0_5\": 0.8455688179993662, \"p4\": 0.8136584911286098, \"phi\": 0.6574202412196095}, {\"truth_threshold\": -11.02, \"match_probability\": 0.0004813271503496699, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11201, \"tn\": 4603, \"fp\": 2415, \"fn\": 580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9507681860623037, \"tn_rate\": 0.6558848674836135, \"fp_rate\": 0.3441151325163864, \"fn_rate\": 0.04923181393769629, \"precision\": 0.8226351351351351, \"recall\": 0.9507681860623037, \"specificity\": 0.6558848674836135, \"npv\": 0.8880956974725063, \"accuracy\": 0.8406830150539922, \"f1\": 0.8820726857502854, \"f2\": 0.9220447810339151, \"f0_5\": 0.8454222960223413, \"p4\": 0.8133305773359207, \"phi\": 0.6566331013973159}, {\"truth_threshold\": -10.98, \"match_probability\": 0.0004948524021024512, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11201, \"tn\": 4604, \"fp\": 2414, \"fn\": 580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9507681860623037, \"tn_rate\": 0.6560273582217155, \"fp_rate\": 0.3439726417782844, \"fn_rate\": 0.04923181393769629, \"precision\": 0.8226955563716489, \"recall\": 0.9507681860623037, \"specificity\": 0.6560273582217155, \"npv\": 0.8881172839506173, \"accuracy\": 0.840736209372839, \"f1\": 0.882107418491101, \"f2\": 0.9220599614745056, \"f0_5\": 0.8454733473226551, \"p4\": 0.8134046406856249, \"phi\": 0.656748098076743}, {\"truth_threshold\": -10.96, \"match_probability\": 0.000501756818131702, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11194, \"tn\": 4607, \"fp\": 2411, \"fn\": 587, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9501740089975385, \"tn_rate\": 0.6564548304360217, \"fp_rate\": 0.34354516956397835, \"fn_rate\": 0.04982599100246159, \"precision\": 0.8227857405365674, \"recall\": 0.9501740089975385, \"specificity\": 0.6564548304360217, \"npv\": 0.8869849826723142, \"accuracy\": 0.840523432097452, \"f1\": 0.881903411329079, \"f2\": 0.921635462464391, \"f0_5\": 0.8454555067144001, \"p4\": 0.8132443498029978, \"phi\": 0.6561763406921362}, {\"truth_threshold\": -10.94, \"match_probability\": 0.0005087575188218651, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11192, \"tn\": 4608, \"fp\": 2410, \"fn\": 589, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9500042441218912, \"tn_rate\": 0.6565973211741237, \"fp_rate\": 0.34340267882587633, \"fn_rate\": 0.04999575587810882, \"precision\": 0.8228201735038965, \"recall\": 0.9500042441218912, \"specificity\": 0.6565973211741237, \"npv\": 0.8866653838753127, \"accuracy\": 0.8404702377786053, \"f1\": 0.8818500571248473, \"f2\": 0.9215163192042947, \"f0_5\": 0.8454577044524014, \"p4\": 0.8132091333315652, \"phi\": 0.6560297627860674}, {\"truth_threshold\": -10.92, \"match_probability\": 0.000515855845520672, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11191, \"tn\": 4608, \"fp\": 2410, \"fn\": 590, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9499193616840675, \"tn_rate\": 0.6565973211741237, \"fp_rate\": 0.34340267882587633, \"fn_rate\": 0.05008063831593244, \"precision\": 0.8228071465333431, \"recall\": 0.9499193616840675, \"specificity\": 0.6565973211741237, \"npv\": 0.8864948056944979, \"accuracy\": 0.8404170434597585, \"f1\": 0.8818060042549839, \"f2\": 0.9214491560312886, \"f0_5\": 0.8454332552693209, \"p4\": 0.813154526823862, \"phi\": 0.6558989763752261}, {\"truth_threshold\": -10.9, \"match_probability\": 0.0005230531582235416, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11190, \"tn\": 4686, \"fp\": 2332, \"fn\": 591, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.949834479246244, \"tn_rate\": 0.6677115987460815, \"fp_rate\": 0.3322884012539185, \"fn_rate\": 0.05016552075375605, \"precision\": 0.8275403046886555, \"recall\": 0.949834479246244, \"specificity\": 0.6677115987460815, \"npv\": 0.8880045480386584, \"accuracy\": 0.844513006010958, \"f1\": 0.8844801011737738, \"f2\": 0.9225670283283316, \"f0_5\": 0.8494132292884361, \"p4\": 0.8188351219898857, \"phi\": 0.6647419931291755}, {\"truth_threshold\": -10.88, \"match_probability\": 0.0005303508358317331, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11185, \"tn\": 4686, \"fp\": 2332, \"fn\": 596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9494100670571258, \"tn_rate\": 0.6677115987460815, \"fp_rate\": 0.3322884012539185, \"fn_rate\": 0.050589932942874116, \"precision\": 0.8274765110601465, \"recall\": 0.9494100670571258, \"specificity\": 0.6677115987460815, \"npv\": 0.8871639530480878, \"accuracy\": 0.8442470344167243, \"f1\": 0.8842596252668196, \"f2\": 0.9222308339242427, \"f0_5\": 0.8492915609956112, \"p4\": 0.8185618530874093, \"phi\": 0.6640934525056326}, {\"truth_threshold\": -10.86, \"match_probability\": 0.0005377502764140461, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11185, \"tn\": 4687, \"fp\": 2331, \"fn\": 596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9494100670571258, \"tn_rate\": 0.6678540894841836, \"fp_rate\": 0.3321459105158165, \"fn_rate\": 0.050589932942874116, \"precision\": 0.8275377330571175, \"recall\": 0.9494100670571258, \"specificity\": 0.6678540894841836, \"npv\": 0.887185311376112, \"accuracy\": 0.8443002287355711, \"f1\": 0.8842945803850258, \"f2\": 0.9222460422163589, \"f0_5\": 0.8493431543777052, \"p4\": 0.8186349069045742, \"phi\": 0.6642084892431851}, {\"truth_threshold\": -10.84, \"match_probability\": 0.0005452528974721083, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11184, \"tn\": 4692, \"fp\": 2326, \"fn\": 597, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9493251846193023, \"tn_rate\": 0.6685665431746937, \"fp_rate\": 0.33143345682530634, \"fn_rate\": 0.050674815380697735, \"precision\": 0.8278312361213915, \"recall\": 0.9493251846193023, \"specificity\": 0.6685665431746937, \"npv\": 0.88712422007941, \"accuracy\": 0.844513006010958, \"f1\": 0.8844252896287217, \"f2\": 0.9222548405185209, \"f0_5\": 0.8495768827577824, \"p4\": 0.8189453532379117, \"phi\": 0.664654092086747}, {\"truth_threshold\": -10.82, \"match_probability\": 0.0005528601362093087, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11184, \"tn\": 4698, \"fp\": 2320, \"fn\": 597, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9493251846193023, \"tn_rate\": 0.6694214876033058, \"fp_rate\": 0.3305785123966942, \"fn_rate\": 0.050674815380697735, \"precision\": 0.8281990521327014, \"recall\": 0.9493251846193023, \"specificity\": 0.6694214876033058, \"npv\": 0.8872521246458923, \"accuracy\": 0.8448321719240385, \"f1\": 0.8846351591852877, \"f2\": 0.9223461107079237, \"f0_5\": 0.8498867729531742, \"p4\": 0.8193830738060698, \"phi\": 0.6653442979161269}, {\"truth_threshold\": -10.78, \"match_probability\": 0.0005683943156829212, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11184, \"tn\": 4701, \"fp\": 2317, \"fn\": 597, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9493251846193023, \"tn_rate\": 0.6698489598176118, \"fp_rate\": 0.33015104018238817, \"fn_rate\": 0.050674815380697735, \"precision\": 0.8283830827346123, \"recall\": 0.9493251846193023, \"specificity\": 0.6698489598176118, \"npv\": 0.8873159682899208, \"accuracy\": 0.8449917548805788, \"f1\": 0.8847401313187248, \"f2\": 0.9223917525773195, \"f0_5\": 0.8500418028425933, \"p4\": 0.8196017763957282, \"phi\": 0.6656893777073708}, {\"truth_threshold\": -10.76, \"match_probability\": 0.0005763242318072081, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11183, \"tn\": 4707, \"fp\": 2311, \"fn\": 598, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9492403021814787, \"tn_rate\": 0.670703904246224, \"fp_rate\": 0.329296095753776, \"fn_rate\": 0.05075969781852135, \"precision\": 0.8287386986808952, \"recall\": 0.9492403021814787, \"specificity\": 0.670703904246224, \"npv\": 0.8872761545711593, \"accuracy\": 0.8452577264748125, \"f1\": 0.8849060336300693, \"f2\": 0.9224157840905342, \"f0_5\": 0.8503277217634625, \"p4\": 0.8199842124817665, \"phi\": 0.6662501482099593}, {\"truth_threshold\": -10.74, \"match_probability\": 0.0005843647169505126, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11180, \"tn\": 4707, \"fp\": 2311, \"fn\": 601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9489856548680078, \"tn_rate\": 0.670703904246224, \"fp_rate\": 0.329296095753776, \"fn_rate\": 0.05101434513199219, \"precision\": 0.8287006152249647, \"recall\": 0.9489856548680078, \"specificity\": 0.670703904246224, \"npv\": 0.8867746797287114, \"accuracy\": 0.8450981435182723, \"f1\": 0.8847736625514403, \"f2\": 0.9222139734389178, \"f0_5\": 0.8502547722260247, \"p4\": 0.8198202723053605, \"phi\": 0.6658622756148366}, {\"truth_threshold\": -10.72, \"match_probability\": 0.0005925173109898081, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11180, \"tn\": 4709, \"fp\": 2309, \"fn\": 601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9489856548680078, \"tn_rate\": 0.6709888857224281, \"fp_rate\": 0.32901111427757196, \"fn_rate\": 0.05101434513199219, \"precision\": 0.828823485803247, \"recall\": 0.9489856548680078, \"specificity\": 0.6709888857224281, \"npv\": 0.8868173258003766, \"accuracy\": 0.8452045321559657, \"f1\": 0.8848436881677879, \"f2\": 0.9222444030158546, \"f0_5\": 0.8503582457367996, \"p4\": 0.8199658699417152, \"phi\": 0.6660923985467205}, {\"truth_threshold\": -10.68, \"match_probability\": 0.000609165092532851, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11175, \"tn\": 4709, \"fp\": 2309, \"fn\": 606, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9485612426788897, \"tn_rate\": 0.6709888857224281, \"fp_rate\": 0.32901111427757196, \"fn_rate\": 0.051438757321110265, \"precision\": 0.8287600118659152, \"recall\": 0.9485612426788897, \"specificity\": 0.6709888857224281, \"npv\": 0.8859830667920978, \"accuracy\": 0.844938560561732, \"f1\": 0.8846229962398575, \"f2\": 0.9219079989440337, \"f0_5\": 0.8502366206613206, \"p4\": 0.8196927064073419, \"phi\": 0.6654465915131922}, {\"truth_threshold\": -10.66, \"match_probability\": 0.0006176634679506185, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11174, \"tn\": 4710, \"fp\": 2308, \"fn\": 607, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9484763602410661, \"tn_rate\": 0.6711313764605301, \"fp_rate\": 0.32886862353946994, \"fn_rate\": 0.05152363975893388, \"precision\": 0.8288087820798101, \"recall\": 0.9484763602410661, \"specificity\": 0.6711313764605301, \"npv\": 0.8858378785029152, \"accuracy\": 0.844938560561732, \"f1\": 0.8846138621699718, \"f2\": 0.9218559218559218, \"f0_5\": 0.8502640429773699, \"p4\": 0.8197108621049091, \"phi\": 0.6654326411478598}, {\"truth_threshold\": -10.64, \"match_probability\": 0.0006262803286962502, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11171, \"tn\": 4710, \"fp\": 2308, \"fn\": 610, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9482217129275953, \"tn_rate\": 0.6711313764605301, \"fp_rate\": 0.32886862353946994, \"fn_rate\": 0.05177828707240472, \"precision\": 0.828770680317531, \"recall\": 0.9482217129275953, \"specificity\": 0.6711313764605301, \"npv\": 0.8853383458646616, \"accuracy\": 0.8447789776051917, \"f1\": 0.8844813935075218, \"f2\": 0.9216540435291982, \"f0_5\": 0.8501910285096732, \"p4\": 0.8195470199620176, \"phi\": 0.6650455860509765}, {\"truth_threshold\": -10.58, \"match_probability\": 0.0006528584362767788, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11164, \"tn\": 4710, \"fp\": 2308, \"fn\": 617, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.94762753586283, \"tn_rate\": 0.6711313764605301, \"fp_rate\": 0.32886862353946994, \"fn_rate\": 0.05237246413717002, \"precision\": 0.8286817102137767, \"recall\": 0.94762753586283, \"specificity\": 0.6711313764605301, \"npv\": 0.8841749577623428, \"accuracy\": 0.8444066173732645, \"f1\": 0.8841721775630618, \"f2\": 0.9211829163641164, \"f0_5\": 0.8500205576451598, \"p4\": 0.8191648574954138, \"phi\": 0.6641433704550233}, {\"truth_threshold\": -10.52, \"match_probability\": 0.0006805636984582193, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11163, \"tn\": 4712, \"fp\": 2306, \"fn\": 618, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9475426534250063, \"tn_rate\": 0.6714163579367342, \"fp_rate\": 0.3285836420632659, \"fn_rate\": 0.05245734657499363, \"precision\": 0.828792040982998, \"recall\": 0.9475426534250063, \"specificity\": 0.6714163579367342, \"npv\": 0.8840525328330207, \"accuracy\": 0.8444598116921113, \"f1\": 0.8841980198019802, \"f2\": 0.9211460069645009, \"f0_5\": 0.8500997608785049, \"p4\": 0.819255779808329, \"phi\": 0.6642451148964094}, {\"truth_threshold\": -10.5, \"match_probability\": 0.000690057457889322, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11162, \"tn\": 4712, \"fp\": 2306, \"fn\": 619, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9474577709871828, \"tn_rate\": 0.6714163579367342, \"fp_rate\": 0.3285836420632659, \"fn_rate\": 0.05254222901281725, \"precision\": 0.8287793287793288, \"recall\": 0.9474577709871828, \"specificity\": 0.6714163579367342, \"npv\": 0.8838867004314388, \"accuracy\": 0.8444066173732645, \"f1\": 0.8841538278743712, \"f2\": 0.9210786902561394, \"f0_5\": 0.8500753964022969, \"p4\": 0.819201202980415, \"phi\": 0.6641163813982309}, {\"truth_threshold\": -10.46, \"match_probability\": 0.000709443850321953, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11161, \"tn\": 4712, \"fp\": 2306, \"fn\": 620, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9473728885493591, \"tn_rate\": 0.6714163579367342, \"fp_rate\": 0.3285836420632659, \"fn_rate\": 0.05262711145064086, \"precision\": 0.8287666146877553, \"recall\": 0.9473728885493591, \"specificity\": 0.6714163579367342, \"npv\": 0.8837209302325582, \"accuracy\": 0.8443534230544177, \"f1\": 0.8841096324461344, \"f2\": 0.9210113713257745, \"f0_5\": 0.850051028957029, \"p4\": 0.8191466300250796, \"phi\": 0.6639876738705074}, {\"truth_threshold\": -10.44, \"match_probability\": 0.0007193401934507505, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11158, \"tn\": 4717, \"fp\": 2301, \"fn\": 623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9471182412358883, \"tn_rate\": 0.6721288116272442, \"fp_rate\": 0.32787118837275575, \"fn_rate\": 0.052881758764111705, \"precision\": 0.8290363325655695, \"recall\": 0.9471182412358883, \"specificity\": 0.6721288116272442, \"npv\": 0.8833333333333333, \"accuracy\": 0.8444598116921113, \"f1\": 0.8841521394611728, \"f2\": 0.920885396893518, \"f0_5\": 0.8502369812700977, \"p4\": 0.8193464657726147, \"phi\": 0.6641783014800995}, {\"truth_threshold\": -10.42, \"match_probability\": 0.0007293744842456983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11158, \"tn\": 4721, \"fp\": 2297, \"fn\": 623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9471182412358883, \"tn_rate\": 0.6726987745796523, \"fp_rate\": 0.3273012254203477, \"fn_rate\": 0.052881758764111705, \"precision\": 0.8292827945001858, \"recall\": 0.9471182412358883, \"specificity\": 0.6726987745796523, \"npv\": 0.8834206586826348, \"accuracy\": 0.8446725889674983, \"f1\": 0.8842922808686005, \"f2\": 0.9209462024794071, \"f0_5\": 0.850444352982424, \"p4\": 0.8196370830490317, \"phi\": 0.6646395470578069}, {\"truth_threshold\": -10.36, \"match_probability\": 0.0007603243767939938, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11158, \"tn\": 4727, \"fp\": 2291, \"fn\": 623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9471182412358883, \"tn_rate\": 0.6735537190082644, \"fp_rate\": 0.32644628099173556, \"fn_rate\": 0.052881758764111705, \"precision\": 0.8296527622871589, \"recall\": 0.9471182412358883, \"specificity\": 0.6735537190082644, \"npv\": 0.8835514018691589, \"accuracy\": 0.8449917548805788, \"f1\": 0.8845025762980578, \"f2\": 0.921037425915837, \"f0_5\": 0.8507556002866858, \"p4\": 0.8200726634673997, \"phi\": 0.6653313660283832}, {\"truth_threshold\": -10.34, \"match_probability\": 0.0007709299271214838, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11154, \"tn\": 4727, \"fp\": 2291, \"fn\": 627, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9467787114845938, \"tn_rate\": 0.6735537190082644, \"fp_rate\": 0.32644628099173556, \"fn_rate\": 0.05322128851540616, \"precision\": 0.8296020825585719, \"recall\": 0.9467787114845938, \"specificity\": 0.6735537190082644, \"npv\": 0.8828912962271199, \"accuracy\": 0.8447789776051917, \"f1\": 0.8843256957107746, \"f2\": 0.9207680496623686, \"f0_5\": 0.8506581656777658, \"p4\": 0.8198544094460365, \"phi\": 0.6648178317194846}, {\"truth_threshold\": -10.32, \"match_probability\": 0.0007816832955544318, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11154, \"tn\": 4734, \"fp\": 2284, \"fn\": 627, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9467787114845938, \"tn_rate\": 0.6745511541749786, \"fp_rate\": 0.32544884582502137, \"fn_rate\": 0.05322128851540616, \"precision\": 0.8300342312844173, \"recall\": 0.9467787114845938, \"specificity\": 0.6745511541749786, \"npv\": 0.8830442081701175, \"accuracy\": 0.845151337837119, \"f1\": 0.8845711566675919, \"f2\": 0.9208744757438658, \"f0_5\": 0.8510216226939099, \"p4\": 0.8203620422409958, \"phi\": 0.6656252181152873}, {\"truth_threshold\": -10.3, \"match_probability\": 0.0007925865391020799, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11153, \"tn\": 4736, \"fp\": 2282, \"fn\": 628, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9466938290467702, \"tn_rate\": 0.6748361356511827, \"fp_rate\": 0.32516386434881733, \"fn_rate\": 0.05330617095322978, \"precision\": 0.8301451432824711, \"recall\": 0.9466938290467702, \"specificity\": 0.6748361356511827, \"npv\": 0.8829231916480239, \"accuracy\": 0.8452045321559657, \"f1\": 0.8845970812182741, \"f2\": 0.9208375303423108, \"f0_5\": 0.8511011736695105, \"p4\": 0.8204524162064949, \"phi\": 0.6657276748315175}, {\"truth_threshold\": -10.28, \"match_probability\": 0.0008036417433073089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11151, \"tn\": 4737, \"fp\": 2281, \"fn\": 630, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.946524064171123, \"tn_rate\": 0.6749786263892847, \"fp_rate\": 0.3250213736107153, \"fn_rate\": 0.053475935828877004, \"precision\": 0.8301816557474687, \"recall\": 0.946524064171123, \"specificity\": 0.6749786263892847, \"npv\": 0.8826159865846842, \"accuracy\": 0.845151337837119, \"f1\": 0.8845436877801134, \"f2\": 0.9207180130788031, \"f0_5\": 0.8511044283991512, \"p4\": 0.8204157538538728, \"phi\": 0.6655866979849794}, {\"truth_threshold\": -10.24, \"match_probability\": 0.0008262165208949831, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11150, \"tn\": 4738, \"fp\": 2280, \"fn\": 631, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9464391817332993, \"tn_rate\": 0.6751211171273868, \"fp_rate\": 0.3248788828726133, \"fn_rate\": 0.05356081826670062, \"precision\": 0.8302308265078183, \"recall\": 0.9464391817332993, \"specificity\": 0.6751211171273868, \"npv\": 0.8824734587446452, \"accuracy\": 0.845151337837119, \"f1\": 0.884534528578795, \"f2\": 0.9206658519668395, \"f0_5\": 0.851132043785591, \"p4\": 0.8204336394331697, \"phi\": 0.6655739542235805}, {\"truth_threshold\": -10.22, \"match_probability\": 0.0008377404115973132, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11146, \"tn\": 4740, \"fp\": 2278, \"fn\": 635, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.946099651982005, \"tn_rate\": 0.6754060986035908, \"fp_rate\": 0.32459390139640926, \"fn_rate\": 0.05390034801799508, \"precision\": 0.8303039332538736, \"recall\": 0.946099651982005, \"specificity\": 0.6754060986035908, \"npv\": 0.881860465116279, \"accuracy\": 0.8450449491994255, \"f1\": 0.8844276929180718, \"f2\": 0.9204267688445531, \"f0_5\": 0.8511385677413443, \"p4\": 0.8203603050103888, \"phi\": 0.6652926190402093}, {\"truth_threshold\": -10.200000000000001, \"match_probability\": 0.0008494248984104829, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11145, \"tn\": 4741, \"fp\": 2277, \"fn\": 636, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9460147695441813, \"tn_rate\": 0.6755485893416928, \"fp_rate\": 0.32445141065830724, \"fn_rate\": 0.05398523045581869, \"precision\": 0.8303531515422441, \"recall\": 0.9460147695441813, \"specificity\": 0.6755485893416928, \"npv\": 0.8817184303514971, \"accuracy\": 0.8450449491994255, \"f1\": 0.8844185216045709, \"f2\": 0.920374591219899, \"f0_5\": 0.851166200797324, \"p4\": 0.8203781692900948, \"phi\": 0.6652800945534532}, {\"truth_threshold\": -10.18, \"match_probability\": 0.0008612722155521146, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11145, \"tn\": 4743, \"fp\": 2275, \"fn\": 636, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9460147695441813, \"tn_rate\": 0.6758335708178969, \"fp_rate\": 0.32416642918210314, \"fn_rate\": 0.05398523045581869, \"precision\": 0.8304769001490313, \"recall\": 0.9460147695441813, \"specificity\": 0.6758335708178969, \"npv\": 0.8817624093697713, \"accuracy\": 0.845151337837119, \"f1\": 0.8844887107654458, \"f2\": 0.9204049947145877, \"f0_5\": 0.851270221964223, \"p4\": 0.8205229303400154, \"phi\": 0.665510956006661}, {\"truth_threshold\": -10.16, \"match_probability\": 0.000873284628214516, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11145, \"tn\": 4745, \"fp\": 2273, \"fn\": 636, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9460147695441813, \"tn_rate\": 0.6761185522941009, \"fp_rate\": 0.3238814477058991, \"fn_rate\": 0.05398523045581869, \"precision\": 0.830600685646147, \"recall\": 0.9460147695441813, \"specificity\": 0.6761185522941009, \"npv\": 0.8818063556959673, \"accuracy\": 0.8452577264748125, \"f1\": 0.8845589110678995, \"f2\": 0.9204354002180305, \"f0_5\": 0.8513742685591188, \"p4\": 0.8206676458610428, \"phi\": 0.6657418111634209}, {\"truth_threshold\": -10.14, \"match_probability\": 0.0008854644329910831, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11144, \"tn\": 4745, \"fp\": 2273, \"fn\": 637, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9459298871063577, \"tn_rate\": 0.6761185522941009, \"fp_rate\": 0.3238814477058991, \"fn_rate\": 0.0540701128936423, \"precision\": 0.830588059923977, \"recall\": 0.9459298871063577, \"specificity\": 0.6761185522941009, \"npv\": 0.8816425120772947, \"accuracy\": 0.8452045321559657, \"f1\": 0.8845146440193666, \"f2\": 0.9203680150641714, \"f0_5\": 0.8513499060337056, \"p4\": 0.8206131124444525, \"phi\": 0.665613939011712}, {\"truth_threshold\": -10.120000000000001, \"match_probability\": 0.0008978139583084768, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11143, \"tn\": 4745, \"fp\": 2273, \"fn\": 638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.945845004668534, \"tn_rate\": 0.6761185522941009, \"fp_rate\": 0.3238814477058991, \"fn_rate\": 0.05415499533146592, \"precision\": 0.8305754323196184, \"recall\": 0.945845004668534, \"specificity\": 0.6761185522941009, \"npv\": 0.8814787293330857, \"accuracy\": 0.845151337837119, \"f1\": 0.8844703734571576, \"f2\": 0.9203006276841758, \"f0_5\": 0.8513255405302163, \"p4\": 0.8205585828561404, \"phi\": 0.6654860923652446}, {\"truth_threshold\": -10.1, \"match_probability\": 0.0009103355648646677, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11142, \"tn\": 4746, \"fp\": 2272, \"fn\": 639, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9457601222307105, \"tn_rate\": 0.6762610430322029, \"fp_rate\": 0.3237389569677971, \"fn_rate\": 0.054239877769289534, \"precision\": 0.83062472044133, \"recall\": 0.9457601222307105, \"specificity\": 0.6762610430322029, \"npv\": 0.8813370473537604, \"accuracy\": 0.845151337837119, \"f1\": 0.8844612026195674, \"f2\": 0.9202484389969936, \"f0_5\": 0.8513532099576692, \"p4\": 0.8205763954503015, \"phi\": 0.6654737323340012}, {\"truth_threshold\": -10.06, \"match_probability\": 0.0009359046285117405, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11140, \"tn\": 4910, \"fp\": 2108, \"fn\": 641, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9455903573550632, \"tn_rate\": 0.6996295240809347, \"fp_rate\": 0.30037047591906524, \"fn_rate\": 0.054409642644936765, \"precision\": 0.8408816425120773, \"recall\": 0.9455903573550632, \"specificity\": 0.6996295240809347, \"npv\": 0.884525310754819, \"accuracy\": 0.853768817490292, \"f1\": 0.8901674058092612, \"f2\": 0.9226131319154575, \"f0_5\": 0.8599262038194927, \"p4\": 0.8321810741693816, \"phi\": 0.6841395971435328}, {\"truth_threshold\": -10.040000000000001, \"match_probability\": 0.0009489569723810712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11139, \"tn\": 4911, \"fp\": 2107, \"fn\": 642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9455054749172396, \"tn_rate\": 0.6997720148190367, \"fp_rate\": 0.3002279851809632, \"fn_rate\": 0.05449452508276038, \"precision\": 0.8409331118828326, \"recall\": 0.9455054749172396, \"specificity\": 0.6997720148190367, \"npv\": 0.8843868179362506, \"accuracy\": 0.853768817490292, \"f1\": 0.8901586286810245, \"f2\": 0.9225608746065926, \"f0_5\": 0.8599552227283255, \"p4\": 0.8321969768106962, \"phi\": 0.6841290986132298}, {\"truth_threshold\": -10.02, \"match_probability\": 0.0009621911719644465, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11139, \"tn\": 4915, \"fp\": 2103, \"fn\": 642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9455054749172396, \"tn_rate\": 0.7003419777714448, \"fp_rate\": 0.29965802222855514, \"fn_rate\": 0.05449452508276038, \"precision\": 0.8411871318531944, \"recall\": 0.9455054749172396, \"specificity\": 0.7003419777714448, \"npv\": 0.8844700377901745, \"accuracy\": 0.853981594765679, \"f1\": 0.8903009231507013, \"f2\": 0.9226220057648346, \"f0_5\": 0.8601677245980633, \"p4\": 0.8324790256798642, \"phi\": 0.6845902676341888}, {\"truth_threshold\": -10.0, \"match_probability\": 0.000975609756097561, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11138, \"tn\": 4915, \"fp\": 2103, \"fn\": 643, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.945420592479416, \"tn_rate\": 0.7003419777714448, \"fp_rate\": 0.29965802222855514, \"fn_rate\": 0.05457940752058399, \"precision\": 0.8411751378294691, \"recall\": 0.945420592479416, \"specificity\": 0.7003419777714448, \"npv\": 0.8843109032025909, \"accuracy\": 0.8539284004468323, \"f1\": 0.8902565742146911, \"f2\": 0.9225544603661062, \"f0_5\": 0.8601436404355549, \"p4\": 0.832424390283846, \"phi\": 0.684464557546981}, {\"truth_threshold\": -9.98, \"match_probability\": 0.0009892152886431212, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11100, \"tn\": 4915, \"fp\": 2103, \"fn\": 681, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9421950598421187, \"tn_rate\": 0.7003419777714448, \"fp_rate\": 0.29965802222855514, \"fn_rate\": 0.05780494015788133, \"precision\": 0.840718018632129, \"recall\": 0.9421950598421187, \"specificity\": 0.7003419777714448, \"npv\": 0.8783059328091494, \"accuracy\": 0.8519070163306559, \"f1\": 0.8885686839577329, \"f2\": 0.919986075886419, \"f0_5\": 0.859226231944638, \"p4\": 0.8303509705958364, \"phi\": 0.6797054654276938}, {\"truth_threshold\": -9.94, \"match_probability\": 0.0010169976324515963, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11099, \"tn\": 4917, \"fp\": 2101, \"fn\": 682, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.942110177404295, \"tn_rate\": 0.700626959247649, \"fp_rate\": 0.2993730407523511, \"fn_rate\": 0.05788982259570495, \"precision\": 0.8408333333333333, \"recall\": 0.942110177404295, \"specificity\": 0.700626959247649, \"npv\": 0.8781925343811395, \"accuracy\": 0.8519602106495027, \"f1\": 0.888595332452664, \"f2\": 0.9199489423778264, \"f0_5\": 0.8593084653381026, \"p4\": 0.830437384347698, \"phi\": 0.6798122000916721}, {\"truth_threshold\": -9.92, \"match_probability\": 0.0010311797509390394, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11098, \"tn\": 4917, \"fp\": 2101, \"fn\": 683, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9420252949664715, \"tn_rate\": 0.700626959247649, \"fp_rate\": 0.2993730407523511, \"fn_rate\": 0.05797470503352856, \"precision\": 0.840821274338965, \"recall\": 0.9420252949664715, \"specificity\": 0.700626959247649, \"npv\": 0.8780357142857143, \"accuracy\": 0.8519070163306559, \"f1\": 0.888550840672538, \"f2\": 0.9198813056379822, \"f0_5\": 0.8592842652956935, \"p4\": 0.8303828943594967, \"phi\": 0.6796874753864636}, {\"truth_threshold\": -9.88, \"match_probability\": 0.0010601394258328775, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11097, \"tn\": 4918, \"fp\": 2100, \"fn\": 684, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9419404125286478, \"tn_rate\": 0.700769449985751, \"fp_rate\": 0.2992305500142491, \"fn_rate\": 0.058059587471352175, \"precision\": 0.8408729256649239, \"recall\": 0.9419404125286478, \"specificity\": 0.700769449985751, \"npv\": 0.8779007497322385, \"accuracy\": 0.8519070163306559, \"f1\": 0.8885419168868605, \"f2\": 0.9198289153031283, \"f0_5\": 0.859313292756586, \"p4\": 0.8303988439944892, \"phi\": 0.6796785490902881}, {\"truth_threshold\": -9.86, \"match_probability\": 0.00107492251294963, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11097, \"tn\": 4920, \"fp\": 2098, \"fn\": 684, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9419404125286478, \"tn_rate\": 0.701054431461955, \"fp_rate\": 0.29894556853804505, \"fn_rate\": 0.058059587471352175, \"precision\": 0.8410003789314134, \"recall\": 0.9419404125286478, \"specificity\": 0.701054431461955, \"npv\": 0.8779443254817987, \"accuracy\": 0.8520134049683494, \"f1\": 0.888613068545804, \"f2\": 0.9198594141149555, \"f0_5\": 0.8594197735474978, \"p4\": 0.8305396848157052, \"phi\": 0.6799100955656148}, {\"truth_threshold\": -9.84, \"match_probability\": 0.0010899115175312943, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11095, \"tn\": 4920, \"fp\": 2098, \"fn\": 686, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9417706476530006, \"tn_rate\": 0.701054431461955, \"fp_rate\": 0.29894556853804505, \"fn_rate\": 0.058229352346999406, \"precision\": 0.8409762752975063, \"recall\": 0.9417706476530006, \"specificity\": 0.701054431461955, \"npv\": 0.8776311095255084, \"accuracy\": 0.8519070163306559, \"f1\": 0.8885240650276287, \"f2\": 0.9197241242104216, \"f0_5\": 0.8593713692624665, \"p4\": 0.8304307187895915, \"phi\": 0.6796608337998047}, {\"truth_threshold\": -9.8, \"match_probability\": 0.0011205187665362995, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11092, \"tn\": 4922, \"fp\": 2096, \"fn\": 689, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9415160003395298, \"tn_rate\": 0.701339412938159, \"fp_rate\": 0.29866058706184095, \"fn_rate\": 0.05848399966047025, \"precision\": 0.8410676372459812, \"recall\": 0.9415160003395298, \"specificity\": 0.701339412938159, \"npv\": 0.8772054892176082, \"accuracy\": 0.8518538220118091, \"f1\": 0.8884616924986984, \"f2\": 0.9195516646770129, \"f0_5\": 0.8594052655230657, \"p4\": 0.830408089282322, \"phi\": 0.6795187764580228}, {\"truth_threshold\": -9.78, \"match_probability\": 0.0011361428542256968, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11088, \"tn\": 4924, \"fp\": 2094, \"fn\": 693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9411764705882353, \"tn_rate\": 0.7016243944143631, \"fp_rate\": 0.2983756055856369, \"fn_rate\": 0.058823529411764705, \"precision\": 0.8411470186618115, \"recall\": 0.9411764705882353, \"specificity\": 0.7016243944143631, \"npv\": 0.8766245326686843, \"accuracy\": 0.8517474333741156, \"f1\": 0.8883547650522774, \"f2\": 0.9193115112924087, \"f0_5\": 0.8594149653536716, \"p4\": 0.830330983943665, \"phi\": 0.679252658492773}, {\"truth_threshold\": -9.76, \"match_probability\": 0.0011519845470053095, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11085, \"tn\": 4929, \"fp\": 2089, \"fn\": 696, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9409218232747645, \"tn_rate\": 0.7023368481048732, \"fp_rate\": 0.2976631518951268, \"fn_rate\": 0.05907817672523555, \"precision\": 0.8414300895703659, \"recall\": 0.9409218232747645, \"specificity\": 0.7023368481048732, \"npv\": 0.8762666666666666, \"accuracy\": 0.8518538220118091, \"f1\": 0.8883991184131437, \"f2\": 0.9191847159109755, \"f0_5\": 0.8596088527692045, \"p4\": 0.8305193010016878, \"phi\": 0.6794590950679145}, {\"truth_threshold\": -9.74, \"match_probability\": 0.0011680468685233154, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11081, \"tn\": 4929, \"fp\": 2089, \"fn\": 700, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.94058229352347, \"tn_rate\": 0.7023368481048732, \"fp_rate\": 0.2976631518951268, \"fn_rate\": 0.059417706476530004, \"precision\": 0.8413819286256644, \"recall\": 0.94058229352347, \"specificity\": 0.7023368481048732, \"npv\": 0.87564398649849, \"accuracy\": 0.8516410447364221, \"f1\": 0.8882209129894594, \"f2\": 0.9189139881248549, \"f0_5\": 0.8595119529638076, \"p4\": 0.8303015321781461, \"phi\": 0.6789622124072139}, {\"truth_threshold\": -9.72, \"match_probability\": 0.0011843328842437272, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11077, \"tn\": 4929, \"fp\": 2089, \"fn\": 704, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9402427637721755, \"tn_rate\": 0.7023368481048732, \"fp_rate\": 0.2976631518951268, \"fn_rate\": 0.059757236227824466, \"precision\": 0.841333738417135, \"recall\": 0.9402427637721755, \"specificity\": 0.7023368481048732, \"npv\": 0.8750221906621694, \"accuracy\": 0.8514282674610352, \"f1\": 0.8880426504188881, \"f2\": 0.918643224415326, \"f0_5\": 0.85941500504306, \"p4\": 0.830083821334252, \"phi\": 0.6784657064830927}, {\"truth_threshold\": -9.68, \"match_probability\": 0.0012175884726710806, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11075, \"tn\": 4931, \"fp\": 2087, \"fn\": 706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9400729988965283, \"tn_rate\": 0.7026218295810772, \"fp_rate\": 0.2973781704189228, \"fn_rate\": 0.05992700110347169, \"precision\": 0.8414374715088893, \"recall\": 0.9400729988965283, \"specificity\": 0.7026218295810772, \"npv\": 0.8747560759269115, \"accuracy\": 0.8514282674610352, \"f1\": 0.8880246963075813, \"f2\": 0.9185383007663471, \"f0_5\": 0.8594732185816946, \"p4\": 0.8301155693879375, \"phi\": 0.6784496216566266}, {\"truth_threshold\": -9.66, \"match_probability\": 0.001234564390578344, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11075, \"tn\": 4932, \"fp\": 2086, \"fn\": 706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9400729988965283, \"tn_rate\": 0.7027643203191792, \"fp_rate\": 0.29723567968082076, \"fn_rate\": 0.05992700110347169, \"precision\": 0.8415014056682623, \"recall\": 0.9400729988965283, \"specificity\": 0.7027643203191792, \"npv\": 0.8747782901738205, \"accuracy\": 0.8514814617798819, \"f1\": 0.8880602998957582, \"f2\": 0.9185535373641868, \"f0_5\": 0.8595265812960807, \"p4\": 0.8301858448175513, \"phi\": 0.67856563388059}, {\"truth_threshold\": -9.64, \"match_probability\": 0.001251776694272957, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11074, \"tn\": 4932, \"fp\": 2086, \"fn\": 707, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9399881164587047, \"tn_rate\": 0.7027643203191792, \"fp_rate\": 0.29723567968082076, \"fn_rate\": 0.06001188354129531, \"precision\": 0.8414893617021276, \"recall\": 0.9399881164587047, \"specificity\": 0.7027643203191792, \"npv\": 0.8746231601347757, \"accuracy\": 0.8514282674610352, \"f1\": 0.888015717092338, \"f2\": 0.9184858337203902, \"f0_5\": 0.8595023361947192, \"p4\": 0.8301314312206403, \"phi\": 0.6784416470248751}, {\"truth_threshold\": -9.620000000000001, \"match_probability\": 0.0012692286670443176, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11073, \"tn\": 4941, \"fp\": 2077, \"fn\": 708, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.939903234020881, \"tn_rate\": 0.7040467369620975, \"fp_rate\": 0.29595326303790254, \"fn_rate\": 0.06009676597911892, \"precision\": 0.8420532319391635, \"recall\": 0.939903234020881, \"specificity\": 0.7040467369620975, \"npv\": 0.8746680828465215, \"accuracy\": 0.8518538220118091, \"f1\": 0.8882916850507401, \"f2\": 0.9185552642930617, \"f0_5\": 0.8599586834625123, \"p4\": 0.8307090246530517, \"phi\": 0.6793619579128082}, {\"truth_threshold\": -9.6, \"match_probability\": 0.0012869236375513526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11071, \"tn\": 4945, \"fp\": 2073, \"fn\": 710, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9397334691452338, \"tn_rate\": 0.7046166999145056, \"fp_rate\": 0.29538330008549446, \"fn_rate\": 0.060266530854766145, \"precision\": 0.8422854534388314, \"recall\": 0.9397334691452338, \"specificity\": 0.7046166999145056, \"npv\": 0.874447391688771, \"accuracy\": 0.8519602106495027, \"f1\": 0.8883450351053159, \"f2\": 0.9184807858233225, \"f0_5\": 0.8601239958357288, \"p4\": 0.8308808206233774, \"phi\": 0.6795784943099941}, {\"truth_threshold\": -9.58, \"match_probability\": 0.0013048649804428731, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11067, \"tn\": 4953, \"fp\": 2065, \"fn\": 714, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9393939393939394, \"tn_rate\": 0.7057566258193217, \"fp_rate\": 0.29424337418067825, \"fn_rate\": 0.06060606060606061, \"precision\": 0.8427505330490405, \"recall\": 0.9393939393939394, \"specificity\": 0.7057566258193217, \"npv\": 0.8740074113287454, \"accuracy\": 0.8521729879248896, \"f1\": 0.8884518123068278, \"f2\": 0.9183317843866171, \"f0_5\": 0.8604549907477957, \"p4\": 0.83122393101643, \"phi\": 0.6800123476352644}, {\"truth_threshold\": -9.540000000000001, \"match_probability\": 0.001341500515704429, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11065, \"tn\": 4958, \"fp\": 2060, \"fn\": 716, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9392241745182922, \"tn_rate\": 0.7064690795098318, \"fp_rate\": 0.29353092049016816, \"fn_rate\": 0.06077582548170783, \"precision\": 0.843047619047619, \"recall\": 0.9392241745182922, \"specificity\": 0.7064690795098318, \"npv\": 0.8738103630595699, \"accuracy\": 0.8523325708814299, \"f1\": 0.8885409138360234, \"f2\": 0.9182725024481734, \"f0_5\": 0.8606742272211073, \"p4\": 0.8314652485611145, \"phi\": 0.6803457673439481}, {\"truth_threshold\": -9.5, \"match_probability\": 0.0013791632139172336, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11064, \"tn\": 4958, \"fp\": 2060, \"fn\": 717, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9391392920804685, \"tn_rate\": 0.7064690795098318, \"fp_rate\": 0.29353092049016816, \"fn_rate\": 0.06086070791953145, \"precision\": 0.8430356598597989, \"recall\": 0.9391392920804685, \"specificity\": 0.7064690795098318, \"npv\": 0.8736563876651983, \"accuracy\": 0.8522793765625831, \"f1\": 0.8884962858863682, \"f2\": 0.9182047536847696, \"f0_5\": 0.8606499992221168, \"p4\": 0.8314108522378068, \"phi\": 0.6802223061134731}, {\"truth_threshold\": -9.48, \"match_probability\": 0.0013983886925891824, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11057, \"tn\": 4958, \"fp\": 2060, \"fn\": 724, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9385451150157033, \"tn_rate\": 0.7064690795098318, \"fp_rate\": 0.29353092049016816, \"fn_rate\": 0.06145488498429675, \"precision\": 0.842951894488069, \"recall\": 0.9385451150157033, \"specificity\": 0.7064690795098318, \"npv\": 0.872580077437522, \"accuracy\": 0.8519070163306559, \"f1\": 0.8881837898626396, \"f2\": 0.9177304493617304, \"f0_5\": 0.860480318759825, \"p4\": 0.8310301783105462, \"phi\": 0.6793587259532718}, {\"truth_threshold\": -9.46, \"match_probability\": 0.0014178817931252896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11056, \"tn\": 4966, \"fp\": 2052, \"fn\": 725, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9384602325778796, \"tn_rate\": 0.707609005414648, \"fp_rate\": 0.29239099458535195, \"fn_rate\": 0.06153976742212036, \"precision\": 0.8434543790051877, \"recall\": 0.9384602325778796, \"specificity\": 0.707609005414648, \"npv\": 0.872605868915832, \"accuracy\": 0.8522793765625831, \"f1\": 0.888424605247298, \"f2\": 0.9177845663434719, \"f0_5\": 0.8608848675501846, \"p4\": 0.8315354135075759, \"phi\": 0.6801650525652385}, {\"truth_threshold\": -9.44, \"match_probability\": 0.0014376462301841668, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11052, \"tn\": 5088, \"fp\": 1930, \"fn\": 729, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9381207028265852, \"tn_rate\": 0.7249928754630949, \"fp_rate\": 0.2750071245369051, \"fn_rate\": 0.061879297173414824, \"precision\": 0.8513326143891542, \"recall\": 0.9381207028265852, \"specificity\": 0.7249928754630949, \"npv\": 0.8746776689014956, \"accuracy\": 0.8585563061864993, \"f1\": 0.8926220571013205, \"f2\": 0.9193757694739294, \"f0_5\": 0.8673813746880347, \"p4\": 0.8397729679295046, \"phi\": 0.6938496067794282}, {\"truth_threshold\": -9.42, \"match_probability\": 0.0014576857696849406, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11050, \"tn\": 5094, \"fp\": 1924, \"fn\": 731, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.937950937950938, \"tn_rate\": 0.725847819891707, \"fp_rate\": 0.27415218010829295, \"fn_rate\": 0.06204906204906205, \"precision\": 0.8517034068136272, \"recall\": 0.937950937950938, \"specificity\": 0.725847819891707, \"npv\": 0.8745064377682403, \"accuracy\": 0.8587690834618863, \"f1\": 0.8927489396081599, \"f2\": 0.9193317581283903, \"f0_5\": 0.8676602226863703, \"p4\": 0.8400761861779575, \"phi\": 0.6943033866880847}, {\"truth_threshold\": -9.4, \"match_probability\": 0.0014780042295062135, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11050, \"tn\": 5101, \"fp\": 1917, \"fn\": 731, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.937950937950938, \"tn_rate\": 0.7268452550584212, \"fp_rate\": 0.2731547449415788, \"fn_rate\": 0.06204906204906205, \"precision\": 0.8521631834657207, \"recall\": 0.937950937950938, \"specificity\": 0.7268452550584212, \"npv\": 0.8746570644718793, \"accuracy\": 0.8591414436938135, \"f1\": 0.8930014546630031, \"f2\": 0.9194388510758683, \"f0_5\": 0.8680419173906896, \"p4\": 0.8405565318578189, \"phi\": 0.6951167771180861}, {\"truth_threshold\": -9.38, \"match_probability\": 0.0014986054801942956, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11050, \"tn\": 5102, \"fp\": 1916, \"fn\": 731, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.937950937950938, \"tn_rate\": 0.7269877457965233, \"fp_rate\": 0.2730122542034768, \"fn_rate\": 0.06204906204906205, \"precision\": 0.8522289063705075, \"recall\": 0.937950937950938, \"specificity\": 0.7269877457965233, \"npv\": 0.8746785530601748, \"accuracy\": 0.8591946380126603, \"f1\": 0.8930375399038267, \"f2\": 0.9194541521051756, \"f0_5\": 0.8680964726215727, \"p4\": 0.8406251149060042, \"phi\": 0.6952329748221449}, {\"truth_threshold\": -9.36, \"match_probability\": 0.0015194934456808581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11047, \"tn\": 5102, \"fp\": 1916, \"fn\": 734, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9376962906374671, \"tn_rate\": 0.7269877457965233, \"fp_rate\": 0.2730122542034768, \"fn_rate\": 0.06230370936253289, \"precision\": 0.85219470801512, \"recall\": 0.9376962906374671, \"specificity\": 0.7269877457965233, \"npv\": 0.8742289239204935, \"accuracy\": 0.85903505505612, \"f1\": 0.8929033301002263, \"f2\": 0.9192504202240085, \"f0_5\": 0.8680244527210724, \"p4\": 0.840461799971642, \"phi\": 0.6948684708892777}, {\"truth_threshold\": -9.34, \"match_probability\": 0.0015406721040101049, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11045, \"tn\": 5102, \"fp\": 1916, \"fn\": 736, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9375265257618198, \"tn_rate\": 0.7269877457965233, \"fp_rate\": 0.2730122542034768, \"fn_rate\": 0.06247347423818012, \"precision\": 0.8521719003163336, \"recall\": 0.9375265257618198, \"specificity\": 0.7269877457965233, \"npv\": 0.8739294278862624, \"accuracy\": 0.8589286664184265, \"f1\": 0.8928138388165872, \"f2\": 0.9191145876674711, \"f0_5\": 0.8679764243614931, \"p4\": 0.8403529406624219, \"phi\": 0.6946255791346109}, {\"truth_threshold\": -9.32, \"match_probability\": 0.0015621454880756095, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11043, \"tn\": 5102, \"fp\": 1916, \"fn\": 738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9373567608861727, \"tn_rate\": 0.7269877457965233, \"fp_rate\": 0.2730122542034768, \"fn_rate\": 0.06264323911382735, \"precision\": 0.8521490855775908, \"recall\": 0.9373567608861727, \"specificity\": 0.7269877457965233, \"npv\": 0.8736301369863013, \"accuracy\": 0.8588222777807331, \"f1\": 0.8927243330638642, \"f2\": 0.9189787460679394, \"f0_5\": 0.8679283839225365, \"p4\": 0.8402440951952859, \"phi\": 0.6943827759778892}, {\"truth_threshold\": -9.3, \"match_probability\": 0.0015839176863668995, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11041, \"tn\": 5102, \"fp\": 1916, \"fn\": 740, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9371869960105255, \"tn_rate\": 0.7269877457965233, \"fp_rate\": 0.2730122542034768, \"fn_rate\": 0.06281300398947458, \"precision\": 0.8521262637956317, \"recall\": 0.9371869960105255, \"specificity\": 0.7269877457965233, \"npv\": 0.8733310510099281, \"accuracy\": 0.8587158891430395, \"f1\": 0.892634812838548, \"f2\": 0.9188428954245103, \"f0_5\": 0.8678803313996447, \"p4\": 0.8401352635626351, \"phi\": 0.6941400613370601}, {\"truth_threshold\": -9.26, \"match_probability\": 0.0016283751621136546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11035, \"tn\": 5110, \"fp\": 1908, \"fn\": 746, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9366777013835837, \"tn_rate\": 0.7281276717013394, \"fp_rate\": 0.2718723282986606, \"fn_rate\": 0.06332229861641626, \"precision\": 0.8525844085606119, \"recall\": 0.9366777013835837, \"specificity\": 0.7281276717013394, \"npv\": 0.8726092896174863, \"accuracy\": 0.8588222777807331, \"f1\": 0.8926549102087041, \"f2\": 0.9185576106680873, \"f0_5\": 0.8681730209431499, \"p4\": 0.8403570986940109, \"phi\": 0.6943433351564093}, {\"truth_threshold\": -9.24, \"match_probability\": 0.001651068901386505, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11034, \"tn\": 5110, \"fp\": 1908, \"fn\": 747, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9365928189457601, \"tn_rate\": 0.7281276717013394, \"fp_rate\": 0.2718723282986606, \"fn_rate\": 0.06340718105423988, \"precision\": 0.8525730180806675, \"recall\": 0.9365928189457601, \"specificity\": 0.7281276717013394, \"npv\": 0.8724603039098514, \"accuracy\": 0.8587690834618863, \"f1\": 0.892610120131052, \"f2\": 0.9184896613724902, \"f0_5\": 0.868148987395553, \"p4\": 0.8403027035147301, \"phi\": 0.6942222306502682}, {\"truth_threshold\": -9.22, \"match_probability\": 0.0016740783800834494, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11033, \"tn\": 5113, \"fp\": 1905, \"fn\": 748, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9365079365079365, \"tn_rate\": 0.7285551439156455, \"fp_rate\": 0.27144485608435454, \"fn_rate\": 0.06349206349206349, \"precision\": 0.852759313649714, \"recall\": 0.9365079365079365, \"specificity\": 0.7285551439156455, \"npv\": 0.8723767275209009, \"accuracy\": 0.8588754720995798, \"f1\": 0.8926736518467575, \"f2\": 0.918467583497053, \"f0_5\": 0.8682889207183668, \"p4\": 0.8404537455946716, \"phi\": 0.6944502928699005}, {\"truth_threshold\": -9.200000000000001, \"match_probability\": 0.0016974079762232014, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11032, \"tn\": 5119, \"fp\": 1899, \"fn\": 749, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.936423054070113, \"tn_rate\": 0.7294100883442576, \"fp_rate\": 0.27058991165574237, \"fn_rate\": 0.06357694592988711, \"precision\": 0.8531436083829557, \"recall\": 0.936423054070113, \"specificity\": 0.7294100883442576, \"npv\": 0.8723585548738922, \"accuracy\": 0.8591414436938135, \"f1\": 0.8928455810942052, \"f2\": 0.9184913828990092, \"f0_5\": 0.8685930241713251, \"p4\": 0.8408099662963188, \"phi\": 0.6950276146957981}, {\"truth_threshold\": -9.18, \"match_probability\": 0.0017210621281120474, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11030, \"tn\": 5119, \"fp\": 1899, \"fn\": 751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9362532891944657, \"tn_rate\": 0.7294100883442576, \"fp_rate\": 0.27058991165574237, \"fn_rate\": 0.06374671080553433, \"precision\": 0.8531208910201872, \"recall\": 0.9362532891944657, \"specificity\": 0.7294100883442576, \"npv\": 0.8720613287904599, \"accuracy\": 0.85903505505612, \"f1\": 0.8927559692432213, \"f2\": 0.918355452683463, \"f0_5\": 0.8685449706285336, \"p4\": 0.8407011882180779, \"phi\": 0.6947857553017219}, {\"truth_threshold\": -9.14, \"match_probability\": 0.001769362158721538, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11029, \"tn\": 5122, \"fp\": 1896, \"fn\": 752, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.936168406756642, \"tn_rate\": 0.7298375605585637, \"fp_rate\": 0.2701624394414363, \"fn_rate\": 0.06383159324335795, \"precision\": 0.8533075435203095, \"recall\": 0.936168406756642, \"specificity\": 0.7298375605585637, \"npv\": 0.8719782090568607, \"accuracy\": 0.8591414436938135, \"f1\": 0.8928195580021048, \"f2\": 0.9183333610884444, \"f0_5\": 0.868685118381878, \"p4\": 0.8408519778216054, \"phi\": 0.6950141287953039}, {\"truth_threshold\": -9.120000000000001, \"match_probability\": 0.001794017222912777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11025, \"tn\": 5122, \"fp\": 1896, \"fn\": 756, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9358288770053476, \"tn_rate\": 0.7298375605585637, \"fp_rate\": 0.2701624394414363, \"fn_rate\": 0.06417112299465241, \"precision\": 0.8532621314139772, \"recall\": 0.9358288770053476, \"specificity\": 0.7298375605585637, \"npv\": 0.8713848247703301, \"accuracy\": 0.8589286664184265, \"f1\": 0.8926402720427495, \"f2\": 0.9180614539095678, \"f0_5\": 0.8685889860553061, \"p4\": 0.8406344687128617, \"phi\": 0.6945308904683359}, {\"truth_threshold\": -9.1, \"match_probability\": 0.0018190152154856484, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11022, \"tn\": 5129, \"fp\": 1889, \"fn\": 759, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9355742296918768, \"tn_rate\": 0.7308349957252779, \"fp_rate\": 0.2691650042747221, \"fn_rate\": 0.06442577030812324, \"precision\": 0.853690651382542, \"recall\": 0.9355742296918768, \"specificity\": 0.7308349957252779, \"npv\": 0.87109375, \"accuracy\": 0.8591414436938135, \"f1\": 0.8927587882715049, \"f2\": 0.9179645206962606, \"f0_5\": 0.8689002759164367, \"p4\": 0.8409497529148903, \"phi\": 0.6949841807694445}, {\"truth_threshold\": -9.08, \"match_probability\": 0.0018443608886787883, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11017, \"tn\": 5131, \"fp\": 1887, \"fn\": 764, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9351498175027587, \"tn_rate\": 0.7311199772014819, \"fp_rate\": 0.2688800227985181, \"fn_rate\": 0.06485018249724132, \"precision\": 0.8537662740235585, \"recall\": 0.9351498175027587, \"specificity\": 0.7311199772014819, \"npv\": 0.8703986429177268, \"accuracy\": 0.8589818607372732, \"f1\": 0.8926068462629126, \"f2\": 0.9176550942893317, \"f0_5\": 0.8688896950959825, \"p4\": 0.8408145617169065, \"phi\": 0.69461443300761}, {\"truth_threshold\": -9.06, \"match_probability\": 0.0018700590600935494, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11015, \"tn\": 5133, \"fp\": 1885, \"fn\": 766, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9349800526271115, \"tn_rate\": 0.731404958677686, \"fp_rate\": 0.26859504132231404, \"fn_rate\": 0.06501994737288855, \"precision\": 0.853875968992248, \"recall\": 0.9349800526271115, \"specificity\": 0.731404958677686, \"npv\": 0.8701474826241736, \"accuracy\": 0.8589818607372732, \"f1\": 0.892589441270613, \"f2\": 0.9175496468079435, \"f0_5\": 0.8689512629967971, \"p4\": 0.8408424206734111, \"phi\": 0.6946066339953482}, {\"truth_threshold\": -9.040000000000001, \"match_probability\": 0.0018961146135791532, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11015, \"tn\": 5134, \"fp\": 1884, \"fn\": 766, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9349800526271115, \"tn_rate\": 0.731547449415788, \"fp_rate\": 0.268452550584212, \"fn_rate\": 0.06501994737288855, \"precision\": 0.8539421660593844, \"recall\": 0.9349800526271115, \"specificity\": 0.731547449415788, \"npv\": 0.8701694915254238, \"accuracy\": 0.85903505505612, \"f1\": 0.8926256077795786, \"f2\": 0.9175649334421805, \"f0_5\": 0.8690061063161715, \"p4\": 0.8409106818247466, \"phi\": 0.6947232069897661}, {\"truth_threshold\": -9.02, \"match_probability\": 0.001922532500129454, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11014, \"tn\": 5134, \"fp\": 1884, \"fn\": 767, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9348951701892878, \"tn_rate\": 0.731547449415788, \"fp_rate\": 0.268452550584212, \"fn_rate\": 0.06510482981071217, \"precision\": 0.8539308419910063, \"recall\": 0.9348951701892878, \"specificity\": 0.731547449415788, \"npv\": 0.870022030164379, \"accuracy\": 0.8589818607372732, \"f1\": 0.8925807366586976, \"f2\": 0.9174969177968079, \"f0_5\": 0.8689820586053998, \"p4\": 0.8408563393957376, \"phi\": 0.694602799152043}, {\"truth_threshold\": -9.0, \"match_probability\": 0.001949317738791423, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11013, \"tn\": 5135, \"fp\": 1883, \"fn\": 768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9348102877514642, \"tn_rate\": 0.73168994015389, \"fp_rate\": 0.26831005984611, \"fn_rate\": 0.06518971224853577, \"precision\": 0.8539857320099256, \"recall\": 0.9348102877514642, \"specificity\": 0.73168994015389, \"npv\": 0.8698966627138743, \"accuracy\": 0.8589818607372732, \"f1\": 0.8925720306358147, \"f2\": 0.9174441852715761, \"f0_5\": 0.8690128619900576, \"p4\": 0.840870250951611, \"phi\": 0.6945990073848984}, {\"truth_threshold\": -8.98, \"match_probability\": 0.001976475417585539, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11007, \"tn\": 5137, \"fp\": 1881, \"fn\": 774, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9343009931245225, \"tn_rate\": 0.731974921630094, \"fp_rate\": 0.26802507836990597, \"fn_rate\": 0.06569900687547746, \"precision\": 0.854050279329609, \"recall\": 0.9343009931245225, \"specificity\": 0.731974921630094, \"npv\": 0.8690576890543056, \"accuracy\": 0.8587690834618863, \"f1\": 0.8923750456037942, \"f2\": 0.9170665866826635, \"f0_5\": 0.8689782577803041, \"p4\": 0.8406807498450123, \"phi\": 0.6941105265743669}, {\"truth_threshold\": -8.96, \"match_probability\": 0.0020040106944381785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11006, \"tn\": 5147, \"fp\": 1871, \"fn\": 775, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.934216110686699, \"tn_rate\": 0.7333998290111142, \"fp_rate\": 0.2666001709888857, \"fn_rate\": 0.06578388931330108, \"precision\": 0.8547021821852916, \"recall\": 0.934216110686699, \"specificity\": 0.7333998290111142, \"npv\": 0.8691320499831138, \"accuracy\": 0.859247832331507, \"f1\": 0.8926920269283802, \"f2\": 0.9171513808103199, \"f0_5\": 0.8695033892145555, \"p4\": 0.8413081998470247, \"phi\": 0.6951570118286624}, {\"truth_threshold\": -8.94, \"match_probability\": 0.002031928798126188, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11003, \"tn\": 5147, \"fp\": 1871, \"fn\": 778, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.933961463373228, \"tn_rate\": 0.7333998290111142, \"fp_rate\": 0.2666001709888857, \"fn_rate\": 0.06603853662677192, \"precision\": 0.8546683237533013, \"recall\": 0.933961463373228, \"specificity\": 0.7333998290111142, \"npv\": 0.8686919831223628, \"accuracy\": 0.8590882493749668, \"f1\": 0.8925572906104239, \"f2\": 0.9169472315743858, \"f0_5\": 0.8694312309369914, \"p4\": 0.8411452488366299, \"phi\": 0.694796854667663}, {\"truth_threshold\": -8.92, \"match_probability\": 0.0020602350292337574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11003, \"tn\": 5163, \"fp\": 1855, \"fn\": 778, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.933961463373228, \"tn_rate\": 0.7356796808207466, \"fp_rate\": 0.26432031917925336, \"fn_rate\": 0.06603853662677192, \"precision\": 0.855731840099549, \"recall\": 0.933961463373228, \"specificity\": 0.7356796808207466, \"npv\": 0.8690456152162935, \"accuracy\": 0.8599393584765147, \"f1\": 0.8931368967896425, \"f2\": 0.9171918242139309, \"f0_5\": 0.8703114865613086, \"p4\": 0.8422341349079849, \"phi\": 0.6966640542353956}, {\"truth_threshold\": -8.9, \"match_probability\": 0.0020889347611217834, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10993, \"tn\": 5166, \"fp\": 1852, \"fn\": 788, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.933112638994992, \"tn_rate\": 0.7361071530350527, \"fp_rate\": 0.2638928469649473, \"fn_rate\": 0.06688736100500807, \"precision\": 0.8558193849746983, \"recall\": 0.933112638994992, \"specificity\": 0.7361071530350527, \"npv\": 0.8676519986563654, \"accuracy\": 0.8595669982445875, \"f1\": 0.8927962316251117, \"f2\": 0.9165568877253247, \"f0_5\": 0.8702363800446478, \"p4\": 0.8418949655426929, \"phi\": 0.6958170513096594}, {\"truth_threshold\": -8.88, \"match_probability\": 0.002118033440909814, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10989, \"tn\": 5167, \"fp\": 1851, \"fn\": 792, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9327731092436975, \"tn_rate\": 0.7362496437731547, \"fp_rate\": 0.26375035622684523, \"fn_rate\": 0.06722689075630252, \"precision\": 0.8558411214953271, \"recall\": 0.9327731092436975, \"specificity\": 0.7362496437731547, \"npv\": 0.8670917939251552, \"accuracy\": 0.8594074152880472, \"f1\": 0.8926526136225174, \"f2\": 0.9162997798679208, \"f0_5\": 0.8701952772366608, \"p4\": 0.8417457709734633, \"phi\": 0.6954556558984263}, {\"truth_threshold\": -8.86, \"match_probability\": 0.0021475365904707793, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10985, \"tn\": 5169, \"fp\": 1849, \"fn\": 796, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.932433579492403, \"tn_rate\": 0.7365346252493588, \"fp_rate\": 0.2634653747506412, \"fn_rate\": 0.06756642050759698, \"precision\": 0.8559295621006701, \"recall\": 0.932433579492403, \"specificity\": 0.7365346252493588, \"npv\": 0.8665549036043587, \"accuracy\": 0.8593010266503538, \"f1\": 0.8925451960186878, \"f2\": 0.9160579072017079, \"f0_5\": 0.8702092938511019, \"p4\": 0.8416645361872506, \"phi\": 0.6952115764114578}, {\"truth_threshold\": -8.84, \"match_probability\": 0.0021774498074386152, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10985, \"tn\": 5176, \"fp\": 1842, \"fn\": 796, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.932433579492403, \"tn_rate\": 0.737532060416073, \"fp_rate\": 0.26246793958392706, \"fn_rate\": 0.06756642050759698, \"precision\": 0.856396663288376, \"recall\": 0.932433579492403, \"specificity\": 0.737532060416073, \"npv\": 0.8667113194909578, \"accuracy\": 0.859673386882281, \"f1\": 0.8927990897269181, \"f2\": 0.9161648679755133, \"f0_5\": 0.8705955079332371, \"p4\": 0.8421397248891881, \"phi\": 0.6960298143080392}, {\"truth_threshold\": -8.82, \"match_probability\": 0.002207778766228983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10984, \"tn\": 5176, \"fp\": 1842, \"fn\": 797, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9323486970545795, \"tn_rate\": 0.737532060416073, \"fp_rate\": 0.26246793958392706, \"fn_rate\": 0.0676513029454206, \"precision\": 0.8563854670201154, \"recall\": 0.9323486970545795, \"specificity\": 0.737532060416073, \"npv\": 0.8665662146325129, \"accuracy\": 0.8596201925634342, \"f1\": 0.8927540943633925, \"f2\": 0.9160967472894078, \"f0_5\": 0.8705714512166125, \"p4\": 0.8420854561782831, \"phi\": 0.6959104972050246}, {\"truth_threshold\": -8.8, \"match_probability\": 0.002238529219073188, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10983, \"tn\": 5177, \"fp\": 1841, \"fn\": 798, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9322638146167558, \"tn_rate\": 0.737674551154175, \"fp_rate\": 0.26232544884582504, \"fn_rate\": 0.0677361853832442, \"precision\": 0.8564410480349345, \"recall\": 0.9322638146167558, \"specificity\": 0.737674551154175, \"npv\": 0.8664435146443514, \"accuracy\": 0.8596201925634342, \"f1\": 0.8927453769559033, \"f2\": 0.9160439047174218, \"f0_5\": 0.8706025968261014, \"p4\": 0.8420990373730807, \"phi\": 0.6959081135914388}, {\"truth_threshold\": -8.78, \"match_probability\": 0.0022697069970654916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10982, \"tn\": 5178, \"fp\": 1840, \"fn\": 799, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9321789321789322, \"tn_rate\": 0.737817041892277, \"fp_rate\": 0.262182958107723, \"fn_rate\": 0.06782106782106782, \"precision\": 0.8564966463890189, \"recall\": 0.9321789321789322, \"specificity\": 0.737817041892277, \"npv\": 0.8663208967709554, \"accuracy\": 0.8596201925634342, \"f1\": 0.8927366581311222, \"f2\": 0.9159910586194242, \"f0_5\": 0.8706337503369326, \"p4\": 0.8421126115557013, \"phi\": 0.6959057722890543}, {\"truth_threshold\": -8.76, \"match_probability\": 0.002301318011223944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10982, \"tn\": 5179, \"fp\": 1839, \"fn\": 799, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9321789321789322, \"tn_rate\": 0.7379595326303791, \"fp_rate\": 0.262040467369621, \"fn_rate\": 0.06782106782106782, \"precision\": 0.8565634505888776, \"recall\": 0.9321789321789322, \"specificity\": 0.7379595326303791, \"npv\": 0.8663432586149213, \"accuracy\": 0.859673386882281, \"f1\": 0.8927729452890009, \"f2\": 0.9160063391442155, \"f0_5\": 0.8706889716958693, \"p4\": 0.8421804393737773, \"phi\": 0.6960226952522346}, {\"truth_threshold\": -8.74, \"match_probability\": 0.002333368253564943, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10979, \"tn\": 5179, \"fp\": 1839, \"fn\": 802, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9319242848654613, \"tn_rate\": 0.7379595326303791, \"fp_rate\": 0.262040467369621, \"fn_rate\": 0.06807571513453867, \"precision\": 0.8565298798564519, \"recall\": 0.9319242848654613, \"specificity\": 0.7379595326303791, \"npv\": 0.8659087109179067, \"accuracy\": 0.8595138039257407, \"f1\": 0.8926379121102483, \"f2\": 0.9158019418771479, \"f0_5\": 0.8706167827066119, \"p4\": 0.8420176674727132, \"phi\": 0.6956650926230542}, {\"truth_threshold\": -8.72, \"match_probability\": 0.0023658637981916145, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10977, \"tn\": 5179, \"fp\": 1839, \"fn\": 804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9317545199898141, \"tn_rate\": 0.7379595326303791, \"fp_rate\": 0.262040467369621, \"fn_rate\": 0.06824548001018589, \"precision\": 0.8565074906367042, \"recall\": 0.9317545199898141, \"specificity\": 0.7379595326303791, \"npv\": 0.8656192545545713, \"accuracy\": 0.8594074152880472, \"f1\": 0.8925478716916697, \"f2\": 0.9156656656656657, \"f0_5\": 0.8705686414465857, \"p4\": 0.8419091695870683, \"phi\": 0.6954267963110702}, {\"truth_threshold\": -8.700000000000001, \"match_probability\": 0.002398810802396238, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10977, \"tn\": 5181, \"fp\": 1837, \"fn\": 804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9317545199898141, \"tn_rate\": 0.7382445141065831, \"fp_rate\": 0.2617554858934169, \"fn_rate\": 0.06824548001018589, \"precision\": 0.8566411737162478, \"recall\": 0.9317545199898141, \"specificity\": 0.7382445141065831, \"npv\": 0.8656641604010025, \"accuracy\": 0.8595138039257407, \"f1\": 0.8926204513112421, \"f2\": 0.915696219426741, \"f0_5\": 0.8706791249583578, \"p4\": 0.8420447915307985, \"phi\": 0.6956607479089453}, {\"truth_threshold\": -8.68, \"match_probability\": 0.00243221550777684, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10976, \"tn\": 5181, \"fp\": 1837, \"fn\": 805, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9316696375519905, \"tn_rate\": 0.7382445141065831, \"fp_rate\": 0.2617554858934169, \"fn_rate\": 0.06833036244800951, \"precision\": 0.8566299851713104, \"recall\": 0.9316696375519905, \"specificity\": 0.7382445141065831, \"npv\": 0.865519545606415, \"accuracy\": 0.859460609606894, \"f1\": 0.8925754249003822, \"f2\": 0.9156280761466207, \"f0_5\": 0.8706550537020291, \"p4\": 0.84199054627545, \"phi\": 0.6955416524418915}, {\"truth_threshold\": -8.66, \"match_probability\": 0.0024660842413681285, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10971, \"tn\": 5183, \"fp\": 1835, \"fn\": 810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9312452253628725, \"tn_rate\": 0.7385294955827871, \"fp_rate\": 0.26147050441721287, \"fn_rate\": 0.06875477463712758, \"precision\": 0.8567077932219272, \"recall\": 0.9312452253628725, \"specificity\": 0.7385294955827871, \"npv\": 0.8648423160353746, \"accuracy\": 0.8593010266503538, \"f1\": 0.892422825070159, \"f2\": 0.9153178708493243, \"f0_5\": 0.8706451868899294, \"p4\": 0.8418549479631773, \"phi\": 0.695180568684223}, {\"truth_threshold\": -8.620000000000001, \"match_probability\": 0.0025352395353924907, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10967, \"tn\": 5183, \"fp\": 1835, \"fn\": 814, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.930905695611578, \"tn_rate\": 0.7385294955827871, \"fp_rate\": 0.26147050441721287, \"fn_rate\": 0.06909430438842204, \"precision\": 0.8566630214029058, \"recall\": 0.930905695611578, \"specificity\": 0.7385294955827871, \"npv\": 0.8642654660663666, \"accuracy\": 0.8590882493749668, \"f1\": 0.8922426066794126, \"f2\": 0.9150452224410106, \"f0_5\": 0.8705488259854895, \"p4\": 0.8416380616704708, \"phi\": 0.6947049012684858}, {\"truth_threshold\": -8.6, \"match_probability\": 0.0025705391874611093, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10966, \"tn\": 5183, \"fp\": 1835, \"fn\": 815, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9308208131737543, \"tn_rate\": 0.7385294955827871, \"fp_rate\": 0.26147050441721287, \"fn_rate\": 0.06917918682624564, \"precision\": 0.8566518240762441, \"recall\": 0.9308208131737543, \"specificity\": 0.7385294955827871, \"npv\": 0.8641213737912637, \"accuracy\": 0.85903505505612, \"f1\": 0.892197542917582, \"f2\": 0.9149770546516479, \"f0_5\": 0.8705247281098675, \"p4\": 0.8415838484211497, \"phi\": 0.6945860368133354}, {\"truth_threshold\": -8.58, \"match_probability\": 0.0026063290533764843, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10966, \"tn\": 5184, \"fp\": 1834, \"fn\": 815, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9308208131737543, \"tn_rate\": 0.7386719863208892, \"fp_rate\": 0.26132801367911085, \"fn_rate\": 0.06917918682624564, \"precision\": 0.85671875, \"recall\": 0.9308208131737543, \"specificity\": 0.7386719863208892, \"npv\": 0.8641440240040007, \"accuracy\": 0.8590882493749668, \"f1\": 0.8922338391440543, \"f2\": 0.9149923236099059, \"f0_5\": 0.8705800161953605, \"p4\": 0.8416516205290396, \"phi\": 0.6947031284076767}, {\"truth_threshold\": -8.56, \"match_probability\": 0.0026426159048347467, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10965, \"tn\": 5187, \"fp\": 1831, \"fn\": 816, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9307359307359307, \"tn_rate\": 0.7390994585351952, \"fp_rate\": 0.2609005414648048, \"fn_rate\": 0.06926406926406926, \"precision\": 0.8569084088777743, \"recall\": 0.9307359307359307, \"specificity\": 0.7390994585351952, \"npv\": 0.8640679660169915, \"accuracy\": 0.8591946380126603, \"f1\": 0.8922976766895878, \"f2\": 0.9149699599465955, \"f0_5\": 0.8707218295878663, \"p4\": 0.8418006702707436, \"phi\": 0.694935601860288}, {\"truth_threshold\": -8.52, \"match_probability\": 0.0027167081150656154, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10963, \"tn\": 5187, \"fp\": 1831, \"fn\": 818, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9305661658602835, \"tn_rate\": 0.7390994585351952, \"fp_rate\": 0.2609005414648048, \"fn_rate\": 0.06943383413971649, \"precision\": 0.8568860403314054, \"recall\": 0.9305661658602835, \"specificity\": 0.7390994585351952, \"npv\": 0.8637801831806827, \"accuracy\": 0.8590882493749668, \"f1\": 0.8922075279755849, \"f2\": 0.9148336059281017, \"f0_5\": 0.8706736343853742, \"p4\": 0.8416922550590772, \"phi\": 0.6946980614259365}, {\"truth_threshold\": -8.5, \"match_probability\": 0.0027545274848556306, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10962, \"tn\": 5187, \"fp\": 1831, \"fn\": 819, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.93048128342246, \"tn_rate\": 0.7390994585351952, \"fp_rate\": 0.2609005414648048, \"fn_rate\": 0.06951871657754011, \"precision\": 0.8568748534354725, \"recall\": 0.93048128342246, \"specificity\": 0.7390994585351952, \"npv\": 0.8636363636363636, \"accuracy\": 0.85903505505612, \"f1\": 0.8921624481158948, \"f2\": 0.9147654255052823, \"f0_5\": 0.870649532190682, \"p4\": 0.8416380524367387, \"phi\": 0.6945793225512642}, {\"truth_threshold\": -8.48, \"match_probability\": 0.0027928718647428573, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10959, \"tn\": 5187, \"fp\": 1831, \"fn\": 822, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.930226636108989, \"tn_rate\": 0.7390994585351952, \"fp_rate\": 0.2609005414648048, \"fn_rate\": 0.06977336389101095, \"precision\": 0.8568412822517592, \"recall\": 0.930226636108989, \"specificity\": 0.7390994585351952, \"npv\": 0.8632051922116825, \"accuracy\": 0.8588754720995798, \"f1\": 0.8920271865206951, \"f2\": 0.9145608705811663, \"f0_5\": 0.8705772072258147, \"p4\": 0.8414754644924681, \"phi\": 0.69422323118355}, {\"truth_threshold\": -8.46, \"match_probability\": 0.0028317485016074407, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10956, \"tn\": 5188, \"fp\": 1830, \"fn\": 825, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9299719887955182, \"tn_rate\": 0.7392419492732972, \"fp_rate\": 0.2607580507267028, \"fn_rate\": 0.0700280112044818, \"precision\": 0.8568747067104646, \"recall\": 0.9299719887955182, \"specificity\": 0.7392419492732972, \"npv\": 0.8627972725760852, \"accuracy\": 0.8587690834618863, \"f1\": 0.891928196360972, \"f2\": 0.9143715573360041, \"f0_5\": 0.8705601907032181, \"p4\": 0.8413806358487774, \"phi\": 0.6939845238736458}, {\"truth_threshold\": -8.44, \"match_probability\": 0.002871164741201907, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10956, \"tn\": 5190, \"fp\": 1828, \"fn\": 825, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9299719887955182, \"tn_rate\": 0.7395269307495013, \"fp_rate\": 0.26047306925049873, \"fn_rate\": 0.0700280112044818, \"precision\": 0.8570087609511889, \"recall\": 0.9299719887955182, \"specificity\": 0.7395269307495013, \"npv\": 0.8628428927680798, \"accuracy\": 0.8588754720995798, \"f1\": 0.892000814166497, \"f2\": 0.9144020831942311, \"f0_5\": 0.870670883862867, \"p4\": 0.8415160677908219, \"phi\": 0.6942189167674314}, {\"truth_threshold\": -8.4, \"match_probability\": 0.002951645913867726, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10955, \"tn\": 5232, \"fp\": 1786, \"fn\": 826, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9298871063576946, \"tn_rate\": 0.7455115417497863, \"fp_rate\": 0.2544884582502137, \"fn_rate\": 0.07011289364230541, \"precision\": 0.8598226198885488, \"recall\": 0.9298871063576946, \"specificity\": 0.7455115417497863, \"npv\": 0.8636513700891383, \"accuracy\": 0.8610564391722964, \"f1\": 0.893483402658837, \"f2\": 0.9149753612294329, \"f0_5\": 0.8729779265280102, \"p4\": 0.8442976972607774, \"phi\": 0.699023143230505}, {\"truth_threshold\": -8.38, \"match_probability\": 0.0029927260447372276, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10954, \"tn\": 5235, \"fp\": 1783, \"fn\": 827, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.929802223919871, \"tn_rate\": 0.7459390139640923, \"fp_rate\": 0.25406098603590765, \"fn_rate\": 0.07019777608012902, \"precision\": 0.8600141320562141, \"recall\": 0.929802223919871, \"specificity\": 0.7459390139640923, \"npv\": 0.8635763774331904, \"accuracy\": 0.8611628278099899, \"f1\": 0.8935475976833347, \"f2\": 0.9149529743906717, \"f0_5\": 0.8731208850770776, \"p4\": 0.8444454507150442, \"phi\": 0.6992567100882607}, {\"truth_threshold\": -8.36, \"match_probability\": 0.0030343761766495666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10953, \"tn\": 5238, \"fp\": 1780, \"fn\": 828, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9297173414820473, \"tn_rate\": 0.7463664861783984, \"fp_rate\": 0.2536335138216016, \"fn_rate\": 0.07028265851795264, \"precision\": 0.8602057645488101, \"recall\": 0.9297173414820473, \"specificity\": 0.7463664861783984, \"npv\": 0.8635014836795252, \"accuracy\": 0.8612692164476834, \"f1\": 0.8936118136575019, \"f2\": 0.9149305845598676, \"f0_5\": 0.8732639165723215, \"p4\": 0.8445931246434294, \"phi\": 0.6994903619692134}, {\"truth_threshold\": -8.34, \"match_probability\": 0.003076604169800717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10952, \"tn\": 5239, \"fp\": 1779, \"fn\": 829, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9296324590442238, \"tn_rate\": 0.7465089769165004, \"fp_rate\": 0.2534910230834996, \"fn_rate\": 0.07036754095577626, \"precision\": 0.8602623517398477, \"recall\": 0.9296324590442238, \"specificity\": 0.7465089769165004, \"npv\": 0.8633816743572841, \"accuracy\": 0.8612692164476834, \"f1\": 0.893603133159269, \"f2\": 0.9148776209172166, \"f0_5\": 0.8732955904632804, \"p4\": 0.8446061960671863, \"phi\": 0.6994896074493991}, {\"truth_threshold\": -8.32, \"match_probability\": 0.003119417991410515, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10947, \"tn\": 5239, \"fp\": 1779, \"fn\": 834, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9292080468551057, \"tn_rate\": 0.7465089769165004, \"fp_rate\": 0.2534910230834996, \"fn_rate\": 0.07079195314489432, \"precision\": 0.8602074493163602, \"recall\": 0.9292080468551057, \"specificity\": 0.7465089769165004, \"npv\": 0.8626708381360119, \"accuracy\": 0.8610032448534497, \"f1\": 0.8933774023748317, \"f2\": 0.9145363408521303, \"f0_5\": 0.8731754008135918, \"p4\": 0.8443352256823581, \"phi\": 0.6988999677682297}, {\"truth_threshold\": -8.3, \"match_probability\": 0.0031628257171415226, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10946, \"tn\": 5239, \"fp\": 1779, \"fn\": 835, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.929123164417282, \"tn_rate\": 0.7465089769165004, \"fp_rate\": 0.2534910230834996, \"fn_rate\": 0.07087683558271794, \"precision\": 0.860196463654224, \"recall\": 0.929123164417282, \"specificity\": 0.7465089769165004, \"npv\": 0.8625288113269673, \"accuracy\": 0.8609500505346029, \"f1\": 0.8933322451644495, \"f2\": 0.9144680779962907, \"f0_5\": 0.8731513536797435, \"p4\": 0.8442810414202678, \"phi\": 0.6987821013245753}, {\"truth_threshold\": -8.28, \"match_probability\": 0.0032068355325356353, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10944, \"tn\": 5239, \"fp\": 1779, \"fn\": 837, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9289533995416348, \"tn_rate\": 0.7465089769165004, \"fp_rate\": 0.2534910230834996, \"fn_rate\": 0.07104660045836517, \"precision\": 0.8601744871492573, \"recall\": 0.9289533995416348, \"specificity\": 0.7465089769165004, \"npv\": 0.8622448979591837, \"accuracy\": 0.8608436618969094, \"f1\": 0.8932419196865817, \"f2\": 0.9143315454408742, \"f0_5\": 0.8731032502034369, \"p4\": 0.8441726827035226, \"phi\": 0.6985464298561495}, {\"truth_threshold\": -8.26, \"match_probability\": 0.0032514557344685887, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10940, \"tn\": 5239, \"fp\": 1779, \"fn\": 841, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9286138697903403, \"tn_rate\": 0.7465089769165004, \"fp_rate\": 0.2534910230834996, \"fn_rate\": 0.07138613020965962, \"precision\": 0.8601305134051419, \"recall\": 0.9286138697903403, \"specificity\": 0.7465089769165004, \"npv\": 0.8616776315789474, \"accuracy\": 0.8606308846215224, \"f1\": 0.893061224489796, \"f2\": 0.9140584529518908, \"f0_5\": 0.8730070063999233, \"p4\": 0.843956004473737, \"phi\": 0.6980753323373076}, {\"truth_threshold\": -8.24, \"match_probability\": 0.0032966947326226116, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10936, \"tn\": 5244, \"fp\": 1774, \"fn\": 845, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.928274340039046, \"tn_rate\": 0.7472214306070105, \"fp_rate\": 0.2527785693929895, \"fn_rate\": 0.07172565996095408, \"precision\": 0.8604248623131393, \"recall\": 0.928274340039046, \"specificity\": 0.7472214306070105, \"npv\": 0.8612251601248152, \"accuracy\": 0.8606840789403691, \"f1\": 0.893062757747744, \"f2\": 0.9138616839923789, \"f0_5\": 0.8731895051180913, \"p4\": 0.8440755683662412, \"phi\": 0.6981916198605294}, {\"truth_threshold\": -8.22, \"match_probability\": 0.0033425610509773486, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10935, \"tn\": 5305, \"fp\": 1713, \"fn\": 846, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9281894576012223, \"tn_rate\": 0.755913365631234, \"fp_rate\": 0.24408663436876604, \"fn_rate\": 0.0718105423987777, \"precision\": 0.8645635673624289, \"recall\": 0.9281894576012223, \"specificity\": 0.755913365631234, \"npv\": 0.8624613883921314, \"accuracy\": 0.863875738071174, \"f1\": 0.8952474517990913, \"f2\": 0.9147259586428428, \"f0_5\": 0.8765812130248666, \"p4\": 0.8481055074571583, \"phi\": 0.7052374244126202}, {\"truth_threshold\": -8.2, \"match_probability\": 0.0033890633293192944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10933, \"tn\": 5309, \"fp\": 1709, \"fn\": 848, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.928019692725575, \"tn_rate\": 0.7564833285836421, \"fp_rate\": 0.24351667141635794, \"fn_rate\": 0.07198030727442492, \"precision\": 0.8648156937193482, \"recall\": 0.928019692725575, \"specificity\": 0.7564833285836421, \"npv\": 0.8622705863245087, \"accuracy\": 0.8639821267088675, \"f1\": 0.8953036072554559, \"f2\": 0.9146504701669845, \"f0_5\": 0.8767582479269916, \"p4\": 0.8482638297896594, \"phi\": 0.7054734264609118}, {\"truth_threshold\": -8.18, \"match_probability\": 0.0034362103247699053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10932, \"tn\": 5313, \"fp\": 1705, \"fn\": 849, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9279348102877515, \"tn_rate\": 0.7570532915360502, \"fp_rate\": 0.24294670846394983, \"fn_rate\": 0.07206518971224854, \"precision\": 0.8650787370420194, \"recall\": 0.9279348102877515, \"specificity\": 0.7570532915360502, \"npv\": 0.8622200584225901, \"accuracy\": 0.8641417096654077, \"f1\": 0.8954050290769104, \"f2\": 0.9146433292615586, \"f0_5\": 0.8769593608111794, \"p4\": 0.8484762030163884, \"phi\": 0.7058264810589358}, {\"truth_threshold\": -8.16, \"match_probability\": 0.0034840109133326283, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10931, \"tn\": 5316, \"fp\": 1702, \"fn\": 850, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9278499278499278, \"tn_rate\": 0.7574807637503562, \"fp_rate\": 0.24251923624964378, \"fn_rate\": 0.07215007215007214, \"precision\": 0.865273490065701, \"recall\": 0.9278499278499278, \"specificity\": 0.7574807637503562, \"npv\": 0.8621472591631528, \"accuracy\": 0.8642480983031012, \"f1\": 0.8954698124027197, \"f2\": 0.9146208812356711, \"f0_5\": 0.8771042960537929, \"p4\": 0.8486218473831724, \"phi\": 0.7060621538883154}, {\"truth_threshold\": -8.14, \"match_probability\": 0.003532474091458984, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10910, \"tn\": 5320, \"fp\": 1698, \"fn\": 871, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.926067396655632, \"tn_rate\": 0.7580507267027643, \"fp_rate\": 0.24194927329723567, \"fn_rate\": 0.07393260334436805, \"precision\": 0.8653236040609137, \"recall\": 0.926067396655632, \"specificity\": 0.7580507267027643, \"npv\": 0.859311904377322, \"accuracy\": 0.8633437948827065, \"f1\": 0.8946656279470253, \"f2\": 0.9132458313801647, \"f0_5\": 0.8768263867680388, \"p4\": 0.8477509667633792, \"phi\": 0.7040854239022586}, {\"truth_threshold\": -8.120000000000001, \"match_probability\": 0.003581608977633939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10906, \"tn\": 5323, \"fp\": 1695, \"fn\": 875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9257278669043375, \"tn_rate\": 0.7584781989170704, \"fp_rate\": 0.24152180108292962, \"fn_rate\": 0.07427213309566251, \"precision\": 0.8654868661217364, \"recall\": 0.9257278669043375, \"specificity\": 0.7584781989170704, \"npv\": 0.8588254275572765, \"accuracy\": 0.8632906005638598, \"f1\": 0.8945943728980396, \"f2\": 0.9130179991628297, \"f0_5\": 0.8768995738522152, \"p4\": 0.8477341202538055, \"phi\": 0.7039736251339233}, {\"truth_threshold\": -8.1, \"match_probability\": 0.0036314248139807737, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10906, \"tn\": 5326, \"fp\": 1692, \"fn\": 875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9257278669043375, \"tn_rate\": 0.7589056711313764, \"fp_rate\": 0.24109432886862353, \"fn_rate\": 0.07427213309566251, \"precision\": 0.8656929671376409, \"recall\": 0.9257278669043375, \"specificity\": 0.7589056711313764, \"npv\": 0.8588937268182552, \"accuracy\": 0.8634501835204, \"f1\": 0.8947044587554863, \"f2\": 0.9130638625632095, \"f0_5\": 0.8770688240876264, \"p4\": 0.8479336486534266, \"phi\": 0.7043268785845292}, {\"truth_threshold\": -8.06, \"match_probability\": 0.0037331369336417713, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10906, \"tn\": 5327, \"fp\": 1691, \"fn\": 875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9257278669043375, \"tn_rate\": 0.7590481618694784, \"fp_rate\": 0.2409518381305215, \"fn_rate\": 0.07427213309566251, \"precision\": 0.8657616892911011, \"recall\": 0.9257278669043375, \"specificity\": 0.7590481618694784, \"npv\": 0.8589164785553047, \"accuracy\": 0.8635033778392468, \"f1\": 0.8947411600623513, \"f2\": 0.9130791513872842, \"f0_5\": 0.877125255352346, \"p4\": 0.8480001414105673, \"phi\": 0.7044446308383269}, {\"truth_threshold\": -8.040000000000001, \"match_probability\": 0.0037850523341144294, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10901, \"tn\": 5327, \"fp\": 1691, \"fn\": 880, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9253034547152195, \"tn_rate\": 0.7590481618694784, \"fp_rate\": 0.2409518381305215, \"fn_rate\": 0.07469654528478058, \"precision\": 0.8657083862770013, \"recall\": 0.9253034547152195, \"specificity\": 0.7590481618694784, \"npv\": 0.8582245851458031, \"accuracy\": 0.863237406245013, \"f1\": 0.8945144216961392, \"f2\": 0.9127369549199544, \"f0_5\": 0.8770052615488584, \"p4\": 0.8477296276648874, \"phi\": 0.70386411990679}, {\"truth_threshold\": -8.02, \"match_probability\": 0.0038376869224252233, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10890, \"tn\": 5327, \"fp\": 1691, \"fn\": 891, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9243697478991597, \"tn_rate\": 0.7590481618694784, \"fp_rate\": 0.2409518381305215, \"fn_rate\": 0.07563025210084033, \"precision\": 0.8655909705110881, \"recall\": 0.9243697478991597, \"specificity\": 0.7590481618694784, \"npv\": 0.8567063364425861, \"accuracy\": 0.8626522687376988, \"f1\": 0.8940152696822921, \"f2\": 0.9119839209446445, \"f0_5\": 0.8767410031398438, \"p4\": 0.8471347759393492, \"phi\": 0.7025887244681602}, {\"truth_threshold\": -8.0, \"match_probability\": 0.0038910505836575876, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10888, \"tn\": 5329, \"fp\": 1689, \"fn\": 893, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9241999830235125, \"tn_rate\": 0.7593331433456826, \"fp_rate\": 0.24066685665431747, \"fn_rate\": 0.07580001697648757, \"precision\": 0.8657072433807744, \"recall\": 0.9241999830235125, \"specificity\": 0.7593331433456826, \"npv\": 0.8564770170363227, \"accuracy\": 0.8626522687376988, \"f1\": 0.893997865177765, \"f2\": 0.9118775229895647, \"f0_5\": 0.8768058754368728, \"p4\": 0.8471595994380249, \"phi\": 0.702592958502662}, {\"truth_threshold\": -7.98, \"match_probability\": 0.003945153336582717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10884, \"tn\": 5331, \"fp\": 1687, \"fn\": 897, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.923860453272218, \"tn_rate\": 0.7596181248218866, \"fp_rate\": 0.24038187517811344, \"fn_rate\": 0.07613954672778202, \"precision\": 0.8658022432582929, \"recall\": 0.923860453272218, \"specificity\": 0.7596181248218866, \"npv\": 0.8559730250481695, \"accuracy\": 0.8625458801000053, \"f1\": 0.8938896189224704, \"f2\": 0.9116341402127481, \"f0_5\": 0.876822685893821, \"p4\": 0.8470763032586273, \"phi\": 0.7023659545319603}, {\"truth_threshold\": -7.96, \"match_probability\": 0.004000005335406395, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10880, \"tn\": 5331, \"fp\": 1687, \"fn\": 901, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9235209235209235, \"tn_rate\": 0.7596181248218866, \"fp_rate\": 0.24038187517811344, \"fn_rate\": 0.07647907647907648, \"precision\": 0.8657595289249622, \"recall\": 0.9235209235209235, \"specificity\": 0.7596181248218866, \"npv\": 0.855423620025674, \"accuracy\": 0.8623331028246183, \"f1\": 0.8937079020864137, \"f2\": 0.9113601715501499, \"f0_5\": 0.8767264581218069, \"p4\": 0.8468601534911835, \"phi\": 0.7019033908274048}, {\"truth_threshold\": -7.94, \"match_probability\": 0.004055616871536931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10867, \"tn\": 5334, \"fp\": 1684, \"fn\": 914, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9224174518292165, \"tn_rate\": 0.7600455970361927, \"fp_rate\": 0.23995440296380735, \"fn_rate\": 0.07758254817078346, \"precision\": 0.8658274241096326, \"recall\": 0.9224174518292165, \"specificity\": 0.7600455970361927, \"npv\": 0.8537131882202305, \"accuracy\": 0.8618011596361509, \"f1\": 0.8932270261384185, \"f2\": 0.9105152911604525, \"f0_5\": 0.8765830442849076, \"p4\": 0.8463572661884528, \"phi\": 0.7007566482546718}, {\"truth_threshold\": -7.92, \"match_probability\": 0.004111998375374417, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10866, \"tn\": 5334, \"fp\": 1684, \"fn\": 915, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.922332569391393, \"tn_rate\": 0.7600455970361927, \"fp_rate\": 0.23995440296380735, \"fn_rate\": 0.07766743060860708, \"precision\": 0.8658167330677291, \"recall\": 0.922332569391393, \"specificity\": 0.7600455970361927, \"npv\": 0.8535765722515603, \"accuracy\": 0.8617479653173041, \"f1\": 0.8931815379556943, \"f2\": 0.9104467607333177, \"f0_5\": 0.8765589454832933, \"p4\": 0.8463032754203778, \"phi\": 0.700641338078233}, {\"truth_threshold\": -7.9, \"match_probability\": 0.00416916041812146, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10860, \"tn\": 5335, \"fp\": 1683, \"fn\": 921, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9218232747644513, \"tn_rate\": 0.7601880877742947, \"fp_rate\": 0.23981191222570533, \"fn_rate\": 0.07817672523554876, \"precision\": 0.8658215737861755, \"recall\": 0.9218232747644513, \"specificity\": 0.7601880877742947, \"npv\": 0.8527813299232737, \"accuracy\": 0.8614819937230703, \"f1\": 0.8929452392698569, \"f2\": 0.9100507818392076, \"f0_5\": 0.8764708730812067, \"p4\": 0.8460457926715341, \"phi\": 0.7000681006039203}, {\"truth_threshold\": -7.88, \"match_probability\": 0.004227113713615665, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10858, \"tn\": 5335, \"fp\": 1683, \"fn\": 923, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.921653509888804, \"tn_rate\": 0.7601880877742947, \"fp_rate\": 0.23981191222570533, \"fn_rate\": 0.07834649011119599, \"precision\": 0.8658001754246073, \"recall\": 0.921653509888804, \"specificity\": 0.7601880877742947, \"npv\": 0.8525087887503995, \"accuracy\": 0.8613756050853769, \"f1\": 0.8928542060685799, \"f2\": 0.9099136847397972, \"f0_5\": 0.8764226329808701, \"p4\": 0.8459378567041969, \"phi\": 0.6998377895975696}, {\"truth_threshold\": -7.84, \"match_probability\": 0.00434543764251929, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10857, \"tn\": 5336, \"fp\": 1682, \"fn\": 924, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9215686274509803, \"tn_rate\": 0.7603305785123967, \"fp_rate\": 0.2396694214876033, \"fn_rate\": 0.0784313725490196, \"precision\": 0.8658585214131909, \"recall\": 0.9215686274509803, \"specificity\": 0.7603305785123967, \"npv\": 0.8523961661341853, \"accuracy\": 0.8613756050853769, \"f1\": 0.8928453947368421, \"f2\": 0.9098603824816051, \"f0_5\": 0.876455107609345, \"p4\": 0.8459502792760416, \"phi\": 0.6998409112920088}, {\"truth_threshold\": -7.82, \"match_probability\": 0.004405830433579104, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10847, \"tn\": 5336, \"fp\": 1682, \"fn\": 934, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9207198030727443, \"tn_rate\": 0.7603305785123967, \"fp_rate\": 0.2396694214876033, \"fn_rate\": 0.07928019692725576, \"precision\": 0.8657514566206401, \"recall\": 0.9207198030727443, \"specificity\": 0.7603305785123967, \"npv\": 0.85103668261563, \"accuracy\": 0.8608436618969094, \"f1\": 0.8923899629781983, \"f2\": 0.9091747271721455, \"f0_5\": 0.8762137098728533, \"p4\": 0.8454108110576191, \"phi\": 0.698690801243701}, {\"truth_threshold\": -7.8, \"match_probability\": 0.00446705879650708, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10846, \"tn\": 5336, \"fp\": 1682, \"fn\": 935, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9206349206349206, \"tn_rate\": 0.7603305785123967, \"fp_rate\": 0.2396694214876033, \"fn_rate\": 0.07936507936507936, \"precision\": 0.8657407407407407, \"recall\": 0.9206349206349206, \"specificity\": 0.7603305785123967, \"npv\": 0.8509009727316218, \"accuracy\": 0.8607904675780627, \"f1\": 0.8923443991937142, \"f2\": 0.909106148997519, \"f0_5\": 0.8761895529381352, \"p4\": 0.845356881361762, \"phi\": 0.6985758957511317}, {\"truth_threshold\": -7.76, \"match_probability\": 0.004592068213160174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10844, \"tn\": 5656, \"fp\": 1362, \"fn\": 937, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9204651557592735, \"tn_rate\": 0.8059276147050441, \"fp_rate\": 0.19407238529495582, \"fn_rate\": 0.0795348442407266, \"precision\": 0.8884155333442569, \"recall\": 0.9204651557592735, \"specificity\": 0.8059276147050441, \"npv\": 0.8578795692401031, \"accuracy\": 0.8777062609713283, \"f1\": 0.9041564180597824, \"f2\": 0.9138715658183044, \"f0_5\": 0.8946456562989852, \"p4\": 0.8660862536204034, \"phi\": 0.7362766919780942}, {\"truth_threshold\": -7.74, \"match_probability\": 0.004655872641715067, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10841, \"tn\": 5656, \"fp\": 1362, \"fn\": 940, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9202105084458025, \"tn_rate\": 0.8059276147050441, \"fp_rate\": 0.19407238529495582, \"fn_rate\": 0.07978949155419744, \"precision\": 0.8883881012865689, \"recall\": 0.9202105084458025, \"specificity\": 0.8059276147050441, \"npv\": 0.8574893875075803, \"accuracy\": 0.877546678014788, \"f1\": 0.9040193462308206, \"f2\": 0.9136649417634467, \"f0_5\": 0.8945752809730497, \"p4\": 0.8659239227190736, \"phi\": 0.7359416279933146}, {\"truth_threshold\": -7.72, \"match_probability\": 0.0047205593958014914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10840, \"tn\": 5661, \"fp\": 1357, \"fn\": 941, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.920125626007979, \"tn_rate\": 0.8066400683955542, \"fp_rate\": 0.1933599316044457, \"fn_rate\": 0.07987437399202105, \"precision\": 0.8887431335574322, \"recall\": 0.920125626007979, \"specificity\": 0.8066400683955542, \"npv\": 0.8574674341108754, \"accuracy\": 0.877759455290175, \"f1\": 0.9041621486362499, \"f2\": 0.9136730668734512, \"f0_5\": 0.8948471990622265, \"p4\": 0.8661893447778568, \"phi\": 0.7364239549218319}, {\"truth_threshold\": -7.7, \"match_probability\": 0.004786140559117481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10839, \"tn\": 5670, \"fp\": 1348, \"fn\": 942, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9200407435701553, \"tn_rate\": 0.8079224850384725, \"fp_rate\": 0.1920775149615275, \"fn_rate\": 0.07995925642984467, \"precision\": 0.889390333962419, \"recall\": 0.9200407435701553, \"specificity\": 0.8079224850384725, \"npv\": 0.8575317604355717, \"accuracy\": 0.8781850098409489, \"f1\": 0.9044559412550067, \"f2\": 0.913742813306132, \"f0_5\": 0.8953559450841745, \"p4\": 0.8667099407253986, \"phi\": 0.7373817324541473}, {\"truth_threshold\": -7.68, \"match_probability\": 0.0048526283775603, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10836, \"tn\": 5670, \"fp\": 1348, \"fn\": 945, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9197860962566845, \"tn_rate\": 0.8079224850384725, \"fp_rate\": 0.1920775149615275, \"fn_rate\": 0.08021390374331551, \"precision\": 0.8893630991464215, \"recall\": 0.9197860962566845, \"specificity\": 0.8079224850384725, \"npv\": 0.8571428571428571, \"accuracy\": 0.8780254268844088, \"f1\": 0.9043187982474442, \"f2\": 0.9135361165441425, \"f0_5\": 0.895285622221855, \"p4\": 0.866547630842037, \"phi\": 0.7370473460909112}, {\"truth_threshold\": -7.66, \"match_probability\": 0.004920035261311362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10836, \"tn\": 5671, \"fp\": 1347, \"fn\": 945, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9197860962566845, \"tn_rate\": 0.8080649757765745, \"fp_rate\": 0.19193502422342548, \"fn_rate\": 0.08021390374331551, \"precision\": 0.8894360994828859, \"recall\": 0.9197860962566845, \"specificity\": 0.8080649757765745, \"npv\": 0.8571644498186215, \"accuracy\": 0.8780786212032555, \"f1\": 0.9043565348022033, \"f2\": 0.9135515200566544, \"f0_5\": 0.8953448019433841, \"p4\": 0.8666114497800413, \"phi\": 0.7371662025552462}, {\"truth_threshold\": -7.640000000000001, \"match_probability\": 0.004988373786945367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10832, \"tn\": 5675, \"fp\": 1343, \"fn\": 949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.91944656650539, \"tn_rate\": 0.8086349387289826, \"fp_rate\": 0.19136506127101738, \"fn_rate\": 0.08055343349460997, \"precision\": 0.8896919917864476, \"recall\": 0.91944656650539, \"specificity\": 0.8086349387289826, \"npv\": 0.8567330917874396, \"accuracy\": 0.8780786212032555, \"f1\": 0.9043245950910002, \"f2\": 0.9133374930437276, \"f0_5\": 0.8954878391560986, \"p4\": 0.866650272124909, \"phi\": 0.7371962414399358}, {\"truth_threshold\": -7.6000000000000005, \"match_probability\": 0.005127896914953068, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10821, \"tn\": 5678, \"fp\": 1340, \"fn\": 960, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9185128596893303, \"tn_rate\": 0.8090624109432887, \"fp_rate\": 0.19093758905671132, \"fn_rate\": 0.08148714031066973, \"precision\": 0.8898116931173423, \"recall\": 0.9185128596893303, \"specificity\": 0.8090624109432887, \"npv\": 0.8553781259415486, \"accuracy\": 0.8776530666524816, \"f1\": 0.9039345083952887, \"f2\": 0.9126254533187147, \"f0_5\": 0.8954075299958626, \"p4\": 0.8662467615479535, \"phi\": 0.7363298746312313}, {\"truth_threshold\": -7.58, \"match_probability\": 0.005199107521767358, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10819, \"tn\": 5682, \"fp\": 1336, \"fn\": 962, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.918343094813683, \"tn_rate\": 0.8096323738956968, \"fp_rate\": 0.19036762610430322, \"fn_rate\": 0.08165690518631695, \"precision\": 0.8900863842040313, \"recall\": 0.918343094813683, \"specificity\": 0.8096323738956968, \"npv\": 0.8552077062010837, \"accuracy\": 0.877759455290175, \"f1\": 0.9039939839572193, \"f2\": 0.912549132070379, \"f0_5\": 0.8955977550040563, \"p4\": 0.8663936211920552, \"phi\": 0.7365838817059429}, {\"truth_threshold\": -7.5600000000000005, \"match_probability\": 0.0052713017837366085, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10817, \"tn\": 5682, \"fp\": 1336, \"fn\": 964, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9181733299380358, \"tn_rate\": 0.8096323738956968, \"fp_rate\": 0.19036762610430322, \"fn_rate\": 0.08182667006196417, \"precision\": 0.8900682958940179, \"recall\": 0.9181733299380358, \"specificity\": 0.8096323738956968, \"npv\": 0.8549503460728257, \"accuracy\": 0.8776530666524816, \"f1\": 0.9039023982618869, \"f2\": 0.9124112218904465, \"f0_5\": 0.8955508088685775, \"p4\": 0.8662855137073654, \"phi\": 0.7363618791639952}, {\"truth_threshold\": -7.54, \"match_probability\": 0.005344493141899607, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10815, \"tn\": 5683, \"fp\": 1335, \"fn\": 966, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9180035650623886, \"tn_rate\": 0.8097748646337988, \"fp_rate\": 0.1902251353662012, \"fn_rate\": 0.08199643493761141, \"precision\": 0.8901234567901235, \"recall\": 0.9180035650623886, \"specificity\": 0.8097748646337988, \"npv\": 0.8547149947360505, \"accuracy\": 0.8775998723336348, \"f1\": 0.903848564623292, \"f2\": 0.9122886931875696, \"f0_5\": 0.8955631738460774, \"p4\": 0.8662411416758311, \"phi\": 0.7362590295738713}, {\"truth_threshold\": -7.5200000000000005, \"match_probability\": 0.005418695216862511, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10814, \"tn\": 5683, \"fp\": 1335, \"fn\": 967, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.917918682624565, \"tn_rate\": 0.8097748646337988, \"fp_rate\": 0.1902251353662012, \"fn_rate\": 0.08208131737543502, \"precision\": 0.8901144127088649, \"recall\": 0.917918682624565, \"specificity\": 0.8097748646337988, \"npv\": 0.8545864661654136, \"accuracy\": 0.877546678014788, \"f1\": 0.9038027580442959, \"f2\": 0.9122197290503264, \"f0_5\": 0.8955396922669229, \"p4\": 0.8661870973884837, \"phi\": 0.7361480993621085}, {\"truth_threshold\": -7.5, \"match_probability\": 0.005493921811082985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10813, \"tn\": 5686, \"fp\": 1332, \"fn\": 968, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9178338001867413, \"tn_rate\": 0.8102023368481048, \"fp_rate\": 0.1897976631518951, \"fn_rate\": 0.08216619981325864, \"precision\": 0.8903252367229313, \"recall\": 0.9178338001867413, \"specificity\": 0.8102023368481048, \"npv\": 0.8545235948301774, \"accuracy\": 0.8776530666524816, \"f1\": 0.9038702666555212, \"f2\": 0.9121969326291991, \"f0_5\": 0.8956942396580574, \"p4\": 0.8663241831440521, \"phi\": 0.7363945043241726}, {\"truth_threshold\": -7.48, \"match_probability\": 0.005570186911180121, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10810, \"tn\": 5686, \"fp\": 1332, \"fn\": 971, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9175791528732705, \"tn_rate\": 0.8102023368481048, \"fp_rate\": 0.1897976631518951, \"fn_rate\": 0.08242084712672948, \"precision\": 0.890298138692143, \"recall\": 0.9175791528732705, \"specificity\": 0.8102023368481048, \"npv\": 0.854138500826198, \"accuracy\": 0.8774934836959413, \"f1\": 0.9037328094302554, \"f2\": 0.9119900111362332, \"f0_5\": 0.8956237882980662, \"p4\": 0.8661620710849246, \"phi\": 0.7360619583376339}, {\"truth_threshold\": -7.46, \"match_probability\": 0.00564750469027039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10809, \"tn\": 5687, \"fp\": 1331, \"fn\": 972, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.917494270435447, \"tn_rate\": 0.8103448275862069, \"fp_rate\": 0.1896551724137931, \"fn_rate\": 0.0825057295645531, \"precision\": 0.8903624382207578, \"recall\": 0.917494270435447, \"specificity\": 0.8103448275862069, \"npv\": 0.8540321369575011, \"accuracy\": 0.8774934836959413, \"f1\": 0.9037247606705405, \"f2\": 0.9119364200863931, \"f0_5\": 0.8956596675560564, \"p4\": 0.8661717324573749, \"phi\": 0.7360702929543863}, {\"truth_threshold\": -7.44, \"match_probability\": 0.005725889510329732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10807, \"tn\": 5687, \"fp\": 1331, \"fn\": 974, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9173245055597997, \"tn_rate\": 0.8103448275862069, \"fp_rate\": 0.1896551724137931, \"fn_rate\": 0.08267549444020032, \"precision\": 0.890344373043335, \"recall\": 0.9173245055597997, \"specificity\": 0.8103448275862069, \"npv\": 0.85377570935295, \"accuracy\": 0.8773870950582477, \"f1\": 0.9036330950290564, \"f2\": 0.9117984543214877, \"f0_5\": 0.8956126829429997, \"p4\": 0.8660636765983983, \"phi\": 0.7358487372672838}, {\"truth_threshold\": -7.42, \"match_probability\": 0.005805355924582104, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10799, \"tn\": 5687, \"fp\": 1331, \"fn\": 982, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9166454460572108, \"tn_rate\": 0.8103448275862069, \"fp_rate\": 0.1896551724137931, \"fn_rate\": 0.08335455394278923, \"precision\": 0.8902720527617477, \"recall\": 0.9166454460572108, \"specificity\": 0.8103448275862069, \"npv\": 0.8527515369620633, \"accuracy\": 0.8769615405074738, \"f1\": 0.9032662791183974, \"f2\": 0.9112464981267088, \"f0_5\": 0.8954246198238835, \"p4\": 0.8656315668571624, \"phi\": 0.7349632118799062}, {\"truth_threshold\": -7.4, \"match_probability\": 0.005885918679914525, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10798, \"tn\": 5688, \"fp\": 1330, \"fn\": 983, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9165605636193872, \"tn_rate\": 0.8104873183243089, \"fp_rate\": 0.18951268167569107, \"fn_rate\": 0.08343943638061285, \"precision\": 0.8903364116094987, \"recall\": 0.9165605636193872, \"specificity\": 0.8104873183243089, \"npv\": 0.8526457802428421, \"accuracy\": 0.8769615405074738, \"f1\": 0.9032581872934878, \"f2\": 0.911192871126713, \"f0_5\": 0.895460501219047, \"p4\": 0.8656412460282069, \"phi\": 0.7349718558612495}, {\"truth_threshold\": -7.38, \"match_probability\": 0.005967592719318969, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10796, \"tn\": 5689, \"fp\": 1329, \"fn\": 985, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.91639079874374, \"tn_rate\": 0.8106298090624109, \"fp_rate\": 0.18937019093758906, \"fn_rate\": 0.08360920125626008, \"precision\": 0.8903917525773196, \"recall\": 0.91639079874374, \"specificity\": 0.8106298090624109, \"npv\": 0.8524123464189391, \"accuracy\": 0.876908346188627, \"f1\": 0.9032042165146825, \"f2\": 0.9110702290334014, \"f0_5\": 0.895472868731441, \"p4\": 0.8655969236509162, \"phi\": 0.7348699800190237}, {\"truth_threshold\": -7.36, \"match_probability\": 0.006050393184361143, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10794, \"tn\": 5689, \"fp\": 1329, \"fn\": 987, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9162210338680927, \"tn_rate\": 0.8106298090624109, \"fp_rate\": 0.18937019093758906, \"fn_rate\": 0.08377896613190731, \"precision\": 0.8903736698836922, \"recall\": 0.9162210338680927, \"specificity\": 0.8106298090624109, \"npv\": 0.8521569802276813, \"accuracy\": 0.8768019575509336, \"f1\": 0.9031124497991968, \"f2\": 0.9109321990986885, \"f0_5\": 0.8954258125528843, \"p4\": 0.865488939415036, \"phi\": 0.7346489154250394}, {\"truth_threshold\": -7.34, \"match_probability\": 0.0061343354176764545, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10792, \"tn\": 5690, \"fp\": 1328, \"fn\": 989, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9160512689924455, \"tn_rate\": 0.810772299800513, \"fp_rate\": 0.18922770019948704, \"fn_rate\": 0.08394873100755454, \"precision\": 0.8904290429042905, \"recall\": 0.9160512689924455, \"specificity\": 0.810772299800513, \"npv\": 0.8519239407096871, \"accuracy\": 0.8767487632320868, \"f1\": 0.903058449437262, \"f2\": 0.9108095334548646, \"f0_5\": 0.8954381772622426, \"p4\": 0.8654446294845728, \"phi\": 0.7345472380006692}, {\"truth_threshold\": -7.32, \"match_probability\": 0.006219434965493263, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10788, \"tn\": 5690, \"fp\": 1328, \"fn\": 993, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.915711739241151, \"tn_rate\": 0.810772299800513, \"fp_rate\": 0.18922770019948704, \"fn_rate\": 0.08428826075884899, \"precision\": 0.8903928689336414, \"recall\": 0.915711739241151, \"specificity\": 0.810772299800513, \"npv\": 0.8514140356127488, \"accuracy\": 0.8765359859566998, \"f1\": 0.9028748378457547, \"f2\": 0.9105334233625928, \"f0_5\": 0.8953440119511993, \"p4\": 0.8652287154037229, \"phi\": 0.7341054939202237}, {\"truth_threshold\": -7.3, \"match_probability\": 0.00630570758018367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10780, \"tn\": 5693, \"fp\": 1325, \"fn\": 1001, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9150326797385621, \"tn_rate\": 0.8111997720148191, \"fp_rate\": 0.18880022798518095, \"fn_rate\": 0.08496732026143791, \"precision\": 0.8905410987195373, \"recall\": 0.9150326797385621, \"specificity\": 0.8111997720148191, \"npv\": 0.8504631012847326, \"accuracy\": 0.8762700143624661, \"f1\": 0.9026207820480616, \"f2\": 0.9100271826301305, \"f0_5\": 0.8953339645520838, \"p4\": 0.8649879503531166, \"phi\": 0.7335811454288161}, {\"truth_threshold\": -7.28, \"match_probability\": 0.006393169222841944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10779, \"tn\": 5698, \"fp\": 1320, \"fn\": 1002, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9149477973007385, \"tn_rate\": 0.8119122257053292, \"fp_rate\": 0.18808777429467086, \"fn_rate\": 0.08505220269926152, \"precision\": 0.8909000743863129, \"recall\": 0.9149477973007385, \"specificity\": 0.8119122257053292, \"npv\": 0.8504477611940299, \"accuracy\": 0.876482791637853, \"f1\": 0.9027638190954774, \"f2\": 0.9100349526366446, \"f0_5\": 0.8956079565282417, \"p4\": 0.8652520717079875, \"phi\": 0.7340681881306576}, {\"truth_threshold\": -7.26, \"match_probability\": 0.006481836065890851, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10778, \"tn\": 5699, \"fp\": 1319, \"fn\": 1003, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9148629148629148, \"tn_rate\": 0.8120547164434312, \"fp_rate\": 0.1879452835565688, \"fn_rate\": 0.08513708513708514, \"precision\": 0.8909647019922294, \"recall\": 0.9148629148629148, \"specificity\": 0.8120547164434312, \"npv\": 0.8503431811399582, \"accuracy\": 0.876482791637853, \"f1\": 0.9027556746796214, \"f2\": 0.9099812566488239, \"f0_5\": 0.8956439362462397, \"p4\": 0.8652617143592551, \"phi\": 0.7340774962326331}, {\"truth_threshold\": -7.24, \"match_probability\": 0.00657172449571595, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10775, \"tn\": 5705, \"fp\": 1313, \"fn\": 1006, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.914608267549444, \"tn_rate\": 0.8129096608720433, \"fp_rate\": 0.1870903391279567, \"fn_rate\": 0.08539173245055598, \"precision\": 0.8913798808735937, \"recall\": 0.914608267549444, \"specificity\": 0.8129096608720433, \"npv\": 0.8500968559082104, \"accuracy\": 0.8766423745943933, \"f1\": 0.9028446939545016, \"f2\": 0.909866243329055, \"f0_5\": 0.8959306869772006, \"p4\": 0.8654812827843685, \"phi\": 0.7344641717035777}, {\"truth_threshold\": -7.22, \"match_probability\": 0.006662851115328145, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10774, \"tn\": 5705, \"fp\": 1313, \"fn\": 1007, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9145233851116205, \"tn_rate\": 0.8129096608720433, \"fp_rate\": 0.1870903391279567, \"fn_rate\": 0.0854766148883796, \"precision\": 0.891370894349301, \"recall\": 0.9145233851116205, \"specificity\": 0.8129096608720433, \"npv\": 0.8499702026221693, \"accuracy\": 0.8765891802755466, \"f1\": 0.9027987263281381, \"f2\": 0.9097971660671159, \"f0_5\": 0.895907132997389, \"p4\": 0.8654273396027146, \"phi\": 0.7343541463645638}, {\"truth_threshold\": -7.2, \"match_probability\": 0.006755232747054526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10773, \"tn\": 5706, \"fp\": 1312, \"fn\": 1008, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9144385026737968, \"tn_rate\": 0.8130521516101453, \"fp_rate\": 0.18694784838985465, \"fn_rate\": 0.0855614973262032, \"precision\": 0.8914356640463384, \"recall\": 0.9144385026737968, \"specificity\": 0.8130521516101453, \"npv\": 0.8498659517426274, \"accuracy\": 0.8765891802755466, \"f1\": 0.9027905807424789, \"f2\": 0.9097434511645189, \"f0_5\": 0.8959431812511435, \"p4\": 0.8654369415749649, \"phi\": 0.7343636684178066}, {\"truth_threshold\": -7.16, \"match_probability\": 0.006943829449084327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10772, \"tn\": 5706, \"fp\": 1312, \"fn\": 1009, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9143536202359732, \"tn_rate\": 0.8130521516101453, \"fp_rate\": 0.18694784838985465, \"fn_rate\": 0.08564637976402682, \"precision\": 0.8914266799073155, \"recall\": 0.9143536202359732, \"specificity\": 0.8130521516101453, \"npv\": 0.8497393894266567, \"accuracy\": 0.8765359859566998, \"f1\": 0.9027446050701865, \"f2\": 0.9096743683286043, \"f0_5\": 0.8959196234010347, \"p4\": 0.8653830034431638, \"phi\": 0.7342536869025799}, {\"truth_threshold\": -7.140000000000001, \"match_probability\": 0.007040079285241038, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10772, \"tn\": 5715, \"fp\": 1303, \"fn\": 1009, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9143536202359732, \"tn_rate\": 0.8143345682530635, \"fp_rate\": 0.18566543174693645, \"fn_rate\": 0.08564637976402682, \"precision\": 0.8920910973084886, \"recall\": 0.9143536202359732, \"specificity\": 0.8143345682530635, \"npv\": 0.849940511600238, \"accuracy\": 0.8770147348263205, \"f1\": 0.9030851777330651, \"f2\": 0.909812665754489, \"f0_5\": 0.8964564504585476, \"p4\": 0.8659545718187891, \"phi\": 0.7353296328159945}, {\"truth_threshold\": -7.12, \"match_probability\": 0.0071376536708013, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10769, \"tn\": 5722, \"fp\": 1296, \"fn\": 1012, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9140989729225023, \"tn_rate\": 0.8153320034197777, \"fp_rate\": 0.1846679965802223, \"fn_rate\": 0.08590102707749767, \"precision\": 0.8925818483215914, \"recall\": 0.9140989729225023, \"specificity\": 0.8153320034197777, \"npv\": 0.8497178497178497, \"accuracy\": 0.8772275121017076, \"f1\": 0.9032122787888954, \"f2\": 0.909712953420399, \"f0_5\": 0.8968038507020203, \"p4\": 0.8662369188953059, \"phi\": 0.7358372058271375}, {\"truth_threshold\": -7.1000000000000005, \"match_probability\": 0.007236570566039904, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10763, \"tn\": 5730, \"fp\": 1288, \"fn\": 1018, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9135896782955607, \"tn_rate\": 0.8164719293245939, \"fp_rate\": 0.1835280706754061, \"fn_rate\": 0.08641032170443935, \"precision\": 0.8931209028296407, \"recall\": 0.9135896782955607, \"specificity\": 0.8164719293245939, \"npv\": 0.8491404860699466, \"accuracy\": 0.877333900739401, \"f1\": 0.9032393420610944, \"f2\": 0.9094212082805239, \"f0_5\": 0.8971409519046428, \"p4\": 0.8664205228575874, \"phi\": 0.7361362257452091}, {\"truth_threshold\": -7.08, \"match_probability\": 0.007336848167297341, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10759, \"tn\": 5730, \"fp\": 1288, \"fn\": 1022, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9132501485442662, \"tn_rate\": 0.8164719293245939, \"fp_rate\": 0.1835280706754061, \"fn_rate\": 0.08674985145573381, \"precision\": 0.8930854154561302, \"recall\": 0.9132501485442662, \"specificity\": 0.8164719293245939, \"npv\": 0.8486374407582938, \"accuracy\": 0.877121123464014, \"f1\": 0.9030552291421856, \"f2\": 0.9091446823612919, \"f0_5\": 0.8970468075172172, \"p4\": 0.8662048453616613, \"phi\": 0.7356979977134743}, {\"truth_threshold\": -7.0600000000000005, \"match_probability\": 0.007438504909873419, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10749, \"tn\": 5735, \"fp\": 1283, \"fn\": 1032, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.91240132416603, \"tn_rate\": 0.817184383015104, \"fp_rate\": 0.18281561698489598, \"fn_rate\": 0.08759867583396995, \"precision\": 0.8933676861702128, \"recall\": 0.91240132416603, \"specificity\": 0.817184383015104, \"npv\": 0.8474951972809222, \"accuracy\": 0.8768551518697804, \"f1\": 0.9027841935077479, \"f2\": 0.9085299885049699, \"f0_5\": 0.8971106177702849, \"p4\": 0.8659825726062971, \"phi\": 0.7352026732452422}, {\"truth_threshold\": -7.04, \"match_probability\": 0.0075415594709504815, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10742, \"tn\": 5736, \"fp\": 1282, \"fn\": 1039, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9118071471012648, \"tn_rate\": 0.817326873753206, \"fp_rate\": 0.18267312624679397, \"fn_rate\": 0.08819285289873526, \"precision\": 0.8933799068529608, \"recall\": 0.9118071471012648, \"specificity\": 0.817326873753206, \"npv\": 0.8466420664206642, \"accuracy\": 0.8765359859566998, \"f1\": 0.9024994749002311, \"f2\": 0.9080611347805505, \"f0_5\": 0.8970055279990647, \"p4\": 0.8656687390194804, \"phi\": 0.7345578240640133}, {\"truth_threshold\": -7.0200000000000005, \"match_probability\": 0.007646030772546182, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10739, \"tn\": 5740, \"fp\": 1278, \"fn\": 1042, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.911552499787794, \"tn_rate\": 0.8178968367056141, \"fp_rate\": 0.18210316329438586, \"fn_rate\": 0.0884475002122061, \"precision\": 0.893650661562786, \"recall\": 0.911552499787794, \"specificity\": 0.8178968367056141, \"npv\": 0.8463580064877617, \"accuracy\": 0.8765891802755466, \"f1\": 0.9025128162030422, \"f2\": 0.9079149828376253, \"f0_5\": 0.8971745559658474, \"p4\": 0.8657603517319179, \"phi\": 0.7347100325358589}, {\"truth_threshold\": -7.0, \"match_probability\": 0.007751937984496124, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10737, \"tn\": 5748, \"fp\": 1270, \"fn\": 1044, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9113827349121467, \"tn_rate\": 0.8190367626104303, \"fp_rate\": 0.18096323738956968, \"fn_rate\": 0.08861726508785332, \"precision\": 0.8942283667860415, \"recall\": 0.9113827349121467, \"specificity\": 0.8190367626104303, \"npv\": 0.8462897526501767, \"accuracy\": 0.876908346188627, \"f1\": 0.9027240625525476, \"f2\": 0.9078994097850536, \"f0_5\": 0.8976073835041549, \"p4\": 0.8661587192545713, \"phi\": 0.7354514754251066}, {\"truth_threshold\": -6.96, \"match_probability\": 0.007968138075995553, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10735, \"tn\": 5748, \"fp\": 1270, \"fn\": 1046, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9112129700364995, \"tn_rate\": 0.8190367626104303, \"fp_rate\": 0.18096323738956968, \"fn_rate\": 0.08878702996350055, \"precision\": 0.8942107455226989, \"recall\": 0.9112129700364995, \"specificity\": 0.8190367626104303, \"npv\": 0.8460406240800706, \"accuracy\": 0.8768019575509336, \"f1\": 0.902631800218616, \"f2\": 0.9077609971418424, \"f0_5\": 0.897560241467534, \"p4\": 0.8660509984240076, \"phi\": 0.7352335443544085}, {\"truth_threshold\": -6.94, \"match_probability\": 0.008078470561568152, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10735, \"tn\": 5760, \"fp\": 1258, \"fn\": 1046, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9112129700364995, \"tn_rate\": 0.8207466514676546, \"fp_rate\": 0.1792533485323454, \"fn_rate\": 0.08878702996350055, \"precision\": 0.8951054781956141, \"recall\": 0.9112129700364995, \"specificity\": 0.8207466514676546, \"npv\": 0.8463120775786072, \"accuracy\": 0.8774402893770945, \"f1\": 0.9030874064103642, \"f2\": 0.9079452610924099, \"f0_5\": 0.8982812578447944, \"p4\": 0.866809318099237, \"phi\": 0.7366734103393674}, {\"truth_threshold\": -6.92, \"match_probability\": 0.008190318175716487, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10734, \"tn\": 5771, \"fp\": 1247, \"fn\": 1047, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9111280875986758, \"tn_rate\": 0.8223140495867769, \"fp_rate\": 0.17768595041322313, \"fn_rate\": 0.08887191240132417, \"precision\": 0.8959185376846673, \"recall\": 0.9111280875986758, \"specificity\": 0.8223140495867769, \"npv\": 0.8464359049574656, \"accuracy\": 0.877972232565562, \"f1\": 0.9034593047723256, \"f2\": 0.9080450046527366, \"f0_5\": 0.8989196884683025, \"p4\": 0.8674497339410793, \"phi\": 0.7378848344833776}, {\"truth_threshold\": -6.9, \"match_probability\": 0.008303701373154063, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10732, \"tn\": 5777, \"fp\": 1241, \"fn\": 1049, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9109583227230286, \"tn_rate\": 0.823168994015389, \"fp_rate\": 0.176831005984611, \"fn_rate\": 0.08904167727697139, \"precision\": 0.8963501211058215, \"recall\": 0.9109583227230286, \"specificity\": 0.823168994015389, \"npv\": 0.8463228830940521, \"accuracy\": 0.8781850098409489, \"f1\": 0.9035951839690157, \"f2\": 0.907998713978713, \"f0_5\": 0.8992341595026226, \"p4\": 0.8677203572366763, \"phi\": 0.7383877976966525}, {\"truth_threshold\": -6.88, \"match_probability\": 0.008418640874938868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10730, \"tn\": 5783, \"fp\": 1235, \"fn\": 1051, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9107885578473813, \"tn_rate\": 0.8240239384440011, \"fp_rate\": 0.17597606155599885, \"fn_rate\": 0.08921144215261863, \"precision\": 0.8967822816548265, \"recall\": 0.9107885578473813, \"specificity\": 0.8240239384440011, \"npv\": 0.8462101258413813, \"accuracy\": 0.878397787116336, \"f1\": 0.9037311547207951, \"f2\": 0.9079524107701941, \"f0_5\": 0.8995489679918177, \"p4\": 0.8679907408393706, \"phi\": 0.7388911324937069}, {\"truth_threshold\": -6.86, \"match_probability\": 0.008535157671667086, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10729, \"tn\": 5785, \"fp\": 1233, \"fn\": 1052, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9107036754095578, \"tn_rate\": 0.8243089199202052, \"fp_rate\": 0.1756910800797948, \"fn_rate\": 0.08929632459044223, \"precision\": 0.8969235913726802, \"recall\": 0.9107036754095578, \"specificity\": 0.8243089199202052, \"npv\": 0.8461313441567939, \"accuracy\": 0.8784509814351827, \"f1\": 0.9037611085372531, \"f2\": 0.9079138882307145, \"f0_5\": 0.8996461453319693, \"p4\": 0.8680628614574889, \"phi\": 0.7390228255176619}, {\"truth_threshold\": -6.84, \"match_probability\": 0.008653273026697373, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10728, \"tn\": 5785, \"fp\": 1233, \"fn\": 1053, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9106187929717342, \"tn_rate\": 0.8243089199202052, \"fp_rate\": 0.1756910800797948, \"fn_rate\": 0.08938120702826585, \"precision\": 0.8969149736644093, \"recall\": 0.9106187929717342, \"specificity\": 0.8243089199202052, \"npv\": 0.8460076045627376, \"accuracy\": 0.878397787116336, \"f1\": 0.9037149355572404, \"f2\": 0.9078446306169079, \"f0_5\": 0.8996226415094339, \"p4\": 0.8680090009239964, \"phi\": 0.7389143328372105}, {\"truth_threshold\": -6.8, \"match_probability\": 0.008894385848470222, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10725, \"tn\": 5786, \"fp\": 1232, \"fn\": 1056, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9103641456582633, \"tn_rate\": 0.8244514106583072, \"fp_rate\": 0.1755485893416928, \"fn_rate\": 0.0896358543417367, \"precision\": 0.8969641214351426, \"recall\": 0.9103641456582633, \"specificity\": 0.8244514106583072, \"npv\": 0.8456591639871383, \"accuracy\": 0.8782913984786425, \"f1\": 0.9036144578313253, \"f2\": 0.9076522062930553, \"f0_5\": 0.8996124746263148, \"p4\": 0.8679104149249791, \"phi\": 0.7387091055423729}, {\"truth_threshold\": -6.78, \"match_probability\": 0.009017427235188254, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10718, \"tn\": 5790, \"fp\": 1228, \"fn\": 1063, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.909769968593498, \"tn_rate\": 0.8250213736107153, \"fp_rate\": 0.17497862638928469, \"fn_rate\": 0.090230031406502, \"precision\": 0.8972040850493889, \"recall\": 0.909769968593498, \"specificity\": 0.8250213736107153, \"npv\": 0.8448854516270247, \"accuracy\": 0.8781318155221023, \"f1\": 0.9034433345977156, \"f2\": 0.9072287116979855, \"f0_5\": 0.899689414924872, \"p4\": 0.8677853563316916, \"phi\": 0.7384314231464997}, {\"truth_threshold\": -6.76, \"match_probability\": 0.009142155026821896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10715, \"tn\": 5858, \"fp\": 1160, \"fn\": 1066, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9095153212800272, \"tn_rate\": 0.8347107438016529, \"fp_rate\": 0.1652892561983471, \"fn_rate\": 0.09048467871997284, \"precision\": 0.9023157894736842, \"recall\": 0.9095153212800272, \"specificity\": 0.8347107438016529, \"npv\": 0.8460427498555748, \"accuracy\": 0.8815894462471408, \"f1\": 0.9059012512681772, \"f2\": 0.9080662384108206, \"f0_5\": 0.9037465629797068, \"p4\": 0.8718891199483015, \"phi\": 0.7462894418355979}, {\"truth_threshold\": -6.74, \"match_probability\": 0.009268591899975812, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10714, \"tn\": 5864, \"fp\": 1154, \"fn\": 1067, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9094304388422035, \"tn_rate\": 0.835565688230265, \"fp_rate\": 0.16443431176973497, \"fn_rate\": 0.09056956115779645, \"precision\": 0.9027637344118639, \"recall\": 0.9094304388422035, \"specificity\": 0.835565688230265, \"npv\": 0.8460539604674651, \"accuracy\": 0.8818554178413746, \"f1\": 0.9060848238826166, \"f2\": 0.9080892324382968, \"f0_5\": 0.9040892444264426, \"p4\": 0.8722101821360766, \"phi\": 0.7469044668285453}, {\"truth_threshold\": -6.68, \"match_probability\": 0.009658388186525174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10711, \"tn\": 5864, \"fp\": 1154, \"fn\": 1070, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9091757915287327, \"tn_rate\": 0.835565688230265, \"fp_rate\": 0.16443431176973497, \"fn_rate\": 0.09082420847126729, \"precision\": 0.9027391487568479, \"recall\": 0.9091757915287327, \"specificity\": 0.835565688230265, \"npv\": 0.8456879146235939, \"accuracy\": 0.8816958348848343, \"f1\": 0.9059460373847585, \"f2\": 0.9078811303802404, \"f0_5\": 0.9040191759085768, \"p4\": 0.8720486013440555, \"phi\": 0.746581997287392}, {\"truth_threshold\": -6.66, \"match_probability\": 0.009791894058579487, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10708, \"tn\": 5867, \"fp\": 1151, \"fn\": 1073, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9089211442152618, \"tn_rate\": 0.8359931604445711, \"fp_rate\": 0.16400683955542888, \"fn_rate\": 0.09107885578473814, \"precision\": 0.9029429125558648, \"recall\": 0.9089211442152618, \"specificity\": 0.8359931604445711, \"npv\": 0.8453890489913545, \"accuracy\": 0.8816958348848343, \"f1\": 0.905922165820643, \"f2\": 0.9077191733211264, \"f0_5\": 0.9041322593174257, \"p4\": 0.8720744120284173, \"phi\": 0.7466211775664253}, {\"truth_threshold\": -6.640000000000001, \"match_probability\": 0.009927226855666866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10689, \"tn\": 5867, \"fp\": 1151, \"fn\": 1092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9073083778966132, \"tn_rate\": 0.8359931604445711, \"fp_rate\": 0.16400683955542888, \"fn_rate\": 0.09269162210338681, \"precision\": 0.9027871621621621, \"recall\": 0.9073083778966132, \"specificity\": 0.8359931604445711, \"npv\": 0.8430809024285099, \"accuracy\": 0.8806851428267461, \"f1\": 0.9050421235341434, \"f2\": 0.9064005155688216, \"f0_5\": 0.9036877969598079, \"p4\": 0.8710517397182682, \"phi\": 0.7445836956379104}, {\"truth_threshold\": -6.62, \"match_probability\": 0.010064411063087227, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10676, \"tn\": 5869, \"fp\": 1149, \"fn\": 1105, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9062049062049062, \"tn_rate\": 0.8362781419207751, \"fp_rate\": 0.16372185807922485, \"fn_rate\": 0.09379509379509379, \"precision\": 0.9028329809725159, \"recall\": 0.9062049062049062, \"specificity\": 0.8362781419207751, \"npv\": 0.8415543447089189, \"accuracy\": 0.8801000053194319, \"f1\": 0.9045158010675252, \"f2\": 0.9055285076930907, \"f0_5\": 0.9035053570521826, \"p4\": 0.8704774094430215, \"phi\": 0.7434345771875801}, {\"truth_threshold\": -6.6000000000000005, \"match_probability\": 0.010203471479982122, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10666, \"tn\": 5869, \"fp\": 1149, \"fn\": 1115, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.90535608182667, \"tn_rate\": 0.8362781419207751, \"fp_rate\": 0.16372185807922485, \"fn_rate\": 0.09464391817332994, \"precision\": 0.9027507405840034, \"recall\": 0.90535608182667, \"specificity\": 0.8362781419207751, \"npv\": 0.8403493699885453, \"accuracy\": 0.8795680621309644, \"f1\": 0.904051534158332, \"f2\": 0.9048338112285583, \"f0_5\": 0.9032706085601531, \"p4\": 0.8699398717833194, \"phi\": 0.7423668053402662}, {\"truth_threshold\": -6.58, \"match_probability\": 0.010344433222956822, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10665, \"tn\": 5869, \"fp\": 1149, \"fn\": 1116, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9052711993888465, \"tn_rate\": 0.8362781419207751, \"fp_rate\": 0.16372185807922485, \"fn_rate\": 0.09472880061115355, \"precision\": 0.9027425088877603, \"recall\": 0.9052711993888465, \"specificity\": 0.8362781419207751, \"npv\": 0.8402290622763063, \"accuracy\": 0.8795148678121176, \"f1\": 0.9040050858232677, \"f2\": 0.9047643286165122, \"f0_5\": 0.9032471162152549, \"p4\": 0.8698861323728755, \"phi\": 0.7422601155986278}, {\"truth_threshold\": -6.5600000000000005, \"match_probability\": 0.010487321729732655, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10660, \"tn\": 5873, \"fp\": 1145, \"fn\": 1121, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9048467871997283, \"tn_rate\": 0.8368481048731833, \"fp_rate\": 0.16315189512681677, \"fn_rate\": 0.09515321280027163, \"precision\": 0.9030072003388395, \"recall\": 0.9048467871997283, \"specificity\": 0.8368481048731833, \"npv\": 0.8397197597941093, \"accuracy\": 0.8794616734932709, \"f1\": 0.9039260578309166, \"f2\": 0.9044782704610633, \"f0_5\": 0.9033745190759479, \"p4\": 0.8698670552652645, \"phi\": 0.7422107467124477}, {\"truth_threshold\": -6.54, \"match_probability\": 0.010632162762829713, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10656, \"tn\": 5873, \"fp\": 1145, \"fn\": 1125, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.904507257448434, \"tn_rate\": 0.8368481048731833, \"fp_rate\": 0.16315189512681677, \"fn_rate\": 0.09549274255156608, \"precision\": 0.9029743242098127, \"recall\": 0.904507257448434, \"specificity\": 0.8368481048731833, \"npv\": 0.8392397827950843, \"accuracy\": 0.8792488962178839, \"f1\": 0.9037401407853447, \"f2\": 0.9042002545608825, \"f0_5\": 0.9032804950411122, \"p4\": 0.8696521667892032, \"phi\": 0.7417846103949791}, {\"truth_threshold\": -6.5200000000000005, \"match_probability\": 0.010778982413279539, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10651, \"tn\": 5873, \"fp\": 1145, \"fn\": 1130, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9040828452593158, \"tn_rate\": 0.8368481048731833, \"fp_rate\": 0.16315189512681677, \"fn_rate\": 0.09591715474068416, \"precision\": 0.9029331976941336, \"recall\": 0.9040828452593158, \"specificity\": 0.8368481048731833, \"npv\": 0.838640582607454, \"accuracy\": 0.8789829246236502, \"f1\": 0.9035076557662128, \"f2\": 0.9038526816021725, \"f0_5\": 0.9031628932417536, \"p4\": 0.8693836146058028, \"phi\": 0.7412522955325025}, {\"truth_threshold\": -6.5, \"match_probability\": 0.010927807104367976, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10650, \"tn\": 5873, \"fp\": 1145, \"fn\": 1131, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9039979628214923, \"tn_rate\": 0.8368481048731833, \"fp_rate\": 0.16315189512681677, \"fn_rate\": 0.09600203717850776, \"precision\": 0.9029249682068673, \"recall\": 0.9039979628214923, \"specificity\": 0.8368481048731833, \"npv\": 0.8385208452312964, \"accuracy\": 0.8789297303048035, \"f1\": 0.9034611469290804, \"f2\": 0.9037831599314313, \"f0_5\": 0.9031393633079493, \"p4\": 0.8693299119486477, \"phi\": 0.7411458799010783}, {\"truth_threshold\": -6.48, \"match_probability\": 0.011078663595407736, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10643, \"tn\": 5873, \"fp\": 1145, \"fn\": 1138, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.903403785756727, \"tn_rate\": 0.8368481048731833, \"fp_rate\": 0.16315189512681677, \"fn_rate\": 0.09659621424327307, \"precision\": 0.902867322701052, \"recall\": 0.903403785756727, \"specificity\": 0.8368481048731833, \"npv\": 0.8376836399942946, \"accuracy\": 0.8785573700728763, \"f1\": 0.903135474564046, \"f2\": 0.9032964421510049, \"f0_5\": 0.9029745643357712, \"p4\": 0.8689540658519197, \"phi\": 0.7404014115620191}, {\"truth_threshold\": -6.46, \"match_probability\": 0.011231578985540796, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10640, \"tn\": 5874, \"fp\": 1144, \"fn\": 1141, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9031491384432561, \"tn_rate\": 0.8369905956112853, \"fp_rate\": 0.16300940438871472, \"fn_rate\": 0.09685086155674391, \"precision\": 0.902919212491514, \"recall\": 0.9031491384432561, \"specificity\": 0.8369905956112853, \"npv\": 0.8373485388453314, \"accuracy\": 0.8784509814351827, \"f1\": 0.903034160831742, \"f2\": 0.9031031438853806, \"f0_5\": 0.9029651883157662, \"p4\": 0.8688553960625781, \"phi\": 0.7402037399281404}, {\"truth_threshold\": -6.44, \"match_probability\": 0.011386580717570208, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10633, \"tn\": 5896, \"fp\": 1122, \"fn\": 1148, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9025549613784908, \"tn_rate\": 0.8401253918495298, \"fp_rate\": 0.15987460815047022, \"fn_rate\": 0.0974450386215092, \"precision\": 0.9045512547851978, \"recall\": 0.9025549613784908, \"specificity\": 0.8401253918495298, \"npv\": 0.8370244179443498, \"accuracy\": 0.8792488962178839, \"f1\": 0.9035520054384772, \"f2\": 0.9029535148355101, \"f0_5\": 0.9041512899440486, \"p4\": 0.8698501688764234, \"phi\": 0.7421278074348698}, {\"truth_threshold\": -6.42, \"match_probability\": 0.011543696581821352, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10629, \"tn\": 5901, \"fp\": 1117, \"fn\": 1152, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9022154316271963, \"tn_rate\": 0.8408378455400399, \"fp_rate\": 0.1591621544599601, \"fn_rate\": 0.09778456837280367, \"precision\": 0.9049037970372893, \"recall\": 0.9022154316271963, \"specificity\": 0.8408378455400399, \"npv\": 0.836665248830285, \"accuracy\": 0.8793020905367307, \"f1\": 0.9035576146555022, \"f2\": 0.9027518260574147, \"f0_5\": 0.9043648430188037, \"p4\": 0.8699465424125425, \"phi\": 0.7423107905572177}, {\"truth_threshold\": -6.38, \"match_probability\": 0.011864383629272682, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10628, \"tn\": 5902, \"fp\": 1116, \"fn\": 1153, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9021305491893727, \"tn_rate\": 0.840980336278142, \"fp_rate\": 0.15901966372185808, \"fn_rate\": 0.09786945081062728, \"precision\": 0.9049727520435967, \"recall\": 0.9021305491893727, \"specificity\": 0.840980336278142, \"npv\": 0.8365698086463501, \"accuracy\": 0.8793020905367307, \"f1\": 0.9035494155154091, \"f2\": 0.9026975606441531, \"f0_5\": 0.9044028796568919, \"p4\": 0.8699550685744802, \"phi\": 0.7423263089007115}, {\"truth_threshold\": -6.36, \"match_probability\": 0.012028012165892355, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10626, \"tn\": 5908, \"fp\": 1110, \"fn\": 1155, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9019607843137255, \"tn_rate\": 0.8418352807067541, \"fp_rate\": 0.15816471929324594, \"fn_rate\": 0.09803921568627451, \"precision\": 0.9054192229038854, \"recall\": 0.9019607843137255, \"specificity\": 0.8418352807067541, \"npv\": 0.8364717542120912, \"accuracy\": 0.8795148678121176, \"f1\": 0.9036866947314709, \"f2\": 0.9026503567787971, \"f0_5\": 0.9047254150702426, \"p4\": 0.8702207435764613, \"phi\": 0.7428429103471756}, {\"truth_threshold\": -6.34, \"match_probability\": 0.012193869549496904, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10617, \"tn\": 5908, \"fp\": 1110, \"fn\": 1164, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.901196842373313, \"tn_rate\": 0.8418352807067541, \"fp_rate\": 0.15816471929324594, \"fn_rate\": 0.09880315762668704, \"precision\": 0.9053466359682784, \"recall\": 0.901196842373313, \"specificity\": 0.8418352807067541, \"npv\": 0.8354072398190046, \"accuracy\": 0.8790361189424969, \"f1\": 0.9032669729453803, \"f2\": 0.9020237549064587, \"f0_5\": 0.904513622655012, \"p4\": 0.8697379121738841, \"phi\": 0.7418921249117105}, {\"truth_threshold\": -6.32, \"match_probability\": 0.012361985366952384, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10614, \"tn\": 5909, \"fp\": 1109, \"fn\": 1167, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9009421950598421, \"tn_rate\": 0.8419777714448561, \"fp_rate\": 0.15802222855514392, \"fn_rate\": 0.09905780494015788, \"precision\": 0.9053996417299326, \"recall\": 0.9009421950598421, \"specificity\": 0.8419777714448561, \"npv\": 0.8350763143018655, \"accuracy\": 0.8789297303048035, \"f1\": 0.9031654186521443, \"f2\": 0.9018301697622648, \"f0_5\": 0.9045046273413666, \"p4\": 0.8696391512262396, \"phi\": 0.7416969545930991}, {\"truth_threshold\": -6.3, \"match_probability\": 0.01253238957641751, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10611, \"tn\": 5910, \"fp\": 1108, \"fn\": 1170, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9006875477463713, \"tn_rate\": 0.8421202621829581, \"fp_rate\": 0.1578797378170419, \"fn_rate\": 0.09931245225362872, \"precision\": 0.9054526836760816, \"recall\": 0.9006875477463713, \"specificity\": 0.8421202621829581, \"npv\": 0.8347457627118644, \"accuracy\": 0.87882334166711, \"f1\": 0.9030638297872341, \"f2\": 0.901636558299203, \"f0_5\": 0.9044956271203778, \"p4\": 0.8695404035785247, \"phi\": 0.7415019803577885}, {\"truth_threshold\": -6.28, \"match_probability\": 0.01270511251140324, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10611, \"tn\": 5911, \"fp\": 1107, \"fn\": 1170, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9006875477463713, \"tn_rate\": 0.8422627529210601, \"fp_rate\": 0.15773724707893988, \"fn_rate\": 0.09931245225362872, \"precision\": 0.9055299539170507, \"recall\": 0.9006875477463713, \"specificity\": 0.8422627529210601, \"npv\": 0.8347691004095467, \"accuracy\": 0.8788765359859567, \"f1\": 0.9031022596706243, \"f2\": 0.9016518813092689, \"f0_5\": 0.9045573116464631, \"p4\": 0.8696025267012687, \"phi\": 0.7416234927480121}, {\"truth_threshold\": -6.26, \"match_probability\": 0.012880184884859674, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10608, \"tn\": 5911, \"fp\": 1107, \"fn\": 1173, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9004329004329005, \"tn_rate\": 0.8422627529210601, \"fp_rate\": 0.15773724707893988, \"fn_rate\": 0.09956709956709957, \"precision\": 0.9055057618437901, \"recall\": 0.9004329004329005, \"specificity\": 0.8422627529210601, \"npv\": 0.8344155844155844, \"accuracy\": 0.8787169530294164, \"f1\": 0.9029622063329928, \"f2\": 0.9014429205119053, \"f0_5\": 0.9044866219880289, \"p4\": 0.8694416691978746, \"phi\": 0.74130720196869}, {\"truth_threshold\": -6.24, \"match_probability\": 0.013057637793289553, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10606, \"tn\": 5924, \"fp\": 1094, \"fn\": 1175, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.9002631355572532, \"tn_rate\": 0.8441151325163865, \"fp_rate\": 0.15588486748361358, \"fn_rate\": 0.09973686444274679, \"precision\": 0.9064957264957265, \"recall\": 0.9002631355572532, \"specificity\": 0.8441151325163865, \"npv\": 0.8344837301028314, \"accuracy\": 0.8793020905367307, \"f1\": 0.9033686810612835, \"f2\": 0.9015027879776962, \"f0_5\": 0.905242314060873, \"p4\": 0.8701414517081485, \"phi\": 0.7426769180343369}, {\"truth_threshold\": -6.22, \"match_probability\": 0.013237502720888259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10599, \"tn\": 5924, \"fp\": 1094, \"fn\": 1182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.899668958492488, \"tn_rate\": 0.8441151325163865, \"fp_rate\": 0.15588486748361358, \"fn_rate\": 0.1003310415075121, \"precision\": 0.9064397502779441, \"recall\": 0.899668958492488, \"specificity\": 0.8441151325163865, \"npv\": 0.8336616943428089, \"accuracy\": 0.8789297303048035, \"f1\": 0.9030416631166397, \"f2\": 0.9010150126664059, \"f0_5\": 0.9050774511980598, \"p4\": 0.8697661892884067, \"phi\": 0.7419404829510258}, {\"truth_threshold\": -6.2, \"match_probability\": 0.013419811543709683, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10592, \"tn\": 5924, \"fp\": 1094, \"fn\": 1189, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8990747814277226, \"tn_rate\": 0.8441151325163865, \"fp_rate\": 0.15588486748361358, \"fn_rate\": 0.10092521857227739, \"precision\": 0.9063837069998288, \"recall\": 0.8990747814277226, \"specificity\": 0.8441151325163865, \"npv\": 0.8328412765359201, \"accuracy\": 0.8785573700728763, \"f1\": 0.9027144500788341, \"f2\": 0.9005271212378847, \"f0_5\": 0.90491243058522, \"p4\": 0.8693910501657014, \"phi\": 0.7412047975419942}, {\"truth_threshold\": -6.18, \"match_probability\": 0.013604596533857708, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10592, \"tn\": 5925, \"fp\": 1093, \"fn\": 1189, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8990747814277226, \"tn_rate\": 0.8442576232544885, \"fp_rate\": 0.15574237674551153, \"fn_rate\": 0.10092521857227739, \"precision\": 0.9064612751390672, \"recall\": 0.8990747814277226, \"specificity\": 0.8442576232544885, \"npv\": 0.8328647736856902, \"accuracy\": 0.8786105643917229, \"f1\": 0.9027529191170204, \"f2\": 0.9005424339811934, \"f0_5\": 0.9049742827361118, \"p4\": 0.8694530770987422, \"phi\": 0.7413265203114648}, {\"truth_threshold\": -6.16, \"match_probability\": 0.013791890363702633, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10584, \"tn\": 5925, \"fp\": 1093, \"fn\": 1197, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8983957219251337, \"tn_rate\": 0.8442576232544885, \"fp_rate\": 0.15574237674551153, \"fn_rate\": 0.10160427807486631, \"precision\": 0.9063971910593475, \"recall\": 0.8983957219251337, \"specificity\": 0.8442576232544885, \"npv\": 0.8319292333614153, \"accuracy\": 0.8781850098409489, \"f1\": 0.9023787194134197, \"f2\": 0.8999846941378548, \"f0_5\": 0.9047855152250851, \"p4\": 0.8690244926309667, \"phi\": 0.7404867243445955}, {\"truth_threshold\": -6.12, \"match_probability\": 0.01417413725876712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10584, \"tn\": 5928, \"fp\": 1090, \"fn\": 1197, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8983957219251337, \"tn_rate\": 0.8446850954687946, \"fp_rate\": 0.15531490453120547, \"fn_rate\": 0.10160427807486631, \"precision\": 0.9066301182114099, \"recall\": 0.8983957219251337, \"specificity\": 0.8446850954687946, \"npv\": 0.832, \"accuracy\": 0.8783445927974892, \"f1\": 0.9024941377105095, \"f2\": 0.9000306132861662, \"f0_5\": 0.9049711852523215, \"p4\": 0.8692105231658871, \"phi\": 0.7408521255907338}, {\"truth_threshold\": -6.1000000000000005, \"match_probability\": 0.014369157708348785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10580, \"tn\": 5928, \"fp\": 1090, \"fn\": 1201, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8980561921738393, \"tn_rate\": 0.8446850954687946, \"fp_rate\": 0.15531490453120547, \"fn_rate\": 0.10194380782616076, \"precision\": 0.9065981148243359, \"recall\": 0.8980561921738393, \"specificity\": 0.8446850954687946, \"npv\": 0.831533174358255, \"accuracy\": 0.8781318155221023, \"f1\": 0.9023069378704532, \"f2\": 0.8997516753410212, \"f0_5\": 0.9048767554438001, \"p4\": 0.8689962840360251, \"phi\": 0.7404327006398318}, {\"truth_threshold\": -6.08, \"match_probability\": 0.01456682177495178, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10575, \"tn\": 5930, \"fp\": 1088, \"fn\": 1206, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8976317799847212, \"tn_rate\": 0.8449700769449986, \"fp_rate\": 0.15502992305500143, \"fn_rate\": 0.10236822001527884, \"precision\": 0.9067135385406843, \"recall\": 0.8976317799847212, \"specificity\": 0.8449700769449986, \"npv\": 0.8309977578475336, \"accuracy\": 0.877972232565562, \"f1\": 0.9021498037877496, \"f2\": 0.899433548233453, \"f0_5\": 0.9048825150171992, \"p4\": 0.8688525209102677, \"phi\": 0.7401525373704542}, {\"truth_threshold\": -6.0600000000000005, \"match_probability\": 0.014767164196367252, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10570, \"tn\": 5932, \"fp\": 1086, \"fn\": 1211, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8972073677956031, \"tn_rate\": 0.8452550584212026, \"fp_rate\": 0.15474494157879737, \"fn_rate\": 0.10279263220439691, \"precision\": 0.9068291008922443, \"recall\": 0.8972073677956031, \"specificity\": 0.8452550584212026, \"npv\": 0.8304633907321853, \"accuracy\": 0.8778126496090217, \"f1\": 0.901992575841618, \"f2\": 0.8991153453555631, \"f0_5\": 0.904888280113004, \"p4\": 0.8687087842115814, \"phi\": 0.7398729432564134}, {\"truth_threshold\": -6.04, \"match_probability\": 0.014970220136448715, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10567, \"tn\": 5933, \"fp\": 1085, \"fn\": 1214, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8969527204821323, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.10304727951786775, \"precision\": 0.9068829385513216, \"recall\": 0.8969527204821323, \"specificity\": 0.8453975491593047, \"npv\": 0.830138519658598, \"accuracy\": 0.8777062609713283, \"f1\": 0.9018904963086246, \"f2\": 0.8989213284333741, \"f0_5\": 0.9048793437120005, \"p4\": 0.8686101627454339, \"phi\": 0.7396810652123379}, {\"truth_threshold\": -6.0200000000000005, \"match_probability\": 0.015176025189488596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10563, \"tn\": 5933, \"fp\": 1085, \"fn\": 1218, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8966131907308378, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.10338680926916222, \"precision\": 0.9068509615384616, \"recall\": 0.8966131907308378, \"specificity\": 0.8453975491593047, \"npv\": 0.8296741714445532, \"accuracy\": 0.8774934836959413, \"f1\": 0.9017030176277263, \"f2\": 0.898642210576465, \"f0_5\": 0.9047847463724668, \"p4\": 0.8683960812412164, \"phi\": 0.7392628482971482}, {\"truth_threshold\": -6.0, \"match_probability\": 0.015384615384615385, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10561, \"tn\": 5933, \"fp\": 1085, \"fn\": 1220, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8964434258551905, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.10355657414480944, \"precision\": 0.9068349647947793, \"recall\": 0.8964434258551905, \"specificity\": 0.8453975491593047, \"npv\": 0.8294421920872361, \"accuracy\": 0.8773870950582477, \"f1\": 0.9016092542792504, \"f2\": 0.898502637400034, \"f0_5\": 0.904737428253234, \"p4\": 0.868289055370911, \"phi\": 0.7390538302060647}, {\"truth_threshold\": -5.98, \"match_probability\": 0.01559602719021019, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10559, \"tn\": 5933, \"fp\": 1085, \"fn\": 1222, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8962736609795433, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.10372633902045666, \"precision\": 0.9068189625558227, \"recall\": 0.8962736609795433, \"specificity\": 0.8453975491593047, \"npv\": 0.8292103424178896, \"accuracy\": 0.8772807064205543, \"f1\": 0.9015154749199573, \"f2\": 0.8983630547236592, \"f0_5\": 0.9046900971605806, \"p4\": 0.8681820394125649, \"phi\": 0.7388448722956047}, {\"truth_threshold\": -5.96, \"match_probability\": 0.015810297518342384, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10551, \"tn\": 5933, \"fp\": 1085, \"fn\": 1230, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8955946014769545, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.10440539852304558, \"precision\": 0.906754898590581, \"recall\": 0.8955946014769545, \"specificity\": 0.8453975491593047, \"npv\": 0.8282842384475778, \"accuracy\": 0.8768551518697804, \"f1\": 0.9011401972925652, \"f2\": 0.8978046289993192, \"f0_5\": 0.9045006429489927, \"p4\": 0.8677540745601303, \"phi\": 0.7380096415059394}, {\"truth_threshold\": -5.94, \"match_probability\": 0.016027463729223174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10550, \"tn\": 5933, \"fp\": 1085, \"fn\": 1231, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8955097190391308, \"tn_rate\": 0.8453975491593047, \"fp_rate\": 0.15460245084069535, \"fn_rate\": 0.1044902809608692, \"precision\": 0.9067468844005157, \"recall\": 0.8955097190391308, \"specificity\": 0.8453975491593047, \"npv\": 0.8281686208821887, \"accuracy\": 0.8768019575509336, \"f1\": 0.9010932695592757, \"f2\": 0.8977348150921561, \"f0_5\": 0.9044769465544144, \"p4\": 0.8677005900746342, \"phi\": 0.7379053051548561}, {\"truth_threshold\": -5.92, \"match_probability\": 0.016247563635676584, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10547, \"tn\": 5937, \"fp\": 1081, \"fn\": 1234, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.89525507172566, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10474492827434004, \"precision\": 0.9070347437220502, \"recall\": 0.89525507172566, \"specificity\": 0.8459675121117127, \"npv\": 0.8279180030679124, \"accuracy\": 0.8768551518697804, \"f1\": 0.9011064120637362, \"f2\": 0.8975864651416122, \"f0_5\": 0.9046540751033572, \"p4\": 0.8677878995345386, \"phi\": 0.7380810077315568}, {\"truth_threshold\": -5.9, \"match_probability\": 0.016470635507626726, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10545, \"tn\": 5937, \"fp\": 1081, \"fn\": 1236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8950853068500128, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10491469314998726, \"precision\": 0.9070187510751764, \"recall\": 0.8950853068500128, \"specificity\": 0.8459675121117127, \"npv\": 0.8276871601840234, \"accuracy\": 0.8767487632320868, \"f1\": 0.9010125176229333, \"f2\": 0.8974468085106383, \"f0_5\": 0.9046066741013983, \"p4\": 0.8676809479640403, \"phi\": 0.7378725409218542}, {\"truth_threshold\": -5.88, \"match_probability\": 0.016696718076600735, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10539, \"tn\": 5937, \"fp\": 1081, \"fn\": 1242, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.894576012223071, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10542398777692895, \"precision\": 0.9069707401032703, \"recall\": 0.894576012223071, \"specificity\": 0.8459675121117127, \"npv\": 0.8269954032595069, \"accuracy\": 0.8764295973190064, \"f1\": 0.9007307380026495, \"f2\": 0.89702778156067, \"f0_5\": 0.9044643929901649, \"p4\": 0.8673601523070628, \"phi\": 0.7372474988416577}, {\"truth_threshold\": -5.86, \"match_probability\": 0.0169258505402461, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10538, \"tn\": 5937, \"fp\": 1081, \"fn\": 1243, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8944911297852475, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10550887021475257, \"precision\": 0.9069627334538256, \"recall\": 0.8944911297852475, \"specificity\": 0.8459675121117127, \"npv\": 0.8268802228412256, \"accuracy\": 0.8763764030001596, \"f1\": 0.9006837606837607, \"f2\": 0.8969579354135812, \"f0_5\": 0.9044406680742229, \"p4\": 0.8673066949672522, \"phi\": 0.7371433773587632}, {\"truth_threshold\": -5.84, \"match_probability\": 0.017158072566861807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10523, \"tn\": 5937, \"fp\": 1081, \"fn\": 1258, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8932178932178932, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10678210678210678, \"precision\": 0.9068424681144432, \"recall\": 0.8932178932178932, \"specificity\": 0.8459675121117127, \"npv\": 0.8251563585823488, \"accuracy\": 0.8755784882174584, \"f1\": 0.8999786187727176, \"f2\": 0.8959099577714208, \"f0_5\": 0.9040844029760984, \"p4\": 0.8665051290681741, \"phi\": 0.7355833395426138}, {\"truth_threshold\": -5.82, \"match_probability\": 0.017393424299941902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10521, \"tn\": 5937, \"fp\": 1081, \"fn\": 1260, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.893048128342246, \"tn_rate\": 0.8459675121117127, \"fp_rate\": 0.15403248788828727, \"fn_rate\": 0.10695187165775401, \"precision\": 0.9068264092397862, \"recall\": 0.893048128342246, \"specificity\": 0.8459675121117127, \"npv\": 0.8249270529387245, \"accuracy\": 0.8754720995797649, \"f1\": 0.8998845314972416, \"f2\": 0.8957701869699962, \"f0_5\": 0.9040368454518896, \"p4\": 0.8663982952046274, \"phi\": 0.7353755866944821}, {\"truth_threshold\": -5.8, \"match_probability\": 0.017631946362730785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10512, \"tn\": 5939, \"fp\": 1079, \"fn\": 1269, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8922841864018335, \"tn_rate\": 0.8462524935879168, \"fp_rate\": 0.1537475064120832, \"fn_rate\": 0.10771581359816654, \"precision\": 0.9069105340350272, \"recall\": 0.8922841864018335, \"specificity\": 0.8462524935879168, \"npv\": 0.8239456159822419, \"accuracy\": 0.8750997393478377, \"f1\": 0.8995379086085915, \"f2\": 0.8951715915864771, \"f0_5\": 0.9039470289792759, \"p4\": 0.866041458918574, \"phi\": 0.7346863783845763}, {\"truth_threshold\": -5.78, \"match_probability\": 0.01787367986278876, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10507, \"tn\": 5939, \"fp\": 1079, \"fn\": 1274, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8918597742127153, \"tn_rate\": 0.8462524935879168, \"fp_rate\": 0.1537475064120832, \"fn_rate\": 0.1081402257872846, \"precision\": 0.9068703607802521, \"recall\": 0.8918597742127153, \"specificity\": 0.8462524935879168, \"npv\": 0.8233744627755442, \"accuracy\": 0.8748337677536039, \"f1\": 0.8993024350579878, \"f2\": 0.8948220064724919, \"f0_5\": 0.9038279569892473, \"p4\": 0.8657745203263262, \"phi\": 0.734168007178494}, {\"truth_threshold\": -5.76, \"match_probability\": 0.018118666396567108, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10503, \"tn\": 5953, \"fp\": 1065, \"fn\": 1278, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.891520244461421, \"tn_rate\": 0.8482473639213451, \"fp_rate\": 0.15175263607865488, \"fn_rate\": 0.10847975553857907, \"precision\": 0.9079356846473029, \"recall\": 0.891520244461421, \"specificity\": 0.8482473639213451, \"npv\": 0.8232609597566035, \"accuracy\": 0.8753657109420714, \"f1\": 0.8996530900680971, \"f2\": 0.8947556736863627, \"f0_5\": 0.9046044132086197, \"p4\": 0.8664268333804, \"phi\": 0.7354696410377397}, {\"truth_threshold\": -5.74, \"match_probability\": 0.018366948053991125, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10499, \"tn\": 5953, \"fp\": 1065, \"fn\": 1282, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8911807147101265, \"tn_rate\": 0.8482473639213451, \"fp_rate\": 0.15175263607865488, \"fn_rate\": 0.10881928528987353, \"precision\": 0.9079038395019025, \"recall\": 0.8911807147101265, \"specificity\": 0.8482473639213451, \"npv\": 0.822805805114029, \"accuracy\": 0.8751529336666845, \"f1\": 0.8994645534375669, \"f2\": 0.8944758724100327, \"f0_5\": 0.9045091924117373, \"p4\": 0.8662133301497615, \"phi\": 0.7350559356646564}, {\"truth_threshold\": -5.72, \"match_probability\": 0.018618567423050236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10496, \"tn\": 5955, \"fp\": 1063, \"fn\": 1285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8909260673966556, \"tn_rate\": 0.8485323453975492, \"fp_rate\": 0.15146765460245085, \"fn_rate\": 0.10907393260334437, \"precision\": 0.9080370274245176, \"recall\": 0.8909260673966556, \"specificity\": 0.8485323453975492, \"npv\": 0.8225138121546961, \"accuracy\": 0.8750997393478377, \"f1\": 0.8994001713796058, \"f2\": 0.8942964742770478, \"f0_5\": 0.9045624558319113, \"p4\": 0.8661768126977426, \"phi\": 0.7349911321238639}, {\"truth_threshold\": -5.7, \"match_probability\": 0.018873567594393605, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10495, \"tn\": 5957, \"fp\": 1061, \"fn\": 1286, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.890841184958832, \"tn_rate\": 0.8488173268737532, \"fp_rate\": 0.15118267312624678, \"fn_rate\": 0.10915881504116798, \"precision\": 0.9081862236067844, \"recall\": 0.890841184958832, \"specificity\": 0.8488173268737532, \"npv\": 0.8224492613557918, \"accuracy\": 0.8751529336666845, \"f1\": 0.8994300895573553, \"f2\": 0.8942569870483981, \"f0_5\": 0.9046633910869752, \"p4\": 0.8662470085667383, \"phi\": 0.735133154945074}, {\"truth_threshold\": -5.66, \"match_probability\": 0.019393885247431873, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10492, \"tn\": 5957, \"fp\": 1061, \"fn\": 1289, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8905865376453612, \"tn_rate\": 0.8488173268737532, \"fp_rate\": 0.15118267312624678, \"fn_rate\": 0.10941346235463882, \"precision\": 0.9081623820652645, \"recall\": 0.8905865376453612, \"specificity\": 0.8488173268737532, \"npv\": 0.822108749654982, \"accuracy\": 0.8749933507101442, \"f1\": 0.8992885917545212, \"f2\": 0.8940470712544949, \"f0_5\": 0.9045919335092166, \"p4\": 0.8660869279156508, \"phi\": 0.7348233100145214}, {\"truth_threshold\": -5.64, \"match_probability\": 0.019659291465137646, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10475, \"tn\": 5958, \"fp\": 1060, \"fn\": 1306, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8891435362023598, \"tn_rate\": 0.8489598176118552, \"fp_rate\": 0.15104018238814476, \"fn_rate\": 0.11085646379764026, \"precision\": 0.9081057650628522, \"recall\": 0.8891435362023598, \"specificity\": 0.8489598176118552, \"npv\": 0.8202092511013216, \"accuracy\": 0.8741422416085962, \"f1\": 0.898524618287871, \"f2\": 0.8928723640021139, \"f0_5\": 0.9042488907304778, \"p4\": 0.8652419706292247, \"phi\": 0.7331928505270839}, {\"truth_threshold\": -5.62, \"match_probability\": 0.019928255966358603, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10472, \"tn\": 5958, \"fp\": 1060, \"fn\": 1309, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8888888888888888, \"tn_rate\": 0.8489598176118552, \"fp_rate\": 0.15104018238814476, \"fn_rate\": 0.1111111111111111, \"precision\": 0.908081859174471, \"recall\": 0.8888888888888888, \"specificity\": 0.8489598176118552, \"npv\": 0.8198706481354067, \"accuracy\": 0.8739826586520559, \"f1\": 0.8983828765066701, \"f2\": 0.8926623022367703, \"f0_5\": 0.9041772436063479, \"p4\": 0.8650820318807868, \"phi\": 0.7328839034339386}, {\"truth_threshold\": -5.6000000000000005, \"match_probability\": 0.02020082442408101, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10471, \"tn\": 5959, \"fp\": 1059, \"fn\": 1310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8888040064510653, \"tn_rate\": 0.8491023083499573, \"fp_rate\": 0.15089769165004274, \"fn_rate\": 0.11119599354893472, \"precision\": 0.9081526452732004, \"recall\": 0.8888040064510653, \"specificity\": 0.8491023083499573, \"npv\": 0.8197826386022836, \"accuracy\": 0.8739826586520559, \"f1\": 0.8983741581227747, \"f2\": 0.8926074948000137, \"f0_5\": 0.9042158166525621, \"p4\": 0.8650904736817854, \"phi\": 0.7329038427639704}, {\"truth_threshold\": -5.58, \"match_probability\": 0.02047704304156655, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10470, \"tn\": 5973, \"fp\": 1045, \"fn\": 1311, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8887191240132417, \"tn_rate\": 0.8510971786833855, \"fp_rate\": 0.14890282131661442, \"fn_rate\": 0.11128087598675834, \"precision\": 0.9092488059053409, \"recall\": 0.8887191240132417, \"specificity\": 0.8510971786833855, \"npv\": 0.8200164744645799, \"accuracy\": 0.8746741847970637, \"f1\": 0.8988667582417582, \"f2\": 0.8927505585020208, \"f0_5\": 0.9050673397762833, \"p4\": 0.8659010382079414, \"phi\": 0.7345218467876188}, {\"truth_threshold\": -5.54, \"match_probability\": 0.02104061824781806, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10470, \"tn\": 5975, \"fp\": 1043, \"fn\": 1311, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8887191240132417, \"tn_rate\": 0.8513821601595897, \"fp_rate\": 0.14861783984041038, \"fn_rate\": 0.11128087598675834, \"precision\": 0.9094067575783896, \"recall\": 0.8887191240132417, \"specificity\": 0.8513821601595897, \"npv\": 0.8200658797694208, \"accuracy\": 0.8747805734347571, \"f1\": 0.8989439340602731, \"f2\": 0.8927810085782015, \"f0_5\": 0.9051925371327789, \"p4\": 0.8660243542246673, \"phi\": 0.7347677426711495}, {\"truth_threshold\": -5.5200000000000005, \"match_probability\": 0.021328069935811763, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10466, \"tn\": 5975, \"fp\": 1043, \"fn\": 1315, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8883795942619472, \"tn_rate\": 0.8513821601595897, \"fp_rate\": 0.14861783984041038, \"fn_rate\": 0.11162040573805279, \"precision\": 0.9093752715266313, \"recall\": 0.8883795942619472, \"specificity\": 0.8513821601595897, \"npv\": 0.8196159122085048, \"accuracy\": 0.8745677961593702, \"f1\": 0.898754830399313, \"f2\": 0.8925008101239916, \"f0_5\": 0.9050971167649653, \"p4\": 0.8658111119728314, \"phi\": 0.7343567232876249}, {\"truth_threshold\": -5.5, \"match_probability\": 0.021619361991176866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10463, \"tn\": 5977, \"fp\": 1041, \"fn\": 1318, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8881249469484763, \"tn_rate\": 0.8516671416357937, \"fp_rate\": 0.14833285836420632, \"fn_rate\": 0.11187505305152363, \"precision\": 0.909509735744089, \"recall\": 0.8881249469484763, \"specificity\": 0.8516671416357937, \"npv\": 0.8193283070596299, \"accuracy\": 0.8745146018405234, \"f1\": 0.8986901438694439, \"f2\": 0.8923210752541447, \"f0_5\": 0.9051507863729952, \"p4\": 0.8657744889197976, \"phi\": 0.7342946397226625}, {\"truth_threshold\": -5.48, \"match_probability\": 0.021914543337334162, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10462, \"tn\": 5979, \"fp\": 1039, \"fn\": 1319, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8880400645106528, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11195993548934725, \"precision\": 0.9096600295626467, \"recall\": 0.8880400645106528, \"specificity\": 0.8519521231119978, \"npv\": 0.8192655522060839, \"accuracy\": 0.8745677961593702, \"f1\": 0.898720041233571, \"f2\": 0.8922814498933902, \"f0_5\": 0.9052522280868738, \"p4\": 0.865844449180691, \"phi\": 0.734438040863323}, {\"truth_threshold\": -5.44, \"match_probability\": 0.02251677238883578, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10405, \"tn\": 5979, \"fp\": 1039, \"fn\": 1376, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8832017655547068, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11679823444529328, \"precision\": 0.9092100664103461, \"recall\": 0.8832017655547068, \"specificity\": 0.8519521231119978, \"npv\": 0.8129163834126445, \"accuracy\": 0.8715357199851056, \"f1\": 0.8960172228202368, \"f2\": 0.8882837044119656, \"f0_5\": 0.9038865819969769, \"p4\": 0.8628102292355825, \"phi\": 0.7286110537841526}, {\"truth_threshold\": -5.42, \"match_probability\": 0.02282392074772345, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10393, \"tn\": 5979, \"fp\": 1039, \"fn\": 1388, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8821831763008233, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11781682369917663, \"precision\": 0.9091147655703289, \"recall\": 0.8821831763008233, \"specificity\": 0.8519521231119978, \"npv\": 0.8115922356454459, \"accuracy\": 0.8708973881589446, \"f1\": 0.8954465170378667, \"f2\": 0.887441082041123, \"f0_5\": 0.9035976977516562, \"p4\": 0.8621724102650937, \"phi\": 0.7273901636167892}, {\"truth_threshold\": -5.4, \"match_probability\": 0.023135159713496674, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10390, \"tn\": 5979, \"fp\": 1039, \"fn\": 1391, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8819285289873525, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11807147101264748, \"precision\": 0.9090909090909091, \"recall\": 0.8819285289873525, \"specificity\": 0.8519521231119978, \"npv\": 0.8112618724559023, \"accuracy\": 0.8707378052024044, \"f1\": 0.8953037483843171, \"f2\": 0.8872303724830496, \"f0_5\": 0.9035254013252866, \"p4\": 0.8620130074555639, \"phi\": 0.7270852557046903}, {\"truth_threshold\": -5.38, \"match_probability\": 0.023450541043293725, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10388, \"tn\": 5979, \"fp\": 1039, \"fn\": 1393, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8817587641117053, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11824123588829472, \"precision\": 0.9090749978121991, \"recall\": 0.8817587641117053, \"specificity\": 0.8519521231119978, \"npv\": 0.8110417797069994, \"accuracy\": 0.8706314165647109, \"f1\": 0.8952085487762841, \"f2\": 0.8870898874485491, \"f0_5\": 0.9034771869401103, \"p4\": 0.861906750432009, \"phi\": 0.726882053526076}, {\"truth_threshold\": -5.36, \"match_probability\": 0.023770117074428793, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10385, \"tn\": 5979, \"fp\": 1039, \"fn\": 1396, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8815041167982345, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11849588320176556, \"precision\": 0.9090511204481793, \"recall\": 0.8815041167982345, \"specificity\": 0.8519521231119978, \"npv\": 0.8107118644067797, \"accuracy\": 0.8704718336081706, \"f1\": 0.8950657185951304, \"f2\": 0.8868791419006627, \"f0_5\": 0.9034048401969483, \"p4\": 0.8617473821535387, \"phi\": 0.7265773547932}, {\"truth_threshold\": -5.34, \"match_probability\": 0.024093940728813348, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10379, \"tn\": 5979, \"fp\": 1039, \"fn\": 1402, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8809948221712928, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11900517782870725, \"precision\": 0.9090033280784726, \"recall\": 0.8809948221712928, \"specificity\": 0.8519521231119978, \"npv\": 0.8100528383687847, \"accuracy\": 0.8701526676950901, \"f1\": 0.8947799474115263, \"f2\": 0.8864575860066277, \"f0_5\": 0.9032600560458114, \"p4\": 0.8614287076354806, \"phi\": 0.7259683331142142}, {\"truth_threshold\": -5.32, \"match_probability\": 0.024422065517348556, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10377, \"tn\": 5979, \"fp\": 1039, \"fn\": 1404, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8808250572956455, \"tn_rate\": 0.8519521231119978, \"fp_rate\": 0.14804787688800228, \"fn_rate\": 0.11917494270435447, \"precision\": 0.9089873861247372, \"recall\": 0.8808250572956455, \"specificity\": 0.8519521231119978, \"npv\": 0.809833401056481, \"accuracy\": 0.8700462790573966, \"f1\": 0.8946846574988145, \"f2\": 0.8863170481721899, \"f0_5\": 0.9032117677778745, \"p4\": 0.8613225011525886, \"phi\": 0.725765437072513}, {\"truth_threshold\": -5.3, \"match_probability\": 0.024754545544286844, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10369, \"tn\": 6466, \"fp\": 552, \"fn\": 1412, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8801459977930566, \"tn_rate\": 0.9213451125676831, \"fp_rate\": 0.0786548874323169, \"fn_rate\": 0.11985400220694338, \"precision\": 0.9494551780972439, \"recall\": 0.8801459977930566, \"specificity\": 0.9213451125676831, \"npv\": 0.8207666920538208, \"accuracy\": 0.8955263577849886, \"f1\": 0.9134877984318562, \"f2\": 0.8931863209578775, \"f0_5\": 0.9347336157937438, \"p4\": 0.8902433649995388, \"phi\": 0.7857009494276447}, {\"truth_threshold\": -5.28, \"match_probability\": 0.0250914355115595, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10367, \"tn\": 6466, \"fp\": 552, \"fn\": 1414, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8799762329174093, \"tn_rate\": 0.9213451125676831, \"fp_rate\": 0.0786548874323169, \"fn_rate\": 0.12002376708259062, \"precision\": 0.9494459199560399, \"recall\": 0.8799762329174093, \"specificity\": 0.9213451125676831, \"npv\": 0.8205583756345177, \"accuracy\": 0.895419969147295, \"f1\": 0.9133920704845815, \"f2\": 0.8930448116051892, \"f0_5\": 0.9346881367546027, \"p4\": 0.8901366292815734, \"phi\": 0.7855067651980641}, {\"truth_threshold\": -5.26, \"match_probability\": 0.02543279072306829, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10366, \"tn\": 6466, \"fp\": 552, \"fn\": 1415, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8798913504795858, \"tn_rate\": 0.9213451125676831, \"fp_rate\": 0.0786548874323169, \"fn_rate\": 0.12010864952041422, \"precision\": 0.9494412896134823, \"recall\": 0.8798913504795858, \"specificity\": 0.9213451125676831, \"npv\": 0.8204542570739753, \"accuracy\": 0.8953667748284483, \"f1\": 0.9133442001850302, \"f2\": 0.8929740532717687, \"f0_5\": 0.9346653923142121, \"p4\": 0.8900832644433955, \"phi\": 0.7854096922904008}, {\"truth_threshold\": -5.24, \"match_probability\": 0.025778667088937956, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10366, \"tn\": 6467, \"fp\": 551, \"fn\": 1415, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8798913504795858, \"tn_rate\": 0.9214876033057852, \"fp_rate\": 0.07851239669421488, \"fn_rate\": 0.12010864952041422, \"precision\": 0.9495282586791243, \"recall\": 0.8798913504795858, \"specificity\": 0.9214876033057852, \"npv\": 0.8204770362852069, \"accuracy\": 0.895419969147295, \"f1\": 0.913384439157635, \"f2\": 0.8929894385003704, \"f0_5\": 0.9347328175440495, \"p4\": 0.8901423186349513, \"phi\": 0.7855355101379642}, {\"truth_threshold\": -5.22, \"match_probability\": 0.02612912112972733, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10353, \"tn\": 6473, \"fp\": 545, \"fn\": 1428, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8787878787878788, \"tn_rate\": 0.9223425477343973, \"fp_rate\": 0.07765745226560274, \"fn_rate\": 0.12121212121212122, \"precision\": 0.9499908240044045, \"recall\": 0.8787878787878788, \"specificity\": 0.9223425477343973, \"npv\": 0.8192633843817239, \"accuracy\": 0.8950476089153678, \"f1\": 0.9130032188368093, \"f2\": 0.8921615938781842, \"f0_5\": 0.9348418904520254, \"p4\": 0.889802943178451, \"phi\": 0.7850305421245946}, {\"truth_threshold\": -5.2, \"match_probability\": 0.026484209980595738, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10353, \"tn\": 6474, \"fp\": 544, \"fn\": 1428, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8787878787878788, \"tn_rate\": 0.9224850384724993, \"fp_rate\": 0.07751496152750072, \"fn_rate\": 0.12121212121212122, \"precision\": 0.9500780031201248, \"recall\": 0.8787878787878788, \"specificity\": 0.9224850384724993, \"npv\": 0.8192862566438877, \"accuracy\": 0.8951008032342146, \"f1\": 0.9130434782608695, \"f2\": 0.8921769704072663, \"f0_5\": 0.9349094258520111, \"p4\": 0.8898619592750407, \"phi\": 0.7851565097845025}, {\"truth_threshold\": -5.18, \"match_probability\": 0.026843991395422352, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10347, \"tn\": 6474, \"fp\": 544, \"fn\": 1434, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8782785841609371, \"tn_rate\": 0.9224850384724993, \"fp_rate\": 0.07751496152750072, \"fn_rate\": 0.1217214158390629, \"precision\": 0.9500505004131852, \"recall\": 0.8782785841609371, \"specificity\": 0.9224850384724993, \"npv\": 0.8186646433990895, \"accuracy\": 0.8947816373211341, \"f1\": 0.9127558221594919, \"f2\": 0.8917521330690339, \"f0_5\": 0.9347727888698166, \"p4\": 0.8895419444763981, \"phi\": 0.7845757600973281}, {\"truth_threshold\": -5.16, \"match_probability\": 0.027208523750875003, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10346, \"tn\": 6481, \"fp\": 537, \"fn\": 1435, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8781937017231135, \"tn_rate\": 0.9234824736392134, \"fp_rate\": 0.07651752636078656, \"fn_rate\": 0.12180629827688651, \"precision\": 0.9506569879628779, \"recall\": 0.8781937017231135, \"specificity\": 0.9234824736392134, \"npv\": 0.8187215765538151, \"accuracy\": 0.8951008032342146, \"f1\": 0.9129897635015884, \"f2\": 0.8917889220266519, \"f0_5\": 0.9352231844231916, \"p4\": 0.8899015777921623, \"phi\": 0.7853613595075197}, {\"truth_threshold\": -5.14, \"match_probability\": 0.0275778660504259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10330, \"tn\": 6481, \"fp\": 537, \"fn\": 1451, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8768355827179357, \"tn_rate\": 0.9234824736392134, \"fp_rate\": 0.07651752636078656, \"fn_rate\": 0.12316441728206434, \"precision\": 0.9505843379037453, \"recall\": 0.8768355827179357, \"specificity\": 0.9234824736392134, \"npv\": 0.8170700958144226, \"accuracy\": 0.8942496941326666, \"f1\": 0.9122218297421406, \"f2\": 0.8906554465348071, \"f0_5\": 0.9348585494760087, \"p4\": 0.8890485296511675, \"phi\": 0.7838161164120524}, {\"truth_threshold\": -5.12, \"match_probability\": 0.027952077928310608, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10323, \"tn\": 6482, \"fp\": 536, \"fn\": 1458, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8762414056531703, \"tn_rate\": 0.9236249643773154, \"fp_rate\": 0.07637503562268452, \"fn_rate\": 0.12375859434682965, \"precision\": 0.9506400221014827, \"recall\": 0.8762414056531703, \"specificity\": 0.9236249643773154, \"npv\": 0.8163727959697733, \"accuracy\": 0.8939305282195862, \"f1\": 0.9119257950530035, \"f2\": 0.8901747063794561, \"f0_5\": 0.9347664668489777, \"p4\": 0.8887344451234619, \"phi\": 0.7832673608401597}, {\"truth_threshold\": -5.1000000000000005, \"match_probability\": 0.028331219653427598, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10322, \"tn\": 6628, \"fp\": 390, \"fn\": 1459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8761565232153468, \"tn_rate\": 0.9444286121402109, \"fp_rate\": 0.055571387859789115, \"fn_rate\": 0.12384347678465325, \"precision\": 0.9635922330097088, \"recall\": 0.8761565232153468, \"specificity\": 0.9444286121402109, \"npv\": 0.8195869914677878, \"accuracy\": 0.9016437044523645, \"f1\": 0.9177966478459966, \"f2\": 0.8923507849782143, \"f0_5\": 0.9447363122151239, \"p4\": 0.8972432271179847, \"phi\": 0.8016640380642799}, {\"truth_threshold\": -5.08, \"match_probability\": 0.02871535213317462, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10317, \"tn\": 6633, \"fp\": 385, \"fn\": 1464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8757321110262287, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.12426788897377132, \"precision\": 0.9640254158101289, \"recall\": 0.8757321110262287, \"specificity\": 0.945141065830721, \"npv\": 0.8191922934420156, \"accuracy\": 0.9016437044523645, \"f1\": 0.9177600853978561, \"f2\": 0.8920727700342407, \"f0_5\": 0.9449705984722196, \"p4\": 0.897268078348951, \"phi\": 0.8018244253977492}, {\"truth_threshold\": -5.0600000000000005, \"match_probability\": 0.029104536917218708, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10315, \"tn\": 6633, \"fp\": 385, \"fn\": 1466, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8755623461505815, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.12443765384941856, \"precision\": 0.9640186915887851, \"recall\": 0.8755623461505815, \"specificity\": 0.945141065830721, \"npv\": 0.8189899987652797, \"accuracy\": 0.901537315814671, \"f1\": 0.9176638049908812, \"f2\": 0.8919306862202546, \"f0_5\": 0.9449258899617082, \"p4\": 0.8971613835562475, \"phi\": 0.8016345200804368}, {\"truth_threshold\": -5.04, \"match_probability\": 0.029498836201196473, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10312, \"tn\": 6633, \"fp\": 385, \"fn\": 1469, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8753076988371106, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.1246923011628894, \"precision\": 0.964008600542208, \"recall\": 0.8753076988371106, \"specificity\": 0.945141065830721, \"npv\": 0.8186867440138238, \"accuracy\": 0.9013777328581307, \"f1\": 0.9175193522555387, \"f2\": 0.8917175420694903, \"f0_5\": 0.9448588026168704, \"p4\": 0.8970013554852597, \"phi\": 0.801349754197416}, {\"truth_threshold\": -5.0200000000000005, \"match_probability\": 0.02989831283034073, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10308, \"tn\": 6633, \"fp\": 385, \"fn\": 1473, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8749681690858161, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.12503183091418385, \"precision\": 0.9639951370055176, \"recall\": 0.8749681690858161, \"specificity\": 0.945141065830721, \"npv\": 0.8182827535159142, \"accuracy\": 0.9011649555827438, \"f1\": 0.9173266886179585, \"f2\": 0.8914333154608506, \"f0_5\": 0.9447693069125438, \"p4\": 0.8967880110424878, \"phi\": 0.800970238078578}, {\"truth_threshold\": -5.0, \"match_probability\": 0.030303030303030304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10306, \"tn\": 6633, \"fp\": 385, \"fn\": 1475, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.874798404210169, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.1252015957898311, \"precision\": 0.9639884014591713, \"recall\": 0.874798404210169, \"specificity\": 0.945141065830721, \"npv\": 0.8180809077454366, \"accuracy\": 0.9010585669450503, \"f1\": 0.9172303310786757, \"f2\": 0.8912911874081121, \"f0_5\": 0.9447245393711614, \"p4\": 0.8966813500853983, \"phi\": 0.8007805535379035}, {\"truth_threshold\": -4.98, \"match_probability\": 0.03071305277425868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10303, \"tn\": 6633, \"fp\": 385, \"fn\": 1478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.874543756896698, \"tn_rate\": 0.945141065830721, \"fp_rate\": 0.054858934169279, \"fn_rate\": 0.12545624310330192, \"precision\": 0.9639782934131736, \"recall\": 0.874543756896698, \"specificity\": 0.945141065830721, \"npv\": 0.8177783257304895, \"accuracy\": 0.90089898398851, \"f1\": 0.9170857626062575, \"f2\": 0.891077976890611, \"f0_5\": 0.9446573634313168, \"p4\": 0.8965213727112811, \"phi\": 0.8004961185282288}, {\"truth_threshold\": -4.96, \"match_probability\": 0.031128445059018316, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10296, \"tn\": 6635, \"fp\": 383, \"fn\": 1485, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8739495798319328, \"tn_rate\": 0.945426047306925, \"fp_rate\": 0.054573952693074954, \"fn_rate\": 0.12605042016806722, \"precision\": 0.964135218653432, \"recall\": 0.8739495798319328, \"specificity\": 0.945426047306925, \"npv\": 0.8171182266009852, \"accuracy\": 0.9006330123942763, \"f1\": 0.9168299198575245, \"f2\": 0.890611213950833, \"f0_5\": 0.9446391544488687, \"p4\": 0.896264752727332, \"phi\": 0.800087515000535}, {\"truth_threshold\": -4.94, \"match_probability\": 0.03154927263559596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10292, \"tn\": 6635, \"fp\": 383, \"fn\": 1489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8736100500806383, \"tn_rate\": 0.945426047306925, \"fp_rate\": 0.054573952693074954, \"fn_rate\": 0.12638994991936167, \"precision\": 0.9641217798594848, \"recall\": 0.8736100500806383, \"specificity\": 0.945426047306925, \"npv\": 0.8167159034958149, \"accuracy\": 0.9004202351188894, \"f1\": 0.9166369789811186, \"f2\": 0.8903268222633609, \"f0_5\": 0.9445494759640976, \"p4\": 0.8960515242400476, \"phi\": 0.7997088525635255}, {\"truth_threshold\": -4.92, \"match_probability\": 0.03197560164877564, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10289, \"tn\": 6636, \"fp\": 382, \"fn\": 1492, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8733554027671675, \"tn_rate\": 0.945568538045027, \"fp_rate\": 0.05443146195497293, \"fn_rate\": 0.12664459723283253, \"precision\": 0.9642020429200637, \"recall\": 0.8733554027671675, \"specificity\": 0.945568538045027, \"npv\": 0.8164370078740157, \"accuracy\": 0.9003138464811958, \"f1\": 0.9165330482807768, \"f2\": 0.8901289038844191, \"f0_5\": 0.9445515468649591, \"p4\": 0.8959499104326363, \"phi\": 0.7995523796651339}, {\"truth_threshold\": -4.9, \"match_probability\": 0.03240749891294454, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10286, \"tn\": 6644, \"fp\": 374, \"fn\": 1495, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8731007554536966, \"tn_rate\": 0.9467084639498433, \"fp_rate\": 0.05329153605015674, \"fn_rate\": 0.12689924454630336, \"precision\": 0.9649155722326455, \"recall\": 0.8731007554536966, \"specificity\": 0.9467084639498433, \"npv\": 0.816316500798624, \"accuracy\": 0.9005798180754295, \"f1\": 0.9167149414018984, \"f2\": 0.8900387650560709, \"f0_5\": 0.9450395986843314, \"p4\": 0.8962561687854869, \"phi\": 0.8002882330540504}, {\"truth_threshold\": -4.88, \"match_probability\": 0.032845031915098126, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10285, \"tn\": 6644, \"fp\": 374, \"fn\": 1496, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.873015873015873, \"tn_rate\": 0.9467084639498433, \"fp_rate\": 0.05329153605015674, \"fn_rate\": 0.12698412698412698, \"precision\": 0.9649122807017544, \"recall\": 0.873015873015873, \"specificity\": 0.9467084639498433, \"npv\": 0.8162162162162162, \"accuracy\": 0.9005266237565828, \"f1\": 0.9166666666666666, \"f2\": 0.889967637540453, \"f0_5\": 0.9450171821305842, \"p4\": 0.896202873136845, \"phi\": 0.8001937510510251}, {\"truth_threshold\": -4.86, \"match_probability\": 0.0332882688177396, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10283, \"tn\": 6645, \"fp\": 373, \"fn\": 1498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8728461081402258, \"tn_rate\": 0.9468509546879453, \"fp_rate\": 0.053149045312054714, \"fn_rate\": 0.12715389185977422, \"precision\": 0.9649962462462462, \"recall\": 0.8728461081402258, \"specificity\": 0.9468509546879453, \"npv\": 0.8160383151172786, \"accuracy\": 0.900473429437736, \"f1\": 0.916610955118777, \"f2\": 0.889840775354794, \"f0_5\": 0.945041816009558, \"p4\": 0.8961545356494185, \"phi\": 0.8001323240045801}, {\"truth_threshold\": -4.84, \"match_probability\": 0.03373727846166985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10277, \"tn\": 6645, \"fp\": 373, \"fn\": 1504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8723368135132841, \"tn_rate\": 0.9468509546879453, \"fp_rate\": 0.053149045312054714, \"fn_rate\": 0.1276631864867159, \"precision\": 0.9649765258215962, \"recall\": 0.8723368135132841, \"specificity\": 0.9468509546879453, \"npv\": 0.8154374769910419, \"accuracy\": 0.9001542635246556, \"f1\": 0.9163211626766529, \"f2\": 0.8894139232180566, \"f0_5\": 0.9449072286276456, \"p4\": 0.8958348198998303, \"phi\": 0.7995658854885399}, {\"truth_threshold\": -4.8, \"match_probability\": 0.034652894744021626, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10274, \"tn\": 6645, \"fp\": 373, \"fn\": 1507, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8720821661998133, \"tn_rate\": 0.9468509546879453, \"fp_rate\": 0.053149045312054714, \"fn_rate\": 0.12791783380018673, \"precision\": 0.9649666572743496, \"recall\": 0.8720821661998133, \"specificity\": 0.9468509546879453, \"npv\": 0.8151373895976447, \"accuracy\": 0.8999946805681154, \"f1\": 0.9161762083110397, \"f2\": 0.889200463900573, \"f0_5\": 0.9448398903787084, \"p4\": 0.8956749869395794, \"phi\": 0.7992828296179348}, {\"truth_threshold\": -4.76, \"match_probability\": 0.0355924451531659, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10270, \"tn\": 6645, \"fp\": 373, \"fn\": 1511, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8717426364485188, \"tn_rate\": 0.9468509546879453, \"fp_rate\": 0.053149045312054714, \"fn_rate\": 0.1282573635514812, \"precision\": 0.9649534905571737, \"recall\": 0.8717426364485188, \"specificity\": 0.9468509546879453, \"npv\": 0.814737616478666, \"accuracy\": 0.8997819032927283, \"f1\": 0.9159828754905458, \"f2\": 0.8889158169889383, \"f0_5\": 0.9447500597943076, \"p4\": 0.89546190211231, \"phi\": 0.7989055909715698}, {\"truth_threshold\": -4.74, \"match_probability\": 0.03607137503645171, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10267, \"tn\": 6645, \"fp\": 373, \"fn\": 1514, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.871487989135048, \"tn_rate\": 0.9468509546879453, \"fp_rate\": 0.053149045312054714, \"fn_rate\": 0.12851201086495204, \"precision\": 0.9649436090225564, \"recall\": 0.871487989135048, \"specificity\": 0.9468509546879453, \"npv\": 0.8144380438779262, \"accuracy\": 0.899622320336188, \"f1\": 0.9158378306052362, \"f2\": 0.8887023059344921, \"f0_5\": 0.9446826521411089, \"p4\": 0.8953021078022805, \"phi\": 0.7986227887241885}, {\"truth_threshold\": -4.72, \"match_probability\": 0.036556505091306896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10265, \"tn\": 6646, \"fp\": 372, \"fn\": 1516, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8713182242594008, \"tn_rate\": 0.9469934454260474, \"fp_rate\": 0.053006554573952695, \"fn_rate\": 0.12868177574059927, \"precision\": 0.9650277333834728, \"recall\": 0.8713182242594008, \"specificity\": 0.9469934454260474, \"npv\": 0.8142612104876256, \"accuracy\": 0.8995691260173414, \"f1\": 0.9157819609242573, \"f2\": 0.8885753362995793, \"f0_5\": 0.9447072465902189, \"p4\": 0.8952538228652972, \"phi\": 0.7985619805791958}, {\"truth_threshold\": -4.7, \"match_probability\": 0.03704790897452556, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10264, \"tn\": 6646, \"fp\": 372, \"fn\": 1517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8712333418215771, \"tn_rate\": 0.9469934454260474, \"fp_rate\": 0.053006554573952695, \"fn_rate\": 0.1287666581784229, \"precision\": 0.9650244452801805, \"recall\": 0.8712333418215771, \"specificity\": 0.9469934454260474, \"npv\": 0.8141614602474581, \"accuracy\": 0.8995159316984946, \"f1\": 0.9157335950394789, \"f2\": 0.8885041551246537, \"f0_5\": 0.944684767602393, \"p4\": 0.8952005649479701, \"phi\": 0.7984677702628395}, {\"truth_threshold\": -4.68, \"match_probability\": 0.037545661038997695, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10263, \"tn\": 6646, \"fp\": 372, \"fn\": 1518, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8711484593837535, \"tn_rate\": 0.9469934454260474, \"fp_rate\": 0.053006554573952695, \"fn_rate\": 0.12885154061624648, \"precision\": 0.9650211565585332, \"recall\": 0.8711484593837535, \"specificity\": 0.9469934454260474, \"npv\": 0.8140617344439001, \"accuracy\": 0.8994627373796479, \"f1\": 0.9156852248394004, \"f2\": 0.8884329714849634, \"f0_5\": 0.9446622853040261, \"p4\": 0.8951473088639028, \"phi\": 0.7983735719883626}, {\"truth_threshold\": -4.66, \"match_probability\": 0.0380498363352935, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10262, \"tn\": 6648, \"fp\": 370, \"fn\": 1519, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8710635769459298, \"tn_rate\": 0.9472784269022514, \"fp_rate\": 0.05272157309774864, \"fn_rate\": 0.1289364230540701, \"precision\": 0.9651993980436419, \"recall\": 0.8710635769459298, \"specificity\": 0.9472784269022514, \"npv\": 0.8140075915268764, \"accuracy\": 0.8995159316984946, \"f1\": 0.9157185561950654, \"f2\": 0.888392547960385, \"f0_5\": 0.9447789500819386, \"p4\": 0.8952105102851164, \"phi\": 0.7985347890089991}, {\"truth_threshold\": -4.64, \"match_probability\": 0.03856051061308806, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10255, \"tn\": 6648, \"fp\": 370, \"fn\": 1526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8704693998811646, \"tn_rate\": 0.9472784269022514, \"fp_rate\": 0.05272157309774864, \"fn_rate\": 0.1295306001188354, \"precision\": 0.9651764705882353, \"recall\": 0.8704693998811646, \"specificity\": 0.9472784269022514, \"npv\": 0.8133104966968436, \"accuracy\": 0.8991435714665673, \"f1\": 0.9153798089797376, \"f2\": 0.8878941626694834, \"f0_5\": 0.9446215066045209, \"p4\": 0.8948377748500793, \"phi\": 0.797875946295278}, {\"truth_threshold\": -4.62, \"match_probability\": 0.03907776032242, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10242, \"tn\": 6649, \"fp\": 369, \"fn\": 1539, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8693659281894576, \"tn_rate\": 0.9474209176403534, \"fp_rate\": 0.052579082359646624, \"fn_rate\": 0.1306340718105424, \"precision\": 0.9652247667514843, \"recall\": 0.8693659281894576, \"specificity\": 0.9474209176403534, \"npv\": 0.8120420127015144, \"accuracy\": 0.8985052396404064, \"f1\": 0.9147909967845659, \"f2\": 0.886983632112237, \"f0_5\": 0.9443983402489626, \"p4\": 0.8942040006925253, \"phi\": 0.7967818278284904}, {\"truth_threshold\": -4.6000000000000005, \"match_probability\": 0.039601662614779175, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10234, \"tn\": 6649, \"fp\": 369, \"fn\": 1547, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8686868686868687, \"tn_rate\": 0.9474209176403534, \"fp_rate\": 0.052579082359646624, \"fn_rate\": 0.13131313131313133, \"precision\": 0.9651985287182873, \"recall\": 0.8686868686868687, \"specificity\": 0.9474209176403534, \"npv\": 0.8112493899463152, \"accuracy\": 0.8980796850896324, \"f1\": 0.9144031451036455, \"f2\": 0.886413636599858, \"f0_5\": 0.944217887919104, \"p4\": 0.8937783116225705, \"phi\": 0.7960308989604284}, {\"truth_threshold\": -4.58, \"match_probability\": 0.0401322953440168, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10229, \"tn\": 6649, \"fp\": 369, \"fn\": 1552, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8682624564977506, \"tn_rate\": 0.9474209176403534, \"fp_rate\": 0.052579082359646624, \"fn_rate\": 0.1317375435022494, \"precision\": 0.9651821098320438, \"recall\": 0.8682624564977506, \"specificity\": 0.9474209176403534, \"npv\": 0.8107547860017071, \"accuracy\": 0.8978137134953987, \"f1\": 0.9141605969882479, \"f2\": 0.8860573091715463, \"f0_5\": 0.9441049969542022, \"p4\": 0.8935123146929206, \"phi\": 0.795561955671537}, {\"truth_threshold\": -4.5600000000000005, \"match_probability\": 0.04066973706707255, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10226, \"tn\": 6654, \"fp\": 364, \"fn\": 1555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8680078091842798, \"tn_rate\": 0.9481333713308635, \"fp_rate\": 0.05186662866913651, \"fn_rate\": 0.13199219081572022, \"precision\": 0.9656279508970728, \"recall\": 0.8680078091842798, \"specificity\": 0.9481333713308635, \"npv\": 0.8105737605067609, \"accuracy\": 0.8979201021330921, \"f1\": 0.914219301774619, \"f2\": 0.885920227327858, \"f0_5\": 0.9443859551910752, \"p4\": 0.893643695966735, \"phi\": 0.7959209640806048}, {\"truth_threshold\": -4.54, \"match_probability\": 0.041214067044512546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10226, \"tn\": 6655, \"fp\": 363, \"fn\": 1555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8680078091842798, \"tn_rate\": 0.9482758620689655, \"fp_rate\": 0.05172413793103448, \"fn_rate\": 0.13199219081572022, \"precision\": 0.9657191425063746, \"recall\": 0.8680078091842798, \"specificity\": 0.9482758620689655, \"npv\": 0.8105968331303288, \"accuracy\": 0.8979732964519389, \"f1\": 0.9142601698703621, \"f2\": 0.8859355777727722, \"f0_5\": 0.9444557326782053, \"p4\": 0.893701875387003, \"phi\": 0.7960490277899177}, {\"truth_threshold\": -4.5200000000000005, \"match_probability\": 0.041765365240871495, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10225, \"tn\": 6656, \"fp\": 362, \"fn\": 1556, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8679229267464562, \"tn_rate\": 0.9484183528070675, \"fp_rate\": 0.051581647192932456, \"fn_rate\": 0.13207707325354384, \"precision\": 0.9658071219420044, \"recall\": 0.8679229267464562, \"specificity\": 0.9484183528070675, \"npv\": 0.8105211885046274, \"accuracy\": 0.8979732964519389, \"f1\": 0.9142525035765379, \"f2\": 0.8858796416627679, \"f0_5\": 0.9445029466644498, \"p4\": 0.8937068586324599, \"phi\": 0.7960834417971703}, {\"truth_threshold\": -4.5, \"match_probability\": 0.04232371232479359, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10224, \"tn\": 6656, \"fp\": 362, \"fn\": 1557, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8678380443086325, \"tn_rate\": 0.9484183528070675, \"fp_rate\": 0.051581647192932456, \"fn_rate\": 0.13216195569136746, \"precision\": 0.9658038919327414, \"recall\": 0.8678380443086325, \"specificity\": 0.9484183528070675, \"npv\": 0.8104225009131865, \"accuracy\": 0.8979201021330921, \"f1\": 0.9142039611928288, \"f2\": 0.8858083521053544, \"f0_5\": 0.9444803695150116, \"p4\": 0.8936536682943326, \"phi\": 0.7959897981573213}, {\"truth_threshold\": -4.48, \"match_probability\": 0.04288918966896465, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10206, \"tn\": 6658, \"fp\": 360, \"fn\": 1575, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8663101604278075, \"tn_rate\": 0.9487033342832716, \"fp_rate\": 0.05129666571672841, \"fn_rate\": 0.13368983957219252, \"precision\": 0.9659284497444633, \"recall\": 0.8663101604278075, \"specificity\": 0.9487033342832716, \"npv\": 0.8086967083687598, \"accuracy\": 0.8970689930315442, \"f1\": 0.9134111961337092, \"f2\": 0.8845553822152886, \"f0_5\": 0.9442131557035803, \"p4\": 0.8928128664292508, \"phi\": 0.7945627459206606}, {\"truth_threshold\": -4.46, \"match_probability\": 0.0434618793498302, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10204, \"tn\": 6660, \"fp\": 358, \"fn\": 1577, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8661403955521603, \"tn_rate\": 0.9489883157594756, \"fp_rate\": 0.051011684240524366, \"fn_rate\": 0.13385960444783973, \"precision\": 0.9661049043741715, \"recall\": 0.8661403955521603, \"specificity\": 0.9489883157594756, \"npv\": 0.8085468010197887, \"accuracy\": 0.8970689930315442, \"f1\": 0.9133956944009309, \"f2\": 0.884443365807995, \"f0_5\": 0.944307686612745, \"p4\": 0.8928228533591884, \"phi\": 0.7946325228262054}, {\"truth_threshold\": -4.44, \"match_probability\": 0.04404186414709147, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10202, \"tn\": 6692, \"fp\": 326, \"fn\": 1579, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.865970630676513, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.13402936932348697, \"precision\": 0.9690349544072948, \"recall\": 0.865970630676513, \"specificity\": 0.9535480193787403, \"npv\": 0.8090920082214969, \"accuracy\": 0.8986648225969467, \"f1\": 0.91460845398718, \"f2\": 0.8847915076666898, \"f0_5\": 0.9465051119811478, \"p4\": 0.8945751358388379, \"phi\": 0.7985546681255716}, {\"truth_threshold\": -4.42, \"match_probability\": 0.04462922754297395, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10201, \"tn\": 6692, \"fp\": 326, \"fn\": 1580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8658857482386895, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.1341142517613106, \"precision\": 0.9690320129191603, \"recall\": 0.8658857482386895, \"specificity\": 0.9535480193787403, \"npv\": 0.8089941972920697, \"accuracy\": 0.8986116282780999, \"f1\": 0.9145597991751838, \"f2\": 0.8847201262770811, \"f0_5\": 0.9464825845719905, \"p4\": 0.8945219680848384, \"phi\": 0.7984616138165306}, {\"truth_threshold\": -4.36, \"match_probability\": 0.046436434660459415, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10200, \"tn\": 6692, \"fp\": 326, \"fn\": 1581, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8658008658008658, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.1341991341991342, \"precision\": 0.9690290708721262, \"recall\": 0.8658008658008658, \"specificity\": 0.9535480193787403, \"npv\": 0.8088964100084612, \"accuracy\": 0.8985584339592532, \"f1\": 0.9145111400008966, \"f2\": 0.8846487424111015, \"f0_5\": 0.9464600538183168, \"p4\": 0.8944688020877962, \"phi\": 0.7983685712202845}, {\"truth_threshold\": -4.34, \"match_probability\": 0.047054161284591715, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10185, \"tn\": 6692, \"fp\": 326, \"fn\": 1596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8645276292335116, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.1354723707664884, \"precision\": 0.9689848729902008, \"recall\": 0.8645276292335116, \"specificity\": 0.9535480193787403, \"npv\": 0.8074324324324325, \"accuracy\": 0.897760519176552, \"f1\": 0.9137807285124708, \"f2\": 0.8835776871692548, \"f0_5\": 0.9461216906641895, \"p4\": 0.8936715223945858, \"phi\": 0.7969743350493775}, {\"truth_threshold\": -4.32, \"match_probability\": 0.04767969441387431, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10182, \"tn\": 6692, \"fp\": 326, \"fn\": 1599, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8642729819200408, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.13572701807995927, \"precision\": 0.9689760182717929, \"recall\": 0.8642729819200408, \"specificity\": 0.9535480193787403, \"npv\": 0.8071402725847304, \"accuracy\": 0.8976009362200117, \"f1\": 0.9136345282426309, \"f2\": 0.8833634092171017, \"f0_5\": 0.94605392748964, \"p4\": 0.893512113620981, \"phi\": 0.7966958027456765}, {\"truth_threshold\": -4.3, \"match_probability\": 0.04831312171665215, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10173, \"tn\": 6692, \"fp\": 326, \"fn\": 1608, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8635090399796282, \"tn_rate\": 0.9535480193787403, \"fp_rate\": 0.04645198062125962, \"fn_rate\": 0.13649096002037178, \"precision\": 0.9689494237546433, \"recall\": 0.8635090399796282, \"specificity\": 0.9535480193787403, \"npv\": 0.8062650602409639, \"accuracy\": 0.897122187350391, \"f1\": 0.9131956912028726, \"f2\": 0.8827204414903771, \"f0_5\": 0.945850456514867, \"p4\": 0.8930339812207464, \"phi\": 0.7958608337300346}, {\"truth_threshold\": -4.28, \"match_probability\": 0.04895453155169113, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10170, \"tn\": 6695, \"fp\": 323, \"fn\": 1611, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8632543926661573, \"tn_rate\": 0.9539754915930464, \"fp_rate\": 0.046024508406953546, \"fn_rate\": 0.13674560733384264, \"precision\": 0.9692175736205089, \"recall\": 0.8632543926661573, \"specificity\": 0.9539754915930464, \"npv\": 0.8060438237418733, \"accuracy\": 0.897122187350391, \"f1\": 0.9131723085211457, \"f2\": 0.88255202457608, \"f0_5\": 0.9459937119788663, \"p4\": 0.8930486198439969, \"phi\": 0.7959690835937588}, {\"truth_threshold\": -4.26, \"match_probability\": 0.04960401296536411, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10169, \"tn\": 6695, \"fp\": 323, \"fn\": 1612, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8631695102283338, \"tn_rate\": 0.9539754915930464, \"fp_rate\": 0.046024508406953546, \"fn_rate\": 0.13683048977166623, \"precision\": 0.9692146397255051, \"recall\": 0.8631695102283338, \"specificity\": 0.9539754915930464, \"npv\": 0.8059467918622848, \"accuracy\": 0.8970689930315442, \"f1\": 0.9131235127733129, \"f2\": 0.8824805609552901, \"f0_5\": 0.9459710878341923, \"p4\": 0.8929955063270094, \"phi\": 0.7958764284904212}, {\"truth_threshold\": -4.22, \"match_probability\": 0.05092755013318443, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10169, \"tn\": 6699, \"fp\": 319, \"fn\": 1612, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8631695102283338, \"tn_rate\": 0.9545454545454546, \"fp_rate\": 0.045454545454545456, \"fn_rate\": 0.13683048977166623, \"precision\": 0.9695842868039665, \"recall\": 0.8631695102283338, \"specificity\": 0.9545454545454546, \"npv\": 0.8060401877030442, \"accuracy\": 0.8972817703069312, \"f1\": 0.9132875297498765, \"f2\": 0.8825418315628688, \"f0_5\": 0.9462527683174213, \"p4\": 0.8932274289656621, \"phi\": 0.796391700012744}, {\"truth_threshold\": -4.2, \"match_probability\": 0.05160178738861727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10165, \"tn\": 6699, \"fp\": 319, \"fn\": 1616, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8628299804770393, \"tn_rate\": 0.9545454545454546, \"fp_rate\": 0.045454545454545456, \"fn_rate\": 0.1371700195229607, \"precision\": 0.9695726821823731, \"recall\": 0.8628299804770393, \"specificity\": 0.9545454545454546, \"npv\": 0.8056524353577871, \"accuracy\": 0.8970689930315442, \"f1\": 0.9130922973276443, \"f2\": 0.8822559366754618, \"f0_5\": 0.9461622949904127, \"p4\": 0.8930149838115192, \"phi\": 0.7960213362025873}, {\"truth_threshold\": -4.18, \"match_probability\": 0.052284459217495936, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10161, \"tn\": 6699, \"fp\": 319, \"fn\": 1620, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8624904507257448, \"tn_rate\": 0.9545454545454546, \"fp_rate\": 0.045454545454545456, \"fn_rate\": 0.13750954927425516, \"precision\": 0.9695610687022901, \"recall\": 0.8624904507257448, \"specificity\": 0.9545454545454546, \"npv\": 0.8052650558961414, \"accuracy\": 0.8968562157561573, \"f1\": 0.9128969947441714, \"f2\": 0.8819700020831887, \"f0_5\": 0.946071767751066, \"p4\": 0.8928025662269897, \"phi\": 0.7956511573164804}, {\"truth_threshold\": -4.14, \"match_probability\": 0.05367547698633007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10140, \"tn\": 6703, \"fp\": 315, \"fn\": 1641, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.860707919531449, \"tn_rate\": 0.9551154174978627, \"fp_rate\": 0.04488458250213736, \"fn_rate\": 0.13929208046855104, \"precision\": 0.96987087517934, \"recall\": 0.860707919531449, \"specificity\": 0.9551154174978627, \"npv\": 0.8033317353787153, \"accuracy\": 0.8959519123357625, \"f1\": 0.9120345385860766, \"f2\": 0.8805293596623769, \"f0_5\": 0.9458778754127721, \"p4\": 0.8919196226970253, \"phi\": 0.7942271299478808}, {\"truth_threshold\": -4.12, \"match_probability\": 0.05438400977727288, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10135, \"tn\": 6703, \"fp\": 315, \"fn\": 1646, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8602835073423308, \"tn_rate\": 0.9551154174978627, \"fp_rate\": 0.04488458250213736, \"fn_rate\": 0.13971649265766914, \"precision\": 0.9698564593301435, \"recall\": 0.8602835073423308, \"specificity\": 0.9551154174978627, \"npv\": 0.8028506407953049, \"accuracy\": 0.8956859407415289, \"f1\": 0.9117898430120103, \"f2\": 0.8801716052384757, \"f0_5\": 0.9457643567682574, \"p4\": 0.8916543081010474, \"phi\": 0.7937660478117431}, {\"truth_threshold\": -4.1, \"match_probability\": 0.05510135083319928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10134, \"tn\": 6703, \"fp\": 315, \"fn\": 1647, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8601986249045073, \"tn_rate\": 0.9551154174978627, \"fp_rate\": 0.04488458250213736, \"fn_rate\": 0.13980137509549273, \"precision\": 0.9698535745047373, \"recall\": 0.8601986249045073, \"specificity\": 0.9551154174978627, \"npv\": 0.802754491017964, \"accuracy\": 0.8956327464226821, \"f1\": 0.9117408906882591, \"f2\": 0.880100046896983, \"f0_5\": 0.9457416428691416, \"p4\": 0.8916012502725129, \"phi\": 0.7936738656992485}, {\"truth_threshold\": -4.08, \"match_probability\": 0.05582759521111378, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10132, \"tn\": 6703, \"fp\": 315, \"fn\": 1649, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.86002886002886, \"tn_rate\": 0.9551154174978627, \"fp_rate\": 0.04488458250213736, \"fn_rate\": 0.13997113997113997, \"precision\": 0.9698478031970901, \"recall\": 0.86002886002886, \"specificity\": 0.9551154174978627, \"npv\": 0.8025622605363985, \"accuracy\": 0.8955263577849886, \"f1\": 0.911642972827065, \"f2\": 0.8799569227562488, \"f0_5\": 0.9456962048946219, \"p4\": 0.8914951396993422, \"phi\": 0.7934895357573434}, {\"truth_threshold\": -4.0600000000000005, \"match_probability\": 0.05656283860997083, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10130, \"tn\": 6704, \"fp\": 314, \"fn\": 1651, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8598590951532128, \"tn_rate\": 0.9552579082359647, \"fp_rate\": 0.04474209176403534, \"fn_rate\": 0.1401409048467872, \"precision\": 0.969934890846419, \"recall\": 0.8598590951532128, \"specificity\": 0.9552579082359647, \"npv\": 0.802393776181927, \"accuracy\": 0.8954731634661418, \"f1\": 0.911586051743532, \"f2\": 0.8798290717065036, \"f0_5\": 0.9457213809586048, \"p4\": 0.8914469704132144, \"phi\": 0.7934344514197145}, {\"truth_threshold\": -4.04, \"match_probability\": 0.05730717736417426, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10125, \"tn\": 6704, \"fp\": 314, \"fn\": 1656, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8594346829640948, \"tn_rate\": 0.9552579082359647, \"fp_rate\": 0.04474209176403534, \"fn_rate\": 0.14056531703590527, \"precision\": 0.9699204904684356, \"recall\": 0.8594346829640948, \"specificity\": 0.9552579082359647, \"npv\": 0.8019138755980861, \"accuracy\": 0.8952071918719081, \"f1\": 0.9113411341134113, \"f2\": 0.8794711880895715, \"f0_5\": 0.9456077105553169, \"p4\": 0.8911817377984805, \"phi\": 0.7929739842315067}, {\"truth_threshold\": -4.0200000000000005, \"match_probability\": 0.0580607084366901, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10123, \"tn\": 6704, \"fp\": 314, \"fn\": 1658, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8592649180884475, \"tn_rate\": 0.9552579082359647, \"fp_rate\": 0.04474209176403534, \"fn_rate\": 0.1407350819115525, \"precision\": 0.9699147264539618, \"recall\": 0.8592649180884475, \"specificity\": 0.9552579082359647, \"npv\": 0.8017220760583592, \"accuracy\": 0.8951008032342146, \"f1\": 0.9112431361958773, \"f2\": 0.879328017233891, \"f0_5\": 0.9455622186104728, \"p4\": 0.8910756565661248, \"phi\": 0.7927898771290336}, {\"truth_threshold\": -4.0, \"match_probability\": 0.058823529411764705, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10122, \"tn\": 6704, \"fp\": 314, \"fn\": 1659, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8591800356506238, \"tn_rate\": 0.9552579082359647, \"fp_rate\": 0.04474209176403534, \"fn_rate\": 0.1408199643493761, \"precision\": 0.9699118436182446, \"recall\": 0.8591800356506238, \"specificity\": 0.9552579082359647, \"npv\": 0.8016262106899438, \"accuracy\": 0.8950476089153678, \"f1\": 0.9111941306206959, \"f2\": 0.8792564280750521, \"f0_5\": 0.9455394675385334, \"p4\": 0.8910226184780352, \"phi\": 0.7926978406562112}, {\"truth_threshold\": -3.98, \"match_probability\": 0.059595738487237926, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10116, \"tn\": 6705, \"fp\": 313, \"fn\": 1665, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8586707410236822, \"tn_rate\": 0.9554003989740667, \"fp_rate\": 0.044599601025933314, \"fn_rate\": 0.1413292589763178, \"precision\": 0.9699875347588456, \"recall\": 0.8586707410236822, \"specificity\": 0.9554003989740667, \"npv\": 0.8010752688172043, \"accuracy\": 0.8947816373211341, \"f1\": 0.9109410175596578, \"f2\": 0.8788421107500912, \"f0_5\": 0.9454735779576425, \"p4\": 0.8907623483115729, \"phi\": 0.7922751892600293}, {\"truth_threshold\": -3.96, \"match_probability\": 0.06037743446644346, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10102, \"tn\": 6705, \"fp\": 313, \"fn\": 1679, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8574823868941516, \"tn_rate\": 0.9554003989740667, \"fp_rate\": 0.044599601025933314, \"fn_rate\": 0.1425176131058484, \"precision\": 0.9699471915506481, \"recall\": 0.8574823868941516, \"specificity\": 0.9554003989740667, \"npv\": 0.7997375954198473, \"accuracy\": 0.8940369168572796, \"f1\": 0.9102540998378086, \"f2\": 0.8778393785084899, \"f0_5\": 0.9451544694148687, \"p4\": 0.8900201246203278, \"phi\": 0.7909889467451251}, {\"truth_threshold\": -3.94, \"match_probability\": 0.061168716749686526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10091, \"tn\": 6707, \"fp\": 311, \"fn\": 1690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8565486800780918, \"tn_rate\": 0.9556853804502707, \"fp_rate\": 0.04431461954972927, \"fn_rate\": 0.14345131992190815, \"precision\": 0.9701019034801, \"recall\": 0.8565486800780918, \"specificity\": 0.9556853804502707, \"npv\": 0.7987376443968084, \"accuracy\": 0.893558167987659, \"f1\": 0.9097957895685885, \"f2\": 0.8770816674199492, \"f0_5\": 0.945044859427972, \"p4\": 0.8895529849614706, \"phi\": 0.7902389941447154}, {\"truth_threshold\": -3.92, \"match_probability\": 0.061969685325289826, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10086, \"tn\": 6707, \"fp\": 311, \"fn\": 1695, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8561242678889738, \"tn_rate\": 0.9556853804502707, \"fp_rate\": 0.04431461954972927, \"fn_rate\": 0.14387573211102622, \"precision\": 0.9700875252476676, \"recall\": 0.8561242678889738, \"specificity\": 0.9556853804502707, \"npv\": 0.7982623184955963, \"accuracy\": 0.8932921963934252, \"f1\": 0.9095500045089728, \"f2\": 0.8767232836703117, \"f0_5\": 0.944930577676179, \"p4\": 0.8892880700808955, \"phi\": 0.7897808660956104}, {\"truth_threshold\": -3.9, \"match_probability\": 0.06278044076019877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10079, \"tn\": 6708, \"fp\": 310, \"fn\": 1702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8555300908242085, \"tn_rate\": 0.9558278711883728, \"fp_rate\": 0.04417212881162724, \"fn_rate\": 0.14446990917579153, \"precision\": 0.970160746943883, \"recall\": 0.8555300908242085, \"specificity\": 0.9558278711883728, \"npv\": 0.7976218787158145, \"accuracy\": 0.8929730304803447, \"f1\": 0.9092467298150654, \"f2\": 0.8762366769252169, \"f0_5\": 0.944841292161164, \"p4\": 0.8889751494708489, \"phi\": 0.7892696284692073}, {\"truth_threshold\": -3.88, \"match_probability\": 0.06360108419013638, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10079, \"tn\": 6711, \"fp\": 307, \"fn\": 1702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8555300908242085, \"tn_rate\": 0.9562553434026788, \"fp_rate\": 0.04374465659732117, \"fn_rate\": 0.14446990917579153, \"precision\": 0.9704409782399384, \"recall\": 0.8555300908242085, \"specificity\": 0.9562553434026788, \"npv\": 0.7976940449304648, \"accuracy\": 0.893132613436885, \"f1\": 0.9093697839130238, \"f2\": 0.8762823856720571, \"f0_5\": 0.9450539146741679, \"p4\": 0.8891487987782885, \"phi\": 0.7896586752067414}, {\"truth_threshold\": -3.86, \"match_probability\": 0.06443171730929868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10076, \"tn\": 6711, \"fp\": 307, \"fn\": 1705, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8552754435107376, \"tn_rate\": 0.9562553434026788, \"fp_rate\": 0.04374465659732117, \"fn_rate\": 0.14472455648926238, \"precision\": 0.9704324376384474, \"recall\": 0.8552754435107376, \"specificity\": 0.9562553434026788, \"npv\": 0.7974096958174905, \"accuracy\": 0.8929730304803447, \"f1\": 0.9092221620646093, \"f2\": 0.8760672613768758, \"f0_5\": 0.9449852756363364, \"p4\": 0.8889898975331227, \"phi\": 0.7893842732084126}, {\"truth_threshold\": -3.84, \"match_probability\": 0.06527244235958121, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10067, \"tn\": 6711, \"fp\": 307, \"fn\": 1714, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8545115015703251, \"tn_rate\": 0.9562553434026788, \"fp_rate\": 0.04374465659732117, \"fn_rate\": 0.1454884984296749, \"precision\": 0.9704067861962599, \"recall\": 0.8545115015703251, \"specificity\": 0.9562553434026788, \"npv\": 0.7965578635014837, \"accuracy\": 0.892494281610724, \"f1\": 0.9087790566463553, \"f2\": 0.8754217538001322, \"f0_5\": 0.9447791730014828, \"p4\": 0.8885132823618651, \"phi\": 0.7885616711718018}, {\"truth_threshold\": -3.8200000000000003, \"match_probability\": 0.06612336211932712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10061, \"tn\": 6712, \"fp\": 306, \"fn\": 1720, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8540022069433835, \"tn_rate\": 0.9563978341407808, \"fp_rate\": 0.04360216585921915, \"fn_rate\": 0.1459977930566166, \"precision\": 0.9704832642037233, \"recall\": 0.8540022069433835, \"specificity\": 0.9563978341407808, \"npv\": 0.7960151802656547, \"accuracy\": 0.8922283100164903, \"f1\": 0.9085244717355969, \"f2\": 0.8750065227600842, \"f0_5\": 0.9447125767620049, \"p4\": 0.8882534776590105, \"phi\": 0.7881436232622401}, {\"truth_threshold\": -3.8000000000000003, \"match_probability\": 0.06698457989158756, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10060, \"tn\": 6712, \"fp\": 306, \"fn\": 1721, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8539173245055598, \"tn_rate\": 0.9563978341407808, \"fp_rate\": 0.04360216585921915, \"fn_rate\": 0.1460826754944402, \"precision\": 0.9704804167470577, \"recall\": 0.8539173245055598, \"specificity\": 0.9563978341407808, \"npv\": 0.7959207873829005, \"accuracy\": 0.8921751156976435, \"f1\": 0.9084751885131169, \"f2\": 0.8749347712645678, \"f0_5\": 0.9446896422199268, \"p4\": 0.8882005378158574, \"phi\": 0.788052354422797}, {\"truth_threshold\": -3.7800000000000002, \"match_probability\": 0.06785619949188462, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10057, \"tn\": 6714, \"fp\": 304, \"fn\": 1724, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.853662677192089, \"tn_rate\": 0.9566828156169849, \"fp_rate\": 0.04331718438301511, \"fn_rate\": 0.14633732280791104, \"precision\": 0.9706592027796545, \"recall\": 0.853662677192089, \"specificity\": 0.9566828156169849, \"npv\": 0.7956861815596112, \"accuracy\": 0.8921219213787968, \"f1\": 0.9084093577815916, \"f2\": 0.874749934765591, \"f0_5\": 0.9447627994363551, \"p4\": 0.8881574422403402, \"phi\": 0.7880384052407353}, {\"truth_threshold\": -3.7600000000000002, \"match_probability\": 0.0687383252354679, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10039, \"tn\": 6728, \"fp\": 290, \"fn\": 1742, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8521347933112638, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.1478652066887361, \"precision\": 0.9719237099428792, \"recall\": 0.8521347933112638, \"specificity\": 0.9586776859504132, \"npv\": 0.7943329397874852, \"accuracy\": 0.8919091441034097, \"f1\": 0.9080958842152872, \"f2\": 0.8736706525333751, \"f0_5\": 0.9453453114111908, \"p4\": 0.8880142931317354, \"phi\": 0.7882198005116487}, {\"truth_threshold\": -3.74, \"match_probability\": 0.06963106192405447, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10029, \"tn\": 6728, \"fp\": 290, \"fn\": 1752, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8512859689330278, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.14871403106697223, \"precision\": 0.9718965015989921, \"recall\": 0.8512859689330278, \"specificity\": 0.9586776859504132, \"npv\": 0.7933962264150943, \"accuracy\": 0.8913772009149423, \"f1\": 0.9076018099547511, \"f2\": 0.8729523179499677, \"f0_5\": 0.9451156303598017, \"p4\": 0.8874852301691262, \"phi\": 0.7873114345911716}, {\"truth_threshold\": -3.72, \"match_probability\": 0.07053451483204333, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10024, \"tn\": 6728, \"fp\": 290, \"fn\": 1757, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8508615567439097, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.14913844325609033, \"precision\": 0.97188287764204, \"recall\": 0.8508615567439097, \"specificity\": 0.9586776859504132, \"npv\": 0.7929286977018267, \"accuracy\": 0.8911112293207085, \"f1\": 0.9073546051142792, \"f2\": 0.8725930568613113, \"f0_5\": 0.9450006599166619, \"p4\": 0.8872207584919407, \"phi\": 0.7868576640712893}, {\"truth_threshold\": -3.7, \"match_probability\": 0.07144878969219468, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10023, \"tn\": 6728, \"fp\": 290, \"fn\": 1758, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8507766743060861, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.14922332569391392, \"precision\": 0.9718801512653932, \"recall\": 0.8507766743060861, \"specificity\": 0.9586776859504132, \"npv\": 0.7928352580721187, \"accuracy\": 0.8910580350018618, \"f1\": 0.9073051507196523, \"f2\": 0.8725211971377335, \"f0_5\": 0.9449776554220957, \"p4\": 0.887167868927202, \"phi\": 0.7867669429021422}, {\"truth_threshold\": -3.68, \"match_probability\": 0.07237399268076448, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10022, \"tn\": 6728, \"fp\": 290, \"fn\": 1759, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8506917918682625, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.14930820813173754, \"precision\": 0.9718774243599689, \"recall\": 0.8506917918682625, \"specificity\": 0.9586776859504132, \"npv\": 0.7927418404618829, \"accuracy\": 0.8910048406830151, \"f1\": 0.9072556918480967, \"f2\": 0.8724493349119019, \"f0_5\": 0.9449546474570518, \"p4\": 0.8871149809507075, \"phi\": 0.7866762327024771}, {\"truth_threshold\": -3.66, \"match_probability\": 0.07331023040208501, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10014, \"tn\": 6728, \"fp\": 290, \"fn\": 1767, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8500127323656735, \"tn_rate\": 0.9586776859504132, \"fp_rate\": 0.04132231404958678, \"fn_rate\": 0.14998726763432646, \"precision\": 0.9718555900621118, \"recall\": 0.8500127323656735, \"specificity\": 0.9586776859504132, \"npv\": 0.7919952913478516, \"accuracy\": 0.890579286132241, \"f1\": 0.9068598596332352, \"f2\": 0.8718743470084279, \"f0_5\": 0.9447704587052097, \"p4\": 0.8866919342132367, \"phi\": 0.7859509455548322}, {\"truth_threshold\": -3.64, \"match_probability\": 0.07425760987258186, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10013, \"tn\": 6729, \"fp\": 289, \"fn\": 1768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.84992784992785, \"tn_rate\": 0.9588201766885153, \"fp_rate\": 0.04117982331148475, \"fn_rate\": 0.15007215007215008, \"precision\": 0.971947194719472, \"recall\": 0.84992784992785, \"specificity\": 0.9588201766885153, \"npv\": 0.7919265623161116, \"accuracy\": 0.890579286132241, \"f1\": 0.9068514241724404, \"f2\": 0.8718176435760805, \"f0_5\": 0.9448187359640681, \"p4\": 0.8866968326399246, \"phi\": 0.7859907083334744}, {\"truth_threshold\": -3.62, \"match_probability\": 0.0752162385042182, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10013, \"tn\": 6730, \"fp\": 288, \"fn\": 1768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.84992784992785, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.15007215007215008, \"precision\": 0.9720415493641394, \"recall\": 0.84992784992785, \"specificity\": 0.9589626674266173, \"npv\": 0.7919510473052483, \"accuracy\": 0.8906324804510878, \"f1\": 0.9068924916221357, \"f2\": 0.8718328254244667, \"f0_5\": 0.9448900632254411, \"p4\": 0.8867546009789904, \"phi\": 0.7861210891299659}, {\"truth_threshold\": -3.6, \"match_probability\": 0.0761862240873569, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10010, \"tn\": 6730, \"fp\": 288, \"fn\": 1771, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8496732026143791, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.1503267973856209, \"precision\": 0.9720334045445718, \"recall\": 0.8496732026143791, \"specificity\": 0.9589626674266173, \"npv\": 0.7916715680508175, \"accuracy\": 0.8904728974945476, \"f1\": 0.9067439648534806, \"f2\": 0.8716171502211696, \"f0_5\": 0.9448209465199252, \"p4\": 0.8865959857583579, \"phi\": 0.7858493716796545}, {\"truth_threshold\": -3.58, \"match_probability\": 0.07716767477303127, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10009, \"tn\": 6730, \"fp\": 288, \"fn\": 1772, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8495883201765555, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.15041167982344453, \"precision\": 0.9720306885500631, \"recall\": 0.8495883201765555, \"specificity\": 0.9589626674266173, \"npv\": 0.7915784521289109, \"accuracy\": 0.8904197031757008, \"f1\": 0.9066944469607754, \"f2\": 0.8715452534786925, \"f0_5\": 0.9447979006588759, \"p4\": 0.8865431171716197, \"phi\": 0.7857588210378516}, {\"truth_threshold\": -3.56, \"match_probability\": 0.07816069905461534, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10002, \"tn\": 6730, \"fp\": 288, \"fn\": 1779, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8489941431117902, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.15100585688820983, \"precision\": 0.9720116618075801, \"recall\": 0.8489941431117902, \"specificity\": 0.9589626674266173, \"npv\": 0.790927253496298, \"accuracy\": 0.8900473429437736, \"f1\": 0.9063476960717683, \"f2\": 0.8710419061552931, \"f0_5\": 0.9446364821216071, \"p4\": 0.8861730811254559, \"phi\": 0.7851252719436267}, {\"truth_threshold\": -3.54, \"match_probability\": 0.07916540574888453, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 10001, \"tn\": 6730, \"fp\": 288, \"fn\": 1780, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8489092606739665, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.15109073932603345, \"precision\": 0.9720089415881038, \"recall\": 0.8489092606739665, \"specificity\": 0.9589626674266173, \"npv\": 0.790834312573443, \"accuracy\": 0.8899941486249269, \"f1\": 0.9062981422745808, \"f2\": 0.8709699893752286, \"f0_5\": 0.9446134083911064, \"p4\": 0.8861202251173323, \"phi\": 0.7850348085136177}, {\"truth_threshold\": -3.52, \"match_probability\": 0.08018190397645779, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9999, \"tn\": 6730, \"fp\": 288, \"fn\": 1782, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8487394957983193, \"tn_rate\": 0.9589626674266173, \"fp_rate\": 0.04103733257338273, \"fn_rate\": 0.15126050420168066, \"precision\": 0.9720034995625547, \"recall\": 0.8487394957983193, \"specificity\": 0.9589626674266173, \"npv\": 0.7906484962406015, \"accuracy\": 0.8898877599872334, \"f1\": 0.9061990212071778, \"f2\": 0.8708261482991064, \"f0_5\": 0.9445672504676076, \"p4\": 0.8860145178056861, \"phi\": 0.7848539143038177}, {\"truth_threshold\": -3.5, \"match_probability\": 0.08121030314161229, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9999, \"tn\": 6731, \"fp\": 287, \"fn\": 1782, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8487394957983193, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.15126050420168066, \"precision\": 0.9720979972778534, \"recall\": 0.8487394957983193, \"specificity\": 0.9591051581647193, \"npv\": 0.7906730882180195, \"accuracy\": 0.8899409543060801, \"f1\": 0.9062400870077492, \"f2\": 0.8708413168437554, \"f0_5\": 0.9446386395843175, \"p4\": 0.8860722740630878, \"phi\": 0.784984422530425}, {\"truth_threshold\": -3.48, \"match_probability\": 0.08225071291146206, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9971, \"tn\": 6731, \"fp\": 287, \"fn\": 1810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8463627875392581, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.15363721246074188, \"precision\": 0.9720218366153246, \"recall\": 0.8463627875392581, \"specificity\": 0.9591051581647193, \"npv\": 0.7880810209577332, \"accuracy\": 0.8884515133783711, \"f1\": 0.9048504923090884, \"f2\": 0.8688264612596285, \"f0_5\": 0.943991062806506, \"p4\": 0.8845930097939031, \"phi\": 0.7824566998966102}, {\"truth_threshold\": -3.46, \"match_probability\": 0.08330324319449184, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9965, \"tn\": 6731, \"fp\": 287, \"fn\": 1816, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8458534929123165, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.15414650708768357, \"precision\": 0.97200546234881, \"recall\": 0.8458534929123165, \"specificity\": 0.9591051581647193, \"npv\": 0.7875277875277875, \"accuracy\": 0.8881323474652907, \"f1\": 0.904552262515318, \"f2\": 0.8683944506413832, \"f0_5\": 0.943851938850897, \"p4\": 0.8842761825518969, \"phi\": 0.7819161465712439}, {\"truth_threshold\": -3.44, \"match_probability\": 0.08436800411843749, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9957, \"tn\": 6731, \"fp\": 287, \"fn\": 1824, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8451744334097275, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.15482556659027247, \"precision\": 0.971983600156189, \"recall\": 0.8451744334097275, \"specificity\": 0.9591051581647193, \"npv\": 0.786791350087668, \"accuracy\": 0.8877067929145167, \"f1\": 0.9041543700340522, \"f2\": 0.8678182959140984, \"f0_5\": 0.9436662433421157, \"p4\": 0.8838538322803821, \"phi\": 0.7811960106650895}, {\"truth_threshold\": -3.4, \"match_probability\": 0.08653465935892166, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9952, \"tn\": 6731, \"fp\": 287, \"fn\": 1829, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8447500212206095, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.15524997877939054, \"precision\": 0.9719699189373963, \"recall\": 0.8447500212206095, \"specificity\": 0.9591051581647193, \"npv\": 0.7863317757009346, \"accuracy\": 0.887440821320283, \"f1\": 0.903905540417802, \"f2\": 0.8674581176019386, \"f0_5\": 0.9435500692113696, \"p4\": 0.8835899131246904, \"phi\": 0.7807462742605271}, {\"truth_threshold\": -3.38, \"match_probability\": 0.08763677481880414, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9948, \"tn\": 6731, \"fp\": 287, \"fn\": 1833, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.844410491469315, \"tn_rate\": 0.9591051581647193, \"fp_rate\": 0.04089484183528071, \"fn_rate\": 0.155589508530685, \"precision\": 0.9719589643380557, \"recall\": 0.844410491469315, \"specificity\": 0.9591051581647193, \"npv\": 0.785964502568893, \"accuracy\": 0.887228044044896, \"f1\": 0.9037063953488372, \"f2\": 0.8671699297407556, \"f0_5\": 0.9434570664441114, \"p4\": 0.883378805274279, \"phi\": 0.780386677798011}, {\"truth_threshold\": -3.36, \"match_probability\": 0.08875156315734896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9946, \"tn\": 6732, \"fp\": 286, \"fn\": 1835, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8442407265936678, \"tn_rate\": 0.9592476489028213, \"fp_rate\": 0.04075235109717868, \"fn_rate\": 0.15575927340633222, \"precision\": 0.972048475371384, \"recall\": 0.8442407265936678, \"specificity\": 0.9592476489028213, \"npv\": 0.7858059997665461, \"accuracy\": 0.8871748497260492, \"f1\": 0.903647844455549, \"f2\": 0.8670409373038566, \"f0_5\": 0.9434821377753325, \"p4\": 0.8833309807601998, \"phi\": 0.780337914682684}, {\"truth_threshold\": -3.34, \"match_probability\": 0.08987913524332442, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9945, \"tn\": 6732, \"fp\": 286, \"fn\": 1836, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8441558441558441, \"tn_rate\": 0.9592476489028213, \"fp_rate\": 0.04075235109717868, \"fn_rate\": 0.15584415584415584, \"precision\": 0.9720457433290979, \"recall\": 0.8441558441558441, \"specificity\": 0.9592476489028213, \"npv\": 0.7857142857142857, \"accuracy\": 0.8871216554072026, \"f1\": 0.9035980374341268, \"f2\": 0.8669688780402754, \"f0_5\": 0.9434588748695569, \"p4\": 0.8832782100283707, \"phi\": 0.78024807223965}, {\"truth_threshold\": -3.3200000000000003, \"match_probability\": 0.0910196020178644, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9939, \"tn\": 6733, \"fp\": 285, \"fn\": 1842, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8436465495289025, \"tn_rate\": 0.9593901396409233, \"fp_rate\": 0.04060986035907666, \"fn_rate\": 0.15635345047109753, \"precision\": 0.9721244131455399, \"recall\": 0.8436465495289025, \"specificity\": 0.9593901396409233, \"npv\": 0.7851895043731778, \"accuracy\": 0.8868556838129688, \"f1\": 0.9033401499659168, \"f2\": 0.866551579828416, \"f0_5\": 0.9433908536932627, \"p4\": 0.8830193296600551, \"phi\": 0.7798402791510975}, {\"truth_threshold\": -3.3000000000000003, \"match_probability\": 0.09217307446755524, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9938, \"tn\": 6733, \"fp\": 285, \"fn\": 1843, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8435616670910788, \"tn_rate\": 0.9593901396409233, \"fp_rate\": 0.04060986035907666, \"fn_rate\": 0.15643833290892115, \"precision\": 0.9721216863934266, \"recall\": 0.8435616670910788, \"specificity\": 0.9593901396409233, \"npv\": 0.785097947761194, \"accuracy\": 0.886802489494122, \"f1\": 0.9032903108525723, \"f2\": 0.8664795019791793, \"f0_5\": 0.9433675697226283, \"p4\": 0.8829665689234075, \"phi\": 0.7797505199340353}, {\"truth_threshold\": -3.2800000000000002, \"match_probability\": 0.0933396635968081, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9936, \"tn\": 6733, \"fp\": 285, \"fn\": 1845, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8433919022154316, \"tn_rate\": 0.9593901396409233, \"fp_rate\": 0.04060986035907666, \"fn_rate\": 0.15660809778456838, \"precision\": 0.9721162312885236, \"recall\": 0.8433919022154316, \"specificity\": 0.9593901396409233, \"npv\": 0.7849148985777571, \"accuracy\": 0.8866961008564286, \"f1\": 0.9031906190346333, \"f2\": 0.8663353387392101, \"f0_5\": 0.9433209911706066, \"p4\": 0.8828610519884172, \"phi\": 0.7795710334426723}, {\"truth_threshold\": -3.24, \"match_probability\": 0.09571263582995625, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9936, \"tn\": 6734, \"fp\": 284, \"fn\": 1845, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8433919022154316, \"tn_rate\": 0.9595326303790254, \"fp_rate\": 0.040467369620974636, \"fn_rate\": 0.15660809778456838, \"precision\": 0.9722113502935421, \"recall\": 0.8433919022154316, \"specificity\": 0.9595326303790254, \"npv\": 0.7849399696934375, \"accuracy\": 0.8867492951752752, \"f1\": 0.9032316712876688, \"f2\": 0.8663504464285714, \"f0_5\": 0.9433926435122766, \"p4\": 0.8829187584856892, \"phi\": 0.7797021031803246}, {\"truth_threshold\": -3.22, \"match_probability\": 0.09691924077303016, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9931, \"tn\": 6734, \"fp\": 284, \"fn\": 1850, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8429674900263135, \"tn_rate\": 0.9595326303790254, \"fp_rate\": 0.040467369620974636, \"fn_rate\": 0.15703250997368645, \"precision\": 0.9721977484092021, \"recall\": 0.8429674900263135, \"specificity\": 0.9595326303790254, \"npv\": 0.7844827586206896, \"accuracy\": 0.8864833235810415, \"f1\": 0.9029823604291689, \"f2\": 0.8659899893615166, \"f0_5\": 0.9432761535685112, \"p4\": 0.8826549894526422, \"phi\": 0.7792536159684221}, {\"truth_threshold\": -3.2, \"match_probability\": 0.09813940601367187, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9931, \"tn\": 6736, \"fp\": 282, \"fn\": 1850, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8429674900263135, \"tn_rate\": 0.9598176118552294, \"fp_rate\": 0.04018238814477059, \"fn_rate\": 0.15703250997368645, \"precision\": 0.9723881327719573, \"recall\": 0.8429674900263135, \"specificity\": 0.9598176118552294, \"npv\": 0.7845329606335896, \"accuracy\": 0.8865897122187351, \"f1\": 0.9030644721287624, \"f2\": 0.8660201963827895, \"f0_5\": 0.9434195276727528, \"p4\": 0.882770384886513, \"phi\": 0.7795158607019236}, {\"truth_threshold\": -3.18, \"match_probability\": 0.09937324220558363, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9928, \"tn\": 6736, \"fp\": 282, \"fn\": 1853, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8427128427128427, \"tn_rate\": 0.9598176118552294, \"fp_rate\": 0.04018238814477059, \"fn_rate\": 0.15728715728715728, \"precision\": 0.9723800195886386, \"recall\": 0.8427128427128427, \"specificity\": 0.9598176118552294, \"npv\": 0.7842589358481779, \"accuracy\": 0.8864301292621948, \"f1\": 0.9029148287935974, \"f2\": 0.8658038860013255, \"f0_5\": 0.9433496132722677, \"p4\": 0.8826121377888899, \"phi\": 0.7792469472834781}, {\"truth_threshold\": -3.16, \"match_probability\": 0.10062085983919537, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9910, \"tn\": 6736, \"fp\": 282, \"fn\": 1871, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8411849588320176, \"tn_rate\": 0.9598176118552294, \"fp_rate\": 0.04018238814477059, \"fn_rate\": 0.15881504116798234, \"precision\": 0.972331240188383, \"recall\": 0.8411849588320176, \"specificity\": 0.9598176118552294, \"npv\": 0.7826187986522598, \"accuracy\": 0.8854726315229533, \"f1\": 0.9020161106812907, \"f2\": 0.8645055481889874, \"f0_5\": 0.9429294563169613, \"p4\": 0.8816629384550922, \"phi\": 0.7776354684887977}, {\"truth_threshold\": -3.14, \"match_probability\": 0.10188236920887628, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9908, \"tn\": 6736, \"fp\": 282, \"fn\": 1873, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8410151939563705, \"tn_rate\": 0.9598176118552294, \"fp_rate\": 0.04018238814477059, \"fn_rate\": 0.15898480604362958, \"precision\": 0.9723258096172719, \"recall\": 0.8410151939563705, \"specificity\": 0.9598176118552294, \"npv\": 0.7824369845510513, \"accuracy\": 0.8853662428852599, \"f1\": 0.9019161622138273, \"f2\": 0.8643612380919147, \"f0_5\": 0.9428827011286424, \"p4\": 0.8815575017042954, \"phi\": 0.7774566265561194}, {\"truth_threshold\": -3.12, \"match_probability\": 0.10315788037939025, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9902, \"tn\": 6740, \"fp\": 278, \"fn\": 1879, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8405058993294288, \"tn_rate\": 0.9603875748076375, \"fp_rate\": 0.039612425192362494, \"fn_rate\": 0.15949410067057126, \"precision\": 0.9726915520628684, \"recall\": 0.8405058993294288, \"specificity\": 0.9603875748076375, \"npv\": 0.7819932706810535, \"accuracy\": 0.8852598542475664, \"f1\": 0.9017804289422158, \"f2\": 0.8639885522825632, \"f0_5\": 0.9430296565779699, \"p4\": 0.8814718994269972, \"phi\": 0.7774459142383447}, {\"truth_threshold\": -3.08, \"match_probability\": 0.1057513470273544, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9896, \"tn\": 6740, \"fp\": 278, \"fn\": 1885, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.839996604702487, \"tn_rate\": 0.9603875748076375, \"fp_rate\": 0.039612425192362494, \"fn_rate\": 0.16000339529751295, \"precision\": 0.9726754472183998, \"recall\": 0.839996604702487, \"specificity\": 0.9603875748076375, \"npv\": 0.7814492753623189, \"accuracy\": 0.8849406883344859, \"f1\": 0.9014803006148941, \"f2\": 0.8635554469614996, \"f0_5\": 0.942889265773577, \"p4\": 0.881155662721362, \"phi\": 0.7769102247564186}, {\"truth_threshold\": -3.04, \"match_probability\": 0.10840213438641137, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9881, \"tn\": 6747, \"fp\": 271, \"fn\": 1900, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8387233681351328, \"tn_rate\": 0.9613850099743516, \"fp_rate\": 0.03861499002564833, \"fn_rate\": 0.16127663186486715, \"precision\": 0.9733057525610717, \"recall\": 0.8387233681351328, \"specificity\": 0.9613850099743516, \"npv\": 0.7802706140858101, \"accuracy\": 0.8845151337837119, \"f1\": 0.9010167327770939, \"f2\": 0.8625776939730428, \"f0_5\": 0.9430414781728989, \"p4\": 0.880768740624664, \"phi\": 0.7764938921198768}, {\"truth_threshold\": -3.02, \"match_probability\": 0.10974929505222096, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9875, \"tn\": 6747, \"fp\": 271, \"fn\": 1906, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8382140735081911, \"tn_rate\": 0.9613850099743516, \"fp_rate\": 0.03861499002564833, \"fn_rate\": 0.16178592649180884, \"precision\": 0.9732899664892568, \"recall\": 0.8382140735081911, \"specificity\": 0.9613850099743516, \"npv\": 0.7797295735583035, \"accuracy\": 0.8841959678706314, \"f1\": 0.9007160122223743, \"f2\": 0.8621442290902741, \"f0_5\": 0.9429007925140839, \"p4\": 0.8804526614879782, \"phi\": 0.775959879160305}, {\"truth_threshold\": -2.98, \"match_probability\": 0.11248769001717858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9874, \"tn\": 6748, \"fp\": 270, \"fn\": 1907, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8381291910703675, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16187080892963246, \"precision\": 0.9733832807570978, \"recall\": 0.8381291910703675, \"specificity\": 0.9615275007124537, \"npv\": 0.7796649335644137, \"accuracy\": 0.8841959678706314, \"f1\": 0.9007069555302166, \"f2\": 0.8620870294056018, \"f0_5\": 0.9429493668468399, \"p4\": 0.8804576012729379, \"phi\": 0.7760026055480103}, {\"truth_threshold\": -2.96, \"match_probability\": 0.11387913869899342, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9873, \"tn\": 6748, \"fp\": 270, \"fn\": 1908, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.838044308632544, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16195569136745608, \"precision\": 0.9733806566104702, \"recall\": 0.838044308632544, \"specificity\": 0.9615275007124537, \"npv\": 0.7795748613678374, \"accuracy\": 0.8841427735517847, \"f1\": 0.9006568144499179, \"f2\": 0.862014772905862, \"f0_5\": 0.9429259068248238, \"p4\": 0.8804049273045547, \"phi\": 0.7759136587702367}, {\"truth_threshold\": -2.94, \"match_probability\": 0.11528556351914263, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9871, \"tn\": 6748, \"fp\": 270, \"fn\": 1910, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8378745437568967, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.1621254562431033, \"precision\": 0.9733754067646189, \"recall\": 0.8378745437568967, \"specificity\": 0.9615275007124537, \"npv\": 0.7793947793947794, \"accuracy\": 0.8840363849140912, \"f1\": 0.9005565185658243, \"f2\": 0.8618702523356326, \"f0_5\": 0.9428789760244531, \"p4\": 0.8802995837160581, \"phi\": 0.7757357964097032}, {\"truth_threshold\": -2.92, \"match_probability\": 0.1167070702330039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9866, \"tn\": 6748, \"fp\": 270, \"fn\": 1915, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8374501315677786, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16254986843222138, \"precision\": 0.97336227308603, \"recall\": 0.8374501315677786, \"specificity\": 0.9615275007124537, \"npv\": 0.7789449382431028, \"accuracy\": 0.8837704133198574, \"f1\": 0.9003056987726422, \"f2\": 0.8615089067411805, \"f0_5\": 0.9427615862398471, \"p4\": 0.8800362500694058, \"phi\": 0.7752913223138093}, {\"truth_threshold\": -2.9, \"match_probability\": 0.1181437639467516, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9863, \"tn\": 6748, \"fp\": 270, \"fn\": 1918, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8371954842543078, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.1628045157456922, \"precision\": 0.9733543866574559, \"recall\": 0.8371954842543078, \"specificity\": 0.9615275007124537, \"npv\": 0.778675282714055, \"accuracy\": 0.8836108303633172, \"f1\": 0.9001551519576526, \"f2\": 0.8612920690919887, \"f0_5\": 0.9426911092844991, \"p4\": 0.879878267212279, \"phi\": 0.775024762381164}, {\"truth_threshold\": -2.88, \"match_probability\": 0.11959574907459691, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9862, \"tn\": 6748, \"fp\": 270, \"fn\": 1919, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8371106018164842, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16288939818351583, \"precision\": 0.9733517568101065, \"recall\": 0.8371106018164842, \"specificity\": 0.9615275007124537, \"npv\": 0.7785854390215761, \"accuracy\": 0.8835576360444705, \"f1\": 0.9001049605257153, \"f2\": 0.8612197848260444, \"f0_5\": 0.9426676097803437, \"p4\": 0.8798256091431943, \"phi\": 0.774935929803197}, {\"truth_threshold\": -2.84, \"match_probability\": 0.12254600750771812, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9859, \"tn\": 6748, \"fp\": 270, \"fn\": 1922, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8368559545030133, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16314404549698666, \"precision\": 0.9733438641524336, \"recall\": 0.8368559545030133, \"specificity\": 0.9615275007124537, \"npv\": 0.778316032295271, \"accuracy\": 0.8833980530879302, \"f1\": 0.8999543587403013, \"f2\": 0.8610029168777182, \"f0_5\": 0.942597089699218, \"p4\": 0.8796676435737069, \"phi\": 0.7746694942185465}, {\"truth_threshold\": -2.82, \"match_probability\": 0.12404448578611339, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9856, \"tn\": 6748, \"fp\": 270, \"fn\": 1925, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8366013071895425, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16339869281045752, \"precision\": 0.9733359668180921, \"recall\": 0.8366013071895425, \"specificity\": 0.9615275007124537, \"npv\": 0.778046811945117, \"accuracy\": 0.88323847013139, \"f1\": 0.8998037157073082, \"f2\": 0.8607860262008734, \"f0_5\": 0.9425265372477766, \"p4\": 0.8795096909427067, \"phi\": 0.7744031517835974}, {\"truth_threshold\": -2.8000000000000003, \"match_probability\": 0.12555866533402688, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9854, \"tn\": 6748, \"fp\": 270, \"fn\": 1927, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8364315423138953, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16356845768610476, \"precision\": 0.9733306993283287, \"recall\": 0.8364315423138953, \"specificity\": 0.9615275007124537, \"npv\": 0.7778674351585014, \"accuracy\": 0.8831320814936965, \"f1\": 0.8997032640949555, \"f2\": 0.8606414197875908, \"f0_5\": 0.9424794842856323, \"p4\": 0.8794043963652203, \"phi\": 0.7742256418630744}, {\"truth_threshold\": -2.7800000000000002, \"match_probability\": 0.12708864643792386, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9853, \"tn\": 6748, \"fp\": 270, \"fn\": 1928, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8363466598760716, \"tn_rate\": 0.9615275007124537, \"fp_rate\": 0.038472499287546306, \"fn_rate\": 0.16365334012392835, \"precision\": 0.973328064802924, \"recall\": 0.8363466598760716, \"specificity\": 0.9615275007124537, \"npv\": 0.7777777777777778, \"accuracy\": 0.8830788871748497, \"f1\": 0.8996530314097881, \"f2\": 0.8605691127919367, \"f0_5\": 0.9424559524037266, \"p4\": 0.8793517512268353, \"phi\": 0.7741369024030662}, {\"truth_threshold\": -2.7600000000000002, \"match_probability\": 0.12863452841989784, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9853, \"tn\": 6749, \"fp\": 269, \"fn\": 1928, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8363466598760716, \"tn_rate\": 0.9616699914505558, \"fp_rate\": 0.03833000854944429, \"fn_rate\": 0.16365334012392835, \"precision\": 0.9734242244615688, \"recall\": 0.8363466598760716, \"specificity\": 0.9616699914505558, \"npv\": 0.7778033882678345, \"accuracy\": 0.8831320814936965, \"f1\": 0.8996941058302516, \"f2\": 0.860584145617161, \"f0_5\": 0.9425280759149783, \"p4\": 0.8794093483151779, \"phi\": 0.7742687801367267}, {\"truth_threshold\": -2.74, \"match_probability\": 0.13019640958968035, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9834, \"tn\": 6749, \"fp\": 269, \"fn\": 1947, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.834733893557423, \"tn_rate\": 0.9616699914505558, \"fp_rate\": 0.03833000854944429, \"fn_rate\": 0.16526610644257703, \"precision\": 0.9733742452736811, \"recall\": 0.834733893557423, \"specificity\": 0.9616699914505558, \"npv\": 0.7761039558417663, \"accuracy\": 0.8821213894356082, \"f1\": 0.8987388046061049, \"f2\": 0.8592098135495483, \"f0_5\": 0.9420803556032418, \"p4\": 0.8784093492342329, \"phi\": 0.7725848504191197}, {\"truth_threshold\": -2.72, \"match_probability\": 0.13177438719593176, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9821, \"tn\": 6752, \"fp\": 266, \"fn\": 1960, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.833630421865716, \"tn_rate\": 0.9620974636648618, \"fp_rate\": 0.037902536335138216, \"fn_rate\": 0.16636957813428402, \"precision\": 0.9736294240111034, \"recall\": 0.833630421865716, \"specificity\": 0.9620974636648618, \"npv\": 0.7750229568411386, \"accuracy\": 0.8815894462471408, \"f1\": 0.8982074263764405, \"f2\": 0.8583139606019822, \"f0_5\": 0.9419900631126629, \"p4\": 0.8778981391180916, \"phi\": 0.7718313131850686}, {\"truth_threshold\": -2.7, \"match_probability\": 0.13336855737682143, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9820, \"tn\": 6752, \"fp\": 266, \"fn\": 1961, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8335455394278923, \"tn_rate\": 0.9620974636648618, \"fp_rate\": 0.037902536335138216, \"fn_rate\": 0.16645446057210764, \"precision\": 0.9736268094388261, \"recall\": 0.8335455394278923, \"specificity\": 0.9620974636648618, \"npv\": 0.7749340066567199, \"accuracy\": 0.8815362519282941, \"f1\": 0.89815704028902, \"f2\": 0.8582415661597623, \"f0_5\": 0.9419664268585132, \"p4\": 0.8778455380916531, \"phi\": 0.7717429466576439}, {\"truth_threshold\": -2.68, \"match_probability\": 0.13497901510990773, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9817, \"tn\": 6752, \"fp\": 266, \"fn\": 1964, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8332908921144215, \"tn_rate\": 0.9620974636648618, \"fp_rate\": 0.037902536335138216, \"fn_rate\": 0.16670910788557847, \"precision\": 0.9736189626103342, \"recall\": 0.8332908921144215, \"specificity\": 0.9620974636648618, \"npv\": 0.7746672785681505, \"accuracy\": 0.8813766689717538, \"f1\": 0.8980058543724845, \"f2\": 0.8580243676473159, \"f0_5\": 0.9418954963252931, \"p4\": 0.8776877434200068, \"phi\": 0.7714779083183232}, {\"truth_threshold\": -2.66, \"match_probability\": 0.13660585416132934, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9805, \"tn\": 6752, \"fp\": 266, \"fn\": 1976, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8322723028605381, \"tn_rate\": 0.9620974636648618, \"fp_rate\": 0.037902536335138216, \"fn_rate\": 0.16772769713946184, \"precision\": 0.9735875285473141, \"recall\": 0.8322723028605381, \"specificity\": 0.9620974636648618, \"npv\": 0.773602199816682, \"accuracy\": 0.8807383371455928, \"f1\": 0.8974006955885044, \"f2\": 0.8571553457470058, \"f0_5\": 0.9416114472294248, \"p4\": 0.8770566904314666, \"phi\": 0.7704186719379824}, {\"truth_threshold\": -2.64, \"match_probability\": 0.1382491670343198, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9804, \"tn\": 6752, \"fp\": 266, \"fn\": 1977, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8321874204227145, \"tn_rate\": 0.9620974636648618, \"fp_rate\": 0.037902536335138216, \"fn_rate\": 0.16781257957728546, \"precision\": 0.9735849056603774, \"recall\": 0.8321874204227145, \"specificity\": 0.9620974636648618, \"npv\": 0.7735135754381945, \"accuracy\": 0.8806851428267461, \"f1\": 0.8973502356871539, \"f2\": 0.8570829107948387, \"f0_5\": 0.9415877528284128, \"p4\": 0.8770041117304846, \"phi\": 0.770330468345491}, {\"truth_threshold\": -2.6, \"match_probability\": 0.14158557762986687, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9797, \"tn\": 6838, \"fp\": 180, \"fn\": 1984, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8315932433579493, \"tn_rate\": 0.9743516671416358, \"fp_rate\": 0.025648332858364205, \"fn_rate\": 0.16840675664205076, \"precision\": 0.9819585045604892, \"recall\": 0.8315932433579493, \"specificity\": 0.9743516671416358, \"npv\": 0.7751076853321243, \"accuracy\": 0.8848874940156392, \"f1\": 0.9005423292582039, \"f2\": 0.8578658867620532, \"f0_5\": 0.947687128789491, \"p4\": 0.8815716974156859, \"phi\": 0.7811233210289296}, {\"truth_threshold\": -2.56, \"match_probability\": 0.14498895966649594, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9791, \"tn\": 6838, \"fp\": 180, \"fn\": 1990, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8310839487310075, \"tn_rate\": 0.9743516671416358, \"fp_rate\": 0.025648332858364205, \"fn_rate\": 0.16891605126899245, \"precision\": 0.9819476481797212, \"recall\": 0.8310839487310075, \"specificity\": 0.9743516671416358, \"npv\": 0.7745808790212959, \"accuracy\": 0.8845683281025587, \"f1\": 0.9002390584773814, \"f2\": 0.8574305981259305, \"f0_5\": 0.9475466950546791, \"p4\": 0.8812559659655541, \"phi\": 0.7805991418336142}, {\"truth_threshold\": -2.54, \"match_probability\": 0.14671598130769928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9789, \"tn\": 6838, \"fp\": 180, \"fn\": 1992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8309141838553603, \"tn_rate\": 0.9743516671416358, \"fp_rate\": 0.025648332858364205, \"fn_rate\": 0.16908581614463966, \"precision\": 0.9819440264820944, \"recall\": 0.8309141838553603, \"specificity\": 0.9743516671416358, \"npv\": 0.77440543601359, \"accuracy\": 0.8844619394648652, \"f1\": 0.9001379310344828, \"f2\": 0.8572854815826809, \"f0_5\": 0.9474998548115454, \"p4\": 0.8811507328385281, \"phi\": 0.7804244957506832}, {\"truth_threshold\": -2.52, \"match_probability\": 0.14846000230384404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9785, \"tn\": 6838, \"fp\": 180, \"fn\": 1996, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8305746541040658, \"tn_rate\": 0.9743516671416358, \"fp_rate\": 0.025648332858364205, \"fn_rate\": 0.16942534589593414, \"precision\": 0.9819367787255394, \"recall\": 0.8305746541040658, \"specificity\": 0.9743516671416358, \"npv\": 0.7740547883178628, \"accuracy\": 0.8842491621894781, \"f1\": 0.8999356203439713, \"f2\": 0.8569952179929584, \"f0_5\": 0.9474061307875525, \"p4\": 0.88094028257729, \"phi\": 0.7800753238970061}, {\"truth_threshold\": -2.5, \"match_probability\": 0.15022110482233483, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9784, \"tn\": 6838, \"fp\": 180, \"fn\": 1997, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8304897716662423, \"tn_rate\": 0.9743516671416358, \"fp_rate\": 0.025648332858364205, \"fn_rate\": 0.16951022833375776, \"precision\": 0.9819349658771578, \"recall\": 0.8304897716662423, \"specificity\": 0.9743516671416358, \"npv\": 0.7739671760045275, \"accuracy\": 0.8841959678706314, \"f1\": 0.8998850310416188, \"f2\": 0.8569226457399103, \"f0_5\": 0.9473826907062765, \"p4\": 0.8808876733387456, \"phi\": 0.7799880559790722}, {\"truth_threshold\": -2.48, \"match_probability\": 0.15199936933317765, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9778, \"tn\": 6840, \"fp\": 178, \"fn\": 2003, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8299804770393006, \"tn_rate\": 0.9746366486178398, \"fp_rate\": 0.02536335138216016, \"fn_rate\": 0.17001952296069944, \"precision\": 0.9821213338690237, \"recall\": 0.8299804770393006, \"specificity\": 0.9746366486178398, \"npv\": 0.7734931584303969, \"accuracy\": 0.8839831905952444, \"f1\": 0.8996641670883747, \"f2\": 0.8565171688857743, \"f0_5\": 0.9473888189128961, \"p4\": 0.8806864884701, \"phi\": 0.7797309541751175}, {\"truth_threshold\": -2.46, \"match_probability\": 0.15379487455210342, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9771, \"tn\": 6841, \"fp\": 177, \"fn\": 2010, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8293862999745353, \"tn_rate\": 0.9747791393559418, \"fp_rate\": 0.025220860644058138, \"fn_rate\": 0.17061370002546472, \"precision\": 0.9822074788902292, \"recall\": 0.8293862999745353, \"specificity\": 0.9747791393559418, \"npv\": 0.7729070161563665, \"accuracy\": 0.883664024682164, \"f1\": 0.8993510976114869, \"f2\": 0.8560239697224559, \"f0_5\": 0.9472980047699378, \"p4\": 0.8803755186858071, \"phi\": 0.7792541175085037}, {\"truth_threshold\": -2.42, \"match_probability\": 0.1574379128610021, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9768, \"tn\": 6842, \"fp\": 176, \"fn\": 2013, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8291316526610645, \"tn_rate\": 0.9749216300940439, \"fp_rate\": 0.025078369905956112, \"fn_rate\": 0.17086834733893558, \"precision\": 0.9823008849557522, \"recall\": 0.8291316526610645, \"specificity\": 0.9749216300940439, \"npv\": 0.7726708074534161, \"accuracy\": 0.8835576360444705, \"f1\": 0.8992405063291139, \"f2\": 0.8558211256746338, \"f0_5\": 0.9473010454448475, \"p4\": 0.8802749504548907, \"phi\": 0.7791260922782471}, {\"truth_threshold\": -2.4, \"match_probability\": 0.15928559409228404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9767, \"tn\": 6842, \"fp\": 176, \"fn\": 2014, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8290467702232408, \"tn_rate\": 0.9749216300940439, \"fp_rate\": 0.025078369905956112, \"fn_rate\": 0.1709532297767592, \"precision\": 0.9822991048979182, \"recall\": 0.8290467702232408, \"specificity\": 0.9749216300940439, \"npv\": 0.7725835591689251, \"accuracy\": 0.8835044417256237, \"f1\": 0.8991898361259436, \"f2\": 0.8557485061419033, \"f0_5\": 0.947277559016934, \"p4\": 0.8802223610202955, \"phi\": 0.779039028455616}, {\"truth_threshold\": -2.38, \"match_probability\": 0.16115081219721364, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9766, \"tn\": 6842, \"fp\": 176, \"fn\": 2015, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8289618877854172, \"tn_rate\": 0.9749216300940439, \"fp_rate\": 0.025078369905956112, \"fn_rate\": 0.17103811221458282, \"precision\": 0.9822973244819956, \"recall\": 0.8289618877854172, \"specificity\": 0.9749216300940439, \"npv\": 0.7724963305859772, \"accuracy\": 0.8834512474067769, \"f1\": 0.8991391612576531, \"f2\": 0.8556758840640661, \"f0_5\": 0.9472540689441115, \"p4\": 0.8801697728979518, \"phi\": 0.7789519745845301}, {\"truth_threshold\": -2.36, \"match_probability\": 0.16303363625026068, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9763, \"tn\": 6842, \"fp\": 176, \"fn\": 2018, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8287072404719463, \"tn_rate\": 0.9749216300940439, \"fp_rate\": 0.025078369905956112, \"fn_rate\": 0.17129275952805365, \"precision\": 0.9822919810846161, \"recall\": 0.8287072404719463, \"specificity\": 0.9749216300940439, \"npv\": 0.772234762979684, \"accuracy\": 0.8832916644502368, \"f1\": 0.8989871086556169, \"f2\": 0.8554580025585756, \"f0_5\": 0.9471835768477016, \"p4\": 0.8800120163957167, \"phi\": 0.7786908726473089}, {\"truth_threshold\": -2.34, \"match_probability\": 0.1649341332206679, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9759, \"tn\": 6843, \"fp\": 175, \"fn\": 2022, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8283677107206519, \"tn_rate\": 0.9750641208321459, \"fp_rate\": 0.02493587916785409, \"fn_rate\": 0.1716322892793481, \"precision\": 0.9823837326353936, \"recall\": 0.8283677107206519, \"specificity\": 0.9750641208321459, \"npv\": 0.7719120135363791, \"accuracy\": 0.8831320814936965, \"f1\": 0.8988256965231407, \"f2\": 0.8551824459322094, \"f0_5\": 0.9471630723838733, \"p4\": 0.8798588891620353, \"phi\": 0.7784762121473408}, {\"truth_threshold\": -2.32, \"match_probability\": 0.16685236791258687, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9753, \"tn\": 6843, \"fp\": 175, \"fn\": 2028, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8278584160937102, \"tn_rate\": 0.9750641208321459, \"fp_rate\": 0.02493587916785409, \"fn_rate\": 0.17214158390628978, \"precision\": 0.9823730862207897, \"recall\": 0.8278584160937102, \"specificity\": 0.9750641208321459, \"npv\": 0.7713899222184647, \"accuracy\": 0.882812915580616, \"f1\": 0.8985213505919204, \"f2\": 0.8547465470097455, \"f0_5\": 0.9470219253102363, \"p4\": 0.879543438743682, \"phi\": 0.7779545661392518}, {\"truth_threshold\": -2.3000000000000003, \"match_probability\": 0.1687884029048976, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9752, \"tn\": 6845, \"fp\": 173, \"fn\": 2029, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8277735336558866, \"tn_rate\": 0.9753491023083499, \"fp_rate\": 0.024650897691650044, \"fn_rate\": 0.1722264663441134, \"precision\": 0.9825692695214105, \"recall\": 0.8277735336558866, \"specificity\": 0.9753491023083499, \"npv\": 0.7713545188190218, \"accuracy\": 0.8828661098994628, \"f1\": 0.8985533953745508, \"f2\": 0.8547038510753914, \"f0_5\": 0.9471455488432625, \"p4\": 0.8796052412725974, \"phi\": 0.7781344743732354}, {\"truth_threshold\": -2.2800000000000002, \"match_probability\": 0.17074229849074432, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9750, \"tn\": 6846, \"fp\": 172, \"fn\": 2031, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8276037687802393, \"tn_rate\": 0.9754915930464519, \"fp_rate\": 0.024508406953548018, \"fn_rate\": 0.17239623121976064, \"precision\": 0.9826647853255392, \"recall\": 0.8276037687802393, \"specificity\": 0.9754915930464519, \"npv\": 0.7712064886786076, \"accuracy\": 0.882812915580616, \"f1\": 0.8984932958577155, \"f2\": 0.8545735020860359, \"f0_5\": 0.9471720841671686, \"p4\": 0.8795572813977282, \"phi\": 0.7780941611187614}, {\"truth_threshold\": -2.2600000000000002, \"match_probability\": 0.17271411261681832, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9748, \"tn\": 6846, \"fp\": 172, \"fn\": 2033, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8274340039045921, \"tn_rate\": 0.9754915930464519, \"fp_rate\": 0.024508406953548018, \"fn_rate\": 0.17256599609540785, \"precision\": 0.9826612903225806, \"recall\": 0.8274340039045921, \"specificity\": 0.9754915930464519, \"npv\": 0.7710327739610316, \"accuracy\": 0.8827065269429225, \"f1\": 0.8983917791806829, \"f2\": 0.8544281607180422, \"f0_5\": 0.9471250072870717, \"p4\": 0.8794521453999312, \"phi\": 0.7779204692533666}, {\"truth_threshold\": -2.24, \"match_probability\": 0.1747039008224231, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9743, \"tn\": 6848, \"fp\": 170, \"fn\": 2038, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8270095917154741, \"tn_rate\": 0.975776574522656, \"fp_rate\": 0.024223425477343973, \"fn_rate\": 0.17299040828452594, \"precision\": 0.9828508019772016, \"recall\": 0.8270095917154741, \"specificity\": 0.975776574522656, \"npv\": 0.770650461399955, \"accuracy\": 0.8825469439863822, \"f1\": 0.8982207061860422, \"f2\": 0.8540947104511106, \"f0_5\": 0.9471545505803667, \"p4\": 0.8793036680739378, \"phi\": 0.7777534252461605}, {\"truth_threshold\": -2.22, \"match_probability\": 0.17671171617835496, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9741, \"tn\": 6848, \"fp\": 170, \"fn\": 2040, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8268398268398268, \"tn_rate\": 0.975776574522656, \"fp_rate\": 0.024223425477343973, \"fn_rate\": 0.17316017316017315, \"precision\": 0.9828473413379074, \"recall\": 0.8268398268398268, \"specificity\": 0.975776574522656, \"npv\": 0.7704770477047704, \"accuracy\": 0.8824405553486888, \"f1\": 0.8981191222570533, \"f2\": 0.8539493293591655, \"f0_5\": 0.947107438016529, \"p4\": 0.8791985474495952, \"phi\": 0.7775799059852467}, {\"truth_threshold\": -2.2, \"match_probability\": 0.17873760922563603, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9729, \"tn\": 6848, \"fp\": 170, \"fn\": 2052, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8258212375859435, \"tn_rate\": 0.975776574522656, \"fp_rate\": 0.024223425477343973, \"fn_rate\": 0.17417876241405653, \"precision\": 0.9828265481361754, \"recall\": 0.8258212375859435, \"specificity\": 0.975776574522656, \"npv\": 0.7694382022471911, \"accuracy\": 0.8818022235225278, \"f1\": 0.897509225092251, \"f2\": 0.8530768286480893, \"f0_5\": 0.9468244545224517, \"p4\": 0.8785679315413675, \"phi\": 0.7765396178133658}, {\"truth_threshold\": -2.18, \"match_probability\": 0.18078162791413613, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9724, \"tn\": 6849, \"fp\": 169, \"fn\": 2057, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8253968253968254, \"tn_rate\": 0.975919065260758, \"fp_rate\": 0.02408093473924195, \"fn_rate\": 0.1746031746031746, \"precision\": 0.9829172141918529, \"recall\": 0.8253968253968254, \"specificity\": 0.975919065260758, \"npv\": 0.7690321131821244, \"accuracy\": 0.8815894462471408, \"f1\": 0.897296299713943, \"f2\": 0.8527281337145062, \"f0_5\": 0.9467801296905731, \"p4\": 0.8783623811230143, \"phi\": 0.7762402624149621}, {\"truth_threshold\": -2.16, \"match_probability\": 0.18284381754112208, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9707, \"tn\": 6849, \"fp\": 169, \"fn\": 2074, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.823953823953824, \"tn_rate\": 0.975919065260758, \"fp_rate\": 0.02408093473924195, \"fn_rate\": 0.17604617604617603, \"precision\": 0.9828878088294857, \"recall\": 0.823953823953824, \"specificity\": 0.975919065260758, \"npv\": 0.7675669617841533, \"accuracy\": 0.8806851428267461, \"f1\": 0.896430715242185, \"f2\": 0.8514912280701754, \"f0_5\": 0.9463780832602126, \"p4\": 0.8774694187523806, \"phi\": 0.7747699178437414}, {\"truth_threshold\": -2.14, \"match_probability\": 0.18492422068977335, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9704, \"tn\": 6850, \"fp\": 168, \"fn\": 2077, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8236991766403531, \"tn_rate\": 0.97606155599886, \"fp_rate\": 0.023938444001139925, \"fn_rate\": 0.1763008233596469, \"precision\": 0.9829821717990276, \"recall\": 0.8236991766403531, \"specificity\": 0.97606155599886, \"npv\": 0.7673350509689706, \"accuracy\": 0.8805787541890526, \"f1\": 0.8963192167367109, \"f2\": 0.851287809670854, \"f0_5\": 0.9463808539273245, \"p4\": 0.877369009606329, \"phi\": 0.7746445970848527}, {\"truth_threshold\": -2.12, \"match_probability\": 0.187022877167705, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9699, \"tn\": 6850, \"fp\": 168, \"fn\": 2082, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.823274764451235, \"tn_rate\": 0.97606155599886, \"fp_rate\": 0.023938444001139925, \"fn_rate\": 0.17672523554876496, \"precision\": 0.9829735481909395, \"recall\": 0.823274764451235, \"specificity\": 0.97606155599886, \"npv\": 0.7669055082848186, \"accuracy\": 0.8803127825948188, \"f1\": 0.8960643015521065, \"f2\": 0.8509238300784334, \"f0_5\": 0.9462623660949482, \"p4\": 0.8771064582292656, \"phi\": 0.774212868522554}, {\"truth_threshold\": -2.1, \"match_probability\": 0.18913982394553902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9694, \"tn\": 6857, \"fp\": 161, \"fn\": 2087, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.822850352262117, \"tn_rate\": 0.9770589911655743, \"fp_rate\": 0.022941008834425763, \"fn_rate\": 0.17714964773788303, \"precision\": 0.9836631151699645, \"recall\": 0.822850352262117, \"specificity\": 0.9770589911655743, \"npv\": 0.7666592128801432, \"accuracy\": 0.8804191712325123, \"f1\": 0.896099094102422, \"f2\": 0.8506642798223907, \"f0_5\": 0.9466611980234761, \"p4\": 0.8772437353362168, \"phi\": 0.7747192012527495}, {\"truth_threshold\": -2.08, \"match_probability\": 0.19127509509556725, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9692, \"tn\": 6857, \"fp\": 161, \"fn\": 2089, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8226805873864698, \"tn_rate\": 0.9770589911655743, \"fp_rate\": 0.022941008834425763, \"fn_rate\": 0.17731941261353026, \"precision\": 0.9836597990459759, \"recall\": 0.8226805873864698, \"specificity\": 0.9770589911655743, \"npv\": 0.7664878157835904, \"accuracy\": 0.8803127825948188, \"f1\": 0.8959970416936304, \"f2\": 0.8505186303245169, \"f0_5\": 0.9466137948547653, \"p4\": 0.8771387262186336, \"phi\": 0.7745467948004292}, {\"truth_threshold\": -2.06, \"match_probability\": 0.1934287217305493, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9689, \"tn\": 6858, \"fp\": 160, \"fn\": 2092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8224259400729989, \"tn_rate\": 0.9772014819036763, \"fp_rate\": 0.022798518096323737, \"fn_rate\": 0.1775740599270011, \"precision\": 0.9837546959082141, \"recall\": 0.8224259400729989, \"specificity\": 0.9772014819036763, \"npv\": 0.7662569832402235, \"accuracy\": 0.8802063939571254, \"f1\": 0.8958853444290338, \"f2\": 0.8503150615203693, \"f0_5\": 0.9466166441956347, \"p4\": 0.8770383184969817, \"phi\": 0.7744223043339225}, {\"truth_threshold\": -2.04, \"match_probability\": 0.19560073194269076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9686, \"tn\": 6860, \"fp\": 158, \"fn\": 2095, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.822171292759528, \"tn_rate\": 0.9774864633798803, \"fp_rate\": 0.022513536620119692, \"fn_rate\": 0.17782870724047195, \"precision\": 0.9839496139780577, \"recall\": 0.822171292759528, \"specificity\": 0.9774864633798803, \"npv\": 0.7660524846454495, \"accuracy\": 0.8801531996382786, \"f1\": 0.8958150289017341, \"f2\": 0.8501263867434349, \"f0_5\": 0.9466935121293274, \"p4\": 0.8769950019926287, \"phi\": 0.7744320469125235}, {\"truth_threshold\": -2.02, \"match_probability\": 0.19779115074284692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9685, \"tn\": 6860, \"fp\": 158, \"fn\": 2096, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8220864103217045, \"tn_rate\": 0.9774864633798803, \"fp_rate\": 0.022513536620119692, \"fn_rate\": 0.17791358967829557, \"precision\": 0.983947983338413, \"recall\": 0.8220864103217045, \"specificity\": 0.9774864633798803, \"npv\": 0.7659669495310406, \"accuracy\": 0.8801000053194319, \"f1\": 0.895763965963744, \"f2\": 0.850053539768638, \"f0_5\": 0.9466697945379547, \"p4\": 0.8769425046122105, \"phi\": 0.774345942009229}, {\"truth_threshold\": -2.0, \"match_probability\": 0.2, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9682, \"tn\": 6874, \"fp\": 144, \"fn\": 2099, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8218317630082336, \"tn_rate\": 0.9794813337133086, \"fp_rate\": 0.020518666286691366, \"fn_rate\": 0.1781682369917664, \"precision\": 0.9853450030531243, \"recall\": 0.8218317630082336, \"specificity\": 0.9794813337133086, \"npv\": 0.7660760057951632, \"accuracy\": 0.8806851428267461, \"f1\": 0.8961910491970195, \"f2\": 0.8500438981562775, \"f0_5\": 0.9476362924537536, \"p4\": 0.8775838501212686, \"phi\": 0.7759661690704349}, {\"truth_threshold\": -1.98, \"match_probability\": 0.20222729838105732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9672, \"tn\": 6912, \"fp\": 106, \"fn\": 2109, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8209829386299975, \"tn_rate\": 0.9848959817611855, \"fp_rate\": 0.015104018238814477, \"fn_rate\": 0.17901706137000253, \"precision\": 0.9891593372877889, \"recall\": 0.8209829386299975, \"specificity\": 0.9848959817611855, \"npv\": 0.766212171599601, \"accuracy\": 0.882174583754455, \"f1\": 0.8972586854677861, \"f2\": 0.8498822536993428, \"f0_5\": 0.9502289116381427, \"p4\": 0.8792235346049531, \"phi\": 0.7802166212510655}, {\"truth_threshold\": -1.96, \"match_probability\": 0.2044730612910191, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9666, \"tn\": 6912, \"fp\": 106, \"fn\": 2115, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8204736440030558, \"tn_rate\": 0.9848959817611855, \"fp_rate\": 0.015104018238814477, \"fn_rate\": 0.17952635599694422, \"precision\": 0.9891526811297585, \"recall\": 0.8204736440030558, \"specificity\": 0.9848959817611855, \"npv\": 0.765702891326022, \"accuracy\": 0.8818554178413746, \"f1\": 0.8969517004593328, \"f2\": 0.8494446006749157, \"f0_5\": 0.9500874796044743, \"p4\": 0.8789084539621893, \"phi\": 0.779703629525196}, {\"truth_threshold\": -1.94, \"match_probability\": 0.2067373008135667, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9663, \"tn\": 6913, \"fp\": 105, \"fn\": 2118, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.820218996689585, \"tn_rate\": 0.9850384724992876, \"fp_rate\": 0.014961527500712453, \"fn_rate\": 0.17978100331041508, \"precision\": 0.9892506142506142, \"recall\": 0.820218996689585, \"specificity\": 0.9850384724992876, \"npv\": 0.765474476802126, \"accuracy\": 0.881749029203681, \"f1\": 0.896839760545733, \"f2\": 0.8492406665260493, \"f0_5\": 0.9500914400330364, \"p4\": 0.8788078228941264, \"phi\": 0.7795819499927322}, {\"truth_threshold\": -1.92, \"match_probability\": 0.2090200256521214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9660, \"tn\": 6915, \"fp\": 103, \"fn\": 2121, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8199643493761141, \"tn_rate\": 0.9853234539754916, \"fp_rate\": 0.014676546024508406, \"fn_rate\": 0.1800356506238859, \"precision\": 0.9894499641503636, \"recall\": 0.8199643493761141, \"specificity\": 0.9853234539754916, \"npv\": 0.7652722443559097, \"accuracy\": 0.8816958348848343, \"f1\": 0.8967694021537319, \"f2\": 0.8490516286673581, \"f0_5\": 0.9501701650502626, \"p4\": 0.8787640795320899, \"phi\": 0.7795951445645934}, {\"truth_threshold\": -1.8800000000000001, \"match_probability\": 0.213640948839702, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9655, \"tn\": 6915, \"fp\": 103, \"fn\": 2126, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.819539937186996, \"tn_rate\": 0.9853234539754916, \"fp_rate\": 0.014676546024508406, \"fn_rate\": 0.180460062813004, \"precision\": 0.9894445583111293, \"recall\": 0.819539937186996, \"specificity\": 0.9853234539754916, \"npv\": 0.7648490211259816, \"accuracy\": 0.8814298632906006, \"f1\": 0.896513301453178, \"f2\": 0.8486867550367427, \"f0_5\": 0.9500521520083444, \"p4\": 0.8785015702560164, \"phi\": 0.7791683311569101}, {\"truth_threshold\": -1.86, \"match_probability\": 0.2159791471714348, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9652, \"tn\": 6915, \"fp\": 103, \"fn\": 2129, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8192852898735251, \"tn_rate\": 0.9853234539754916, \"fp_rate\": 0.014676546024508406, \"fn_rate\": 0.18071471012647483, \"precision\": 0.9894413121476167, \"recall\": 0.8192852898735251, \"specificity\": 0.9853234539754916, \"npv\": 0.7645953118089341, \"accuracy\": 0.8812702803340603, \"f1\": 0.8963595839524517, \"f2\": 0.8484678000668084, \"f0_5\": 0.9499812995807169, \"p4\": 0.8783440788505906, \"phi\": 0.7789123575973318}, {\"truth_threshold\": -1.84, \"match_probability\": 0.21833583067084317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9650, \"tn\": 6916, \"fp\": 102, \"fn\": 2131, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.819115524997878, \"tn_rate\": 0.9854659447135936, \"fp_rate\": 0.014534055286406384, \"fn_rate\": 0.18088447500212207, \"precision\": 0.989540607054963, \"recall\": 0.819115524997878, \"specificity\": 0.9854659447135936, \"npv\": 0.7644523046313695, \"accuracy\": 0.8812170860152135, \"f1\": 0.8962987043143082, \"f2\": 0.8483367325409663, \"f0_5\": 0.9500088601862609, \"p4\": 0.878295964699765, \"phi\": 0.7788765788214594}, {\"truth_threshold\": -1.82, \"match_probability\": 0.2207109902760858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9647, \"tn\": 6916, \"fp\": 102, \"fn\": 2134, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8188608776844071, \"tn_rate\": 0.9854659447135936, \"fp_rate\": 0.014534055286406384, \"fn_rate\": 0.1811391223155929, \"precision\": 0.9895373884500974, \"recall\": 0.8188608776844071, \"specificity\": 0.9854659447135936, \"npv\": 0.7641988950276243, \"accuracy\": 0.8810575030586734, \"f1\": 0.8961449140733859, \"f2\": 0.8481177360082992, \"f0_5\": 0.9499379640388365, \"p4\": 0.8781384888439608, \"phi\": 0.7786207740715082}, {\"truth_threshold\": -1.8, \"match_probability\": 0.22310461320426225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9620, \"tn\": 6921, \"fp\": 97, \"fn\": 2161, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8165690518631695, \"tn_rate\": 0.9861783984041037, \"fp_rate\": 0.013821601595896267, \"fn_rate\": 0.1834309481368305, \"precision\": 0.9900174951116599, \"recall\": 0.8165690518631695, \"specificity\": 0.9861783984041037, \"npv\": 0.7620568156793658, \"accuracy\": 0.8798872280440448, \"f1\": 0.8949669736719695, \"f2\": 0.8462201579845534, \"f0_5\": 0.9496732413275681, \"p4\": 0.8770058943458882, \"phi\": 0.7769978992243239}, {\"truth_threshold\": -1.78, \"match_probability\": 0.225516682897264, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9618, \"tn\": 6921, \"fp\": 97, \"fn\": 2163, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8163992869875223, \"tn_rate\": 0.9861783984041037, \"fp_rate\": 0.013821601595896267, \"fn_rate\": 0.1836007130124777, \"precision\": 0.9900154400411735, \"recall\": 0.8163992869875223, \"specificity\": 0.9861783984041037, \"npv\": 0.761889035667107, \"accuracy\": 0.8797808394063514, \"f1\": 0.8948641607740975, \"f2\": 0.8460739984869544, \"f0_5\": 0.9496257972788847, \"p4\": 0.8769009718035451, \"phi\": 0.7768280078302763}, {\"truth_threshold\": -1.76, \"match_probability\": 0.22794717896853242, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9617, \"tn\": 6923, \"fp\": 95, \"fn\": 2164, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8163144045496986, \"tn_rate\": 0.9864633798803077, \"fp_rate\": 0.01353662011969222, \"fn_rate\": 0.18368559545030133, \"precision\": 0.9902182866556837, \"recall\": 0.8163144045496986, \"specificity\": 0.9864633798803077, \"npv\": 0.7618575987674701, \"accuracy\": 0.8798340337251982, \"f1\": 0.8948960126552831, \"f2\": 0.8460306847772538, \"f0_5\": 0.9497521183511426, \"p4\": 0.8769621715940641, \"phi\": 0.7770133930784171}, {\"truth_threshold\": -1.74, \"match_probability\": 0.2303960771507819, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9616, \"tn\": 6923, \"fp\": 95, \"fn\": 2165, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.816229522111875, \"tn_rate\": 0.9864633798803077, \"fp_rate\": 0.01353662011969222, \"fn_rate\": 0.18377047788812495, \"precision\": 0.9902172793739059, \"recall\": 0.816229522111875, \"specificity\": 0.9864633798803077, \"npv\": 0.7617737676056338, \"accuracy\": 0.8797808394063514, \"f1\": 0.8948445933370557, \"f2\": 0.8459575965514208, \"f0_5\": 0.9497283950617283, \"p4\": 0.8769097117643143, \"phi\": 0.7769284881970455}, {\"truth_threshold\": -1.72, \"match_probability\": 0.23286334924474508, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9614, \"tn\": 6923, \"fp\": 95, \"fn\": 2167, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8160597572362278, \"tn_rate\": 0.9864633798803077, \"fp_rate\": 0.01353662011969222, \"fn_rate\": 0.1839402427637722, \"precision\": 0.9902152641878669, \"recall\": 0.8160597572362278, \"specificity\": 0.9864633798803077, \"npv\": 0.7616061606160616, \"accuracy\": 0.8796744507686579, \"f1\": 0.8947417403443462, \"f2\": 0.8458114123836503, \"f0_5\": 0.949680937234526, \"p4\": 0.876804795527584, \"phi\": 0.7767587066683401}, {\"truth_threshold\": -1.7, \"match_probability\": 0.2353489630689996, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9613, \"tn\": 6923, \"fp\": 95, \"fn\": 2168, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8159748747984042, \"tn_rate\": 0.9864633798803077, \"fp_rate\": 0.01353662011969222, \"fn_rate\": 0.18402512520159578, \"precision\": 0.9902142562834776, \"recall\": 0.8159748747984042, \"specificity\": 0.9864633798803077, \"npv\": 0.7615223847761522, \"accuracy\": 0.8796212564498112, \"f1\": 0.8946903066685281, \"f2\": 0.8457383164414415, \"f0_5\": 0.9496572026949598, \"p4\": 0.8767523391188324, \"phi\": 0.7766738300148439}, {\"truth_threshold\": -1.68, \"match_probability\": 0.2378528824109348, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9612, \"tn\": 6926, \"fp\": 92, \"fn\": 2169, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8158899923605806, \"tn_rate\": 0.9868908520946138, \"fp_rate\": 0.01310914790538615, \"fn_rate\": 0.1841100076394194, \"precision\": 0.9905193734542457, \"recall\": 0.8158899923605806, \"specificity\": 0.9868908520946138, \"npv\": 0.7615173172072567, \"accuracy\": 0.8797276450875047, \"f1\": 0.8947637886897836, \"f2\": 0.8457098613359612, \"f0_5\": 0.9498586872739491, \"p4\": 0.8768703376629254, \"phi\": 0.7769946264875521}, {\"truth_threshold\": -1.6600000000000001, \"match_probability\": 0.24037506697891697, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9605, \"tn\": 6929, \"fp\": 89, \"fn\": 2176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8152958152958153, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.1847041847041847, \"precision\": 0.9908190633381473, \"recall\": 0.8152958152958153, \"specificity\": 0.98731832430892, \"npv\": 0.7610104338275673, \"accuracy\": 0.8795148678121176, \"f1\": 0.8945285215366705, \"f2\": 0.8452427047766553, \"f0_5\": 0.949917914433214, \"p4\": 0.8766735770982503, \"phi\": 0.7768069161620027}, {\"truth_threshold\": -1.6400000000000001, \"match_probability\": 0.2429154723557138, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9603, \"tn\": 6929, \"fp\": 89, \"fn\": 2178, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8151260504201681, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18487394957983194, \"precision\": 0.9908171687990095, \"recall\": 0.8151260504201681, \"specificity\": 0.98731832430892, \"npv\": 0.7608433073459976, \"accuracy\": 0.8794084791744242, \"f1\": 0.8944255576770829, \"f2\": 0.8450964517037455, \"f0_5\": 0.9498704227581158, \"p4\": 0.8765686772812255, \"phi\": 0.776637444879365}, {\"truth_threshold\": -1.62, \"match_probability\": 0.2454740499532359, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9599, \"tn\": 6929, \"fp\": 89, \"fn\": 2182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8147865206688736, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.1852134793311264, \"precision\": 0.990813377374071, \"recall\": 0.8147865206688736, \"specificity\": 0.98731832430892, \"npv\": 0.7605092745033476, \"accuracy\": 0.8791957018990372, \"f1\": 0.894219572406726, \"f2\": 0.8448039146659156, \"f0_5\": 0.9497753942967961, \"p4\": 0.8763588911626516, \"phi\": 0.7762986147175851}, {\"truth_threshold\": -1.6, \"match_probability\": 0.2480507469686566, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9593, \"tn\": 6929, \"fp\": 89, \"fn\": 2188, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.814277226041932, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18572277395806808, \"precision\": 0.9908076843627349, \"recall\": 0.814277226041932, \"specificity\": 0.98731832430892, \"npv\": 0.7600087748162773, \"accuracy\": 0.8788765359859567, \"f1\": 0.8939104505427946, \"f2\": 0.8443650318628314, \"f0_5\": 0.9496327387198321, \"p4\": 0.8760442456670421, \"phi\": 0.7757906501164332}, {\"truth_threshold\": -1.58, \"match_probability\": 0.25064550634196875, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9591, \"tn\": 6929, \"fp\": 89, \"fn\": 2190, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8141074611662847, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18589253883371532, \"precision\": 0.9908057851239669, \"recall\": 0.8141074611662847, \"specificity\": 0.98731832430892, \"npv\": 0.7598420879482399, \"accuracy\": 0.8787701473482632, \"f1\": 0.8938073715111132, \"f2\": 0.8442187169917611, \"f0_5\": 0.9495851567295697, \"p4\": 0.8759393727887095, \"phi\": 0.7756214033226424}, {\"truth_threshold\": -1.56, \"match_probability\": 0.2532582667150385, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9590, \"tn\": 6929, \"fp\": 89, \"fn\": 2191, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8140225787284611, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.1859774212715389, \"precision\": 0.990804835210249, \"recall\": 0.8140225787284611, \"specificity\": 0.98731832430892, \"npv\": 0.7597587719298246, \"accuracy\": 0.8787169530294164, \"f1\": 0.8937558247903076, \"f2\": 0.8441455556924811, \"f0_5\": 0.9495613600807968, \"p4\": 0.8758869380243364, \"phi\": 0.7755367939257432}, {\"truth_threshold\": -1.52, \"match_probability\": 0.2585375233025599, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9588, \"tn\": 6929, \"fp\": 89, \"fn\": 2193, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8138528138528138, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18614718614718614, \"precision\": 0.9908029347938411, \"recall\": 0.8138528138528138, \"specificity\": 0.98731832430892, \"npv\": 0.7595921946941461, \"accuracy\": 0.8786105643917229, \"f1\": 0.8936527169354087, \"f2\": 0.8439992253657506, \"f0_5\": 0.9495137554714889, \"p4\": 0.8757820718407365, \"phi\": 0.7753676031166844}, {\"truth_threshold\": -1.5, \"match_probability\": 0.2612038749637415, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9587, \"tn\": 6929, \"fp\": 89, \"fn\": 2194, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8137679314149903, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18623206858500976, \"precision\": 0.9908019842910294, \"recall\": 0.8137679314149903, \"specificity\": 0.98731832430892, \"npv\": 0.759508933464869, \"accuracy\": 0.8785573700728763, \"f1\": 0.893601155799972, \"f2\": 0.8439260563380282, \"f0_5\": 0.9494899475091612, \"p4\": 0.8757296404197333, \"phi\": 0.7752830216984268}, {\"truth_threshold\": -1.48, \"match_probability\": 0.2638879384476761, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9568, \"tn\": 6929, \"fp\": 89, \"fn\": 2213, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8121551650963416, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18784483490365844, \"precision\": 0.9907838873356115, \"recall\": 0.8121551650963416, \"specificity\": 0.98731832430892, \"npv\": 0.7579304309779041, \"accuracy\": 0.877546678014788, \"f1\": 0.892620580278011, \"f2\": 0.8425353551364012, \"f0_5\": 0.9490368783352179, \"p4\": 0.8747336538163843, \"phi\": 0.773677742105709}, {\"truth_threshold\": -1.46, \"match_probability\": 0.26658963034795197, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9562, \"tn\": 6929, \"fp\": 89, \"fn\": 2219, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8116458704693998, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18835412953060013, \"precision\": 0.9907781577038649, \"recall\": 0.8116458704693998, \"specificity\": 0.98731832430892, \"npv\": 0.7574333187581985, \"accuracy\": 0.8772275121017076, \"f1\": 0.8923105636431504, \"f2\": 0.8420959929546455, \"f0_5\": 0.9488935198967947, \"p4\": 0.8744192142037515, \"phi\": 0.7731715073742761}, {\"truth_threshold\": -1.44, \"match_probability\": 0.26930886274910526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9551, \"tn\": 6929, \"fp\": 89, \"fn\": 2230, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8107121636533401, \"tn_rate\": 0.98731832430892, \"fp_rate\": 0.01268167569108008, \"fn_rate\": 0.18928783634665988, \"precision\": 0.9907676348547718, \"recall\": 0.8107121636533401, \"specificity\": 0.98731832430892, \"npv\": 0.7565236379517415, \"accuracy\": 0.8766423745943933, \"f1\": 0.8917417487512255, \"f2\": 0.841290254386583, \"f0_5\": 0.9486303410738761, \"p4\": 0.8738428433970383, \"phi\": 0.7722442742343384}, {\"truth_threshold\": -1.42, \"match_probability\": 0.2720455431978043, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9548, \"tn\": 6930, \"fp\": 88, \"fn\": 2233, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8104575163398693, \"tn_rate\": 0.987460815047022, \"fp_rate\": 0.012539184952978056, \"fn_rate\": 0.1895424836601307, \"precision\": 0.9908675799086758, \"recall\": 0.8104575163398693, \"specificity\": 0.987460815047022, \"npv\": 0.7563025210084033, \"accuracy\": 0.8765359859566998, \"f1\": 0.891628145865434, \"f2\": 0.8410852713178295, \"f0_5\": 0.9486338797814208, \"p4\": 0.8737424294110739, \"phi\": 0.772127398934872}, {\"truth_threshold\": -1.4000000000000001, \"match_probability\": 0.2747995746759952, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9543, \"tn\": 6930, \"fp\": 88, \"fn\": 2238, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8100331041507512, \"tn_rate\": 0.987460815047022, \"fp_rate\": 0.012539184952978056, \"fn_rate\": 0.18996689584924878, \"precision\": 0.9908628387498702, \"recall\": 0.8100331041507512, \"specificity\": 0.987460815047022, \"npv\": 0.7558900523560209, \"accuracy\": 0.8762700143624661, \"f1\": 0.8913693256118065, \"f2\": 0.840718879393886, \"f0_5\": 0.9485140642083292, \"p4\": 0.8734804984351267, \"phi\": 0.7717064790451775}, {\"truth_threshold\": -1.3800000000000001, \"match_probability\": 0.27757085557606836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9539, \"tn\": 6935, \"fp\": 83, \"fn\": 2242, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8096935743994568, \"tn_rate\": 0.9881732687375321, \"fp_rate\": 0.01182673126246794, \"fn_rate\": 0.19030642560054326, \"precision\": 0.9913739347329038, \"recall\": 0.8096935743994568, \"specificity\": 0.9881732687375321, \"npv\": 0.7556935817805382, \"accuracy\": 0.8763232086813129, \"f1\": 0.8913703686399103, \"f2\": 0.8404997709089628, \"f0_5\": 0.9487954803159004, \"p4\": 0.87355466772721, \"phi\": 0.7720494809342017}, {\"truth_threshold\": -1.36, \"match_probability\": 0.2803592796780973, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9529, \"tn\": 6935, \"fp\": 83, \"fn\": 2252, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8088447500212206, \"tn_rate\": 0.9881732687375321, \"fp_rate\": 0.01182673126246794, \"fn_rate\": 0.1911552499787794, \"precision\": 0.991364960466084, \"recall\": 0.8088447500212206, \"specificity\": 0.9881732687375321, \"npv\": 0.7548710133884837, \"accuracy\": 0.8757912654928454, \"f1\": 0.8908521478988454, \"f2\": 0.8397666384658771, \"f0_5\": 0.9485556152820084, \"p4\": 0.8730308916205575, \"phi\": 0.7712091268962498}, {\"truth_threshold\": -1.34, \"match_probability\": 0.28316473612920606, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9524, \"tn\": 6935, \"fp\": 83, \"fn\": 2257, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8084203378321025, \"tn_rate\": 0.9881732687375321, \"fp_rate\": 0.01182673126246794, \"fn_rate\": 0.19157966216789746, \"precision\": 0.9913604663266369, \"recall\": 0.8084203378321025, \"specificity\": 0.9881732687375321, \"npv\": 0.7544604003481288, \"accuracy\": 0.8755252938986117, \"f1\": 0.8905928558069945, \"f2\": 0.8393999753221343, \"f0_5\": 0.9484355394451194, \"p4\": 0.8727690433035836, \"phi\": 0.7707892928935522}, {\"truth_threshold\": -1.32, \"match_probability\": 0.2859871094251169, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9520, \"tn\": 6935, \"fp\": 83, \"fn\": 2261, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8080808080808081, \"tn_rate\": 0.9881732687375321, \"fp_rate\": 0.01182673126246794, \"fn_rate\": 0.1919191919191919, \"precision\": 0.9913568676455274, \"recall\": 0.8080808080808081, \"specificity\": 0.9881732687375321, \"npv\": 0.7541322314049587, \"accuracy\": 0.8753125166232246, \"f1\": 0.8903853348297793, \"f2\": 0.8391065982689019, \"f0_5\": 0.9483394098778715, \"p4\": 0.8725595836213947, \"phi\": 0.7704535899991517}, {\"truth_threshold\": -1.28, \"match_probability\": 0.29168212118218634, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9511, \"tn\": 6936, \"fp\": 82, \"fn\": 2270, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8073168661403956, \"tn_rate\": 0.9883157594756341, \"fp_rate\": 0.011684240524365916, \"fn_rate\": 0.19268313385960445, \"precision\": 0.9914521004899406, \"recall\": 0.8073168661403956, \"specificity\": 0.9883157594756341, \"npv\": 0.7534216815120574, \"accuracy\": 0.8748869620724506, \"f1\": 0.8899597641994947, \"f2\": 0.8384611315831232, \"f0_5\": 0.9481985125515922, \"p4\": 0.8721450690364876, \"phi\": 0.7698349712287639}, {\"truth_threshold\": -1.26, \"match_probability\": 0.29455450524326093, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9510, \"tn\": 6936, \"fp\": 82, \"fn\": 2271, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.807231983702572, \"tn_rate\": 0.9883157594756341, \"fp_rate\": 0.011684240524365916, \"fn_rate\": 0.19276801629742807, \"precision\": 0.9914512093411176, \"recall\": 0.807231983702572, \"specificity\": 0.9883157594756341, \"npv\": 0.7533398501140437, \"accuracy\": 0.8748337677536039, \"f1\": 0.8899078276329949, \"f2\": 0.838387756541364, \"f0_5\": 0.9481744401682984, \"p4\": 0.8720927154001622, \"phi\": 0.7697511588096887}, {\"truth_threshold\": -1.24, \"match_probability\": 0.2974432973281369, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9507, \"tn\": 6937, \"fp\": 81, \"fn\": 2274, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8069773363891011, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.1930226636108989, \"precision\": 0.9915519399249061, \"recall\": 0.8069773363891011, \"specificity\": 0.9884582502137361, \"npv\": 0.7531212680490718, \"accuracy\": 0.8747273791159105, \"f1\": 0.8897936262810614, \"f2\": 0.8381823952602624, \"f0_5\": 0.9481778469271738, \"p4\": 0.8719923628610442, \"phi\": 0.7696359983863785}, {\"truth_threshold\": -1.22, \"match_probability\": 0.300348358478604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9500, \"tn\": 6937, \"fp\": 81, \"fn\": 2281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8063831593243358, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.1936168406756642, \"precision\": 0.9915457676651707, \"recall\": 0.8063831593243358, \"specificity\": 0.9884582502137361, \"npv\": 0.7525493599479279, \"accuracy\": 0.8743550188839831, \"f1\": 0.8894298286677278, \"f2\": 0.8376686359227581, \"f0_5\": 0.948009180720487, \"p4\": 0.8716259329582681, \"phi\": 0.7690498163723901}, {\"truth_threshold\": -1.2, \"match_probability\": 0.30326954502292763, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9498, \"tn\": 6937, \"fp\": 81, \"fn\": 2283, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8062133944486886, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.19378660555131144, \"precision\": 0.9915440025054807, \"recall\": 0.8062133944486886, \"specificity\": 0.9884582502137361, \"npv\": 0.7523861171366595, \"accuracy\": 0.8742486302462897, \"f1\": 0.8893258426966292, \"f2\": 0.8375218242421036, \"f0_5\": 0.947960955745853, \"p4\": 0.8715212479946122, \"phi\": 0.7688824173369645}, {\"truth_threshold\": -1.18, \"match_probability\": 0.3062067085740297, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9496, \"tn\": 6937, \"fp\": 81, \"fn\": 2285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8060436295730413, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.19395637042695865, \"precision\": 0.9915422366085413, \"recall\": 0.8060436295730413, \"specificity\": 0.9884582502137361, \"npv\": 0.752222945131208, \"accuracy\": 0.8741422416085962, \"f1\": 0.8892218372506789, \"f2\": 0.8373750022045466, \"f0_5\": 0.9479127153666473, \"p4\": 0.8714165671485684, \"phi\": 0.7687150544982093}, {\"truth_threshold\": -1.16, \"match_probability\": 0.309159696030225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9489, \"tn\": 6937, \"fp\": 81, \"fn\": 2292, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.805449452508276, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.19455054749172396, \"precision\": 0.9915360501567398, \"recall\": 0.805449452508276, \"specificity\": 0.9884582502137361, \"npv\": 0.7516524000433417, \"accuracy\": 0.873769881376669, \"f1\": 0.888857664746382, \"f2\": 0.8368610434966663, \"f0_5\": 0.9477437526218014, \"p4\": 0.871050216509764, \"phi\": 0.7681295692706271}, {\"truth_threshold\": -1.1400000000000001, \"match_probability\": 0.3121283495785485, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9488, \"tn\": 6937, \"fp\": 81, \"fn\": 2293, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8053645700704524, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.19463542992954758, \"precision\": 0.9915351656390428, \"recall\": 0.8053645700704524, \"specificity\": 0.9884582502137361, \"npv\": 0.7515709642470206, \"accuracy\": 0.8737166870578222, \"f1\": 0.8888056206088993, \"f2\": 0.8367876104633729, \"f0_5\": 0.9477195996563917, \"p4\": 0.8709978847966526, \"phi\": 0.7680459646379397}, {\"truth_threshold\": -1.12, \"match_probability\": 0.3151125067007146, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9485, \"tn\": 6937, \"fp\": 81, \"fn\": 2296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8051099227569816, \"tn_rate\": 0.9884582502137361, \"fp_rate\": 0.011541749786263893, \"fn_rate\": 0.1948900772430184, \"precision\": 0.9915325109763746, \"recall\": 0.8051099227569816, \"specificity\": 0.9884582502137361, \"npv\": 0.7513267626990144, \"accuracy\": 0.873557104101282, \"f1\": 0.8886494589403663, \"f2\": 0.8365672958193685, \"f0_5\": 0.9476471175941652, \"p4\": 0.8708408957761696, \"phi\": 0.7677952048462747}, {\"truth_threshold\": -1.1, \"match_probability\": 0.3181120001817404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9483, \"tn\": 6945, \"fp\": 73, \"fn\": 2298, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8049401578813343, \"tn_rate\": 0.9895981761185523, \"fp_rate\": 0.010401823881447706, \"fn_rate\": 0.19505984211866564, \"precision\": 0.9923608204269568, \"recall\": 0.8049401578813343, \"specificity\": 0.9895981761185523, \"npv\": 0.7513794222654983, \"accuracy\": 0.8738762700143624, \"f1\": 0.8888784740122792, \"f2\": 0.8365384615384616, \"f0_5\": 0.9482051794820517, \"p4\": 0.8711895975101278, \"phi\": 0.7687198015906281}, {\"truth_threshold\": -1.08, \"match_probability\": 0.32112665812126734, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9473, \"tn\": 6945, \"fp\": 73, \"fn\": 2308, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8040913335030982, \"tn_rate\": 0.9895981761185523, \"fp_rate\": 0.010401823881447706, \"fn_rate\": 0.19590866649690178, \"precision\": 0.9923528179342133, \"recall\": 0.8040913335030982, \"specificity\": 0.9895981761185523, \"npv\": 0.7505673835512807, \"accuracy\": 0.873344326825895, \"f1\": 0.8883574811272097, \"f2\": 0.8358037762484559, \"f0_5\": 0.9479635745021515, \"p4\": 0.8706663256964162, \"phi\": 0.7678853888472156}, {\"truth_threshold\": -1.06, \"match_probability\": 0.3241563039476125, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9470, \"tn\": 6945, \"fp\": 73, \"fn\": 2311, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8038366861896273, \"tn_rate\": 0.9895981761185523, \"fp_rate\": 0.010401823881447706, \"fn_rate\": 0.19616331381037264, \"precision\": 0.9923504139159594, \"recall\": 0.8038366861896273, \"specificity\": 0.9895981761185523, \"npv\": 0.750324114088159, \"accuracy\": 0.8731847438693547, \"f1\": 0.8882010879759895, \"f2\": 0.8355833200981171, \"f0_5\": 0.9478910175565031, \"p4\": 0.8705093637549206, \"phi\": 0.7676352401152124}, {\"truth_threshold\": -1.04, \"match_probability\": 0.32720075643457636, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9463, \"tn\": 6945, \"fp\": 73, \"fn\": 2318, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8032425091248621, \"tn_rate\": 0.9895981761185523, \"fp_rate\": 0.010401823881447706, \"fn_rate\": 0.19675749087513794, \"precision\": 0.9923447986577181, \"recall\": 0.8032425091248621, \"specificity\": 0.9895981761185523, \"npv\": 0.7497570981323546, \"accuracy\": 0.8728123836374275, \"f1\": 0.887835999437069, \"f2\": 0.8350688316272503, \"f0_5\": 0.9477215823735603, \"p4\": 0.8701431541985052, \"phi\": 0.7670518733250566}, {\"truth_threshold\": -1.02, \"match_probability\": 0.33025982972103385, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9459, \"tn\": 6946, \"fp\": 72, \"fn\": 2322, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8029029793735676, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.1970970206264324, \"precision\": 0.9924457034938622, \"recall\": 0.8029029793735676, \"specificity\": 0.9897406668566543, \"npv\": 0.7494605092792404, \"accuracy\": 0.8726528006808872, \"f1\": 0.887668918918919, \"f2\": 0.8347895154884829, \"f0_5\": 0.9477006311992786, \"p4\": 0.869990550195065, \"phi\": 0.7668554268265478}, {\"truth_threshold\": -1.0, \"match_probability\": 0.3333333333333333, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9458, \"tn\": 6946, \"fp\": 72, \"fn\": 2323, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.802818096935744, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.197181903064256, \"precision\": 0.9924449108079748, \"recall\": 0.802818096935744, \"specificity\": 0.9897406668566543, \"npv\": 0.749379652605459, \"accuracy\": 0.8725996063620405, \"f1\": 0.8876167237576839, \"f2\": 0.8347159953401349, \"f0_5\": 0.9476763992705557, \"p4\": 0.8699382417212892, \"phi\": 0.7667721688544693}, {\"truth_threshold\": -0.98, \"match_probability\": 0.33642107221052214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9453, \"tn\": 6946, \"fp\": 72, \"fn\": 2328, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8023936847466259, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.19760631525337408, \"precision\": 0.9924409448818897, \"recall\": 0.8023936847466259, \"specificity\": 0.9897406668566543, \"npv\": 0.7489756307957731, \"accuracy\": 0.8723336347678068, \"f1\": 0.8873556744578992, \"f2\": 0.8343483556638246, \"f0_5\": 0.9475551813315691, \"p4\": 0.8696767141716063, \"phi\": 0.7663560128571771}, {\"truth_threshold\": -0.96, \"match_probability\": 0.339522846732419, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9451, \"tn\": 6946, \"fp\": 72, \"fn\": 2330, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8022239198709787, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.19777608012902131, \"precision\": 0.9924393573453744, \"recall\": 0.8022239198709787, \"specificity\": 0.9897406668566543, \"npv\": 0.748814144027598, \"accuracy\": 0.8722272461301133, \"f1\": 0.8872512204280886, \"f2\": 0.8342012816212686, \"f0_5\": 0.9475066669340124, \"p4\": 0.8695721100504828, \"phi\": 0.7661896128735087}, {\"truth_threshold\": -0.9400000000000001, \"match_probability\": 0.3426384527505482, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9437, \"tn\": 6946, \"fp\": 72, \"fn\": 2344, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8010355657414481, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.1989644342585519, \"precision\": 0.9924282258912609, \"recall\": 0.8010355657414481, \"specificity\": 0.9897406668566543, \"npv\": 0.7476856835306781, \"accuracy\": 0.8714825256662588, \"f1\": 0.8865194927195866, \"f2\": 0.8331714724630516, \"f0_5\": 0.947166629865307, \"p4\": 0.8688399908733193, \"phi\": 0.7650258093594844}, {\"truth_threshold\": -0.92, \"match_probability\": 0.34576768162194854, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9435, \"tn\": 6946, \"fp\": 72, \"fn\": 2346, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8008658008658008, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.19913419913419914, \"precision\": 0.9924266330072579, \"recall\": 0.8008658008658008, \"specificity\": 0.9897406668566543, \"npv\": 0.7475247524752475, \"accuracy\": 0.8713761370285653, \"f1\": 0.8864148816234498, \"f2\": 0.8330243153043386, \"f0_5\": 0.9471179907245678, \"p4\": 0.8687354179997595, \"phi\": 0.7648596937757018}, {\"truth_threshold\": -0.9, \"match_probability\": 0.34891032024586677, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9431, \"tn\": 6946, \"fp\": 72, \"fn\": 2350, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.8005262711145064, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.19947372888549358, \"precision\": 0.9924234452278228, \"recall\": 0.8005262711145064, \"specificity\": 0.9897406668566543, \"npv\": 0.7472030981067126, \"accuracy\": 0.8711633597531784, \"f1\": 0.886205600451043, \"f2\": 0.8327299698023911, \"f0_5\": 0.9470206655553993, \"p4\": 0.8685262838653895, \"phi\": 0.7645275689229115}, {\"truth_threshold\": -0.88, \"match_probability\": 0.3520661511033437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9424, \"tn\": 6946, \"fp\": 72, \"fn\": 2357, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7999320940497411, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.2000679059502589, \"precision\": 0.9924178601516428, \"recall\": 0.7999320940497411, \"specificity\": 0.9897406668566543, \"npv\": 0.746640868537031, \"accuracy\": 0.8707909995212512, \"f1\": 0.885839169055788, \"f2\": 0.8322147651006712, \"f0_5\": 0.9468501959208279, \"p4\": 0.8681603362364958, \"phi\": 0.7639466910430045}, {\"truth_threshold\": -0.86, \"match_probability\": 0.3552349522996959, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9419, \"tn\": 6946, \"fp\": 72, \"fn\": 2362, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.799507681860623, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.20049231813937696, \"precision\": 0.9924138657675693, \"recall\": 0.799507681860623, \"specificity\": 0.9897406668566543, \"npv\": 0.7462397937258273, \"accuracy\": 0.8705250279270174, \"f1\": 0.8855772846934938, \"f2\": 0.831846683741058, \"f0_5\": 0.9467283144034576, \"p4\": 0.8678989738417522, \"phi\": 0.7635320432235554}, {\"truth_threshold\": -0.84, \"match_probability\": 0.3584164976098956, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9414, \"tn\": 6946, \"fp\": 72, \"fn\": 2367, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.799083269671505, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.20091673032849502, \"precision\": 0.9924098671726755, \"recall\": 0.799083269671505, \"specificity\": 0.9897406668566543, \"npv\": 0.7458391495758617, \"accuracy\": 0.8702590563327837, \"f1\": 0.8853152771900127, \"f2\": 0.8314785373608903, \"f0_5\": 0.9466063348416289, \"p4\": 0.8676376352922996, \"phi\": 0.7631176157903997}, {\"truth_threshold\": -0.8, \"match_probability\": 0.36481689431254416, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9410, \"tn\": 6946, \"fp\": 72, \"fn\": 2371, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7987437399202105, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.2012562600797895, \"precision\": 0.9924066652604936, \"recall\": 0.7987437399202105, \"specificity\": 0.9897406668566543, \"npv\": 0.7455189438660513, \"accuracy\": 0.8700462790573966, \"f1\": 0.8851055824671965, \"f2\": 0.8311839734303784, \"f0_5\": 0.9465086805206301, \"p4\": 0.8674285815449974, \"phi\": 0.7627862322811028}, {\"truth_threshold\": -0.78, \"match_probability\": 0.36803527205213776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9408, \"tn\": 6946, \"fp\": 72, \"fn\": 2373, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7985739750445633, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.2014260249554367, \"precision\": 0.9924050632911392, \"recall\": 0.7985739750445633, \"specificity\": 0.9897406668566543, \"npv\": 0.7453589440927139, \"accuracy\": 0.8699398904197032, \"f1\": 0.885000705517144, \"f2\": 0.8310366758532965, \"f0_5\": 0.946459829782097, \"p4\": 0.8673240603487583, \"phi\": 0.76262059327585}, {\"truth_threshold\": -0.76, \"match_probability\": 0.37126544671083744, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9403, \"tn\": 6946, \"fp\": 72, \"fn\": 2378, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7981495628554452, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.20185043714455478, \"precision\": 0.992401055408971, \"recall\": 0.7981495628554452, \"specificity\": 0.9897406668566543, \"npv\": 0.7449592449592449, \"accuracy\": 0.8696739188254694, \"f1\": 0.8847384267971397, \"f2\": 0.8306683863672503, \"f0_5\": 0.9463376341055937, \"p4\": 0.8670627738588901, \"phi\": 0.7622066494315675}, {\"truth_threshold\": -0.74, \"match_probability\": 0.37450717119369914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9402, \"tn\": 6946, \"fp\": 72, \"fn\": 2379, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7980646804176216, \"tn_rate\": 0.9897406668566543, \"fp_rate\": 0.010259333143345683, \"fn_rate\": 0.2019353195823784, \"precision\": 0.9924002533248891, \"recall\": 0.7980646804176216, \"specificity\": 0.9897406668566543, \"npv\": 0.7448793565683646, \"accuracy\": 0.8696207245066226, \"f1\": 0.8846859562455893, \"f2\": 0.8305947206615075, \"f0_5\": 0.9463131831632345, \"p4\": 0.8670105193823301, \"phi\": 0.7621238869830793}, {\"truth_threshold\": -0.72, \"match_probability\": 0.3777601944082411, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9388, \"tn\": 6947, \"fp\": 71, \"fn\": 2393, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.796876326288091, \"tn_rate\": 0.9898831575947563, \"fp_rate\": 0.010116842405243659, \"fn_rate\": 0.203123673711909, \"precision\": 0.9924939211333121, \"recall\": 0.796876326288091, \"specificity\": 0.9898831575947563, \"npv\": 0.7437901498929336, \"accuracy\": 0.868929198361615, \"f1\": 0.8839924670433145, \"f2\": 0.8295777883816694, \"f0_5\": 0.9460467178587983, \"p4\": 0.8663356322640372, \"phi\": 0.7611034592693499}, {\"truth_threshold\": -0.7000000000000001, \"match_probability\": 0.3810242613298804, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9383, \"tn\": 6947, \"fp\": 71, \"fn\": 2398, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7964519140989729, \"tn_rate\": 0.9898831575947563, \"fp_rate\": 0.010116842405243659, \"fn_rate\": 0.20354808590102708, \"precision\": 0.9924899513433467, \"recall\": 0.7964519140989729, \"specificity\": 0.9898831575947563, \"npv\": 0.7433921883360085, \"accuracy\": 0.8686632267673813, \"f1\": 0.8837296915469743, \"f2\": 0.8292092332708827, \"f0_5\": 0.9459241486380224, \"p4\": 0.8660744349774768, \"phi\": 0.7606904331348598}, {\"truth_threshold\": -0.68, \"match_probability\": 0.38429911307016507, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9381, \"tn\": 6947, \"fp\": 71, \"fn\": 2400, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7962821492233257, \"tn_rate\": 0.9898831575947563, \"fp_rate\": 0.010116842405243659, \"fn_rate\": 0.20371785077667431, \"precision\": 0.9924883622513754, \"recall\": 0.7962821492233257, \"specificity\": 0.9898831575947563, \"npv\": 0.7432331229271424, \"accuracy\": 0.8685568381296878, \"f1\": 0.8836245466961805, \"f2\": 0.8290617929864253, \"f0_5\": 0.9458750932666519, \"p4\": 0.865969962513103, \"phi\": 0.7605252836875473}, {\"truth_threshold\": -0.66, \"match_probability\": 0.38758448694777375, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9378, \"tn\": 6947, \"fp\": 71, \"fn\": 2403, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7960275019098548, \"tn_rate\": 0.9898831575947563, \"fp_rate\": 0.010116842405243659, \"fn_rate\": 0.20397249809014514, \"precision\": 0.9924859773521008, \"recall\": 0.7960275019098548, \"specificity\": 0.9898831575947563, \"npv\": 0.7429946524064172, \"accuracy\": 0.8683972551731475, \"f1\": 0.8834667922750824, \"f2\": 0.8288406130132748, \"f0_5\": 0.9458014805252436, \"p4\": 0.86581326070469, \"phi\": 0.7602776248097688}, {\"truth_threshold\": -0.64, \"match_probability\": 0.3908801165622518, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9375, \"tn\": 6948, \"fp\": 70, \"fn\": 2406, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.795772854596384, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.204227145403616, \"precision\": 0.9925886712546321, \"recall\": 0.795772854596384, \"specificity\": 0.9900256483328583, \"npv\": 0.7427838357921744, \"accuracy\": 0.8682908665354541, \"f1\": 0.8833506077452181, \"f2\": 0.8286340575226714, \"f0_5\": 0.9458041605294486, \"p4\": 0.8657131309174757, \"phi\": 0.7601674914995407}, {\"truth_threshold\": -0.62, \"match_probability\": 0.3941857318704517, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9373, \"tn\": 6948, \"fp\": 70, \"fn\": 2408, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7956030897207368, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.2043969102792632, \"precision\": 0.9925871015567087, \"recall\": 0.7956030897207368, \"specificity\": 0.9900256483328583, \"npv\": 0.7426250534416418, \"accuracy\": 0.8681844778977605, \"f1\": 0.883245382585752, \"f2\": 0.8284865734438807, \"f0_5\": 0.9457550501483261, \"p4\": 0.865608671483382, \"phi\": 0.7600024983728791}, {\"truth_threshold\": -0.6, \"match_probability\": 0.39750105926563917, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9371, \"tn\": 6948, \"fp\": 70, \"fn\": 2410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7954333248450896, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.20456667515491045, \"precision\": 0.9925855311937295, \"recall\": 0.7954333248450896, \"specificity\": 0.9900256483328583, \"npv\": 0.7424663389613165, \"accuracy\": 0.868078089260067, \"f1\": 0.8831401375930638, \"f2\": 0.8283390789357377, \"f0_5\": 0.9457059239075588, \"p4\": 0.8655042156930722, \"phi\": 0.7598375399810888}, {\"truth_threshold\": -0.58, \"match_probability\": 0.4008258216592253, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9368, \"tn\": 6948, \"fp\": 70, \"fn\": 2413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7951786775316187, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.20482132246838128, \"precision\": 0.9925831744013562, \"recall\": 0.7951786775316187, \"specificity\": 0.9900256483328583, \"npv\": 0.7422283944023075, \"accuracy\": 0.8679185063035267, \"f1\": 0.8829822329044724, \"f2\": 0.8281178176160673, \"f0_5\": 0.9456322047927644, \"p4\": 0.8653475388236925, \"phi\": 0.7595901674718412}, {\"truth_threshold\": -0.56, \"match_probability\": 0.4041597385650814, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9367, \"tn\": 6948, \"fp\": 70, \"fn\": 2414, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7950937950937951, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.2049062049062049, \"precision\": 0.9925823884709124, \"recall\": 0.7950937950937951, \"specificity\": 0.9900256483328583, \"npv\": 0.7421491134372997, \"accuracy\": 0.8678653119846801, \"f1\": 0.8829295880855877, \"f2\": 0.8280440586269691, \"f0_5\": 0.94560762381635, \"p4\": 0.8652953150145284, \"phi\": 0.7595077273117138}, {\"truth_threshold\": -0.54, \"match_probability\": 0.4075025261863895, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9359, \"tn\": 6948, \"fp\": 70, \"fn\": 2422, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7944147355912062, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.20558526440879382, \"precision\": 0.9925760950259837, \"recall\": 0.7944147355912062, \"specificity\": 0.9900256483328583, \"npv\": 0.7415154749199573, \"accuracy\": 0.8674397574339061, \"f1\": 0.8825082508250826, \"f2\": 0.8274538928085159, \"f0_5\": 0.9454108329797766, \"p4\": 0.8648775570606991, \"phi\": 0.7588485177977309}, {\"truth_threshold\": -0.52, \"match_probability\": 0.4108538975049788, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9356, \"tn\": 6948, \"fp\": 70, \"fn\": 2425, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7941600882777353, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.20583991172226465, \"precision\": 0.9925737322300021, \"recall\": 0.7941600882777353, \"specificity\": 0.9900256483328583, \"npv\": 0.7412781393363918, \"accuracy\": 0.8672801744773658, \"f1\": 0.8823501673975574, \"f2\": 0.8272325375773651, \"f0_5\": 0.9453369707992321, \"p4\": 0.864720912672317, \"phi\": 0.7586014569372743}, {\"truth_threshold\": -0.5, \"match_probability\": 0.4142135623730951, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9344, \"tn\": 6948, \"fp\": 70, \"fn\": 2437, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.793141499023852, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.20685850097614802, \"precision\": 0.9925642659868281, \"recall\": 0.793141499023852, \"specificity\": 0.9900256483328583, \"npv\": 0.7403303143313799, \"accuracy\": 0.8666418426512048, \"f1\": 0.8817173861759849, \"f2\": 0.8263468817432523, \"f0_5\": 0.9450411635010215, \"p4\": 0.8640944154550849, \"phi\": 0.7576139899586097}, {\"truth_threshold\": -0.48, \"match_probability\": 0.41758122760754685, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9340, \"tn\": 6948, \"fp\": 70, \"fn\": 2441, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7928019692725575, \"tn_rate\": 0.9900256483328583, \"fp_rate\": 0.009974351667141636, \"fn_rate\": 0.2071980307274425, \"precision\": 0.9925611052072264, \"recall\": 0.7928019692725575, \"specificity\": 0.9900256483328583, \"npv\": 0.7400149110661413, \"accuracy\": 0.8664290653758179, \"f1\": 0.8815062998442735, \"f2\": 0.8260515795804295, \"f0_5\": 0.9449424333785233, \"p4\": 0.8638856114273555, \"phi\": 0.7572851098061725}, {\"truth_threshold\": -0.46, \"match_probability\": 0.4209565970861701, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9337, \"tn\": 6953, \"fp\": 65, \"fn\": 2444, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7925473219590866, \"tn_rate\": 0.9907381020233684, \"fp_rate\": 0.009261897976631519, \"fn_rate\": 0.20745267804091333, \"precision\": 0.9930865773239737, \"recall\": 0.7925473219590866, \"specificity\": 0.9907381020233684, \"npv\": 0.7399169947855698, \"accuracy\": 0.8665354540135114, \"f1\": 0.8815559646886655, \"f2\": 0.8259031242260199, \"f0_5\": 0.9452509668144728, \"p4\": 0.8640116337307522, \"phi\": 0.7577275326662466}, {\"truth_threshold\": -0.44, \"match_probability\": 0.42433937184654724, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9337, \"tn\": 6956, \"fp\": 62, \"fn\": 2444, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7925473219590866, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20745267804091333, \"precision\": 0.9934035535695287, \"recall\": 0.7925473219590866, \"specificity\": 0.9911655742376746, \"npv\": 0.74, \"accuracy\": 0.8666950369700516, \"f1\": 0.8816808309726156, \"f2\": 0.8259469596447464, \"f0_5\": 0.9454806893897969, \"p4\": 0.8641811659978876, \"phi\": 0.7581410311076506}, {\"truth_threshold\": -0.42, \"match_probability\": 0.4277292501869187, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9326, \"tn\": 6956, \"fp\": 62, \"fn\": 2455, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7916136151430269, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20838638485697308, \"precision\": 0.9933958244567533, \"recall\": 0.7916136151430269, \"specificity\": 0.9911655742376746, \"npv\": 0.7391350547231963, \"accuracy\": 0.8661098994627374, \"f1\": 0.8810997212905664, \"f2\": 0.8251344847112118, \"f0_5\": 0.9452090892506031, \"p4\": 0.8636069831472272, \"phi\": 0.7572383560021332}, {\"truth_threshold\": -0.4, \"match_probability\": 0.43112592776921604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9325, \"tn\": 6956, \"fp\": 62, \"fn\": 2456, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7915287327052033, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2084712672947967, \"precision\": 0.9933951209118994, \"recall\": 0.7915287327052033, \"specificity\": 0.9911655742376746, \"npv\": 0.7390565235869103, \"accuracy\": 0.8660567051438907, \"f1\": 0.8810468631897204, \"f2\": 0.8250606076693033, \"f0_5\": 0.9451843743031483, \"p4\": 0.8635547899092214, \"phi\": 0.7571563459815727}, {\"truth_threshold\": -0.38, \"match_probability\": 0.434529097724148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9322, \"tn\": 6956, \"fp\": 62, \"fn\": 2459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7912740853917325, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20872591460826756, \"precision\": 0.9933930093776641, \"recall\": 0.7912740853917325, \"specificity\": 0.9911655742376746, \"npv\": 0.7388210302708444, \"accuracy\": 0.8658971221873504, \"f1\": 0.880888258918025, \"f2\": 0.8248389608551001, \"f0_5\": 0.9451102054058438, \"p4\": 0.8633982153705453, \"phi\": 0.7569103671891753}, {\"truth_threshold\": -0.36, \"match_probability\": 0.4379384507582655, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9318, \"tn\": 6956, \"fp\": 62, \"fn\": 2463, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.790934555640438, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.209065444359562, \"precision\": 0.9933901918976545, \"recall\": 0.790934555640438, \"specificity\": 0.9911655742376746, \"npv\": 0.7385072725342393, \"accuracy\": 0.8656843449119634, \"f1\": 0.8806767166012949, \"f2\": 0.8245433951578649, \"f0_5\": 0.9450112573781465, \"p4\": 0.8631894613603738, \"phi\": 0.7565825149906952}, {\"truth_threshold\": -0.34, \"match_probability\": 0.4413536752629294, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9313, \"tn\": 6956, \"fp\": 62, \"fn\": 2468, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7905101434513199, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20948985654868008, \"precision\": 0.9933866666666666, \"recall\": 0.7905101434513199, \"specificity\": 0.9911655742376746, \"npv\": 0.7381154499151104, \"accuracy\": 0.8654183733177296, \"f1\": 0.8804121762147854, \"f2\": 0.8241738791837023, \"f0_5\": 0.944887481991031, \"p4\": 0.8629285381169377, \"phi\": 0.7561728915863614}, {\"truth_threshold\": -0.32, \"match_probability\": 0.4447744574251037, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9310, \"tn\": 6956, \"fp\": 62, \"fn\": 2471, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7902554961378491, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20974450386215093, \"precision\": 0.9933845497225778, \"recall\": 0.7902554961378491, \"specificity\": 0.9911655742376746, \"npv\": 0.7378805558502175, \"accuracy\": 0.8652587903611895, \"f1\": 0.88025339195386, \"f2\": 0.8239521382044747, \"f0_5\": 0.9448131685238182, \"p4\": 0.8627719944035506, \"phi\": 0.7559272197275105}, {\"truth_threshold\": -0.3, \"match_probability\": 0.44820048133989093, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9308, \"tn\": 6956, \"fp\": 62, \"fn\": 2473, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7900857312622018, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.20991426873779814, \"precision\": 0.9933831376734258, \"recall\": 0.7900857312622018, \"specificity\": 0.9911655742376746, \"npv\": 0.7377240428465373, \"accuracy\": 0.865152401723496, \"f1\": 0.8801475107559926, \"f2\": 0.8238042978015364, \"f0_5\": 0.9447636060981304, \"p4\": 0.8626676361761926, \"phi\": 0.7557634810187344}, {\"truth_threshold\": -0.28, \"match_probability\": 0.45163142912472937, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9301, \"tn\": 6956, \"fp\": 62, \"fn\": 2480, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7894915541974366, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21050844580256345, \"precision\": 0.9933781907508277, \"recall\": 0.7894915541974366, \"specificity\": 0.9911655742376746, \"npv\": 0.7371767698177194, \"accuracy\": 0.8647800414915687, \"f1\": 0.8797767688233068, \"f2\": 0.823286773947988, \"f0_5\": 0.9445900107651372, \"p4\": 0.8623024090279556, \"phi\": 0.7551906631318133}, {\"truth_threshold\": -0.24, \"match_probability\": 0.4585068155821077, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9300, \"tn\": 6956, \"fp\": 62, \"fn\": 2481, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.789406671759613, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21059332824038707, \"precision\": 0.9933774834437086, \"recall\": 0.789406671759613, \"specificity\": 0.9911655742376746, \"npv\": 0.7370986542333369, \"accuracy\": 0.864726847172722, \"f1\": 0.879723785650097, \"f2\": 0.8232128314980703, \"f0_5\": 0.9445651953117065, \"p4\": 0.8622502370925574, \"phi\": 0.7551088659484771}, {\"truth_threshold\": -0.2, \"match_probability\": 0.46539803861923645, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9290, \"tn\": 6956, \"fp\": 62, \"fn\": 2491, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7885578473813768, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2114421526186232, \"precision\": 0.9933704020530368, \"recall\": 0.7885578473813768, \"specificity\": 0.9911655742376746, \"npv\": 0.736318407960199, \"accuracy\": 0.8641949039842545, \"f1\": 0.8791936781337245, \"f2\": 0.8224732629789645, \"f0_5\": 0.9443168188009514, \"p4\": 0.8617285637914833, \"phi\": 0.754291359927087}, {\"truth_threshold\": -0.18, \"match_probability\": 0.4688487764824174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9275, \"tn\": 6956, \"fp\": 62, \"fn\": 2506, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7872846108140226, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21271538918597743, \"precision\": 0.9933597515261862, \"recall\": 0.7872846108140226, \"specificity\": 0.9911655742376746, \"npv\": 0.7351511308391461, \"accuracy\": 0.8633969892015533, \"f1\": 0.8783975755279856, \"f2\": 0.8213634189971839, \"f0_5\": 0.943943495695007, \"p4\": 0.8609462093340501, \"phi\": 0.7530666844240742}, {\"truth_threshold\": -0.16, \"match_probability\": 0.47230249597156454, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9273, \"tn\": 6956, \"fp\": 62, \"fn\": 2508, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7871148459383753, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21288515406162464, \"precision\": 0.9933583288698447, \"recall\": 0.7871148459383753, \"specificity\": 0.9911655742376746, \"npv\": 0.7349957734573119, \"accuracy\": 0.8632906005638598, \"f1\": 0.8782913430573972, \"f2\": 0.8212153952425654, \"f0_5\": 0.9438936503735673, \"p4\": 0.8608419093627375, \"phi\": 0.752903537510702}, {\"truth_threshold\": -0.14, \"match_probability\": 0.47575886867897205, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9264, \"tn\": 6956, \"fp\": 62, \"fn\": 2517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7863509039979628, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2136490960020372, \"precision\": 0.9933519193652155, \"recall\": 0.7863509039979628, \"specificity\": 0.9911655742376746, \"npv\": 0.7342974770400085, \"accuracy\": 0.862811851694239, \"f1\": 0.877813047804046, \"f2\": 0.8205491585473871, \"f0_5\": 0.9436691453600896, \"p4\": 0.8603725997312968, \"phi\": 0.7521697920571372}, {\"truth_threshold\": -0.12, \"match_probability\": 0.4792175651819362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9262, \"tn\": 6956, \"fp\": 62, \"fn\": 2519, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7861811391223156, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2138188608776844, \"precision\": 0.9933504933504933, \"recall\": 0.7861811391223156, \"specificity\": 0.9911655742376746, \"npv\": 0.7341424802110817, \"accuracy\": 0.8627054630565456, \"f1\": 0.8777067045723762, \"f2\": 0.8204010770975056, \"f0_5\": 0.9436192106281965, \"p4\": 0.8602683175999072, \"phi\": 0.7520068297499543}, {\"truth_threshold\": -0.1, \"match_probability\": 0.48267825516781476, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9261, \"tn\": 6956, \"fp\": 62, \"fn\": 2520, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.786096256684492, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21390374331550802, \"precision\": 0.9933497801136973, \"recall\": 0.786096256684492, \"specificity\": 0.9911655742376746, \"npv\": 0.7340650063317856, \"accuracy\": 0.8626522687376988, \"f1\": 0.8776535253980288, \"f2\": 0.8203270324375077, \"f0_5\": 0.9435942371568887, \"p4\": 0.8602161777419742, \"phi\": 0.751925361157923}, {\"truth_threshold\": -0.06, \"match_probability\": 0.48960429064337574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9260, \"tn\": 6956, \"fp\": 62, \"fn\": 2521, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7860113742466683, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21398862575333163, \"precision\": 0.993349066723879, \"recall\": 0.7860113742466683, \"specificity\": 0.9911655742376746, \"npv\": 0.7339875488023636, \"accuracy\": 0.8625990744188521, \"f1\": 0.877600341183718, \"f2\": 0.8202529851539524, \"f0_5\": 0.943569259614013, \"p4\": 0.8601640386879758, \"phi\": 0.7518439009366339}, {\"truth_threshold\": -0.04, \"match_probability\": 0.49306897219313867, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9251, \"tn\": 6956, \"fp\": 62, \"fn\": 2530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7852474323062558, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21475256769374415, \"precision\": 0.9933426393213787, \"recall\": 0.7852474323062558, \"specificity\": 0.9911655742376746, \"npv\": 0.7332911659287371, \"accuracy\": 0.8621203255492313, \"f1\": 0.8771214563382953, \"f2\": 0.8195864415188617, \"f0_5\": 0.9433442783431566, \"p4\": 0.8596948232255152, \"phi\": 0.7511111351795413}, {\"truth_threshold\": -0.02, \"match_probability\": 0.4965343196002423, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9249, \"tn\": 6956, \"fp\": 62, \"fn\": 2532, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7850776674306086, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2149223325693914, \"precision\": 0.993341209322307, \"recall\": 0.7850776674306086, \"specificity\": 0.9911655742376746, \"npv\": 0.7331365935919055, \"accuracy\": 0.8620139369115378, \"f1\": 0.8770149819836905, \"f2\": 0.8194382918401701, \"f0_5\": 0.9432942376338602, \"p4\": 0.8595905618875354, \"phi\": 0.7509483901934808}, {\"truth_threshold\": 0.0, \"match_probability\": 0.5, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9248, \"tn\": 6956, \"fp\": 62, \"fn\": 2533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.784992784992785, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.215007215007215, \"precision\": 0.9933404940923738, \"recall\": 0.784992784992785, \"specificity\": 0.9911655742376746, \"npv\": 0.7330593318579408, \"accuracy\": 0.8619607425926911, \"f1\": 0.8769617372338913, \"f2\": 0.8193642130630471, \"f0_5\": 0.9432692111544032, \"p4\": 0.8595384324081555, \"phi\": 0.7508670302090028}, {\"truth_threshold\": 0.02, \"match_probability\": 0.5034656803997578, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9246, \"tn\": 6956, \"fp\": 62, \"fn\": 2535, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7848230201171378, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21517697988286225, \"precision\": 0.9933390631714654, \"recall\": 0.7848230201171378, \"specificity\": 0.9911655742376746, \"npv\": 0.7329048572331682, \"accuracy\": 0.8618543539549977, \"f1\": 0.8768552325857082, \"f2\": 0.819216047632549, \"f0_5\": 0.9432191459408729, \"p4\": 0.8594341758239563, \"phi\": 0.7507043352435896}, {\"truth_threshold\": 0.04, \"match_probability\": 0.5069310278068614, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9245, \"tn\": 6956, \"fp\": 62, \"fn\": 2536, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7847381376793141, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21526186232068584, \"precision\": 0.9933383474803911, \"recall\": 0.7847381376793141, \"specificity\": 0.9911655742376746, \"npv\": 0.7328276443320692, \"accuracy\": 0.8618011596361509, \"f1\": 0.8768019726858877, \"f2\": 0.8191419609788946, \"f0_5\": 0.9431941072047991, \"p4\": 0.8593820487172726, \"phi\": 0.7506230002572327}, {\"truth_threshold\": 0.06, \"match_probability\": 0.5103957093566241, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9239, \"tn\": 6956, \"fp\": 62, \"fn\": 2542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7842288430523725, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21577115694762752, \"precision\": 0.9933340501021396, \"recall\": 0.7842288430523725, \"specificity\": 0.9911655742376746, \"npv\": 0.7323647083596546, \"accuracy\": 0.8614819937230703, \"f1\": 0.8764823071814818, \"f2\": 0.8186973859105007, \"f0_5\": 0.943043788914974, \"p4\": 0.8590693026142466, \"phi\": 0.750135165117323}, {\"truth_threshold\": 0.08, \"match_probability\": 0.5138593924401896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9232, \"tn\": 6956, \"fp\": 62, \"fn\": 2549, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7836346659876071, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.21636533401239283, \"precision\": 0.9933290294813858, \"recall\": 0.7836346659876071, \"specificity\": 0.9911655742376746, \"npv\": 0.7318253550762757, \"accuracy\": 0.8611096334911431, \"f1\": 0.8761091340450771, \"f2\": 0.8181785954837109, \"f0_5\": 0.9428682313050227, \"p4\": 0.8587044677929222, \"phi\": 0.7495664022324456}, {\"truth_threshold\": 0.1, \"match_probability\": 0.5173217448321853, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9228, \"tn\": 6956, \"fp\": 62, \"fn\": 2553, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7832951362363128, \"tn_rate\": 0.9911655742376746, \"fp_rate\": 0.00883442576232545, \"fn_rate\": 0.2167048637636873, \"precision\": 0.9933261571582347, \"recall\": 0.7832951362363128, \"specificity\": 0.9911655742376746, \"npv\": 0.7315175097276264, \"accuracy\": 0.8608968562157562, \"f1\": 0.8758957809311376, \"f2\": 0.8178820860070195, \"f0_5\": 0.9427678224801291, \"p4\": 0.8584960078645175, \"phi\": 0.7492415773560582}, {\"truth_threshold\": 0.12, \"match_probability\": 0.5207824348180637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9225, \"tn\": 6957, \"fp\": 61, \"fn\": 2556, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7830404889228418, \"tn_rate\": 0.9913080649757766, \"fp_rate\": 0.008691935024223425, \"fn_rate\": 0.21695951107715813, \"precision\": 0.9934309713547276, \"recall\": 0.7830404889228418, \"specificity\": 0.9913080649757766, \"npv\": 0.7313150425733207, \"accuracy\": 0.8607904675780627, \"f1\": 0.8757772820050316, \"f2\": 0.817674171246233, \"f0_5\": 0.942769545222279, \"p4\": 0.8583960801064947, \"phi\": 0.7491368552066919}, {\"truth_threshold\": 0.14, \"match_probability\": 0.5242411313210279, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9222, \"tn\": 6957, \"fp\": 61, \"fn\": 2559, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.782785841609371, \"tn_rate\": 0.9913080649757766, \"fp_rate\": 0.008691935024223425, \"fn_rate\": 0.217214158390629, \"precision\": 0.9934288484326188, \"recall\": 0.782785841609371, \"specificity\": 0.9913080649757766, \"npv\": 0.7310844892812106, \"accuracy\": 0.8606308846215224, \"f1\": 0.8756171667299658, \"f2\": 0.8174517347137766, \"f0_5\": 0.9426941712837078, \"p4\": 0.8582397475776071, \"phi\": 0.7488934236351276}, {\"truth_threshold\": 0.16, \"match_probability\": 0.5276975040284355, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9219, \"tn\": 6959, \"fp\": 59, \"fn\": 2562, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7825311942959001, \"tn_rate\": 0.9915930464519807, \"fp_rate\": 0.008406953548019378, \"fn_rate\": 0.21746880570409982, \"precision\": 0.9936408708773442, \"recall\": 0.7825311942959001, \"specificity\": 0.9915930464519807, \"npv\": 0.7309106186324966, \"accuracy\": 0.8605776903026757, \"f1\": 0.8755401491048957, \"f2\": 0.8172582532534307, \"f0_5\": 0.9427729940891334, \"p4\": 0.8581962203515158, \"phi\": 0.7489278147455546}, {\"truth_threshold\": 0.18, \"match_probability\": 0.5311512235175825, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9218, \"tn\": 6959, \"fp\": 59, \"fn\": 2563, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7824463118580766, \"tn_rate\": 0.9915930464519807, \"fp_rate\": 0.008406953548019378, \"fn_rate\": 0.21755368814192344, \"precision\": 0.9936401854047645, \"recall\": 0.7824463118580766, \"specificity\": 0.9915930464519807, \"npv\": 0.7308338584331023, \"accuracy\": 0.860524495983829, \"f1\": 0.875486750878526, \"f2\": 0.8171840924806297, \"f0_5\": 0.9427478573912332, \"p4\": 0.8581441115779974, \"phi\": 0.7488467293141865}, {\"truth_threshold\": 0.2, \"match_probability\": 0.5346019613807635, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9216, \"tn\": 6959, \"fp\": 59, \"fn\": 2565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7822765469824293, \"tn_rate\": 0.9915930464519807, \"fp_rate\": 0.008406953548019378, \"fn_rate\": 0.21772345301757068, \"precision\": 0.9936388140161725, \"recall\": 0.7822765469824293, \"specificity\": 0.9915930464519807, \"npv\": 0.7306803863922722, \"accuracy\": 0.8604181073461354, \"f1\": 0.8753799392097265, \"f2\": 0.8170357630454441, \"f0_5\": 0.9426975716536078, \"p4\": 0.858039896317268, \"phi\": 0.7486845832103263}, {\"truth_threshold\": 0.22, \"match_probability\": 0.5380493903495076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9214, \"tn\": 6960, \"fp\": 58, \"fn\": 2567, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7821067821067821, \"tn_rate\": 0.9917355371900827, \"fp_rate\": 0.008264462809917356, \"fn_rate\": 0.2178932178932179, \"precision\": 0.9937446074201898, \"recall\": 0.7821067821067821, \"specificity\": 0.9917355371900827, \"npv\": 0.7305552639865645, \"accuracy\": 0.8603649130272887, \"f1\": 0.8753146819930652, \"f2\": 0.8169019079367331, \"f0_5\": 0.9427244265280649, \"p4\": 0.8579920743076057, \"phi\": 0.7486614003378455}, {\"truth_threshold\": 0.24, \"match_probability\": 0.5414931844178922, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9199, \"tn\": 6963, \"fp\": 55, \"fn\": 2582, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7808335455394279, \"tn_rate\": 0.9921630094043887, \"fp_rate\": 0.007836990595611285, \"fn_rate\": 0.21916645446057212, \"precision\": 0.9940566241625243, \"recall\": 0.7808335455394279, \"specificity\": 0.9921630094043887, \"npv\": 0.7294918805657412, \"accuracy\": 0.8597265812011278, \"f1\": 0.8746375089137153, \"f2\": 0.8158324169002094, \"f0_5\": 0.9425784371990081, \"p4\": 0.8573796780910784, \"phi\": 0.7478639592129701}, {\"truth_threshold\": 0.26, \"match_probability\": 0.5449330189648354, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9195, \"tn\": 6963, \"fp\": 55, \"fn\": 2586, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7804940157881335, \"tn_rate\": 0.9921630094043887, \"fp_rate\": 0.007836990595611285, \"fn_rate\": 0.21950598421186657, \"precision\": 0.994054054054054, \"recall\": 0.7804940157881335, \"specificity\": 0.9921630094043887, \"npv\": 0.7291863022306001, \"accuracy\": 0.8595138039257407, \"f1\": 0.8744234701155437, \"f2\": 0.8155355305637351, \"f0_5\": 0.9424776039851581, \"p4\": 0.8571712935027356, \"phi\": 0.7475404619056286}, {\"truth_threshold\": 0.28, \"match_probability\": 0.5483685708752706, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9191, \"tn\": 6963, \"fp\": 55, \"fn\": 2590, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.780154486036839, \"tn_rate\": 0.9921630094043887, \"fp_rate\": 0.007836990595611285, \"fn_rate\": 0.21984551396316102, \"precision\": 0.9940514817218257, \"recall\": 0.780154486036839, \"specificity\": 0.9921630094043887, \"npv\": 0.7288809797969225, \"accuracy\": 0.8593010266503538, \"f1\": 0.8742093498834831, \"f2\": 0.815238602093312, \"f0_5\": 0.9423767046037117, \"p4\": 0.8569629207381582, \"phi\": 0.7472170956645205}, {\"truth_threshold\": 0.3, \"match_probability\": 0.5517995186601091, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9189, \"tn\": 6964, \"fp\": 54, \"fn\": 2592, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7799847211611918, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.22001527883880825, \"precision\": 0.994157740993184, \"recall\": 0.7799847211611918, \"specificity\": 0.9923055001424907, \"npv\": 0.7287568020092089, \"accuracy\": 0.859247832331507, \"f1\": 0.8741438356164384, \"f2\": 0.8151045824684656, \"f0_5\": 0.9424035443972678, \"p4\": 0.8569150946198847, \"phi\": 0.7471946415753854}, {\"truth_threshold\": 0.32, \"match_probability\": 0.5552255425748963, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9177, \"tn\": 6964, \"fp\": 54, \"fn\": 2604, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7789661319073083, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.22103386809269163, \"precision\": 0.9941501462463438, \"recall\": 0.7789661319073083, \"specificity\": 0.9923055001424907, \"npv\": 0.7278428093645485, \"accuracy\": 0.858609500505346, \"f1\": 0.873500856653341, \"f2\": 0.8142134681927069, \"f0_5\": 0.9421004003695719, \"p4\": 0.8562900534134279, \"phi\": 0.7462256262032758}, {\"truth_threshold\": 0.34, \"match_probability\": 0.5586463247370707, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9175, \"tn\": 6964, \"fp\": 54, \"fn\": 2606, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7787963670316611, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.22120363296833884, \"precision\": 0.9941488785350525, \"recall\": 0.7787963670316611, \"specificity\": 0.9923055001424907, \"npv\": 0.7276907001044932, \"accuracy\": 0.8585031118676525, \"f1\": 0.8733936220847216, \"f2\": 0.8140649122495697, \"f0_5\": 0.9420498182639587, \"p4\": 0.8561858900251229, \"phi\": 0.746064237776585}, {\"truth_threshold\": 0.36, \"match_probability\": 0.5620615492417346, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9171, \"tn\": 6964, \"fp\": 54, \"fn\": 2610, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7784568372803667, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.2215431627196333, \"precision\": 0.9941463414634146, \"recall\": 0.7784568372803667, \"specificity\": 0.9923055001424907, \"npv\": 0.7273866722373094, \"accuracy\": 0.8582903345922656, \"f1\": 0.8731790916880892, \"f2\": 0.8137677687270404, \"f0_5\": 0.9419486041782215, \"p4\": 0.8559775718773227, \"phi\": 0.7457415585628366}, {\"truth_threshold\": 0.38, \"match_probability\": 0.5654709022758521, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9166, \"tn\": 6964, \"fp\": 54, \"fn\": 2615, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7780324250912486, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.22196757490875138, \"precision\": 0.9941431670281996, \"recall\": 0.7780324250912486, \"specificity\": 0.9923055001424907, \"npv\": 0.7270069944670634, \"accuracy\": 0.8580243629980319, \"f1\": 0.8729108137707728, \"f2\": 0.8133962799943206, \"f0_5\": 0.9418219929717844, \"p4\": 0.8557171902937721, \"phi\": 0.7453383924018921}, {\"truth_threshold\": 0.4, \"match_probability\": 0.5688740722307839, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9163, \"tn\": 6964, \"fp\": 54, \"fn\": 2618, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7777777777777778, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.2222222222222222, \"precision\": 0.9941412607138982, \"recall\": 0.7777777777777778, \"specificity\": 0.9923055001424907, \"npv\": 0.7267793780004175, \"accuracy\": 0.8578647800414916, \"f1\": 0.8727497856938756, \"f2\": 0.8131733551055181, \"f0_5\": 0.9417459762790602, \"p4\": 0.8555609698856462, \"phi\": 0.7450965901019101}, {\"truth_threshold\": 0.42, \"match_probability\": 0.5722707498130813, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9160, \"tn\": 6964, \"fp\": 54, \"fn\": 2621, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.777523130464307, \"tn_rate\": 0.9923055001424907, \"fp_rate\": 0.007694499857509262, \"fn_rate\": 0.22247686953569307, \"precision\": 0.9941393531582374, \"recall\": 0.777523130464307, \"specificity\": 0.9923055001424907, \"npv\": 0.7265519040166928, \"accuracy\": 0.8577051970849513, \"f1\": 0.8725887115979996, \"f2\": 0.8129504064752032, \"f0_5\": 0.9416699220757859, \"p4\": 0.8554047558528594, \"phi\": 0.7448548607623287}, {\"truth_threshold\": 0.44, \"match_probability\": 0.5756606281534528, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9156, \"tn\": 6968, \"fp\": 50, \"fn\": 2625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7771836007130125, \"tn_rate\": 0.9928754630948988, \"fp_rate\": 0.007124536905101168, \"fn_rate\": 0.22281639928698752, \"precision\": 0.9945687595046708, \"recall\": 0.7771836007130125, \"specificity\": 0.9928754630948988, \"npv\": 0.7263629730011467, \"accuracy\": 0.8577051970849513, \"f1\": 0.8725401438986039, \"f2\": 0.812710811290609, \"f0_5\": 0.9418784075712375, \"p4\": 0.8554217547566111, \"phi\": 0.7450906085858587}, {\"truth_threshold\": 0.46, \"match_probability\": 0.57904340291383, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9148, \"tn\": 6968, \"fp\": 50, \"fn\": 2633, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7765045412104236, \"tn_rate\": 0.9928754630948988, \"fp_rate\": 0.007124536905101168, \"fn_rate\": 0.22349545878957644, \"precision\": 0.994564035659926, \"recall\": 0.7765045412104236, \"specificity\": 0.9928754630948988, \"npv\": 0.7257577335694199, \"accuracy\": 0.8572796425341773, \"f1\": 0.8721102054435388, \"f2\": 0.8121160470153759, \"f0_5\": 0.9416754163835875, \"p4\": 0.8550052083032234, \"phi\": 0.7444468858897132}, {\"truth_threshold\": 0.48, \"match_probability\": 0.5824187723924531, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9130, \"tn\": 6974, \"fp\": 44, \"fn\": 2651, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7749766573295985, \"tn_rate\": 0.9937304075235109, \"fp_rate\": 0.006269592476489028, \"fn_rate\": 0.2250233426704015, \"precision\": 0.9952038369304557, \"recall\": 0.7749766573295985, \"specificity\": 0.9937304075235109, \"npv\": 0.7245714285714285, \"accuracy\": 0.8566413107080164, \"f1\": 0.8713910761154856, \"f2\": 0.810863618601016, \"f0_5\": 0.9416836850465169, \"p4\": 0.8544058192209648, \"phi\": 0.7438389151542295}, {\"truth_threshold\": 0.5, \"match_probability\": 0.5857864376269051, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9108, \"tn\": 6974, \"fp\": 44, \"fn\": 2673, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.773109243697479, \"tn_rate\": 0.9937304075235109, \"fp_rate\": 0.006269592476489028, \"fn_rate\": 0.226890756302521, \"precision\": 0.9951923076923077, \"recall\": 0.773109243697479, \"specificity\": 0.9937304075235109, \"npv\": 0.7229190421892816, \"accuracy\": 0.8554710356933879, \"f1\": 0.8702049395691014, \"f2\": 0.8092259577795152, \"f0_5\": 0.9411229824960218, \"p4\": 0.8532606884736696, \"phi\": 0.742075641077803}, {\"truth_threshold\": 0.52, \"match_probability\": 0.5891461024950211, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9105, \"tn\": 6974, \"fp\": 44, \"fn\": 2676, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7728545963840081, \"tn_rate\": 0.9937304075235109, \"fp_rate\": 0.006269592476489028, \"fn_rate\": 0.22714540361599186, \"precision\": 0.9951907312274566, \"recall\": 0.7728545963840081, \"specificity\": 0.9937304075235109, \"npv\": 0.7226943005181348, \"accuracy\": 0.8553114527368477, \"f1\": 0.870043000477783, \"f2\": 0.8090025411831606, \"f0_5\": 0.9410463650081651, \"p4\": 0.8531045589403159, \"phi\": 0.7418354938029343}, {\"truth_threshold\": 0.54, \"match_probability\": 0.5924974738136106, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9098, \"tn\": 6974, \"fp\": 44, \"fn\": 2683, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7722604193192428, \"tn_rate\": 0.9937304075235109, \"fp_rate\": 0.006269592476489028, \"fn_rate\": 0.22773958068075714, \"precision\": 0.9951870487858236, \"recall\": 0.7722604193192428, \"specificity\": 0.9937304075235109, \"npv\": 0.7221704463083773, \"accuracy\": 0.8549390925049205, \"f1\": 0.8696649620035368, \"f2\": 0.8084811431415064, \"f0_5\": 0.9408674429667625, \"p4\": 0.8527402793555587, \"phi\": 0.7412754284401}, {\"truth_threshold\": 0.56, \"match_probability\": 0.5958402614349186, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9096, \"tn\": 6974, \"fp\": 44, \"fn\": 2685, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7720906544435956, \"tn_rate\": 0.9937304075235109, \"fp_rate\": 0.006269592476489028, \"fn_rate\": 0.22790934555640438, \"precision\": 0.9951859956236324, \"recall\": 0.7720906544435956, \"specificity\": 0.9937304075235109, \"npv\": 0.722020913138006, \"accuracy\": 0.854832703867227, \"f1\": 0.8695569045456718, \"f2\": 0.8083321484430541, \"f0_5\": 0.9408162843135227, \"p4\": 0.8526362052666343, \"phi\": 0.7411154812294664}, {\"truth_threshold\": 0.58, \"match_probability\": 0.5991741783407747, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9089, \"tn\": 6978, \"fp\": 40, \"fn\": 2692, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7714964773788303, \"tn_rate\": 0.994300370475919, \"fp_rate\": 0.005699629524080934, \"fn_rate\": 0.22850352262116969, \"precision\": 0.9956183590754738, \"recall\": 0.7714964773788303, \"specificity\": 0.994300370475919, \"npv\": 0.7216132368148914, \"accuracy\": 0.8546731209106867, \"f1\": 0.8693448110951698, \"f2\": 0.8078680248164543, \"f0_5\": 0.9409487131705903, \"p4\": 0.8524968740928289, \"phi\": 0.7411165193912986}, {\"truth_threshold\": 0.6, \"match_probability\": 0.6024989407343608, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9086, \"tn\": 6978, \"fp\": 40, \"fn\": 2695, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7712418300653595, \"tn_rate\": 0.994300370475919, \"fp_rate\": 0.005699629524080934, \"fn_rate\": 0.22875816993464052, \"precision\": 0.9956169186938417, \"recall\": 0.7712418300653595, \"specificity\": 0.994300370475919, \"npv\": 0.7213894345084255, \"accuracy\": 0.8545135379541465, \"f1\": 0.8691825704309561, \"f2\": 0.8076444444444445, \"f0_5\": 0.9408719063891477, \"p4\": 0.8523407698892483, \"phi\": 0.7408769273182564}, {\"truth_threshold\": 0.62, \"match_probability\": 0.6058142681295483, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9083, \"tn\": 6978, \"fp\": 40, \"fn\": 2698, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7709871827518886, \"tn_rate\": 0.994300370475919, \"fp_rate\": 0.005699629524080934, \"fn_rate\": 0.22901281724811137, \"precision\": 0.9956154773649019, \"recall\": 0.7709871827518886, \"specificity\": 0.994300370475919, \"npv\": 0.7211657709797437, \"accuracy\": 0.8543539549976062, \"f1\": 0.8690202831993876, \"f2\": 0.8074208402225896, \"f0_5\": 0.9407950614214986, \"p4\": 0.8521846713439194, \"phi\": 0.7406374063907706}, {\"truth_threshold\": 0.64, \"match_probability\": 0.6091198834377483, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9080, \"tn\": 6979, \"fp\": 39, \"fn\": 2701, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7707325354384178, \"tn_rate\": 0.994442861214021, \"fp_rate\": 0.005557138785978911, \"fn_rate\": 0.2292674645615822, \"precision\": 0.9957232152648317, \"recall\": 0.7707325354384178, \"specificity\": 0.994442861214021, \"npv\": 0.7209710743801653, \"accuracy\": 0.8542475663599127, \"f1\": 0.8688995215311005, \"f2\": 0.8072115641057553, \"f0_5\": 0.9407961539258554, \"p4\": 0.8520847895988872, \"phi\": 0.7405382078985855}, {\"truth_threshold\": 0.66, \"match_probability\": 0.6124155130522262, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9074, \"tn\": 6979, \"fp\": 39, \"fn\": 2707, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7702232408114761, \"tn_rate\": 0.994442861214021, \"fp_rate\": 0.005557138785978911, \"fn_rate\": 0.2297767591885239, \"precision\": 0.9957203994293866, \"recall\": 0.7702232408114761, \"specificity\": 0.994442861214021, \"npv\": 0.7205244683047698, \"accuracy\": 0.8539284004468323, \"f1\": 0.8685747104431895, \"f2\": 0.8067642299553675, \"f0_5\": 0.9406422988410424, \"p4\": 0.851772614938643, \"phi\": 0.7400595726737443}, {\"truth_threshold\": 0.68, \"match_probability\": 0.6157008869298349, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9071, \"tn\": 6982, \"fp\": 36, \"fn\": 2710, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7699685934980053, \"tn_rate\": 0.9948703334283272, \"fp_rate\": 0.005129666571672842, \"fn_rate\": 0.23003140650199475, \"precision\": 0.9960469968156364, \"recall\": 0.7699685934980053, \"specificity\": 0.9948703334283272, \"npv\": 0.7203879488237722, \"accuracy\": 0.8539284004468323, \"f1\": 0.8685369590195328, \"f2\": 0.8065835571126247, \"f0_5\": 0.9407994357899977, \"p4\": 0.8517851263534449, \"phi\": 0.7402414032161202}, {\"truth_threshold\": 0.7000000000000001, \"match_probability\": 0.6189757386701197, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9066, \"tn\": 6986, \"fp\": 32, \"fn\": 2715, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7695441813088872, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.2304558186911128, \"precision\": 0.9964827434601011, \"recall\": 0.7695441813088872, \"specificity\": 0.9954402963807353, \"npv\": 0.7201319451602928, \"accuracy\": 0.8538752061279855, \"f1\": 0.8684323961875569, \"f2\": 0.8062680089644623, \"f0_5\": 0.9409835384966683, \"p4\": 0.8517497199086909, \"phi\": 0.7404046956084107}, {\"truth_threshold\": 0.72, \"match_probability\": 0.622239805591759, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9061, \"tn\": 6986, \"fp\": 32, \"fn\": 2720, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7691197691197691, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.23088023088023088, \"precision\": 0.9964808094138348, \"recall\": 0.7691197691197691, \"specificity\": 0.9954402963807353, \"npv\": 0.7197609725942716, \"accuracy\": 0.8536092345337518, \"f1\": 0.8681613490466609, \"f2\": 0.8058950139637476, \"f0_5\": 0.9408551907461633, \"p4\": 0.8514895827551938, \"phi\": 0.7400066646769581}, {\"truth_threshold\": 0.74, \"match_probability\": 0.6254928288063007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9058, \"tn\": 6986, \"fp\": 32, \"fn\": 2723, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7688651218062983, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.2311348781937017, \"precision\": 0.9964796479647965, \"recall\": 0.7688651218062983, \"specificity\": 0.9954402963807353, \"npv\": 0.7195385724585436, \"accuracy\": 0.8534496515772115, \"f1\": 0.8679986584255666, \"f2\": 0.8056711851140286, \"f0_5\": 0.940778130907127, \"p4\": 0.8513335076831481, \"phi\": 0.7397679402286886}, {\"truth_threshold\": 0.76, \"match_probability\": 0.6287345532891625, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9053, \"tn\": 6986, \"fp\": 32, \"fn\": 2728, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7684407096171803, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.2315592903828198, \"precision\": 0.9964777105118326, \"recall\": 0.7684407096171803, \"specificity\": 0.9954402963807353, \"npv\": 0.7191682108297303, \"accuracy\": 0.8531836799829778, \"f1\": 0.8677274034314195, \"f2\": 0.8052980839367361, \"f0_5\": 0.9406496124353193, \"p4\": 0.8510733945131908, \"phi\": 0.7393702227792909}, {\"truth_threshold\": 0.8, \"match_probability\": 0.6351831056874558, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9043, \"tn\": 6986, \"fp\": 32, \"fn\": 2738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7675918852389441, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.23240811476105594, \"precision\": 0.996473829201102, \"recall\": 0.7675918852389441, \"specificity\": 0.9954402963807353, \"npv\": 0.718428630193336, \"accuracy\": 0.8526517367945103, \"f1\": 0.8671845032604526, \"f2\": 0.8045516824142779, \"f0_5\": 0.9403922547367983, \"p4\": 0.8505532125532672, \"phi\": 0.7385753741068085}, {\"truth_threshold\": 0.8200000000000001, \"match_probability\": 0.6383894434731548, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9022, \"tn\": 6986, \"fp\": 32, \"fn\": 2759, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7658093540446481, \"tn_rate\": 0.9954402963807353, \"fp_rate\": 0.004559703619264748, \"fn_rate\": 0.23419064595535183, \"precision\": 0.9964656505411973, \"recall\": 0.7658093540446481, \"specificity\": 0.9954402963807353, \"npv\": 0.7168804515135967, \"accuracy\": 0.8515346560987287, \"f1\": 0.8660427165826734, \"f2\": 0.8029833742746271, \"f0_5\": 0.939850407317124, \"p4\": 0.8494610192821909, \"phi\": 0.7369087262487273}, {\"truth_threshold\": 0.84, \"match_probability\": 0.6415835023901045, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9020, \"tn\": 6987, \"fp\": 31, \"fn\": 2761, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.765639589169001, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.23436041083099907, \"precision\": 0.9965749640923655, \"recall\": 0.765639589169001, \"specificity\": 0.9955827871188373, \"npv\": 0.7167624128026262, \"accuracy\": 0.8514814617798819, \"f1\": 0.8659754224270353, \"f2\": 0.8028482421005786, \"f0_5\": 0.9398770449098677, \"p4\": 0.849413144650872, \"phi\": 0.7368910184925169}, {\"truth_threshold\": 0.86, \"match_probability\": 0.6447650477003041, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9016, \"tn\": 6987, \"fp\": 31, \"fn\": 2765, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7653000594177065, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.23469994058229351, \"precision\": 0.9965734497623522, \"recall\": 0.7653000594177065, \"specificity\": 0.9955827871188373, \"npv\": 0.7164684167350287, \"accuracy\": 0.8512686845044949, \"f1\": 0.8657576339542923, \"f2\": 0.8025493582097524, \"f0_5\": 0.9397736037857783, \"p4\": 0.8492051369187554, \"phi\": 0.7365740458910138}, {\"truth_threshold\": 0.88, \"match_probability\": 0.6479338488966562, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9012, \"tn\": 6987, \"fp\": 31, \"fn\": 2769, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.764960529666412, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.235039470333588, \"precision\": 0.9965719340926683, \"recall\": 0.764960529666412, \"specificity\": 0.9955827871188373, \"npv\": 0.7161746617466175, \"accuracy\": 0.851055907229108, \"f1\": 0.8655397618132924, \"f2\": 0.8022504317481796, \"f0_5\": 0.9396700936333493, \"p4\": 0.8489971381011799, \"phi\": 0.7362571969271376}, {\"truth_threshold\": 0.9, \"match_probability\": 0.6510896797541332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9010, \"tn\": 6987, \"fp\": 31, \"fn\": 2771, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7647907647907648, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.2352092352092352, \"precision\": 0.9965711757548944, \"recall\": 0.7647907647907648, \"specificity\": 0.9955827871188373, \"npv\": 0.7160278745644599, \"accuracy\": 0.8509495185914144, \"f1\": 0.8654307943521276, \"f2\": 0.8021009525505208, \"f0_5\": 0.9396183126499114, \"p4\": 0.8488931420159708, \"phi\": 0.736098818759232}, {\"truth_threshold\": 0.92, \"match_probability\": 0.6542323183780514, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 9004, \"tn\": 6987, \"fp\": 31, \"fn\": 2777, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7642814701638231, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.2357185298361769, \"precision\": 0.9965688987271721, \"recall\": 0.7642814701638231, \"specificity\": 0.9955827871188373, \"npv\": 0.715587873822204, \"accuracy\": 0.850630352678334, \"f1\": 0.8651037663335895, \"f2\": 0.801652451076408, \"f0_5\": 0.9394628659669039, \"p4\": 0.8485811669615951, \"phi\": 0.7356238692715511}, {\"truth_threshold\": 0.9400000000000001, \"match_probability\": 0.6573615472494517, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8997, \"tn\": 6987, \"fp\": 31, \"fn\": 2784, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7636872930990578, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.2363127069009422, \"precision\": 0.9965662383695171, \"recall\": 0.7636872930990578, \"specificity\": 0.9955827871188373, \"npv\": 0.7150752225974824, \"accuracy\": 0.8502579924464068, \"f1\": 0.8647219952904993, \"f2\": 0.8011290782162701, \"f0_5\": 0.9392813145971227, \"p4\": 0.848217220871474, \"phi\": 0.7350701117273057}, {\"truth_threshold\": 0.96, \"match_probability\": 0.660477153267581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8992, \"tn\": 6987, \"fp\": 31, \"fn\": 2789, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7632628809099398, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.23673711909006026, \"precision\": 0.9965643355868337, \"recall\": 0.7632628809099398, \"specificity\": 0.9955827871188373, \"npv\": 0.7147094926350246, \"accuracy\": 0.849992020852173, \"f1\": 0.8644491443953086, \"f2\": 0.8007551605606711, \"f0_5\": 0.9391515050237086, \"p4\": 0.8479572755597717, \"phi\": 0.7346748010707878}, {\"truth_threshold\": 0.98, \"match_probability\": 0.6635789277894779, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8986, \"tn\": 6987, \"fp\": 31, \"fn\": 2795, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.762753586282998, \"tn_rate\": 0.9955827871188373, \"fp_rate\": 0.004417212881162725, \"fn_rate\": 0.23724641371700195, \"precision\": 0.9965620494621271, \"recall\": 0.762753586282998, \"specificity\": 0.9955827871188373, \"npv\": 0.7142711102024126, \"accuracy\": 0.8496728549390925, \"f1\": 0.8641215501490528, \"f2\": 0.80030637145758, \"f0_5\": 0.938995590294468, \"p4\": 0.847645358792619, \"phi\": 0.7342006812811978}, {\"truth_threshold\": 1.0, \"match_probability\": 0.6666666666666666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8986, \"tn\": 6988, \"fp\": 30, \"fn\": 2795, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.762753586282998, \"tn_rate\": 0.9957252778569393, \"fp_rate\": 0.004274722143060701, \"fn_rate\": 0.23724641371700195, \"precision\": 0.9966725820763088, \"recall\": 0.762753586282998, \"specificity\": 0.9957252778569393, \"npv\": 0.7143003168762139, \"accuracy\": 0.8497260492579393, \"f1\": 0.8641631004471799, \"f2\": 0.8003206270039188, \"f0_5\": 0.9390740934266903, \"p4\": 0.8477014536142978, \"phi\": 0.7343418256042534}, {\"truth_threshold\": 1.02, \"match_probability\": 0.6697401702789662, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8983, \"tn\": 6988, \"fp\": 30, \"fn\": 2798, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7624989389695273, \"tn_rate\": 0.9957252778569393, \"fp_rate\": 0.004274722143060701, \"fn_rate\": 0.2375010610304728, \"precision\": 0.9966714745367802, \"recall\": 0.7624989389695273, \"specificity\": 0.9957252778569393, \"npv\": 0.7140813406907828, \"accuracy\": 0.849566466301399, \"f1\": 0.8639992305472732, \"f2\": 0.8000961932415341, \"f0_5\": 0.938996090565091, \"p4\": 0.84754549944109, \"phi\": 0.7341048948775136}, {\"truth_threshold\": 1.04, \"match_probability\": 0.6727992435654236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8973, \"tn\": 6988, \"fp\": 30, \"fn\": 2808, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7616501145912911, \"tn_rate\": 0.9957252778569393, \"fp_rate\": 0.004274722143060701, \"fn_rate\": 0.23834988540870894, \"precision\": 0.9966677774075309, \"recall\": 0.7616501145912911, \"specificity\": 0.9957252778569393, \"npv\": 0.7133523887300939, \"accuracy\": 0.8490345231129316, \"f1\": 0.8634526558891455, \"f2\": 0.7993479074242343, \"f0_5\": 0.9387357981294332, \"p4\": 0.8470256861511894, \"phi\": 0.7333156223445954}, {\"truth_threshold\": 1.06, \"match_probability\": 0.6758436960523875, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8971, \"tn\": 6988, \"fp\": 30, \"fn\": 2810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7614803497156438, \"tn_rate\": 0.9957252778569393, \"fp_rate\": 0.004274722143060701, \"fn_rate\": 0.23851965028435618, \"precision\": 0.9966670369958893, \"recall\": 0.7614803497156438, \"specificity\": 0.9957252778569393, \"npv\": 0.7132067768932435, \"accuracy\": 0.8489281344752381, \"f1\": 0.8633432778365894, \"f2\": 0.7991982182628062, \"f0_5\": 0.9386836873495867, \"p4\": 0.8469217297031658, \"phi\": 0.7331578593613138}, {\"truth_threshold\": 1.08, \"match_probability\": 0.6788733418787326, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8969, \"tn\": 6988, \"fp\": 30, \"fn\": 2812, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7613105848399966, \"tn_rate\": 0.9957252778569393, \"fp_rate\": 0.004274722143060701, \"fn_rate\": 0.2386894151600034, \"precision\": 0.9966662962551395, \"recall\": 0.7613105848399966, \"specificity\": 0.9957252778569393, \"npv\": 0.7130612244897959, \"accuracy\": 0.8488217458375446, \"f1\": 0.8632338787295476, \"f2\": 0.7990485184327281, \"f0_5\": 0.9386315591184042, \"p4\": 0.8468177753069146, \"phi\": 0.7330001268396205}, {\"truth_threshold\": 1.1, \"match_probability\": 0.6818879998182596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8965, \"tn\": 6989, \"fp\": 29, \"fn\": 2816, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7609710550887021, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.23902894491129786, \"precision\": 0.9967756281965755, \"recall\": 0.7609710550887021, \"specificity\": 0.9958677685950413, \"npv\": 0.7127995920448751, \"accuracy\": 0.8486621628810043, \"f1\": 0.8630565583634175, \"f2\": 0.7987633201468335, \"f0_5\": 0.9386058588269782, \"p4\": 0.8466659439547372, \"phi\": 0.7328260878289422}, {\"truth_threshold\": 1.12, \"match_probability\": 0.6848874932992853, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8958, \"tn\": 6989, \"fp\": 29, \"fn\": 2823, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7603768780239368, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.23962312197606314, \"precision\": 0.9967731167241571, \"recall\": 0.7603768780239368, \"specificity\": 0.9958677685950413, \"npv\": 0.712291072156543, \"accuracy\": 0.848289802649077, \"f1\": 0.862673343605547, \"f2\": 0.7982392044340682, \"f0_5\": 0.9384231808753588, \"p4\": 0.8463021268592755, \"phi\": 0.7322745365983017}, {\"truth_threshold\": 1.1400000000000001, \"match_probability\": 0.6878716504214515, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8956, \"tn\": 6989, \"fp\": 29, \"fn\": 2825, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7602071131482896, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.23979288685171038, \"precision\": 0.9967723984418475, \"recall\": 0.7602071131482896, \"specificity\": 0.9958677685950413, \"npv\": 0.7121459140004076, \"accuracy\": 0.8481834140113835, \"f1\": 0.8625638062217086, \"f2\": 0.7980894330677788, \"f0_5\": 0.9383709478007586, \"p4\": 0.8461981836303725, \"phi\": 0.7321170188197101}, {\"truth_threshold\": 1.16, \"match_probability\": 0.690840303969775, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8951, \"tn\": 6989, \"fp\": 29, \"fn\": 2830, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7597827009591716, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24021729904082845, \"precision\": 0.9967706013363029, \"recall\": 0.7597827009591716, \"specificity\": 0.9958677685950413, \"npv\": 0.7117832773194827, \"accuracy\": 0.8479174424171498, \"f1\": 0.8622898704301334, \"f2\": 0.797714957935263, \"f0_5\": 0.9382402884635542, \"p4\": 0.845938334252808, \"phi\": 0.7317233569530927}, {\"truth_threshold\": 1.18, \"match_probability\": 0.6937932914259702, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8943, \"tn\": 6989, \"fp\": 29, \"fn\": 2838, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7591036414565826, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24089635854341737, \"precision\": 0.9967677218011591, \"recall\": 0.7591036414565826, \"specificity\": 0.9958677685950413, \"npv\": 0.7112038261931414, \"accuracy\": 0.8474918878663759, \"f1\": 0.8618512986074303, \"f2\": 0.7971156588705077, \"f0_5\": 0.9380310054752564, \"p4\": 0.8455226008296758, \"phi\": 0.7310938912791489}, {\"truth_threshold\": 1.2, \"match_probability\": 0.6967304549770723, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8939, \"tn\": 6989, \"fp\": 29, \"fn\": 2842, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7587641117052881, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24123588829471182, \"precision\": 0.9967662801070473, \"recall\": 0.7587641117052881, \"specificity\": 0.9958677685950413, \"npv\": 0.7109144542772862, \"accuracy\": 0.8472791105909889, \"f1\": 0.8616318858740181, \"f2\": 0.7968159452328317, \"f0_5\": 0.9379262585776341, \"p4\": 0.8453147457913759, \"phi\": 0.7307793396373269}, {\"truth_threshold\": 1.22, \"match_probability\": 0.6996516415213959, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8935, \"tn\": 6989, \"fp\": 29, \"fn\": 2846, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7584245819539938, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24157541804600627, \"precision\": 0.9967648371262829, \"recall\": 0.7584245819539938, \"specificity\": 0.9958677685950413, \"npv\": 0.7106253177427555, \"accuracy\": 0.8470663333156019, \"f1\": 0.861412388527356, \"f2\": 0.796516188846099, \"f0_5\": 0.9378214413166236, \"p4\": 0.8451068984515122, \"phi\": 0.7304649085831658}, {\"truth_threshold\": 1.24, \"match_probability\": 0.7025567026718631, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8917, \"tn\": 6989, \"fp\": 29, \"fn\": 2864, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7568966980731686, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24310330192683133, \"precision\": 0.9967583277442432, \"recall\": 0.7568966980731686, \"specificity\": 0.9958677685950413, \"npv\": 0.7093271084948747, \"accuracy\": 0.8461088355763604, \"f1\": 0.8604236020649394, \"f2\": 0.7951667558409131, \"f0_5\": 0.937348890991275, \"p4\": 0.8441716790036807, \"phi\": 0.7290514569169517}, {\"truth_threshold\": 1.26, \"match_probability\": 0.705445494756739, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8910, \"tn\": 6989, \"fp\": 29, \"fn\": 2871, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7563025210084033, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24369747899159663, \"precision\": 0.9967557892381698, \"recall\": 0.7563025210084033, \"specificity\": 0.9958677685950413, \"npv\": 0.7088235294117647, \"accuracy\": 0.8457364753444332, \"f1\": 0.86003861003861, \"f2\": 0.794641742325598, \"f0_5\": 0.9371647348381261, \"p4\": 0.8438080230746409, \"phi\": 0.7285024368161869}, {\"truth_threshold\": 1.28, \"match_probability\": 0.7083178788178136, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8906, \"tn\": 6989, \"fp\": 29, \"fn\": 2875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7559629912571089, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.2440370087428911, \"precision\": 0.9967543368774482, \"recall\": 0.7559629912571089, \"specificity\": 0.9958677685950413, \"npv\": 0.708536090835361, \"accuracy\": 0.8455236980690463, \"f1\": 0.8598184977794942, \"f2\": 0.794341675734494, \"f0_5\": 0.9370594053155447, \"p4\": 0.8436002296655781, \"phi\": 0.7281888753501865}, {\"truth_threshold\": 1.3, \"match_probability\": 0.7111737206060699, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8903, \"tn\": 6989, \"fp\": 29, \"fn\": 2878, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7557083439436381, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24429165605636194, \"precision\": 0.9967532467532467, \"recall\": 0.7557083439436381, \"specificity\": 0.9958677685950413, \"npv\": 0.708320664842404, \"accuracy\": 0.845364115112506, \"f1\": 0.8596533577946217, \"f2\": 0.7941165976880262, \"f0_5\": 0.9369803616156939, \"p4\": 0.8434443893230896, \"phi\": 0.7279537825504444}, {\"truth_threshold\": 1.32, \"match_probability\": 0.714012890574883, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8899, \"tn\": 6989, \"fp\": 29, \"fn\": 2882, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7553688141923436, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.2446311858076564, \"precision\": 0.9967517921146953, \"recall\": 0.7553688141923436, \"specificity\": 0.9958677685950413, \"npv\": 0.7080336338770135, \"accuracy\": 0.845151337837119, \"f1\": 0.8594330967212324, \"f2\": 0.7938164561478627, \"f0_5\": 0.9368749078811615, \"p4\": 0.8432366084347942, \"phi\": 0.7276404297593438}, {\"truth_threshold\": 1.34, \"match_probability\": 0.7168352638707939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8898, \"tn\": 6989, \"fp\": 29, \"fn\": 2883, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.75528393175452, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24471606824548, \"precision\": 0.9967514282513722, \"recall\": 0.75528393175452, \"specificity\": 0.9958677685950413, \"npv\": 0.7079619124797407, \"accuracy\": 0.8450981435182723, \"f1\": 0.8593780181572339, \"f2\": 0.7937414140693297, \"f0_5\": 0.936848533344564, \"p4\": 0.8431846643195262, \"phi\": 0.7275621101659948}, {\"truth_threshold\": 1.36, \"match_probability\": 0.7196407203219027, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8889, \"tn\": 6989, \"fp\": 29, \"fn\": 2892, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7545199898141075, \"tn_rate\": 0.9958677685950413, \"fp_rate\": 0.004132231404958678, \"fn_rate\": 0.24548001018589255, \"precision\": 0.9967481498093743, \"recall\": 0.7545199898141075, \"specificity\": 0.9958677685950413, \"npv\": 0.7073170731707317, \"accuracy\": 0.8446193946486515, \"f1\": 0.8588820715976617, \"f2\": 0.7930659148495771, \"f0_5\": 0.9366109624259794, \"p4\": 0.8427171869968407, \"phi\": 0.7268575681974284}, {\"truth_threshold\": 1.3800000000000001, \"match_probability\": 0.7224291444239316, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8886, \"tn\": 6991, \"fp\": 27, \"fn\": 2895, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7542653425006366, \"tn_rate\": 0.9961527500712454, \"fp_rate\": 0.003847249928754631, \"fn_rate\": 0.24573465749936338, \"precision\": 0.9969707169303265, \"recall\": 0.7542653425006366, \"specificity\": 0.9961527500712454, \"npv\": 0.7071616427270888, \"accuracy\": 0.8445662003298048, \"f1\": 0.8587996520730646, \"f2\": 0.7928689972696611, \"f0_5\": 0.936689646448675, \"p4\": 0.8426733444587817, \"phi\": 0.7269069144342046}, {\"truth_threshold\": 1.4000000000000001, \"match_probability\": 0.7252004253240049, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8881, \"tn\": 6991, \"fp\": 27, \"fn\": 2900, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7538409303115186, \"tn_rate\": 0.9961527500712454, \"fp_rate\": 0.003847249928754631, \"fn_rate\": 0.24615906968848145, \"precision\": 0.9969690166142793, \"recall\": 0.7538409303115186, \"specificity\": 0.9961527500712454, \"npv\": 0.7068041654028915, \"accuracy\": 0.8443002287355711, \"f1\": 0.8585238532553531, \"f2\": 0.7924935750999429, \"f0_5\": 0.9365574842342818, \"p4\": 0.8424136461872431, \"phi\": 0.7265159591748461}, {\"truth_threshold\": 1.42, \"match_probability\": 0.7279544568021957, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8878, \"tn\": 6991, \"fp\": 27, \"fn\": 2903, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7535862829980478, \"tn_rate\": 0.9961527500712454, \"fp_rate\": 0.003847249928754631, \"fn_rate\": 0.2464137170019523, \"precision\": 0.9969679955081415, \"recall\": 0.7535862829980478, \"specificity\": 0.9961527500712454, \"npv\": 0.7065898524358197, \"accuracy\": 0.8441406457790308, \"f1\": 0.8583583099680944, \"f2\": 0.7922682896357244, \"f0_5\": 0.9364781333727137, \"p4\": 0.8422578323079735, \"phi\": 0.7262814747918455}, {\"truth_threshold\": 1.44, \"match_probability\": 0.7306911372508947, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8871, \"tn\": 6991, \"fp\": 27, \"fn\": 2910, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7529921059332824, \"tn_rate\": 0.9961527500712454, \"fp_rate\": 0.003847249928754631, \"fn_rate\": 0.2470078940667176, \"precision\": 0.9969656102494943, \"recall\": 0.7529921059332824, \"specificity\": 0.9961527500712454, \"npv\": 0.7060902939097061, \"accuracy\": 0.8437682855471036, \"f1\": 0.8579718555055854, \"f2\": 0.791742529720467, \"f0_5\": 0.936292825026914, \"p4\": 0.8418942812432606, \"phi\": 0.7257346030640107}, {\"truth_threshold\": 1.46, \"match_probability\": 0.7334103696520481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8863, \"tn\": 6992, \"fp\": 26, \"fn\": 2918, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7523130464306935, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.2476869535693065, \"precision\": 0.997075036562043, \"recall\": 0.7523130464306935, \"specificity\": 0.9962952408093474, \"npv\": 0.7055499495459132, \"accuracy\": 0.8433959253151764, \"f1\": 0.8575713594581519, \"f2\": 0.7911556245871494, \"f0_5\": 0.9361598749392652, \"p4\": 0.8415347788932921, \"phi\": 0.7252522922558292}, {\"truth_threshold\": 1.48, \"match_probability\": 0.7361120615523239, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8859, \"tn\": 6992, \"fp\": 26, \"fn\": 2922, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.751973516679399, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.24802648332060095, \"precision\": 0.9970737197523917, \"recall\": 0.751973516679399, \"specificity\": 0.9962952408093474, \"npv\": 0.7052652814202138, \"accuracy\": 0.8431831480397893, \"f1\": 0.8573502371044227, \"f2\": 0.7908550411541002, \"f0_5\": 0.9360537604868874, \"p4\": 0.8413270534333664, \"phi\": 0.7249402263244279}, {\"truth_threshold\": 1.5, \"match_probability\": 0.7387961250362586, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8858, \"tn\": 6992, \"fp\": 26, \"fn\": 2923, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7518886342415754, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.24811136575842457, \"precision\": 0.9970733903647006, \"recall\": 0.7518886342415754, \"specificity\": 0.9962952408093474, \"npv\": 0.7051941502773575, \"accuracy\": 0.8431299537209426, \"f1\": 0.8572949431405759, \"f2\": 0.7907798885873447, \"f0_5\": 0.9360272206606505, \"p4\": 0.8412751230724667, \"phi\": 0.7248622282061995}, {\"truth_threshold\": 1.54, \"match_probability\": 0.7441110376077843, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8851, \"tn\": 6992, \"fp\": 26, \"fn\": 2930, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7512944571768101, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.24870554282318988, \"precision\": 0.9970710825729413, \"recall\": 0.7512944571768101, \"specificity\": 0.9962952408093474, \"npv\": 0.7046966337431969, \"accuracy\": 0.8427575934890154, \"f1\": 0.8569077355019847, \"f2\": 0.7902537454688309, \"f0_5\": 0.935841316162321, \"p4\": 0.8409116216802448, \"phi\": 0.7243164467946432}, {\"truth_threshold\": 1.56, \"match_probability\": 0.7467417332849615, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8846, \"tn\": 6992, \"fp\": 26, \"fn\": 2935, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.750870044987692, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.24912995501230795, \"precision\": 0.9970694319206492, \"recall\": 0.750870044987692, \"specificity\": 0.9962952408093474, \"npv\": 0.7043416943688929, \"accuracy\": 0.8424916218947817, \"f1\": 0.856630997917978, \"f2\": 0.7898778484177441, \"f0_5\": 0.935708392392477, \"p4\": 0.8406519896283415, \"phi\": 0.7239268227074813}, {\"truth_threshold\": 1.58, \"match_probability\": 0.7493544936580313, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8844, \"tn\": 6992, \"fp\": 26, \"fn\": 2937, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7507002801120448, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.24929971988795518, \"precision\": 0.9970687711386697, \"recall\": 0.7507002801120448, \"specificity\": 0.9962952408093474, \"npv\": 0.7041998187128613, \"accuracy\": 0.8423852332570881, \"f1\": 0.8565202653624522, \"f2\": 0.7897274708004429, \"f0_5\": 0.9356551913840164, \"p4\": 0.8405481395282295, \"phi\": 0.7237710242762931}, {\"truth_threshold\": 1.6, \"match_probability\": 0.7519492530313435, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8837, \"tn\": 6992, \"fp\": 26, \"fn\": 2944, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7501061030472795, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.2498938969527205, \"precision\": 0.9970664560532551, \"recall\": 0.7501061030472795, \"specificity\": 0.9962952408093474, \"npv\": 0.7037037037037037, \"accuracy\": 0.8420128730251609, \"f1\": 0.8561325324549506, \"f2\": 0.789201064532838, \"f0_5\": 0.9354688459339868, \"p4\": 0.8401846762738667, \"phi\": 0.7232259598335897}, {\"truth_threshold\": 1.62, \"match_probability\": 0.754525950046764, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8832, \"tn\": 6992, \"fp\": 26, \"fn\": 2949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7496816908581615, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25031830914183856, \"precision\": 0.9970648001806277, \"recall\": 0.7496816908581615, \"specificity\": 0.9962952408093474, \"npv\": 0.7033497636052711, \"accuracy\": 0.8417469014309272, \"f1\": 0.8558554193517128, \"f2\": 0.7888249794576828, \"f0_5\": 0.9353356067184886, \"p4\": 0.8399250710436122, \"phi\": 0.7228368468667333}, {\"truth_threshold\": 1.6400000000000001, \"match_probability\": 0.7570845276442862, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8818, \"tn\": 6992, \"fp\": 26, \"fn\": 2963, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7484933367286308, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25150666327136917, \"precision\": 0.9970601537765716, \"recall\": 0.7484933367286308, \"specificity\": 0.9962952408093474, \"npv\": 0.7023606228026118, \"accuracy\": 0.8410021809670727, \"f1\": 0.8550787878787879, \"f2\": 0.7877715837621498, \"f0_5\": 0.9349619356617257, \"p4\": 0.8391982256958582, \"phi\": 0.7217482977388433}, {\"truth_threshold\": 1.6600000000000001, \"match_probability\": 0.7596249330210829, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8811, \"tn\": 6992, \"fp\": 26, \"fn\": 2970, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7478991596638656, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25210084033613445, \"precision\": 0.9970578250537513, \"recall\": 0.7478991596638656, \"specificity\": 0.9962952408093474, \"npv\": 0.7018670949608512, \"accuracy\": 0.8406298207351455, \"f1\": 0.8546900766320691, \"f2\": 0.7872446882650417, \"f0_5\": 0.9347747671285196, \"p4\": 0.8388348296260776, \"phi\": 0.7212045561600783}, {\"truth_threshold\": 1.68, \"match_probability\": 0.7621471175890653, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8810, \"tn\": 6992, \"fp\": 26, \"fn\": 2971, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7478142772260419, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25218572277395807, \"precision\": 0.9970574920778633, \"recall\": 0.7478142772260419, \"specificity\": 0.9962952408093474, \"npv\": 0.7017966475961056, \"accuracy\": 0.8405766264162987, \"f1\": 0.8546345249066305, \"f2\": 0.7871694067190851, \"f0_5\": 0.9347480106100796, \"p4\": 0.8387829173202036, \"phi\": 0.7211269077283371}, {\"truth_threshold\": 1.7, \"match_probability\": 0.7646510369310004, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8806, \"tn\": 6992, \"fp\": 26, \"fn\": 2975, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7474747474747475, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25252525252525254, \"precision\": 0.9970561594202898, \"recall\": 0.7474747474747475, \"specificity\": 0.9962952408093474, \"npv\": 0.7015149994983445, \"accuracy\": 0.8403638491409118, \"f1\": 0.8544122641051763, \"f2\": 0.7868682536278504, \"f0_5\": 0.9346409390986861, \"p4\": 0.8385752716024337, \"phi\": 0.7208163862486197}, {\"truth_threshold\": 1.74, \"match_probability\": 0.7696039228492181, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8804, \"tn\": 6992, \"fp\": 26, \"fn\": 2977, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7473049825991003, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.2526950174008998, \"precision\": 0.9970554926387316, \"recall\": 0.7473049825991003, \"specificity\": 0.9962952408093474, \"npv\": 0.7013742602066406, \"accuracy\": 0.8402574605032183, \"f1\": 0.8543011013536461, \"f2\": 0.7867176609357687, \"f0_5\": 0.9345873760642025, \"p4\": 0.8384714508328962, \"phi\": 0.7206611688241054}, {\"truth_threshold\": 1.76, \"match_probability\": 0.7720528210314674, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8803, \"tn\": 6992, \"fp\": 26, \"fn\": 2978, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7472201001612766, \"tn_rate\": 0.9962952408093474, \"fp_rate\": 0.0037047591906526076, \"fn_rate\": 0.25277989983872334, \"precision\": 0.9970551591346698, \"recall\": 0.7472201001612766, \"specificity\": 0.9962952408093474, \"npv\": 0.7013039117352056, \"accuracy\": 0.8402042661843715, \"f1\": 0.8542455118874333, \"f2\": 0.7866423605526066, \"f0_5\": 0.9345605877232096, \"p4\": 0.8384195409669408, \"phi\": 0.7205835709324377}, {\"truth_threshold\": 1.78, \"match_probability\": 0.774483317102736, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8794, \"tn\": 6993, \"fp\": 25, \"fn\": 2987, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7464561582208641, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2535438417791359, \"precision\": 0.997165211475224, \"recall\": 0.7464561582208641, \"specificity\": 0.9964377315474494, \"npv\": 0.7007014028056112, \"accuracy\": 0.8397787116335975, \"f1\": 0.8537864077669903, \"f2\": 0.7859785853457985, \"f0_5\": 0.9343987079499331, \"p4\": 0.8380082522833674, \"phi\": 0.7200283630681037}, {\"truth_threshold\": 1.8, \"match_probability\": 0.7768953867957377, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8789, \"tn\": 6993, \"fp\": 25, \"fn\": 2992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.746031746031746, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.25396825396825395, \"precision\": 0.9971636033582936, \"recall\": 0.746031746031746, \"specificity\": 0.9964377315474494, \"npv\": 0.7003505257886831, \"accuracy\": 0.8395127400393638, \"f1\": 0.8535081330420005, \"f2\": 0.7856019164074511, \"f0_5\": 0.9342645151689096, \"p4\": 0.8377487179675559, \"phi\": 0.7196408486681835}, {\"truth_threshold\": 1.82, \"match_probability\": 0.7792890097239141, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8781, \"tn\": 6993, \"fp\": 25, \"fn\": 3000, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7453526865291571, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2546473134708429, \"precision\": 0.9971610265727913, \"recall\": 0.7453526865291571, \"specificity\": 0.9964377315474494, \"npv\": 0.6997898528970279, \"accuracy\": 0.8390871854885898, \"f1\": 0.8530626123281683, \"f2\": 0.7849991060253889, \"f0_5\": 0.9340495691947666, \"p4\": 0.8373334801671197, \"phi\": 0.7190211987561812}, {\"truth_threshold\": 1.84, \"match_probability\": 0.7816641693291569, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8770, \"tn\": 6993, \"fp\": 25, \"fn\": 3011, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7444189797130973, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.25558102028690266, \"precision\": 0.9971574758385446, \"recall\": 0.7444189797130973, \"specificity\": 0.9964377315474494, \"npv\": 0.6990203918432627, \"accuracy\": 0.8385020479812756, \"f1\": 0.8524494556765163, \"f2\": 0.7841699601208891, \"f0_5\": 0.9337535401716318, \"p4\": 0.8367625617204828, \"phi\": 0.7181699280136449}, {\"truth_threshold\": 1.86, \"match_probability\": 0.7840208528285652, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8764, \"tn\": 6993, \"fp\": 25, \"fn\": 3017, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7439096850861556, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2560903149138443, \"precision\": 0.9971555353282512, \"recall\": 0.7439096850861556, \"specificity\": 0.9964377315474494, \"npv\": 0.6986013986013986, \"accuracy\": 0.8381828820681951, \"f1\": 0.8521147301895965, \"f2\": 0.7837175612111673, \"f0_5\": 0.9335918358650958, \"p4\": 0.8364511675917777, \"phi\": 0.7177059625220722}, {\"truth_threshold\": 1.8800000000000001, \"match_probability\": 0.786359051160298, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8756, \"tn\": 6993, \"fp\": 25, \"fn\": 3025, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7432306255835668, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2567693744164332, \"precision\": 0.9971529438560528, \"recall\": 0.7432306255835668, \"specificity\": 0.9964377315474494, \"npv\": 0.6980435216610101, \"accuracy\": 0.8377573275174212, \"f1\": 0.8516681256687093, \"f2\": 0.7831142116089795, \"f0_5\": 0.9333759727107984, \"p4\": 0.8360359924420653, \"phi\": 0.7170877404699478}, {\"truth_threshold\": 1.9000000000000001, \"match_probability\": 0.7886787589285739, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8750, \"tn\": 6993, \"fp\": 25, \"fn\": 3031, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7427213309566251, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.25727866904337493, \"precision\": 0.9971509971509972, \"recall\": 0.7427213309566251, \"specificity\": 0.9964377315474494, \"npv\": 0.6976256983240223, \"accuracy\": 0.8374381616043407, \"f1\": 0.8513329441525589, \"f2\": 0.782661586074885, \"f0_5\": 0.933213881956443, \"p4\": 0.8357246235618079, \"phi\": 0.7166243722320601}, {\"truth_threshold\": 1.92, \"match_probability\": 0.7909799743478786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8746, \"tn\": 6993, \"fp\": 25, \"fn\": 3035, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7423818012053306, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2576181987946694, \"precision\": 0.997149697867974, \"recall\": 0.7423818012053306, \"specificity\": 0.9964377315474494, \"npv\": 0.6973474272038293, \"accuracy\": 0.8372253843289537, \"f1\": 0.8511093810821331, \"f2\": 0.7823597817336077, \"f0_5\": 0.9331057292222341, \"p4\": 0.8355170501300985, \"phi\": 0.7163156018429997}, {\"truth_threshold\": 1.94, \"match_probability\": 0.7932626991864332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8738, \"tn\": 6993, \"fp\": 25, \"fn\": 3043, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7417027417027418, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2582972582972583, \"precision\": 0.9971470957434668, \"recall\": 0.7417027417027418, \"specificity\": 0.9964377315474494, \"npv\": 0.6967915504184934, \"accuracy\": 0.8367998297781797, \"f1\": 0.8506619937694704, \"f2\": 0.7817560434448083, \"f0_5\": 0.9328892020583777, \"p4\": 0.8351019169457489, \"phi\": 0.7156984006441444}, {\"truth_threshold\": 1.96, \"match_probability\": 0.795526938708981, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8732, \"tn\": 6993, \"fp\": 25, \"fn\": 3049, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7411934470758, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.25880655292419996, \"precision\": 0.9971451410300332, \"recall\": 0.7411934470758, \"specificity\": 0.9964377315474494, \"npv\": 0.6963752240589524, \"accuracy\": 0.8364806638650992, \"f1\": 0.8503262245593534, \"f2\": 0.7813031262862153, \"f0_5\": 0.9327266124035976, \"p4\": 0.8347905787697832, \"phi\": 0.7152357962936522}, {\"truth_threshold\": 1.98, \"match_probability\": 0.7977727016189426, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8730, \"tn\": 6993, \"fp\": 25, \"fn\": 3051, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7410236822001528, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2589763177998472, \"precision\": 0.9971444888635066, \"recall\": 0.7410236822001528, \"specificity\": 0.9964377315474494, \"npv\": 0.696236559139785, \"accuracy\": 0.8363742752274057, \"f1\": 0.8502142578885858, \"f2\": 0.7811521322858319, \"f0_5\": 0.9326723787953249, \"p4\": 0.8346868015651708, \"phi\": 0.7150816512303343}, {\"truth_threshold\": 2.0, \"match_probability\": 0.8, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8726, \"tn\": 6993, \"fp\": 25, \"fn\": 3055, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7406841524488583, \"tn_rate\": 0.9964377315474494, \"fp_rate\": 0.003562268452550584, \"fn_rate\": 0.2593158475511417, \"precision\": 0.9971431836361558, \"recall\": 0.7406841524488583, \"specificity\": 0.9964377315474494, \"npv\": 0.6959593949044586, \"accuracy\": 0.8361614979520188, \"f1\": 0.8499902591077343, \"f2\": 0.7808501118568233, \"f0_5\": 0.9325638559367319, \"p4\": 0.8344792503879819, \"phi\": 0.7147734455731806}, {\"truth_threshold\": 2.02, \"match_probability\": 0.8022088492571531, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8721, \"tn\": 7002, \"fp\": 16, \"fn\": 3060, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7402597402597403, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2597402597402597, \"precision\": 0.9981687077944374, \"recall\": 0.7402597402597403, \"specificity\": 0.9977201481903676, \"npv\": 0.6958855098389982, \"accuracy\": 0.8363742752274057, \"f1\": 0.8500828540793449, \"f2\": 0.7805982707076493, \"f0_5\": 0.9331464401121359, \"p4\": 0.8347219452434623, \"phi\": 0.7156801339337635}, {\"truth_threshold\": 2.04, \"match_probability\": 0.8043992680573092, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8712, \"tn\": 7002, \"fp\": 16, \"fn\": 3069, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7394957983193278, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2605042016806723, \"precision\": 0.998166819431714, \"recall\": 0.7394957983193278, \"specificity\": 0.9977201481903676, \"npv\": 0.6952636282394995, \"accuracy\": 0.835895526357785, \"f1\": 0.8495782339460725, \"f2\": 0.7799183556542291, \"f0_5\": 0.9329021480735871, \"p4\": 0.8342548933702512, \"phi\": 0.7149881004734103}, {\"truth_threshold\": 2.06, \"match_probability\": 0.8065712782694506, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8710, \"tn\": 7002, \"fp\": 16, \"fn\": 3071, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7393260334436805, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2606739665563195, \"precision\": 0.9981663992665597, \"recall\": 0.7393260334436805, \"specificity\": 0.9977201481903676, \"npv\": 0.695125583242331, \"accuracy\": 0.8357891377200914, \"f1\": 0.8494660359877115, \"f2\": 0.7797672336615935, \"f0_5\": 0.9328478097890115, \"p4\": 0.8341511068131158, \"phi\": 0.7148343923355095}, {\"truth_threshold\": 2.08, \"match_probability\": 0.8087249049044327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8707, \"tn\": 7002, \"fp\": 16, \"fn\": 3074, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7390713861302096, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2609286138697903, \"precision\": 0.9981657686575719, \"recall\": 0.7390713861302096, \"specificity\": 0.9977201481903676, \"npv\": 0.6949186184994045, \"accuracy\": 0.8356295547635513, \"f1\": 0.8492976980101443, \"f2\": 0.7795405303776389, \"f0_5\": 0.9327662674351338, \"p4\": 0.8339954288151754, \"phi\": 0.7146038826000217}, {\"truth_threshold\": 2.1, \"match_probability\": 0.8108601760544609, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8700, \"tn\": 7002, \"fp\": 16, \"fn\": 3081, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7384772090654443, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26152279093455566, \"precision\": 0.9981642955484167, \"recall\": 0.7384772090654443, \"specificity\": 0.9977201481903676, \"npv\": 0.6944361797084201, \"accuracy\": 0.8352571945316241, \"f1\": 0.8489047177635751, \"f2\": 0.7790114613180515, \"f0_5\": 0.9325758387822918, \"p4\": 0.8336321885858307, \"phi\": 0.7140662710968798}, {\"truth_threshold\": 2.12, \"match_probability\": 0.8129771228322951, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8693, \"tn\": 7002, \"fp\": 16, \"fn\": 3088, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7378830320006791, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26211696799932094, \"precision\": 0.9981628200711907, \"recall\": 0.7378830320006791, \"specificity\": 0.9977201481903676, \"npv\": 0.6939544103072349, \"accuracy\": 0.8348848342996968, \"f1\": 0.8485114690092728, \"f2\": 0.7784822595955797, \"f0_5\": 0.9323851813716026, \"p4\": 0.833268959876714, \"phi\": 0.7135290013246758}, {\"truth_threshold\": 2.14, \"match_probability\": 0.8150757793102267, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8689, \"tn\": 7002, \"fp\": 16, \"fn\": 3092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7375435022493846, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2624564977506154, \"precision\": 0.9981619758759334, \"recall\": 0.7375435022493846, \"specificity\": 0.9977201481903676, \"npv\": 0.693679413512978, \"accuracy\": 0.8346720570243098, \"f1\": 0.8482866347749682, \"f2\": 0.7781797990291783, \"f0_5\": 0.932276131413489, \"p4\": 0.8330614056509392, \"phi\": 0.7132221431555537}, {\"truth_threshold\": 2.16, \"match_probability\": 0.8171561824588779, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8686, \"tn\": 7002, \"fp\": 16, \"fn\": 3095, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7372888549359138, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2627111450640862, \"precision\": 0.9981613422201793, \"recall\": 0.7372888549359138, \"specificity\": 0.9977201481903676, \"npv\": 0.6934733089036348, \"accuracy\": 0.8345124740677695, \"f1\": 0.8481179514719523, \"f2\": 0.7779529251603196, \"f0_5\": 0.9321942947906158, \"p4\": 0.8329057423349764, \"phi\": 0.7129920725015868}, {\"truth_threshold\": 2.18, \"match_probability\": 0.8192183720858639, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8667, \"tn\": 7002, \"fp\": 16, \"fn\": 3114, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7356760886172651, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2643239113827349, \"precision\": 0.9981573188989981, \"recall\": 0.7356760886172651, \"specificity\": 0.9977201481903676, \"npv\": 0.6921708185053381, \"accuracy\": 0.8335017820096814, \"f1\": 0.847048475371384, \"f2\": 0.7765154908882398, \"f0_5\": 0.9316750155870401, \"p4\": 0.8319199196422915, \"phi\": 0.7115364067528538}, {\"truth_threshold\": 2.2, \"match_probability\": 0.8212623907743639, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8662, \"tn\": 7002, \"fp\": 16, \"fn\": 3119, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.735251676428147, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26474832357185296, \"precision\": 0.9981562572021203, \"recall\": 0.735251676428147, \"specificity\": 0.9977201481903676, \"npv\": 0.691828870664954, \"accuracy\": 0.8332358104154476, \"f1\": 0.8467667041399873, \"f2\": 0.7761370560194976, \"f0_5\": 0.9315380810014411, \"p4\": 0.8316605049715895, \"phi\": 0.7111537514014594}, {\"truth_threshold\": 2.22, \"match_probability\": 0.823288283821645, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8657, \"tn\": 7002, \"fp\": 16, \"fn\": 3124, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.734827264239029, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26517273576097106, \"precision\": 0.9981551942811022, \"recall\": 0.734827264239029, \"specificity\": 0.9977201481903676, \"npv\": 0.6914872605174798, \"accuracy\": 0.8329698388212139, \"f1\": 0.8464847951500929, \"f2\": 0.7757585533272399, \"f0_5\": 0.9314010285542142, \"p4\": 0.8314010951982104, \"phi\": 0.7107712682460922}, {\"truth_threshold\": 2.24, \"match_probability\": 0.8252960991775768, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8650, \"tn\": 7002, \"fp\": 16, \"fn\": 3131, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7342330871742636, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26576691282573633, \"precision\": 0.9981537041310871, \"recall\": 0.7342330871742636, \"specificity\": 0.9977201481903676, \"npv\": 0.691009572683312, \"accuracy\": 0.8325974785892867, \"f1\": 0.8460898909375458, \"f2\": 0.775228535579853, \"f0_5\": 0.93120895683066, \"p4\": 0.8310379294962751, \"phi\": 0.7102360805808096}, {\"truth_threshold\": 2.2600000000000002, \"match_probability\": 0.8272858873831817, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8649, \"tn\": 7002, \"fp\": 16, \"fn\": 3132, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.73414820473644, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26585179526355995, \"precision\": 0.9981534910559723, \"recall\": 0.73414820473644, \"specificity\": 0.9977201481903676, \"npv\": 0.6909413854351687, \"accuracy\": 0.8325442842704399, \"f1\": 0.8460334539763279, \"f2\": 0.7751528079011991, \"f0_5\": 0.931181499106393, \"p4\": 0.8309860494238047, \"phi\": 0.710159652661198}, {\"truth_threshold\": 2.2800000000000002, \"match_probability\": 0.8292577015092557, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8646, \"tn\": 7002, \"fp\": 16, \"fn\": 3135, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7338935574229691, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2661064425770308, \"precision\": 0.9981528515354422, \"recall\": 0.7338935574229691, \"specificity\": 0.9977201481903676, \"npv\": 0.6907369044095887, \"accuracy\": 0.8323847013138996, \"f1\": 0.845864109964291, \"f2\": 0.7749256085756283, \"f0_5\": 0.9310990975467919, \"p4\": 0.8308304102966865, \"phi\": 0.7099304100445418}, {\"truth_threshold\": 2.3000000000000003, \"match_probability\": 0.8312115970951024, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8640, \"tn\": 7002, \"fp\": 16, \"fn\": 3141, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7333842627960275, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.2666157372039725, \"precision\": 0.9981515711645101, \"recall\": 0.7333842627960275, \"specificity\": 0.9977201481903676, \"npv\": 0.6903283052351376, \"accuracy\": 0.8320655354008192, \"f1\": 0.8455252727895484, \"f2\": 0.7744711366081033, \"f0_5\": 0.9309341665768774, \"p4\": 0.8305191368552319, \"phi\": 0.7094721097486149}, {\"truth_threshold\": 2.32, \"match_probability\": 0.8331476320874132, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8630, \"tn\": 7002, \"fp\": 16, \"fn\": 3151, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7325354384177913, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26746456158220866, \"precision\": 0.9981494332639371, \"recall\": 0.7325354384177913, \"specificity\": 0.9977201481903676, \"npv\": 0.6896483797892249, \"accuracy\": 0.8315335922123517, \"f1\": 0.8449601018260146, \"f2\": 0.7737134660211583, \"f0_5\": 0.9306589021891513, \"p4\": 0.8300003615191143, \"phi\": 0.7087088227466521}, {\"truth_threshold\": 2.34, \"match_probability\": 0.835065866779332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8622, \"tn\": 7002, \"fp\": 16, \"fn\": 3159, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7318563789152025, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26814362108479756, \"precision\": 0.998147719379486, \"recall\": 0.7318563789152025, \"specificity\": 0.9977201481903676, \"npv\": 0.6891054030115146, \"accuracy\": 0.8311080376615777, \"f1\": 0.8445075664821979, \"f2\": 0.773107133890463, \"f0_5\": 0.9304383484773272, \"p4\": 0.8295853530098075, \"phi\": 0.7080986839957305}, {\"truth_threshold\": 2.36, \"match_probability\": 0.8369663637497393, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8615, \"tn\": 7002, \"fp\": 16, \"fn\": 3166, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7312622018504371, \"tn_rate\": 0.9977201481903676, \"fp_rate\": 0.002279851809632374, \"fn_rate\": 0.26873779814956283, \"precision\": 0.9981462171243193, \"recall\": 0.7312622018504371, \"specificity\": 0.9977201481903676, \"npv\": 0.6886309992132179, \"accuracy\": 0.8307356774296505, \"f1\": 0.8441113070742701, \"f2\": 0.7725764505425522, \"f0_5\": 0.9302451139185833, \"p4\": 0.8292222286823345, \"phi\": 0.7075651695216633}, {\"truth_threshold\": 2.38, \"match_probability\": 0.8388491878027863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8600, \"tn\": 7003, \"fp\": 15, \"fn\": 3181, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7299889652830829, \"tn_rate\": 0.9978626389284696, \"fp_rate\": 0.0021373610715303506, \"fn_rate\": 0.27001103471691706, \"precision\": 0.9982588508415554, \"recall\": 0.7299889652830829, \"specificity\": 0.9978626389284696, \"npv\": 0.6876472898664572, \"accuracy\": 0.8299909569657961, \"f1\": 0.8433026083545794, \"f2\": 0.7714526633057643, \"f0_5\": 0.9299106853225493, \"p4\": 0.8284997714416503, \"phi\": 0.7065676788906226}, {\"truth_threshold\": 2.4, \"match_probability\": 0.840714405907716, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8599, \"tn\": 7003, \"fp\": 15, \"fn\": 3182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7299040828452593, \"tn_rate\": 0.9978626389284696, \"fp_rate\": 0.0021373610715303506, \"fn_rate\": 0.2700959171547407, \"precision\": 0.9982586487114, \"recall\": 0.7299040828452593, \"specificity\": 0.9978626389284696, \"npv\": 0.6875797741777123, \"accuracy\": 0.8299377626469493, \"f1\": 0.8432458936013729, \"f2\": 0.7713767985934192, \"f0_5\": 0.9298829941388931, \"p4\": 0.8284478980641494, \"phi\": 0.7064915998739644}, {\"truth_threshold\": 2.42, \"match_probability\": 0.8425620871389979, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8593, \"tn\": 7003, \"fp\": 15, \"fn\": 3188, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7293947882183176, \"tn_rate\": 0.9978626389284696, \"fp_rate\": 0.0021373610715303506, \"fn_rate\": 0.2706052117816824, \"precision\": 0.9982574349442379, \"recall\": 0.7293947882183176, \"specificity\": 0.9978626389284696, \"npv\": 0.6871749582965362, \"accuracy\": 0.8296185967338688, \"f1\": 0.84290548825347, \"f2\": 0.7709215531472045, \"f0_5\": 0.9297167463700691, \"p4\": 0.8281366604869154, \"phi\": 0.7060352673849588}, {\"truth_threshold\": 2.44, \"match_probability\": 0.8443923026168105, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8588, \"tn\": 7003, \"fp\": 15, \"fn\": 3193, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7289703760291996, \"tn_rate\": 0.9978626389284696, \"fp_rate\": 0.0021373610715303506, \"fn_rate\": 0.27102962397080044, \"precision\": 0.9982564221783099, \"recall\": 0.7289703760291996, \"specificity\": 0.9978626389284696, \"npv\": 0.686837975676736, \"accuracy\": 0.829352625139635, \"f1\": 0.8426216640502355, \"f2\": 0.7705421070576202, \"f0_5\": 0.9295780746000476, \"p4\": 0.8278772992433721, \"phi\": 0.7056551755096762}, {\"truth_threshold\": 2.46, \"match_probability\": 0.8462051254478966, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8581, \"tn\": 7003, \"fp\": 15, \"fn\": 3200, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7283761989644343, \"tn_rate\": 0.9978626389284696, \"fp_rate\": 0.0021373610715303506, \"fn_rate\": 0.2716238010355657, \"precision\": 0.9982550023266635, \"recall\": 0.7283761989644343, \"specificity\": 0.9978626389284696, \"npv\": 0.6863667548760168, \"accuracy\": 0.8289802649077078, \"f1\": 0.8422240761643028, \"f2\": 0.7700107681263461, \"f0_5\": 0.9293837322647027, \"p4\": 0.8275141984365033, \"phi\": 0.7051233291751681}, {\"truth_threshold\": 2.48, \"match_probability\": 0.8480006306668223, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8576, \"tn\": 7005, \"fp\": 13, \"fn\": 3205, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7279517867753161, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2720482132246838, \"precision\": 0.9984864361392479, \"recall\": 0.7279517867753161, \"specificity\": 0.9981476204046736, \"npv\": 0.6860920666013712, \"accuracy\": 0.8288206819511676, \"f1\": 0.8420225822287678, \"f2\": 0.7696587869976487, \"f0_5\": 0.929405899820101, \"p4\": 0.8273660656070305, \"phi\": 0.7050333644644973}, {\"truth_threshold\": 2.5, \"match_probability\": 0.8497788951776651, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8570, \"tn\": 7005, \"fp\": 13, \"fn\": 3211, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7274424921483745, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2725575078516255, \"precision\": 0.9984853780729349, \"recall\": 0.7274424921483745, \"specificity\": 0.9981476204046736, \"npv\": 0.6856891151135474, \"accuracy\": 0.8285015160380871, \"f1\": 0.8416813985464545, \"f2\": 0.7692031522070835, \"f0_5\": 0.9292390432199162, \"p4\": 0.8270548299059188, \"phi\": 0.7045780634657202}, {\"truth_threshold\": 2.52, \"match_probability\": 0.851539997696156, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8566, \"tn\": 7005, \"fp\": 13, \"fn\": 3215, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.72710296239708, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27289703760291995, \"precision\": 0.9984846718731787, \"recall\": 0.72710296239708, \"specificity\": 0.9981476204046736, \"npv\": 0.6854207436399217, \"accuracy\": 0.8282887387627001, \"f1\": 0.8414538310412574, \"f2\": 0.7688993411485916, \"f0_5\": 0.9291277089615376, \"p4\": 0.8268473414181746, \"phi\": 0.7042746631692436}, {\"truth_threshold\": 2.54, \"match_probability\": 0.8532840186923007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8555, \"tn\": 7005, \"fp\": 13, \"fn\": 3226, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7261692555810203, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2738307444189797, \"precision\": 0.9984827264239029, \"recall\": 0.7261692555810203, \"specificity\": 0.9981476204046736, \"npv\": 0.684683804124719, \"accuracy\": 0.8277036012553859, \"f1\": 0.840827559093813, \"f2\": 0.7680636357106946, \"f0_5\": 0.9288211408594446, \"p4\": 0.8262767556327094, \"phi\": 0.7034408626067744}, {\"truth_threshold\": 2.56, \"match_probability\": 0.8550110403335041, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8550, \"tn\": 7005, \"fp\": 13, \"fn\": 3231, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7257448433919023, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2742551566080978, \"precision\": 0.9984818404764685, \"recall\": 0.7257448433919023, \"specificity\": 0.9981476204046736, \"npv\": 0.6843493552168816, \"accuracy\": 0.8274376296611522, \"f1\": 0.8405426661423515, \"f2\": 0.7676836604593532, \"f0_5\": 0.9286815979840549, \"p4\": 0.8260174018387387, \"phi\": 0.7030621285545261}, {\"truth_threshold\": 2.58, \"match_probability\": 0.8567211464282175, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8544, \"tn\": 7005, \"fp\": 13, \"fn\": 3237, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7252355487649605, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27476445123503945, \"precision\": 0.9984807759728876, \"recall\": 0.7252355487649605, \"specificity\": 0.9981476204046736, \"npv\": 0.6839484475688342, \"accuracy\": 0.8271184637480717, \"f1\": 0.8402006096961353, \"f2\": 0.7672276000790216, \"f0_5\": 0.9285139863939664, \"p4\": 0.8257061798190525, \"phi\": 0.7026078667788909}, {\"truth_threshold\": 2.6, \"match_probability\": 0.8584144223701331, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8537, \"tn\": 7005, \"fp\": 13, \"fn\": 3244, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7246413717001953, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2753586282998048, \"precision\": 0.9984795321637427, \"recall\": 0.7246413717001953, \"specificity\": 0.9981476204046736, \"npv\": 0.6834813152502683, \"accuracy\": 0.8267461035161445, \"f1\": 0.8398012886724706, \"f2\": 0.7666954053956964, \"f0_5\": 0.9283182183945543, \"p4\": 0.8253430906655864, \"phi\": 0.7020781961842679}, {\"truth_threshold\": 2.62, \"match_probability\": 0.8600909550829424, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8528, \"tn\": 7005, \"fp\": 13, \"fn\": 3253, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7238774297597828, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2761225702402173, \"precision\": 0.9984779299847792, \"recall\": 0.7238774297597828, \"specificity\": 0.9981476204046736, \"npv\": 0.6828816533437317, \"accuracy\": 0.8262673546465238, \"f1\": 0.8392874717055407, \"f2\": 0.7660109584119285, \"f0_5\": 0.928066166068125, \"p4\": 0.8248762662610145, \"phi\": 0.7013976670425994}, {\"truth_threshold\": 2.64, \"match_probability\": 0.8617508329656802, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8518, \"tn\": 7005, \"fp\": 13, \"fn\": 3263, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7230286053815466, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27697139461845344, \"precision\": 0.998476145821123, \"recall\": 0.7230286053815466, \"specificity\": 0.9981476204046736, \"npv\": 0.6822165952473704, \"accuracy\": 0.8257354114580563, \"f1\": 0.8387160299330445, \"f2\": 0.7652502021381726, \"f0_5\": 0.9277856442653306, \"p4\": 0.8243575775483292, \"phi\": 0.7006421496911622}, {\"truth_threshold\": 2.66, \"match_probability\": 0.8633941458386707, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8514, \"tn\": 7005, \"fp\": 13, \"fn\": 3267, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7226890756302521, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2773109243697479, \"precision\": 0.9984754309839334, \"recall\": 0.7226890756302521, \"specificity\": 0.9981476204046736, \"npv\": 0.6819509345794392, \"accuracy\": 0.8255226341826692, \"f1\": 0.8384872956470356, \"f2\": 0.7649458230759555, \"f0_5\": 0.9276732986118678, \"p4\": 0.8241501033286972, \"phi\": 0.7003401268296385}, {\"truth_threshold\": 2.68, \"match_probability\": 0.8650209848900923, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8510, \"tn\": 7005, \"fp\": 13, \"fn\": 3271, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7223495458789576, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27765045412104233, \"precision\": 0.9984747154757715, \"recall\": 0.7223495458789576, \"specificity\": 0.9981476204046736, \"npv\": 0.6816854807318022, \"accuracy\": 0.8253098569072823, \"f1\": 0.8382584712371947, \"f2\": 0.76464140025518, \"f0_5\": 0.9275608745885379, \"p4\": 0.8239426297296496, \"phi\": 0.700038208947537}, {\"truth_threshold\": 2.7, \"match_probability\": 0.8666314426231786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8505, \"tn\": 7005, \"fp\": 13, \"fn\": 3276, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7219251336898396, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27807486631016043, \"precision\": 0.9984738201455741, \"recall\": 0.7219251336898396, \"specificity\": 0.9981476204046736, \"npv\": 0.6813539538955354, \"accuracy\": 0.8250438853130486, \"f1\": 0.837972313907089, \"f2\": 0.7642608101793609, \"f0_5\": 0.9274202342267681, \"p4\": 0.8236832884992799, \"phi\": 0.6996609590106655}, {\"truth_threshold\": 2.72, \"match_probability\": 0.8682256128040682, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8501, \"tn\": 7005, \"fp\": 13, \"fn\": 3280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7215856039385451, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2784143960614549, \"precision\": 0.998473103124266, \"recall\": 0.7215856039385451, \"specificity\": 0.9981476204046736, \"npv\": 0.6810889645114244, \"accuracy\": 0.8248311080376616, \"f1\": 0.8377432865237743, \"f2\": 0.7639562888673209, \"f0_5\": 0.9273076335711324, \"p4\": 0.8234758160462532, \"phi\": 0.699359276824709}, {\"truth_threshold\": 2.74, \"match_probability\": 0.8698035904103196, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8490, \"tn\": 7005, \"fp\": 13, \"fn\": 3291, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7206518971224853, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.27934810287751466, \"precision\": 0.9984711278372339, \"recall\": 0.7206518971224853, \"specificity\": 0.9981476204046736, \"npv\": 0.6803613053613053, \"accuracy\": 0.8242459705303473, \"f1\": 0.8371129954644054, \"f2\": 0.7631186294425369, \"f0_5\": 0.9269975760487411, \"p4\": 0.8229052686459857, \"phi\": 0.6985301893725836}, {\"truth_threshold\": 2.7600000000000002, \"match_probability\": 0.8713654715801021, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8486, \"tn\": 7005, \"fp\": 13, \"fn\": 3295, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7203123673711909, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.2796876326288091, \"precision\": 0.9984704082833274, \"recall\": 0.7203123673711909, \"specificity\": 0.9981476204046736, \"npv\": 0.6800970873786408, \"accuracy\": 0.8240331932549604, \"f1\": 0.8368836291913215, \"f2\": 0.7628139438721392, \"f0_5\": 0.926884680079516, \"p4\": 0.8226977973312947, \"phi\": 0.6982288984555113}, {\"truth_threshold\": 2.7800000000000002, \"match_probability\": 0.8729113535620762, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8474, \"tn\": 7005, \"fp\": 13, \"fn\": 3307, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7192937781173075, \"tn_rate\": 0.9981476204046736, \"fp_rate\": 0.0018523795953263038, \"fn_rate\": 0.28070622188269245, \"precision\": 0.9984682455520207, \"recall\": 0.7192937781173075, \"specificity\": 0.9981476204046736, \"npv\": 0.6793056633048875, \"accuracy\": 0.8233948614287994, \"f1\": 0.8361949871718966, \"f2\": 0.7618996241750733, \"f0_5\": 0.9265455181613418, \"p4\": 0.8220753839536206, \"phi\": 0.6973256492142033}, {\"truth_threshold\": 2.8000000000000003, \"match_probability\": 0.8744413346659732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8466, \"tn\": 7006, \"fp\": 12, \"fn\": 3315, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7186147186147186, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.2813852813852814, \"precision\": 0.9985845718329794, \"recall\": 0.7186147186147186, \"specificity\": 0.9982901111427758, \"npv\": 0.6788101928107741, \"accuracy\": 0.8230225011968721, \"f1\": 0.8357766918406634, \"f2\": 0.761303550232006, \"f0_5\": 0.9264001050489133, \"p4\": 0.8217159179775819, \"phi\": 0.6968698432458877}, {\"truth_threshold\": 2.82, \"match_probability\": 0.8759555142138866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8460, \"tn\": 7006, \"fp\": 12, \"fn\": 3321, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7181054239877769, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.28189457601222306, \"precision\": 0.9985835694050992, \"recall\": 0.7181054239877769, \"specificity\": 0.9982901111427758, \"npv\": 0.6784158032342403, \"accuracy\": 0.8227033352837917, \"f1\": 0.8354317878832765, \"f2\": 0.7608461040362616, \"f0_5\": 0.9262300466399527, \"p4\": 0.8214047033540218, \"phi\": 0.6964189312798784}, {\"truth_threshold\": 2.84, \"match_probability\": 0.8774539924922818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8446, \"tn\": 7006, \"fp\": 12, \"fn\": 3335, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7169170698582463, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.2830829301417537, \"precision\": 0.9985812248758572, \"recall\": 0.7169170698582463, \"specificity\": 0.9982901111427758, \"npv\": 0.6774973406827193, \"accuracy\": 0.8219586148199373, \"f1\": 0.8346262167103118, \"f2\": 0.7597783455075384, \"f0_5\": 0.9258325477385833, \"p4\": 0.8206785327319771, \"phi\": 0.6953677048931479}, {\"truth_threshold\": 2.86, \"match_probability\": 0.8789368707047344, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8439, \"tn\": 7006, \"fp\": 12, \"fn\": 3342, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.716322892793481, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.28367710720651895, \"precision\": 0.9985800496982605, \"recall\": 0.716322892793481, \"specificity\": 0.9982901111427758, \"npv\": 0.6770390413606494, \"accuracy\": 0.82158625458801, \"f1\": 0.8342230130486358, \"f2\": 0.7592442645074224, \"f0_5\": 0.9256334320500165, \"p4\": 0.820315445041678, \"phi\": 0.694842563591416}, {\"truth_threshold\": 2.88, \"match_probability\": 0.880404250925403, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8435, \"tn\": 7006, \"fp\": 12, \"fn\": 3346, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7159833630421866, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.28401663695781343, \"precision\": 0.9985793772937137, \"recall\": 0.7159833630421866, \"specificity\": 0.9982901111427758, \"npv\": 0.6767774343122102, \"accuracy\": 0.821373477312623, \"f1\": 0.8339924856634369, \"f2\": 0.7589390149538429, \"f0_5\": 0.9255195417937633, \"p4\": 0.8201079654504064, \"phi\": 0.6945426237029967}, {\"truth_threshold\": 2.9, \"match_probability\": 0.8818562360532484, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8432, \"tn\": 7006, \"fp\": 12, \"fn\": 3349, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7157287157287158, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.2842712842712843, \"precision\": 0.9985788725722407, \"recall\": 0.7157287157287158, \"specificity\": 0.9982901111427758, \"npv\": 0.6765813616610333, \"accuracy\": 0.8212138943560827, \"f1\": 0.8338195302843016, \"f2\": 0.7587100489490354, \"f0_5\": 0.9254340716026077, \"p4\": 0.8199523552688562, \"phi\": 0.6943177359088011}, {\"truth_threshold\": 2.92, \"match_probability\": 0.8832929297669961, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8431, \"tn\": 7006, \"fp\": 12, \"fn\": 3350, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7156438332908921, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.2843561667091079, \"precision\": 0.9985787042520431, \"recall\": 0.7156438332908921, \"specificity\": 0.9982901111427758, \"npv\": 0.6765160293549634, \"accuracy\": 0.8211607000372361, \"f1\": 0.8337618670886076, \"f2\": 0.7586337214533806, \"f0_5\": 0.9254055715320616, \"p4\": 0.8199004851095677, \"phi\": 0.6942427860845557}, {\"truth_threshold\": 2.94, \"match_probability\": 0.8847144364808572, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8427, \"tn\": 7006, \"fp\": 12, \"fn\": 3354, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7153043035395976, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.2846956964604023, \"precision\": 0.9985780305723427, \"recall\": 0.7153043035395976, \"specificity\": 0.9982901111427758, \"npv\": 0.6762548262548262, \"accuracy\": 0.820947922761849, \"f1\": 0.8335311572700297, \"f2\": 0.7583283839965445, \"f0_5\": 0.9252915211805784, \"p4\": 0.8196930039495293, \"phi\": 0.693943050599988}, {\"truth_threshold\": 2.96, \"match_probability\": 0.8861208613010066, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8412, \"tn\": 7006, \"fp\": 12, \"fn\": 3369, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7140310669722434, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.28596893302775656, \"precision\": 0.9985754985754985, \"recall\": 0.7140310669722434, \"specificity\": 0.9982901111427758, \"npv\": 0.6752771084337349, \"accuracy\": 0.8201500079791478, \"f1\": 0.8326651818856718, \"f2\": 0.7571829768848564, \"f0_5\": 0.9248631176198958, \"p4\": 0.8189149411129435, \"phi\": 0.6928199498431712}, {\"truth_threshold\": 2.98, \"match_probability\": 0.8875123099828214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8405, \"tn\": 7006, \"fp\": 12, \"fn\": 3376, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7134368899074781, \"tn_rate\": 0.9982901111427758, \"fp_rate\": 0.0017098888572242804, \"fn_rate\": 0.28656311009252183, \"precision\": 0.9985743138885589, \"recall\": 0.7134368899074781, \"specificity\": 0.9982901111427758, \"npv\": 0.6748218069736082, \"accuracy\": 0.8197776477472206, \"f1\": 0.8322606198633528, \"f2\": 0.756648241839362, \"f0_5\": 0.9246628088626813, \"p4\": 0.8185518398084966, \"phi\": 0.692296325008377}, {\"truth_threshold\": 3.0, \"match_probability\": 0.8888888888888888, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8402, \"tn\": 7007, \"fp\": 11, \"fn\": 3379, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7131822425940073, \"tn_rate\": 0.9984326018808778, \"fp_rate\": 0.001567398119122257, \"fn_rate\": 0.2868177574059927, \"precision\": 0.9986924997028408, \"recall\": 0.7131822425940073, \"specificity\": 0.9984326018808778, \"npv\": 0.6746581937223185, \"accuracy\": 0.8196712591095271, \"f1\": 0.832128354956918, \"f2\": 0.7564326485046006, \"f0_5\": 0.9246582880285256, \"p4\": 0.8184516192990564, \"phi\": 0.6922184257723865}, {\"truth_threshold\": 3.02, \"match_probability\": 0.890250704947779, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8394, \"tn\": 7007, \"fp\": 11, \"fn\": 3387, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7125031830914184, \"tn_rate\": 0.9984326018808778, \"fp_rate\": 0.001567398119122257, \"fn_rate\": 0.2874968169085816, \"precision\": 0.9986912552052349, \"recall\": 0.7125031830914184, \"specificity\": 0.9984326018808778, \"npv\": 0.6741389263036367, \"accuracy\": 0.8192457045587531, \"f1\": 0.8316655107500248, \"f2\": 0.7558212825730699, \"f0_5\": 0.9244289773353009, \"p4\": 0.8180366296020617, \"phi\": 0.691620599204551}, {\"truth_threshold\": 3.04, \"match_probability\": 0.8915978656135887, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8389, \"tn\": 7007, \"fp\": 11, \"fn\": 3392, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7120787709023003, \"tn_rate\": 0.9984326018808778, \"fp_rate\": 0.001567398119122257, \"fn_rate\": 0.2879212290976997, \"precision\": 0.9986904761904762, \"recall\": 0.7120787709023003, \"specificity\": 0.9984326018808778, \"npv\": 0.6738147898836426, \"accuracy\": 0.8189797329645194, \"f1\": 0.8313760467766711, \"f2\": 0.7554390894027808, \"f0_5\": 0.9242854939291774, \"p4\": 0.8177772580835219, \"phi\": 0.6912471625997741}, {\"truth_threshold\": 3.06, \"match_probability\": 0.8929304788262556, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8383, \"tn\": 7007, \"fp\": 11, \"fn\": 3398, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7115694762753586, \"tn_rate\": 0.9984326018808778, \"fp_rate\": 0.001567398119122257, \"fn_rate\": 0.2884305237246414, \"precision\": 0.9986895401477246, \"recall\": 0.7115694762753586, \"specificity\": 0.9984326018808778, \"npv\": 0.6734262373858722, \"accuracy\": 0.8186605670514389, \"f1\": 0.8310285006195787, \"f2\": 0.754980366727908, \"f0_5\": 0.9241131468130608, \"p4\": 0.8174660090283445, \"phi\": 0.6907992463881589}, {\"truth_threshold\": 3.08, \"match_probability\": 0.8942486529726457, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8375, \"tn\": 7007, \"fp\": 11, \"fn\": 3406, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7108904167727698, \"tn_rate\": 0.9984326018808778, \"fp_rate\": 0.001567398119122257, \"fn_rate\": 0.2891095832272303, \"precision\": 0.9986882900071548, \"recall\": 0.7108904167727698, \"specificity\": 0.9984326018808778, \"npv\": 0.6729088639200999, \"accuracy\": 0.8182350125006649, \"f1\": 0.8305647840531561, \"f2\": 0.7543685822374347, \"f0_5\": 0.9238830667402096, \"p4\": 0.8170510044118655, \"phi\": 0.6902023765120477}, {\"truth_threshold\": 3.1, \"match_probability\": 0.895552496848409, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8366, \"tn\": 7008, \"fp\": 10, \"fn\": 3415, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7101264748323571, \"tn_rate\": 0.9985750926189798, \"fp_rate\": 0.0014249073810202336, \"fn_rate\": 0.2898735251676428, \"precision\": 0.9988061127029608, \"recall\": 0.7101264748323571, \"specificity\": 0.9985750926189798, \"npv\": 0.6723592056029933, \"accuracy\": 0.8178094579498909, \"f1\": 0.8300838418415439, \"f2\": 0.7536936936936937, \"f0_5\": 0.923705421221155, \"p4\": 0.8166394635414966, \"phi\": 0.6896781228242674}, {\"truth_threshold\": 3.12, \"match_probability\": 0.8968421196206098, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8362, \"tn\": 7008, \"fp\": 10, \"fn\": 3419, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7097869450810628, \"tn_rate\": 0.9985750926189798, \"fp_rate\": 0.0014249073810202336, \"fn_rate\": 0.2902130549189373, \"precision\": 0.9988055422838031, \"recall\": 0.7097869450810628, \"specificity\": 0.9985750926189798, \"npv\": 0.6721012755346696, \"accuracy\": 0.817596680674504, \"f1\": 0.8298516349923089, \"f2\": 0.753387631541012, \"f0_5\": 0.9235900947668383, \"p4\": 0.8164319492048886, \"phi\": 0.6893800987675409}, {\"truth_threshold\": 3.14, \"match_probability\": 0.8981176307911237, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8358, \"tn\": 7008, \"fp\": 10, \"fn\": 3423, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7094474153297683, \"tn_rate\": 0.9985750926189798, \"fp_rate\": 0.0014249073810202336, \"fn_rate\": 0.2905525846702317, \"precision\": 0.9988049713193117, \"recall\": 0.7094474153297683, \"specificity\": 0.9985750926189798, \"npv\": 0.6718435432844406, \"accuracy\": 0.8173839033991169, \"f1\": 0.8296193359471934, \"f2\": 0.753081525264903, \"f0_5\": 0.9234746867610987, \"p4\": 0.8162244328230006, \"phi\": 0.6890821745349761}, {\"truth_threshold\": 3.16, \"match_probability\": 0.8993791401608047, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8354, \"tn\": 7009, \"fp\": 9, \"fn\": 3427, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7091078855784738, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2908921144215262, \"precision\": 0.9989238311610666, \"recall\": 0.7091078855784738, \"specificity\": 0.9987175833570818, \"npv\": 0.6716174779609045, \"accuracy\": 0.8172243204425768, \"f1\": 0.829428117553614, \"f2\": 0.7527889415538774, \"f0_5\": 0.9234408507063427, \"p4\": 0.8160722446241571, \"phi\": 0.6889312132353422}, {\"truth_threshold\": 3.18, \"match_probability\": 0.9006267577944164, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8342, \"tn\": 7009, \"fp\": 9, \"fn\": 3439, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7080892963245904, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29191070367540956, \"precision\": 0.9989222847563166, \"recall\": 0.7080892963245904, \"specificity\": 0.9987175833570818, \"npv\": 0.6708460949464012, \"accuracy\": 0.8165859886164157, \"f1\": 0.8287303794953308, \"f2\": 0.7518702118071203, \"f0_5\": 0.9230939471063406, \"p4\": 0.8154496605656439, \"phi\": 0.6880384426521002}, {\"truth_threshold\": 3.2, \"match_probability\": 0.9018605939863281, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8339, \"tn\": 7009, \"fp\": 9, \"fn\": 3442, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7078346490111196, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2921653509888804, \"precision\": 0.9989218974604696, \"recall\": 0.7078346490111196, \"specificity\": 0.9987175833570818, \"npv\": 0.6706535259783752, \"accuracy\": 0.8164264056598756, \"f1\": 0.8285558149932932, \"f2\": 0.7516404672627632, \"f0_5\": 0.9230071060146547, \"p4\": 0.8152940112405244, \"phi\": 0.6878153895992729}, {\"truth_threshold\": 3.22, \"match_probability\": 0.9030807592269698, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8333, \"tn\": 7009, \"fp\": 9, \"fn\": 3448, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7073253543841779, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29267464561582207, \"precision\": 0.9989211220330856, \"recall\": 0.7073253543841779, \"specificity\": 0.9987175833570818, \"npv\": 0.6702687195180262, \"accuracy\": 0.816107239746795, \"f1\": 0.8282065298414749, \"f2\": 0.75118090361663, \"f0_5\": 0.9228332853440829, \"p4\": 0.8149827084077577, \"phi\": 0.6873694506125182}, {\"truth_threshold\": 3.24, \"match_probability\": 0.9042873641700437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8321, \"tn\": 7009, \"fp\": 9, \"fn\": 3460, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7063067651302946, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29369323486970544, \"precision\": 0.9989195678271309, \"recall\": 0.7063067651302946, \"specificity\": 0.9987175833570818, \"npv\": 0.6695004298404814, \"accuracy\": 0.8154689079206341, \"f1\": 0.8275073342946646, \"f2\": 0.7502614779817507, \"f0_5\": 0.9224850890224163, \"p4\": 0.8143600851707604, \"phi\": 0.6864782395469954}, {\"truth_threshold\": 3.2600000000000002, \"match_probability\": 0.9054805196004887, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8312, \"tn\": 7009, \"fp\": 9, \"fn\": 3469, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.705542823189882, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29445717681011796, \"precision\": 0.9989183992308617, \"recall\": 0.705542823189882, \"specificity\": 0.9987175833570818, \"npv\": 0.6689253674365336, \"accuracy\": 0.8149901590510134, \"f1\": 0.826982389811959, \"f2\": 0.7495716475786816, \"f0_5\": 0.9222234550094308, \"p4\": 0.8138931014198122, \"phi\": 0.6858104130319366}, {\"truth_threshold\": 3.2800000000000002, \"match_probability\": 0.9066603364031919, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8308, \"tn\": 7009, \"fp\": 9, \"fn\": 3473, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7052032934385876, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29479670656141244, \"precision\": 0.9989178790429242, \"recall\": 0.7052032934385876, \"specificity\": 0.9987175833570818, \"npv\": 0.6686701011257393, \"accuracy\": 0.8147773817756263, \"f1\": 0.8267489302418151, \"f2\": 0.7492649843978283, \"f0_5\": 0.9221070390019757, \"p4\": 0.8136855483530349, \"phi\": 0.6855137608674063}, {\"truth_threshold\": 3.3000000000000003, \"match_probability\": 0.9078269255324448, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8301, \"tn\": 7009, \"fp\": 9, \"fn\": 3480, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7046091163738223, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29539088362617777, \"precision\": 0.9989169675090253, \"recall\": 0.7046091163738223, \"specificity\": 0.9987175833570818, \"npv\": 0.6682238535608733, \"accuracy\": 0.8144050215436991, \"f1\": 0.8263401523070031, \"f2\": 0.7487282173395389, \"f0_5\": 0.9219031118811222, \"p4\": 0.8133223231904688, \"phi\": 0.6849948554105041}, {\"truth_threshold\": 3.3200000000000003, \"match_probability\": 0.9089803979821356, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8296, \"tn\": 7009, \"fp\": 9, \"fn\": 3485, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7041847041847041, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2958152958152958, \"precision\": 0.9989163154726068, \"recall\": 0.7041847041847041, \"specificity\": 0.9987175833570818, \"npv\": 0.6679054697922623, \"accuracy\": 0.8141390499494654, \"f1\": 0.8260479936274022, \"f2\": 0.7483447292933302, \"f0_5\": 0.9217572942823493, \"p4\": 0.8130628707815233, \"phi\": 0.6846243920905638}, {\"truth_threshold\": 3.34, \"match_probability\": 0.9101208647566755, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8288, \"tn\": 7009, \"fp\": 9, \"fn\": 3493, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7035056446821153, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2964943553178847, \"precision\": 0.9989152705797276, \"recall\": 0.7035056446821153, \"specificity\": 0.9987175833570818, \"npv\": 0.667396686345458, \"accuracy\": 0.8137134953986914, \"f1\": 0.825580237075406, \"f2\": 0.7477310044928818, \"f0_5\": 0.9215237163379216, \"p4\": 0.8126477363734936, \"phi\": 0.6840319680198567}, {\"truth_threshold\": 3.36, \"match_probability\": 0.911248436842651, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8284, \"tn\": 7009, \"fp\": 9, \"fn\": 3497, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7031661149308208, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2968338850691792, \"precision\": 0.9989147473773061, \"recall\": 0.7031661149308208, \"specificity\": 0.9987175833570818, \"npv\": 0.6671425851894156, \"accuracy\": 0.8135007181233044, \"f1\": 0.8253462189897379, \"f2\": 0.7474240756446577, \"f0_5\": 0.9214068026605566, \"p4\": 0.8124401641457072, \"phi\": 0.6837359021242824}, {\"truth_threshold\": 3.38, \"match_probability\": 0.9123632251811958, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8281, \"tn\": 7009, \"fp\": 9, \"fn\": 3500, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.70291146761735, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29708853238265004, \"precision\": 0.9989143546441496, \"recall\": 0.70291146761735, \"specificity\": 0.9987175833570818, \"npv\": 0.6669521362641545, \"accuracy\": 0.8133411351667642, \"f1\": 0.8251706442130436, \"f2\": 0.7471938499296207, \"f0_5\": 0.9213190627711889, \"p4\": 0.8122844827179028, \"phi\": 0.6835139165310891}, {\"truth_threshold\": 3.4, \"match_probability\": 0.9134653406410783, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8276, \"tn\": 7009, \"fp\": 9, \"fn\": 3505, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7024870554282319, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2975129445717681, \"precision\": 0.9989136994568497, \"recall\": 0.7024870554282319, \"specificity\": 0.9987175833570818, \"npv\": 0.6666349629066007, \"accuracy\": 0.8130751635725304, \"f1\": 0.8248779029203628, \"f2\": 0.7468100850042412, \"f0_5\": 0.9211727254513479, \"p4\": 0.8120250092824732, \"phi\": 0.6831440619566358}, {\"truth_threshold\": 3.42, \"match_probability\": 0.9145548939924946, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8267, \"tn\": 7009, \"fp\": 9, \"fn\": 3514, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7017231134878193, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.29827688651218065, \"precision\": 0.998912518124698, \"recall\": 0.7017231134878193, \"specificity\": 0.9987175833570818, \"npv\": 0.6660648104152808, \"accuracy\": 0.8125964147029098, \"f1\": 0.8243506007877549, \"f2\": 0.7461191335740072, \"f0_5\": 0.9209089896401916, \"p4\": 0.8115579428704606, \"phi\": 0.682478705446993}, {\"truth_threshold\": 3.44, \"match_probability\": 0.9156319958815625, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8257, \"tn\": 7009, \"fp\": 9, \"fn\": 3524, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7008742891095833, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2991257108904168, \"precision\": 0.9989112025163319, \"recall\": 0.7008742891095833, \"specificity\": 0.9987175833570818, \"npv\": 0.6654324503939998, \"accuracy\": 0.8120644715144423, \"f1\": 0.8237641542375418, \"f2\": 0.7453511464163206, \"f0_5\": 0.9206154532277846, \"p4\": 0.8110389578767019, \"phi\": 0.681739994500017}, {\"truth_threshold\": 3.46, \"match_probability\": 0.9166967568055082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8255, \"tn\": 7009, \"fp\": 9, \"fn\": 3526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.700704524233936, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.299295475766064, \"precision\": 0.9989109390125847, \"recall\": 0.700704524233936, \"specificity\": 0.9987175833570818, \"npv\": 0.6653061224489796, \"accuracy\": 0.8119580828767488, \"f1\": 0.8236467947118983, \"f2\": 0.7451975157073735, \"f0_5\": 0.9205566830965497, \"p4\": 0.8109351579643429, \"phi\": 0.6815923246526181}, {\"truth_threshold\": 3.48, \"match_probability\": 0.9177492870885379, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8247, \"tn\": 7009, \"fp\": 9, \"fn\": 3534, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.7000254647313471, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.2999745352686529, \"precision\": 0.9989098837209303, \"recall\": 0.7000254647313471, \"specificity\": 0.9987175833570818, \"npv\": 0.6648012899554206, \"accuracy\": 0.8115325283259748, \"f1\": 0.8231771223237011, \"f2\": 0.7445828819068255, \"f0_5\": 0.9203213927017074, \"p4\": 0.8105199483006847, \"phi\": 0.6810018858600627}, {\"truth_threshold\": 3.5, \"match_probability\": 0.9187896968583877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8241, \"tn\": 7009, \"fp\": 9, \"fn\": 3540, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6995161701044054, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.3004838298955946, \"precision\": 0.9989090909090909, \"recall\": 0.6995161701044054, \"specificity\": 0.9987175833570818, \"npv\": 0.6644231680728031, \"accuracy\": 0.8112133624128943, \"f1\": 0.822824621836154, \"f2\": 0.7441217900097519, \"f0_5\": 0.9201447042272393, \"p4\": 0.8102085302837679, \"phi\": 0.680559308937153}, {\"truth_threshold\": 3.52, \"match_probability\": 0.9198180960235423, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8239, \"tn\": 7009, \"fp\": 9, \"fn\": 3542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6993464052287581, \"tn_rate\": 0.9987175833570818, \"fp_rate\": 0.0012824166429182104, \"fn_rate\": 0.3006535947712418, \"precision\": 0.9989088263821533, \"recall\": 0.6993464052287581, \"specificity\": 0.9987175833570818, \"npv\": 0.6642972230120368, \"accuracy\": 0.8111069737752008, \"f1\": 0.8227070747416246, \"f2\": 0.7439680705049484, \"f0_5\": 0.9200857659750296, \"p4\": 0.8101047221783794, \"phi\": 0.6804118312422014}, {\"truth_threshold\": 3.54, \"match_probability\": 0.9208345942511155, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8234, \"tn\": 7011, \"fp\": 7, \"fn\": 3547, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6989219930396401, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3010780069603599, \"precision\": 0.9991505885208106, \"recall\": 0.6989219930396401, \"specificity\": 0.9990025648332859, \"npv\": 0.6640462208751657, \"accuracy\": 0.8109473908186605, \"f1\": 0.8224952552192588, \"f2\": 0.7436105843041633, \"f0_5\": 0.9201028047826573, \"p4\": 0.8099555409290095, \"phi\": 0.6803391360052881}, {\"truth_threshold\": 3.56, \"match_probability\": 0.9218393009453847, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8232, \"tn\": 7011, \"fp\": 7, \"fn\": 3549, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6987522281639929, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30124777183600715, \"precision\": 0.9991503823279524, \"recall\": 0.6987522281639929, \"specificity\": 0.9990025648332859, \"npv\": 0.6639204545454546, \"accuracy\": 0.8108410021809671, \"f1\": 0.8223776223776224, \"f2\": 0.743456821342774, \"f0_5\": 0.9200438116100766, \"p4\": 0.8098517237894047, \"phi\": 0.6801917777547274}, {\"truth_threshold\": 3.58, \"match_probability\": 0.9228323252269688, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8229, \"tn\": 7011, \"fp\": 7, \"fn\": 3552, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.698497580850522, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30150241914947795, \"precision\": 0.9991500728508985, \"recall\": 0.698497580850522, \"specificity\": 0.9990025648332859, \"npv\": 0.6637318943481966, \"accuracy\": 0.8106814192244268, \"f1\": 0.8222011290403157, \"f2\": 0.7432261560693642, \"f0_5\": 0.9199552822806036, \"p4\": 0.809695996013322, \"phi\": 0.6799707851757588}, {\"truth_threshold\": 3.6, \"match_probability\": 0.9238137759126431, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8227, \"tn\": 7011, \"fp\": 7, \"fn\": 3554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6983278159748748, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3016721840251252, \"precision\": 0.9991498664075783, \"recall\": 0.6983278159748748, \"specificity\": 0.9990025648332859, \"npv\": 0.6636062470421202, \"accuracy\": 0.8105750305867333, \"f1\": 0.8220834374219336, \"f2\": 0.7430723653311174, \"f0_5\": 0.9198962363307019, \"p4\": 0.8095921761048456, \"phi\": 0.6798234866307685}, {\"truth_threshold\": 3.62, \"match_probability\": 0.9247837614957818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8220, \"tn\": 7011, \"fp\": 7, \"fn\": 3561, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6977336389101095, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3022663610898905, \"precision\": 0.9991491430655159, \"recall\": 0.6977336389101095, \"specificity\": 0.9990025648332859, \"npv\": 0.66316685584563, \"accuracy\": 0.8102026703548061, \"f1\": 0.821671331467413, \"f2\": 0.7425340102256508, \"f0_5\": 0.9196894090268298, \"p4\": 0.8092287975175181, \"phi\": 0.6793081294669354}, {\"truth_threshold\": 3.64, \"match_probability\": 0.9257423901274181, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8216, \"tn\": 7011, \"fp\": 7, \"fn\": 3565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6973941091588151, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30260589084118494, \"precision\": 0.9991487291742673, \"recall\": 0.6973941091588151, \"specificity\": 0.9990025648332859, \"npv\": 0.6629160363086233, \"accuracy\": 0.8099898930794192, \"f1\": 0.8214357128574286, \"f2\": 0.7422263175962563, \"f0_5\": 0.9195711055895059, \"p4\": 0.8090211462803409, \"phi\": 0.6790137705891135}, {\"truth_threshold\": 3.66, \"match_probability\": 0.9266897695979149, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8212, \"tn\": 7011, \"fp\": 7, \"fn\": 3569, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6970545794075206, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3029454205924794, \"precision\": 0.9991483148801558, \"recall\": 0.6970545794075206, \"specificity\": 0.9990025648332859, \"npv\": 0.6626654064272212, \"accuracy\": 0.8097771158040321, \"f1\": 0.8212, \"f2\": 0.7419185804889508, \"f0_5\": 0.9194527173791343, \"p4\": 0.808813490347944, \"phi\": 0.6787195067718281}, {\"truth_threshold\": 3.68, \"match_probability\": 0.9276260073192355, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8206, \"tn\": 7011, \"fp\": 7, \"fn\": 3575, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6965452847805789, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3034547152194211, \"precision\": 0.9991476926823328, \"recall\": 0.6965452847805789, \"specificity\": 0.9990025648332859, \"npv\": 0.6622898167390894, \"accuracy\": 0.8094579498909517, \"f1\": 0.8208462538761628, \"f2\": 0.7414568914108102, \"f0_5\": 0.919274975914682, \"p4\": 0.8085019974855074, \"phi\": 0.6782782890023981}, {\"truth_threshold\": 3.7, \"match_probability\": 0.9285512103078053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8203, \"tn\": 7011, \"fp\": 7, \"fn\": 3578, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6962906374671081, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30370936253289194, \"precision\": 0.9991473812423873, \"recall\": 0.6962906374671081, \"specificity\": 0.9990025648332859, \"npv\": 0.6621021815091133, \"accuracy\": 0.8092983669344114, \"f1\": 0.8206693011855335, \"f2\": 0.7412260093251889, \"f0_5\": 0.9191860334819928, \"p4\": 0.8083462469535077, \"phi\": 0.6780577600803829}, {\"truth_threshold\": 3.72, \"match_probability\": 0.9294654851679567, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8199, \"tn\": 7011, \"fp\": 7, \"fn\": 3582, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6959511077158136, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3040488922841864, \"precision\": 0.9991469656349012, \"recall\": 0.6959511077158136, \"specificity\": 0.9990025648332859, \"npv\": 0.6618521665250637, \"accuracy\": 0.8090855896590244, \"f1\": 0.8204332816330615, \"f2\": 0.7409181275980481, \"f0_5\": 0.9190673691290214, \"p4\": 0.8081385752552376, \"phi\": 0.6777638043200118}, {\"truth_threshold\": 3.74, \"match_probability\": 0.9303689380759456, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8194, \"tn\": 7011, \"fp\": 7, \"fn\": 3587, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6955266955266955, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30447330447330445, \"precision\": 0.9991464455554201, \"recall\": 0.6955266955266955, \"specificity\": 0.9990025648332859, \"npv\": 0.6615399131911681, \"accuracy\": 0.8088196180647906, \"f1\": 0.8201381243118807, \"f2\": 0.740533212833258, \"f0_5\": 0.918918918918919, \"p4\": 0.807878978582517, \"phi\": 0.6773964925139465}, {\"truth_threshold\": 3.7600000000000002, \"match_probability\": 0.9312616747645321, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8188, \"tn\": 7011, \"fp\": 7, \"fn\": 3593, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6950174008997538, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.30498259910024617, \"precision\": 0.9991458206223307, \"recall\": 0.6950174008997538, \"specificity\": 0.9990025648332859, \"npv\": 0.6611655978875896, \"accuracy\": 0.8085004521517102, \"f1\": 0.8197837404885863, \"f2\": 0.740071223268678, \"f0_5\": 0.9187406027692376, \"p4\": 0.8075674520456926, \"phi\": 0.6769559129274149}, {\"truth_threshold\": 3.7800000000000002, \"match_probability\": 0.9321438005081154, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8174, \"tn\": 7011, \"fp\": 7, \"fn\": 3607, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6938290467702233, \"tn_rate\": 0.9990025648332859, \"fp_rate\": 0.0009974351667141636, \"fn_rate\": 0.3061709532297768, \"precision\": 0.9991443588803325, \"recall\": 0.6938290467702233, \"specificity\": 0.9990025648332859, \"npv\": 0.6602938406479563, \"accuracy\": 0.8077557316878557, \"f1\": 0.8189560164312193, \"f2\": 0.7389928577886267, \"f0_5\": 0.9183237838445119, \"p4\": 0.8068405107783406, \"phi\": 0.6759287170494391}, {\"truth_threshold\": 3.8000000000000003, \"match_probability\": 0.9330154201084124, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8167, \"tn\": 7012, \"fp\": 6, \"fn\": 3614, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6932348697054579, \"tn_rate\": 0.9991450555713879, \"fp_rate\": 0.0008549444286121402, \"fn_rate\": 0.30676513029454205, \"precision\": 0.9992658754435336, \"recall\": 0.6932348697054579, \"specificity\": 0.9991450555713879, \"npv\": 0.6598908338038773, \"accuracy\": 0.8074365657747753, \"f1\": 0.8185827403026962, \"f2\": 0.7384668246016963, \"f0_5\": 0.9181975580689407, \"p4\": 0.8065320940585332, \"phi\": 0.6755641147178068}, {\"truth_threshold\": 3.8200000000000003, \"match_probability\": 0.9338766378806729, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8156, \"tn\": 7013, \"fp\": 5, \"fn\": 3625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6923011628893981, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3076988371106018, \"precision\": 0.9993873299840705, \"recall\": 0.6923011628893981, \"specificity\": 0.9992875463094899, \"npv\": 0.6592404587328445, \"accuracy\": 0.8069046225863078, \"f1\": 0.817972119145522, \"f2\": 0.7376322691507642, \"f0_5\": 0.9179516038266742, \"p4\": 0.8060158986057917, \"phi\": 0.6749070619287142}, {\"truth_threshold\": 3.84, \"match_probability\": 0.9347275576404188, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8150, \"tn\": 7013, \"fp\": 5, \"fn\": 3631, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6917918682624565, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3082081317375435, \"precision\": 0.9993868792152054, \"recall\": 0.6917918682624565, \"specificity\": 0.9992875463094899, \"npv\": 0.658868846298384, \"accuracy\": 0.8065854566732273, \"f1\": 0.8176163723916533, \"f2\": 0.7371696304202319, \"f0_5\": 0.9177721222494989, \"p4\": 0.8057042773735117, \"phi\": 0.6744679246832744}, {\"truth_threshold\": 3.86, \"match_probability\": 0.9355682826907014, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8143, \"tn\": 7013, \"fp\": 5, \"fn\": 3638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6911976911976911, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3088023088023088, \"precision\": 0.999386352479136, \"recall\": 0.6911976911976911, \"specificity\": 0.9992875463094899, \"npv\": 0.6584358276218195, \"accuracy\": 0.8062130964413, \"f1\": 0.8172010637764062, \"f2\": 0.7366297582862933, \"f0_5\": 0.9175624816893155, \"p4\": 0.8053407023921781, \"phi\": 0.673955862252492}, {\"truth_threshold\": 3.88, \"match_probability\": 0.9363989158098637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8139, \"tn\": 7013, \"fp\": 5, \"fn\": 3642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6908581614463968, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3091418385536033, \"precision\": 0.9993860510805501, \"recall\": 0.6908581614463968, \"specificity\": 0.9992875463094899, \"npv\": 0.6581886438291882, \"accuracy\": 0.8060003191659131, \"f1\": 0.8169636135508156, \"f2\": 0.7363211985235579, \"f0_5\": 0.9174425682530378, \"p4\": 0.805132936954587, \"phi\": 0.6736633827222929}, {\"truth_threshold\": 3.9, \"match_probability\": 0.9372195592398013, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8134, \"tn\": 7013, \"fp\": 5, \"fn\": 3647, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6904337492572786, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3095662507427213, \"precision\": 0.9993856739157144, \"recall\": 0.6904337492572786, \"specificity\": 0.9992875463094899, \"npv\": 0.6578799249530957, \"accuracy\": 0.8057343475716794, \"f1\": 0.8166666666666667, \"f2\": 0.7359354360060076, \"f0_5\": 0.9172925547511108, \"p4\": 0.8048732215235902, \"phi\": 0.6732979135444158}, {\"truth_threshold\": 3.92, \"match_probability\": 0.9380303146747102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8127, \"tn\": 7013, \"fp\": 5, \"fn\": 3654, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6898395721925134, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.31016042780748665, \"precision\": 0.999385145105755, \"recall\": 0.6898395721925134, \"specificity\": 0.9992875463094899, \"npv\": 0.6574482047436018, \"accuracy\": 0.8053619873397521, \"f1\": 0.816250690503691, \"f2\": 0.7353952511944404, \"f0_5\": 0.9170823083346499, \"p4\": 0.8045096035419587, \"phi\": 0.6727864993574897}, {\"truth_threshold\": 3.94, \"match_probability\": 0.9388312832503134, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8121, \"tn\": 7013, \"fp\": 5, \"fn\": 3660, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6893302775655716, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3106697224344283, \"precision\": 0.9993846911149397, \"recall\": 0.6893302775655716, \"specificity\": 0.9992875463094899, \"npv\": 0.6570786095755645, \"accuracy\": 0.8050428214266716, \"f1\": 0.8158939066659969, \"f2\": 0.7349321266968326, \"f0_5\": 0.9169018855142825, \"p4\": 0.8041979155044479, \"phi\": 0.672348369207017}, {\"truth_threshold\": 3.96, \"match_probability\": 0.9396225655335566, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8120, \"tn\": 7013, \"fp\": 5, \"fn\": 3661, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6892453951277481, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.3107546048722519, \"precision\": 0.9993846153846154, \"recall\": 0.6892453951277481, \"specificity\": 0.9992875463094899, \"npv\": 0.6570170507775904, \"accuracy\": 0.8049896271078248, \"f1\": 0.8158344217823772, \"f2\": 0.7348549295009864, \"f0_5\": 0.9168717960299, \"p4\": 0.8041459660896908, \"phi\": 0.6722753676634058}, {\"truth_threshold\": 3.98, \"match_probability\": 0.9404042615127621, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8118, \"tn\": 7013, \"fp\": 5, \"fn\": 3663, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6890756302521008, \"tn_rate\": 0.9992875463094899, \"fp_rate\": 0.0007124536905101168, \"fn_rate\": 0.31092436974789917, \"precision\": 0.999384463868029, \"recall\": 0.6890756302521008, \"specificity\": 0.9992875463094899, \"npv\": 0.6568939677781941, \"accuracy\": 0.8048832384701314, \"f1\": 0.8157154340836013, \"f2\": 0.7347005267254331, \"f0_5\": 0.9168116007498928, \"p4\": 0.804042066042346, \"phi\": 0.6721293818282704}, {\"truth_threshold\": 4.0, \"match_probability\": 0.9411764705882353, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8117, \"tn\": 7014, \"fp\": 4, \"fn\": 3664, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6889907478142773, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3110092521857228, \"precision\": 0.9995074498214506, \"recall\": 0.6889907478142773, \"specificity\": 0.9994300370475919, \"npv\": 0.6568645813822813, \"accuracy\": 0.8048832384701314, \"f1\": 0.8156969148829264, \"f2\": 0.7346366186985247, \"f0_5\": 0.9168643397718288, \"p4\": 0.8040451213224991, \"phi\": 0.6722054365167336}, {\"truth_threshold\": 4.0200000000000005, \"match_probability\": 0.9419392915633099, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8101, \"tn\": 7014, \"fp\": 4, \"fn\": 3680, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6876326288090994, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3123673711909006, \"precision\": 0.9995064774830351, \"recall\": 0.6876326288090994, \"specificity\": 0.9994300370475919, \"npv\": 0.6558818028801197, \"accuracy\": 0.8040321293685835, \"f1\": 0.8147440410338932, \"f2\": 0.7334009306704811, \"f0_5\": 0.9163819823080925, \"p4\": 0.8032138327511489, \"phi\": 0.6710386122106103}, {\"truth_threshold\": 4.04, \"match_probability\": 0.9426928226358258, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8088, \"tn\": 7014, \"fp\": 4, \"fn\": 3693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6865291571173924, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.31347084288260757, \"precision\": 0.9995056846267919, \"recall\": 0.6865291571173924, \"specificity\": 0.9994300370475919, \"npv\": 0.6550854581115159, \"accuracy\": 0.8033406032235757, \"f1\": 0.8139687012529563, \"f2\": 0.7323964068385975, \"f0_5\": 0.9159890371242837, \"p4\": 0.802538330265206, \"phi\": 0.6700916450608124}, {\"truth_threshold\": 4.0600000000000005, \"match_probability\": 0.9434371613900292, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8080, \"tn\": 7014, \"fp\": 4, \"fn\": 3701, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6858500976148035, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3141499023851965, \"precision\": 0.9995051954477981, \"recall\": 0.6858500976148035, \"specificity\": 0.9994300370475919, \"npv\": 0.6545963602426504, \"accuracy\": 0.8029150486728017, \"f1\": 0.8134910646866348, \"f2\": 0.7317780031879437, \"f0_5\": 0.9157467642858762, \"p4\": 0.8021225993243476, \"phi\": 0.6695093742184891}, {\"truth_threshold\": 4.08, \"match_probability\": 0.9441724047888862, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8075, \"tn\": 7014, \"fp\": 4, \"fn\": 3706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6854256854256854, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.31457431457431456, \"precision\": 0.9995048892189627, \"recall\": 0.6854256854256854, \"specificity\": 0.9994300370475919, \"npv\": 0.6542910447761194, \"accuracy\": 0.802649077078568, \"f1\": 0.8131923464249748, \"f2\": 0.7313914098871438, \"f0_5\": 0.9155951652039821, \"p4\": 0.8018627527980067, \"phi\": 0.6691456393986986}, {\"truth_threshold\": 4.1, \"match_probability\": 0.9448986491668007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8064, \"tn\": 7014, \"fp\": 4, \"fn\": 3717, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6844919786096256, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3155080213903743, \"precision\": 0.9995042141794744, \"recall\": 0.6844919786096256, \"specificity\": 0.9994300370475919, \"npv\": 0.6536203522504892, \"accuracy\": 0.8020639395712538, \"f1\": 0.8125346365056174, \"f2\": 0.7305406580663865, \"f0_5\": 0.9152611626903957, \"p4\": 0.8012910498348033, \"phi\": 0.6683459208733357}, {\"truth_threshold\": 4.12, \"match_probability\": 0.9456159902227271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8060, \"tn\": 7014, \"fp\": 4, \"fn\": 3721, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6841524488583313, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3158475511416688, \"precision\": 0.9995039682539683, \"recall\": 0.6841524488583313, \"specificity\": 0.9994300370475919, \"npv\": 0.6533768048439683, \"accuracy\": 0.8018511622958668, \"f1\": 0.8122952884857647, \"f2\": 0.7302312096832645, \"f0_5\": 0.9151395417489838, \"p4\": 0.8010831437681771, \"phi\": 0.6680552835465554}, {\"truth_threshold\": 4.14, \"match_probability\": 0.94632452301367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8054, \"tn\": 7014, \"fp\": 4, \"fn\": 3727, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6836431542313895, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.31635684576861045, \"precision\": 0.9995035989079176, \"recall\": 0.6836431542313895, \"specificity\": 0.9994300370475919, \"npv\": 0.6530118238525277, \"accuracy\": 0.8015319963827863, \"f1\": 0.8119360854881799, \"f2\": 0.7297669529919176, \"f0_5\": 0.9149569445391135, \"p4\": 0.8007712703386483, \"phi\": 0.667619496557531}, {\"truth_threshold\": 4.16, \"match_probability\": 0.9470243419485608, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8049, \"tn\": 7014, \"fp\": 4, \"fn\": 3732, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6832187420422714, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.31678125795772855, \"precision\": 0.9995032906991184, \"recall\": 0.6832187420422714, \"specificity\": 0.9994300370475919, \"npv\": 0.6527079843662759, \"accuracy\": 0.8012660247885526, \"f1\": 0.8116365836442473, \"f2\": 0.7293799952878917, \"f0_5\": 0.9148046280090014, \"p4\": 0.800511362514897, \"phi\": 0.6672564953839223}, {\"truth_threshold\": 4.18, \"match_probability\": 0.9477155407825041, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8038, \"tn\": 7014, \"fp\": 4, \"fn\": 3743, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6822850352262116, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3177149647737883, \"precision\": 0.9995026112907237, \"recall\": 0.6822850352262116, \"specificity\": 0.9994300370475919, \"npv\": 0.6520405317467696, \"accuracy\": 0.8006808872812383, \"f1\": 0.8109771477576553, \"f2\": 0.7285284414313163, \"f0_5\": 0.9144690436642472, \"p4\": 0.7999395219758743, \"phi\": 0.6664583864318205}, {\"truth_threshold\": 4.2, \"match_probability\": 0.9483982126113827, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8030, \"tn\": 7014, \"fp\": 4, \"fn\": 3751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6816059757236228, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3183940242763772, \"precision\": 0.9995021160069704, \"recall\": 0.6816059757236228, \"specificity\": 0.9994300370475919, \"npv\": 0.6515559684161635, \"accuracy\": 0.8002553327304643, \"f1\": 0.8104970981579611, \"f2\": 0.7279089162043584, \"f0_5\": 0.9142245599653892, \"p4\": 0.799523599802541, \"phi\": 0.665878368696563}, {\"truth_threshold\": 4.22, \"match_probability\": 0.9490724498668156, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8025, \"tn\": 7014, \"fp\": 4, \"fn\": 3756, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6811815635345048, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3188184364654953, \"precision\": 0.9995018059534189, \"recall\": 0.6811815635345048, \"specificity\": 0.9994300370475919, \"npv\": 0.6512534818941504, \"accuracy\": 0.7999893611362306, \"f1\": 0.8101968702675416, \"f2\": 0.7275216216706254, \"f0_5\": 0.9140715766453288, \"p4\": 0.7992636318210224, \"phi\": 0.6655160389120589}, {\"truth_threshold\": 4.24, \"match_probability\": 0.9497383443114579, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8017, \"tn\": 7014, \"fp\": 4, \"fn\": 3764, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6805025040319158, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3194974959680842, \"precision\": 0.9995013090637078, \"recall\": 0.6805025040319158, \"specificity\": 0.9994300370475919, \"npv\": 0.6507700872146966, \"accuracy\": 0.7995638065854567, \"f1\": 0.8097161902838097, \"f2\": 0.7269018043340285, \"f0_5\": 0.9138265131653939, \"p4\": 0.798847656016925, \"phi\": 0.664936600634147}, {\"truth_threshold\": 4.26, \"match_probability\": 0.9503959870346359, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8012, \"tn\": 7014, \"fp\": 4, \"fn\": 3769, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6800780918427978, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3199219081572023, \"precision\": 0.9995009980039921, \"recall\": 0.6800780918427978, \"specificity\": 0.9994300370475919, \"npv\": 0.6504683297783548, \"accuracy\": 0.799297834991223, \"f1\": 0.8094155680153559, \"f2\": 0.7265143271672108, \"f0_5\": 0.9136731668377238, \"p4\": 0.7985876540090537, \"phi\": 0.6645746321953064}, {\"truth_threshold\": 4.28, \"match_probability\": 0.9510454684483088, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8002, \"tn\": 7014, \"fp\": 4, \"fn\": 3779, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6792292674645616, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3207707325354384, \"precision\": 0.9995003747189608, \"recall\": 0.6792292674645616, \"specificity\": 0.9994300370475919, \"npv\": 0.6498656536644121, \"accuracy\": 0.7987658918027555, \"f1\": 0.8088138676909081, \"f2\": 0.7257391619807727, \"f0_5\": 0.9133660541034129, \"p4\": 0.7980676097697896, \"phi\": 0.6638511107142017}, {\"truth_threshold\": 4.3, \"match_probability\": 0.9516868782833479, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8001, \"tn\": 7014, \"fp\": 4, \"fn\": 3780, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.679144385026738, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32085561497326204, \"precision\": 0.9995003123048095, \"recall\": 0.679144385026738, \"specificity\": 0.9994300370475919, \"npv\": 0.6498054474708171, \"accuracy\": 0.7987126974839087, \"f1\": 0.8087536642070151, \"f2\": 0.7256616299951024, \"f0_5\": 0.9133353119791786, \"p4\": 0.7980156023607798, \"phi\": 0.663778788972109}, {\"truth_threshold\": 4.32, \"match_probability\": 0.9523203055861257, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8000, \"tn\": 7014, \"fp\": 4, \"fn\": 3781, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6790595025889143, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32094049741108566, \"precision\": 0.9995002498750625, \"recall\": 0.6790595025889143, \"specificity\": 0.9994300370475919, \"npv\": 0.6497452524316814, \"accuracy\": 0.798659503165062, \"f1\": 0.8086934546373515, \"f2\": 0.7255840951966332, \"f0_5\": 0.9133045642395597, \"p4\": 0.7979635944042006, \"phi\": 0.6637064727506994}, {\"truth_threshold\": 4.34, \"match_probability\": 0.9529458387154083, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7999, \"tn\": 7014, \"fp\": 4, \"fn\": 3782, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6789746201510908, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3210253798489093, \"precision\": 0.9995001874297138, \"recall\": 0.6789746201510908, \"specificity\": 0.9994300370475919, \"npv\": 0.6496850685439052, \"accuracy\": 0.7986063088462152, \"f1\": 0.8086332389809947, \"f2\": 0.7255065575852123, \"f0_5\": 0.9132738108830178, \"p4\": 0.7979115858988445, \"phi\": 0.6636341620480534}, {\"truth_threshold\": 4.36, \"match_probability\": 0.9535635653395406, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7992, \"tn\": 7014, \"fp\": 4, \"fn\": 3789, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6783804430863254, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32161955691367455, \"precision\": 0.9994997498749375, \"recall\": 0.6783804430863254, \"specificity\": 0.9994300370475919, \"npv\": 0.6492640933074146, \"accuracy\": 0.798233948614288, \"f1\": 0.8082115588815291, \"f2\": 0.7249637155297532, \"f0_5\": 0.9130583799840055, \"p4\": 0.7975475108940767, \"phi\": 0.6631281414937504}, {\"truth_threshold\": 4.38, \"match_probability\": 0.9541735724339184, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7983, \"tn\": 7014, \"fp\": 4, \"fn\": 3798, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6776165011459129, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32238349885408707, \"precision\": 0.9994991861775385, \"recall\": 0.6776165011459129, \"specificity\": 0.9994300370475919, \"npv\": 0.6487236403995561, \"accuracy\": 0.7977551997446672, \"f1\": 0.8076689599352489, \"f2\": 0.7242655731160749, \"f0_5\": 0.9127809920190263, \"p4\": 0.7970793741927327, \"phi\": 0.662477939792738}, {\"truth_threshold\": 4.4, \"match_probability\": 0.9547759462787397, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7971, \"tn\": 7014, \"fp\": 4, \"fn\": 3810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6765979118920296, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32340208810797044, \"precision\": 0.9994984326018809, \"recall\": 0.6765979118920296, \"specificity\": 0.9994300370475919, \"npv\": 0.6480044345898004, \"accuracy\": 0.7971168679185063, \"f1\": 0.8069447256529662, \"f2\": 0.7233343617851503, \"f0_5\": 0.9124104301641446, \"p4\": 0.7964551200320886, \"phi\": 0.6616116952111082}, {\"truth_threshold\": 4.42, \"match_probability\": 0.9553707724570261, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7965, \"tn\": 7014, \"fp\": 4, \"fn\": 3816, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6760886172650878, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32391138273491216, \"precision\": 0.9994980549629816, \"recall\": 0.6760886172650878, \"specificity\": 0.9994300370475919, \"npv\": 0.6476454293628808, \"accuracy\": 0.7967977020054258, \"f1\": 0.8065822784810126, \"f2\": 0.722868603996878, \"f0_5\": 0.9122248436676822, \"p4\": 0.7961429615503911, \"phi\": 0.6611788681431262}, {\"truth_threshold\": 4.44, \"match_probability\": 0.9559581358529086, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7964, \"tn\": 7014, \"fp\": 4, \"fn\": 3817, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6760037348272643, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3239962651727358, \"precision\": 0.9994979919678715, \"recall\": 0.6760037348272643, \"specificity\": 0.9994300370475919, \"npv\": 0.6475856338288247, \"accuracy\": 0.7967445076865791, \"f1\": 0.8065218492075548, \"f2\": 0.7227909678356205, \"f0_5\": 0.9121938927450576, \"p4\": 0.7960909330745212, \"phi\": 0.6611067493909895}, {\"truth_threshold\": 4.46, \"match_probability\": 0.9565381206501699, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7959, \"tn\": 7014, \"fp\": 4, \"fn\": 3822, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6755793226381461, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3244206773618538, \"precision\": 0.9994976767549918, \"recall\": 0.6755793226381461, \"specificity\": 0.9994300370475919, \"npv\": 0.6472868217054264, \"accuracy\": 0.7964785360923453, \"f1\": 0.8062196110210696, \"f2\": 0.7224027447492148, \"f0_5\": 0.9120390530103362, \"p4\": 0.7958307817838, \"phi\": 0.6607462373411052}, {\"truth_threshold\": 4.48, \"match_probability\": 0.9571108103310354, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7949, \"tn\": 7014, \"fp\": 4, \"fn\": 3832, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.67473049825991, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32526950174008995, \"precision\": 0.9994970451401987, \"recall\": 0.67473049825991, \"specificity\": 0.9994300370475919, \"npv\": 0.6466900239719713, \"accuracy\": 0.7959465929038778, \"f1\": 0.8056146751798926, \"f2\": 0.7216260871144035, \"f0_5\": 0.9117289473080541, \"p4\": 0.7953104341571883, \"phi\": 0.6600256210340976}, {\"truth_threshold\": 4.5, \"match_probability\": 0.9576762876752064, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7943, \"tn\": 7014, \"fp\": 4, \"fn\": 3838, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6742212036329683, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32577879636703166, \"precision\": 0.9994966654083302, \"recall\": 0.6742212036329683, \"specificity\": 0.9994300370475919, \"npv\": 0.6463324732768153, \"accuracy\": 0.7956274269907974, \"f1\": 0.8052514193025142, \"f2\": 0.7211599571462294, \"f0_5\": 0.9115426105717368, \"p4\": 0.7949981963415389, \"phi\": 0.6595935115985495}, {\"truth_threshold\": 4.5200000000000005, \"match_probability\": 0.9582346347591285, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7935, \"tn\": 7014, \"fp\": 4, \"fn\": 3846, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6735421441303794, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32645785586962056, \"precision\": 0.9994961582063232, \"recall\": 0.6735421441303794, \"specificity\": 0.9994300370475919, \"npv\": 0.6458563535911602, \"accuracy\": 0.7952018724400234, \"f1\": 0.8047667342799188, \"f2\": 0.7205382925013166, \"f0_5\": 0.9112938420194318, \"p4\": 0.7945818445923004, \"phi\": 0.659017668574246}, {\"truth_threshold\": 4.54, \"match_probability\": 0.9587859329554874, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7933, \"tn\": 7014, \"fp\": 4, \"fn\": 3848, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6733723792547321, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3266276207452678, \"precision\": 0.9994960312460628, \"recall\": 0.6733723792547321, \"specificity\": 0.9994300370475919, \"npv\": 0.6457374332535445, \"accuracy\": 0.7950954838023299, \"f1\": 0.8046455015721675, \"f2\": 0.7203828481139101, \"f0_5\": 0.9112315927312826, \"p4\": 0.794477750399962, \"phi\": 0.6588737618045324}, {\"truth_threshold\": 4.5600000000000005, \"match_probability\": 0.9593302629329274, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7929, \"tn\": 7014, \"fp\": 4, \"fn\": 3852, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6730328495034378, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3269671504965623, \"precision\": 0.999495777133493, \"recall\": 0.6730328495034378, \"specificity\": 0.9994300370475919, \"npv\": 0.6454997239094423, \"accuracy\": 0.7948827065269429, \"f1\": 0.8044029623617733, \"f2\": 0.7200719254590697, \"f0_5\": 0.9111070254866361, \"p4\": 0.7942695544404497, \"phi\": 0.6585860129426983}, {\"truth_threshold\": 4.58, \"match_probability\": 0.9598677046559833, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7927, \"tn\": 7014, \"fp\": 4, \"fn\": 3854, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6728630846277905, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3271369153722095, \"precision\": 0.9994956499810869, \"recall\": 0.6728630846277905, \"specificity\": 0.9994300370475919, \"npv\": 0.6453809348546191, \"accuracy\": 0.7947763178892494, \"f1\": 0.8042816558441559, \"f2\": 0.7199164471891745, \"f0_5\": 0.9110447075048845, \"p4\": 0.7941654526535974, \"phi\": 0.6584421708203054}, {\"truth_threshold\": 4.6000000000000005, \"match_probability\": 0.9603983373852208, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7922, \"tn\": 7014, \"fp\": 4, \"fn\": 3859, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6724386724386724, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32756132756132755, \"precision\": 0.9994953318193288, \"recall\": 0.6724386724386724, \"specificity\": 0.9994300370475919, \"npv\": 0.6450841534075232, \"accuracy\": 0.7945103462950157, \"f1\": 0.8039782818287918, \"f2\": 0.71952770208901, \"f0_5\": 0.9108888122341037, \"p4\": 0.7939051870034513, \"phi\": 0.6580826596261944}, {\"truth_threshold\": 4.62, \"match_probability\": 0.96092223967758, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7920, \"tn\": 7014, \"fp\": 4, \"fn\": 3861, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6722689075630253, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3277310924369748, \"precision\": 0.9994952044422009, \"recall\": 0.6722689075630253, \"specificity\": 0.9994300370475919, \"npv\": 0.6449655172413793, \"accuracy\": 0.7944039576573222, \"f1\": 0.803856889114438, \"f2\": 0.7193721842755414, \"f0_5\": 0.910826413966005, \"p4\": 0.7938010762443144, \"phi\": 0.6579388927536185}, {\"truth_threshold\": 4.66, \"match_probability\": 0.9619501636647065, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7913, \"tn\": 7014, \"fp\": 4, \"fn\": 3868, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6716747304982599, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32832526950174007, \"precision\": 0.9994947581154477, \"recall\": 0.6716747304982599, \"specificity\": 0.9994300370475919, \"npv\": 0.6445506340746187, \"accuracy\": 0.794031597425395, \"f1\": 0.8034318204893898, \"f2\": 0.7188277829254556, \"f0_5\": 0.910607839075698, \"p4\": 0.7934366681601858, \"phi\": 0.6574358776448783}, {\"truth_threshold\": 4.68, \"match_probability\": 0.9624543389610023, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7911, \"tn\": 7014, \"fp\": 4, \"fn\": 3870, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6715049656226126, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3284950343773873, \"precision\": 0.9994946304485155, \"recall\": 0.6715049656226126, \"specificity\": 0.9994300370475919, \"npv\": 0.6444321940463065, \"accuracy\": 0.7939252087877015, \"f1\": 0.8033103168155971, \"f2\": 0.7186722142480786, \"f0_5\": 0.9105453373541125, \"p4\": 0.7933325456876495, \"phi\": 0.6572922072502075}, {\"truth_threshold\": 4.7, \"match_probability\": 0.9629520910254744, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7901, \"tn\": 7014, \"fp\": 4, \"fn\": 3880, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6706561412443766, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.32934385875562344, \"precision\": 0.999493991144845, \"recall\": 0.6706561412443766, \"specificity\": 0.9994300370475919, \"npv\": 0.6438406462272811, \"accuracy\": 0.793393265599234, \"f1\": 0.8027024281215077, \"f2\": 0.7178942012393466, \"f0_5\": 0.9102324831225087, \"p4\": 0.7928118936746839, \"phi\": 0.6565741759462805}, {\"truth_threshold\": 4.72, \"match_probability\": 0.9634434949086931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7893, \"tn\": 7014, \"fp\": 4, \"fn\": 3888, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6699770817417876, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3300229182582124, \"precision\": 0.999493478536153, \"recall\": 0.6699770817417876, \"specificity\": 0.9994300370475919, \"npv\": 0.64336818932306, \"accuracy\": 0.79296771104846, \"f1\": 0.8022156723244233, \"f2\": 0.7172715872121553, \"f0_5\": 0.9099817842237543, \"p4\": 0.7923953238894568, \"phi\": 0.6560001348031651}, {\"truth_threshold\": 4.74, \"match_probability\": 0.9639286249635483, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7889, \"tn\": 7014, \"fp\": 4, \"fn\": 3892, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6696375519904931, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3303624480095068, \"precision\": 0.9994932218421386, \"recall\": 0.6696375519904931, \"specificity\": 0.9994300370475919, \"npv\": 0.6431322207958922, \"accuracy\": 0.792754933773073, \"f1\": 0.8019721459794653, \"f2\": 0.716960212298017, \"f0_5\": 0.9098562959887436, \"p4\": 0.7921870227202211, \"phi\": 0.6557132418674794}, {\"truth_threshold\": 4.76, \"match_probability\": 0.9644075548468342, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7870, \"tn\": 7014, \"fp\": 4, \"fn\": 3911, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6680247856718445, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3319752143281555, \"precision\": 0.999491998983998, \"recall\": 0.6680247856718445, \"specificity\": 0.9994300370475919, \"npv\": 0.6420137299771167, \"accuracy\": 0.7917442417149848, \"f1\": 0.8008140422284405, \"f2\": 0.7154805629295611, \"f0_5\": 0.909258959724565, \"p4\": 0.7911974411726196, \"phi\": 0.6543516582062306}, {\"truth_threshold\": 4.78, \"match_probability\": 0.9648803575209879, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7863, \"tn\": 7014, \"fp\": 4, \"fn\": 3918, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6674306086070791, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3325693913929208, \"precision\": 0.9994915469683489, \"recall\": 0.6674306086070791, \"specificity\": 0.9994300370475919, \"npv\": 0.641602634467618, \"accuracy\": 0.7913718814830576, \"f1\": 0.8003868078175895, \"f2\": 0.7149351712098343, \"f0_5\": 0.9090383592684224, \"p4\": 0.7908327944770354, \"phi\": 0.653850502605788}, {\"truth_threshold\": 4.8, \"match_probability\": 0.9653471052559783, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7847, \"tn\": 7014, \"fp\": 4, \"fn\": 3934, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6660724896019014, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33392751039809865, \"precision\": 0.9994905107629601, \"recall\": 0.6660724896019014, \"specificity\": 0.9994300370475919, \"npv\": 0.6406649616368286, \"accuracy\": 0.7905207723815096, \"f1\": 0.7994091279543603, \"f2\": 0.7136880400181901, \"f0_5\": 0.9085330554590715, \"p4\": 0.7899991836457877, \"phi\": 0.6527059708096437}, {\"truth_threshold\": 4.82, \"match_probability\": 0.9658078696313372, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7843, \"tn\": 7014, \"fp\": 4, \"fn\": 3938, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6657329598506069, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33426704014939307, \"precision\": 0.9994902510513572, \"recall\": 0.6657329598506069, \"specificity\": 0.9994300370475919, \"npv\": 0.6404309715120526, \"accuracy\": 0.7903079951061227, \"f1\": 0.7991644589362136, \"f2\": 0.7133761437849048, \"f0_5\": 0.908406495401793, \"p4\": 0.7897907516449313, \"phi\": 0.6524200473460614}, {\"truth_threshold\": 4.84, \"match_probability\": 0.9662627215383301, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7834, \"tn\": 7014, \"fp\": 4, \"fn\": 3947, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6649690179101944, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33503098208980564, \"precision\": 0.9994896657310538, \"recall\": 0.6649690179101944, \"specificity\": 0.9994300370475919, \"npv\": 0.6399051181461546, \"accuracy\": 0.789829246236502, \"f1\": 0.7986135888679341, \"f2\": 0.7126742112732434, \"f0_5\": 0.9081213919736628, \"p4\": 0.7893217360905572, \"phi\": 0.6517770248735032}, {\"truth_threshold\": 4.86, \"match_probability\": 0.9667117311822604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7832, \"tn\": 7014, \"fp\": 4, \"fn\": 3949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6647992530345471, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3352007469654528, \"precision\": 0.9994895354772844, \"recall\": 0.6647992530345471, \"specificity\": 0.9994300370475919, \"npv\": 0.6397883790933139, \"accuracy\": 0.7897228575988084, \"f1\": 0.7984911046541265, \"f2\": 0.7125181950509462, \"f0_5\": 0.9080579710144927, \"p4\": 0.7892175021531256, \"phi\": 0.6516341882992472}, {\"truth_threshold\": 4.88, \"match_probability\": 0.9671549680849019, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7823, \"tn\": 7014, \"fp\": 4, \"fn\": 3958, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6640353110941346, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3359646889058654, \"precision\": 0.9994889485115626, \"recall\": 0.6640353110941346, \"specificity\": 0.9994300370475919, \"npv\": 0.6392635800218739, \"accuracy\": 0.7892441087291877, \"f1\": 0.7979396164830681, \"f2\": 0.7118159815108005, \"f0_5\": 0.9077722852700225, \"p4\": 0.7887484118539378, \"phi\": 0.6509916809912739}, {\"truth_threshold\": 4.9, \"match_probability\": 0.9675925010870554, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7817, \"tn\": 7014, \"fp\": 4, \"fn\": 3964, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6635260164671929, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33647398353280705, \"precision\": 0.9994885564505818, \"recall\": 0.6635260164671929, \"specificity\": 0.9994300370475919, \"npv\": 0.6389141920204044, \"accuracy\": 0.7889249428161073, \"f1\": 0.7975716763595552, \"f2\": 0.7113477113477114, \"f0_5\": 0.9075815627539765, \"p4\": 0.7884356505009505, \"phi\": 0.6505635762009097}, {\"truth_threshold\": 4.92, \"match_probability\": 0.9680243983512243, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7812, \"tn\": 7014, \"fp\": 4, \"fn\": 3969, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6631016042780749, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33689839572192515, \"precision\": 0.9994882292732856, \"recall\": 0.6631016042780749, \"specificity\": 0.9994300370475919, \"npv\": 0.638623326959847, \"accuracy\": 0.7886589712218735, \"f1\": 0.797264887482778, \"f2\": 0.7109574080815435, \"f0_5\": 0.9074224648623533, \"p4\": 0.7881749947325772, \"phi\": 0.6502069645120797}, {\"truth_threshold\": 4.94, \"match_probability\": 0.9684507273644041, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7808, \"tn\": 7014, \"fp\": 4, \"fn\": 3973, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6627620745267804, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33723792547321957, \"precision\": 0.9994879672299027, \"recall\": 0.6627620745267804, \"specificity\": 0.9994300370475919, \"npv\": 0.6383908255210704, \"accuracy\": 0.7884461939464865, \"f1\": 0.7970193436431379, \"f2\": 0.7106451143148391, \"f0_5\": 0.9072950800622835, \"p4\": 0.7879664560569193, \"phi\": 0.6499217681385032}, {\"truth_threshold\": 4.96, \"match_probability\": 0.9688715549409818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7800, \"tn\": 7014, \"fp\": 4, \"fn\": 3981, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6620830150241915, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3379169849758085, \"precision\": 0.9994874423372629, \"recall\": 0.6620830150241915, \"specificity\": 0.9994300370475919, \"npv\": 0.6379263301500682, \"accuracy\": 0.7880206393957125, \"f1\": 0.7965279550676538, \"f2\": 0.7100203903291582, \"f0_5\": 0.907040026048329, \"p4\": 0.7875493408640332, \"phi\": 0.6493516228290215}, {\"truth_threshold\": 4.98, \"match_probability\": 0.9692869472257413, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7795, \"tn\": 7014, \"fp\": 4, \"fn\": 3986, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6616586028350734, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33834139716492656, \"precision\": 0.9994871137325299, \"recall\": 0.6616586028350734, \"specificity\": 0.9994300370475919, \"npv\": 0.6376363636363637, \"accuracy\": 0.7877546678014788, \"f1\": 0.7962206332992849, \"f2\": 0.7096298454199516, \"f0_5\": 0.9068804244130582, \"p4\": 0.7872886180121759, \"phi\": 0.6489954492067844}, {\"truth_threshold\": 5.0, \"match_probability\": 0.9696969696969697, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7788, \"tn\": 7014, \"fp\": 4, \"fn\": 3993, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6610644257703081, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3389355742296919, \"precision\": 0.9994866529774127, \"recall\": 0.6610644257703081, \"specificity\": 0.9994300370475919, \"npv\": 0.6372308530934859, \"accuracy\": 0.7873823075695515, \"f1\": 0.7957901190415368, \"f2\": 0.7090829630708719, \"f0_5\": 0.9066567324035484, \"p4\": 0.786923572248304, \"phi\": 0.6484970216886514}, {\"truth_threshold\": 5.0200000000000005, \"match_probability\": 0.9701016871696593, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7786, \"tn\": 7014, \"fp\": 4, \"fn\": 3995, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6608946608946609, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33910533910533913, \"precision\": 0.9994865211810012, \"recall\": 0.6608946608946609, \"specificity\": 0.9994300370475919, \"npv\": 0.6371150876555546, \"accuracy\": 0.7872759189318581, \"f1\": 0.7956670584027388, \"f2\": 0.708926685362567, \"f0_5\": 0.9065927668195897, \"p4\": 0.7868192661682983, \"phi\": 0.6483546599389496}, {\"truth_threshold\": 5.04, \"match_probability\": 0.9705011637988036, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7781, \"tn\": 7014, \"fp\": 4, \"fn\": 4000, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6604702487055428, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.33952975129445717, \"precision\": 0.9994861913937059, \"recall\": 0.6604702487055428, \"specificity\": 0.9994300370475919, \"npv\": 0.6368258579989104, \"accuracy\": 0.7870099473376243, \"f1\": 0.7953592967392416, \"f2\": 0.708535941284671, \"f0_5\": 0.9064327485380117, \"p4\": 0.7865584866882352, \"phi\": 0.6479988450779448}, {\"truth_threshold\": 5.0600000000000005, \"match_probability\": 0.9708954630827813, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7771, \"tn\": 7014, \"fp\": 4, \"fn\": 4010, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6596214243273066, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3403785756726933, \"precision\": 0.9994855305466238, \"recall\": 0.6596214243273066, \"specificity\": 0.9994300370475919, \"npv\": 0.6362481857764877, \"accuracy\": 0.7864780041491569, \"f1\": 0.794743301288607, \"f2\": 0.7077542396036358, \"f0_5\": 0.9061122641729438, \"p4\": 0.7860368659836329, \"phi\": 0.6472875982034892}, {\"truth_threshold\": 5.08, \"match_probability\": 0.9712846478668253, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7769, \"tn\": 7014, \"fp\": 4, \"fn\": 4012, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6594516594516594, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.34054834054834054, \"precision\": 0.9994853981731635, \"recall\": 0.6594516594516594, \"specificity\": 0.9994300370475919, \"npv\": 0.6361327770723744, \"accuracy\": 0.7863716155114634, \"f1\": 0.7946200265930244, \"f2\": 0.7075978650928102, \"f0_5\": 0.9060480955379843, \"p4\": 0.785932531876399, \"phi\": 0.6471454099594143}, {\"truth_threshold\": 5.1000000000000005, \"match_probability\": 0.9716687803465724, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7762, \"tn\": 7014, \"fp\": 4, \"fn\": 4019, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6588574823868941, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3411425176131058, \"precision\": 0.999484934329127, \"recall\": 0.6588574823868941, \"specificity\": 0.9994300370475919, \"npv\": 0.6357291761080395, \"accuracy\": 0.7859992552795362, \"f1\": 0.7941883665012534, \"f2\": 0.7070504645654946, \"f0_5\": 0.9058233166063718, \"p4\": 0.7855673360832615, \"phi\": 0.6466479112078427}, {\"truth_threshold\": 5.12, \"match_probability\": 0.9720479220716894, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7759, \"tn\": 7014, \"fp\": 4, \"fn\": 4022, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6586028350734233, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3413971649265767, \"precision\": 0.9994847352827515, \"recall\": 0.6586028350734233, \"specificity\": 0.9994300370475919, \"npv\": 0.6355563610003625, \"accuracy\": 0.7858396723229959, \"f1\": 0.7940032746623005, \"f2\": 0.7068158215970995, \"f0_5\": 0.9057268928162865, \"p4\": 0.7854108109433898, \"phi\": 0.6464347735866749}, {\"truth_threshold\": 5.14, \"match_probability\": 0.9724221339495741, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7751, \"tn\": 7014, \"fp\": 4, \"fn\": 4030, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6579237755708344, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.34207622442916563, \"precision\": 0.9994842037395228, \"recall\": 0.6579237755708344, \"specificity\": 0.9994300370475919, \"npv\": 0.6350959797174937, \"accuracy\": 0.7854141177722219, \"f1\": 0.7935094185094185, \"f2\": 0.7061899815958745, \"f0_5\": 0.9054694983762062, \"p4\": 0.7849933731028264, \"phi\": 0.6458666294271367}, {\"truth_threshold\": 5.16, \"match_probability\": 0.972791476249125, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7749, \"tn\": 7014, \"fp\": 4, \"fn\": 4032, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6577540106951871, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3422459893048128, \"precision\": 0.9994840706823165, \"recall\": 0.6577540106951871, \"specificity\": 0.9994300370475919, \"npv\": 0.6349809885931559, \"accuracy\": 0.7853077291345284, \"f1\": 0.7933858912665097, \"f2\": 0.7060334930845346, \"f0_5\": 0.9054050896174608, \"p4\": 0.7848890050714286, \"phi\": 0.6457246439512876}, {\"truth_threshold\": 5.18, \"match_probability\": 0.9731560086045776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7739, \"tn\": 7014, \"fp\": 4, \"fn\": 4042, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.656905186316951, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.343094813683049, \"precision\": 0.9994834043652331, \"recall\": 0.656905186316951, \"specificity\": 0.9994300370475919, \"npv\": 0.6344066570188133, \"accuracy\": 0.784775785946061, \"f1\": 0.7927678754353616, \"f2\": 0.7052508793992746, \"f0_5\": 0.9050826842560756, \"p4\": 0.7843671129700722, \"phi\": 0.6450150192259572}, {\"truth_threshold\": 5.2, \"match_probability\": 0.9735157900194042, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7736, \"tn\": 7014, \"fp\": 4, \"fn\": 4045, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6566505390034801, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3433494609965198, \"precision\": 0.999483204134367, \"recall\": 0.6566505390034801, \"specificity\": 0.9994300370475919, \"npv\": 0.6342345600868071, \"accuracy\": 0.7846162029895207, \"f1\": 0.7925823472158189, \"f2\": 0.705016039661709, \"f0_5\": 0.9049858449732108, \"p4\": 0.7842105283315676, \"phi\": 0.6448022299930618}, {\"truth_threshold\": 5.22, \"match_probability\": 0.9738708788702727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7730, \"tn\": 7014, \"fp\": 4, \"fn\": 4051, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6561412443765385, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3438587556234615, \"precision\": 0.9994828032066201, \"recall\": 0.6561412443765385, \"specificity\": 0.9994300370475919, \"npv\": 0.6338906461816539, \"accuracy\": 0.7842970370764403, \"f1\": 0.7922111196515501, \"f2\": 0.7045462831309928, \"f0_5\": 0.9047920031837442, \"p4\": 0.7838973352832612, \"phi\": 0.6443767871637621}, {\"truth_threshold\": 5.24, \"match_probability\": 0.974221332911062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7718, \"tn\": 7014, \"fp\": 4, \"fn\": 4063, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6551226551226551, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3448773448773449, \"precision\": 0.9994819994819995, \"recall\": 0.6551226551226551, \"specificity\": 0.9994300370475919, \"npv\": 0.6332039360837772, \"accuracy\": 0.7836587052502793, \"f1\": 0.7914679792852382, \"f2\": 0.7036064617292054, \"f0_5\": 0.9044036654245471, \"p4\": 0.7832708531195222, \"phi\": 0.6435264426756919}, {\"truth_threshold\": 5.26, \"match_probability\": 0.9745672092769317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7714, \"tn\": 7014, \"fp\": 4, \"fn\": 4067, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6547831253713606, \"tn_rate\": 0.9994300370475919, \"fp_rate\": 0.0005699629524080935, \"fn_rate\": 0.3452168746286393, \"precision\": 0.9994817310183985, \"recall\": 0.6547831253713606, \"specificity\": 0.9994300370475919, \"npv\": 0.6329753632343651, \"accuracy\": 0.7834459279748923, \"f1\": 0.7912200625673111, \"f2\": 0.7032930965318551, \"f0_5\": 0.9042740252737205, \"p4\": 0.7830619969619403, \"phi\": 0.6432431544333777}, {\"truth_threshold\": 5.28, \"match_probability\": 0.9749085644884405, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7711, \"tn\": 7015, \"fp\": 3, \"fn\": 4070, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6545284780578898, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.34547152194211017, \"precision\": 0.9996110967072854, \"recall\": 0.6545284780578898, \"specificity\": 0.9995725277856939, \"npv\": 0.6328371673432567, \"accuracy\": 0.7833395393371988, \"f1\": 0.7910746345216723, \"f2\": 0.7030708632699952, \"f0_5\": 0.9042615568637569, \"p4\": 0.7829597531110387, \"phi\": 0.6431835240889556}, {\"truth_threshold\": 5.3, \"match_probability\": 0.9752454544557132, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7705, \"tn\": 7015, \"fp\": 3, \"fn\": 4076, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6540191834309481, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3459808165690519, \"precision\": 0.9996107939802802, \"recall\": 0.6540191834309481, \"specificity\": 0.9995725277856939, \"npv\": 0.6324948156162654, \"accuracy\": 0.7830203734241183, \"f1\": 0.7907024475345067, \"f2\": 0.7026006711409396, \"f0_5\": 0.904066834064722, \"p4\": 0.7826464157673267, \"phi\": 0.6427588871776454}, {\"truth_threshold\": 5.32, \"match_probability\": 0.9755779344826514, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7700, \"tn\": 7015, \"fp\": 3, \"fn\": 4081, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6535947712418301, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3464052287581699, \"precision\": 0.9996105413475269, \"recall\": 0.6535947712418301, \"specificity\": 0.9995725277856939, \"npv\": 0.632209805335256, \"accuracy\": 0.7827544018298845, \"f1\": 0.7903921166084993, \"f2\": 0.7022087657540993, \"f0_5\": 0.9039043974361984, \"p4\": 0.7823852760263452, \"phi\": 0.6424051597811362}, {\"truth_threshold\": 5.34, \"match_probability\": 0.9759060592711867, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7699, \"tn\": 7015, \"fp\": 3, \"fn\": 4082, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6535098888040064, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.34649011119599354, \"precision\": 0.9996104907816151, \"recall\": 0.6535098888040064, \"specificity\": 0.9995725277856939, \"npv\": 0.6321528340993061, \"accuracy\": 0.7827012075110378, \"f1\": 0.7903300313093466, \"f2\": 0.7021303760989311, \"f0_5\": 0.9038718918030477, \"p4\": 0.7823330453037642, \"phi\": 0.6423344291924387}, {\"truth_threshold\": 5.36, \"match_probability\": 0.9762298829255712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7685, \"tn\": 7015, \"fp\": 3, \"fn\": 4096, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6523215346744758, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.34767846532552416, \"precision\": 0.9996097814776275, \"recall\": 0.6523215346744758, \"specificity\": 0.9995725277856939, \"npv\": 0.6313563135631356, \"accuracy\": 0.7819564870471833, \"f1\": 0.7894601674456829, \"f2\": 0.7010326205940305, \"f0_5\": 0.9034161709731268, \"p4\": 0.7816017171662987, \"phi\": 0.6413447208566955}, {\"truth_threshold\": 5.38, \"match_probability\": 0.9765494589567063, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7674, \"tn\": 7015, \"fp\": 3, \"fn\": 4107, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6513878278584161, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3486121721415839, \"precision\": 0.9996092223524814, \"recall\": 0.6513878278584161, \"specificity\": 0.9995725277856939, \"npv\": 0.6307318827549002, \"accuracy\": 0.7813713495398691, \"f1\": 0.7887758248535307, \"f2\": 0.7001697049323917, \"f0_5\": 0.9030572618795453, \"p4\": 0.7810269722738747, \"phi\": 0.6405677715572354}, {\"truth_threshold\": 5.4, \"match_probability\": 0.9768648402865033, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7669, \"tn\": 7015, \"fp\": 3, \"fn\": 4112, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.650963415669298, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.349036584330702, \"precision\": 0.9996089676746611, \"recall\": 0.650963415669298, \"specificity\": 0.9995725277856939, \"npv\": 0.6304484587040532, \"accuracy\": 0.7811053779456354, \"f1\": 0.7884645041895851, \"f2\": 0.6997773560113877, \"f0_5\": 0.9028938755327415, \"p4\": 0.7807656862716641, \"phi\": 0.6402148094976412}, {\"truth_threshold\": 5.42, \"match_probability\": 0.9771760792522766, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7663, \"tn\": 7015, \"fp\": 3, \"fn\": 4118, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6504541210423563, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.34954587895764366, \"precision\": 0.9996086616227498, \"recall\": 0.6504541210423563, \"specificity\": 0.9995725277856939, \"npv\": 0.6301086858887991, \"accuracy\": 0.7807862120325549, \"f1\": 0.7880907080783669, \"f2\": 0.6993064427815294, \"f0_5\": 0.9026976086700436, \"p4\": 0.7804521111323072, \"phi\": 0.63979141687883}, {\"truth_threshold\": 5.44, \"match_probability\": 0.9774832276111642, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7651, \"tn\": 7015, \"fp\": 3, \"fn\": 4130, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.649435531788473, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35056446821152704, \"precision\": 0.9996080480794356, \"recall\": 0.649435531788473, \"specificity\": 0.9995725277856939, \"npv\": 0.6294302377747869, \"accuracy\": 0.7801478802063939, \"f1\": 0.7873424234628248, \"f2\": 0.6983643068385118, \"f0_5\": 0.9023044083307781, \"p4\": 0.7798248552375122, \"phi\": 0.6389451598534174}, {\"truth_threshold\": 5.46, \"match_probability\": 0.9777863365445763, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7650, \"tn\": 7015, \"fp\": 3, \"fn\": 4131, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6493506493506493, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35064935064935066, \"precision\": 0.999607996863975, \"recall\": 0.6493506493506493, \"specificity\": 0.9995725277856939, \"npv\": 0.6293737663735869, \"accuracy\": 0.7800946858875472, \"f1\": 0.7872800246989812, \"f2\": 0.6982857768771564, \"f0_5\": 0.9022716014436346, \"p4\": 0.7797725775018398, \"phi\": 0.6388746701513044}, {\"truth_threshold\": 5.48, \"match_probability\": 0.9780854566626659, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7646, \"tn\": 7015, \"fp\": 3, \"fn\": 4135, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6490111195993549, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35098888040064513, \"precision\": 0.999607791868218, \"recall\": 0.6490111195993549, \"specificity\": 0.9995725277856939, \"npv\": 0.6291479820627802, \"accuracy\": 0.7798819086121602, \"f1\": 0.7870303654143078, \"f2\": 0.6979716283570372, \"f0_5\": 0.9021403119616773, \"p4\": 0.7795634566206517, \"phi\": 0.6385927600361408}, {\"truth_threshold\": 5.5, \"match_probability\": 0.9783806380088231, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7638, \"tn\": 7015, \"fp\": 3, \"fn\": 4143, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.648332060096766, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35166793990323403, \"precision\": 0.9996073812328229, \"recall\": 0.648332060096766, \"specificity\": 0.9995725277856939, \"npv\": 0.6286968990858577, \"accuracy\": 0.7794563540613862, \"f1\": 0.7865307383379673, \"f2\": 0.6973431936455765, \"f0_5\": 0.9018774353524619, \"p4\": 0.779145166876745, \"phi\": 0.6380291731611183}, {\"truth_threshold\": 5.5200000000000005, \"match_probability\": 0.9786719300641882, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7632, \"tn\": 7015, \"fp\": 3, \"fn\": 4149, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6478227654698243, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3521772345301757, \"precision\": 0.999607072691552, \"recall\": 0.6478227654698243, \"specificity\": 0.9995725277856939, \"npv\": 0.6283590111071301, \"accuracy\": 0.7791371881483058, \"f1\": 0.7861557478368356, \"f2\": 0.696871747110064, \"f0_5\": 0.9016800170128305, \"p4\": 0.778831407249238, \"phi\": 0.6376066867398484}, {\"truth_threshold\": 5.54, \"match_probability\": 0.9789593817521819, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7628, \"tn\": 7015, \"fp\": 3, \"fn\": 4153, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6474832357185298, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35251676428147016, \"precision\": 0.9996068667278207, \"recall\": 0.6474832357185298, \"specificity\": 0.9995725277856939, \"npv\": 0.6281339541547278, \"accuracy\": 0.7789244108729187, \"f1\": 0.785905625386359, \"f2\": 0.6965573920189937, \"f0_5\": 0.9015482803451129, \"p4\": 0.7786222138519253, \"phi\": 0.637325125927831}, {\"truth_threshold\": 5.5600000000000005, \"match_probability\": 0.9792430414430521, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7618, \"tn\": 7015, \"fp\": 3, \"fn\": 4163, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6466344113402936, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3533655886597063, \"precision\": 0.9996063508725889, \"recall\": 0.6466344113402936, \"specificity\": 0.9995725277856939, \"npv\": 0.6275720164609053, \"accuracy\": 0.7783924676844513, \"f1\": 0.7852798680548397, \"f2\": 0.6957713033153713, \"f0_5\": 0.9012185023068733, \"p4\": 0.7780991586415829, \"phi\": 0.6366215618722096}, {\"truth_threshold\": 5.58, \"match_probability\": 0.9795229569584335, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7607, \"tn\": 7015, \"fp\": 3, \"fn\": 4174, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6457007045242339, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35429929547576605, \"precision\": 0.9996057818659658, \"recall\": 0.6457007045242339, \"specificity\": 0.9995725277856939, \"npv\": 0.6269550451336133, \"accuracy\": 0.7778073301771371, \"f1\": 0.7845907895415399, \"f2\": 0.6949062739796105, \"f0_5\": 0.9008550247507164, \"p4\": 0.7775236782872034, \"phi\": 0.6358481973527959}, {\"truth_threshold\": 5.6000000000000005, \"match_probability\": 0.979799175575919, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7598, \"tn\": 7015, \"fp\": 3, \"fn\": 4183, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6449367625838214, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35506323741617857, \"precision\": 0.9996053150901197, \"recall\": 0.6449367625838214, \"specificity\": 0.9995725277856939, \"npv\": 0.6264511519914271, \"accuracy\": 0.7773285813075164, \"f1\": 0.7840264162625116, \"f2\": 0.6941982640475103, \"f0_5\": 0.9005570700485954, \"p4\": 0.7770527363027266, \"phi\": 0.635215876163351}, {\"truth_threshold\": 5.62, \"match_probability\": 0.9800717440336414, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7588, \"tn\": 7015, \"fp\": 3, \"fn\": 4193, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6440879382055853, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35591206179441476, \"precision\": 0.9996047951521538, \"recall\": 0.6440879382055853, \"specificity\": 0.9995725277856939, \"npv\": 0.6258922198429693, \"accuracy\": 0.7767966381190489, \"f1\": 0.7833987198017758, \"f2\": 0.6934113131682355, \"f0_5\": 0.9002254122671729, \"p4\": 0.7765293664836684, \"phi\": 0.6345137509525819}, {\"truth_threshold\": 5.64, \"match_probability\": 0.9803407085348623, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7582, \"tn\": 7015, \"fp\": 3, \"fn\": 4199, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6435786435786436, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3564213564213564, \"precision\": 0.9996044825313118, \"recall\": 0.6435786435786436, \"specificity\": 0.9995725277856939, \"npv\": 0.6255573390404852, \"accuracy\": 0.7764774722059684, \"f1\": 0.7830217907673241, \"f2\": 0.6929390045513535, \"f0_5\": 0.9000261152394292, \"p4\": 0.776215293046877, \"phi\": 0.6340927044495657}, {\"truth_threshold\": 5.66, \"match_probability\": 0.9806061147525681, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7574, \"tn\": 7015, \"fp\": 3, \"fn\": 4207, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6428995840760546, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3571004159239453, \"precision\": 0.999604064933351, \"recall\": 0.6428995840760546, \"specificity\": 0.9995725277856939, \"npv\": 0.6251113883443237, \"accuracy\": 0.7760519176551944, \"f1\": 0.782518855253642, \"f2\": 0.692309098553957, \"f0_5\": 0.8997600323124807, \"p4\": 0.7757964677215918, \"phi\": 0.6335315750457724}, {\"truth_threshold\": 5.68, \"match_probability\": 0.9808680078340698, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7564, \"tn\": 7015, \"fp\": 3, \"fn\": 4217, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6420507596978186, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3579492403021815, \"precision\": 0.9996035416941985, \"recall\": 0.6420507596978186, \"specificity\": 0.9995725277856939, \"npv\": 0.6245548433048433, \"accuracy\": 0.7755199744667269, \"f1\": 0.7818896009923506, \"f2\": 0.6915214569124719, \"f0_5\": 0.8994268591405266, \"p4\": 0.7752728374650737, \"phi\": 0.632830589410377}, {\"truth_threshold\": 5.7, \"match_probability\": 0.9811264324056064, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7557, \"tn\": 7015, \"fp\": 3, \"fn\": 4224, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6414565826330533, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3585434173669468, \"precision\": 0.9996031746031746, \"recall\": 0.6414565826330533, \"specificity\": 0.9995725277856939, \"npv\": 0.6241658510543643, \"accuracy\": 0.7751476142347997, \"f1\": 0.78144873584613, \"f2\": 0.6909699363616414, \"f0_5\": 0.8991932605126008, \"p4\": 0.7749062304253875, \"phi\": 0.6323401803017271}, {\"truth_threshold\": 5.72, \"match_probability\": 0.9813814325769498, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7547, \"tn\": 7015, \"fp\": 3, \"fn\": 4234, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6406077582548171, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3593922417451829, \"precision\": 0.9996026490066225, \"recall\": 0.6406077582548171, \"specificity\": 0.9995725277856939, \"npv\": 0.6236109876433461, \"accuracy\": 0.7746156710463322, \"f1\": 0.780818374631421, \"f2\": 0.6901818048798332, \"f0_5\": 0.8988590076463162, \"p4\": 0.7743824109535531, \"phi\": 0.6316399957055633}, {\"truth_threshold\": 5.74, \"match_probability\": 0.9816330519460089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7545, \"tn\": 7015, \"fp\": 3, \"fn\": 4236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6404379933791698, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.35956200662083015, \"precision\": 0.9996025437201908, \"recall\": 0.6404379933791698, \"specificity\": 0.9995725277856939, \"npv\": 0.6235001333214826, \"accuracy\": 0.7745092824086388, \"f1\": 0.7806922241191991, \"f2\": 0.6900241439859526, \"f0_5\": 0.8987920806232578, \"p4\": 0.7742776335252564, \"phi\": 0.631500015101079}, {\"truth_threshold\": 5.76, \"match_probability\": 0.9818813336034329, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7537, \"tn\": 7015, \"fp\": 3, \"fn\": 4244, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6397589338765809, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36024106612341905, \"precision\": 0.9996021220159151, \"recall\": 0.6397589338765809, \"specificity\": 0.9995725277856939, \"npv\": 0.6230571098676614, \"accuracy\": 0.7740837278578648, \"f1\": 0.7801873609026448, \"f2\": 0.6893933850431728, \"f0_5\": 0.8985241172122744, \"p4\": 0.7738584783337049, \"phi\": 0.6309402799295956}, {\"truth_threshold\": 5.78, \"match_probability\": 0.9821263201372112, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7534, \"tn\": 7015, \"fp\": 3, \"fn\": 4247, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6395042865631101, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3604957134368899, \"precision\": 0.999601963646013, \"recall\": 0.6395042865631101, \"specificity\": 0.9995725277856939, \"npv\": 0.6228911383413248, \"accuracy\": 0.7739241449013246, \"f1\": 0.7799979293922766, \"f2\": 0.6891568028393187, \"f0_5\": 0.8984235254835555, \"p4\": 0.7737012762789442, \"phi\": 0.6307304563537209}, {\"truth_threshold\": 5.8, \"match_probability\": 0.9823680536372692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7525, \"tn\": 7015, \"fp\": 3, \"fn\": 4256, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6387403446226976, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3612596553773024, \"precision\": 0.9996014877789585, \"recall\": 0.6387403446226976, \"specificity\": 0.9995725277856939, \"npv\": 0.6223937538816432, \"accuracy\": 0.7734453960317038, \"f1\": 0.7794292816821171, \"f2\": 0.6884469003879089, \"f0_5\": 0.8981214045305899, \"p4\": 0.7732296079030498, \"phi\": 0.6301012373648621}, {\"truth_threshold\": 5.82, \"match_probability\": 0.982606575700058, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7511, \"tn\": 7015, \"fp\": 3, \"fn\": 4270, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6375519904931669, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36244800950683304, \"precision\": 0.9996007452754858, \"recall\": 0.6375519904931669, \"specificity\": 0.9995725277856939, \"npv\": 0.6216216216216216, \"accuracy\": 0.7727006755678494, \"f1\": 0.7785436641617, \"f2\": 0.6873421428309967, \"f0_5\": 0.8976504051437723, \"p4\": 0.7724957141353005, \"phi\": 0.6291232003776154}, {\"truth_threshold\": 5.84, \"match_probability\": 0.9828419274331381, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7507, \"tn\": 7015, \"fp\": 3, \"fn\": 4274, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6372124607418725, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3627875392581275, \"precision\": 0.9996005326231691, \"recall\": 0.6372124607418725, \"specificity\": 0.9995725277856939, \"npv\": 0.6214013641598016, \"accuracy\": 0.7724878982924623, \"f1\": 0.7782903944844747, \"f2\": 0.6870263938206977, \"f0_5\": 0.8975156022094163, \"p4\": 0.7722859878499769, \"phi\": 0.62884392794917}, {\"truth_threshold\": 5.86, \"match_probability\": 0.9830741494597539, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7501, \"tn\": 7015, \"fp\": 3, \"fn\": 4280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6367031661149308, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36329683388506917, \"precision\": 0.9996002132196162, \"recall\": 0.6367031661149308, \"specificity\": 0.9995725277856939, \"npv\": 0.621071270473661, \"accuracy\": 0.7721687323793819, \"f1\": 0.7779102929738139, \"f2\": 0.686552683605477, \"f0_5\": 0.8973132042969592, \"p4\": 0.7719713627966993, \"phi\": 0.6284251578121854}, {\"truth_threshold\": 5.88, \"match_probability\": 0.9833032819233992, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7497, \"tn\": 7015, \"fp\": 3, \"fn\": 4284, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6363636363636364, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36363636363636365, \"precision\": 0.9996, \"recall\": 0.6363636363636364, \"specificity\": 0.9995725277856939, \"npv\": 0.620851402779007, \"accuracy\": 0.7719559551039948, \"f1\": 0.7776567605414657, \"f2\": 0.6862368189806678, \"f0_5\": 0.8971781431751275, \"p4\": 0.7717615888815168, \"phi\": 0.6281460698948557}, {\"truth_threshold\": 5.9, \"match_probability\": 0.9835293644923733, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7490, \"tn\": 7015, \"fp\": 3, \"fn\": 4291, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6357694592988711, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3642305407011289, \"precision\": 0.9995996263178967, \"recall\": 0.6357694592988711, \"specificity\": 0.9995725277856939, \"npv\": 0.6204670086679639, \"accuracy\": 0.7715835948720676, \"f1\": 0.7772128255681229, \"f2\": 0.6856839445593863, \"f0_5\": 0.8969415371350562, \"p4\": 0.7713944382584839, \"phi\": 0.6276578430934774}, {\"truth_threshold\": 5.92, \"match_probability\": 0.9837524363643234, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7485, \"tn\": 7015, \"fp\": 3, \"fn\": 4296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.635345047109753, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.364654952890247, \"precision\": 0.9995993589743589, \"recall\": 0.635345047109753, \"specificity\": 0.9995725277856939, \"npv\": 0.6201927327380427, \"accuracy\": 0.7713176232778339, \"f1\": 0.7768955316830142, \"f2\": 0.6852889474840694, \"f0_5\": 0.8967723384372079, \"p4\": 0.7711321515351114, \"phi\": 0.6273092473488769}, {\"truth_threshold\": 5.94, \"match_probability\": 0.9839725362707769, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7473, \"tn\": 7015, \"fp\": 3, \"fn\": 4308, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6343264578558696, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3656735421441304, \"precision\": 0.9995987158908507, \"recall\": 0.6343264578558696, \"specificity\": 0.9995725277856939, \"npv\": 0.6195354588006712, \"accuracy\": 0.7706792914516729, \"f1\": 0.7761333541050007, \"f2\": 0.6843406593406594, \"f0_5\": 0.89636559913638, \"p4\": 0.7705025389146583, \"phi\": 0.626473084268576}, {\"truth_threshold\": 5.96, \"match_probability\": 0.9841897024816576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7463, \"tn\": 7015, \"fp\": 3, \"fn\": 4318, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6334776334776335, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3665223665223665, \"precision\": 0.9995981784087865, \"recall\": 0.6334776334776335, \"specificity\": 0.9995725277856939, \"npv\": 0.6189887937880526, \"accuracy\": 0.7701473482632055, \"f1\": 0.775497480126773, \"f2\": 0.6835501007510533, \"f0_5\": 0.8960259334854124, \"p4\": 0.7699777260989433, \"phi\": 0.6257767832898584}, {\"truth_threshold\": 5.98, \"match_probability\": 0.9844039728097899, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7455, \"tn\": 7015, \"fp\": 3, \"fn\": 4326, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6327985739750446, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3672014260249554, \"precision\": 0.999597747385358, \"recall\": 0.6327985739750446, \"specificity\": 0.9995725277856939, \"npv\": 0.6185521558945419, \"accuracy\": 0.7697217937124315, \"f1\": 0.7749883050054577, \"f2\": 0.6829174453116412, \"f0_5\": 0.8957537308052772, \"p4\": 0.7695577860597327, \"phi\": 0.6252200695678317}, {\"truth_threshold\": 6.0, \"match_probability\": 0.9846153846153847, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7447, \"tn\": 7015, \"fp\": 3, \"fn\": 4334, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6321195144724556, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3678804855275444, \"precision\": 0.9995973154362416, \"recall\": 0.6321195144724556, \"specificity\": 0.9995725277856939, \"npv\": 0.6181161335800511, \"accuracy\": 0.7692962391616576, \"f1\": 0.774478706255525, \"f2\": 0.6822846043903691, \"f0_5\": 0.8954811091604339, \"p4\": 0.7691377654303845, \"phi\": 0.6246636456041181}, {\"truth_threshold\": 6.0200000000000005, \"match_probability\": 0.9848239748105114, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7436, \"tn\": 7015, \"fp\": 3, \"fn\": 4345, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6311858076563959, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36881419234360413, \"precision\": 0.9995967199892458, \"recall\": 0.6311858076563959, \"specificity\": 0.9995725277856939, \"npv\": 0.6175176056338029, \"accuracy\": 0.7687111016543433, \"f1\": 0.7737773152965661, \"f2\": 0.6814141451166541, \"f0_5\": 0.895105568529263, \"p4\": 0.7685601041505072, \"phi\": 0.6238990341453191}, {\"truth_threshold\": 6.04, \"match_probability\": 0.9850297798635513, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7433, \"tn\": 7015, \"fp\": 3, \"fn\": 4348, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6309311603429251, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36906883965707493, \"precision\": 0.999596557288865, \"recall\": 0.6309311603429251, \"specificity\": 0.9995725277856939, \"npv\": 0.6173545718560239, \"accuracy\": 0.768551518697803, \"f1\": 0.7735858874954468, \"f2\": 0.6811766862170088, \"f0_5\": 0.8950030102347983, \"p4\": 0.7684025332373824, \"phi\": 0.6236905982303793}, {\"truth_threshold\": 6.0600000000000005, \"match_probability\": 0.9852328358036327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7428, \"tn\": 7015, \"fp\": 3, \"fn\": 4353, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.630506748153807, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.369493251846193, \"precision\": 0.9995962858296327, \"recall\": 0.630506748153807, \"specificity\": 0.9995725277856939, \"npv\": 0.6170830401125967, \"accuracy\": 0.7682855471035693, \"f1\": 0.7732667083073079, \"f2\": 0.680780863348914, \"f0_5\": 0.8948319479580773, \"p4\": 0.7681398892240558, \"phi\": 0.6233432948035451}, {\"truth_threshold\": 6.08, \"match_probability\": 0.9854331782250482, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7423, \"tn\": 7015, \"fp\": 3, \"fn\": 4358, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6300823359646889, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.36991766403531107, \"precision\": 0.9995960140048479, \"recall\": 0.6300823359646889, \"specificity\": 0.9995725277856939, \"npv\": 0.6168117471203728, \"accuracy\": 0.7680195755093356, \"f1\": 0.7729473629405946, \"f2\": 0.68038496791934, \"f0_5\": 0.8946607207424371, \"p4\": 0.7678772127760727, \"phi\": 0.6229961033955023}, {\"truth_threshold\": 6.1000000000000005, \"match_probability\": 0.9856308422916512, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7413, \"tn\": 7015, \"fp\": 3, \"fn\": 4368, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6292335115864528, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37076648841354726, \"precision\": 0.9995954692556634, \"recall\": 0.6292335115864528, \"specificity\": 0.9995725277856939, \"npv\": 0.6162698761310726, \"accuracy\": 0.7674876323208681, \"f1\": 0.772308173152055, \"f2\": 0.6795929592959296, \"f0_5\": 0.8943177705392689, \"p4\": 0.7673517618656202, \"phi\": 0.6223020557729122}, {\"truth_threshold\": 6.12, \"match_probability\": 0.9858258627412329, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7405, \"tn\": 7015, \"fp\": 3, \"fn\": 4376, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6285544520838638, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37144554791613615, \"precision\": 0.9995950323974082, \"recall\": 0.6285544520838638, \"specificity\": 0.9995725277856939, \"npv\": 0.6158370643490475, \"accuracy\": 0.7670620777700942, \"f1\": 0.7717963416540726, \"f2\": 0.6789591432553364, \"f0_5\": 0.8940429333784078, \"p4\": 0.7669313062572592, \"phi\": 0.621747138509009}, {\"truth_threshold\": 6.140000000000001, \"match_probability\": 0.9860182738898777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7402, \"tn\": 7015, \"fp\": 3, \"fn\": 4379, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.628299804770393, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.371700195229607, \"precision\": 0.999594868332208, \"recall\": 0.628299804770393, \"specificity\": 0.9995725277856939, \"npv\": 0.615674916622784, \"accuracy\": 0.7669024948135539, \"f1\": 0.7716042947982904, \"f2\": 0.6787214142933118, \"f0_5\": 0.893939759909181, \"p4\": 0.7667736134959816, \"phi\": 0.6215391178606321}, {\"truth_threshold\": 6.16, \"match_probability\": 0.9862081096362973, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7398, \"tn\": 7015, \"fp\": 3, \"fn\": 4383, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6279602750190986, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37203972498090143, \"precision\": 0.9995946493717065, \"recall\": 0.6279602750190986, \"specificity\": 0.9995725277856939, \"npv\": 0.6154588524302509, \"accuracy\": 0.766689717538167, \"f1\": 0.7713481388802002, \"f2\": 0.678404401650619, \"f0_5\": 0.893802102210946, \"p4\": 0.7665633377921417, \"phi\": 0.6212618190913433}, {\"truth_threshold\": 6.18, \"match_probability\": 0.9863954034661423, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7382, \"tn\": 7015, \"fp\": 3, \"fn\": 4399, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6266021560139208, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3733978439860793, \"precision\": 0.9995937711577522, \"recall\": 0.6266021560139208, \"specificity\": 0.9995725277856939, \"npv\": 0.6145961100403013, \"accuracy\": 0.765838608436619, \"f1\": 0.7703224459981217, \"f2\": 0.677135885817021, \"f0_5\": 0.8932504053628906, \"p4\": 0.7657220196325584, \"phi\": 0.6201533315657621}, {\"truth_threshold\": 6.2, \"match_probability\": 0.9865801884562904, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7381, \"tn\": 7015, \"fp\": 3, \"fn\": 4400, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6265172735760971, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3734827264239029, \"precision\": 0.999593716143012, \"recall\": 0.6265172735760971, \"specificity\": 0.9995725277856939, \"npv\": 0.6145422689443715, \"accuracy\": 0.7657854141177722, \"f1\": 0.7702582833289852, \"f2\": 0.6770565788508109, \"f0_5\": 0.8932158675605683, \"p4\": 0.7656694257219969, \"phi\": 0.620084088581934}, {\"truth_threshold\": 6.22, \"match_probability\": 0.9867624972791117, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7378, \"tn\": 7015, \"fp\": 3, \"fn\": 4403, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6262626262626263, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37373737373737376, \"precision\": 0.9995935510093483, \"recall\": 0.6262626262626263, \"specificity\": 0.9995725277856939, \"npv\": 0.6143808022420739, \"accuracy\": 0.765625831161232, \"f1\": 0.770065755140382, \"f2\": 0.676818640491698, \"f0_5\": 0.8931122140176734, \"p4\": 0.765511635797068, \"phi\": 0.6198763860229083}, {\"truth_threshold\": 6.24, \"match_probability\": 0.9869423622067105, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7374, \"tn\": 7015, \"fp\": 3, \"fn\": 4407, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6259230965113318, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3740769034886682, \"precision\": 0.9995933306222041, \"recall\": 0.6259230965113318, \"specificity\": 0.9995725277856939, \"npv\": 0.6141656452460165, \"accuracy\": 0.765413053885845, \"f1\": 0.7698089570936424, \"f2\": 0.6765013485991083, \"f0_5\": 0.8929739155707331, \"p4\": 0.7653012300591268, \"phi\": 0.6195995107959623}, {\"truth_threshold\": 6.26, \"match_probability\": 0.9871198151151404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7371, \"tn\": 7015, \"fp\": 3, \"fn\": 4410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6256684491978609, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37433155080213903, \"precision\": 0.999593165174939, \"recall\": 0.6256684491978609, \"specificity\": 0.9995725277856939, \"npv\": 0.6140043763676148, \"accuracy\": 0.7652534709293047, \"f1\": 0.7696162881754112, \"f2\": 0.676263349113729, \"f0_5\": 0.8928701213750999, \"p4\": 0.7651434113266637, \"phi\": 0.6193919004546102}, {\"truth_threshold\": 6.28, \"match_probability\": 0.9872948874885967, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7357, \"tn\": 7015, \"fp\": 3, \"fn\": 4424, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6244800950683304, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37551990493166965, \"precision\": 0.9995923913043478, \"recall\": 0.6244800950683304, \"specificity\": 0.9995725277856939, \"npv\": 0.6132529067226156, \"accuracy\": 0.7645087504654503, \"f1\": 0.7687163680058513, \"f2\": 0.6751523383011526, \"f0_5\": 0.8923849494189855, \"p4\": 0.7644067591760988, \"phi\": 0.6184235729962779}, {\"truth_threshold\": 6.3, \"match_probability\": 0.9874676104235824, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7351, \"tn\": 7015, \"fp\": 3, \"fn\": 4430, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6239708004413886, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3760291995586113, \"precision\": 0.999592058743541, \"recall\": 0.6239708004413886, \"specificity\": 0.9995725277856939, \"npv\": 0.6129314110965487, \"accuracy\": 0.7641895845523698, \"f1\": 0.7683302848183956, \"f2\": 0.6746760160064613, \"f0_5\": 0.8921766148020487, \"p4\": 0.7640909673871361, \"phi\": 0.6180088373164987}, {\"truth_threshold\": 6.32, \"match_probability\": 0.9876380146330476, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7348, \"tn\": 7015, \"fp\": 3, \"fn\": 4433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6237161531279178, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37628384687208216, \"precision\": 0.9995918922595565, \"recall\": 0.6237161531279178, \"specificity\": 0.9995725277856939, \"npv\": 0.6127707896575821, \"accuracy\": 0.7640300015958296, \"f1\": 0.7681371524148024, \"f2\": 0.6744378155117026, \"f0_5\": 0.8920723564404516, \"p4\": 0.7639330525044858, \"phi\": 0.6178015282053412}, {\"truth_threshold\": 6.34, \"match_probability\": 0.9878061304505031, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7344, \"tn\": 7015, \"fp\": 3, \"fn\": 4437, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6233766233766234, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37662337662337664, \"precision\": 0.9995916700694161, \"recall\": 0.6233766233766234, \"specificity\": 0.9995725277856939, \"npv\": 0.6125567586447782, \"accuracy\": 0.7638172243204425, \"f1\": 0.767879548306148, \"f2\": 0.6741201740375613, \"f0_5\": 0.8919332507469212, \"p4\": 0.7637224795479763, \"phi\": 0.6175251768574733}, {\"truth_threshold\": 6.36, \"match_probability\": 0.9879719878341077, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7340, \"tn\": 7015, \"fp\": 3, \"fn\": 4441, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6230370936253289, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37696290637467106, \"precision\": 0.9995914476372055, \"recall\": 0.6230370936253289, \"specificity\": 0.9995725277856939, \"npv\": 0.612342877094972, \"accuracy\": 0.7636044470450556, \"f1\": 0.7676218364358921, \"f2\": 0.673802485908899, \"f0_5\": 0.8917940368867397, \"p4\": 0.7635118839007478, \"phi\": 0.6172488948956579}, {\"truth_threshold\": 6.38, \"match_probability\": 0.9881356163707273, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7330, \"tn\": 7015, \"fp\": 3, \"fn\": 4451, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6221882692470928, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.37781173075290725, \"precision\": 0.9995908904950225, \"recall\": 0.6221882692470928, \"specificity\": 0.9995725277856939, \"npv\": 0.6118088260945403, \"accuracy\": 0.7630725038565881, \"f1\": 0.7669770848592654, \"f2\": 0.6730080614062471, \"f0_5\": 0.891445528178435, \"p4\": 0.762985294898295, \"phi\": 0.6165584928393628}, {\"truth_threshold\": 6.4, \"match_probability\": 0.9882970452799678, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7323, \"tn\": 7015, \"fp\": 3, \"fn\": 4458, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6215940921823275, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3784059078176725, \"precision\": 0.9995904995904996, \"recall\": 0.6215940921823275, \"specificity\": 0.9995725277856939, \"npv\": 0.6114355443214503, \"accuracy\": 0.7627001436246609, \"f1\": 0.7665253571989323, \"f2\": 0.6724517906336088, \"f0_5\": 0.891201168309602, \"p4\": 0.7626165970862839, \"phi\": 0.616075468111836}, {\"truth_threshold\": 6.42, \"match_probability\": 0.9884563034181787, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7319, \"tn\": 7015, \"fp\": 3, \"fn\": 4462, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.621254562431033, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.378745437568967, \"precision\": 0.9995902758809069, \"recall\": 0.621254562431033, \"specificity\": 0.9995725277856939, \"npv\": 0.6112224448897795, \"accuracy\": 0.7624873663492739, \"f1\": 0.7662670784693504, \"f2\": 0.6721338573999927, \"f0_5\": 0.8910613844992573, \"p4\": 0.7624058807795675, \"phi\": 0.6157995486385383}, {\"truth_threshold\": 6.44, \"match_probability\": 0.9886134192824297, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7310, \"tn\": 7015, \"fp\": 3, \"fn\": 4471, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6204906204906205, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3795093795093795, \"precision\": 0.999589771639546, \"recall\": 0.6204906204906205, \"specificity\": 0.9995725277856939, \"npv\": 0.6107435138429392, \"accuracy\": 0.7620086174796532, \"f1\": 0.7656855556719389, \"f2\": 0.67141833679299, \"f0_5\": 0.8907464723515219, \"p4\": 0.7619316838444827, \"phi\": 0.6151789808617459}, {\"truth_threshold\": 6.46, \"match_probability\": 0.9887684210144592, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7295, \"tn\": 7015, \"fp\": 3, \"fn\": 4486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6192173839232663, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38078261607673375, \"precision\": 0.9995889284735544, \"recall\": 0.6192173839232663, \"specificity\": 0.9995725277856939, \"npv\": 0.6099469611338144, \"accuracy\": 0.761210702696952, \"f1\": 0.764715131820326, \"f2\": 0.6702252765425747, \"f0_5\": 0.8902203890366827, \"p4\": 0.7611410908549785, \"phi\": 0.6141454708076794}, {\"truth_threshold\": 6.48, \"match_probability\": 0.9889213364045922, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7287, \"tn\": 7015, \"fp\": 3, \"fn\": 4494, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6185383244206774, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38146167557932265, \"precision\": 0.9995884773662551, \"recall\": 0.6185383244206774, \"specificity\": 0.9995725277856939, \"npv\": 0.609522982014076, \"accuracy\": 0.760785148146178, \"f1\": 0.764196948246028, \"f2\": 0.6695887087881796, \"f0_5\": 0.8899391807723309, \"p4\": 0.7607193044884217, \"phi\": 0.6135946571200266}, {\"truth_threshold\": 6.5, \"match_probability\": 0.989072192895632, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7270, \"tn\": 7015, \"fp\": 3, \"fn\": 4511, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6170953229776759, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38290467702232406, \"precision\": 0.9995875154681699, \"recall\": 0.6170953229776759, \"specificity\": 0.9995725277856939, \"npv\": 0.6086239805656776, \"accuracy\": 0.7598808447257833, \"f1\": 0.763094363388265, \"f2\": 0.6682353806276081, \"f0_5\": 0.8893401512000587, \"p4\": 0.7598226883481888, \"phi\": 0.6124250779228155}, {\"truth_threshold\": 6.5200000000000005, \"match_probability\": 0.9892210175867204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7265, \"tn\": 7015, \"fp\": 3, \"fn\": 4516, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6166709107885578, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38332908921144215, \"precision\": 0.9995872317006054, \"recall\": 0.6166709107885578, \"specificity\": 0.9995725277856939, \"npv\": 0.6083600728471078, \"accuracy\": 0.7596148731315495, \"f1\": 0.7627696991968083, \"f2\": 0.6678371819385204, \"f0_5\": 0.889163586517514, \"p4\": 0.7595588940486808, \"phi\": 0.6120813160246199}, {\"truth_threshold\": 6.54, \"match_probability\": 0.9893678372371703, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7256, \"tn\": 7015, \"fp\": 3, \"fn\": 4525, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6159069688481453, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38409303115185467, \"precision\": 0.9995867199338752, \"recall\": 0.6159069688481453, \"specificity\": 0.9995725277856939, \"npv\": 0.6078856152512998, \"accuracy\": 0.7591361242619288, \"f1\": 0.7621848739495798, \"f2\": 0.6671202397808138, \"f0_5\": 0.8888453340519882, \"p4\": 0.7590839674984996, \"phi\": 0.6114628092359783}, {\"truth_threshold\": 6.5600000000000005, \"match_probability\": 0.9895126782702673, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7251, \"tn\": 7015, \"fp\": 3, \"fn\": 4530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6154825566590273, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38451744334097276, \"precision\": 0.9995864350703061, \"recall\": 0.6154825566590273, \"specificity\": 0.9995725277856939, \"npv\": 0.6076223473365093, \"accuracy\": 0.7588701526676951, \"f1\": 0.761859732072498, \"f2\": 0.6667218360366325, \"f0_5\": 0.8886682844326789, \"p4\": 0.7588200652996132, \"phi\": 0.6111193409955212}, {\"truth_threshold\": 6.58, \"match_probability\": 0.9896555667770431, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7242, \"tn\": 7015, \"fp\": 3, \"fn\": 4539, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6147186147186147, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3852813852813853, \"precision\": 0.9995859213250518, \"recall\": 0.6147186147186147, \"specificity\": 0.9995725277856939, \"npv\": 0.6071490392937511, \"accuracy\": 0.7583914037980743, \"f1\": 0.761274046042258, \"f2\": 0.6660045246372014, \"f0_5\": 0.8883491572826967, \"p4\": 0.758344943209808, \"phi\": 0.6105013613054692}, {\"truth_threshold\": 6.6000000000000005, \"match_probability\": 0.9897965285200179, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7240, \"tn\": 7015, \"fp\": 3, \"fn\": 4541, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6145488498429675, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3854511501570325, \"precision\": 0.9995858069860555, \"recall\": 0.6145488498429675, \"specificity\": 0.9995725277856939, \"npv\": 0.6070439598476982, \"accuracy\": 0.7582850151603808, \"f1\": 0.7611438183347351, \"f2\": 0.6658450898523001, \"f0_5\": 0.88827816357078, \"p4\": 0.7582393433009447, \"phi\": 0.6103640783323495}, {\"truth_threshold\": 6.62, \"match_probability\": 0.9899355889369128, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7235, \"tn\": 7015, \"fp\": 3, \"fn\": 4546, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6141244376538494, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38587556234615056, \"precision\": 0.9995855208621166, \"recall\": 0.6141244376538494, \"specificity\": 0.9995725277856939, \"npv\": 0.6067814202923623, \"accuracy\": 0.7580190435661471, \"f1\": 0.7608181292391819, \"f2\": 0.6654464515654317, \"f0_5\": 0.8881005572877029, \"p4\": 0.7579753159893495, \"phi\": 0.6100209436809214}, {\"truth_threshold\": 6.640000000000001, \"match_probability\": 0.9900727731443332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7228, \"tn\": 7015, \"fp\": 3, \"fn\": 4553, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6135302605890841, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3864697394109159, \"precision\": 0.9995851196238418, \"recall\": 0.6135302605890841, \"specificity\": 0.9995725277856939, \"npv\": 0.6064142461964038, \"accuracy\": 0.7576466833342199, \"f1\": 0.7603618767094467, \"f2\": 0.6648882347530126, \"f0_5\": 0.887851615280678, \"p4\": 0.7576056113630457, \"phi\": 0.6095407295150505}, {\"truth_threshold\": 6.66, \"match_probability\": 0.9902081059414205, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7224, \"tn\": 7015, \"fp\": 3, \"fn\": 4557, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6131907308377896, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3868092691622103, \"precision\": 0.9995848899958489, \"recall\": 0.6131907308377896, \"specificity\": 0.9995725277856939, \"npv\": 0.6062046318700312, \"accuracy\": 0.7574339060588329, \"f1\": 0.76010101010101, \"f2\": 0.6645691891593531, \"f0_5\": 0.887709208877092, \"p4\": 0.7573943166237276, \"phi\": 0.6092664125474985}, {\"truth_threshold\": 6.68, \"match_probability\": 0.9903416118134748, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7216, \"tn\": 7015, \"fp\": 3, \"fn\": 4565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6125116713352008, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38748832866479926, \"precision\": 0.999584429976451, \"recall\": 0.6125116713352008, \"specificity\": 0.9995725277856939, \"npv\": 0.6057858376511226, \"accuracy\": 0.7570083515080589, \"f1\": 0.759578947368421, \"f2\": 0.6639309570689877, \"f0_5\": 0.8874240598174976, \"p4\": 0.7569716504245526, \"phi\": 0.6087179769256245}, {\"truth_threshold\": 6.7, \"match_probability\": 0.9904733149355459, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7201, \"tn\": 7015, \"fp\": 3, \"fn\": 4580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6112384347678466, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3887615652321535, \"precision\": 0.9995835646862854, \"recall\": 0.6112384347678466, \"specificity\": 0.9995725277856939, \"npv\": 0.605002156101768, \"accuracy\": 0.7562104367253577, \"f1\": 0.7585988938635765, \"f2\": 0.6627337652775732, \"f0_5\": 0.8868881937088947, \"p4\": 0.7561788732322893, \"phi\": 0.6076903702221033}, {\"truth_threshold\": 6.72, \"match_probability\": 0.9906032391759949, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7188, \"tn\": 7015, \"fp\": 3, \"fn\": 4593, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6101349630761396, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.38986503692386043, \"precision\": 0.9995828118481435, \"recall\": 0.6101349630761396, \"specificity\": 0.9995725277856939, \"npv\": 0.6043246037215714, \"accuracy\": 0.75551891058035, \"f1\": 0.7577482605945604, \"f2\": 0.6616956641811654, \"f0_5\": 0.8864224935257121, \"p4\": 0.7554915029601501, \"phi\": 0.6068005232857544}, {\"truth_threshold\": 6.74, \"match_probability\": 0.9907314081000241, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7182, \"tn\": 7015, \"fp\": 3, \"fn\": 4599, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6096256684491979, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39037433155080214, \"precision\": 0.9995824634655532, \"recall\": 0.6096256684491979, \"specificity\": 0.9995725277856939, \"npv\": 0.6040123988289995, \"accuracy\": 0.7551997446672696, \"f1\": 0.7573552673204682, \"f2\": 0.6612163729768546, \"f0_5\": 0.8862071518471903, \"p4\": 0.7551741612318066, \"phi\": 0.6063900571138098}, {\"truth_threshold\": 6.76, \"match_probability\": 0.9908578449731781, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7156, \"tn\": 7015, \"fp\": 3, \"fn\": 4625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6074187250657839, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39258127493421613, \"precision\": 0.9995809470596452, \"recall\": 0.6074187250657839, \"specificity\": 0.9995725277856939, \"npv\": 0.6026632302405498, \"accuracy\": 0.7538166923772541, \"f1\": 0.755649419218585, \"f2\": 0.6591382200688982, \"f0_5\": 0.8852710493109335, \"p4\": 0.7537983187884133, \"phi\": 0.6046130561788696}, {\"truth_threshold\": 6.78, \"match_probability\": 0.9909825727648117, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7144, \"tn\": 7015, \"fp\": 3, \"fn\": 4637, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6064001358119006, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3935998641880995, \"precision\": 0.9995802434587939, \"recall\": 0.6064001358119006, \"specificity\": 0.9995725277856939, \"npv\": 0.6020425677995194, \"accuracy\": 0.7531783605510931, \"f1\": 0.7548605240912933, \"f2\": 0.6581784009876361, \"f0_5\": 0.884837375213654, \"p4\": 0.7531629285418007, \"phi\": 0.6037938202890727}, {\"truth_threshold\": 6.8, \"match_probability\": 0.9911056141515298, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7143, \"tn\": 7015, \"fp\": 3, \"fn\": 4638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6063152533740769, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3936847466259231, \"precision\": 0.9995801847187238, \"recall\": 0.6063152533740769, \"specificity\": 0.9995725277856939, \"npv\": 0.6019909036299665, \"accuracy\": 0.7531251662322463, \"f1\": 0.7547947376763354, \"f2\": 0.658098396904367, \"f0_5\": 0.8848011891490153, \"p4\": 0.7531099682182892, \"phi\": 0.6037255766732568}, {\"truth_threshold\": 6.82, \"match_probability\": 0.9912269915205945, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7135, \"tn\": 7015, \"fp\": 3, \"fn\": 4646, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.605636193871488, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.394363806128512, \"precision\": 0.9995797142056598, \"recall\": 0.605636193871488, \"specificity\": 0.9995725277856939, \"npv\": 0.6015779092702169, \"accuracy\": 0.7526996116814724, \"f1\": 0.7542681959934457, \"f2\": 0.6574582580811618, \"f0_5\": 0.8845114422433243, \"p4\": 0.7526862235609453, \"phi\": 0.6031797715592798}, {\"truth_threshold\": 6.84, \"match_probability\": 0.9913467269733026, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7130, \"tn\": 7015, \"fp\": 3, \"fn\": 4651, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6052117816823699, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39478821831763006, \"precision\": 0.9995794195990467, \"recall\": 0.6052117816823699, \"specificity\": 0.9995725277856939, \"npv\": 0.6013200754328819, \"accuracy\": 0.7524336400872387, \"f1\": 0.7539388812519826, \"f2\": 0.6570580754557016, \"f0_5\": 0.8843301168357601, \"p4\": 0.7524213268793449, \"phi\": 0.6028387729423127}, {\"truth_threshold\": 6.86, \"match_probability\": 0.9914648423283329, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7127, \"tn\": 7015, \"fp\": 3, \"fn\": 4654, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6049571343688991, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3950428656311009, \"precision\": 0.9995792426367461, \"recall\": 0.6049571343688991, \"specificity\": 0.9995725277856939, \"npv\": 0.6011654811894764, \"accuracy\": 0.7522740571306984, \"f1\": 0.7537412088202633, \"f2\": 0.6568179304751723, \"f0_5\": 0.8842212352050818, \"p4\": 0.7522623679937543, \"phi\": 0.6026342215107109}, {\"truth_threshold\": 6.88, \"match_probability\": 0.9915813591250612, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7121, \"tn\": 7015, \"fp\": 3, \"fn\": 4660, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6044478397419574, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39555216025804263, \"precision\": 0.9995788882650196, \"recall\": 0.6044478397419574, \"specificity\": 0.9995725277856939, \"npv\": 0.6008565310492505, \"accuracy\": 0.7519548912176179, \"f1\": 0.7533456757471568, \"f2\": 0.6563375608317358, \"f0_5\": 0.8840032773046652, \"p4\": 0.7519444030534469, \"phi\": 0.6022252258506156}, {\"truth_threshold\": 6.9, \"match_probability\": 0.9916962986268459, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7117, \"tn\": 7015, \"fp\": 3, \"fn\": 4664, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6041083099906629, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39589169000933705, \"precision\": 0.9995786516853933, \"recall\": 0.6041083099906629, \"specificity\": 0.9995725277856939, \"npv\": 0.6006507406456032, \"accuracy\": 0.751742113942231, \"f1\": 0.7530818475212951, \"f2\": 0.6560172553646486, \"f0_5\": 0.8838578276744243, \"p4\": 0.7517323913509787, \"phi\": 0.601952641343461}, {\"truth_threshold\": 6.92, \"match_probability\": 0.9918096818242835, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7107, \"tn\": 7015, \"fp\": 3, \"fn\": 4674, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6032594856124268, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3967405143875732, \"precision\": 0.9995780590717299, \"recall\": 0.6032594856124268, \"specificity\": 0.9995725277856939, \"npv\": 0.600136880828129, \"accuracy\": 0.7512101707537635, \"f1\": 0.7524217881530888, \"f2\": 0.6552162849872774, \"f0_5\": 0.8834936973222943, \"p4\": 0.7512022385992017, \"phi\": 0.6012714567354457}, {\"truth_threshold\": 6.94, \"match_probability\": 0.9919215294384318, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7101, \"tn\": 7015, \"fp\": 3, \"fn\": 4680, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6027501909854851, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3972498090145149, \"precision\": 0.9995777027027027, \"recall\": 0.6027501909854851, \"specificity\": 0.9995725277856939, \"npv\": 0.5998289867464729, \"accuracy\": 0.750891004840683, \"f1\": 0.7520254169976172, \"f2\": 0.6547355609648152, \"f0_5\": 0.8832748712590491, \"p4\": 0.750884061763084, \"phi\": 0.6008629351513198}, {\"truth_threshold\": 6.96, \"match_probability\": 0.9920318619240045, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7099, \"tn\": 7015, \"fp\": 3, \"fn\": 4682, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6025804261098379, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39741957389016214, \"precision\": 0.9995775837792171, \"recall\": 0.6025804261098379, \"specificity\": 0.9995725277856939, \"npv\": 0.5997264255792083, \"accuracy\": 0.7507846162029895, \"f1\": 0.7518932373033946, \"f2\": 0.6545752959834765, \"f0_5\": 0.8832018711587748, \"p4\": 0.750777988544713, \"phi\": 0.6007267927407695}, {\"truth_threshold\": 6.98, \"match_probability\": 0.9921406994725337, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7095, \"tn\": 7015, \"fp\": 3, \"fn\": 4686, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6022408963585434, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39775910364145656, \"precision\": 0.9995773457311918, \"recall\": 0.6022408963585434, \"specificity\": 0.9995725277856939, \"npv\": 0.5995214084266302, \"accuracy\": 0.7505718389276025, \"f1\": 0.7516287938979819, \"f2\": 0.6542547305521744, \"f0_5\": 0.8830557837353447, \"p4\": 0.7505658206228455, \"phi\": 0.6004545550166687}, {\"truth_threshold\": 7.0, \"match_probability\": 0.9922480620155039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7091, \"tn\": 7015, \"fp\": 3, \"fn\": 4690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6019013666072489, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.39809863339275103, \"precision\": 0.9995771074147166, \"recall\": 0.6019013666072489, \"specificity\": 0.9995725277856939, \"npv\": 0.5993165313968389, \"accuracy\": 0.7503590616522156, \"f1\": 0.7513642384105961, \"f2\": 0.6539341178206499, \"f0_5\": 0.8829095798988968, \"p4\": 0.7503536239700014, \"phi\": 0.6001823800005686}, {\"truth_threshold\": 7.0200000000000005, \"match_probability\": 0.9923539692274538, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7087, \"tn\": 7015, \"fp\": 3, \"fn\": 4694, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6015618368559545, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3984381631440455, \"precision\": 0.999576868829337, \"recall\": 0.6015618368559545, \"specificity\": 0.9995725277856939, \"npv\": 0.5991117943462294, \"accuracy\": 0.7501462843768285, \"f1\": 0.7510995707699645, \"f2\": 0.6536134577784336, \"f0_5\": 0.8827632595102265, \"p4\": 0.7501413984850919, \"phi\": 0.5999102675869133}, {\"truth_threshold\": 7.04, \"match_probability\": 0.9924584405290495, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7073, \"tn\": 7015, \"fp\": 3, \"fn\": 4708, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6003734827264239, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3996265172735761, \"precision\": 0.999576031656303, \"recall\": 0.6003734827264239, \"specificity\": 0.9995725277856939, \"npv\": 0.5983963149364497, \"accuracy\": 0.7494015639129741, \"f1\": 0.7501723497905287, \"f2\": 0.6524907749077491, \"f0_5\": 0.8822502182861419, \"p4\": 0.7493983807727613, \"phi\": 0.5989583656105751}, {\"truth_threshold\": 7.0600000000000005, \"match_probability\": 0.9925614950901266, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7072, \"tn\": 7015, \"fp\": 3, \"fn\": 4709, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.6002886002886003, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.3997113997113997, \"precision\": 0.9995759717314487, \"recall\": 0.6002886002886003, \"specificity\": 0.9995725277856939, \"npv\": 0.59834527465029, \"accuracy\": 0.7493483695941273, \"f1\": 0.7501060670343657, \"f2\": 0.6524105610804627, \"f0_5\": 0.8822135176268057, \"p4\": 0.7493452944015976, \"phi\": 0.5988904017882886}, {\"truth_threshold\": 7.08, \"match_probability\": 0.9926631518327027, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7068, \"tn\": 7015, \"fp\": 3, \"fn\": 4713, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5999490705373058, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40005092946269416, \"precision\": 0.9995757318625371, \"recall\": 0.5999490705373058, \"specificity\": 0.9995725277856939, \"npv\": 0.5981412005457026, \"accuracy\": 0.7491355923187404, \"f1\": 0.7498408656906429, \"f2\": 0.6520896761693883, \"f0_5\": 0.8820666417072257, \"p4\": 0.7491329305797368, \"phi\": 0.5986185852962704}, {\"truth_threshold\": 7.1000000000000005, \"match_probability\": 0.9927634294339601, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7059, \"tn\": 7015, \"fp\": 3, \"fn\": 4722, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5991851285968933, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4008148714031067, \"precision\": 0.9995751911639762, \"recall\": 0.5991851285968933, \"specificity\": 0.9995725277856939, \"npv\": 0.5976825423873221, \"accuracy\": 0.7486568434491196, \"f1\": 0.7492437509950645, \"f2\": 0.6513675119034437, \"f0_5\": 0.8817357415873491, \"p4\": 0.7486550042730764, \"phi\": 0.5980072247034739}, {\"truth_threshold\": 7.12, \"match_probability\": 0.9928623463291987, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7058, \"tn\": 7015, \"fp\": 3, \"fn\": 4723, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5991002461590696, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4008997538409303, \"precision\": 0.9995751310012746, \"recall\": 0.5991002461590696, \"specificity\": 0.9995725277856939, \"npv\": 0.5976316237859942, \"accuracy\": 0.7486036491302729, \"f1\": 0.749177369705976, \"f2\": 0.651287256620836, \"f0_5\": 0.8816989381636477, \"p4\": 0.7486018921071363, \"phi\": 0.597939315070555}, {\"truth_threshold\": 7.140000000000001, \"match_probability\": 0.9929599207147589, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7051, \"tn\": 7015, \"fp\": 3, \"fn\": 4730, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5985060690943044, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40149393090569563, \"precision\": 0.9995747093847462, \"recall\": 0.5985060690943044, \"specificity\": 0.9995725277856939, \"npv\": 0.5972754363558961, \"accuracy\": 0.7482312888983457, \"f1\": 0.7487125033182904, \"f2\": 0.6507253866883237, \"f0_5\": 0.8814411080831063, \"p4\": 0.7482300549314018, \"phi\": 0.5974640555817445}, {\"truth_threshold\": 7.16, \"match_probability\": 0.9930561705509157, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7049, \"tn\": 7015, \"fp\": 3, \"fn\": 4732, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5983363042186571, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40166369578134287, \"precision\": 0.9995745887691435, \"recall\": 0.5983363042186571, \"specificity\": 0.9995725277856939, \"npv\": 0.5971737464884651, \"accuracy\": 0.7481249002606521, \"f1\": 0.7485796208782456, \"f2\": 0.650564825753101, \"f0_5\": 0.8813673760284079, \"p4\": 0.7481237989714964, \"phi\": 0.5973283018026332}, {\"truth_threshold\": 7.18, \"match_probability\": 0.9931511135647422, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7044, \"tn\": 7015, \"fp\": 3, \"fn\": 4737, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5979118920295391, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4020881079704609, \"precision\": 0.9995742869306088, \"recall\": 0.5979118920295391, \"specificity\": 0.9995725277856939, \"npv\": 0.5969196732471069, \"accuracy\": 0.7478589286664185, \"f1\": 0.7482472912683238, \"f2\": 0.650163371545661, \"f0_5\": 0.8811829167604894, \"p4\": 0.7478581263387065, \"phi\": 0.5969889845885543}, {\"truth_threshold\": 7.2, \"match_probability\": 0.9932447672529455, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7043, \"tn\": 7015, \"fp\": 3, \"fn\": 4738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5978270095917154, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4021729904082845, \"precision\": 0.9995742265114959, \"recall\": 0.5978270095917154, \"specificity\": 0.9995725277856939, \"npv\": 0.5968688845401174, \"accuracy\": 0.7478057343475717, \"f1\": 0.7481808041642323, \"f2\": 0.6500830718109655, \"f0_5\": 0.8811460027524084, \"p4\": 0.7478049861879394, \"phi\": 0.5969211326583912}, {\"truth_threshold\": 7.22, \"match_probability\": 0.9933371488846718, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7036, \"tn\": 7015, \"fp\": 3, \"fn\": 4745, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5972328325269501, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4027671674730498, \"precision\": 0.9995738030970308, \"recall\": 0.5972328325269501, \"specificity\": 0.9995725277856939, \"npv\": 0.5965136054421769, \"accuracy\": 0.7474333741156445, \"f1\": 0.7477151965993624, \"f2\": 0.6495208906449051, \"f0_5\": 0.8808873976513008, \"p4\": 0.7474329524450702, \"phi\": 0.596446276399704}, {\"truth_threshold\": 7.24, \"match_probability\": 0.993428275504284, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7030, \"tn\": 7015, \"fp\": 3, \"fn\": 4751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5967235379000085, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4032764620999915, \"precision\": 0.9995734394995024, \"recall\": 0.5967235379000085, \"specificity\": 0.9995725277856939, \"npv\": 0.596209416964134, \"accuracy\": 0.7471142082025639, \"f1\": 0.7473158286382481, \"f2\": 0.6490389054046568, \"f0_5\": 0.8806654473479819, \"p4\": 0.7471139927008015, \"phi\": 0.5960394058384528}, {\"truth_threshold\": 7.26, \"match_probability\": 0.9935181639341092, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7028, \"tn\": 7015, \"fp\": 3, \"fn\": 4753, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5965537730243613, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40344622697563876, \"precision\": 0.9995733181624236, \"recall\": 0.5965537730243613, \"specificity\": 0.9995725277856939, \"npv\": 0.5961080897348743, \"accuracy\": 0.7470078195648705, \"f1\": 0.7471826493727408, \"f2\": 0.6488782199242914, \"f0_5\": 0.8805914045858915, \"p4\": 0.7470076576079774, \"phi\": 0.595903812834875}, {\"truth_threshold\": 7.28, \"match_probability\": 0.9936068307771581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7011, \"tn\": 7015, \"fp\": 3, \"fn\": 4770, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5951107715813598, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40488922841864017, \"precision\": 0.9995722840034217, \"recall\": 0.5951107715813598, \"specificity\": 0.9995725277856939, \"npv\": 0.5952481968604157, \"accuracy\": 0.7461035161444758, \"f1\": 0.746049481245012, \"f2\": 0.6475119139975618, \"f0_5\": 0.8799608404247308, \"p4\": 0.7461035007378295, \"phi\": 0.5947518861602747}, {\"truth_threshold\": 7.3, \"match_probability\": 0.9936942924198163, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7008, \"tn\": 7015, \"fp\": 3, \"fn\": 4773, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5948561242678889, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.405143875732111, \"precision\": 0.9995721009841677, \"recall\": 0.5948561242678889, \"specificity\": 0.9995725277856939, \"npv\": 0.595096708517136, \"accuracy\": 0.7459439331879355, \"f1\": 0.7458492975734355, \"f2\": 0.6472707121086173, \"f0_5\": 0.87984934086629, \"p4\": 0.7459438859653188, \"phi\": 0.5945487186515239}, {\"truth_threshold\": 7.32, \"match_probability\": 0.9937805650345067, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6998, \"tn\": 7015, \"fp\": 3, \"fn\": 4783, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5940072998896528, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40599270011034716, \"precision\": 0.9995714897871733, \"recall\": 0.5940072998896528, \"specificity\": 0.9995725277856939, \"npv\": 0.5945923037803017, \"accuracy\": 0.745411989999468, \"f1\": 0.7451815568097114, \"f2\": 0.6464665127020786, \"f0_5\": 0.8794771898956893, \"p4\": 0.7454117106998154, \"phi\": 0.5938717388432556}, {\"truth_threshold\": 7.34, \"match_probability\": 0.9938656645823235, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6994, \"tn\": 7015, \"fp\": 3, \"fn\": 4787, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5936677701383584, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40633222986164164, \"precision\": 0.9995712448192082, \"recall\": 0.5936677701383584, \"specificity\": 0.9995725277856939, \"npv\": 0.5943907812235214, \"accuracy\": 0.7451992127240811, \"f1\": 0.744914261369688, \"f2\": 0.6461447497274625, \"f0_5\": 0.8793281198923785, \"p4\": 0.7451987860480968, \"phi\": 0.593601052294521}, {\"truth_threshold\": 7.36, \"match_probability\": 0.9939496068156388, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6974, \"tn\": 7015, \"fp\": 3, \"fn\": 4807, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5919701213818861, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4080298786181139, \"precision\": 0.9995700157660886, \"recall\": 0.5919701213818861, \"specificity\": 0.9995725277856939, \"npv\": 0.5933852140077821, \"accuracy\": 0.7441353263471461, \"f1\": 0.7435760742083378, \"f2\": 0.6445352211604222, \"f0_5\": 0.8785809670185694, \"p4\": 0.7441336908138121, \"phi\": 0.5922485183250411}, {\"truth_threshold\": 7.38, \"match_probability\": 0.994032407280681, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6967, \"tn\": 7015, \"fp\": 3, \"fn\": 4814, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5913759443171208, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40862405568287924, \"precision\": 0.9995695839311334, \"recall\": 0.5913759443171208, \"specificity\": 0.9995725277856939, \"npv\": 0.5930340688139318, \"accuracy\": 0.7437629661152189, \"f1\": 0.7431070342915045, \"f2\": 0.6439716049839169, \"f0_5\": 0.8783187514182699, \"p4\": 0.7437607200408374, \"phi\": 0.59177548373707}, {\"truth_threshold\": 7.4, \"match_probability\": 0.9941140813200855, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6957, \"tn\": 7015, \"fp\": 3, \"fn\": 4824, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5905271199388846, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4094728800611154, \"precision\": 0.9995689655172414, \"recall\": 0.5905271199388846, \"specificity\": 0.9995725277856939, \"npv\": 0.592533153137934, \"accuracy\": 0.7432310229267515, \"f1\": 0.7424363694573395, \"f2\": 0.6431661859329931, \"f0_5\": 0.8779435148027561, \"p4\": 0.7432277343288489, \"phi\": 0.5911000352185708}, {\"truth_threshold\": 7.42, \"match_probability\": 0.9941946440754179, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6951, \"tn\": 7015, \"fp\": 3, \"fn\": 4830, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5900178253119429, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.40998217468805703, \"precision\": 0.9995685936151855, \"recall\": 0.5900178253119429, \"specificity\": 0.9995725277856939, \"npv\": 0.5922330097087378, \"accuracy\": 0.7429118570136709, \"f1\": 0.7420336269015212, \"f2\": 0.6426827915233552, \"f0_5\": 0.8777180089400712, \"p4\": 0.7429078461122776, \"phi\": 0.5906949434924084}, {\"truth_threshold\": 7.44, \"match_probability\": 0.9942741104896703, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6943, \"tn\": 7015, \"fp\": 3, \"fn\": 4838, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5893387658093541, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.41066123419064593, \"precision\": 0.9995680967463288, \"recall\": 0.5893387658093541, \"specificity\": 0.9995725277856939, \"npv\": 0.5918332911499199, \"accuracy\": 0.7424863024628969, \"f1\": 0.7414962353820687, \"f2\": 0.6420380987608656, \"f0_5\": 0.8774169088841147, \"p4\": 0.7424812148276678, \"phi\": 0.5901550274121933}, {\"truth_threshold\": 7.46, \"match_probability\": 0.9943524953097296, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6938, \"tn\": 7015, \"fp\": 3, \"fn\": 4843, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5889143536202359, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.411085646379764, \"precision\": 0.9995677856216684, \"recall\": 0.5889143536202359, \"specificity\": 0.9995725277856939, \"npv\": 0.5915837409343903, \"accuracy\": 0.7422203308686632, \"f1\": 0.7411601324644803, \"f2\": 0.641635068898548, \"f0_5\": 0.8772284738905045, \"p4\": 0.7422145039683676, \"phi\": 0.589817699209959}, {\"truth_threshold\": 7.48, \"match_probability\": 0.9944298130888198, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6937, \"tn\": 7015, \"fp\": 3, \"fn\": 4844, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5888294711824124, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.41117052881758764, \"precision\": 0.9995677233429395, \"recall\": 0.5888294711824124, \"specificity\": 0.9995725277856939, \"npv\": 0.5915338561430138, \"accuracy\": 0.7421671365498165, \"f1\": 0.7410928903370546, \"f2\": 0.6415544539804676, \"f0_5\": 0.8771907640170962, \"p4\": 0.7421611556526428, \"phi\": 0.589750244563527}, {\"truth_threshold\": 7.5, \"match_probability\": 0.994506078188917, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6932, \"tn\": 7015, \"fp\": 3, \"fn\": 4849, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5884050589932943, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.41159494100670574, \"precision\": 0.9995674116798846, \"recall\": 0.5884050589932943, \"specificity\": 0.9995725277856939, \"npv\": 0.5912845583277141, \"accuracy\": 0.7419011649555828, \"f1\": 0.7407565719170763, \"f2\": 0.6411513346528792, \"f0_5\": 0.8770021001492877, \"p4\": 0.7418943832631195, \"phi\": 0.5894130262122471}, {\"truth_threshold\": 7.5200000000000005, \"match_probability\": 0.9945813047831374, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6923, \"tn\": 7015, \"fp\": 3, \"fn\": 4858, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5876411170528818, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.41235888294711825, \"precision\": 0.9995668495524112, \"recall\": 0.5876411170528818, \"specificity\": 0.9995725277856939, \"npv\": 0.5908363513854965, \"accuracy\": 0.741422416085962, \"f1\": 0.7401507457101619, \"f2\": 0.6404255319148936, \"f0_5\": 0.8766620235532481, \"p4\": 0.7414140630308083, \"phi\": 0.5888062631690587}, {\"truth_threshold\": 7.54, \"match_probability\": 0.9946555068581004, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6918, \"tn\": 7015, \"fp\": 3, \"fn\": 4863, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5872167048637636, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.4127832951362363, \"precision\": 0.9995665366276549, \"recall\": 0.5872167048637636, \"specificity\": 0.9995725277856939, \"npv\": 0.5905876410170062, \"accuracy\": 0.7411564444917282, \"f1\": 0.73981392364453, \"f2\": 0.640022203719123, \"f0_5\": 0.8764728240212847, \"p4\": 0.7411471459029598, \"phi\": 0.5884693000021177}, {\"truth_threshold\": 7.5600000000000005, \"match_probability\": 0.9947286982162634, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6909, \"tn\": 7015, \"fp\": 3, \"fn\": 4872, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5864527629233511, \"tn_rate\": 0.9995725277856939, \"fp_rate\": 0.0004274722143060701, \"fn_rate\": 0.41354723707664887, \"precision\": 0.9995659722222222, \"recall\": 0.5864527629233511, \"specificity\": 0.9995725277856939, \"npv\": 0.5901404896104989, \"accuracy\": 0.7406776956221076, \"f1\": 0.7392071898571658, \"f2\": 0.6392960248723073, \"f0_5\": 0.8761317811762915, \"p4\": 0.7406665636660635, \"phi\": 0.5878629948623427}, {\"truth_threshold\": 7.58, \"match_probability\": 0.9948008924782327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6903, \"tn\": 7016, \"fp\": 2, \"fn\": 4878, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5859434682964094, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4140565317035905, \"precision\": 0.9997103548153512, \"recall\": 0.5859434682964094, \"specificity\": 0.999715018523796, \"npv\": 0.589877249033126, \"accuracy\": 0.7404117240278738, \"f1\": 0.738841913732206, \"f2\": 0.6388235947361602, \"f0_5\": 0.8759929951016472, \"p4\": 0.7403990556685782, \"phi\": 0.5876197613404861}, {\"truth_threshold\": 7.6000000000000005, \"match_probability\": 0.9948721030850469, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6896, \"tn\": 7016, \"fp\": 2, \"fn\": 4885, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5853492912316441, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4146507087683558, \"precision\": 0.9997100608872137, \"recall\": 0.5853492912316441, \"specificity\": 0.999715018523796, \"npv\": 0.5895302915721368, \"accuracy\": 0.7400393637959466, \"f1\": 0.738369291717972, \"f2\": 0.6382584872829588, \"f0_5\": 0.8757270210550377, \"p4\": 0.7400250495103023, \"phi\": 0.5871486184022594}, {\"truth_threshold\": 7.62, \"match_probability\": 0.9949423433004362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6892, \"tn\": 7016, \"fp\": 2, \"fn\": 4889, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5850097614803497, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4149902385196503, \"precision\": 0.9997098926602843, \"recall\": 0.5850097614803497, \"specificity\": 0.999715018523796, \"npv\": 0.5893322133557329, \"accuracy\": 0.7398265865205597, \"f1\": 0.73809906291834, \"f2\": 0.637935502980488, \"f0_5\": 0.8755748659704754, \"p4\": 0.7398112850772868, \"phi\": 0.5868794730209894}, {\"truth_threshold\": 7.640000000000001, \"match_probability\": 0.9950116262130546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6886, \"tn\": 7016, \"fp\": 2, \"fn\": 4895, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5845004668534081, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.415499533146592, \"precision\": 0.9997096399535423, \"recall\": 0.5845004668534081, \"specificity\": 0.999715018523796, \"npv\": 0.5890353454789691, \"accuracy\": 0.7395074206074791, \"f1\": 0.7376935025978896, \"f2\": 0.6374509368288529, \"f0_5\": 0.8753464012406885, \"p4\": 0.7394905745563836, \"phi\": 0.5864758626131595}, {\"truth_threshold\": 7.66, \"match_probability\": 0.9950799647386886, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6884, \"tn\": 7016, \"fp\": 2, \"fn\": 4897, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5843307019777608, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4156692980222392, \"precision\": 0.9997095556200988, \"recall\": 0.5843307019777608, \"specificity\": 0.999715018523796, \"npv\": 0.588936455972467, \"accuracy\": 0.7394010319697856, \"f1\": 0.737558257888252, \"f2\": 0.6372893908535456, \"f0_5\": 0.8752701843610935, \"p4\": 0.7393836539628682, \"phi\": 0.5863413544693464}, {\"truth_threshold\": 7.68, \"match_probability\": 0.9951473716224397, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6875, \"tn\": 7016, \"fp\": 2, \"fn\": 4906, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5835667600373483, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.41643323996265175, \"precision\": 0.9997091755125782, \"recall\": 0.5835667600373483, \"specificity\": 0.999715018523796, \"npv\": 0.5884918637812447, \"accuracy\": 0.738922283100165, \"f1\": 0.7369492978883053, \"f2\": 0.6365622858835948, \"f0_5\": 0.8749268243019674, \"p4\": 0.7389024050932442, \"phi\": 0.5857362446962067}, {\"truth_threshold\": 7.7, \"match_probability\": 0.9952138594408825, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6871, \"tn\": 7016, \"fp\": 2, \"fn\": 4910, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5832272302860538, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.41677276971394617, \"precision\": 0.9997090062563655, \"recall\": 0.5832272302860538, \"specificity\": 0.999715018523796, \"npv\": 0.5882944826429649, \"accuracy\": 0.7387095058247779, \"f1\": 0.7366784603838319, \"f2\": 0.6362390503176102, \"f0_5\": 0.8747740177730248, \"p4\": 0.7386884607046392, \"phi\": 0.585467399713266}, {\"truth_threshold\": 7.72, \"match_probability\": 0.9952794406041985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6868, \"tn\": 7016, \"fp\": 2, \"fn\": 4913, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5829725829725829, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.417027417027417, \"precision\": 0.9997088791848617, \"recall\": 0.5829725829725829, \"specificity\": 0.999715018523796, \"npv\": 0.5881465336574734, \"accuracy\": 0.7385499228682376, \"f1\": 0.7364752560184441, \"f2\": 0.6359965922139497, \"f0_5\": 0.8746593311428644, \"p4\": 0.7385279797016371, \"phi\": 0.5852658033199649}, {\"truth_threshold\": 7.74, \"match_probability\": 0.9953441273582849, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6861, \"tn\": 7016, \"fp\": 2, \"fn\": 4920, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5823784059078176, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4176215940921823, \"precision\": 0.9997085822526592, \"recall\": 0.5823784059078176, \"specificity\": 0.999715018523796, \"npv\": 0.5878016085790885, \"accuracy\": 0.7381775626363104, \"f1\": 0.7360008581849389, \"f2\": 0.6354307518476671, \"f0_5\": 0.8743914561721, \"p4\": 0.738153448044245, \"phi\": 0.5847955359522872}, {\"truth_threshold\": 7.76, \"match_probability\": 0.9954079317868398, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6842, \"tn\": 7016, \"fp\": 2, \"fn\": 4939, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.580765639589169, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.419234360410831, \"precision\": 0.9997077732320281, \"recall\": 0.580765639589169, \"specificity\": 0.999715018523796, \"npv\": 0.5868674194897533, \"accuracy\": 0.7371668705782223, \"f1\": 0.7347114093959731, \"f2\": 0.6338941595019271, \"f0_5\": 0.8736624358352274, \"p4\": 0.7371363218051581, \"phi\": 0.5835199687276168}, {\"truth_threshold\": 7.78, \"match_probability\": 0.9954708658134229, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6833, \"tn\": 7016, \"fp\": 2, \"fn\": 4948, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5800016976487564, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4199983023512435, \"precision\": 0.9997073884418435, \"recall\": 0.5800016976487564, \"specificity\": 0.999715018523796, \"npv\": 0.5864259445001672, \"accuracy\": 0.7366881217086015, \"f1\": 0.734099699183498, \"f2\": 0.6331659222743193, \"f0_5\": 0.8733161217760282, \"p4\": 0.7366542470181631, \"phi\": 0.5829161955310692}, {\"truth_threshold\": 7.8, \"match_probability\": 0.9955329412034929, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6831, \"tn\": 7016, \"fp\": 2, \"fn\": 4950, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5798319327731093, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42016806722689076, \"precision\": 0.9997073027952583, \"recall\": 0.5798319327731093, \"specificity\": 0.999715018523796, \"npv\": 0.5863279291325422, \"accuracy\": 0.736581733070908, \"f1\": 0.7339636832491673, \"f2\": 0.6330040587875531, \"f0_5\": 0.8732390765218725, \"p4\": 0.736547094815614, \"phi\": 0.5827820621950641}, {\"truth_threshold\": 7.82, \"match_probability\": 0.9955941695664209, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6821, \"tn\": 7016, \"fp\": 2, \"fn\": 4960, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5789831083948731, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4210168916051269, \"precision\": 0.9997068738091749, \"recall\": 0.5789831083948731, \"specificity\": 0.999715018523796, \"npv\": 0.5858383433533734, \"accuracy\": 0.7360497898824405, \"f1\": 0.7332831649107718, \"f2\": 0.6321945613287115, \"f0_5\": 0.8728533770122591, \"p4\": 0.7360111995929557, \"phi\": 0.5821116047616229}, {\"truth_threshold\": 7.84, \"match_probability\": 0.9956545623574807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6810, \"tn\": 7016, \"fp\": 2, \"fn\": 4971, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5780494015788133, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42195059842118665, \"precision\": 0.9997064004697592, \"recall\": 0.5780494015788133, \"specificity\": 0.999715018523796, \"npv\": 0.5853007424710103, \"accuracy\": 0.7354646523751264, \"f1\": 0.7325337492604743, \"f2\": 0.6313037674280629, \"f0_5\": 0.8724281944195342, \"p4\": 0.7354214549595849, \"phi\": 0.5813745029643611}, {\"truth_threshold\": 7.86, \"match_probability\": 0.995714130879816, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6806, \"tn\": 7016, \"fp\": 2, \"fn\": 4975, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5777098718275189, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4222901281724811, \"precision\": 0.9997062279670975, \"recall\": 0.5777098718275189, \"specificity\": 0.999715018523796, \"npv\": 0.585105495788508, \"accuracy\": 0.7352518750997393, \"f1\": 0.7322610145785142, \"f2\": 0.6309797522806497, \"f0_5\": 0.8722733447825084, \"p4\": 0.7352069344279084, \"phi\": 0.5811065698008792}, {\"truth_threshold\": 7.88, \"match_probability\": 0.9957728862863844, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6804, \"tn\": 7016, \"fp\": 2, \"fn\": 4977, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5775401069518716, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42245989304812837, \"precision\": 0.9997061416397296, \"recall\": 0.5775401069518716, \"specificity\": 0.999715018523796, \"npv\": 0.5850079212874176, \"accuracy\": 0.7351454864620458, \"f1\": 0.7321246032173024, \"f2\": 0.6308177266827368, \"f0_5\": 0.872195872324061, \"p4\": 0.7350996605153283, \"phi\": 0.5809726239354122}, {\"truth_threshold\": 7.9, \"match_probability\": 0.9958308395818786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6798, \"tn\": 7016, \"fp\": 2, \"fn\": 4983, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5770308123249299, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42296918767507, \"precision\": 0.9997058823529412, \"recall\": 0.5770308123249299, \"specificity\": 0.999715018523796, \"npv\": 0.5847153929494124, \"accuracy\": 0.7348263205489654, \"f1\": 0.7317151929390238, \"f2\": 0.6303315777761294, \"f0_5\": 0.8719632641543316, \"p4\": 0.7347777840231327, \"phi\": 0.5805708690503925}, {\"truth_threshold\": 7.92, \"match_probability\": 0.9958880016246255, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6790, \"tn\": 7016, \"fp\": 2, \"fn\": 4991, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5763517528223411, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4236482471776589, \"precision\": 0.9997055359246172, \"recall\": 0.5763517528223411, \"specificity\": 0.999715018523796, \"npv\": 0.5843258099441992, \"accuracy\": 0.7344007659981914, \"f1\": 0.7311689010929845, \"f2\": 0.6296832109206915, \"f0_5\": 0.8716526740096023, \"p4\": 0.7343484870844739, \"phi\": 0.5800353883855606}, {\"truth_threshold\": 7.94, \"match_probability\": 0.9959443831284631, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6788, \"tn\": 7016, \"fp\": 2, \"fn\": 4993, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5761819879466938, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42381801205330616, \"precision\": 0.9997054491899853, \"recall\": 0.5761819879466938, \"specificity\": 0.999715018523796, \"npv\": 0.5842284952951953, \"accuracy\": 0.7342943773604979, \"f1\": 0.7310322545904906, \"f2\": 0.6295210891419668, \"f0_5\": 0.8715749467142601, \"p4\": 0.7342411398488735, \"phi\": 0.5799015525117351}, {\"truth_threshold\": 7.96, \"match_probability\": 0.9959999946645937, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6782, \"tn\": 7016, \"fp\": 2, \"fn\": 4999, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5756726933197521, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4243273066802479, \"precision\": 0.9997051886792453, \"recall\": 0.5756726933197521, \"specificity\": 0.999715018523796, \"npv\": 0.5839367457344985, \"accuracy\": 0.7339752114474174, \"f1\": 0.7306221384325343, \"f2\": 0.6290346516287008, \"f0_5\": 0.871341573091451, \"p4\": 0.7339190427153115, \"phi\": 0.5795001269872736}, {\"truth_threshold\": 7.98, \"match_probability\": 0.9960548466634173, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6776, \"tn\": 7016, \"fp\": 2, \"fn\": 5005, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5751633986928104, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42483660130718953, \"precision\": 0.9997049277072882, \"recall\": 0.5751633986928104, \"specificity\": 0.999715018523796, \"npv\": 0.5836452874136927, \"accuracy\": 0.7336560455343369, \"f1\": 0.7302117570989817, \"f2\": 0.6285481058216764, \"f0_5\": 0.8711079114493611, \"p4\": 0.7335968621463504, \"phi\": 0.5790988243397809}, {\"truth_threshold\": 8.0, \"match_probability\": 0.9961089494163424, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6767, \"tn\": 7016, \"fp\": 2, \"fn\": 5014, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5743994567523979, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42560054324760205, \"precision\": 0.999704535381888, \"recall\": 0.5743994567523979, \"specificity\": 0.999715018523796, \"npv\": 0.5832086450540316, \"accuracy\": 0.7331772966647162, \"f1\": 0.7295956873315363, \"f2\": 0.6278180839812221, \"f0_5\": 0.8707568777826389, \"p4\": 0.7331134340194123, \"phi\": 0.5784971000078958}, {\"truth_threshold\": 8.02, \"match_probability\": 0.9961623130775747, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6761, \"tn\": 7016, \"fp\": 2, \"fn\": 5020, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5738901621254563, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42610983787454376, \"precision\": 0.9997042732515156, \"recall\": 0.5738901621254563, \"specificity\": 0.999715018523796, \"npv\": 0.582917912927883, \"accuracy\": 0.7328581307516358, \"f1\": 0.7291846419327006, \"f2\": 0.6273312672815335, \"f0_5\": 0.8705224937553112, \"p4\": 0.7327910431963617, \"phi\": 0.5780961030431672}, {\"truth_threshold\": 8.040000000000001, \"match_probability\": 0.9962149476658856, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6754, \"tn\": 7016, \"fp\": 2, \"fn\": 5027, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5732959850606909, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42670401493930904, \"precision\": 0.9997039668442865, \"recall\": 0.5732959850606909, \"specificity\": 0.999715018523796, \"npv\": 0.5825790915884747, \"accuracy\": 0.7324857705197085, \"f1\": 0.7287047526568484, \"f2\": 0.6267631774313289, \"f0_5\": 0.8702486792939054, \"p4\": 0.7324148134026783, \"phi\": 0.5776284270037277}, {\"truth_threshold\": 8.06, \"match_probability\": 0.9962668630663583, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6751, \"tn\": 7016, \"fp\": 2, \"fn\": 5030, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5730413377472201, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.4269586622527799, \"precision\": 0.9997038353324449, \"recall\": 0.5730413377472201, \"specificity\": 0.999715018523796, \"npv\": 0.5824340029885439, \"accuracy\": 0.7323261875631683, \"f1\": 0.7284989748570195, \"f2\": 0.6265196651632422, \"f0_5\": 0.8701312092387802, \"p4\": 0.7322535365909125, \"phi\": 0.577428044975489}, {\"truth_threshold\": 8.08, \"match_probability\": 0.9963180690321144, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6748, \"tn\": 7016, \"fp\": 2, \"fn\": 5033, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5727866904337493, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42721330956625075, \"precision\": 0.9997037037037036, \"recall\": 0.5727866904337493, \"specificity\": 0.999715018523796, \"npv\": 0.5822889866378953, \"accuracy\": 0.732166604606628, \"f1\": 0.7282931304300901, \"f2\": 0.6262761257749564, \"f0_5\": 0.870013666486166, \"p4\": 0.7320922384268802, \"phi\": 0.5772276932211108}, {\"truth_threshold\": 8.1, \"match_probability\": 0.9963685751860192, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6746, \"tn\": 7016, \"fp\": 2, \"fn\": 5035, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5726169255581021, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.427383074441898, \"precision\": 0.9997036158861885, \"recall\": 0.5726169255581021, \"specificity\": 0.999715018523796, \"npv\": 0.5821923491826404, \"accuracy\": 0.7320602159689346, \"f1\": 0.7281558637810999, \"f2\": 0.6261137511137511, \"f0_5\": 0.8699352642302633, \"p4\": 0.7319846944314317, \"phi\": 0.577094142182413}, {\"truth_threshold\": 8.120000000000001, \"match_probability\": 0.9964183910223661, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6739, \"tn\": 7016, \"fp\": 2, \"fn\": 5042, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5720227484933367, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42797725150666327, \"precision\": 0.999703308114523, \"recall\": 0.5720227484933367, \"specificity\": 0.999715018523796, \"npv\": 0.5818543705423785, \"accuracy\": 0.7316878557370073, \"f1\": 0.7276751970629521, \"f2\": 0.6255453448435905, \"f0_5\": 0.8696606013679185, \"p4\": 0.731608215340483, \"phi\": 0.576626819170739}, {\"truth_threshold\": 8.14, \"match_probability\": 0.996467525908541, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6734, \"tn\": 7016, \"fp\": 2, \"fn\": 5047, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5715983363042186, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42840166369578137, \"precision\": 0.9997030878859857, \"recall\": 0.5715983363042186, \"specificity\": 0.999715018523796, \"npv\": 0.5816131973804195, \"accuracy\": 0.7314218841427735, \"f1\": 0.7273316411945779, \"f2\": 0.6251392499071667, \"f0_5\": 0.8694641704325371, \"p4\": 0.7313392299239146, \"phi\": 0.5762931173905421}, {\"truth_threshold\": 8.16, \"match_probability\": 0.9965159890866674, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6727, \"tn\": 7016, \"fp\": 2, \"fn\": 5054, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5710041592394534, \"tn_rate\": 0.999715018523796, \"fp_rate\": 0.00028498147620404675, \"fn_rate\": 0.42899584076054664, \"precision\": 0.9997027790161985, \"recall\": 0.5710041592394534, \"specificity\": 0.999715018523796, \"npv\": 0.5812758906379453, \"accuracy\": 0.7310495239108463, \"f1\": 0.7268503511615343, \"f2\": 0.6245705903106605, \"f0_5\": 0.8691888260071841, \"p4\": 0.7309625493729195, \"phi\": 0.5758260749940032}, {\"truth_threshold\": 8.18, \"match_probability\": 0.9965637896752301, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6719, \"tn\": 7017, \"fp\": 1, \"fn\": 5062, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5703250997368644, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.42967490026313554, \"precision\": 0.9998511904761904, \"recall\": 0.5703250997368644, \"specificity\": 0.999857509261898, \"npv\": 0.5809255733090488, \"accuracy\": 0.7306771636789191, \"f1\": 0.726339116804497, \"f2\": 0.6239321001411485, \"f0_5\": 0.8689635550037506, \"p4\": 0.7305845105566382, \"phi\": 0.5754553070577468}, {\"truth_threshold\": 8.2, \"match_probability\": 0.9966109366706807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6717, \"tn\": 7017, \"fp\": 1, \"fn\": 5064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5701553348612172, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4298446651387828, \"precision\": 0.9998511461744567, \"recall\": 0.5701553348612172, \"specificity\": 0.999857509261898, \"npv\": 0.5808294015396076, \"accuracy\": 0.7305707750412256, \"f1\": 0.7262014162927726, \"f2\": 0.6237695479365551, \"f0_5\": 0.8688846920032081, \"p4\": 0.730476822866776, \"phi\": 0.5753219711861021}, {\"truth_threshold\": 8.22, \"match_probability\": 0.9966574389490227, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6713, \"tn\": 7017, \"fp\": 1, \"fn\": 5068, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5698158051099228, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43018419489007725, \"precision\": 0.9998510574918081, \"recall\": 0.5698158051099228, \"specificity\": 0.999857509261898, \"npv\": 0.5806371534960695, \"accuracy\": 0.7303579977658387, \"f1\": 0.725925925925926, \"f2\": 0.623444407295962, \"f0_5\": 0.868726868028056, \"p4\": 0.7302614182660399, \"phi\": 0.5750553391693994}, {\"truth_threshold\": 8.24, \"match_probability\": 0.9967033052673774, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6708, \"tn\": 7017, \"fp\": 1, \"fn\": 5073, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5693913929208047, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4306086070791953, \"precision\": 0.9998509464897898, \"recall\": 0.5693913929208047, \"specificity\": 0.999857509261898, \"npv\": 0.5803970223325062, \"accuracy\": 0.7300920261716048, \"f1\": 0.7255813953488373, \"f2\": 0.6230379135474523, \"f0_5\": 0.868529404148432, \"p4\": 0.7299921075770262, \"phi\": 0.5747221235047726}, {\"truth_threshold\": 8.26, \"match_probability\": 0.9967485442655314, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6702, \"tn\": 7017, \"fp\": 1, \"fn\": 5079, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.568882098293863, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.431117901706137, \"precision\": 0.9998508130687752, \"recall\": 0.568882098293863, \"specificity\": 0.999857509261898, \"npv\": 0.580109126984127, \"accuracy\": 0.7297728602585244, \"f1\": 0.7251677126163169, \"f2\": 0.6225500213647426, \"f0_5\": 0.8682921773378592, \"p4\": 0.7296688538764853, \"phi\": 0.5743223735009374}, {\"truth_threshold\": 8.28, \"match_probability\": 0.9967931644674644, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6700, \"tn\": 7017, \"fp\": 1, \"fn\": 5081, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5687123334182158, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43128766658178425, \"precision\": 0.9998507685420086, \"recall\": 0.5687123334182158, \"specificity\": 0.999857509261898, \"npv\": 0.5800132253265002, \"accuracy\": 0.7296664716208309, \"f1\": 0.7250297586841251, \"f2\": 0.6223873664653972, \"f0_5\": 0.8682130361539458, \"p4\": 0.7295610829745439, \"phi\": 0.5741891498188385}, {\"truth_threshold\": 8.3, \"match_probability\": 0.9968371742828585, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6693, \"tn\": 7017, \"fp\": 1, \"fn\": 5088, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5681181563534504, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4318818436465495, \"precision\": 0.9998506124887959, \"recall\": 0.5681181563534504, \"specificity\": 0.999857509261898, \"npv\": 0.5796778190830235, \"accuracy\": 0.7292941113889037, \"f1\": 0.7245466847090664, \"f2\": 0.6218179791147943, \"f0_5\": 0.8679357833856368, \"p4\": 0.7291838070880396, \"phi\": 0.5737229703132193}, {\"truth_threshold\": 8.32, \"match_probability\": 0.9968805820085895, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6690, \"tn\": 7017, \"fp\": 1, \"fn\": 5091, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5678635090399796, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4321364909600204, \"precision\": 0.9998505455088925, \"recall\": 0.5678635090399796, \"specificity\": 0.999857509261898, \"npv\": 0.5795341922695738, \"accuracy\": 0.7291345284323634, \"f1\": 0.7243395409268082, \"f2\": 0.6215739106197157, \"f0_5\": 0.8678168374627059, \"p4\": 0.7290220802993927, \"phi\": 0.5735232282306945}, {\"truth_threshold\": 8.34, \"match_probability\": 0.9969233958301993, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6688, \"tn\": 7017, \"fp\": 1, \"fn\": 5093, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5676937441643324, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4323062558356676, \"precision\": 0.9998505008222455, \"recall\": 0.5676937441643324, \"specificity\": 0.999857509261898, \"npv\": 0.5794384805945499, \"accuracy\": 0.72902813979467, \"f1\": 0.7242014076881429, \"f2\": 0.6214111831713527, \"f0_5\": 0.8677374990269092, \"p4\": 0.7289142500296293, \"phi\": 0.5733900831886671}, {\"truth_threshold\": 8.36, \"match_probability\": 0.9969656238233504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6682, \"tn\": 7017, \"fp\": 1, \"fn\": 5099, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5671844495373907, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4328155504626093, \"precision\": 0.9998503666018256, \"recall\": 0.5671844495373907, \"specificity\": 0.999857509261898, \"npv\": 0.5791515351601189, \"accuracy\": 0.7287089738815894, \"f1\": 0.723786828422877, \"f2\": 0.6209229282435371, \"f0_5\": 0.8674992859553917, \"p4\": 0.7285906994890233, \"phi\": 0.5729907263853458}, {\"truth_threshold\": 8.38, \"match_probability\": 0.9970072739552628, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6677, \"tn\": 7017, \"fp\": 1, \"fn\": 5104, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5667600373482726, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4332399626517274, \"precision\": 0.9998502545672358, \"recall\": 0.5667600373482726, \"specificity\": 0.999857509261898, \"npv\": 0.578912630971042, \"accuracy\": 0.7284430022873557, \"f1\": 0.7234411398233924, \"f2\": 0.6205159659492212, \"f0_5\": 0.867300548151612, \"p4\": 0.728321005379237, \"phi\": 0.5726580186051025}, {\"truth_threshold\": 8.4, \"match_probability\": 0.9970483540861322, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6664, \"tn\": 7017, \"fp\": 1, \"fn\": 5117, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5656565656565656, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43434343434343436, \"precision\": 0.9998499624906226, \"recall\": 0.5656565656565656, \"specificity\": 0.999857509261898, \"npv\": 0.5782924015164002, \"accuracy\": 0.727751476142348, \"f1\": 0.7225414724059417, \"f2\": 0.6194575098997936, \"f0_5\": 0.8667828620483338, \"p4\": 0.7276195068700849, \"phi\": 0.5717933579122838}, {\"truth_threshold\": 8.42, \"match_probability\": 0.9970888719705324, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6651, \"tn\": 7017, \"fp\": 1, \"fn\": 5130, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5645530939648586, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43544690603514136, \"precision\": 0.9998496692723993, \"recall\": 0.5645530939648586, \"specificity\": 0.999857509261898, \"npv\": 0.5776734996295382, \"accuracy\": 0.7270599499973402, \"f1\": 0.7216405359952259, \"f2\": 0.6183985421005653, \"f0_5\": 0.8662637734767772, \"p4\": 0.7269175807482471, \"phi\": 0.5709292426714282}, {\"truth_threshold\": 8.44, \"match_probability\": 0.9971288352587981, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6648, \"tn\": 7017, \"fp\": 1, \"fn\": 5133, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5642984466513878, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43570155334861216, \"precision\": 0.9998496014438262, \"recall\": 0.5642984466513878, \"specificity\": 0.999857509261898, \"npv\": 0.5775308641975309, \"accuracy\": 0.7269003670408001, \"f1\": 0.7214324470971243, \"f2\": 0.6181540922024064, \"f0_5\": 0.8661437840373141, \"p4\": 0.7267555366444531, \"phi\": 0.5707299085553147}, {\"truth_threshold\": 8.46, \"match_probability\": 0.9971682514983926, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6637, \"tn\": 7017, \"fp\": 1, \"fn\": 5144, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5633647398353281, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4366352601646719, \"precision\": 0.9998493522145224, \"recall\": 0.5633647398353281, \"specificity\": 0.999857509261898, \"npv\": 0.5770084696982156, \"accuracy\": 0.7263152295334858, \"f1\": 0.7206688745317336, \"f2\": 0.617257542502139, \"f0_5\": 0.8657031800276525, \"p4\": 0.7261611774538101, \"phi\": 0.5699992630407686}, {\"truth_threshold\": 8.48, \"match_probability\": 0.9972071281352571, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6629, \"tn\": 7017, \"fp\": 1, \"fn\": 5152, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5626856803327391, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43731431966726086, \"precision\": 0.9998491704374057, \"recall\": 0.5626856803327391, \"specificity\": 0.999857509261898, \"npv\": 0.5766291396170597, \"accuracy\": 0.7258896749827118, \"f1\": 0.7201129759382977, \"f2\": 0.6166052758864456, \"f0_5\": 0.8653821049058771, \"p4\": 0.7257287202803675, \"phi\": 0.5694681266499164}, {\"truth_threshold\": 8.5, \"match_probability\": 0.9972454725151444, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6622, \"tn\": 7017, \"fp\": 1, \"fn\": 5159, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5620915032679739, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43790849673202614, \"precision\": 0.9998490110221954, \"recall\": 0.5620915032679739, \"specificity\": 0.999857509261898, \"npv\": 0.5762976346911958, \"accuracy\": 0.7255173147507846, \"f1\": 0.719626168224299, \"f2\": 0.6160343833144175, \"f0_5\": 0.8651007237478118, \"p4\": 0.7253501840530331, \"phi\": 0.569003548873852}, {\"truth_threshold\": 8.52, \"match_probability\": 0.9972832918849344, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6616, \"tn\": 7017, \"fp\": 1, \"fn\": 5165, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5615822086410321, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43841779135896786, \"precision\": 0.9998488741121354, \"recall\": 0.5615822086410321, \"specificity\": 0.999857509261898, \"npv\": 0.5760137908389427, \"accuracy\": 0.7251981488377042, \"f1\": 0.7192086096314817, \"f2\": 0.6155449284531364, \"f0_5\": 0.8648592120055426, \"p4\": 0.7250256227437714, \"phi\": 0.5686054626548736}, {\"truth_threshold\": 8.540000000000001, \"match_probability\": 0.997320593393935, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6613, \"tn\": 7017, \"fp\": 1, \"fn\": 5168, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5613275613275613, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43867243867243866, \"precision\": 0.9998488055639553, \"recall\": 0.5613275613275613, \"specificity\": 0.999857509261898, \"npv\": 0.5758719737382028, \"accuracy\": 0.7250385658811639, \"f1\": 0.7189997281870073, \"f2\": 0.615300160035729, \"f0_5\": 0.8647383424431833, \"p4\": 0.724863306755852, \"phi\": 0.5684064621136006}, {\"truth_threshold\": 8.56, \"match_probability\": 0.9973573840951653, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6607, \"tn\": 7017, \"fp\": 1, \"fn\": 5174, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5608182667006196, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4391817332993804, \"precision\": 0.9998486682808717, \"recall\": 0.5608182667006196, \"specificity\": 0.999857509261898, \"npv\": 0.5755885489295381, \"accuracy\": 0.7247193999680834, \"f1\": 0.7185817608352819, \"f2\": 0.6148105412044964, \"f0_5\": 0.8644963755789914, \"p4\": 0.7245386038610214, \"phi\": 0.5680085459543355}, {\"truth_threshold\": 8.58, \"match_probability\": 0.9973936709466236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6604, \"tn\": 7017, \"fp\": 1, \"fn\": 5177, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5605636193871488, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4394363806128512, \"precision\": 0.9998485995457986, \"recall\": 0.5605636193871488, \"specificity\": 0.999857509261898, \"npv\": 0.5754469411185829, \"accuracy\": 0.7245598170115432, \"f1\": 0.7183726748613075, \"f2\": 0.6145656907815147, \"f0_5\": 0.8643752781340802, \"p4\": 0.7243762168529748, \"phi\": 0.5678096302511048}, {\"truth_threshold\": 8.6, \"match_probability\": 0.9974294608125389, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6599, \"tn\": 7017, \"fp\": 1, \"fn\": 5182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5601392071980307, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.43986079280196927, \"precision\": 0.9998484848484849, \"recall\": 0.5601392071980307, \"specificity\": 0.999857509261898, \"npv\": 0.5752110828756456, \"accuracy\": 0.7242938454173095, \"f1\": 0.7180240465698275, \"f2\": 0.6141575459757278, \"f0_5\": 0.864173279903617, \"p4\": 0.7241055189820685, \"phi\": 0.5674781667116181}, {\"truth_threshold\": 8.620000000000001, \"match_probability\": 0.9974647604646075, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6597, \"tn\": 7017, \"fp\": 1, \"fn\": 5184, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5599694423223835, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4400305576776165, \"precision\": 0.9998484389208852, \"recall\": 0.5599694423223835, \"specificity\": 0.999857509261898, \"npv\": 0.575116793705434, \"accuracy\": 0.7241874567796159, \"f1\": 0.7178845421404865, \"f2\": 0.6139942667808347, \"f0_5\": 0.8640924213449297, \"p4\": 0.7239972212897476, \"phi\": 0.5673456031804067}, {\"truth_threshold\": 8.64, \"match_probability\": 0.9974995765832131, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6594, \"tn\": 7017, \"fp\": 1, \"fn\": 5187, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5597147950089126, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.44028520499108736, \"precision\": 0.9998483699772555, \"recall\": 0.5597147950089126, \"specificity\": 0.999857509261898, \"npv\": 0.5749754178957719, \"accuracy\": 0.7240278738230757, \"f1\": 0.71767522855899, \"f2\": 0.6137493251922038, \"f0_5\": 0.8639710699405152, \"p4\": 0.7238347548357167, \"phi\": 0.5671467812919205}, {\"truth_threshold\": 8.66, \"match_probability\": 0.9975339157586318, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6592, \"tn\": 7017, \"fp\": 1, \"fn\": 5189, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5595450301332654, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.44045496986673455, \"precision\": 0.9998483239799788, \"recall\": 0.5595450301332654, \"specificity\": 0.999857509261898, \"npv\": 0.5748812059642798, \"accuracy\": 0.7239214851853822, \"f1\": 0.7175356481985414, \"f2\": 0.6135860156002755, \"f0_5\": 0.8638901265955495, \"p4\": 0.7237264305673609, \"phi\": 0.5670142489534163}, {\"truth_threshold\": 8.68, \"match_probability\": 0.9975677844922232, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6569, \"tn\": 7017, \"fp\": 1, \"fn\": 5212, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5575927340633223, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4424072659366777, \"precision\": 0.9998477929984779, \"recall\": 0.5575927340633223, \"specificity\": 0.999857509261898, \"npv\": 0.5737999836454329, \"accuracy\": 0.7226980158519071, \"f1\": 0.7159282872867964, \"f2\": 0.6117070808656461, \"f0_5\": 0.8629568324531672, \"p4\": 0.7224799317216747, \"phi\": 0.5654910190914793}, {\"truth_threshold\": 8.700000000000001, \"match_probability\": 0.9976011891976038, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6565, \"tn\": 7017, \"fp\": 1, \"fn\": 5216, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5572532043120278, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.44274679568797215, \"precision\": 0.9998477002741395, \"recall\": 0.5572532043120278, \"specificity\": 0.999857509261898, \"npv\": 0.5736123600098095, \"accuracy\": 0.72248523857652, \"f1\": 0.7156483348776367, \"f2\": 0.6113801452784504, \"f0_5\": 0.8627940596661848, \"p4\": 0.7222630037441364, \"phi\": 0.5652262762743231}, {\"truth_threshold\": 8.72, \"match_probability\": 0.9976341362018084, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6558, \"tn\": 7017, \"fp\": 1, \"fn\": 5223, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5566590272472626, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4433409727527375, \"precision\": 0.9998475377344107, \"recall\": 0.5566590272472626, \"specificity\": 0.999857509261898, \"npv\": 0.5732843137254902, \"accuracy\": 0.7221128783445928, \"f1\": 0.7151581243184296, \"f2\": 0.6108078907661644, \"f0_5\": 0.8625088776073861, \"p4\": 0.7218832751685129, \"phi\": 0.564763094525082}, {\"truth_threshold\": 8.74, \"match_probability\": 0.9976666317464351, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6554, \"tn\": 7017, \"fp\": 1, \"fn\": 5227, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5563194974959681, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4436805025040319, \"precision\": 0.9998474446987032, \"recall\": 0.5563194974959681, \"specificity\": 0.999857509261898, \"npv\": 0.5730970271153218, \"accuracy\": 0.7219001010692058, \"f1\": 0.7148778359511344, \"f2\": 0.6104808211777417, \"f0_5\": 0.8623457277440068, \"p4\": 0.7216662274212629, \"phi\": 0.5644984865984949}, {\"truth_threshold\": 8.76, \"match_probability\": 0.9976986819887761, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6542, \"tn\": 7017, \"fp\": 1, \"fn\": 5239, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5553009082420847, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4446990917579153, \"precision\": 0.9998471649090631, \"recall\": 0.5553009082420847, \"specificity\": 0.999857509261898, \"npv\": 0.5725359007832899, \"accuracy\": 0.7212617692430449, \"f1\": 0.7140362366295568, \"f2\": 0.6094993198800007, \"f0_5\": 0.8618554527968804, \"p4\": 0.721014820998794, \"phi\": 0.5637049555892203}, {\"truth_threshold\": 8.78, \"match_probability\": 0.9977302930029345, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6540, \"tn\": 7017, \"fp\": 1, \"fn\": 5241, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5551311433664374, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4448688566335625, \"precision\": 0.9998471181776487, \"recall\": 0.5551311433664374, \"specificity\": 0.999857509261898, \"npv\": 0.5724424865394029, \"accuracy\": 0.7211553806053513, \"f1\": 0.7138958628970636, \"f2\": 0.6093356936550824, \"f0_5\": 0.8617736197127421, \"p4\": 0.7209062147202043, \"phi\": 0.5635727429845406}, {\"truth_threshold\": 8.8, \"match_probability\": 0.9977614707809268, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6533, \"tn\": 7017, \"fp\": 1, \"fn\": 5248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5545369663016722, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4454630336983278, \"precision\": 0.9998469543924089, \"recall\": 0.5545369663016722, \"specificity\": 0.999857509261898, \"npv\": 0.5721157766000815, \"accuracy\": 0.7207830203734241, \"f1\": 0.7134043134043134, \"f2\": 0.6087629058108763, \"f0_5\": 0.8614869319830155, \"p4\": 0.7205260056031424, \"phi\": 0.5631100942892865}, {\"truth_threshold\": 8.82, \"match_probability\": 0.997792221233771, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6519, \"tn\": 7017, \"fp\": 1, \"fn\": 5262, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5533486121721416, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4466513878278584, \"precision\": 0.9998466257668711, \"recall\": 0.5533486121721416, \"specificity\": 0.999857509261898, \"npv\": 0.5714634742242853, \"accuracy\": 0.7200382999095697, \"f1\": 0.7124200863340802, \"f2\": 0.6076168816643054, \"f0_5\": 0.8609122844087583, \"p4\": 0.7197651785341289, \"phi\": 0.5621852404254322}, {\"truth_threshold\": 8.84, \"match_probability\": 0.9978225501925614, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6516, \"tn\": 7017, \"fp\": 1, \"fn\": 5265, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5530939648586708, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.44690603514132926, \"precision\": 0.9998465551634188, \"recall\": 0.5530939648586708, \"specificity\": 0.999857509261898, \"npv\": 0.5713238886174891, \"accuracy\": 0.7198787169530294, \"f1\": 0.7122089845884796, \"f2\": 0.6073712272329002, \"f0_5\": 0.8607889244101562, \"p4\": 0.7196020728476911, \"phi\": 0.5619871340722601}, {\"truth_threshold\": 8.86, \"match_probability\": 0.9978524634095293, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6506, \"tn\": 7017, \"fp\": 1, \"fn\": 5275, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5522451404804346, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4477548595195654, \"precision\": 0.9998463193483941, \"recall\": 0.5522451404804346, \"specificity\": 0.999857509261898, \"npv\": 0.5708590953465669, \"accuracy\": 0.7193467737645619, \"f1\": 0.7115048118985127, \"f2\": 0.606552180641793, \"f0_5\": 0.860377158877516, \"p4\": 0.7190582043101689, \"phi\": 0.561326973942447}, {\"truth_threshold\": 8.88, \"match_probability\": 0.9978819665590902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6501, \"tn\": 7017, \"fp\": 1, \"fn\": 5280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5518207282913166, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4481792717086835, \"precision\": 0.9998462011688711, \"recall\": 0.5518207282913166, \"specificity\": 0.999857509261898, \"npv\": 0.5706269821907782, \"accuracy\": 0.7190808021703282, \"f1\": 0.7111524366898212, \"f2\": 0.6061425427964048, \"f0_5\": 0.8601709492180264, \"p4\": 0.718786164075433, \"phi\": 0.5609970056668958}, {\"truth_threshold\": 8.9, \"match_probability\": 0.9979110652388782, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6496, \"tn\": 7017, \"fp\": 1, \"fn\": 5285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5513963161021984, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.44860368389780153, \"precision\": 0.9998460828074496, \"recall\": 0.5513963161021984, \"specificity\": 0.999857509261898, \"npv\": 0.5703950577141929, \"accuracy\": 0.7188148305760945, \"f1\": 0.7107998686946055, \"f2\": 0.6057328285559762, \"f0_5\": 0.8599645211681538, \"p4\": 0.718514052871947, \"phi\": 0.5606671116558744}, {\"truth_threshold\": 8.92, \"match_probability\": 0.9979397649707662, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6488, \"tn\": 7017, \"fp\": 1, \"fn\": 5293, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5507172565996096, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4492827434003905, \"precision\": 0.9998458930497766, \"recall\": 0.5507172565996096, \"specificity\": 0.999857509261898, \"npv\": 0.5700243704305443, \"accuracy\": 0.7183892760253205, \"f1\": 0.7102353585112205, \"f2\": 0.6050771268162572, \"f0_5\": 0.8596337811696744, \"p4\": 0.7180785267217804, \"phi\": 0.5601394352186901}, {\"truth_threshold\": 8.94, \"match_probability\": 0.9979680712018738, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6483, \"tn\": 7017, \"fp\": 1, \"fn\": 5298, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5502928444104914, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4497071555895085, \"precision\": 0.9998457742134484, \"recall\": 0.5502928444104914, \"specificity\": 0.999857509261898, \"npv\": 0.5697929354445798, \"accuracy\": 0.7181233044310867, \"f1\": 0.7098822885299754, \"f2\": 0.6046672138486793, \"f0_5\": 0.8594267836784474, \"p4\": 0.7178062298557281, \"phi\": 0.5598097333771965}, {\"truth_threshold\": 8.96, \"match_probability\": 0.9979959893055618, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6480, \"tn\": 7017, \"fp\": 1, \"fn\": 5301, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5500381970970206, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4499618029029794, \"precision\": 0.9998457028236384, \"recall\": 0.5500381970970206, \"specificity\": 0.999857509261898, \"npv\": 0.5696541646371164, \"accuracy\": 0.7179637214745466, \"f1\": 0.7096703537400065, \"f2\": 0.6044212293629325, \"f0_5\": 0.8593024797772179, \"p4\": 0.7176428172638686, \"phi\": 0.5596119475928317}, {\"truth_threshold\": 8.98, \"match_probability\": 0.9980235245824145, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6469, \"tn\": 7017, \"fp\": 1, \"fn\": 5312, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5491044902809609, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45089550971903913, \"precision\": 0.9998454404945905, \"recall\": 0.5491044902809609, \"specificity\": 0.999857509261898, \"npv\": 0.5691459161326953, \"accuracy\": 0.7173785839672323, \"f1\": 0.7088926634157032, \"f2\": 0.603519050639997, \"f0_5\": 0.8588460210828178, \"p4\": 0.7170434156042929, \"phi\": 0.5588869589252541}, {\"truth_threshold\": 9.0, \"match_probability\": 0.9980506822612085, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6458, \"tn\": 7017, \"fp\": 1, \"fn\": 5323, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5481707834649011, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4518292165350989, \"precision\": 0.9998451772720235, \"recall\": 0.5481707834649011, \"specificity\": 0.999857509261898, \"npv\": 0.5686385737439222, \"accuracy\": 0.716793446459918, \"f1\": 0.7081140350877193, \"f2\": 0.6026165015023421, \"f0_5\": 0.8583884945636282, \"p4\": 0.7164436628530728, \"phi\": 0.5581623236229721}, {\"truth_threshold\": 9.02, \"match_probability\": 0.9980774674998706, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6455, \"tn\": 7017, \"fp\": 1, \"fn\": 5326, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5479161361514303, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45208386384856974, \"precision\": 0.9998451053283767, \"recall\": 0.5479161361514303, \"specificity\": 0.999857509261898, \"npv\": 0.5685003645791137, \"accuracy\": 0.7166338635033779, \"f1\": 0.7079015188901684, \"f2\": 0.6023702874206793, \"f0_5\": 0.8582635287860657, \"p4\": 0.7162800326414966, \"phi\": 0.5579647568667551}, {\"truth_threshold\": 9.040000000000001, \"match_probability\": 0.9981038853864208, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6448, \"tn\": 7017, \"fp\": 1, \"fn\": 5333, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5473219590866649, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.452678040913335, \"precision\": 0.9998449371995658, \"recall\": 0.5473219590866649, \"specificity\": 0.999857509261898, \"npv\": 0.5681781376518219, \"accuracy\": 0.7162615032714507, \"f1\": 0.7074053757542512, \"f2\": 0.601795680660034, \"f0_5\": 0.8579716315831493, \"p4\": 0.7158981261959871, \"phi\": 0.5575038691407426}, {\"truth_threshold\": 9.06, \"match_probability\": 0.9981299409399065, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6446, \"tn\": 7017, \"fp\": 1, \"fn\": 5335, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5471521942110178, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45284780578898226, \"precision\": 0.9998448890957035, \"recall\": 0.5471521942110178, \"specificity\": 0.999857509261898, \"npv\": 0.568086139896373, \"accuracy\": 0.7161551146337571, \"f1\": 0.7072635505815229, \"f2\": 0.6016314797185044, \"f0_5\": 0.857888152466129, \"p4\": 0.7157889836094962, \"phi\": 0.557372212943939}, {\"truth_threshold\": 9.08, \"match_probability\": 0.9981556391113212, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6439, \"tn\": 7017, \"fp\": 1, \"fn\": 5342, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5465580171462524, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45344198285374754, \"precision\": 0.9998447204968944, \"recall\": 0.5465580171462524, \"specificity\": 0.999857509261898, \"npv\": 0.5677643822315721, \"accuracy\": 0.7157827544018299, \"f1\": 0.706766917293233, \"f2\": 0.6010566798596072, \"f0_5\": 0.8575956953730588, \"p4\": 0.7154068916148765, \"phi\": 0.5569115070291086}, {\"truth_threshold\": 9.1, \"match_probability\": 0.9981809847845143, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6432, \"tn\": 7017, \"fp\": 1, \"fn\": 5349, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5459638400814871, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45403615991851287, \"precision\": 0.9998445515311675, \"recall\": 0.5459638400814871, \"specificity\": 0.999857509261898, \"npv\": 0.5674429888403687, \"accuracy\": 0.7154103941699027, \"f1\": 0.7062699022729768, \"f2\": 0.6004817297458782, \"f0_5\": 0.8573028016954123, \"p4\": 0.7150246545221765, \"phi\": 0.5564509419088819}, {\"truth_threshold\": 9.120000000000001, \"match_probability\": 0.9982059827770873, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6422, \"tn\": 7017, \"fp\": 1, \"fn\": 5359, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.545115015703251, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.454884984296749, \"precision\": 0.9998443095126888, \"recall\": 0.545115015703251, \"specificity\": 0.999857509261898, \"npv\": 0.5669844861021331, \"accuracy\": 0.7148784509814352, \"f1\": 0.7055592177543397, \"f2\": 0.5996601116775917, \"f0_5\": 0.8568836228751368, \"p4\": 0.7144783484707197, \"phi\": 0.5557932349076983}, {\"truth_threshold\": 9.14, \"match_probability\": 0.9982306378412784, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6410, \"tn\": 7017, \"fp\": 1, \"fn\": 5371, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5440964264493676, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4559035735506324, \"precision\": 0.9998440180939011, \"recall\": 0.5440964264493676, \"specificity\": 0.999857509261898, \"npv\": 0.5664352599289635, \"accuracy\": 0.7142401191552742, \"f1\": 0.7047053649956024, \"f2\": 0.5986737648267488, \"f0_5\": 0.8563794255177021, \"p4\": 0.7138223856557074, \"phi\": 0.5550043621380567}, {\"truth_threshold\": 9.16, \"match_probability\": 0.9982549546648377, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6406, \"tn\": 7017, \"fp\": 1, \"fn\": 5375, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5437568966980731, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45624310330192686, \"precision\": 0.9998439207117216, \"recall\": 0.5437568966980731, \"specificity\": 0.999857509261898, \"npv\": 0.5662524209167205, \"accuracy\": 0.7140273418798873, \"f1\": 0.7044204970310095, \"f2\": 0.5983448842726644, \"f0_5\": 0.8562110722018765, \"p4\": 0.7136036349334848, \"phi\": 0.5547414951763194}, {\"truth_threshold\": 9.18, \"match_probability\": 0.9982789378718879, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6403, \"tn\": 7017, \"fp\": 1, \"fn\": 5378, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5435022493846023, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45649775061539766, \"precision\": 0.999843847595253, \"recall\": 0.5435022493846023, \"specificity\": 0.999857509261898, \"npv\": 0.5661153691004437, \"accuracy\": 0.713867758923347, \"f1\": 0.7042067638163322, \"f2\": 0.5980981916006576, \"f0_5\": 0.8560847126774875, \"p4\": 0.7134395401095992, \"phi\": 0.5545443745883066}, {\"truth_threshold\": 9.200000000000001, \"match_probability\": 0.9983025920237768, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6399, \"tn\": 7017, \"fp\": 1, \"fn\": 5382, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5431627196333079, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45683728036669213, \"precision\": 0.99984375, \"recall\": 0.5431627196333079, \"specificity\": 0.999857509261898, \"npv\": 0.565932736511009, \"accuracy\": 0.71365498164796, \"f1\": 0.7039216764754413, \"f2\": 0.5977692250205515, \"f0_5\": 0.8559161071132394, \"p4\": 0.7132207045308286, \"phi\": 0.5542815865683556}, {\"truth_threshold\": 9.22, \"match_probability\": 0.9983259216199165, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6396, \"tn\": 7017, \"fp\": 1, \"fn\": 5385, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5429080723198371, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.457091927680163, \"precision\": 0.9998436767234641, \"recall\": 0.5429080723198371, \"specificity\": 0.999857509261898, \"npv\": 0.5657958393807451, \"accuracy\": 0.7134953986914198, \"f1\": 0.7037077786335131, \"f2\": 0.5975224678163712, \"f0_5\": 0.8557895581899435, \"p4\": 0.7130565459155764, \"phi\": 0.5540845250716827}, {\"truth_threshold\": 9.24, \"match_probability\": 0.9983489310986134, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6392, \"tn\": 7017, \"fp\": 1, \"fn\": 5389, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5425685425685426, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4574314574314574, \"precision\": 0.9998435789144376, \"recall\": 0.5425685425685426, \"specificity\": 0.999857509261898, \"npv\": 0.5656134128647429, \"accuracy\": 0.7132826214160327, \"f1\": 0.703422471662815, \"f2\": 0.5971934151764859, \"f0_5\": 0.8556206998099216, \"p4\": 0.7128376250827592, \"phi\": 0.5538218156868676}, {\"truth_threshold\": 9.26, \"match_probability\": 0.9983716248378863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6388, \"tn\": 7017, \"fp\": 1, \"fn\": 5393, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5422290128172481, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4577709871827519, \"precision\": 0.9998434809829394, \"recall\": 0.5422290128172481, \"specificity\": 0.999857509261898, \"npv\": 0.5654311039484287, \"accuracy\": 0.7130698441406458, \"f1\": 0.703137039075399, \"f2\": 0.596864313344421, \"f0_5\": 0.855451696708359, \"p4\": 0.712618655354457, \"phi\": 0.5535591510987585}, {\"truth_threshold\": 9.28, \"match_probability\": 0.998394007156274, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6384, \"tn\": 7017, \"fp\": 1, \"fn\": 5397, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5418894830659536, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45811051693404636, \"precision\": 0.9998433829287392, \"recall\": 0.5418894830659536, \"specificity\": 0.999857509261898, \"npv\": 0.5652489125181247, \"accuracy\": 0.7128570668652587, \"f1\": 0.7028514807882859, \"f2\": 0.5965351623091443, \"f0_5\": 0.8552825486991238, \"p4\": 0.7123996366003166, \"phi\": 0.5532965312072544}, {\"truth_threshold\": 9.3, \"match_probability\": 0.9984160823136331, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6377, \"tn\": 7017, \"fp\": 1, \"fn\": 5404, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5412953060011884, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.45870469399881164, \"precision\": 0.9998432110379429, \"recall\": 0.5412953060011884, \"specificity\": 0.999857509261898, \"npv\": 0.5649303598744062, \"accuracy\": 0.7124847066333315, \"f1\": 0.7023514510710942, \"f2\": 0.595959029568988, \"f0_5\": 0.8549861904378838, \"p4\": 0.7120162354193406, \"phi\": 0.5528370536472786}, {\"truth_threshold\": 9.32, \"match_probability\": 0.9984378545119243, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6370, \"tn\": 7017, \"fp\": 1, \"fn\": 5411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5407011289364231, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4592988710635769, \"precision\": 0.9998430387694239, \"recall\": 0.5407011289364231, \"specificity\": 0.999857509261898, \"npv\": 0.5646121660766013, \"accuracy\": 0.7121123464014043, \"f1\": 0.7018510356985456, \"f2\": 0.5953827460510328, \"f0_5\": 0.8546893868240977, \"p4\": 0.7116326829955838, \"phi\": 0.552377712127781}, {\"truth_threshold\": 9.34, \"match_probability\": 0.9984593278959899, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6365, \"tn\": 7017, \"fp\": 1, \"fn\": 5416, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5402767167473049, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.459723283252695, \"precision\": 0.9998429154885329, \"recall\": 0.5402767167473049, \"specificity\": 0.999857509261898, \"npv\": 0.5643851041582885, \"accuracy\": 0.7118463748071706, \"f1\": 0.7014933597839863, \"f2\": 0.5949710226210506, \"f0_5\": 0.8544771110216136, \"p4\": 0.711358623991578, \"phi\": 0.5520496940354566}, {\"truth_threshold\": 9.36, \"match_probability\": 0.9984805065543192, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6360, \"tn\": 7017, \"fp\": 1, \"fn\": 5421, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5398523045581869, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4601476954418131, \"precision\": 0.9998427920138343, \"recall\": 0.5398523045581869, \"specificity\": 0.999857509261898, \"npv\": 0.5641582247949831, \"accuracy\": 0.7115804032129368, \"f1\": 0.7011354867159079, \"f2\": 0.5945592222118351, \"f0_5\": 0.8542646071188718, \"p4\": 0.7110844872073372, \"phi\": 0.5517217448825317}, {\"truth_threshold\": 9.38, \"match_probability\": 0.9985013945198057, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6354, \"tn\": 7017, \"fp\": 1, \"fn\": 5427, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5393430099312452, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46065699006875477, \"precision\": 0.9998426435877262, \"recall\": 0.5393430099312452, \"specificity\": 0.999857509261898, \"npv\": 0.5638862102217936, \"accuracy\": 0.7112612372998564, \"f1\": 0.7007057785619761, \"f2\": 0.5940649600777875, \"f0_5\": 0.8540093008252466, \"p4\": 0.71075542003395, \"phi\": 0.5513282966239341}, {\"truth_threshold\": 9.4, \"match_probability\": 0.9985219957704938, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6345, \"tn\": 7017, \"fp\": 1, \"fn\": 5436, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5385790679908327, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4614209320091673, \"precision\": 0.9998424204223133, \"recall\": 0.5385790679908327, \"specificity\": 0.999857509261898, \"npv\": 0.563478679836184, \"accuracy\": 0.7107824884302356, \"f1\": 0.7000606829591217, \"f2\": 0.593323358892837, \"f0_5\": 0.8536257231265976, \"p4\": 0.710261607597147, \"phi\": 0.5507383091064463}, {\"truth_threshold\": 9.42, \"match_probability\": 0.998542314230315, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6343, \"tn\": 7017, \"fp\": 1, \"fn\": 5438, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5384093031151854, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4615906968848145, \"precision\": 0.9998423707440101, \"recall\": 0.5384093031151854, \"specificity\": 0.999857509261898, \"npv\": 0.5633881975110397, \"accuracy\": 0.7106760997925422, \"f1\": 0.6999172413793103, \"f2\": 0.5931585247250692, \"f0_5\": 0.8535403827004333, \"p4\": 0.7101518368756736, \"phi\": 0.5506072307988509}, {\"truth_threshold\": 9.44, \"match_probability\": 0.9985623537698158, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6338, \"tn\": 7017, \"fp\": 1, \"fn\": 5443, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5379848909260674, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4620151090739326, \"precision\": 0.9998422464111059, \"recall\": 0.5379848909260674, \"specificity\": 0.999857509261898, \"npv\": 0.5631621187800963, \"accuracy\": 0.7104101281983084, \"f1\": 0.6995584988962472, \"f2\": 0.5927463853506163, \"f0_5\": 0.8533268707757762, \"p4\": 0.7098773547942239, \"phi\": 0.5502795826584318}, {\"truth_threshold\": 9.46, \"match_probability\": 0.9985821182068747, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6332, \"tn\": 7017, \"fp\": 1, \"fn\": 5449, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5374755962991257, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4625244037008743, \"precision\": 0.9998420969524712, \"recall\": 0.5374755962991257, \"specificity\": 0.999857509261898, \"npv\": 0.5628910636932456, \"accuracy\": 0.710090962285228, \"f1\": 0.6991277464944242, \"f2\": 0.5922517163327534, \"f0_5\": 0.8530703527065988, \"p4\": 0.7095478717613215, \"phi\": 0.5498864944803914}, {\"truth_threshold\": 9.48, \"match_probability\": 0.9986016113074108, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6329, \"tn\": 7017, \"fp\": 1, \"fn\": 5452, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5372209489856549, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46277905101434513, \"precision\": 0.9998420221169037, \"recall\": 0.5372209489856549, \"specificity\": 0.999857509261898, \"npv\": 0.5627556339722511, \"accuracy\": 0.7099313793286877, \"f1\": 0.6989122632654188, \"f2\": 0.592004340180342, \"f0_5\": 0.8529419692191585, \"p4\": 0.7093830873493934, \"phi\": 0.5496899869435955}, {\"truth_threshold\": 9.5, \"match_probability\": 0.9986208367860828, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6316, \"tn\": 7017, \"fp\": 1, \"fn\": 5465, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5361174772939479, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4638825227060521, \"precision\": 0.9998416970080735, \"recall\": 0.5361174772939479, \"specificity\": 0.999857509261898, \"npv\": 0.5621695241147252, \"accuracy\": 0.70923985318368, \"f1\": 0.6979776770913914, \"f2\": 0.5909320559121274, \"f0_5\": 0.8523846797484412, \"p4\": 0.7086686895191092, \"phi\": 0.548838734680349}, {\"truth_threshold\": 9.52, \"match_probability\": 0.9986397983069785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6310, \"tn\": 7017, \"fp\": 1, \"fn\": 5471, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5356081826670062, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4643918173329938, \"precision\": 0.9998415465061005, \"recall\": 0.5356081826670062, \"specificity\": 0.999857509261898, \"npv\": 0.5618994234465087, \"accuracy\": 0.7089206872705995, \"f1\": 0.6975458766305549, \"f2\": 0.5904369795078133, \"f0_5\": 0.8521269412559082, \"p4\": 0.7083387845827182, \"phi\": 0.5484460020462248}, {\"truth_threshold\": 9.540000000000001, \"match_probability\": 0.9986584994842955, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6303, \"tn\": 7017, \"fp\": 1, \"fn\": 5478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5350140056022409, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4649859943977591, \"precision\": 0.9998413705583756, \"recall\": 0.5350140056022409, \"specificity\": 0.999857509261898, \"npv\": 0.5615846338535414, \"accuracy\": 0.7085483270386723, \"f1\": 0.6970417473043959, \"f2\": 0.589859249831549, \"f0_5\": 0.8518258237154364, \"p4\": 0.7079537486949808, \"phi\": 0.5479879355094625}, {\"truth_threshold\": 9.56, \"match_probability\": 0.9986769438830138, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6301, \"tn\": 7017, \"fp\": 1, \"fn\": 5480, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5348442407265936, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46515575927340636, \"precision\": 0.9998413202158045, \"recall\": 0.5348442407265936, \"specificity\": 0.999857509261898, \"npv\": 0.5614947587420981, \"accuracy\": 0.7084419384009788, \"f1\": 0.6968976386661505, \"f2\": 0.5896941564032494, \"f0_5\": 0.8517397063991997, \"p4\": 0.707843709310231, \"phi\": 0.5478570833259973}, {\"truth_threshold\": 9.58, \"match_probability\": 0.9986951350195571, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6300, \"tn\": 7017, \"fp\": 1, \"fn\": 5481, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5347593582887701, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46524064171123, \"precision\": 0.9998412950325345, \"recall\": 0.5347593582887701, \"specificity\": 0.999857509261898, \"npv\": 0.5614498319731157, \"accuracy\": 0.708388744082132, \"f1\": 0.6968255723924345, \"f2\": 0.5896116050538137, \"f0_5\": 0.8516966337704475, \"p4\": 0.7077886847521341, \"phi\": 0.54779166122144}, {\"truth_threshold\": 9.6, \"match_probability\": 0.9987130763624487, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6298, \"tn\": 7017, \"fp\": 1, \"fn\": 5483, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5345895934131228, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46541040658687716, \"precision\": 0.9998412446420066, \"recall\": 0.5345895934131228, \"specificity\": 0.999857509261898, \"npv\": 0.56136, \"accuracy\": 0.7082823554444385, \"f1\": 0.6966814159292035, \"f2\": 0.5894464930835034, \"f0_5\": 0.8516104605565622, \"p4\": 0.7076786258939467, \"phi\": 0.5476608249788696}, {\"truth_threshold\": 9.620000000000001, \"match_probability\": 0.9987307713329557, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6293, \"tn\": 7017, \"fp\": 1, \"fn\": 5488, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5341651812240048, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46583481877599525, \"precision\": 0.9998411185255799, \"recall\": 0.5341651812240048, \"specificity\": 0.999857509261898, \"npv\": 0.5611355457816873, \"accuracy\": 0.7080163838502048, \"f1\": 0.6963208852005532, \"f2\": 0.5890336590662324, \"f0_5\": 0.8513948643017561, \"p4\": 0.7074034218216235, \"phi\": 0.5473337807710885}, {\"truth_threshold\": 9.64, \"match_probability\": 0.998748223305727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6290, \"tn\": 7017, \"fp\": 1, \"fn\": 5491, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5339105339105339, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4660894660894661, \"precision\": 0.9998410427594977, \"recall\": 0.5339105339105339, \"specificity\": 0.999857509261898, \"npv\": 0.5610009593859929, \"accuracy\": 0.7078568008936645, \"f1\": 0.6961044710048694, \"f2\": 0.5887859215576149, \"f0_5\": 0.8512653945053458, \"p4\": 0.7072382602580997, \"phi\": 0.5471375860001828}, {\"truth_threshold\": 9.66, \"match_probability\": 0.9987654356094217, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6283, \"tn\": 7017, \"fp\": 1, \"fn\": 5498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5333163568457686, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4666836431542314, \"precision\": 0.9998408656906429, \"recall\": 0.5333163568457686, \"specificity\": 0.999857509261898, \"npv\": 0.5606871753895326, \"accuracy\": 0.7074844406617373, \"f1\": 0.6955992250207583, \"f2\": 0.5882077591372079, \"f0_5\": 0.8509629709889752, \"p4\": 0.7068527688055339, \"phi\": 0.5466798905433363}, {\"truth_threshold\": 9.68, \"match_probability\": 0.9987824115273289, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6271, \"tn\": 7017, \"fp\": 1, \"fn\": 5510, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5322977675918852, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46770223240811476, \"precision\": 0.9998405612244898, \"recall\": 0.5322977675918852, \"specificity\": 0.999857509261898, \"npv\": 0.5601500758361938, \"accuracy\": 0.7068461088355764, \"f1\": 0.6947321774774275, \"f2\": 0.587216270881714, \"f0_5\": 0.8504434619870351, \"p4\": 0.7061915516916564, \"phi\": 0.545895569225978}, {\"truth_threshold\": 9.700000000000001, \"match_probability\": 0.9987991542979808, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6264, \"tn\": 7017, \"fp\": 1, \"fn\": 5517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5317035905271199, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.46829640947288004, \"precision\": 0.9998403830806065, \"recall\": 0.5317035905271199, \"specificity\": 0.999857509261898, \"npv\": 0.5598372426998564, \"accuracy\": 0.7064737486036491, \"f1\": 0.6942258672281946, \"f2\": 0.5866376969038566, \"f0_5\": 0.850139789907983, \"p4\": 0.7058056219505777, \"phi\": 0.545438222246268}, {\"truth_threshold\": 9.72, \"match_probability\": 0.9988156671157563, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6255, \"tn\": 7017, \"fp\": 1, \"fn\": 5526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5309396485867074, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4690603514132926, \"precision\": 0.9998401534526854, \"recall\": 0.5309396485867074, \"specificity\": 0.999857509261898, \"npv\": 0.5594355417364267, \"accuracy\": 0.7059949997340285, \"f1\": 0.6935743194544547, \"f2\": 0.5858935931060322, \"f0_5\": 0.849748675451705, \"p4\": 0.7053091871995145, \"phi\": 0.5448503918142884}, {\"truth_threshold\": 9.74, \"match_probability\": 0.9988319531314767, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6247, \"tn\": 7017, \"fp\": 1, \"fn\": 5534, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5302605890841185, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4697394109158815, \"precision\": 0.9998399487836107, \"recall\": 0.5302605890841185, \"specificity\": 0.999857509261898, \"npv\": 0.559078957851964, \"accuracy\": 0.7055694451832544, \"f1\": 0.6929946197792446, \"f2\": 0.5852319568312974, \"f0_5\": 0.8494003752753378, \"p4\": 0.704867684627019, \"phi\": 0.5443280517438777}, {\"truth_threshold\": 9.76, \"match_probability\": 0.9988480154529947, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6235, \"tn\": 7017, \"fp\": 1, \"fn\": 5546, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5292419998302351, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4707580001697649, \"precision\": 0.9998396407953817, \"recall\": 0.5292419998302351, \"specificity\": 0.999857509261898, \"npv\": 0.5585449335349837, \"accuracy\": 0.7049311133570935, \"f1\": 0.6921241050119332, \"f2\": 0.5842391304347826, \"f0_5\": 0.8488767869298843, \"p4\": 0.7042050272624966, \"phi\": 0.5435448501851673}, {\"truth_threshold\": 9.78, \"match_probability\": 0.9988638571457743, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6229, \"tn\": 7017, \"fp\": 1, \"fn\": 5552, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5287327052032934, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47126729479670654, \"precision\": 0.9998394863563402, \"recall\": 0.5287327052032934, \"specificity\": 0.999857509261898, \"npv\": 0.558278303763227, \"accuracy\": 0.704611947444013, \"f1\": 0.691688412636722, \"f2\": 0.5837425497619673, \"f0_5\": 0.8486144791695049, \"p4\": 0.703873515991607, \"phi\": 0.5431533875215552}, {\"truth_threshold\": 9.8, \"match_probability\": 0.9988794812334637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6226, \"tn\": 7017, \"fp\": 1, \"fn\": 5555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5284780578898226, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4715219421101774, \"precision\": 0.9998394090252127, \"recall\": 0.5284780578898226, \"specificity\": 0.999857509261898, \"npv\": 0.5581450843143494, \"accuracy\": 0.7044523644874727, \"f1\": 0.6914704575744114, \"f2\": 0.5834942175404397, \"f0_5\": 0.8484831965984355, \"p4\": 0.7037077145042581, \"phi\": 0.5429576905712111}, {\"truth_threshold\": 9.82, \"match_probability\": 0.9988948906984604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6217, \"tn\": 7017, \"fp\": 1, \"fn\": 5564, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5277141159494101, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4722858840505899, \"precision\": 0.9998391765841107, \"recall\": 0.5277141159494101, \"specificity\": 0.999857509261898, \"npv\": 0.5577458071695414, \"accuracy\": 0.703973615617852, \"f1\": 0.6908161564531363, \"f2\": 0.5827490532788422, \"f0_5\": 0.848088833110523, \"p4\": 0.7032101259304776, \"phi\": 0.5423707367404098}, {\"truth_threshold\": 9.84, \"match_probability\": 0.9989100884824688, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6216, \"tn\": 7017, \"fp\": 1, \"fn\": 5565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5276292335115864, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47237076648841353, \"precision\": 0.9998391507157793, \"recall\": 0.5276292335115864, \"specificity\": 0.999857509261898, \"npv\": 0.5577014783023366, \"accuracy\": 0.7039204212990052, \"f1\": 0.6907434159351039, \"f2\": 0.5826662417277516, \"f0_5\": 0.8480449671205217, \"p4\": 0.7031548212166093, \"phi\": 0.5423055323013455}, {\"truth_threshold\": 9.86, \"match_probability\": 0.9989250774870504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6207, \"tn\": 7017, \"fp\": 1, \"fn\": 5574, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5268652915711739, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4731347084288261, \"precision\": 0.9998389175257731, \"recall\": 0.5268652915711739, \"specificity\": 0.999857509261898, \"npv\": 0.5573028353585895, \"accuracy\": 0.7034416724293845, \"f1\": 0.6900883873478236, \"f2\": 0.5819207980199504, \"f0_5\": 0.8476497418949553, \"p4\": 0.7026569243188271, \"phi\": 0.5417188057842359}, {\"truth_threshold\": 9.88, \"match_probability\": 0.9989398605741672, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6202, \"tn\": 7017, \"fp\": 1, \"fn\": 5579, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5264408793820559, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47355912061794414, \"precision\": 0.999838787683379, \"recall\": 0.5264408793820559, \"specificity\": 0.999857509261898, \"npv\": 0.5570816132105431, \"accuracy\": 0.7031757008351508, \"f1\": 0.6897241992882562, \"f2\": 0.581506553903276, \"f0_5\": 0.8474298363074905, \"p4\": 0.7023801944027092, \"phi\": 0.5413929345617802}, {\"truth_threshold\": 9.9, \"match_probability\": 0.9989544405667166, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6197, \"tn\": 7017, \"fp\": 1, \"fn\": 5584, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5260164671929378, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47398353280706224, \"precision\": 0.999838657631494, \"recall\": 0.5260164671929378, \"specificity\": 0.999857509261898, \"npv\": 0.5568605666216967, \"accuracy\": 0.7029097292409171, \"f1\": 0.6893598086656655, \"f2\": 0.5810922320993211, \"f0_5\": 0.8472096902086238, \"p4\": 0.7021033780477702, \"phi\": 0.5410671259163208}, {\"truth_threshold\": 9.92, \"match_probability\": 0.998968820249061, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6192, \"tn\": 7017, \"fp\": 1, \"fn\": 5589, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5255920550038197, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4744079449961803, \"precision\": 0.9998385273696109, \"recall\": 0.5255920550038197, \"specificity\": 0.999857509261898, \"npv\": 0.5566396953831508, \"accuracy\": 0.7026437576466833, \"f1\": 0.6889952153110048, \"f2\": 0.5806778325862295, \"f0_5\": 0.8469893032035675, \"p4\": 0.7018264749793452, \"phi\": 0.5407413796527871}, {\"truth_threshold\": 9.94, \"match_probability\": 0.9989830023675484, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6190, \"tn\": 7017, \"fp\": 1, \"fn\": 5591, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5254222901281724, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4745777098718275, \"precision\": 0.9998384752059442, \"recall\": 0.5254222901281724, \"specificity\": 0.999857509261898, \"npv\": 0.5565513959390863, \"accuracy\": 0.7025373690089899, \"f1\": 0.6888493211662586, \"f2\": 0.5805120510175373, \"f0_5\": 0.8469010808592147, \"p4\": 0.7017156894105677, \"phi\": 0.5406110985706164}, {\"truth_threshold\": 9.96, \"match_probability\": 0.9989969896310279, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6180, \"tn\": 7017, \"fp\": 1, \"fn\": 5601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5245734657499364, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47542653425006365, \"precision\": 0.9998382138812489, \"recall\": 0.5245734657499364, \"specificity\": 0.999857509261898, \"npv\": 0.5561103185924869, \"accuracy\": 0.7020054258205224, \"f1\": 0.6881193630998775, \"f2\": 0.5796829565706781, \"f0_5\": 0.8464593891247775, \"p4\": 0.701161552175988, \"phi\": 0.5399598419712338}, {\"truth_threshold\": 9.98, \"match_probability\": 0.9990107847113568, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6176, \"tn\": 7017, \"fp\": 1, \"fn\": 5605, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5242339359986419, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4757660640013581, \"precision\": 0.9998381091144568, \"recall\": 0.5242339359986419, \"specificity\": 0.999857509261898, \"npv\": 0.5559340833465378, \"accuracy\": 0.7017926485451353, \"f1\": 0.6878271522441252, \"f2\": 0.5793512316842085, \"f0_5\": 0.8462824412836746, \"p4\": 0.7009397992363576, \"phi\": 0.539699408543776}, {\"truth_threshold\": 10.0, \"match_probability\": 0.9990243902439024, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6162, \"tn\": 7017, \"fp\": 1, \"fn\": 5619, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5230455818691113, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47695441813088874, \"precision\": 0.9998377413597274, \"recall\": 0.5230455818691113, \"specificity\": 0.999857509261898, \"npv\": 0.555318138651472, \"accuracy\": 0.7010479280812809, \"f1\": 0.6868033883192154, \"f2\": 0.5781898023908271, \"f0_5\": 0.8456618999258914, \"p4\": 0.700163220133725, \"phi\": 0.5387882011675941}, {\"truth_threshold\": 10.02, \"match_probability\": 0.9990378088280355, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6155, \"tn\": 7017, \"fp\": 1, \"fn\": 5626, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5224514048043459, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.477548595195654, \"precision\": 0.9998375568551007, \"recall\": 0.5224514048043459, \"specificity\": 0.999857509261898, \"npv\": 0.5550106778454481, \"accuracy\": 0.7006755678493537, \"f1\": 0.6862909070636115, \"f2\": 0.5776088588588588, \"f0_5\": 0.8453509133360803, \"p4\": 0.6997746703278418, \"phi\": 0.538332777135125}, {\"truth_threshold\": 10.040000000000001, \"match_probability\": 0.9990510430276189, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6153, \"tn\": 7017, \"fp\": 1, \"fn\": 5628, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5222816399286988, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47771836007130125, \"precision\": 0.9998375040623985, \"recall\": 0.5222816399286988, \"specificity\": 0.999857509261898, \"npv\": 0.5549228944246738, \"accuracy\": 0.7005691792116602, \"f1\": 0.6861444103707833, \"f2\": 0.5774428469537145, \"f0_5\": 0.845261972140561, \"p4\": 0.6996636240757003, \"phi\": 0.5382026778739366}, {\"truth_threshold\": 10.06, \"match_probability\": 0.9990640953714882, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6140, \"tn\": 7017, \"fp\": 1, \"fn\": 5641, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5211781682369918, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47882183176300824, \"precision\": 0.9998371600716496, \"recall\": 0.5211781682369918, \"specificity\": 0.999857509261898, \"npv\": 0.5543529783536104, \"accuracy\": 0.6998776530666525, \"f1\": 0.6851913848900792, \"f2\": 0.5763634656904159, \"f0_5\": 0.8446828999862429, \"p4\": 0.698941474931467, \"phi\": 0.5373572687119891}, {\"truth_threshold\": 10.08, \"match_probability\": 0.9990769683539271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6127, \"tn\": 7017, \"fp\": 1, \"fn\": 5654, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5200746965452848, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.47992530345471524, \"precision\": 0.9998368146214099, \"recall\": 0.5200746965452848, \"specificity\": 0.999857509261898, \"npv\": 0.5537842317102044, \"accuracy\": 0.6991861269216447, \"f1\": 0.6842369758222123, \"f2\": 0.5752835574250732, \"f0_5\": 0.8441021684622378, \"p4\": 0.6982187181656, \"phi\": 0.5365122662162318}, {\"truth_threshold\": 10.1, \"match_probability\": 0.9990896644351354, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6118, \"tn\": 7017, \"fp\": 1, \"fn\": 5663, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5193107546048723, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48068924539512775, \"precision\": 0.9998365746036935, \"recall\": 0.5193107546048723, \"specificity\": 0.999857509261898, \"npv\": 0.553391167192429, \"accuracy\": 0.6987073780520241, \"f1\": 0.6835754189944134, \"f2\": 0.5745356197058769, \"f0_5\": 0.8436991477507791, \"p4\": 0.697717989546616, \"phi\": 0.5359275009096163}, {\"truth_threshold\": 10.120000000000001, \"match_probability\": 0.9991021860416915, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6116, \"tn\": 7017, \"fp\": 1, \"fn\": 5665, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5191409897292251, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.480859010270775, \"precision\": 0.9998365211705085, \"recall\": 0.5191409897292251, \"specificity\": 0.999857509261898, \"npv\": 0.5533038952846554, \"accuracy\": 0.6986009894143306, \"f1\": 0.6834283160129624, \"f2\": 0.5743693769839033, \"f0_5\": 0.8436094788821761, \"p4\": 0.6976066764819212, \"phi\": 0.5357975791953101}, {\"truth_threshold\": 10.14, \"match_probability\": 0.9991145355670089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6111, \"tn\": 7017, \"fp\": 1, \"fn\": 5670, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5187165775401069, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48128342245989303, \"precision\": 0.9998363874345549, \"recall\": 0.5187165775401069, \"specificity\": 0.999857509261898, \"npv\": 0.5530858358950106, \"accuracy\": 0.6983350178200968, \"f1\": 0.6830604146873079, \"f2\": 0.5739537155308438, \"f0_5\": 0.8433851334566231, \"p4\": 0.6973283299109173, \"phi\": 0.5354728163367994}, {\"truth_threshold\": 10.16, \"match_probability\": 0.9991267153717854, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6109, \"tn\": 7017, \"fp\": 1, \"fn\": 5672, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5185468126644597, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48145318733554027, \"precision\": 0.999836333878887, \"recall\": 0.5185468126644597, \"specificity\": 0.999857509261898, \"npv\": 0.5529986602569155, \"accuracy\": 0.6982286291824034, \"f1\": 0.6829131965792856, \"f2\": 0.5737874290866739, \"f0_5\": 0.8432953259159052, \"p4\": 0.6972169656710102, \"phi\": 0.5353429277314987}, {\"truth_threshold\": 10.18, \"match_probability\": 0.9991387277844479, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6106, \"tn\": 7017, \"fp\": 1, \"fn\": 5675, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5182921653509889, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4817078346490111, \"precision\": 0.9998362534796136, \"recall\": 0.5182921653509889, \"specificity\": 0.999857509261898, \"npv\": 0.5528679483138985, \"accuracy\": 0.6980690462258631, \"f1\": 0.6826923076923077, \"f2\": 0.5735379759914335, \"f0_5\": 0.8431605401971886, \"p4\": 0.6970498918132766, \"phi\": 0.535148112503897}, {\"truth_threshold\": 10.200000000000001, \"match_probability\": 0.9991505751015896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6100, \"tn\": 7017, \"fp\": 1, \"fn\": 5681, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5177828707240472, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4822171292759528, \"precision\": 0.9998360924438616, \"recall\": 0.5177828707240472, \"specificity\": 0.999857509261898, \"npv\": 0.5526067097180658, \"accuracy\": 0.6977498803127826, \"f1\": 0.68225030757186, \"f2\": 0.5730389854391733, \"f0_5\": 0.8428907005665331, \"p4\": 0.6967156448794765, \"phi\": 0.5347585455433139}, {\"truth_threshold\": 10.22, \"match_probability\": 0.9991622595884027, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6094, \"tn\": 7017, \"fp\": 1, \"fn\": 5687, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5172735760971056, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4827264239028945, \"precision\": 0.9998359310910583, \"recall\": 0.5172735760971056, \"specificity\": 0.999857509261898, \"npv\": 0.552345717884131, \"accuracy\": 0.6974307143997021, \"f1\": 0.6818080107406579, \"f2\": 0.5725398823728368, \"f0_5\": 0.8426205027515832, \"p4\": 0.6963812652429492, \"phi\": 0.5343690629610437}, {\"truth_threshold\": 10.24, \"match_probability\": 0.999173783479105, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6091, \"tn\": 7017, \"fp\": 1, \"fn\": 5690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5170189287836346, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48298107121636535, \"precision\": 0.9998358502954695, \"recall\": 0.5170189287836346, \"specificity\": 0.999857509261898, \"npv\": 0.5522153143936414, \"accuracy\": 0.6972711314431619, \"f1\": 0.681586750965143, \"f2\": 0.572290288634997, \"f0_5\": 0.8424852693020554, \"p4\": 0.6962140255065186, \"phi\": 0.5341743532063247}, {\"truth_threshold\": 10.26, \"match_probability\": 0.9991851489773601, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6088, \"tn\": 7017, \"fp\": 1, \"fn\": 5693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5167642814701638, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48323571852983616, \"precision\": 0.9998357694202661, \"recall\": 0.5167642814701638, \"specificity\": 0.999857509261898, \"npv\": 0.5520849724626279, \"accuracy\": 0.6971115484866216, \"f1\": 0.6813654168998321, \"f2\": 0.5720406667543645, \"f0_5\": 0.8423499460386861, \"p4\": 0.6960467524086789, \"phi\": 0.5339796644196375}, {\"truth_threshold\": 10.28, \"match_probability\": 0.9991963582566927, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6072, \"tn\": 7017, \"fp\": 1, \"fn\": 5709, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5154061624649859, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.484593837535014, \"precision\": 0.9998353367363741, \"recall\": 0.5154061624649859, \"specificity\": 0.999857509261898, \"npv\": 0.5513908533710514, \"accuracy\": 0.6962604393850736, \"f1\": 0.6801837123333707, \"f2\": 0.5707088745605955, \"f0_5\": 0.8416267014110277, \"p4\": 0.6951540632171155, \"phi\": 0.5329416766089639}, {\"truth_threshold\": 10.3, \"match_probability\": 0.9992074134608979, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6065, \"tn\": 7017, \"fp\": 1, \"fn\": 5716, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5148119854002207, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4851880145997793, \"precision\": 0.9998351467194198, \"recall\": 0.5148119854002207, \"specificity\": 0.999857509261898, \"npv\": 0.55108772480955, \"accuracy\": 0.6958880791531464, \"f1\": 0.6796660503165798, \"f2\": 0.5701259635269788, \"f0_5\": 0.8413094742682757, \"p4\": 0.6947632103267175, \"phi\": 0.532487742476405}, {\"truth_threshold\": 10.32, \"match_probability\": 0.9992183167044456, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6056, \"tn\": 7017, \"fp\": 1, \"fn\": 5725, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5140480434598081, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48595195654019185, \"precision\": 0.9998349017665511, \"recall\": 0.5140480434598081, \"specificity\": 0.999857509261898, \"npv\": 0.5506984774760634, \"accuracy\": 0.6954093302835257, \"f1\": 0.6789998878798071, \"f2\": 0.5693762810026137, \"f0_5\": 0.8409008858896387, \"p4\": 0.6942604138546631, \"phi\": 0.5319042776209122}, {\"truth_threshold\": 10.34, \"match_probability\": 0.9992290700728785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6044, \"tn\": 7017, \"fp\": 1, \"fn\": 5737, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5130294542059248, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4869705457940752, \"precision\": 0.9998345740281224, \"recall\": 0.5130294542059248, \"specificity\": 0.999857509261898, \"npv\": 0.5501803355809942, \"accuracy\": 0.6947709984573648, \"f1\": 0.6781106249298777, \"f2\": 0.5683763095036581, \"f0_5\": 0.840354828842357, \"p4\": 0.6935895409981094, \"phi\": 0.5311266109426723}, {\"truth_threshold\": 10.38, \"match_probability\": 0.9992501353842916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6042, \"tn\": 7017, \"fp\": 1, \"fn\": 5739, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5128596893302776, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4871403106697224, \"precision\": 0.9998345192785041, \"recall\": 0.5128596893302776, \"specificity\": 0.999857509261898, \"npv\": 0.5500940733772343, \"accuracy\": 0.6946646098196713, \"f1\": 0.6779622980251346, \"f2\": 0.5682096037015442, \"f0_5\": 0.8402636775790615, \"p4\": 0.6934776755424131, \"phi\": 0.5309970314909376}, {\"truth_threshold\": 10.4, \"match_probability\": 0.999260451357236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6039, \"tn\": 7017, \"fp\": 1, \"fn\": 5742, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5126050420168067, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48739495798319327, \"precision\": 0.9998344370860928, \"recall\": 0.5126050420168067, \"specificity\": 0.999857509261898, \"npv\": 0.5499647307782741, \"accuracy\": 0.694505026863131, \"f1\": 0.6777397452443746, \"f2\": 0.5679595214807013, \"f0_5\": 0.840126874600039, \"p4\": 0.6933098486988434, \"phi\": 0.5308026792082744}, {\"truth_threshold\": 10.42, \"match_probability\": 0.9992706255157543, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6032, \"tn\": 7017, \"fp\": 1, \"fn\": 5749, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5120108649520414, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4879891350479586, \"precision\": 0.9998342449859108, \"recall\": 0.5120108649520414, \"specificity\": 0.999857509261898, \"npv\": 0.5496631677894407, \"accuracy\": 0.6941326666312038, \"f1\": 0.6772201639160211, \"f2\": 0.5673758865248227, \"f0_5\": 0.83980731211539, \"p4\": 0.692918118655063, \"phi\": 0.5303492691727643}, {\"truth_threshold\": 10.44, \"match_probability\": 0.9992806598065492, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6027, \"tn\": 7017, \"fp\": 1, \"fn\": 5754, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5115864527629234, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48841354723707664, \"precision\": 0.9998341074983411, \"recall\": 0.5115864527629234, \"specificity\": 0.999857509261898, \"npv\": 0.5494479680526192, \"accuracy\": 0.6938666950369701, \"f1\": 0.6768487843225336, \"f2\": 0.566958910295003, \"f0_5\": 0.8395787479452818, \"p4\": 0.6926381962063473, \"phi\": 0.5300254720190346}, {\"truth_threshold\": 10.46, \"match_probability\": 0.9992905561496781, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6020, \"tn\": 7017, \"fp\": 1, \"fn\": 5761, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5109922756981581, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.489007724301842, \"precision\": 0.9998339146321209, \"recall\": 0.5109922756981581, \"specificity\": 0.999857509261898, \"npv\": 0.5491469713570198, \"accuracy\": 0.6934943348050429, \"f1\": 0.6763285024154589, \"f2\": 0.5663750117602785, \"f0_5\": 0.8392583298480413, \"p4\": 0.6922461427666944, \"phi\": 0.5295722496078638}, {\"truth_threshold\": 10.48, \"match_probability\": 0.9993003164389153, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6014, \"tn\": 7017, \"fp\": 1, \"fn\": 5767, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5104829810712164, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.48951701892878363, \"precision\": 0.999833748960931, \"recall\": 0.5104829810712164, \"specificity\": 0.999857509261898, \"npv\": 0.5488892365456821, \"accuracy\": 0.6931751688919623, \"f1\": 0.6758822207237581, \"f2\": 0.5658744048627186, \"f0_5\": 0.8389832872966714, \"p4\": 0.6919099459690242, \"phi\": 0.5291838598072464}, {\"truth_threshold\": 10.5, \"match_probability\": 0.9993099425421107, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5998, \"tn\": 7017, \"fp\": 1, \"fn\": 5783, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5091248620660386, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4908751379339615, \"precision\": 0.9998333055509252, \"recall\": 0.5091248620660386, \"specificity\": 0.999857509261898, \"npv\": 0.548203125, \"accuracy\": 0.6923240597904143, \"f1\": 0.6746906636670417, \"f2\": 0.5645389002880108, \"f0_5\": 0.8382480364479973, \"p4\": 0.6910127357388371, \"phi\": 0.5281485416016103}, {\"truth_threshold\": 10.52, \"match_probability\": 0.9993194363015417, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5991, \"tn\": 7017, \"fp\": 1, \"fn\": 5790, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5085306850012732, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49146931499872676, \"precision\": 0.9998331108144193, \"recall\": 0.5085306850012732, \"specificity\": 0.999857509261898, \"npv\": 0.5479034902787538, \"accuracy\": 0.6919516995584871, \"f1\": 0.6741686828335115, \"f2\": 0.5639543640334362, \"f0_5\": 0.83792553637864, \"p4\": 0.6906198909010781, \"phi\": 0.5276957661016479}, {\"truth_threshold\": 10.540000000000001, \"match_probability\": 0.9993287995342623, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5981, \"tn\": 7017, \"fp\": 1, \"fn\": 5800, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5076818606230371, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4923181393769629, \"precision\": 0.9998328318288198, \"recall\": 0.5076818606230371, \"specificity\": 0.999857509261898, \"npv\": 0.5474760084263088, \"accuracy\": 0.6914197563700197, \"f1\": 0.6734222822721387, \"f2\": 0.5631190449290099, \"f0_5\": 0.8374639446638102, \"p4\": 0.690058348763606, \"phi\": 0.5270491285597032}, {\"truth_threshold\": 10.56, \"match_probability\": 0.9993380340324456, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5976, \"tn\": 7017, \"fp\": 1, \"fn\": 5805, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5072574484339191, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.492742551566081, \"precision\": 0.9998326919859462, \"recall\": 0.5072574484339191, \"specificity\": 0.999857509261898, \"npv\": 0.5472625175479644, \"accuracy\": 0.6911537847757859, \"f1\": 0.6730487667530127, \"f2\": 0.5627012673960943, \"f0_5\": 0.8372327607946426, \"p4\": 0.6897774291407547, \"phi\": 0.5267258907993542}, {\"truth_threshold\": 10.58, \"match_probability\": 0.9993471415637232, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5973, \"tn\": 7017, \"fp\": 1, \"fn\": 5808, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5070028011204482, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49299719887955185, \"precision\": 0.9998326079678608, \"recall\": 0.5070028011204482, \"specificity\": 0.999857509261898, \"npv\": 0.5471345029239766, \"accuracy\": 0.6909942018192458, \"f1\": 0.6728245564629681, \"f2\": 0.5624505631097216, \"f0_5\": 0.8370939260588054, \"p4\": 0.6896088296564364, \"phi\": 0.5265319739536924}, {\"truth_threshold\": 10.6, \"match_probability\": 0.9993561238715196, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5969, \"tn\": 7017, \"fp\": 1, \"fn\": 5812, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5066632713691537, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49333672863084627, \"precision\": 0.9998324958123953, \"recall\": 0.5066632713691537, \"specificity\": 0.999857509261898, \"npv\": 0.5469639098916518, \"accuracy\": 0.6907814245438587, \"f1\": 0.6725254915216045, \"f2\": 0.5621162466568728, \"f0_5\": 0.8369086677322565, \"p4\": 0.6893839745465404, \"phi\": 0.5262734481839904}, {\"truth_threshold\": 10.620000000000001, \"match_probability\": 0.9993649826753817, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5959, \"tn\": 7017, \"fp\": 1, \"fn\": 5822, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5058144469909176, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4941855530090824, \"precision\": 0.9998322147651006, \"recall\": 0.5058144469909176, \"specificity\": 0.999857509261898, \"npv\": 0.546537892359218, \"accuracy\": 0.6902494813553912, \"f1\": 0.6717772391635195, \"f2\": 0.5612802350990882, \"f0_5\": 0.8364447938014092, \"p4\": 0.6888215568252662, \"phi\": 0.5256272832603104}, {\"truth_threshold\": 10.64, \"match_probability\": 0.9993737196713037, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5948, \"tn\": 7017, \"fp\": 1, \"fn\": 5833, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5048807401748578, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49511925982514216, \"precision\": 0.9998319045217684, \"recall\": 0.5048807401748578, \"specificity\": 0.999857509261898, \"npv\": 0.5460700389105059, \"accuracy\": 0.6896643438480771, \"f1\": 0.6709531866892273, \"f2\": 0.560360258511861, \"f0_5\": 0.8359333277117239, \"p4\": 0.6882024330857236, \"phi\": 0.5249167470105417}, {\"truth_threshold\": 10.66, \"match_probability\": 0.9993823365320493, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5945, \"tn\": 7017, \"fp\": 1, \"fn\": 5836, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5046260928613869, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.495373907138613, \"precision\": 0.9998318197107299, \"recall\": 0.5046260928613869, \"specificity\": 0.999857509261898, \"npv\": 0.5459425814984828, \"accuracy\": 0.6895047608915368, \"f1\": 0.6707282676143735, \"f2\": 0.5601092896174863, \"f0_5\": 0.8357936173203993, \"p4\": 0.6880334963396983, \"phi\": 0.5247230087090736}, {\"truth_threshold\": 10.68, \"match_probability\": 0.9993908349074672, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5929, \"tn\": 7017, \"fp\": 1, \"fn\": 5852, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5032679738562091, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49673202614379086, \"precision\": 0.999831365935919, \"recall\": 0.5032679738562091, \"specificity\": 0.999857509261898, \"npv\": 0.545263812262025, \"accuracy\": 0.6886536517899888, \"f1\": 0.6695274123426119, \"f2\": 0.5587703094959853, \"f0_5\": 0.8350469000873215, \"p4\": 0.6871318827336321, \"phi\": 0.5236900561173482}, {\"truth_threshold\": 10.700000000000001, \"match_probability\": 0.9993992164248033, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5924, \"tn\": 7017, \"fp\": 1, \"fn\": 5857, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5028435616670911, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4971564383329089, \"precision\": 0.999831223628692, \"recall\": 0.5028435616670911, \"specificity\": 0.999857509261898, \"npv\": 0.5450520428771166, \"accuracy\": 0.6883876801957551, \"f1\": 0.6691516999887044, \"f2\": 0.5583517125676262, \"f0_5\": 0.8348129985062428, \"p4\": 0.6868499141266344, \"phi\": 0.5233673677291657}, {\"truth_threshold\": 10.72, \"match_probability\": 0.9994074826890101, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5915, \"tn\": 7017, \"fp\": 1, \"fn\": 5866, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5020796197266786, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4979203802733215, \"precision\": 0.9998309668695065, \"recall\": 0.5020796197266786, \"specificity\": 0.999857509261898, \"npv\": 0.5446712722192036, \"accuracy\": 0.6879089313261344, \"f1\": 0.6684748827484884, \"f2\": 0.5575980392156863, \"f0_5\": 0.834391310481027, \"p4\": 0.6863421118576007, \"phi\": 0.5227866587969117}, {\"truth_threshold\": 10.74, \"match_probability\": 0.9994156352830494, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5911, \"tn\": 7017, \"fp\": 1, \"fn\": 5870, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5017400899753841, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.4982599100246159, \"precision\": 0.999830852503383, \"recall\": 0.5017400899753841, \"specificity\": 0.999857509261898, \"npv\": 0.5445022115310002, \"accuracy\": 0.6876961540507474, \"f1\": 0.66817385406658, \"f2\": 0.5572629911758051, \"f0_5\": 0.8342036185046149, \"p4\": 0.6861163147783371, \"phi\": 0.5225286194124876}, {\"truth_threshold\": 10.76, \"match_probability\": 0.9994236757681928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5906, \"tn\": 7017, \"fp\": 1, \"fn\": 5875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5013156777862661, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.498684322213734, \"precision\": 0.9998307093279161, \"recall\": 0.5013156777862661, \"specificity\": 0.999857509261898, \"npv\": 0.5442910331988831, \"accuracy\": 0.6874301824565137, \"f1\": 0.6677973767526006, \"f2\": 0.5568441100488394, \"f0_5\": 0.8339687650032478, \"p4\": 0.685833975341428, \"phi\": 0.5222061162456415}, {\"truth_threshold\": 10.78, \"match_probability\": 0.9994316056843171, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5901, \"tn\": 7017, \"fp\": 1, \"fn\": 5880, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5008912655971479, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49910873440285203, \"precision\": 0.9998305659098611, \"recall\": 0.5008912655971479, \"specificity\": 0.999857509261898, \"npv\": 0.5440800186089788, \"accuracy\": 0.6871642108622799, \"f1\": 0.6674206865350902, \"f2\": 0.5564251499264512, \"f0_5\": 0.8337336460482071, \"p4\": 0.6855515321840239, \"phi\": 0.5218836640772315}, {\"truth_threshold\": 10.8, \"match_probability\": 0.9994394265501966, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5894, \"tn\": 7017, \"fp\": 1, \"fn\": 5887, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.5002970885323826, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.49970291146761736, \"precision\": 0.999830364715861, \"recall\": 0.5002970885323826, \"specificity\": 0.999857509261898, \"npv\": 0.5437848729076256, \"accuracy\": 0.6867918506303526, \"f1\": 0.6668929622086445, \"f2\": 0.5558384730002452, \"f0_5\": 0.8334040326913832, \"p4\": 0.6851559369211601, \"phi\": 0.5214323163445252}, {\"truth_threshold\": 10.82, \"match_probability\": 0.9994471398637907, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5884, \"tn\": 7017, \"fp\": 1, \"fn\": 5897, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4994482641541465, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5005517358458534, \"precision\": 0.9998300764655905, \"recall\": 0.4994482641541465, \"specificity\": 0.999857509261898, \"npv\": 0.5433637912343193, \"accuracy\": 0.6862599074418853, \"f1\": 0.6661383448432017, \"f2\": 0.5550000943236054, \"f0_5\": 0.8329322499362986, \"p4\": 0.684590445428269, \"phi\": 0.5207877055257315}, {\"truth_threshold\": 10.84, \"match_probability\": 0.9994547471025279, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5877, \"tn\": 7017, \"fp\": 1, \"fn\": 5904, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4988540870893812, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5011459129106188, \"precision\": 0.9998298741068391, \"recall\": 0.4988540870893812, \"specificity\": 0.999857509261898, \"npv\": 0.5430694218713722, \"accuracy\": 0.6858875472099579, \"f1\": 0.6656096041678464, \"f2\": 0.5544130410173201, \"f0_5\": 0.8326013657099142, \"p4\": 0.6841943514097734, \"phi\": 0.5203365973629756}, {\"truth_threshold\": 10.86, \"match_probability\": 0.999462249723586, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5871, \"tn\": 7017, \"fp\": 1, \"fn\": 5910, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4983447924624395, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5016552075375604, \"precision\": 0.9998297002724795, \"recall\": 0.4983447924624395, \"specificity\": 0.999857509261898, \"npv\": 0.542817359016013, \"accuracy\": 0.6855683812968775, \"f1\": 0.6651560641250779, \"f2\": 0.5539097290361537, \"f0_5\": 0.8323173325016303, \"p4\": 0.6838546776521496, \"phi\": 0.5199500110217039}, {\"truth_threshold\": 10.88, \"match_probability\": 0.9994696491641683, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5859, \"tn\": 7017, \"fp\": 1, \"fn\": 5922, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.49732620320855614, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5026737967914439, \"precision\": 0.9998293515358362, \"recall\": 0.49732620320855614, \"specificity\": 0.999857509261898, \"npv\": 0.5423139346162764, \"accuracy\": 0.6849300494707166, \"f1\": 0.6642480585000851, \"f2\": 0.5529027630982938, \"f0_5\": 0.8317481048238267, \"p4\": 0.6831748720561448, \"phi\": 0.5191770523627167}, {\"truth_threshold\": 10.9, \"match_probability\": 0.9994769468417765, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5855, \"tn\": 7017, \"fp\": 1, \"fn\": 5926, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4969866734572617, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5030133265427383, \"precision\": 0.9998292349726776, \"recall\": 0.4969866734572617, \"specificity\": 0.999857509261898, \"npv\": 0.5421463339256741, \"accuracy\": 0.6847172721953295, \"f1\": 0.6639451153824346, \"f2\": 0.552567006417516, \"f0_5\": 0.8315580173270842, \"p4\": 0.682948133869855, \"phi\": 0.5189194625209708}, {\"truth_threshold\": 10.92, \"match_probability\": 0.9994841441544793, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5848, \"tn\": 7017, \"fp\": 1, \"fn\": 5933, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4963924963924964, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5036075036075036, \"precision\": 0.999829030603522, \"recall\": 0.4963924963924964, \"specificity\": 0.999857509261898, \"npv\": 0.5418532818532819, \"accuracy\": 0.6843449119634023, \"f1\": 0.6634146341463415, \"f2\": 0.5519793102146376, \"f0_5\": 0.8312249481195099, \"p4\": 0.6825511772840556, \"phi\": 0.5184687556830926}, {\"truth_threshold\": 10.94, \"match_probability\": 0.9994912424811782, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5838, \"tn\": 7017, \"fp\": 1, \"fn\": 5943, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.49554367201426025, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5044563279857398, \"precision\": 0.9998287377975681, \"recall\": 0.49554367201426025, \"specificity\": 0.999857509261898, \"npv\": 0.5414351851851852, \"accuracy\": 0.6838129687749348, \"f1\": 0.6626560726447219, \"f2\": 0.55113947472764, \"f0_5\": 0.8307482141332498, \"p4\": 0.6819837311772622, \"phi\": 0.5178250542681606}, {\"truth_threshold\": 10.96, \"match_probability\": 0.9994982431818683, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5832, \"tn\": 7017, \"fp\": 1, \"fn\": 5949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4950343773873186, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5049656226126814, \"precision\": 0.9998285616320932, \"recall\": 0.4950343773873186, \"specificity\": 0.999857509261898, \"npv\": 0.5411846367422489, \"accuracy\": 0.6834938028618543, \"f1\": 0.6622005223117974, \"f2\": 0.5506354211907775, \"f0_5\": 0.8304616523794606, \"p4\": 0.6816430563036133, \"phi\": 0.5174389262952731}, {\"truth_threshold\": 10.98, \"match_probability\": 0.9995051475978975, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5828, \"tn\": 7017, \"fp\": 1, \"fn\": 5953, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4946948476360241, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5053051523639759, \"precision\": 0.9998284439869617, \"recall\": 0.4946948476360241, \"specificity\": 0.999857509261898, \"npv\": 0.541017733230532, \"accuracy\": 0.6832810255864674, \"f1\": 0.6618966496308916, \"f2\": 0.5502993220402999, \"f0_5\": 0.8302703934809242, \"p4\": 0.6814158530424594, \"phi\": 0.5171815461345685}, {\"truth_threshold\": 11.0, \"match_probability\": 0.9995119570522206, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5826, \"tn\": 7017, \"fp\": 1, \"fn\": 5955, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4945250827603769, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5054749172396231, \"precision\": 0.999828385103827, \"recall\": 0.4945250827603769, \"specificity\": 0.999857509261898, \"npv\": 0.5409343200740055, \"accuracy\": 0.6831746369487739, \"f1\": 0.661744661517492, \"f2\": 0.550131253422976, \"f0_5\": 0.8301746986235002, \"p4\": 0.6813022253466666, \"phi\": 0.5170528675626836}, {\"truth_threshold\": 11.02, \"match_probability\": 0.9995186728496503, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5817, \"tn\": 7017, \"fp\": 1, \"fn\": 5964, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.49376114081996436, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5062388591800356, \"precision\": 0.9998281196287384, \"recall\": 0.49376114081996436, \"specificity\": 0.999857509261898, \"npv\": 0.5405592789461521, \"accuracy\": 0.6826958880791532, \"f1\": 0.6610602875163362, \"f2\": 0.5493747875033055, \"f0_5\": 0.8297435312241463, \"p4\": 0.6807906850408599, \"phi\": 0.5164739085431003}, {\"truth_threshold\": 11.040000000000001, \"match_probability\": 0.9995252962771056, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5790, \"tn\": 7017, \"fp\": 1, \"fn\": 5991, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.49146931499872676, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5085306850012732, \"precision\": 0.9998273182524607, \"recall\": 0.49146931499872676, \"specificity\": 0.999857509261898, \"npv\": 0.5394372693726938, \"accuracy\": 0.6812596414702909, \"f1\": 0.6590029592533576, \"f2\": 0.5471038457904186, \"f0_5\": 0.8284446988124196, \"p4\": 0.6792539306799175, \"phi\": 0.5147379501009057}, {\"truth_threshold\": 11.06, \"match_probability\": 0.9995318286038558, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5783, \"tn\": 7017, \"fp\": 1, \"fn\": 5998, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4908751379339615, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5091248620660386, \"precision\": 0.9998271092669433, \"recall\": 0.4908751379339615, \"specificity\": 0.999857509261898, \"npv\": 0.5391471379177871, \"accuracy\": 0.6808872812383637, \"f1\": 0.6584685454027897, \"f2\": 0.5465147047705451, \"f0_5\": 0.8281066529197812, \"p4\": 0.6788549860662565, \"phi\": 0.5142881090316578}, {\"truth_threshold\": 11.08, \"match_probability\": 0.9995382710817619, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5776, \"tn\": 7017, \"fp\": 1, \"fn\": 6005, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.49028096086919615, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5097190391308039, \"precision\": 0.9998268997749697, \"recall\": 0.49028096086919615, \"specificity\": 0.999857509261898, \"npv\": 0.5388573183842728, \"accuracy\": 0.6805149210064365, \"f1\": 0.6579337054334207, \"f2\": 0.5459254078372809, \"f0_5\": 0.8277680644329158, \"p4\": 0.6784558227793401, \"phi\": 0.5138383584088829}, {\"truth_threshold\": 11.1, \"match_probability\": 0.999544624945514, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5774, \"tn\": 7017, \"fp\": 1, \"fn\": 6007, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4901111959935489, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5098888040064511, \"precision\": 0.9998268398268398, \"recall\": 0.4901111959935489, \"specificity\": 0.999857509261898, \"npv\": 0.5387745700245701, \"accuracy\": 0.680408532368743, \"f1\": 0.6577808156755525, \"f2\": 0.5457570086391047, \"f0_5\": 0.8276712250222183, \"p4\": 0.6783417358355109, \"phi\": 0.5137098747675127}, {\"truth_threshold\": 11.120000000000001, \"match_probability\": 0.9995508914128666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5762, \"tn\": 7017, \"fp\": 1, \"fn\": 6019, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48909260673966554, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5109073932603344, \"precision\": 0.999826479264272, \"recall\": 0.48909260673966554, \"specificity\": 0.999857509261898, \"npv\": 0.5382786130714943, \"accuracy\": 0.6797702005425821, \"f1\": 0.6568627450980392, \"f2\": 0.5447463459829448, \"f0_5\": 0.8270892544426263, \"p4\": 0.6776568365809204, \"phi\": 0.5129391263284612}, {\"truth_threshold\": 11.14, \"match_probability\": 0.9995570716848697, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5752, \"tn\": 7017, \"fp\": 1, \"fn\": 6029, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4882437823614294, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5117562176385706, \"precision\": 0.9998261776464453, \"recall\": 0.4882437823614294, \"specificity\": 0.999857509261898, \"npv\": 0.5378660125709029, \"accuracy\": 0.6792382573541146, \"f1\": 0.6560967263602144, \"f2\": 0.5439037766892978, \"f0_5\": 0.826603052338114, \"p4\": 0.6770855904127107, \"phi\": 0.5122970354597648}, {\"truth_threshold\": 11.16, \"match_probability\": 0.9995631669460973, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5747, \"tn\": 7017, \"fp\": 1, \"fn\": 6034, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48781937017231136, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5121806298276886, \"precision\": 0.9998260264439806, \"recall\": 0.48781937017231136, \"specificity\": 0.999857509261898, \"npv\": 0.5376599494291625, \"accuracy\": 0.6789722857598809, \"f1\": 0.6557133892406869, \"f2\": 0.543482372522318, \"f0_5\": 0.8263595318206655, \"p4\": 0.6767997970743476, \"phi\": 0.5119760575002167}, {\"truth_threshold\": 11.18, \"match_probability\": 0.9995691783648718, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5741, \"tn\": 7017, \"fp\": 1, \"fn\": 6040, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48731007554536965, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5126899244546304, \"precision\": 0.9998258446534308, \"recall\": 0.48731007554536965, \"specificity\": 0.999857509261898, \"npv\": 0.537412881979015, \"accuracy\": 0.6786531198468003, \"f1\": 0.6552530959310621, \"f2\": 0.542976582302425, \"f0_5\": 0.8260669371780482, \"p4\": 0.6764566946302629, \"phi\": 0.511590942959764}, {\"truth_threshold\": 11.200000000000001, \"match_probability\": 0.9995751070934877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5738, \"tn\": 7017, \"fp\": 1, \"fn\": 6043, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48705542823189885, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5129445717681012, \"precision\": 0.9998257536156124, \"recall\": 0.48705542823189885, \"specificity\": 0.999857509261898, \"npv\": 0.5372894333843797, \"accuracy\": 0.6784935368902602, \"f1\": 0.6550228310502283, \"f2\": 0.5427236441367308, \"f0_5\": 0.8259204882402049, \"p4\": 0.6762850816973986, \"phi\": 0.511398409730316}, {\"truth_threshold\": 11.22, \"match_probability\": 0.9995809542684295, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5732, \"tn\": 7017, \"fp\": 1, \"fn\": 6049, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48654613360495713, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5134538663950429, \"precision\": 0.9998255712541427, \"recall\": 0.48654613360495713, \"specificity\": 0.999857509261898, \"npv\": 0.5370427062605235, \"accuracy\": 0.6781743709771796, \"f1\": 0.6545620646340071, \"f2\": 0.5422176816694099, \"f0_5\": 0.8256272866073229, \"p4\": 0.6759417320492593, \"phi\": 0.5110133911384195}, {\"truth_threshold\": 11.24, \"match_probability\": 0.9995867210105881, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5728, \"tn\": 7017, \"fp\": 1, \"fn\": 6053, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48620660385366266, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5137933961463373, \"precision\": 0.9998254494676209, \"recall\": 0.48620660385366266, \"specificity\": 0.999857509261898, \"npv\": 0.5368783473603672, \"accuracy\": 0.6779615937017927, \"f1\": 0.6542547115933752, \"f2\": 0.5418803095377746, \"f0_5\": 0.8254315935095253, \"p4\": 0.6757127403610651, \"phi\": 0.5107567473964001}, {\"truth_threshold\": 11.26, \"match_probability\": 0.9995924084254744, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5723, \"tn\": 7017, \"fp\": 1, \"fn\": 6058, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4857821916645446, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5142178083354554, \"precision\": 0.9998252969951084, \"recall\": 0.4857821916645446, \"specificity\": 0.999857509261898, \"npv\": 0.5366730401529637, \"accuracy\": 0.677695622107559, \"f1\": 0.6538703227649243, \"f2\": 0.5414585225552528, \"f0_5\": 0.8251867231882805, \"p4\": 0.6754263970358284, \"phi\": 0.5104359822740981}, {\"truth_threshold\": 11.28, \"match_probability\": 0.9995980176034294, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5717, \"tn\": 7017, \"fp\": 1, \"fn\": 6064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4852728970376029, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5147271029623971, \"precision\": 0.9998251136761105, \"recall\": 0.4852728970376029, \"specificity\": 0.999857509261898, \"npv\": 0.5364268786790001, \"accuracy\": 0.6773764561944784, \"f1\": 0.6534087662152123, \"f2\": 0.5409522728132925, \"f0_5\": 0.8248925056993622, \"p4\": 0.675082632486425, \"phi\": 0.5100511218791226}, {\"truth_threshold\": 11.3, \"match_probability\": 0.9996035496198316, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5710, \"tn\": 7017, \"fp\": 1, \"fn\": 6071, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4846787199728376, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5153212800271624, \"precision\": 0.9998248993171074, \"recall\": 0.4846787199728376, \"specificity\": 0.999857509261898, \"npv\": 0.5361399755501223, \"accuracy\": 0.6770040959625512, \"f1\": 0.6528698833752573, \"f2\": 0.54036150279171, \"f0_5\": 0.8245487364620938, \"p4\": 0.6746813627627055, \"phi\": 0.5096021972778711}, {\"truth_threshold\": 11.32, \"match_probability\": 0.999609005535302, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5704, \"tn\": 7017, \"fp\": 1, \"fn\": 6077, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4841694253458959, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5158305746541041, \"precision\": 0.9998247151621384, \"recall\": 0.4841694253458959, \"specificity\": 0.999857509261898, \"npv\": 0.5358943027340767, \"accuracy\": 0.6766849300494707, \"f1\": 0.6524076403980327, \"f2\": 0.5398550038804445, \"f0_5\": 0.8242536342880263, \"p4\": 0.674337235689392, \"phi\": 0.5092174722487465}, {\"truth_threshold\": 11.34, \"match_probability\": 0.9996143863959054, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5689, \"tn\": 7017, \"fp\": 1, \"fn\": 6092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48289618877854174, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5171038112214583, \"precision\": 0.9998242530755712, \"recall\": 0.48289618877854174, \"specificity\": 0.999857509261898, \"npv\": 0.5352811045846365, \"accuracy\": 0.6758870152667695, \"f1\": 0.6512506439242173, \"f2\": 0.5385882531147045, \"f0_5\": 0.8235140847109232, \"p4\": 0.6734761806489686, \"phi\": 0.5082559298736389}, {\"truth_threshold\": 11.36, \"match_probability\": 0.9996196932333503, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5688, \"tn\": 7017, \"fp\": 1, \"fn\": 6093, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4828113063407181, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5171886936592819, \"precision\": 0.9998242221831605, \"recall\": 0.4828113063407181, \"specificity\": 0.999857509261898, \"npv\": 0.5352402745995424, \"accuracy\": 0.6758338209479228, \"f1\": 0.6511734401831711, \"f2\": 0.5385037774790298, \"f0_5\": 0.8234646900425631, \"p4\": 0.6734187393668167, \"phi\": 0.5081918406794003}, {\"truth_threshold\": 11.38, \"match_probability\": 0.9996249270651847, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5685, \"tn\": 7017, \"fp\": 1, \"fn\": 6096, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48255665902724726, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5174433409727527, \"precision\": 0.9998241294407316, \"recall\": 0.48255665902724726, \"specificity\": 0.999857509261898, \"npv\": 0.5351178220086936, \"accuracy\": 0.6756742379913825, \"f1\": 0.6509417759203069, \"f2\": 0.5382503313766333, \"f0_5\": 0.8233164373642288, \"p4\": 0.6732463872070167, \"phi\": 0.5079995832591271}, {\"truth_threshold\": 11.4, \"match_probability\": 0.9996300888949902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5681, \"tn\": 7017, \"fp\": 1, \"fn\": 6100, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4822171292759528, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5177828707240472, \"precision\": 0.9998240056318198, \"recall\": 0.4822171292759528, \"specificity\": 0.999857509261898, \"npv\": 0.5349546390180682, \"accuracy\": 0.6754614607159956, \"f1\": 0.6506327664204318, \"f2\": 0.5379123584441162, \"f0_5\": 0.8231186067402707, \"p4\": 0.6730165181606185, \"phi\": 0.5077432636848631}, {\"truth_threshold\": 11.42, \"match_probability\": 0.9996351797125727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5679, \"tn\": 7017, \"fp\": 1, \"fn\": 6102, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4820473644003056, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5179526355996944, \"precision\": 0.9998239436619718, \"recall\": 0.4820473644003056, \"specificity\": 0.999857509261898, \"npv\": 0.5348730848387835, \"accuracy\": 0.675355072078302, \"f1\": 0.6504782085791192, \"f2\": 0.5377433527763048, \"f0_5\": 0.8230196226196342, \"p4\": 0.6729015552309493, \"phi\": 0.5076151140058894}, {\"truth_threshold\": 11.44, \"match_probability\": 0.9996402004941516, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5670, \"tn\": 7017, \"fp\": 1, \"fn\": 6111, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48128342245989303, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5187165775401069, \"precision\": 0.9998236642567448, \"recall\": 0.48128342245989303, \"specificity\": 0.999857509261898, \"npv\": 0.5345063985374772, \"accuracy\": 0.6748763232086813, \"f1\": 0.649782259912904, \"f2\": 0.5369826688133346, \"f0_5\": 0.8225736254170898, \"p4\": 0.6723839870144264, \"phi\": 0.5070385234474547}, {\"truth_threshold\": 11.46, \"match_probability\": 0.9996451522025451, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5663, \"tn\": 7017, \"fp\": 1, \"fn\": 6118, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48068924539512775, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5193107546048723, \"precision\": 0.9998234463276836, \"recall\": 0.48068924539512775, \"specificity\": 0.999857509261898, \"npv\": 0.5342215454891511, \"accuracy\": 0.6745039629767541, \"f1\": 0.6492404700487245, \"f2\": 0.5363908464044859, \"f0_5\": 0.8222260940267735, \"p4\": 0.6719811671362543, \"phi\": 0.5065901574827701}, {\"truth_threshold\": 11.48, \"match_probability\": 0.9996500357873543, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5657, \"tn\": 7017, \"fp\": 1, \"fn\": 6124, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.48017995076818604, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5198200492318139, \"precision\": 0.9998232591021562, \"recall\": 0.48017995076818604, \"specificity\": 0.999857509261898, \"npv\": 0.533977627273419, \"accuracy\": 0.6741847970636736, \"f1\": 0.6487757325534721, \"f2\": 0.5358834451138645, \"f0_5\": 0.8219277598581931, \"p4\": 0.671635706343846, \"phi\": 0.5062059083589786}, {\"truth_threshold\": 11.5, \"match_probability\": 0.9996548521851435, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5649, \"tn\": 7017, \"fp\": 1, \"fn\": 6132, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47950089126559714, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5204991087344029, \"precision\": 0.9998230088495575, \"recall\": 0.47950089126559714, \"specificity\": 0.999857509261898, \"npv\": 0.5336527492584987, \"accuracy\": 0.6737592425128996, \"f1\": 0.6481555848775171, \"f2\": 0.5352067305870315, \"f0_5\": 0.8215293330618656, \"p4\": 0.6711748229138478, \"phi\": 0.5056936682685188}, {\"truth_threshold\": 11.52, \"match_probability\": 0.9996596023196187, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5644, \"tn\": 7017, \"fp\": 1, \"fn\": 6137, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4790764790764791, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5209235209235209, \"precision\": 0.999822852081488, \"recall\": 0.4790764790764791, \"specificity\": 0.999857509261898, \"npv\": 0.5334499011707465, \"accuracy\": 0.6734932709186658, \"f1\": 0.6477677034316538, \"f2\": 0.5347836798120108, \"f0_5\": 0.8212799394662553, \"p4\": 0.6708866140589841, \"phi\": 0.5053735713185643}, {\"truth_threshold\": 11.540000000000001, \"match_probability\": 0.9996642871018043, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5639, \"tn\": 7017, \"fp\": 1, \"fn\": 6142, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.478652066887361, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.521347933112639, \"precision\": 0.999822695035461, \"recall\": 0.478652066887361, \"specificity\": 0.999857509261898, \"npv\": 0.5332472072345923, \"accuracy\": 0.6732272993244321, \"f1\": 0.6473795993341369, \"f2\": 0.5343605488590706, \"f0_5\": 0.8210302553798666, \"p4\": 0.6705982842393097, \"phi\": 0.5050535149795218}, {\"truth_threshold\": 11.56, \"match_probability\": 0.9996689074302161, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5630, \"tn\": 7017, \"fp\": 1, \"fn\": 6151, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4778881249469485, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5221118750530516, \"precision\": 0.9998224116497958, \"recall\": 0.4778881249469485, \"specificity\": 0.999857509261898, \"npv\": 0.5328827460510328, \"accuracy\": 0.6727485504548114, \"f1\": 0.6466804502641856, \"f2\": 0.5335987110226519, \"f0_5\": 0.8205800903658359, \"p4\": 0.6700789846178208, \"phi\": 0.5044775152691208}, {\"truth_threshold\": 11.58, \"match_probability\": 0.9996734641910328, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5629, \"tn\": 7017, \"fp\": 1, \"fn\": 6152, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47780324250912487, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5221967574908751, \"precision\": 0.999822380106572, \"recall\": 0.47780324250912487, \"specificity\": 0.999857509261898, \"npv\": 0.5328422811147392, \"accuracy\": 0.6726953561359647, \"f1\": 0.6466027224168629, \"f2\": 0.5335140463282405, \"f0_5\": 0.8205300137022244, \"p4\": 0.670021260308438, \"phi\": 0.504413523332621}, {\"truth_threshold\": 11.6, \"match_probability\": 0.9996779582582649, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5626, \"tn\": 7017, \"fp\": 1, \"fn\": 6155, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.477548595195654, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5224514048043459, \"precision\": 0.9998222854096321, \"recall\": 0.477548595195654, \"specificity\": 0.999857509261898, \"npv\": 0.5327209231703613, \"accuracy\": 0.6725357731794245, \"f1\": 0.6463694852941176, \"f2\": 0.5332600329851567, \"f0_5\": 0.820379713610779, \"p4\": 0.6698480580856075, \"phi\": 0.5042215571189914}, {\"truth_threshold\": 11.620000000000001, \"match_probability\": 0.9996823904939214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5621, \"tn\": 7017, \"fp\": 1, \"fn\": 6160, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.477124183006536, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5228758169934641, \"precision\": 0.9998221273568125, \"recall\": 0.477124183006536, \"specificity\": 0.999857509261898, \"npv\": 0.5325187827274797, \"accuracy\": 0.6722698015851907, \"f1\": 0.6459805780612538, \"f2\": 0.5328366132028969, \"f0_5\": 0.8201289795441945, \"p4\": 0.6695592898965835, \"phi\": 0.5039016453195245}, {\"truth_threshold\": 11.64, \"match_probability\": 0.9996867617481742, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5615, \"tn\": 7017, \"fp\": 1, \"fn\": 6166, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47661488837959426, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5233851116204057, \"precision\": 0.9998219373219374, \"recall\": 0.47661488837959426, \"specificity\": 0.999857509261898, \"npv\": 0.5322764165971327, \"accuracy\": 0.6719506356721102, \"f1\": 0.6455135942978675, \"f2\": 0.532328403488813, \"f0_5\": 0.8198277120747555, \"p4\": 0.6692126062369114, \"phi\": 0.5035178035312263}, {\"truth_threshold\": 11.66, \"match_probability\": 0.9996910728595202, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5605, \"tn\": 7017, \"fp\": 1, \"fn\": 6176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4757660640013581, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5242339359986419, \"precision\": 0.9998216196931858, \"recall\": 0.4757660640013581, \"specificity\": 0.999857509261898, \"npv\": 0.5318729629348897, \"accuracy\": 0.6714186924836427, \"f1\": 0.6447345718065222, \"f2\": 0.5314811302863645, \"f0_5\": 0.8193246601374068, \"p4\": 0.6686344062338716, \"phi\": 0.5028781932777369}, {\"truth_threshold\": 11.68, \"match_probability\": 0.9996953246549412, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5604, \"tn\": 7017, \"fp\": 1, \"fn\": 6177, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4756811815635345, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5243188184364656, \"precision\": 0.999821587867975, \"recall\": 0.4756811815635345, \"specificity\": 0.999857509261898, \"npv\": 0.5318326512050933, \"accuracy\": 0.671365498164796, \"f1\": 0.6446566202691821, \"f2\": 0.5313963852908267, \"f0_5\": 0.819274290225432, \"p4\": 0.6685765590644549, \"phi\": 0.50281424086893}, {\"truth_threshold\": 11.700000000000001, \"match_probability\": 0.9996995179500615, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5600, \"tn\": 7017, \"fp\": 1, \"fn\": 6181, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47534165181224003, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5246583481877599, \"precision\": 0.9998214604534904, \"recall\": 0.47534165181224003, \"specificity\": 0.999857509261898, \"npv\": 0.5316714653735415, \"accuracy\": 0.671152720889409, \"f1\": 0.6443447244275687, \"f2\": 0.5310573731626363, \"f0_5\": 0.8190726927014772, \"p4\": 0.6683451208464983, \"phi\": 0.5025584468197153}, {\"truth_threshold\": 11.72, \"match_probability\": 0.999703653549304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5598, \"tn\": 7017, \"fp\": 1, \"fn\": 6183, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47517188693659285, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5248281130634072, \"precision\": 0.9998213966779782, \"recall\": 0.47517188693659285, \"specificity\": 0.999857509261898, \"npv\": 0.5315909090909091, \"accuracy\": 0.6710463322517155, \"f1\": 0.6441887226697354, \"f2\": 0.5308878478083568, \"f0_5\": 0.8189718231559235, \"p4\": 0.6682293719735365, \"phi\": 0.5024305591241861}, {\"truth_threshold\": 11.74, \"match_probability\": 0.999707732246043, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5589, \"tn\": 7017, \"fp\": 1, \"fn\": 6192, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4744079449961803, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5255920550038197, \"precision\": 0.9998211091234347, \"recall\": 0.4744079449961803, \"specificity\": 0.999857509261898, \"npv\": 0.531228707699296, \"accuracy\": 0.6705675833820948, \"f1\": 0.6434862702204824, \"f2\": 0.5301248245247941, \"f0_5\": 0.8185173252101579, \"p4\": 0.6677082557872719, \"phi\": 0.5018551410607464}, {\"truth_threshold\": 11.76, \"match_probability\": 0.9997117548227562, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5586, \"tn\": 7017, \"fp\": 1, \"fn\": 6195, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4741532976827095, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5258467023172906, \"precision\": 0.9998210130660462, \"recall\": 0.4741532976827095, \"specificity\": 0.999857509261898, \"npv\": 0.5311080835603996, \"accuracy\": 0.6704080004255546, \"f1\": 0.6432519576232151, \"f2\": 0.5298704255278784, \"f0_5\": 0.8183656128219403, \"p4\": 0.6675344606037203, \"phi\": 0.5016633627466461}, {\"truth_threshold\": 11.78, \"match_probability\": 0.9997157220511734, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5584, \"tn\": 7017, \"fp\": 1, \"fn\": 6197, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47398353280706224, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5260164671929378, \"precision\": 0.9998209489704566, \"recall\": 0.47398353280706224, \"specificity\": 0.999857509261898, \"npv\": 0.5310276978961708, \"accuracy\": 0.6703016117878611, \"f1\": 0.6430957042496833, \"f2\": 0.5297008101083307, \"f0_5\": 0.8182644119457225, \"p4\": 0.6674185721401418, \"phi\": 0.5015355181960498}, {\"truth_threshold\": 11.8, \"match_probability\": 0.9997196346924244, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5579, \"tn\": 7017, \"fp\": 1, \"fn\": 6202, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47355912061794414, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5264408793820559, \"precision\": 0.999820788530466, \"recall\": 0.47355912061794414, \"specificity\": 0.999857509261898, \"npv\": 0.5308268401543234, \"accuracy\": 0.6700356401936273, \"f1\": 0.6427049133114452, \"f2\": 0.52927671523983, \"f0_5\": 0.8180112020175362, \"p4\": 0.6671287632864352, \"phi\": 0.5012159335313301}, {\"truth_threshold\": 11.82, \"match_probability\": 0.9997234934971839, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5571, \"tn\": 7017, \"fp\": 1, \"fn\": 6210, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47288006111535524, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5271199388846448, \"precision\": 0.9998205312275664, \"recall\": 0.47288006111535524, \"specificity\": 0.999857509261898, \"npv\": 0.5305057836244046, \"accuracy\": 0.6696100856428533, \"f1\": 0.6420791793926123, \"f2\": 0.5285979960528313, \"f0_5\": 0.8176054477677654, \"p4\": 0.6666648077950638, \"phi\": 0.5007046770205398}, {\"truth_threshold\": 11.84, \"match_probability\": 0.9997272992058148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5565, \"tn\": 7017, \"fp\": 1, \"fn\": 6216, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47237076648841353, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5276292335115864, \"precision\": 0.9998203377650018, \"recall\": 0.47237076648841353, \"specificity\": 0.999857509261898, \"npv\": 0.5302652459759691, \"accuracy\": 0.6692909197297728, \"f1\": 0.641609500201764, \"f2\": 0.5280888214082369, \"f0_5\": 0.8173006315171097, \"p4\": 0.6663166293401871, \"phi\": 0.5003212979777055}, {\"truth_threshold\": 11.86, \"match_probability\": 0.9997310525485098, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5562, \"tn\": 7017, \"fp\": 1, \"fn\": 6219, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4721161191749427, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5278838808250573, \"precision\": 0.9998202408772245, \"recall\": 0.4721161191749427, \"specificity\": 0.999857509261898, \"npv\": 0.5301450589301904, \"accuracy\": 0.6691313367732327, \"f1\": 0.6413745387453874, \"f2\": 0.5278341905973011, \"f0_5\": 0.8171480621749478, \"p4\": 0.6661424718016975, \"phi\": 0.5001296286921258}, {\"truth_threshold\": 11.88, \"match_probability\": 0.9997347542454303, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5554, \"tn\": 7017, \"fp\": 1, \"fn\": 6227, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4714370596723538, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5285629403276462, \"precision\": 0.9998199819981998, \"recall\": 0.4714370596723538, \"specificity\": 0.999857509261898, \"npv\": 0.5298248263364542, \"accuracy\": 0.6687057822224587, \"f1\": 0.6407475772958007, \"f2\": 0.5271550333149831, \"f0_5\": 0.8167406840975265, \"p4\": 0.6656778283339282, \"phi\": 0.4996185761481905}, {\"truth_threshold\": 11.9, \"match_probability\": 0.9997384050068445, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5548, \"tn\": 7017, \"fp\": 1, \"fn\": 6233, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4709277650454121, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5290722349545879, \"precision\": 0.999819787349072, \"recall\": 0.4709277650454121, \"specificity\": 0.999857509261898, \"npv\": 0.5295849056603773, \"accuracy\": 0.6683866163093781, \"f1\": 0.6402769763416042, \"f2\": 0.5266455299679152, \"f0_5\": 0.8164346469670659, \"p4\": 0.6653291318302058, \"phi\": 0.499235348926767}, {\"truth_threshold\": 11.92, \"match_probability\": 0.9997420055332628, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5540, \"tn\": 7017, \"fp\": 1, \"fn\": 6241, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.47024870554282316, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5297512944571768, \"precision\": 0.9998195271611623, \"recall\": 0.47024870554282316, \"specificity\": 0.999857509261898, \"npv\": 0.5292653492231105, \"accuracy\": 0.6679610617586041, \"f1\": 0.6396490012700612, \"f2\": 0.525966011582645, \"f0_5\": 0.8160259242892915, \"p4\": 0.6648639167594368, \"phi\": 0.4987244615490945}, {\"truth_threshold\": 11.94, \"match_probability\": 0.9997455565155712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5539, \"tn\": 7017, \"fp\": 1, \"fn\": 6242, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4701638231049996, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5298361768950004, \"precision\": 0.9998194945848375, \"recall\": 0.4701638231049996, \"specificity\": 0.999857509261898, \"npv\": 0.5292254317821857, \"accuracy\": 0.6679078674397574, \"f1\": 0.6395704635990993, \"f2\": 0.5258810572687225, \"f0_5\": 0.8159747797648861, \"p4\": 0.6648057417957121, \"phi\": 0.4986606071999025}, {\"truth_threshold\": 11.96, \"match_probability\": 0.9997490586351637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5535, \"tn\": 7017, \"fp\": 1, \"fn\": 6246, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4698242933537051, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5301757066462949, \"precision\": 0.9998193641618497, \"recall\": 0.4698242933537051, \"specificity\": 0.999857509261898, \"npv\": 0.5290658222121692, \"accuracy\": 0.6676950901643705, \"f1\": 0.6392562222093896, \"f2\": 0.5255412077478162, \"f0_5\": 0.8157700810611643, \"p4\": 0.6645729905254563, \"phi\": 0.4984052043396401}, {\"truth_threshold\": 11.98, \"match_probability\": 0.9997525125640727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5530, \"tn\": 7017, \"fp\": 1, \"fn\": 6251, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46939988116458703, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5306001188354129, \"precision\": 0.9998192008678358, \"recall\": 0.46939988116458703, \"specificity\": 0.999857509261898, \"npv\": 0.5288664455833585, \"accuracy\": 0.6674291185701368, \"f1\": 0.6388632162661737, \"f2\": 0.5251163232361599, \"f0_5\": 0.8155139359976404, \"p4\": 0.6642819355332727, \"phi\": 0.4980859833498898}, {\"truth_threshold\": 12.0, \"match_probability\": 0.9997559189650964, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5522, \"tn\": 7017, \"fp\": 1, \"fn\": 6259, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46872082166199813, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5312791783380019, \"precision\": 0.9998189389824371, \"recall\": 0.46872082166199813, \"specificity\": 0.999857509261898, \"npv\": 0.5285477553479964, \"accuracy\": 0.6670035640193628, \"f1\": 0.6382339343504392, \"f2\": 0.5244363401523353, \"f0_5\": 0.8151034747438963, \"p4\": 0.6638159788125039, \"phi\": 0.49757530459733523}, {\"truth_threshold\": 12.02, \"match_probability\": 0.9997592784919264, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5512, \"tn\": 7017, \"fp\": 1, \"fn\": 6269, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.467871997283762, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5321280027162381, \"precision\": 0.9998186105568656, \"recall\": 0.467871997283762, \"specificity\": 0.999857509261898, \"npv\": 0.5281499322595213, \"accuracy\": 0.6664716208308953, \"f1\": 0.6374465132415866, \"f2\": 0.5235860706347246, \"f0_5\": 0.8145893062985842, \"p4\": 0.6632330657634364, \"phi\": 0.4969370845520988}, {\"truth_threshold\": 12.040000000000001, \"match_probability\": 0.9997625917892721, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5506, \"tn\": 7017, \"fp\": 1, \"fn\": 6275, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4673627026568203, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5326372973431797, \"precision\": 0.9998184129289994, \"recall\": 0.4673627026568203, \"specificity\": 0.999857509261898, \"npv\": 0.5279115257297623, \"accuracy\": 0.6661524549178148, \"f1\": 0.6369736233225358, \"f2\": 0.5230757538332922, \"f0_5\": 0.8142802212428644, \"p4\": 0.6628830676532189, \"phi\": 0.496554220378801}, {\"truth_threshold\": 12.06, \"match_probability\": 0.9997658594929839, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5503, \"tn\": 7017, \"fp\": 1, \"fn\": 6278, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4671080553433495, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5328919446566506, \"precision\": 0.9998183139534884, \"recall\": 0.4671080553433495, \"specificity\": 0.999857509261898, \"npv\": 0.5277924031590824, \"accuracy\": 0.6659928719612745, \"f1\": 0.636737055250217, \"f2\": 0.5228205517975222, \"f0_5\": 0.8141255140988846, \"p4\": 0.6627079979531069, \"phi\": 0.4963628072370562}, {\"truth_threshold\": 12.08, \"match_probability\": 0.9997690822301749, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5498, \"tn\": 7017, \"fp\": 1, \"fn\": 6283, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4666836431542314, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5333163568457686, \"precision\": 0.999818148754319, \"recall\": 0.4666836431542314, \"specificity\": 0.999857509261898, \"npv\": 0.5275939849624061, \"accuracy\": 0.6657269003670409, \"f1\": 0.6363425925925926, \"f2\": 0.5223951504095168, \"f0_5\": 0.8138674245788554, \"p4\": 0.6624161101827867, \"phi\": 0.49604381324884056}, {\"truth_threshold\": 12.1, \"match_probability\": 0.9997722606193405, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5497, \"tn\": 7017, \"fp\": 1, \"fn\": 6284, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46659876071640777, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5334012392835922, \"precision\": 0.9998181156784285, \"recall\": 0.46659876071640777, \"specificity\": 0.999857509261898, \"npv\": 0.5275543192241184, \"accuracy\": 0.6656737060481941, \"f1\": 0.6362636726662423, \"f2\": 0.5223100604309985, \"f0_5\": 0.813815769993782, \"p4\": 0.6623577168613934, \"phi\": 0.4959800186237535}, {\"truth_threshold\": 12.120000000000001, \"match_probability\": 0.999775395270477, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5489, \"tn\": 7017, \"fp\": 1, \"fn\": 6292, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46591970121381887, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5340802987861811, \"precision\": 0.9998178506375228, \"recall\": 0.46591970121381887, \"specificity\": 0.999857509261898, \"npv\": 0.5272372079044256, \"accuracy\": 0.6652481514974201, \"f1\": 0.6356319842510567, \"f2\": 0.5216292241608698, \"f0_5\": 0.8134020924098279, \"p4\": 0.6618903805808687, \"phi\": 0.4954697114201677}, {\"truth_threshold\": 12.14, \"match_probability\": 0.9997784867851973, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5486, \"tn\": 7017, \"fp\": 1, \"fn\": 6295, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.465665053900348, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5343349460996519, \"precision\": 0.9998177510479315, \"recall\": 0.465665053900348, \"specificity\": 0.999857509261898, \"npv\": 0.5271183894230769, \"accuracy\": 0.6650885685408798, \"f1\": 0.635394950196896, \"f2\": 0.5213738571781567, \"f0_5\": 0.8132467609475525, \"p4\": 0.6617150423281595, \"phi\": 0.49527836893497096}, {\"truth_threshold\": 12.16, \"match_probability\": 0.9997815357568474, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5483, \"tn\": 7017, \"fp\": 1, \"fn\": 6298, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46541040658687716, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5345895934131228, \"precision\": 0.99981765134938, \"recall\": 0.46541040658687716, \"specificity\": 0.999857509261898, \"npv\": 0.526999624483665, \"accuracy\": 0.6649289855843395, \"f1\": 0.6351578337677382, \"f2\": 0.5211184610705596, \"f0_5\": 0.8130913189192396, \"p4\": 0.6615396564146178, \"phi\": 0.49508703877194177}, {\"truth_threshold\": 12.18, \"match_probability\": 0.999784542770618, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5473, \"tn\": 7017, \"fp\": 1, \"fn\": 6308, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.464561582208641, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5354384177913589, \"precision\": 0.9998173182316404, \"recall\": 0.464561582208641, \"specificity\": 0.999857509261898, \"npv\": 0.5266041275797373, \"accuracy\": 0.6643970423958722, \"f1\": 0.6343668501883512, \"f2\": 0.5202669303015324, \"f0_5\": 0.8125723787748315, \"p4\": 0.6609546914442145, \"phi\": 0.49444935998980494}, {\"truth_threshold\": 12.200000000000001, \"match_probability\": 0.9997875084036579, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5466, \"tn\": 7017, \"fp\": 1, \"fn\": 6315, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46396740514387574, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5360325948561243, \"precision\": 0.9998170843241265, \"recall\": 0.46396740514387574, \"specificity\": 0.999857509261898, \"npv\": 0.5263276327632763, \"accuracy\": 0.664024682163945, \"f1\": 0.6338126159554731, \"f2\": 0.5196706660835504, \"f0_5\": 0.812208386579096, \"p4\": 0.6605448987256288, \"phi\": 0.4940030651404045}, {\"truth_threshold\": 12.22, \"match_probability\": 0.9997904332251836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5461, \"tn\": 7017, \"fp\": 1, \"fn\": 6320, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46354299295475765, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5364570070452424, \"precision\": 0.9998169168802636, \"recall\": 0.46354299295475765, \"specificity\": 0.999857509261898, \"npv\": 0.526130314163605, \"accuracy\": 0.6637587105697111, \"f1\": 0.6334164588528678, \"f2\": 0.5192446658806527, \"f0_5\": 0.8119480210532576, \"p4\": 0.6602520290236793, \"phi\": 0.49368432323215217}, {\"truth_threshold\": 12.24, \"match_probability\": 0.999793317796588, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5457, \"tn\": 7017, \"fp\": 1, \"fn\": 6324, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.46320346320346323, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5367965367965368, \"precision\": 0.9998167827042873, \"recall\": 0.46320346320346323, \"specificity\": 0.999857509261898, \"npv\": 0.5259725657746795, \"accuracy\": 0.6635459332943242, \"f1\": 0.6330993677127443, \"f2\": 0.5189038073865582, \"f0_5\": 0.8117395055484485, \"p4\": 0.6600176366008567, \"phi\": 0.4934293536248113}, {\"truth_threshold\": 12.26, \"match_probability\": 0.9997961626715484, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5449, \"tn\": 7017, \"fp\": 1, \"fn\": 6332, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4625244037008743, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5374755962991257, \"precision\": 0.9998165137614679, \"recall\": 0.4625244037008743, \"specificity\": 0.999857509261898, \"npv\": 0.5256573526106825, \"accuracy\": 0.6631203787435502, \"f1\": 0.632464743775753, \"f2\": 0.5182219347966676, \"f0_5\": 0.8113218784431673, \"p4\": 0.6595485931652595, \"phi\": 0.49291947774976297}, {\"truth_threshold\": 12.280000000000001, \"match_probability\": 0.9997989683961317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5441, \"tn\": 7017, \"fp\": 1, \"fn\": 6340, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4618453441982854, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5381546558017146, \"precision\": 0.9998162440279309, \"recall\": 0.4618453441982854, \"specificity\": 0.999857509261898, \"npv\": 0.5253425170322678, \"accuracy\": 0.6626948241927763, \"f1\": 0.6318295302792777, \"f2\": 0.517539854658905, \"f0_5\": 0.8109034546484247, \"p4\": 0.6590792036426465, \"phi\": 0.4924096856288555}, {\"truth_threshold\": 12.3, \"match_probability\": 0.9998017355088994, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5433, \"tn\": 7017, \"fp\": 1, \"fn\": 6348, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4611662846956965, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5388337153043036, \"precision\": 0.999815973500184, \"recall\": 0.4611662846956965, \"specificity\": 0.999857509261898, \"npv\": 0.5250280583613917, \"accuracy\": 0.6622692696420023, \"f1\": 0.6311937264013942, \"f2\": 0.5168575668784962, \"f0_5\": 0.8104842318823283, \"p4\": 0.6586094664673772, \"phi\": 0.4918999764228742}, {\"truth_threshold\": 12.32, \"match_probability\": 0.9998044645410099, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5423, \"tn\": 7017, \"fp\": 1, \"fn\": 6358, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4603174603174603, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5396825396825397, \"precision\": 0.9998156342182891, \"recall\": 0.4603174603174603, \"specificity\": 0.999857509261898, \"npv\": 0.5246355140186916, \"accuracy\": 0.6617373264535348, \"f1\": 0.6303981400755594, \"f2\": 0.5160044150110376, \"f0_5\": 0.8099590763807988, \"p4\": 0.658021803717022, \"phi\": 0.4912629552345792}, {\"truth_threshold\": 12.34, \"match_probability\": 0.9998071560163209, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5414, \"tn\": 7017, \"fp\": 1, \"fn\": 6367, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4595535183770478, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5404464816229522, \"precision\": 0.9998153277931672, \"recall\": 0.4595535183770478, \"specificity\": 0.999857509261898, \"npv\": 0.5242827256425583, \"accuracy\": 0.661258577583914, \"f1\": 0.6296813212374971, \"f2\": 0.5152363006528483, \"f0_5\": 0.8094853622798361, \"p4\": 0.6574924381522456, \"phi\": 0.49068974445414865}, {\"truth_threshold\": 12.36, \"match_probability\": 0.9998098104514891, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5412, \"tn\": 7017, \"fp\": 1, \"fn\": 6369, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45938375350140054, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5406162464985994, \"precision\": 0.9998152595603178, \"recall\": 0.45938375350140054, \"specificity\": 0.999857509261898, \"npv\": 0.5242043926490363, \"accuracy\": 0.6611521889462205, \"f1\": 0.6295219262533442, \"f2\": 0.5150655728343834, \"f0_5\": 0.8093799539377262, \"p4\": 0.6573747407711895, \"phi\": 0.490562378086017}, {\"truth_threshold\": 12.38, \"match_probability\": 0.9998124283560689, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5411, \"tn\": 7017, \"fp\": 1, \"fn\": 6370, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4592988710635769, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5407011289364231, \"precision\": 0.9998152254249815, \"recall\": 0.4592988710635769, \"specificity\": 0.999857509261898, \"npv\": 0.5241652349294091, \"accuracy\": 0.6610989946273738, \"f1\": 0.6294422148548828, \"f2\": 0.5149802040505558, \"f0_5\": 0.8093272308474677, \"p4\": 0.6573158837999321, \"phi\": 0.4904986967746174}, {\"truth_threshold\": 12.4, \"match_probability\": 0.9998150102326104, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5408, \"tn\": 7017, \"fp\": 1, \"fn\": 6373, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4590442237501061, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5409557762498939, \"precision\": 0.9998151229432427, \"recall\": 0.4590442237501061, \"specificity\": 0.999857509261898, \"npv\": 0.5240477968633308, \"accuracy\": 0.6609394116708336, \"f1\": 0.6292030250145434, \"f2\": 0.5147240781984658, \"f0_5\": 0.8091689858455278, \"p4\": 0.6571392797259592, \"phi\": 0.49030766031132444}, {\"truth_threshold\": 12.42, \"match_probability\": 0.9998175565767553, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5400, \"tn\": 7017, \"fp\": 1, \"fn\": 6381, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45836516424751717, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5416348357524828, \"precision\": 0.9998148491020181, \"recall\": 0.45836516424751717, \"specificity\": 0.999857509261898, \"npv\": 0.5237348858038513, \"accuracy\": 0.6605138571200596, \"f1\": 0.6285647770923058, \"f2\": 0.5140409328891005, \"f0_5\": 0.8087464430133293, \"p4\": 0.6566680918061567, \"phi\": 0.4897982842392499}, {\"truth_threshold\": 12.44, \"match_probability\": 0.9998200678773314, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5397, \"tn\": 7017, \"fp\": 1, \"fn\": 6384, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45811051693404636, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5418894830659536, \"precision\": 0.9998147462022972, \"recall\": 0.45811051693404636, \"specificity\": 0.999857509261898, \"npv\": 0.5236176404745915, \"accuracy\": 0.6603542741635193, \"f1\": 0.6283252808661738, \"f2\": 0.5137846997448688, \"f0_5\": 0.808587780541156, \"p4\": 0.6564913047002175, \"phi\": 0.48960728852157315}, {\"truth_threshold\": 12.46, \"match_probability\": 0.9998225446164466, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5393, \"tn\": 7017, \"fp\": 1, \"fn\": 6388, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4577709871827519, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5422290128172481, \"precision\": 0.9998146088246199, \"recall\": 0.4577709871827519, \"specificity\": 0.999857509261898, \"npv\": 0.523461395001865, \"accuracy\": 0.6601414968881324, \"f1\": 0.6280058224163028, \"f2\": 0.5134430100156137, \"f0_5\": 0.8083760530023684, \"p4\": 0.6562555105884935, \"phi\": 0.48935264468139866}, {\"truth_threshold\": 12.48, \"match_probability\": 0.999824987269581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5387, \"tn\": 7017, \"fp\": 1, \"fn\": 6394, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45726169255581023, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5427383074441898, \"precision\": 0.9998144023756496, \"recall\": 0.45726169255581023, \"specificity\": 0.999857509261898, \"npv\": 0.5232272015509656, \"accuracy\": 0.6598223309750518, \"f1\": 0.6275263556409808, \"f2\": 0.5129303778184034, \"f0_5\": 0.8080580805808059, \"p4\": 0.6559016519341497, \"phi\": 0.48897071538527564}, {\"truth_threshold\": 12.5, \"match_probability\": 0.9998273963056777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5378, \"tn\": 7017, \"fp\": 1, \"fn\": 6403, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45649775061539766, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5435022493846023, \"precision\": 0.9998140918386317, \"recall\": 0.45649775061539766, \"specificity\": 0.999857509261898, \"npv\": 0.522876304023845, \"accuracy\": 0.6593435821054311, \"f1\": 0.6268065268065268, \"f2\": 0.5121612098356284, \"f0_5\": 0.8075802624861098, \"p4\": 0.6553704857649431, \"phi\": 0.4883979027792678}, {\"truth_threshold\": 12.52, \"match_probability\": 0.999829772187233, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5368, \"tn\": 7017, \"fp\": 1, \"fn\": 6413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4556489262371615, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5443510737628384, \"precision\": 0.9998137455764574, \"recall\": 0.4556489262371615, \"specificity\": 0.999857509261898, \"npv\": 0.5224869694713329, \"accuracy\": 0.6588116389169637, \"f1\": 0.6260058309037901, \"f2\": 0.5113062694073496, \"f0_5\": 0.8070481402411522, \"p4\": 0.654779766373657, \"phi\": 0.48776155749508276}, {\"truth_threshold\": 12.540000000000001, \"match_probability\": 0.9998321153703844, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5362, \"tn\": 7017, \"fp\": 1, \"fn\": 6419, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45513963161021986, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5448603683897801, \"precision\": 0.9998135371993288, \"recall\": 0.45513963161021986, \"specificity\": 0.999857509261898, \"npv\": 0.5222536469187258, \"accuracy\": 0.6584924730038831, \"f1\": 0.6255249650023332, \"f2\": 0.5107931487796978, \"f0_5\": 0.8067282520386363, \"p4\": 0.6544250632798182, \"phi\": 0.4873798068415149}, {\"truth_threshold\": 12.56, \"match_probability\": 0.999834426304998, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5357, \"tn\": 7017, \"fp\": 1, \"fn\": 6424, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45471521942110177, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5452847805788982, \"precision\": 0.9998133631952221, \"recall\": 0.45471521942110177, \"specificity\": 0.999857509261898, \"npv\": 0.5220593705825459, \"accuracy\": 0.6582265014096494, \"f1\": 0.6251239862302351, \"f2\": 0.5103654586334362, \"f0_5\": 0.8064613253846385, \"p4\": 0.6541293212338367, \"phi\": 0.4870617133573699}, {\"truth_threshold\": 12.58, \"match_probability\": 0.9998367054347549, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5352, \"tn\": 7017, \"fp\": 1, \"fn\": 6429, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45429080723198373, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5457091927680163, \"precision\": 0.9998131888660564, \"recall\": 0.45429080723198373, \"specificity\": 0.999857509261898, \"npv\": 0.5218652387327086, \"accuracy\": 0.6579605298154158, \"f1\": 0.6247227734329404, \"f2\": 0.5099376869866799, \"f0_5\": 0.8061940770644414, \"p4\": 0.6538334368229103, \"phi\": 0.48674364879796267}, {\"truth_threshold\": 12.6, \"match_probability\": 0.999838953197236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5348, \"tn\": 7017, \"fp\": 1, \"fn\": 6433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45395127748068925, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5460487225193108, \"precision\": 0.9998130491680688, \"recall\": 0.45395127748068925, \"specificity\": 0.999857509261898, \"npv\": 0.5217100371747212, \"accuracy\": 0.6577477525400287, \"f1\": 0.6244016345592528, \"f2\": 0.5095954109732624, \"f0_5\": 0.805980046417699, \"p4\": 0.6535966265233107, \"phi\": 0.4864892178368099}, {\"truth_threshold\": 12.620000000000001, \"match_probability\": 0.9998411700240056, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5342, \"tn\": 7017, \"fp\": 1, \"fn\": 6439, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45344198285374754, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5465580171462524, \"precision\": 0.9998128392288976, \"recall\": 0.45344198285374754, \"specificity\": 0.999857509261898, \"npv\": 0.5214774078478003, \"accuracy\": 0.6574285866269483, \"f1\": 0.6239196449427704, \"f2\": 0.5090818990984809, \"f0_5\": 0.8056586130968539, \"p4\": 0.6532412393092537, \"phi\": 0.48610760562318556}, {\"truth_threshold\": 12.64, \"match_probability\": 0.9998433563406941, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5328, \"tn\": 7017, \"fp\": 1, \"fn\": 6453, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.452253628724217, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5477463712757831, \"precision\": 0.99981234753237, \"recall\": 0.452253628724217, \"specificity\": 0.999857509261898, \"npv\": 0.5209354120267261, \"accuracy\": 0.6566838661630938, \"f1\": 0.6227936879018118, \"f2\": 0.507883247859989, \"f0_5\": 0.8049067891349669, \"p4\": 0.6524111973123712, \"phi\": 0.48521733499328185}, {\"truth_threshold\": 12.66, \"match_probability\": 0.9998455125670797, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5308, \"tn\": 7017, \"fp\": 1, \"fn\": 6473, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.45055597996774466, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5494440200322553, \"precision\": 0.9998116406102844, \"recall\": 0.45055597996774466, \"specificity\": 0.999857509261898, \"npv\": 0.5201630837657524, \"accuracy\": 0.6556199797861588, \"f1\": 0.6211819777647747, \"f2\": 0.5061697785745618, \"f0_5\": 0.80382833085986, \"p4\": 0.6512234530015724, \"phi\": 0.48394589565098334}, {\"truth_threshold\": 12.68, \"match_probability\": 0.9998476391171683, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5302, \"tn\": 7017, \"fp\": 1, \"fn\": 6479, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.450046685340803, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5499533146591971, \"precision\": 0.9998114274938714, \"recall\": 0.450046685340803, \"specificity\": 0.999857509261898, \"npv\": 0.5199318316538234, \"accuracy\": 0.6553008138730784, \"f1\": 0.6206977288691173, \"f2\": 0.5056554828618841, \"f0_5\": 0.803503773527718, \"p4\": 0.6508666743852276, \"phi\": 0.48356454833561413}, {\"truth_threshold\": 12.700000000000001, \"match_probability\": 0.9998497363992734, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5298, \"tn\": 7017, \"fp\": 1, \"fn\": 6483, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4497071555895085, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5502928444104914, \"precision\": 0.9998112851481411, \"recall\": 0.4497071555895085, \"specificity\": 0.999857509261898, \"npv\": 0.5197777777777778, \"accuracy\": 0.6550880365976913, \"f1\": 0.6203747072599531, \"f2\": 0.5053125536501154, \"f0_5\": 0.8032871395214847, \"p4\": 0.6506287045723019, \"phi\": 0.4833103381211157}, {\"truth_threshold\": 12.72, \"match_probability\": 0.9998518048160936, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5293, \"tn\": 7017, \"fp\": 1, \"fn\": 6488, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4492827434003905, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5507172565996096, \"precision\": 0.999811106913487, \"recall\": 0.4492827434003905, \"specificity\": 0.999857509261898, \"npv\": 0.519585338763421, \"accuracy\": 0.6548220650034576, \"f1\": 0.6199707174231333, \"f2\": 0.5048838185356176, \"f0_5\": 0.803016051218254, \"p4\": 0.6503311098602694, \"phi\": 0.4829925991598847}, {\"truth_threshold\": 12.74, \"match_probability\": 0.9998538447647903, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5285, \"tn\": 7017, \"fp\": 1, \"fn\": 6496, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.44860368389780153, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5513963161021984, \"precision\": 0.9998108210367007, \"recall\": 0.44860368389780153, \"specificity\": 0.999857509261898, \"npv\": 0.519277732553837, \"accuracy\": 0.6543965104526837, \"f1\": 0.619323841331224, \"f2\": 0.5041976721999618, \"f0_5\": 0.8025816249050873, \"p4\": 0.6498546512557567, \"phi\": 0.4824842713485644}, {\"truth_threshold\": 12.76, \"match_probability\": 0.9998558566370636, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5283, \"tn\": 7017, \"fp\": 1, \"fn\": 6498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4484339190221543, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5515660809778457, \"precision\": 0.9998107494322483, \"recall\": 0.4484339190221543, \"specificity\": 0.999857509261898, \"npv\": 0.5192008879023308, \"accuracy\": 0.6542901218149901, \"f1\": 0.6191620275417521, \"f2\": 0.5040261028850557, \"f0_5\": 0.8024728863505179, \"p4\": 0.6497354773889639, \"phi\": 0.48235719979778785}, {\"truth_threshold\": 12.780000000000001, \"match_probability\": 0.9998578408192266, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5275, \"tn\": 7017, \"fp\": 1, \"fn\": 6506, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4477548595195654, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5522451404804346, \"precision\": 0.9998104624715694, \"recall\": 0.4477548595195654, \"specificity\": 0.999857509261898, \"npv\": 0.518893736596909, \"accuracy\": 0.6538645672642162, \"f1\": 0.6185143929178636, \"f2\": 0.5033396946564885, \"f0_5\": 0.8020374030713091, \"p4\": 0.6492585442665959, \"phi\": 0.48184895480008394}, {\"truth_threshold\": 12.8, \"match_probability\": 0.9998597976922806, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5271, \"tn\": 7017, \"fp\": 1, \"fn\": 6510, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4474153297682709, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5525846702317291, \"precision\": 0.9998103186646434, \"recall\": 0.4474153297682709, \"specificity\": 0.999857509261898, \"npv\": 0.518740297183411, \"accuracy\": 0.6536517899888292, \"f1\": 0.6181903477394007, \"f2\": 0.5029964119398428, \"f0_5\": 0.8018193434543187, \"p4\": 0.649019934741455, \"phi\": 0.48159485683632647}, {\"truth_threshold\": 12.82, \"match_probability\": 0.9998617276319876, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5264, \"tn\": 7017, \"fp\": 1, \"fn\": 6517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.44682115270350564, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5531788472964944, \"precision\": 0.9998100664767331, \"recall\": 0.44682115270350564, \"specificity\": 0.999857509261898, \"npv\": 0.5184719964533767, \"accuracy\": 0.653279429756902, \"f1\": 0.6176229027337792, \"f2\": 0.5023955410486934, \"f0_5\": 0.8014372278554246, \"p4\": 0.6486021379250371, \"phi\": 0.4811502243481661}, {\"truth_threshold\": 12.84, \"match_probability\": 0.9998636310089414, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5252, \"tn\": 7017, \"fp\": 1, \"fn\": 6529, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.44580256344962227, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5541974365503777, \"precision\": 0.9998096325909004, \"recall\": 0.44580256344962227, \"specificity\": 0.999857509261898, \"npv\": 0.5180126974752695, \"accuracy\": 0.652641097930741, \"f1\": 0.6166490548315134, \"f2\": 0.5013651030032266, \"f0_5\": 0.8007806544079529, \"p4\": 0.6478852304234947, \"phi\": 0.4803881110820064}, {\"truth_threshold\": 12.86, \"match_probability\": 0.99986550818864, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5240, \"tn\": 7017, \"fp\": 1, \"fn\": 6541, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4447839741957389, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5552160258042611, \"precision\": 0.9998091967181836, \"recall\": 0.4447839741957389, \"specificity\": 0.999857509261898, \"npv\": 0.5175542115356248, \"accuracy\": 0.6520027661045801, \"f1\": 0.6156738338620609, \"f2\": 0.5003341926859544, \"f0_5\": 0.8001221560543594, \"p4\": 0.647167453453006, \"phi\": 0.479626139125749}, {\"truth_threshold\": 12.88, \"match_probability\": 0.9998673595315546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5233, \"tn\": 7017, \"fp\": 1, \"fn\": 6548, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4441897971309736, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5558102028690264, \"precision\": 0.99980894153611, \"recall\": 0.4441897971309736, \"specificity\": 0.999857509261898, \"npv\": 0.5172871360117951, \"accuracy\": 0.6516304058726528, \"f1\": 0.6151043197178959, \"f2\": 0.49973261010733794, \"f0_5\": 0.7997371397132989, \"p4\": 0.6467483463845157, \"phi\": 0.4791817195819001}, {\"truth_threshold\": 12.9, \"match_probability\": 0.9998691853931992, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5226, \"tn\": 7017, \"fp\": 1, \"fn\": 6555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4435956200662083, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5564043799337917, \"precision\": 0.9998086856705567, \"recall\": 0.4435956200662083, \"specificity\": 0.999857509261898, \"npv\": 0.5170203359858532, \"accuracy\": 0.6512580456407255, \"f1\": 0.6145343367826905, \"f2\": 0.49913086665011175, \"f0_5\": 0.7993514637951604, \"p4\": 0.6463289403185946, \"phi\": 0.47873734654935646}, {\"truth_threshold\": 12.92, \"match_probability\": 0.9998709861241983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5223, \"tn\": 7017, \"fp\": 1, \"fn\": 6558, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4433409727527375, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5566590272472626, \"precision\": 0.9998085758039816, \"recall\": 0.4433409727527375, \"specificity\": 0.999857509261898, \"npv\": 0.5169060773480663, \"accuracy\": 0.6510984626841854, \"f1\": 0.6142899147309615, \"f2\": 0.49887292733246735, \"f0_5\": 0.7991859717844355, \"p4\": 0.6461491030438451, \"phi\": 0.4785469150581858}, {\"truth_threshold\": 12.94, \"match_probability\": 0.9998727620703545, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5218, \"tn\": 7017, \"fp\": 1, \"fn\": 6563, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4429165605636194, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5570834394363806, \"precision\": 0.9998083924123395, \"recall\": 0.4429165605636194, \"specificity\": 0.999857509261898, \"npv\": 0.5167157584683358, \"accuracy\": 0.6508324910899516, \"f1\": 0.6138823529411764, \"f2\": 0.4984429627648396, \"f0_5\": 0.7989098814955446, \"p4\": 0.6458492514888386, \"phi\": 0.47822954786232746}, {\"truth_threshold\": 12.96, \"match_probability\": 0.9998745135727142, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5215, \"tn\": 7017, \"fp\": 1, \"fn\": 6566, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.44266191325014853, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5573380867498514, \"precision\": 0.999808282208589, \"recall\": 0.44266191325014853, \"specificity\": 0.999857509261898, \"npv\": 0.5166016343959361, \"accuracy\": 0.6506729081334114, \"f1\": 0.6136377007707242, \"f2\": 0.49818494459304546, \"f0_5\": 0.7987440649410323, \"p4\": 0.645669266747714, \"phi\": 0.4780391386438233}, {\"truth_threshold\": 12.98, \"match_probability\": 0.9998762409676335, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5204, \"tn\": 7017, \"fp\": 1, \"fn\": 6577, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4417282064340888, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5582717935659112, \"precision\": 0.9998078770413065, \"recall\": 0.4417282064340888, \"specificity\": 0.999857509261898, \"npv\": 0.5161836104163602, \"accuracy\": 0.6500877706260971, \"f1\": 0.6127399034498999, \"f2\": 0.49723862485428727, \"f0_5\": 0.7981350265329284, \"p4\": 0.6450088474293041, \"phi\": 0.47734104189984594}, {\"truth_threshold\": 13.0, \"match_probability\": 0.9998779445868424, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5201, \"tn\": 7017, \"fp\": 1, \"fn\": 6580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4414735591206179, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5585264408793821, \"precision\": 0.9998077662437524, \"recall\": 0.4414735591206179, \"specificity\": 0.999857509261898, \"npv\": 0.5160697212620431, \"accuracy\": 0.6499281876695568, \"f1\": 0.6124948477889655, \"f2\": 0.4969804686006956, \"f0_5\": 0.7979686397250606, \"p4\": 0.6448286030437806, \"phi\": 0.4771506708739083}, {\"truth_threshold\": 13.02, \"match_probability\": 0.9998796247575082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5197, \"tn\": 7017, \"fp\": 1, \"fn\": 6584, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4411340293693235, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5588659706306766, \"precision\": 0.9998076183147364, \"recall\": 0.4411340293693235, \"specificity\": 0.999857509261898, \"npv\": 0.515917947209764, \"accuracy\": 0.6497154103941699, \"f1\": 0.6121679722009541, \"f2\": 0.49663621421199494, \"f0_5\": 0.7977465999447395, \"p4\": 0.6445881902240432, \"phi\": 0.4768968553598423}, {\"truth_threshold\": 13.040000000000001, \"match_probability\": 0.9998812818022986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5193, \"tn\": 7017, \"fp\": 1, \"fn\": 6588, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.440794499618029, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5592055003819709, \"precision\": 0.9998074701578745, \"recall\": 0.440794499618029, \"specificity\": 0.999857509261898, \"npv\": 0.5157662624035281, \"accuracy\": 0.6495026331187829, \"f1\": 0.611840942562592, \"f2\": 0.4962919071829963, \"f0_5\": 0.7975243419233959, \"p4\": 0.6443476778053396, \"phi\": 0.4766430540550279}, {\"truth_threshold\": 13.06, \"match_probability\": 0.999882916039443, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5185, \"tn\": 7017, \"fp\": 1, \"fn\": 6596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4401154401154401, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5598845598845599, \"precision\": 0.9998071731585036, \"recall\": 0.4401154401154401, \"specificity\": 0.999857509261898, \"npv\": 0.5154631602145009, \"accuracy\": 0.6490770785680089, \"f1\": 0.611186420699004, \"f2\": 0.49560313515580195, \"f0_5\": 0.7970791698693312, \"p4\": 0.6438663532876513, \"phi\": 0.4761354936368062}, {\"truth_threshold\": 13.08, \"match_probability\": 0.999884527782794, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5181, \"tn\": 7017, \"fp\": 1, \"fn\": 6600, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43977591036414565, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5602240896358543, \"precision\": 0.9998070243149363, \"recall\": 0.43977591036414565, \"specificity\": 0.999857509261898, \"npv\": 0.5153117426745979, \"accuracy\": 0.648864301292622, \"f1\": 0.6108589282556152, \"f2\": 0.4952586701334455, \"f0_5\": 0.7968562551908702, \"p4\": 0.6436255407458851, \"phi\": 0.4758817343050268}, {\"truth_threshold\": 13.1, \"match_probability\": 0.9998861173418873, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5170, \"tn\": 7017, \"fp\": 1, \"fn\": 6611, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4388422035480859, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5611577964519141, \"precision\": 0.9998066138077741, \"recall\": 0.4388422035480859, \"specificity\": 0.999857509261898, \"npv\": 0.5148958027590256, \"accuracy\": 0.6482791637853077, \"f1\": 0.6099575271354413, \"f2\": 0.49431111960990537, \"f0_5\": 0.7962421068843369, \"p4\": 0.6429627874632191, \"phi\": 0.47518396682806935}, {\"truth_threshold\": 13.120000000000001, \"match_probability\": 0.9998876850220009, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5165, \"tn\": 7017, \"fp\": 1, \"fn\": 6616, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43841779135896786, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5615822086410321, \"precision\": 0.999806426635695, \"recall\": 0.43841779135896786, \"specificity\": 0.999857509261898, \"npv\": 0.5147069610503924, \"accuracy\": 0.648013192191074, \"f1\": 0.6095474125213902, \"f2\": 0.49388028303690956, \"f0_5\": 0.7959623979041455, \"p4\": 0.6426612835064447, \"phi\": 0.4748668336087287}, {\"truth_threshold\": 13.14, \"match_probability\": 0.9998892311242138, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5161, \"tn\": 7017, \"fp\": 1, \"fn\": 6620, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4380782616076734, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5619217383923266, \"precision\": 0.9998062766369624, \"recall\": 0.4380782616076734, \"specificity\": 0.999857509261898, \"npv\": 0.5145559873872553, \"accuracy\": 0.647800414915687, \"f1\": 0.6092191465501977, \"f2\": 0.4935355544505221, \"f0_5\": 0.795738382312128, \"p4\": 0.642419966312753, \"phi\": 0.4746131420448277}, {\"truth_threshold\": 13.16, \"match_probability\": 0.9998907559454638, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5156, \"tn\": 7017, \"fp\": 1, \"fn\": 6625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4376538494185553, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5623461505814447, \"precision\": 0.9998060888113244, \"recall\": 0.4376538494185553, \"specificity\": 0.999857509261898, \"npv\": 0.5143673948101452, \"accuracy\": 0.6475344433214533, \"f1\": 0.608808596056205, \"f2\": 0.49310456953769055, \"f0_5\": 0.7954580517757414, \"p4\": 0.6421181769173813, \"phi\": 0.47429604617442356}, {\"truth_threshold\": 13.18, \"match_probability\": 0.9998922597786042, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5149, \"tn\": 7017, \"fp\": 1, \"fn\": 6632, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43705967235379, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.56294032764621, \"precision\": 0.9998058252427184, \"recall\": 0.43705967235379, \"specificity\": 0.999857509261898, \"npv\": 0.5141035973331379, \"accuracy\": 0.647162083089526, \"f1\": 0.608233417990668, \"f2\": 0.49250105214829554, \"f0_5\": 0.7950650072573423, \"p4\": 0.6416954042241778, \"phi\": 0.47385214626251165}, {\"truth_threshold\": 13.200000000000001, \"match_probability\": 0.9998937429124599, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5139, \"tn\": 7017, \"fp\": 1, \"fn\": 6642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4362108479755539, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5637891520244461, \"precision\": 0.9998054474708171, \"recall\": 0.4362108479755539, \"specificity\": 0.999857509261898, \"npv\": 0.5137272128267076, \"accuracy\": 0.6466301399010586, \"f1\": 0.6074109095207139, \"f2\": 0.4916386040104087, \"f0_5\": 0.7945023344980057, \"p4\": 0.6410908995876152, \"phi\": 0.4732180718904552}, {\"truth_threshold\": 13.22, \"match_probability\": 0.9998952056318829, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5131, \"tn\": 7017, \"fp\": 1, \"fn\": 6650, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4355317884729649, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5644682115270351, \"precision\": 0.9998051441932969, \"recall\": 0.4355317884729649, \"specificity\": 0.999857509261898, \"npv\": 0.5134265017926392, \"accuracy\": 0.6462045853502846, \"f1\": 0.6067522024478212, \"f2\": 0.4909484078383344, \"f0_5\": 0.7940511931659909, \"p4\": 0.6406068332554198, \"phi\": 0.4727108692648441}, {\"truth_threshold\": 13.24, \"match_probability\": 0.999896648217807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5129, \"tn\": 7017, \"fp\": 1, \"fn\": 6652, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43536202359731774, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5646379764026823, \"precision\": 0.9998050682261208, \"recall\": 0.43536202359731774, \"specificity\": 0.999857509261898, \"npv\": 0.513351379032848, \"accuracy\": 0.646098196712591, \"f1\": 0.6065874283011058, \"f2\": 0.4907758257741034, \"f0_5\": 0.7939382681650723, \"p4\": 0.6404857521825494, \"phi\": 0.4725840763924904}, {\"truth_threshold\": 13.26, \"match_probability\": 0.9998980709473013, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5124, \"tn\": 7017, \"fp\": 1, \"fn\": 6657, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43493761140819964, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5650623885918004, \"precision\": 0.9998048780487805, \"recall\": 0.43493761140819964, \"specificity\": 0.999857509261898, \"npv\": 0.5131636682755595, \"accuracy\": 0.6458322251183574, \"f1\": 0.606175322370756, \"f2\": 0.49034431280981455, \"f0_5\": 0.7936557107896286, \"p4\": 0.6401829363316346, \"phi\": 0.4722671076827773}, {\"truth_threshold\": 13.3, \"match_probability\": 0.9999008579262733, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5116, \"tn\": 7017, \"fp\": 1, \"fn\": 6665, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43425855190561075, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5657414480943893, \"precision\": 0.9998045729919874, \"recall\": 0.43425855190561075, \"specificity\": 0.999857509261898, \"npv\": 0.5128636164303464, \"accuracy\": 0.6454066705675834, \"f1\": 0.6055154456148657, \"f2\": 0.4896537202580349, \"f0_5\": 0.7932028900120934, \"p4\": 0.6396980937689367, \"phi\": 0.47175999732692664}, {\"truth_threshold\": 13.32, \"match_probability\": 0.9999022227110415, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5115, \"tn\": 7017, \"fp\": 1, \"fn\": 6666, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4341736694677871, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5658263305322129, \"precision\": 0.9998045347928068, \"recall\": 0.4341736694677871, \"specificity\": 0.999857509261898, \"npv\": 0.5128261346196009, \"accuracy\": 0.6453534762487366, \"f1\": 0.6054329170858732, \"f2\": 0.48956738131699845, \"f0_5\": 0.7931462242208094, \"p4\": 0.6396374591925866, \"phi\": 0.4716966119213227}, {\"truth_threshold\": 13.34, \"match_probability\": 0.9999035687100634, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5108, \"tn\": 7017, \"fp\": 1, \"fn\": 6673, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4335794924030218, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5664205075969782, \"precision\": 0.9998042669798395, \"recall\": 0.4335794924030218, \"specificity\": 0.999857509261898, \"npv\": 0.5125639152666179, \"accuracy\": 0.6449811160168094, \"f1\": 0.6048549437537004, \"f2\": 0.4889629161641108, \"f0_5\": 0.7927491696930192, \"p4\": 0.6392128345850128, \"phi\": 0.4712529349101284}, {\"truth_threshold\": 13.36, \"match_probability\": 0.9999048961818684, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5105, \"tn\": 7017, \"fp\": 1, \"fn\": 6676, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.433324845089551, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5666751549104491, \"precision\": 0.999804151978065, \"recall\": 0.433324845089551, \"specificity\": 0.999857509261898, \"npv\": 0.5124516176148397, \"accuracy\": 0.6448215330602691, \"f1\": 0.6046070942144846, \"f2\": 0.4887038100708405, \"f0_5\": 0.792578792113026, \"p4\": 0.6390307546055352, \"phi\": 0.4710627986822647}, {\"truth_threshold\": 13.38, \"match_probability\": 0.999906205381429, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5101, \"tn\": 7017, \"fp\": 1, \"fn\": 6680, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4329853153382565, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5670146846617435, \"precision\": 0.9998039984319874, \"recall\": 0.4329853153382565, \"specificity\": 0.999857509261898, \"npv\": 0.5123019639337081, \"accuracy\": 0.6446087557848822, \"f1\": 0.6042764911449386, \"f2\": 0.4883582889748401, \"f0_5\": 0.7923514243996397, \"p4\": 0.6387878895930441, \"phi\": 0.47080929392371607}, {\"truth_threshold\": 13.4, \"match_probability\": 0.9999074965602103, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5088, \"tn\": 7017, \"fp\": 1, \"fn\": 6693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4318818436465495, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5681181563534504, \"precision\": 0.999803497740224, \"recall\": 0.4318818436465495, \"specificity\": 0.999857509261898, \"npv\": 0.5118161925601751, \"accuracy\": 0.6439172296398744, \"f1\": 0.6032009484291642, \"f2\": 0.4872349797943041, \"f0_5\": 0.791610915766873, \"p4\": 0.6379978518130565, \"phi\": 0.46998548278166485}, {\"truth_threshold\": 13.42, \"match_probability\": 0.9999087699662178, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5081, \"tn\": 7017, \"fp\": 1, \"fn\": 6700, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43128766658178425, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5687123334182158, \"precision\": 0.9998032270759544, \"recall\": 0.43128766658178425, \"specificity\": 0.999857509261898, \"npv\": 0.5115550047386455, \"accuracy\": 0.6435448694079472, \"f1\": 0.6026211231690684, \"f2\": 0.48662988928475653, \"f0_5\": 0.7912111868946401, \"p4\": 0.6375719846039072, \"phi\": 0.46954194144380756}, {\"truth_threshold\": 13.44, \"match_probability\": 0.9999100258440452, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5076, \"tn\": 7017, \"fp\": 1, \"fn\": 6705, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.43086325439266615, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5691367456073338, \"precision\": 0.9998030332873744, \"recall\": 0.43086325439266615, \"specificity\": 0.999857509261898, \"npv\": 0.5113686051595977, \"accuracy\": 0.6432788978137135, \"f1\": 0.6022066674575869, \"f2\": 0.4861975824217927, \"f0_5\": 0.7909252391785347, \"p4\": 0.6372675947227097, \"phi\": 0.4692251468862625}, {\"truth_threshold\": 13.46, \"match_probability\": 0.9999112644349214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5074, \"tn\": 7017, \"fp\": 1, \"fn\": 6707, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4306934895170189, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5693065104829811, \"precision\": 0.9998029556650246, \"recall\": 0.4306934895170189, \"specificity\": 0.999857509261898, \"npv\": 0.5112940833576217, \"accuracy\": 0.64317250917602, \"f1\": 0.6020408163265306, \"f2\": 0.48602463648728905, \"f0_5\": 0.7908107602630841, \"p4\": 0.6371457922134884, \"phi\": 0.46909843383254585}, {\"truth_threshold\": 13.48, \"match_probability\": 0.9999124859767564, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5069, \"tn\": 7017, \"fp\": 1, \"fn\": 6712, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4302690773279009, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5697309226720991, \"precision\": 0.9998027613412229, \"recall\": 0.4302690773279009, \"specificity\": 0.999857509261898, \"npv\": 0.5111078738436885, \"accuracy\": 0.6429065375817863, \"f1\": 0.6016260162601627, \"f2\": 0.48559221366440586, \"f0_5\": 0.7905243130282898, \"p4\": 0.6368411692922802, \"phi\": 0.4687816629994308}, {\"truth_threshold\": 13.5, \"match_probability\": 0.9999136907041872, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5063, \"tn\": 7017, \"fp\": 1, \"fn\": 6718, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42975978270095916, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5702402172990408, \"precision\": 0.9998025276461295, \"recall\": 0.42975978270095916, \"specificity\": 0.999857509261898, \"npv\": 0.5108846013833273, \"accuracy\": 0.6425873716687058, \"f1\": 0.6011279311368358, \"f2\": 0.4850731969035027, \"f0_5\": 0.7901801042544558, \"p4\": 0.6364754012969654, \"phi\": 0.4684015600037232}, {\"truth_threshold\": 13.52, \"match_probability\": 0.9999148788486228, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5057, \"tn\": 7017, \"fp\": 1, \"fn\": 6724, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4292504880740175, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5707495119259826, \"precision\": 0.9998022933965994, \"recall\": 0.4292504880740175, \"specificity\": 0.999857509261898, \"npv\": 0.5106615239065571, \"accuracy\": 0.6422682057556253, \"f1\": 0.6006294910624146, \"f2\": 0.48455406078724467, \"f0_5\": 0.789835379377128, \"p4\": 0.6361093920168318, \"phi\": 0.4680214806559675}, {\"truth_threshold\": 13.540000000000001, \"match_probability\": 0.9999160506382885, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5056, \"tn\": 7017, \"fp\": 1, \"fn\": 6725, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4291656056361939, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5708343943638061, \"precision\": 0.9998022543009689, \"recall\": 0.4291656056361939, \"specificity\": 0.999857509261898, \"npv\": 0.5106243632659001, \"accuracy\": 0.6422150114367785, \"f1\": 0.6005463831809004, \"f2\": 0.48446752649431785, \"f0_5\": 0.7897778749726639, \"p4\": 0.6360483669559787, \"phi\": 0.4679581363705896}, {\"truth_threshold\": 13.56, \"match_probability\": 0.9999172062982694, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5053, \"tn\": 7017, \"fp\": 1, \"fn\": 6728, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.428910958322723, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5710890416772769, \"precision\": 0.9998021369212505, \"recall\": 0.428910958322723, \"specificity\": 0.999857509261898, \"npv\": 0.5105129137868316, \"accuracy\": 0.6420554284802383, \"f1\": 0.6002970002970003, \"f2\": 0.4842079037142091, \"f0_5\": 0.7896052754945776, \"p4\": 0.6358652513895368, \"phi\": 0.4677681073753025}, {\"truth_threshold\": 13.58, \"match_probability\": 0.9999183460505544, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5047, \"tn\": 7017, \"fp\": 1, \"fn\": 6734, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42840166369578137, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5715983363042186, \"precision\": 0.9998019017432647, \"recall\": 0.42840166369578137, \"specificity\": 0.999857509261898, \"npv\": 0.5102901607155843, \"accuracy\": 0.6417362625671579, \"f1\": 0.5997979677936894, \"f2\": 0.48368856858084797, \"f0_5\": 0.7892596878616333, \"p4\": 0.6354988381960172, \"phi\": 0.4673880666008746}, {\"truth_threshold\": 13.6, \"match_probability\": 0.9999194701140777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5043, \"tn\": 7017, \"fp\": 1, \"fn\": 6738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4280621339444869, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5719378660555131, \"precision\": 0.9998017446471055, \"recall\": 0.4280621339444869, \"specificity\": 0.999857509261898, \"npv\": 0.5101417666303163, \"accuracy\": 0.6415234852917708, \"f1\": 0.5994650817236256, \"f2\": 0.48334227879159636, \"f0_5\": 0.789029007729136, \"p4\": 0.6352544275525477, \"phi\": 0.4671347186853546}, {\"truth_threshold\": 13.64, \"match_probability\": 0.9999216720355576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5031, \"tn\": 7017, \"fp\": 1, \"fn\": 6750, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4270435446906035, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5729564553093965, \"precision\": 0.9998012718600954, \"recall\": 0.4270435446906035, \"specificity\": 0.999857509261898, \"npv\": 0.5096971017650904, \"accuracy\": 0.6408851534656099, \"f1\": 0.59846547314578, \"f2\": 0.4823030907278166, \"f0_5\": 0.7883355793036447, \"p4\": 0.6345205441337751, \"phi\": 0.4663747341866594}, {\"truth_threshold\": 13.66, \"match_probability\": 0.9999227503164871, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5029, \"tn\": 7017, \"fp\": 1, \"fn\": 6752, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4268737798149563, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5731262201850437, \"precision\": 0.9998011928429423, \"recall\": 0.4268737798149563, \"specificity\": 0.999857509261898, \"npv\": 0.5096230663083738, \"accuracy\": 0.6407787648279164, \"f1\": 0.5982987329724585, \"f2\": 0.4821298462246424, \"f0_5\": 0.7882198050217861, \"p4\": 0.6343981349084841, \"phi\": 0.4662480785962154}, {\"truth_threshold\": 13.68, \"match_probability\": 0.9999238137546823, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5024, \"tn\": 7017, \"fp\": 1, \"fn\": 6757, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42644936762583824, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5735506323741618, \"precision\": 0.9998009950248756, \"recall\": 0.42644936762583824, \"specificity\": 0.999857509261898, \"npv\": 0.5094380717293452, \"accuracy\": 0.6405127932336826, \"f1\": 0.5978817089134832, \"f2\": 0.4816966768298529, \"f0_5\": 0.7879301151155861, \"p4\": 0.6340919922777759, \"phi\": 0.4659314500409017}, {\"truth_threshold\": 13.700000000000001, \"match_probability\": 0.9999248625544251, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5020, \"tn\": 7017, \"fp\": 1, \"fn\": 6761, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42610983787454376, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5738901621254563, \"precision\": 0.9998008364867557, \"recall\": 0.42610983787454376, \"specificity\": 0.999857509261898, \"npv\": 0.5092901727391493, \"accuracy\": 0.6403000159582957, \"f1\": 0.5975479109629805, \"f2\": 0.48135008150349984, \"f0_5\": 0.7876981013651342, \"p4\": 0.6338469549417979, \"phi\": 0.465678157798895}, {\"truth_threshold\": 13.72, \"match_probability\": 0.9999258969171868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5015, \"tn\": 7017, \"fp\": 1, \"fn\": 6766, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42568542568542567, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5743145743145743, \"precision\": 0.9998006379585327, \"recall\": 0.42568542568542567, \"specificity\": 0.999857509261898, \"npv\": 0.5091054197199448, \"accuracy\": 0.640034044364062, \"f1\": 0.5971304399595165, \"f2\": 0.4809167625623322, \"f0_5\": 0.7874077563196734, \"p4\": 0.6335405038376631, \"phi\": 0.46536155556402736}, {\"truth_threshold\": 13.74, \"match_probability\": 0.9999269170416667, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5012, \"tn\": 7017, \"fp\": 1, \"fn\": 6769, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42543077837195487, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5745692216280451, \"precision\": 0.9998005186515061, \"recall\": 0.42543077837195487, \"specificity\": 0.999857509261898, \"npv\": 0.5089946322356014, \"accuracy\": 0.6398744614075217, \"f1\": 0.5968798380373943, \"f2\": 0.4806567313040643, \"f0_5\": 0.7872333741714573, \"p4\": 0.6333565506293806, \"phi\": 0.4651716011077908}, {\"truth_threshold\": 13.76, \"match_probability\": 0.99992792312383, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5007, \"tn\": 7017, \"fp\": 1, \"fn\": 6774, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42500636618283677, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5749936338171632, \"precision\": 0.9998003194888179, \"recall\": 0.42500636618283677, \"specificity\": 0.999857509261898, \"npv\": 0.5088100935392648, \"accuracy\": 0.639608489813288, \"f1\": 0.596461969146465, \"f2\": 0.48022327936775877, \"f0_5\": 0.7869424449124571, \"p4\": 0.6330498240452136, \"phi\": 0.4648550216687547}, {\"truth_threshold\": 13.780000000000001, \"match_probability\": 0.999928915356946, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5003, \"tn\": 7017, \"fp\": 1, \"fn\": 6778, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4246668364315423, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5753331635684577, \"precision\": 0.9998001598721024, \"recall\": 0.4246668364315423, \"specificity\": 0.999857509261898, \"npv\": 0.5086625588981515, \"accuracy\": 0.639395712537901, \"f1\": 0.5961274947870122, \"f2\": 0.4798764579496624, \"f0_5\": 0.7867094379972953, \"p4\": 0.6328043183920038, \"phi\": 0.4646017681794267}, {\"truth_threshold\": 13.8, \"match_probability\": 0.999929893931624, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5001, \"tn\": 7017, \"fp\": 1, \"fn\": 6780, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4244970715558951, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5755029284441049, \"precision\": 0.9998000799680128, \"recall\": 0.4244970715558951, \"specificity\": 0.999857509261898, \"npv\": 0.5085888236573168, \"accuracy\": 0.6392893239002074, \"f1\": 0.5959601978192218, \"f2\": 0.4797030272800522, \"f0_5\": 0.786592846582151, \"p4\": 0.6326815240200123, \"phi\": 0.4644751447497962}, {\"truth_threshold\": 13.82, \"match_probability\": 0.9999308590358513, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4994, \"tn\": 7017, \"fp\": 1, \"fn\": 6787, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4239028944911298, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5760971055088702, \"precision\": 0.9997997997997998, \"recall\": 0.4239028944911298, \"specificity\": 0.999857509261898, \"npv\": 0.5083309185743263, \"accuracy\": 0.6389169636682802, \"f1\": 0.5953743443013829, \"f2\": 0.47909591511732763, \"f0_5\": 0.7861843140959038, \"p4\": 0.6322515250859418, \"phi\": 0.4640319799082125}, {\"truth_threshold\": 13.84, \"match_probability\": 0.9999318108550282, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4991, \"tn\": 7017, \"fp\": 1, \"fn\": 6790, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4236482471776589, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5763517528223411, \"precision\": 0.9997996794871795, \"recall\": 0.4236482471776589, \"specificity\": 0.999857509261898, \"npv\": 0.5082204678786123, \"accuracy\": 0.63875738071174, \"f1\": 0.595123114529303, \"f2\": 0.47883567426510093, \"f0_5\": 0.7860090081577372, \"p4\": 0.6320671354894397, \"phi\": 0.4638420601850212}, {\"truth_threshold\": 13.86, \"match_probability\": 0.9999327495720041, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4987, \"tn\": 7017, \"fp\": 1, \"fn\": 6794, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4233087174263645, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5766912825736356, \"precision\": 0.9997995188452286, \"recall\": 0.4233087174263645, \"specificity\": 0.999857509261898, \"npv\": 0.5080732749257838, \"accuracy\": 0.638544603436353, \"f1\": 0.5947880016697478, \"f2\": 0.47848863985262513, \"f0_5\": 0.7857750606624019, \"p4\": 0.6318211850616552, \"phi\": 0.4635888412998153}, {\"truth_threshold\": 13.88, \"match_probability\": 0.9999336753671121, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4983, \"tn\": 7017, \"fp\": 1, \"fn\": 6798, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42296918767507, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5770308123249299, \"precision\": 0.9997993579454254, \"recall\": 0.42296918767507, \"specificity\": 0.999857509261898, \"npv\": 0.5079261672095549, \"accuracy\": 0.638331826160966, \"f1\": 0.594452728899493, \"f2\": 0.4781415521608966, \"f0_5\": 0.7855408771321374, \"p4\": 0.6315751228295161, \"phi\": 0.4633356307816913}, {\"truth_threshold\": 13.9, \"match_probability\": 0.9999345884182044, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4981, \"tn\": 7017, \"fp\": 1, \"fn\": 6800, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4227994227994228, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5772005772005772, \"precision\": 0.9997992773986351, \"recall\": 0.4227994227994228, \"specificity\": 0.999857509261898, \"npv\": 0.5078526452920316, \"accuracy\": 0.6382254375232725, \"f1\": 0.5942850325120802, \"f2\": 0.47796798833147813, \"f0_5\": 0.7854236967422499, \"p4\": 0.6314520497101814, \"phi\": 0.4632090286247322}, {\"truth_threshold\": 13.92, \"match_probability\": 0.9999354889006857, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4977, \"tn\": 7017, \"fp\": 1, \"fn\": 6804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42245989304812837, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5775401069518716, \"precision\": 0.9997991161108879, \"recall\": 0.42245989304812837, \"specificity\": 0.999857509261898, \"npv\": 0.507705665291947, \"accuracy\": 0.6380126602478855, \"f1\": 0.5939495196610777, \"f2\": 0.4776208206978619, \"f0_5\": 0.7851891584892563, \"p4\": 0.6312058193114435, \"phi\": 0.46295583044385885}, {\"truth_threshold\": 13.94, \"match_probability\": 0.999936376987547, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4971, \"tn\": 7017, \"fp\": 1, \"fn\": 6810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42195059842118665, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5780494015788133, \"precision\": 0.9997988736926791, \"recall\": 0.42195059842118665, \"specificity\": 0.999857509261898, \"npv\": 0.5074853547407246, \"accuracy\": 0.637693494334805, \"f1\": 0.5934459499791083, \"f2\": 0.4770999692874693, \"f0_5\": 0.7848369067542391, \"p4\": 0.6308362628516032, \"phi\": 0.46257604829148646}, {\"truth_threshold\": 13.96, \"match_probability\": 0.9999372528493993, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4970, \"tn\": 7017, \"fp\": 1, \"fn\": 6811, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42186571598336303, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5781342840166369, \"precision\": 0.99979883323275, \"recall\": 0.42186571598336303, \"specificity\": 0.999857509261898, \"npv\": 0.5074486549030952, \"accuracy\": 0.6376403000159583, \"f1\": 0.5933619866284623, \"f2\": 0.4770131490546118, \"f0_5\": 0.7847781462182221, \"p4\": 0.6307746454583173, \"phi\": 0.4625127530070991}, {\"truth_threshold\": 13.98, \"match_probability\": 0.9999381166545053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4962, \"tn\": 7017, \"fp\": 1, \"fn\": 6819, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.42118665648077414, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5788133435192259, \"precision\": 0.999798508966351, \"recall\": 0.42118665648077414, \"specificity\": 0.999857509261898, \"npv\": 0.5071552471812663, \"accuracy\": 0.6372147454651843, \"f1\": 0.5926899187768753, \"f2\": 0.47631846717991055, \"f0_5\": 0.7843075269497044, \"p4\": 0.6302814520741974, \"phi\": 0.462006408318421}, {\"truth_threshold\": 14.0, \"match_probability\": 0.9999389685688129, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4955, \"tn\": 7017, \"fp\": 1, \"fn\": 6826, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4205924794160088, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5794075205839911, \"precision\": 0.9997982243744956, \"recall\": 0.4205924794160088, \"specificity\": 0.999857509261898, \"npv\": 0.506898793614101, \"accuracy\": 0.6368423852332571, \"f1\": 0.5921013323773675, \"f2\": 0.47571044546851, \"f0_5\": 0.7838949533301692, \"p4\": 0.6298495360151252, \"phi\": 0.4615633818625937}, {\"truth_threshold\": 14.02, \"match_probability\": 0.9999398087559863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4952, \"tn\": 7017, \"fp\": 1, \"fn\": 6829, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.420337832102538, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.579662167897462, \"precision\": 0.9997981021603068, \"recall\": 0.420337832102538, \"specificity\": 0.999857509261898, \"npv\": 0.5067889643218259, \"accuracy\": 0.6366828022767168, \"f1\": 0.5918489303215011, \"f2\": 0.4754498146974672, \"f0_5\": 0.7837179121957396, \"p4\": 0.62966432254096, \"phi\": 0.4613735204053956}, {\"truth_threshold\": 14.040000000000001, \"match_probability\": 0.9999406373774375, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4947, \"tn\": 7017, \"fp\": 1, \"fn\": 6834, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4199134199134199, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5800865800865801, \"precision\": 0.9997978981406629, \"recall\": 0.4199134199134199, \"specificity\": 0.999857509261898, \"npv\": 0.5066060212259043, \"accuracy\": 0.6364168306824831, \"f1\": 0.5914280590591189, \"f2\": 0.47501536334306343, \"f0_5\": 0.7834225445792291, \"p4\": 0.6293554909056732, \"phi\": 0.46105709382952414}, {\"truth_threshold\": 14.06, \"match_probability\": 0.9999414545923574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4943, \"tn\": 7017, \"fp\": 1, \"fn\": 6838, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41957389016212543, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5804261098378746, \"precision\": 0.9997977346278317, \"recall\": 0.41957389016212543, \"specificity\": 0.999857509261898, \"npv\": 0.506459761818838, \"accuracy\": 0.6362040534070961, \"f1\": 0.5910911808669657, \"f2\": 0.47466774218329877, \"f0_5\": 0.7831859809234084, \"p4\": 0.6291082970558756, \"phi\": 0.4608039607072939}, {\"truth_threshold\": 14.08, \"match_probability\": 0.9999422605577463, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4942, \"tn\": 7017, \"fp\": 1, \"fn\": 6839, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41948900772430187, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5805109922756981, \"precision\": 0.9997976937082743, \"recall\": 0.41948900772430187, \"specificity\": 0.999857509261898, \"npv\": 0.5064232101616628, \"accuracy\": 0.6361508590882494, \"f1\": 0.5910069361396795, \"f2\": 0.4745808285478326, \"f0_5\": 0.7831268025227395, \"p4\": 0.6290464807078463, \"phi\": 0.4607406785421318}, {\"truth_threshold\": 14.1, \"match_probability\": 0.9999430554284441, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4936, \"tn\": 7017, \"fp\": 1, \"fn\": 6845, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41897971309736015, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5810202869026398, \"precision\": 0.9997974478428195, \"recall\": 0.41897971309736015, \"specificity\": 0.999857509261898, \"npv\": 0.5062040109652287, \"accuracy\": 0.6358316931751689, \"f1\": 0.5905012561311161, \"f2\": 0.4740592766178137, \"f0_5\": 0.7827714167908909, \"p4\": 0.6286754320790985, \"phi\": 0.4603609947822421}, {\"truth_threshold\": 14.120000000000001, \"match_probability\": 0.9999438393571597, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4928, \"tn\": 7017, \"fp\": 1, \"fn\": 6853, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41830065359477125, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5816993464052288, \"precision\": 0.9997971190910935, \"recall\": 0.41830065359477125, \"specificity\": 0.999857509261898, \"npv\": 0.5059120403749099, \"accuracy\": 0.6354061386243949, \"f1\": 0.5898264512268103, \"f2\": 0.47336368701131537, \"f0_5\": 0.7822967266723815, \"p4\": 0.6281802980327902, \"phi\": 0.4598547738820315}, {\"truth_threshold\": 14.14, \"match_probability\": 0.9999446124945011, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4923, \"tn\": 7017, \"fp\": 1, \"fn\": 6858, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41787624140565316, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5821237585943468, \"precision\": 0.9997969130787977, \"recall\": 0.41787624140565316, \"specificity\": 0.999857509261898, \"npv\": 0.5057297297297297, \"accuracy\": 0.6351401670301612, \"f1\": 0.589404369949117, \"f2\": 0.4729288349216108, \"f0_5\": 0.7819995552308034, \"p4\": 0.6278706048255572, \"phi\": 0.4595383994431604}, {\"truth_threshold\": 14.16, \"match_probability\": 0.999945374989003, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4919, \"tn\": 7017, \"fp\": 1, \"fn\": 6862, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41753671165435874, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5824632883456413, \"precision\": 0.9997967479674796, \"recall\": 0.41753671165435874, \"specificity\": 0.999857509261898, \"npv\": 0.505583975790763, \"accuracy\": 0.6349273897547741, \"f1\": 0.5890665229626968, \"f2\": 0.4725808930904619, \"f0_5\": 0.7817615460411302, \"p4\": 0.627622720019696, \"phi\": 0.4592853072537436}, {\"truth_threshold\": 14.18, \"match_probability\": 0.9999461269871569, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4910, \"tn\": 7017, \"fp\": 1, \"fn\": 6871, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41677276971394617, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5832272302860538, \"precision\": 0.9997963754836082, \"recall\": 0.41677276971394617, \"specificity\": 0.999857509261898, \"npv\": 0.5052563364055299, \"accuracy\": 0.6344486408851535, \"f1\": 0.588305775221663, \"f2\": 0.47179782838474105, \"f0_5\": 0.781225139220366, \"p4\": 0.6270645545352531, \"phi\": 0.45871587311960144}, {\"truth_threshold\": 14.200000000000001, \"match_probability\": 0.9999468686334378, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4902, \"tn\": 7017, \"fp\": 1, \"fn\": 6879, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41609371021135727, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5839062897886428, \"precision\": 0.9997960432388334, \"recall\": 0.41609371021135727, \"specificity\": 0.999857509261898, \"npv\": 0.5049654576856649, \"accuracy\": 0.6340230863343795, \"f1\": 0.5876288659793815, \"f2\": 0.4711015434293732, \"f0_5\": 0.780747300353582, \"p4\": 0.626567911910256, \"phi\": 0.4582097356590055}, {\"truth_threshold\": 14.22, \"match_probability\": 0.9999476000703327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4899, \"tn\": 7017, \"fp\": 1, \"fn\": 6882, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4158390628978864, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5841609371021136, \"precision\": 0.9997959183673469, \"recall\": 0.4158390628978864, \"specificity\": 0.999857509261898, \"npv\": 0.5048564644938485, \"accuracy\": 0.6338635033778393, \"f1\": 0.5873748576224447, \"f2\": 0.4708403813624481, \"f0_5\": 0.7805678595328384, \"p4\": 0.6263815502487758, \"phi\": 0.4580199402729821}, {\"truth_threshold\": 14.24, \"match_probability\": 0.9999483214383678, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4897, \"tn\": 7017, \"fp\": 1, \"fn\": 6884, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4156692980222392, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5843307019777608, \"precision\": 0.999795835034708, \"recall\": 0.4156692980222392, \"specificity\": 0.999857509261898, \"npv\": 0.5047838285015467, \"accuracy\": 0.6337571147401457, \"f1\": 0.5872054679537142, \"f2\": 0.47066625658375305, \"f0_5\": 0.7804481560577566, \"p4\": 0.626257272485632, \"phi\": 0.4578934118435469}, {\"truth_threshold\": 14.26, \"match_probability\": 0.9999490328761353, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4889, \"tn\": 7017, \"fp\": 1, \"fn\": 6892, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4149902385196503, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5850097614803497, \"precision\": 0.9997955010224949, \"recall\": 0.4149902385196503, \"specificity\": 0.999857509261898, \"npv\": 0.5044934934215256, \"accuracy\": 0.6333315601893718, \"f1\": 0.5865275028492591, \"f2\": 0.4699696235628869, \"f0_5\": 0.7799687310551674, \"p4\": 0.6257598674938784, \"phi\": 0.4573873124345751}, {\"truth_threshold\": 14.280000000000001, \"match_probability\": 0.9999497345203204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4883, \"tn\": 7017, \"fp\": 1, \"fn\": 6898, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4144809438927086, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5855190561072914, \"precision\": 0.9997952497952498, \"recall\": 0.4144809438927086, \"specificity\": 0.999857509261898, \"npv\": 0.5042759611929573, \"accuracy\": 0.6330123942762913, \"f1\": 0.5860186018601861, \"f2\": 0.4694470081525919, \"f0_5\": 0.7796085193345468, \"p4\": 0.6253865042132172, \"phi\": 0.4570077524951005}, {\"truth_threshold\": 14.3, \"match_probability\": 0.9999504265057271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4878, \"tn\": 7017, \"fp\": 1, \"fn\": 6903, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4140565317035905, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5859434682964094, \"precision\": 0.9997950399672064, \"recall\": 0.4140565317035905, \"specificity\": 0.999857509261898, \"npv\": 0.5040948275862069, \"accuracy\": 0.6327464226820576, \"f1\": 0.585594237695078, \"f2\": 0.4690114031882776, \"f0_5\": 0.779307920886986, \"p4\": 0.6250751647708198, \"phi\": 0.4566914617995371}, {\"truth_threshold\": 14.32, \"match_probability\": 0.9999511089653043, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4875, \"tn\": 7017, \"fp\": 1, \"fn\": 6906, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41380188439011967, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5861981156098803, \"precision\": 0.9997949138638228, \"recall\": 0.41380188439011967, \"specificity\": 0.999857509261898, \"npv\": 0.5039862098685628, \"accuracy\": 0.6325868397255173, \"f1\": 0.5853394969082067, \"f2\": 0.46875, \"f0_5\": 0.7791273773373821, \"p4\": 0.6248882721334068, \"phi\": 0.4565016913183025}, {\"truth_threshold\": 14.34, \"match_probability\": 0.9999517820301712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4863, \"tn\": 7017, \"fp\": 1, \"fn\": 6918, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4127832951362363, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5872167048637636, \"precision\": 0.9997944078947368, \"recall\": 0.4127832951362363, \"specificity\": 0.999857509261898, \"npv\": 0.5035522066738428, \"accuracy\": 0.6319485078993563, \"f1\": 0.5843196155001502, \"f2\": 0.46770408555820575, \"f0_5\": 0.7784038159874508, \"p4\": 0.6241400318595428, \"phi\": 0.4557426378194785}, {\"truth_threshold\": 14.36, \"match_probability\": 0.9999524458296426, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4860, \"tn\": 7017, \"fp\": 1, \"fn\": 6921, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4125286478227655, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5874713521772346, \"precision\": 0.9997942810121374, \"recall\": 0.4125286478227655, \"specificity\": 0.999857509261898, \"npv\": 0.5034438226431339, \"accuracy\": 0.6317889249428161, \"f1\": 0.5840644153346953, \"f2\": 0.467442531499471, \"f0_5\": 0.77822257806245, \"p4\": 0.6239528038106353, \"phi\": 0.45555288130465255}, {\"truth_threshold\": 14.38, \"match_probability\": 0.9999531004912537, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4855, \"tn\": 7017, \"fp\": 1, \"fn\": 6926, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4121042356336474, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5878957643663526, \"precision\": 0.9997940691927513, \"recall\": 0.4121042356336474, \"specificity\": 0.999857509261898, \"npv\": 0.5032632862368214, \"accuracy\": 0.6315229533485823, \"f1\": 0.5836388772014185, \"f2\": 0.46700654097729893, \"f0_5\": 0.7779202050953373, \"p4\": 0.6236406072022687, \"phi\": 0.4552366263003289}, {\"truth_threshold\": 14.4, \"match_probability\": 0.9999537461407846, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4850, \"tn\": 7017, \"fp\": 1, \"fn\": 6931, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4116798234445293, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5883201765554706, \"precision\": 0.9997938569367141, \"recall\": 0.4116798234445293, \"specificity\": 0.999857509261898, \"npv\": 0.5030828792658446, \"accuracy\": 0.6312569817543486, \"f1\": 0.5832130832130832, \"f2\": 0.4665704665704666, \"f0_5\": 0.777617444284111, \"p4\": 0.6233282228250245, \"phi\": 0.4549203784146349}, {\"truth_threshold\": 14.42, \"match_probability\": 0.9999543829022842, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4844, \"tn\": 7017, \"fp\": 1, \"fn\": 6937, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.41117052881758764, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5888294711824124, \"precision\": 0.9997936016511868, \"recall\": 0.41117052881758764, \"specificity\": 0.999857509261898, \"npv\": 0.5028665615594095, \"accuracy\": 0.6309378158412682, \"f1\": 0.582701792373391, \"f2\": 0.46604706652042566, \"f0_5\": 0.7772536183049324, \"p4\": 0.6229531129948678, \"phi\": 0.454540890025491}, {\"truth_threshold\": 14.44, \"match_probability\": 0.9999550108980944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4841, \"tn\": 7017, \"fp\": 1, \"fn\": 6940, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4109158815041168, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5890841184958832, \"precision\": 0.9997934737711689, \"recall\": 0.4109158815041168, \"specificity\": 0.999857509261898, \"npv\": 0.5027584724510998, \"accuracy\": 0.6307782328847279, \"f1\": 0.582446008542381, \"f2\": 0.46578532117153526, \"f0_5\": 0.777071495072073, \"p4\": 0.6227654561297252, \"phi\": 0.4543511494271597}, {\"truth_threshold\": 14.46, \"match_probability\": 0.9999556302488732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4827, \"tn\": 7017, \"fp\": 1, \"fn\": 6954, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4097275273745862, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5902724726254138, \"precision\": 0.9997928748964374, \"recall\": 0.4097275273745862, \"specificity\": 0.999857509261898, \"npv\": 0.5022546703886622, \"accuracy\": 0.6300335124208735, \"f1\": 0.5812511289060148, \"f2\": 0.46456344317831844, \"f0_5\": 0.7762197279130351, \"p4\": 0.6218888216528198, \"phi\": 0.4534657233230032}, {\"truth_threshold\": 14.48, \"match_probability\": 0.9999562410736184, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4825, \"tn\": 7017, \"fp\": 1, \"fn\": 6956, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.409557762498939, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5904422375010611, \"precision\": 0.9997927890592623, \"recall\": 0.409557762498939, \"specificity\": 0.999857509261898, \"npv\": 0.5021827810777929, \"accuracy\": 0.6299271237831799, \"f1\": 0.5810802673571386, \"f2\": 0.4643888354186718, \"f0_5\": 0.7760977963648061, \"p4\": 0.621763466399744, \"phi\": 0.45333923772927875}, {\"truth_threshold\": 14.5, \"match_probability\": 0.9999568434896896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4817, \"tn\": 7017, \"fp\": 1, \"fn\": 6964, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40887870299635004, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5911212970036499, \"precision\": 0.9997924449979244, \"recall\": 0.40887870299635004, \"specificity\": 0.999857509261898, \"npv\": 0.5018954295114799, \"accuracy\": 0.629501569232406, \"f1\": 0.5803964094222543, \"f2\": 0.46369026991644524, \"f0_5\": 0.7756094419218755, \"p4\": 0.6212617396655896, \"phi\": 0.45283330438790076}, {\"truth_threshold\": 14.52, \"match_probability\": 0.9999574376128317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4811, \"tn\": 7017, \"fp\": 1, \"fn\": 6970, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4083694083694084, \"tn_rate\": 0.999857509261898, \"fp_rate\": 0.00014249073810202338, \"fn_rate\": 0.5916305916305916, \"precision\": 0.9997921862011637, \"recall\": 0.4083694083694084, \"specificity\": 0.999857509261898, \"npv\": 0.5016801315507257, \"accuracy\": 0.6291824033193255, \"f1\": 0.5798830832278672, \"f2\": 0.4631662045594578, \"f0_5\": 0.7752425150665506, \"p4\": 0.6208851226717029, \"phi\": 0.45245386345270705}, {\"truth_threshold\": 14.540000000000001, \"match_probability\": 0.9999580235571964, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4808, \"tn\": 7018, \"fp\": 0, \"fn\": 6973, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4081147610559375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5918852389440624, \"precision\": 1.0, \"recall\": 0.4081147610559375, \"specificity\": 1.0, \"npv\": 0.5016081766850118, \"accuracy\": 0.629076014681632, \"f1\": 0.5796612212912171, \"f2\": 0.4629130401294, \"f0_5\": 0.77515880437236, \"p4\": 0.6207441106628614, \"phi\": 0.45245298227717323}, {\"truth_threshold\": 14.56, \"match_probability\": 0.9999586014353645, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4805, \"tn\": 7018, \"fp\": 0, \"fn\": 6976, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40786011374246667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5921398862575333, \"precision\": 1.0, \"recall\": 0.40786011374246667, \"specificity\": 1.0, \"npv\": 0.5015006431327712, \"accuracy\": 0.6289164317250917, \"f1\": 0.5794043168937658, \"f2\": 0.4626509272275607, \"f0_5\": 0.7749750008064256, \"p4\": 0.620555618593925, \"phi\": 0.4522633185988581}, {\"truth_threshold\": 14.58, \"match_probability\": 0.9999591713583673, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4800, \"tn\": 7018, \"fp\": 0, \"fn\": 6981, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40743570155334863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5925642984466514, \"precision\": 1.0, \"recall\": 0.40743570155334863, \"specificity\": 1.0, \"npv\": 0.5013215229659261, \"accuracy\": 0.628650460130858, \"f1\": 0.578975936312647, \"f2\": 0.46221400508435406, \"f0_5\": 0.7746683451147478, \"p4\": 0.6202413107016621, \"phi\": 0.45194721640188834}, {\"truth_threshold\": 14.6, \"match_probability\": 0.9999597334357079, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4797, \"tn\": 7018, \"fp\": 0, \"fn\": 6984, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40718105423987777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5928189457601223, \"precision\": 1.0, \"recall\": 0.40718105423987777, \"specificity\": 1.0, \"npv\": 0.5012141122696757, \"accuracy\": 0.6284908771743177, \"f1\": 0.5787187839305103, \"f2\": 0.46195181140578956, \"f0_5\": 0.7744841615809358, \"p4\": 0.6200526331144376, \"phi\": 0.4517575573622106}, {\"truth_threshold\": 14.620000000000001, \"match_probability\": 0.9999602877753826, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4789, \"tn\": 7018, \"fp\": 0, \"fn\": 6992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4065019947372889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5934980052627111, \"precision\": 1.0, \"recall\": 0.4065019947372889, \"specificity\": 1.0, \"npv\": 0.5009279086366881, \"accuracy\": 0.6280653226235438, \"f1\": 0.5780325890162945, \"f2\": 0.4612524801109549, \"f0_5\": 0.7739923069463749, \"p4\": 0.6195491514334636, \"phi\": 0.45125180784168845}, {\"truth_threshold\": 14.64, \"match_probability\": 0.9999608344839012, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4782, \"tn\": 7018, \"fp\": 0, \"fn\": 6999, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40590781767252354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5940921823274764, \"precision\": 1.0, \"recall\": 0.40590781767252354, \"specificity\": 1.0, \"npv\": 0.5006777484483128, \"accuracy\": 0.6276929623916165, \"f1\": 0.5774316247056692, \"f2\": 0.4606403883944053, \"f0_5\": 0.7735610987091138, \"p4\": 0.6191081962175969, \"phi\": 0.45080928587358016}, {\"truth_threshold\": 14.66, \"match_probability\": 0.9999613736663076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4777, \"tn\": 7018, \"fp\": 0, \"fn\": 7004, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4054834054834055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5945165945165946, \"precision\": 1.0, \"recall\": 0.4054834054834055, \"specificity\": 1.0, \"npv\": 0.500499215518471, \"accuracy\": 0.6274269907973828, \"f1\": 0.5770020533880903, \"f2\": 0.4602030789387488, \"f0_5\": 0.7732526141992295, \"p4\": 0.6187929937874634, \"phi\": 0.45049320344507143}, {\"truth_threshold\": 14.68, \"match_probability\": 0.9999619054261999, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4765, \"tn\": 7018, \"fp\": 0, \"fn\": 7016, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40446481622952213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5955351837704779, \"precision\": 1.0, \"recall\": 0.40446481622952213, \"specificity\": 1.0, \"npv\": 0.500071255522303, \"accuracy\": 0.6267886589712218, \"f1\": 0.5759700229662759, \"f2\": 0.45915319239145097, \"f0_5\": 0.7725106189812263, \"p4\": 0.618035707447558, \"phi\": 0.44973462004441533}, {\"truth_threshold\": 14.700000000000001, \"match_probability\": 0.9999624298657506, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4763, \"tn\": 7018, \"fp\": 0, \"fn\": 7018, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4042950513538749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5957049486461251, \"precision\": 1.0, \"recall\": 0.4042950513538749, \"specificity\": 1.0, \"npv\": 0.5, \"accuracy\": 0.6266822703335284, \"f1\": 0.5757978723404256, \"f2\": 0.45897816408734365, \"f0_5\": 0.772386728505173, \"p4\": 0.6179093828041384, \"phi\": 0.44960819129208207}, {\"truth_threshold\": 14.72, \"match_probability\": 0.9999629470857259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4755, \"tn\": 7018, \"fp\": 0, \"fn\": 7026, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.403615991851286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5963840081487141, \"precision\": 1.0, \"recall\": 0.403615991851286, \"specificity\": 1.0, \"npv\": 0.4997151808601538, \"accuracy\": 0.6262567157827544, \"f1\": 0.5751088534107403, \"f2\": 0.4582779159197363, \"f0_5\": 0.7718905230349664, \"p4\": 0.6174037679594923, \"phi\": 0.44910248091723537}, {\"truth_threshold\": 14.74, \"match_probability\": 0.9999634571855048, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4753, \"tn\": 7018, \"fp\": 0, \"fn\": 7028, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40344622697563876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5965537730243613, \"precision\": 1.0, \"recall\": 0.40344622697563876, \"specificity\": 1.0, \"npv\": 0.49964402676918696, \"accuracy\": 0.6261503271450609, \"f1\": 0.5749364944961897, \"f2\": 0.45810282013223586, \"f0_5\": 0.7717663105251193, \"p4\": 0.6172772850080631, \"phi\": 0.4489760544070736}, {\"truth_threshold\": 14.76, \"match_probability\": 0.9999639602630992, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4749, \"tn\": 7018, \"fp\": 0, \"fn\": 7032, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4031066972243443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5968933027756557, \"precision\": 1.0, \"recall\": 0.4031066972243443, \"specificity\": 1.0, \"npv\": 0.49950177935943063, \"accuracy\": 0.6259375498696739, \"f1\": 0.5745916515426497, \"f2\": 0.45775258805158753, \"f0_5\": 0.7715176917828248, \"p4\": 0.6170242237748318, \"phi\": 0.4487232025817956}, {\"truth_threshold\": 14.780000000000001, \"match_probability\": 0.9999644564151715, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4743, \"tn\": 7018, \"fp\": 0, \"fn\": 7038, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4025974025974026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5974025974025974, \"precision\": 1.0, \"recall\": 0.4025974025974026, \"specificity\": 1.0, \"npv\": 0.4992885600455322, \"accuracy\": 0.6256183839565934, \"f1\": 0.5740740740740741, \"f2\": 0.45722713864306785, \"f0_5\": 0.7711442786069652, \"p4\": 0.6166443930789846, \"phi\": 0.44834392760572606}, {\"truth_threshold\": 14.8, \"match_probability\": 0.9999649457370537, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4734, \"tn\": 7018, \"fp\": 0, \"fn\": 7047, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40183346065699005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5981665393430099, \"precision\": 1.0, \"recall\": 0.40183346065699005, \"specificity\": 1.0, \"npv\": 0.49896907216494846, \"accuracy\": 0.6251396350869727, \"f1\": 0.5732970027247957, \"f2\": 0.4564387365498091, \"f0_5\": 0.7705830647524172, \"p4\": 0.616074107773766, \"phi\": 0.4477750205503302}, {\"truth_threshold\": 14.82, \"match_probability\": 0.9999654283227661, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4733, \"tn\": 7018, \"fp\": 0, \"fn\": 7048, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40174857821916643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5982514217808336, \"precision\": 1.0, \"recall\": 0.40174857821916643, \"specificity\": 1.0, \"npv\": 0.49893359874875587, \"accuracy\": 0.6250864407681259, \"f1\": 0.5732106091800896, \"f2\": 0.4563511194245714, \"f0_5\": 0.7705206264448279, \"p4\": 0.616010702678355, \"phi\": 0.44771180900562}, {\"truth_threshold\": 14.86, \"match_probability\": 0.9999663736553089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4726, \"tn\": 7018, \"fp\": 0, \"fn\": 7055, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40115440115440115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5988455988455988, \"precision\": 1.0, \"recall\": 0.40115440115440115, \"specificity\": 1.0, \"npv\": 0.49868542599303634, \"accuracy\": 0.6247140805361987, \"f1\": 0.572605561277034, \"f2\": 0.4557377049180328, \"f0_5\": 0.7700831024930748, \"p4\": 0.6155666419725353, \"phi\": 0.4472693298546905}, {\"truth_threshold\": 14.88, \"match_probability\": 0.9999668365837804, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4724, \"tn\": 7018, \"fp\": 0, \"fn\": 7057, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.4009846362787539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5990153637212461, \"precision\": 1.0, \"recall\": 0.4009846362787539, \"specificity\": 1.0, \"npv\": 0.4986145648312611, \"accuracy\": 0.6246076918985053, \"f1\": 0.5724325961829748, \"f2\": 0.4555624132078383, \"f0_5\": 0.7699579489519836, \"p4\": 0.6154396950200659, \"phi\": 0.4471429077176025}, {\"truth_threshold\": 14.9, \"match_probability\": 0.9999672931393985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4721, \"tn\": 7018, \"fp\": 0, \"fn\": 7060, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40072998896528306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5992700110347169, \"precision\": 1.0, \"recall\": 0.40072998896528306, \"specificity\": 1.0, \"npv\": 0.4985083108396079, \"accuracy\": 0.624448108941965, \"f1\": 0.5721730699309174, \"f2\": 0.45529945028450186, \"f0_5\": 0.7697700962008804, \"p4\": 0.6152492140720877, \"phi\": 0.4469532748530409}, {\"truth_threshold\": 14.92, \"match_probability\": 0.9999677434098888, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4717, \"tn\": 7018, \"fp\": 0, \"fn\": 7064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.40039045921398864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5996095407860114, \"precision\": 1.0, \"recall\": 0.40039045921398864, \"specificity\": 1.0, \"npv\": 0.4983667092742508, \"accuracy\": 0.624235331666578, \"f1\": 0.5718268881076494, \"f2\": 0.4549487857101522, \"f0_5\": 0.7695193970439492, \"p4\": 0.6149951263206994, \"phi\": 0.4467004315906597}, {\"truth_threshold\": 14.94, \"match_probability\": 0.9999681874817694, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4711, \"tn\": 7018, \"fp\": 0, \"fn\": 7070, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3998811645870469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6001188354129531, \"precision\": 1.0, \"recall\": 0.3998811645870469, \"specificity\": 1.0, \"npv\": 0.4981544576944918, \"accuracy\": 0.6239161657534975, \"f1\": 0.5713073005093379, \"f2\": 0.45442268737339636, \"f0_5\": 0.7691428571428571, \"p4\": 0.6146137516475135, \"phi\": 0.4463211676439985}, {\"truth_threshold\": 14.96, \"match_probability\": 0.9999686254403675, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4702, \"tn\": 7018, \"fp\": 0, \"fn\": 7079, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3991172226466344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6008827773533656, \"precision\": 1.0, \"recall\": 0.3991172226466344, \"specificity\": 1.0, \"npv\": 0.49783641909626164, \"accuracy\": 0.6234374168838768, \"f1\": 0.5705272098525754, \"f2\": 0.4536333114652877, \"f0_5\": 0.7685769394226682, \"p4\": 0.6140411408939164, \"phi\": 0.4457522730419284}, {\"truth_threshold\": 14.98, \"match_probability\": 0.9999690573698359, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4700, \"tn\": 7018, \"fp\": 0, \"fn\": 7081, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39894745777098717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6010525422290128, \"precision\": 1.0, \"recall\": 0.39894745777098717, \"specificity\": 1.0, \"npv\": 0.49776579899283635, \"accuracy\": 0.6233310282461834, \"f1\": 0.5703537406710758, \"f2\": 0.4534578573633838, \"f0_5\": 0.7684509989862987, \"p4\": 0.6139138043584946, \"phi\": 0.44562585211535505}, {\"truth_threshold\": 15.0, \"match_probability\": 0.9999694833531692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4692, \"tn\": 7018, \"fp\": 0, \"fn\": 7089, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39826839826839827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6017316017316018, \"precision\": 1.0, \"recall\": 0.39826839826839827, \"specificity\": 1.0, \"npv\": 0.4974835188204437, \"accuracy\": 0.6229054736954094, \"f1\": 0.5696594427244582, \"f2\": 0.452755905511811, \"f0_5\": 0.7679465776293823, \"p4\": 0.6134041309033008, \"phi\": 0.4451201682754273}, {\"truth_threshold\": 15.02, \"match_probability\": 0.9999699034722195, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4678, \"tn\": 7018, \"fp\": 0, \"fn\": 7103, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39708004413886766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6029199558611323, \"precision\": 1.0, \"recall\": 0.39708004413886766, \"specificity\": 1.0, \"npv\": 0.49699029813752565, \"accuracy\": 0.6221607532315548, \"f1\": 0.5684427972537821, \"f2\": 0.45152696807073084, \"f0_5\": 0.7670612927557144, \"p4\": 0.6125109366944869, \"phi\": 0.4442352186860444}, {\"truth_threshold\": 15.040000000000001, \"match_probability\": 0.9999703178077124, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4670, \"tn\": 7018, \"fp\": 0, \"fn\": 7111, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39640098463627876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6035990153637213, \"precision\": 1.0, \"recall\": 0.39640098463627876, \"specificity\": 1.0, \"npv\": 0.4967088965956543, \"accuracy\": 0.6217351986807809, \"f1\": 0.5677466415415476, \"f2\": 0.4508244198169672, \"f0_5\": 0.7665539542365648, \"p4\": 0.6119998128188536, \"phi\": 0.4437295298806661}, {\"truth_threshold\": 15.06, \"match_probability\": 0.9999707264392624, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4668, \"tn\": 7018, \"fp\": 0, \"fn\": 7113, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3962312197606315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6037687802393685, \"precision\": 1.0, \"recall\": 0.3962312197606315, \"specificity\": 1.0, \"npv\": 0.49663859599462173, \"accuracy\": 0.6216288100430873, \"f1\": 0.5675724968083166, \"f2\": 0.45064874884151995, \"f0_5\": 0.7664269530095557, \"p4\": 0.6118719488547146, \"phi\": 0.4436031071477706}, {\"truth_threshold\": 15.08, \"match_probability\": 0.9999711294453882, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4663, \"tn\": 7018, \"fp\": 0, \"fn\": 7118, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39580680757151343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6041931924284866, \"precision\": 1.0, \"recall\": 0.39580680757151343, \"specificity\": 1.0, \"npv\": 0.49646293152235427, \"accuracy\": 0.6213628384488536, \"f1\": 0.5671369496472878, \"f2\": 0.4502095120397011, \"f0_5\": 0.766109157822101, \"p4\": 0.6115521433067744, \"phi\": 0.4432870492169357}, {\"truth_threshold\": 15.1, \"match_probability\": 0.9999715269035279, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4657, \"tn\": 7018, \"fp\": 0, \"fn\": 7124, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39529751294457177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6047024870554283, \"precision\": 1.0, \"recall\": 0.39529751294457177, \"specificity\": 1.0, \"npv\": 0.49625229811907795, \"accuracy\": 0.6210436725357732, \"f1\": 0.5666139433021049, \"f2\": 0.44968231590737917, \"f0_5\": 0.7657272518004539, \"p4\": 0.6111681013694349, \"phi\": 0.44290777735268966}, {\"truth_threshold\": 15.120000000000001, \"match_probability\": 0.9999719188900533, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4650, \"tn\": 7018, \"fp\": 0, \"fn\": 7131, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3947033358798065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6052966641201936, \"precision\": 1.0, \"recall\": 0.3947033358798065, \"specificity\": 1.0, \"npv\": 0.4960067849317973, \"accuracy\": 0.620671312303846, \"f1\": 0.5660032864706956, \"f2\": 0.4490670993162591, \"f0_5\": 0.7652809321615484, \"p4\": 0.6107196716478562, \"phi\": 0.44246528974779264}, {\"truth_threshold\": 15.14, \"match_probability\": 0.9999723054802854, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4645, \"tn\": 7018, \"fp\": 0, \"fn\": 7136, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3942789236906884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6057210763093116, \"precision\": 1.0, \"recall\": 0.3942789236906884, \"specificity\": 1.0, \"npv\": 0.49583156704818426, \"accuracy\": 0.6204053407096122, \"f1\": 0.5655667843662486, \"f2\": 0.44862755703220075, \"f0_5\": 0.7649616284048615, \"p4\": 0.6103991128088503, \"phi\": 0.44214922434357556}, {\"truth_threshold\": 15.16, \"match_probability\": 0.9999726867485083, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4639, \"tn\": 7018, \"fp\": 0, \"fn\": 7142, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3937696290637467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6062303709362533, \"precision\": 1.0, \"recall\": 0.3937696290637467, \"specificity\": 1.0, \"npv\": 0.4956214689265537, \"accuracy\": 0.6200861747965317, \"f1\": 0.5650426309378807, \"f2\": 0.4480999942043545, \"f0_5\": 0.7645779081649471, \"p4\": 0.6100141642108039, \"phi\": 0.44176994236280753}, {\"truth_threshold\": 15.18, \"match_probability\": 0.9999730627679836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4627, \"tn\": 7018, \"fp\": 0, \"fn\": 7154, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3927510398098633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6072489601901366, \"precision\": 1.0, \"recall\": 0.3927510398098633, \"specificity\": 1.0, \"npv\": 0.49520180637877503, \"accuracy\": 0.6194478429703708, \"f1\": 0.5639931740614335, \"f2\": 0.4470445015555255, \"f0_5\": 0.763808643401895, \"p4\": 0.6092433534179678, \"phi\": 0.4410113653535321}, {\"truth_threshold\": 15.200000000000001, \"match_probability\": 0.9999734336109646, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4619, \"tn\": 7018, \"fp\": 0, \"fn\": 7162, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3920719803072744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6079280196927256, \"precision\": 1.0, \"recall\": 0.3920719803072744, \"specificity\": 1.0, \"npv\": 0.4949224259520451, \"accuracy\": 0.6190222884195968, \"f1\": 0.5632926829268292, \"f2\": 0.4463405678062733, \"f0_5\": 0.7632944442608322, \"p4\": 0.6087287996162336, \"phi\": 0.4405056363334058}, {\"truth_threshold\": 15.22, \"match_probability\": 0.9999737993487102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4608, \"tn\": 7018, \"fp\": 0, \"fn\": 7173, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39113827349121466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6088617265087853, \"precision\": 1.0, \"recall\": 0.39113827349121466, \"specificity\": 1.0, \"npv\": 0.4945387921922345, \"accuracy\": 0.6184371509122826, \"f1\": 0.5623283909939594, \"f2\": 0.4453723034098817, \"f0_5\": 0.7625856419422103, \"p4\": 0.6080203949559846, \"phi\": 0.43981024243700967}, {\"truth_threshold\": 15.24, \"match_probability\": 0.9999741600514982, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4602, \"tn\": 7018, \"fp\": 0, \"fn\": 7179, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.390628978864273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.609371021135727, \"precision\": 1.0, \"recall\": 0.390628978864273, \"specificity\": 1.0, \"npv\": 0.4943297879833768, \"accuracy\": 0.6181179849992021, \"f1\": 0.5618018677897821, \"f2\": 0.4448439856165178, \"f0_5\": 0.7621981516446388, \"p4\": 0.6076335545242082, \"phi\": 0.43943092779427695}, {\"truth_threshold\": 15.26, \"match_probability\": 0.9999745157886392, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4599, \"tn\": 7018, \"fp\": 0, \"fn\": 7182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.39037433155080214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6096256684491979, \"precision\": 1.0, \"recall\": 0.39037433155080214, \"specificity\": 1.0, \"npv\": 0.49422535211267604, \"accuracy\": 0.6179584020426618, \"f1\": 0.5615384615384615, \"f2\": 0.4445797807551766, \"f0_5\": 0.7620041753653445, \"p4\": 0.6074400179748957, \"phi\": 0.4392412679455856}, {\"truth_threshold\": 15.280000000000001, \"match_probability\": 0.9999748666284898, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4598, \"tn\": 7018, \"fp\": 0, \"fn\": 7183, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3902894491129785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6097105508870215, \"precision\": 1.0, \"recall\": 0.3902894491129785, \"specificity\": 1.0, \"npv\": 0.4941905499612703, \"accuracy\": 0.6179052077238151, \"f1\": 0.5614506380120886, \"f2\": 0.44449170565716717, \"f0_5\": 0.7619394823186293, \"p4\": 0.6073754885259044, \"phi\": 0.43917804760851165}, {\"truth_threshold\": 15.3, \"match_probability\": 0.9999752126384654, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4590, \"tn\": 7018, \"fp\": 0, \"fn\": 7191, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38961038961038963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6103896103896104, \"precision\": 1.0, \"recall\": 0.38961038961038963, \"specificity\": 1.0, \"npv\": 0.4939123090998663, \"accuracy\": 0.6174796531730411, \"f1\": 0.5607476635514018, \"f2\": 0.4437869822485207, \"f0_5\": 0.7614213197969543, \"p4\": 0.6068589414701355, \"phi\": 0.4386722776535646}, {\"truth_threshold\": 15.32, \"match_probability\": 0.9999755538850542, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4586, \"tn\": 7018, \"fp\": 0, \"fn\": 7195, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38927085985909515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6107291401409048, \"precision\": 1.0, \"recall\": 0.38927085985909515, \"specificity\": 1.0, \"npv\": 0.4937733061281925, \"accuracy\": 0.6172668758976542, \"f1\": 0.5603959186167288, \"f2\": 0.4434345387739315, \"f0_5\": 0.7611618257261411, \"p4\": 0.6066004598090405, \"phi\": 0.4384193876324241}, {\"truth_threshold\": 15.34, \"match_probability\": 0.9999758904338284, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4581, \"tn\": 7018, \"fp\": 0, \"fn\": 7200, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38884644766997706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6111535523300229, \"precision\": 1.0, \"recall\": 0.38884644766997706, \"specificity\": 1.0, \"npv\": 0.49359966239977493, \"accuracy\": 0.6170009043034204, \"f1\": 0.55995599559956, \"f2\": 0.44299390774586594, \"f0_5\": 0.7608370702541106, \"p4\": 0.6062771620047788, \"phi\": 0.4381032701261797}, {\"truth_threshold\": 15.36, \"match_probability\": 0.999976222349458, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4569, \"tn\": 7018, \"fp\": 0, \"fn\": 7212, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3878278584160937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6121721415839063, \"precision\": 1.0, \"recall\": 0.3878278584160937, \"specificity\": 1.0, \"npv\": 0.493183415319747, \"accuracy\": 0.6163625724772595, \"f1\": 0.5588990825688074, \"f2\": 0.44193604549939064, \"f0_5\": 0.7600558938017766, \"p4\": 0.6055003565844282, \"phi\": 0.43734456412512135}, {\"truth_threshold\": 15.38, \"match_probability\": 0.999976549695723, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4566, \"tn\": 7018, \"fp\": 0, \"fn\": 7215, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3875732111026229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6124267888973771, \"precision\": 1.0, \"recall\": 0.3875732111026229, \"specificity\": 1.0, \"npv\": 0.49307946321927915, \"accuracy\": 0.6162029895207192, \"f1\": 0.5586346118553863, \"f2\": 0.4416715031921068, \"f0_5\": 0.7598602096854717, \"p4\": 0.6053059580389653, \"phi\": 0.4371548820368516}, {\"truth_threshold\": 15.4, \"match_probability\": 0.999976872535525, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4561, \"tn\": 7018, \"fp\": 0, \"fn\": 7220, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3871487989135048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6128512010864952, \"precision\": 1.0, \"recall\": 0.3871487989135048, \"specificity\": 1.0, \"npv\": 0.4929063070655991, \"accuracy\": 0.6159370179264855, \"f1\": 0.5581936115530535, \"f2\": 0.44123053110186705, \"f0_5\": 0.759533721898418, \"p4\": 0.6049817845454569, \"phi\": 0.43683873999147316}, {\"truth_threshold\": 15.42, \"match_probability\": 0.9999771909309003, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4560, \"tn\": 7018, \"fp\": 0, \"fn\": 7221, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38706391647568117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6129360835243188, \"precision\": 1.0, \"recall\": 0.38706391647568117, \"specificity\": 1.0, \"npv\": 0.49287169042769857, \"accuracy\": 0.6158838236076387, \"f1\": 0.5581053791077657, \"f2\": 0.4411423264453216, \"f0_5\": 0.7594683721395024, \"p4\": 0.6049169234159454, \"phi\": 0.43677551077977633}, {\"truth_threshold\": 15.44, \"match_probability\": 0.999977504943031, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4552, \"tn\": 7018, \"fp\": 0, \"fn\": 7229, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38638485697309227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6136151430269078, \"precision\": 1.0, \"recall\": 0.38638485697309227, \"specificity\": 1.0, \"npv\": 0.4925949322664421, \"accuracy\": 0.6154582690568647, \"f1\": 0.557399130594502, \"f2\": 0.44043656629770106, \"f0_5\": 0.7589449464803761, \"p4\": 0.6043977164027835, \"phi\": 0.4362696671205085}, {\"truth_threshold\": 15.46, \"match_probability\": 0.999977814632257, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4549, \"tn\": 7018, \"fp\": 0, \"fn\": 7232, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3861302096596214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6138697903403786, \"precision\": 1.0, \"recall\": 0.3861302096596214, \"specificity\": 1.0, \"npv\": 0.4924912280701754, \"accuracy\": 0.6152986861003245, \"f1\": 0.5571341090018371, \"f2\": 0.44017184990227004, \"f0_5\": 0.7587483737532108, \"p4\": 0.6042028677154393, \"phi\": 0.4360799710491887}, {\"truth_threshold\": 15.48, \"match_probability\": 0.9999781200580878, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4540, \"tn\": 7018, \"fp\": 0, \"fn\": 7241, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3853662677192089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6146337322807911, \"precision\": 1.0, \"recall\": 0.3853662677192089, \"specificity\": 1.0, \"npv\": 0.4921803773055614, \"accuracy\": 0.6148199372307037, \"f1\": 0.5563384596532075, \"f2\": 0.4393775162589037, \"f0_5\": 0.7581577101633212, \"p4\": 0.6036178419081956, \"phi\": 0.43551086673799105}, {\"truth_threshold\": 15.5, \"match_probability\": 0.9999784212792137, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4534, \"tn\": 7018, \"fp\": 0, \"fn\": 7247, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3848569730922672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6151430269077328, \"precision\": 1.0, \"recall\": 0.3848569730922672, \"specificity\": 1.0, \"npv\": 0.4919733613739923, \"accuracy\": 0.6145007713176233, \"f1\": 0.5558075390744713, \"f2\": 0.43884780672887064, \"f0_5\": 0.7577631447003376, \"p4\": 0.6032274236066282, \"phi\": 0.43513144990959085}, {\"truth_threshold\": 15.52, \"match_probability\": 0.999978718353517, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4531, \"tn\": 7018, \"fp\": 0, \"fn\": 7250, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3846023257787964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6153976742212036, \"precision\": 1.0, \"recall\": 0.3846023257787964, \"specificity\": 1.0, \"npv\": 0.491869918699187, \"accuracy\": 0.6143411883610831, \"f1\": 0.5555419323197646, \"f2\": 0.43858290581744264, \"f0_5\": 0.7575656244775121, \"p4\": 0.6030320937329599, \"phi\": 0.4349417371468675}, {\"truth_threshold\": 15.540000000000001, \"match_probability\": 0.9999790113380835, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4528, \"tn\": 7018, \"fp\": 0, \"fn\": 7253, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3843476784653255, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6156523215346745, \"precision\": 1.0, \"recall\": 0.3843476784653255, \"specificity\": 1.0, \"npv\": 0.49176651951510053, \"accuracy\": 0.6141816054045428, \"f1\": 0.5552762278496536, \"f2\": 0.43831797413459306, \"f0_5\": 0.7573679456729, \"p4\": 0.6028366832018078, \"phi\": 0.43475202141289937}, {\"truth_threshold\": 15.56, \"match_probability\": 0.9999793002892131, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4515, \"tn\": 7018, \"fp\": 0, \"fn\": 7266, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38324420677361853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6167557932263814, \"precision\": 1.0, \"recall\": 0.38324420677361853, \"specificity\": 1.0, \"npv\": 0.491318958274993, \"accuracy\": 0.6134900792595351, \"f1\": 0.5541237113402062, \"f2\": 0.4371695811305409, \"f0_5\": 0.7565095003518649, \"p4\": 0.6019889689681662, \"phi\": 0.43392988424046147}, {\"truth_threshold\": 15.58, \"match_probability\": 0.9999795852624306, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4512, \"tn\": 7018, \"fp\": 0, \"fn\": 7269, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3829895594601477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6170104405398523, \"precision\": 1.0, \"recall\": 0.3829895594601477, \"specificity\": 1.0, \"npv\": 0.4912157905788479, \"accuracy\": 0.6133304963029949, \"f1\": 0.5538574848094273, \"f2\": 0.4369044852428538, \"f0_5\": 0.7563109725434979, \"p4\": 0.6017931260299865, \"phi\": 0.43374015174256253}, {\"truth_threshold\": 15.6, \"match_probability\": 0.9999798663124968, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4506, \"tn\": 7018, \"fp\": 0, \"fn\": 7275, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.382480264833206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.617519735166794, \"precision\": 1.0, \"recall\": 0.382480264833206, \"specificity\": 1.0, \"npv\": 0.4910095851115931, \"accuracy\": 0.6130113303899144, \"f1\": 0.5533247375207221, \"f2\": 0.4363742010459035, \"f0_5\": 0.7559134373427278, \"p4\": 0.6014011955296891, \"phi\": 0.43336067674527734}, {\"truth_threshold\": 15.620000000000001, \"match_probability\": 0.9999801434934182, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4502, \"tn\": 7018, \"fp\": 0, \"fn\": 7279, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38214073508191154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6178592649180884, \"precision\": 1.0, \"recall\": 0.38214073508191154, \"specificity\": 1.0, \"npv\": 0.4908722109533469, \"accuracy\": 0.6127985531145274, \"f1\": 0.5529693545415464, \"f2\": 0.4360206097702708, \"f0_5\": 0.7556480580079895, \"p4\": 0.6011397268981287, \"phi\": 0.4331076858299736}, {\"truth_threshold\": 15.64, \"match_probability\": 0.9999804168584587, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4495, \"tn\": 7018, \"fp\": 0, \"fn\": 7286, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38154655801714626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6184534419828538, \"precision\": 1.0, \"recall\": 0.38154655801714626, \"specificity\": 1.0, \"npv\": 0.49063199105145416, \"accuracy\": 0.6124261928826001, \"f1\": 0.5523470140083558, \"f2\": 0.4354016931749937, \"f0_5\": 0.7551829575619099, \"p4\": 0.6006818060709841, \"phi\": 0.43266493668748063}, {\"truth_threshold\": 15.66, \"match_probability\": 0.9999806864601481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4486, \"tn\": 7018, \"fp\": 0, \"fn\": 7295, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38078261607673375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6192173839232663, \"precision\": 1.0, \"recall\": 0.38078261607673375, \"specificity\": 1.0, \"npv\": 0.4903234821490952, \"accuracy\": 0.6119474440129794, \"f1\": 0.5515460748755149, \"f2\": 0.4346056965704321, \"f0_5\": 0.7545836837678722, \"p4\": 0.6000923924380624, \"phi\": 0.4320956586875019}, {\"truth_threshold\": 15.68, \"match_probability\": 0.9999809523502939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4480, \"tn\": 7018, \"fp\": 0, \"fn\": 7301, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.38027332144979203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6197266785502079, \"precision\": 1.0, \"recall\": 0.38027332144979203, \"specificity\": 1.0, \"npv\": 0.49011802500174595, \"accuracy\": 0.611628278099899, \"f1\": 0.5510116229014206, \"f2\": 0.43407487791644056, \"f0_5\": 0.7541833608296017, \"p4\": 0.599699036940909, \"phi\": 0.4317161211604521}, {\"truth_threshold\": 15.700000000000001, \"match_probability\": 0.9999812145799899, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4478, \"tn\": 7018, \"fp\": 0, \"fn\": 7303, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3801035565741448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6198964434258551, \"precision\": 1.0, \"recall\": 0.3801035565741448, \"specificity\": 1.0, \"npv\": 0.4900495775434676, \"accuracy\": 0.6115218894622054, \"f1\": 0.5508333845869979, \"f2\": 0.43389791093368474, \"f0_5\": 0.7540497760414913, \"p4\": 0.5995678447791305, \"phi\": 0.4315896052060675}, {\"truth_threshold\": 15.72, \"match_probability\": 0.9999814731996269, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4467, \"tn\": 7018, \"fp\": 0, \"fn\": 7314, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37916984975808504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6208301502419149, \"precision\": 1.0, \"recall\": 0.37916984975808504, \"specificity\": 1.0, \"npv\": 0.4896734579960927, \"accuracy\": 0.6109367519548912, \"f1\": 0.5498522895125554, \"f2\": 0.43292434726987267, \"f0_5\": 0.7533137711221289, \"p4\": 0.5988456272509608, \"phi\": 0.4308937357387555}, {\"truth_threshold\": 15.74, \"match_probability\": 0.999981728258902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4457, \"tn\": 7018, \"fp\": 0, \"fn\": 7324, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3783210253798489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6216789746201511, \"precision\": 1.0, \"recall\": 0.3783210253798489, \"specificity\": 1.0, \"npv\": 0.4893320317947288, \"accuracy\": 0.6104048087664238, \"f1\": 0.5489592314324424, \"f2\": 0.4320389290630271, \"f0_5\": 0.752642777533858, \"p4\": 0.5981880916277775, \"phi\": 0.43026107890417725}, {\"truth_threshold\": 15.76, \"match_probability\": 0.9999819798068281, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4447, \"tn\": 7018, \"fp\": 0, \"fn\": 7334, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3774722010016128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6225277989983873, \"precision\": 1.0, \"recall\": 0.3774722010016128, \"specificity\": 1.0, \"npv\": 0.48899108138238573, \"accuracy\": 0.6098728655779563, \"f1\": 0.548065072713828, \"f2\": 0.4311531674778461, \"f0_5\": 0.7519699685481417, \"p4\": 0.5975296229196165, \"phi\": 0.4296283740159254}, {\"truth_threshold\": 15.780000000000001, \"match_probability\": 0.9999822278917435, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4443, \"tn\": 7018, \"fp\": 0, \"fn\": 7338, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3771326712503183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6228673287496816, \"precision\": 1.0, \"recall\": 0.3771326712503183, \"specificity\": 1.0, \"npv\": 0.48885483421565895, \"accuracy\": 0.6096600883025692, \"f1\": 0.547707100591716, \"f2\": 0.4307987666530921, \"f0_5\": 0.7517003349913715, \"p4\": 0.5972659730303761, \"phi\": 0.4293752781441696}, {\"truth_threshold\": 15.8, \"match_probability\": 0.9999824725613211, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4440, \"tn\": 7018, \"fp\": 0, \"fn\": 7341, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37687802393684744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6231219760631526, \"precision\": 1.0, \"recall\": 0.37687802393684744, \"specificity\": 1.0, \"npv\": 0.48875269865589527, \"accuracy\": 0.6095005053460291, \"f1\": 0.547438505640836, \"f2\": 0.4305329299511287, \"f0_5\": 0.7514979181476592, \"p4\": 0.5970681369066574, \"phi\": 0.42918545089883386}, {\"truth_threshold\": 15.82, \"match_probability\": 0.9999827138625776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4435, \"tn\": 7018, \"fp\": 0, \"fn\": 7346, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3764536117477294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6235463882522706, \"precision\": 1.0, \"recall\": 0.3764536117477294, \"specificity\": 1.0, \"npv\": 0.48858256752993595, \"accuracy\": 0.6092345337517953, \"f1\": 0.5469906265416872, \"f2\": 0.4300898000349115, \"f0_5\": 0.7511601910504386, \"p4\": 0.5967382216101151, \"phi\": 0.4288690618168012}, {\"truth_threshold\": 15.84, \"match_probability\": 0.9999829518418826, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4426, \"tn\": 7018, \"fp\": 0, \"fn\": 7355, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3756896698073169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6243103301926831, \"precision\": 1.0, \"recall\": 0.3756896698073169, \"specificity\": 1.0, \"npv\": 0.48827662979197106, \"accuracy\": 0.6087557848821746, \"f1\": 0.5461837477633121, \"f2\": 0.42929194956353056, \"f0_5\": 0.7505511276920468, \"p4\": 0.5961437787033526, \"phi\": 0.42829952815894523}, {\"truth_threshold\": 15.860000000000001, \"match_probability\": 0.999983186544967, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4424, \"tn\": 7018, \"fp\": 0, \"fn\": 7357, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37551990493166965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6244800950683304, \"precision\": 1.0, \"recall\": 0.37551990493166965, \"specificity\": 1.0, \"npv\": 0.4882086956521739, \"accuracy\": 0.6086493962444811, \"f1\": 0.5460043196544276, \"f2\": 0.42911461162411735, \"f0_5\": 0.7504155782474472, \"p4\": 0.5960115760226931, \"phi\": 0.4281729591860266}, {\"truth_threshold\": 15.88, \"match_probability\": 0.9999834180169326, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4414, \"tn\": 7018, \"fp\": 0, \"fn\": 7367, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3746710805534335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6253289194465665, \"precision\": 1.0, \"recall\": 0.3746710805534335, \"specificity\": 1.0, \"npv\": 0.4878693083072645, \"accuracy\": 0.6081174530560136, \"f1\": 0.5451065143562828, \"f2\": 0.42822771547207883, \"f0_5\": 0.749736725889187, \"p4\": 0.5953499917685805, \"phi\": 0.4275400810594709}, {\"truth_threshold\": 15.9, \"match_probability\": 0.9999836463022602, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4406, \"tn\": 7018, \"fp\": 0, \"fn\": 7375, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37399202105084456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6260079789491554, \"precision\": 1.0, \"recall\": 0.37399202105084456, \"specificity\": 1.0, \"npv\": 0.4875981379837421, \"accuracy\": 0.6076918985052396, \"f1\": 0.5443874714276888, \"f2\": 0.42751795070832527, \"f0_5\": 0.7491923142322734, \"p4\": 0.5948200368465038, \"phi\": 0.4270337376427866}, {\"truth_threshold\": 15.92, \"match_probability\": 0.9999838714448183, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4404, \"tn\": 7018, \"fp\": 0, \"fn\": 7377, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3738222561751974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6261777438248026, \"precision\": 1.0, \"recall\": 0.3738222561751974, \"specificity\": 1.0, \"npv\": 0.48753039249739494, \"accuracy\": 0.6075855098675461, \"f1\": 0.5442075996292863, \"f2\": 0.4273404750815091, \"f0_5\": 0.7490560261251148, \"p4\": 0.5946874522792629, \"phi\": 0.4269071459666091}, {\"truth_threshold\": 15.94, \"match_probability\": 0.9999840934878717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4389, \"tn\": 7018, \"fp\": 0, \"fn\": 7392, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37254901960784315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6274509803921569, \"precision\": 1.0, \"recall\": 0.37254901960784315, \"specificity\": 1.0, \"npv\": 0.4870229007633588, \"accuracy\": 0.6067875950848449, \"f1\": 0.5428571428571428, \"f2\": 0.4260089686098655, \"f0_5\": 0.7480314960629921, \"p4\": 0.5936918405328632, \"phi\": 0.4259576319376813}, {\"truth_threshold\": 15.96, \"match_probability\": 0.9999843124740891, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4385, \"tn\": 7018, \"fp\": 0, \"fn\": 7396, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37220948985654867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6277905101434513, \"precision\": 1.0, \"recall\": 0.37220948985654867, \"specificity\": 1.0, \"npv\": 0.48688774802275564, \"accuracy\": 0.606574817809458, \"f1\": 0.5424965977978473, \"f2\": 0.4256537692442097, \"f0_5\": 0.7477575798915453, \"p4\": 0.5934259768251723, \"phi\": 0.42570440485030653}, {\"truth_threshold\": 15.98, \"match_probability\": 0.9999845284455526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4381, \"tn\": 7018, \"fp\": 0, \"fn\": 7400, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37186996010525425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6281300398947458, \"precision\": 1.0, \"recall\": 0.37186996010525425, \"specificity\": 1.0, \"npv\": 0.4867526702732695, \"accuracy\": 0.606362040534071, \"f1\": 0.542135874272986, \"f2\": 0.42529851470730995, \"f0_5\": 0.7474833646135471, \"p4\": 0.593159957840806, \"phi\": 0.42545116767456015}, {\"truth_threshold\": 16.0, \"match_probability\": 0.9999847414437646, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4377, \"tn\": 7018, \"fp\": 0, \"fn\": 7404, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3715304303539598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6284695696460403, \"precision\": 1.0, \"recall\": 0.3715304303539598, \"specificity\": 1.0, \"npv\": 0.4866176674525031, \"accuracy\": 0.606149263258684, \"f1\": 0.5417749721500186, \"f2\": 0.42494320498631094, \"f0_5\": 0.7472088497388097, \"p4\": 0.5928937832401282, \"phi\": 0.4251979202753331}, {\"truth_threshold\": 16.02, \"match_probability\": 0.999984951509656, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4371, \"tn\": 7018, \"fp\": 0, \"fn\": 7410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.37102113572701806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6289788642729819, \"precision\": 1.0, \"recall\": 0.37102113572701806, \"specificity\": 1.0, \"npv\": 0.48641530357637924, \"accuracy\": 0.6058300973456034, \"f1\": 0.5412332838038633, \"f2\": 0.42441013690649576, \"f0_5\": 0.7467965146078934, \"p4\": 0.5924942288136642, \"phi\": 0.4248180297114407}, {\"truth_threshold\": 16.04, \"match_probability\": 0.9999851586835948, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4361, \"tn\": 7018, \"fp\": 0, \"fn\": 7420, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3701723113487819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6298276886512181, \"precision\": 1.0, \"recall\": 0.3701723113487819, \"specificity\": 1.0, \"npv\": 0.4860784042111096, \"accuracy\": 0.6052981541571361, \"f1\": 0.5403295750216826, \"f2\": 0.42352141400407883, \"f0_5\": 0.7461077844311377, \"p4\": 0.5918275218543816, \"phi\": 0.4241848257346719}, {\"truth_threshold\": 16.06, \"match_probability\": 0.9999853630053928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4355, \"tn\": 7018, \"fp\": 0, \"fn\": 7426, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36966301672184027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6303369832781598, \"precision\": 1.0, \"recall\": 0.36966301672184027, \"specificity\": 1.0, \"npv\": 0.48587648850733867, \"accuracy\": 0.6049789882440555, \"f1\": 0.539786812097174, \"f2\": 0.4229880145301968, \"f0_5\": 0.7456936406287455, \"p4\": 0.5914270260434817, \"phi\": 0.42380487077880236}, {\"truth_threshold\": 16.080000000000002, \"match_probability\": 0.9999855645143139, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4348, \"tn\": 7018, \"fp\": 0, \"fn\": 7433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36906883965707493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6309311603429251, \"precision\": 1.0, \"recall\": 0.36906883965707493, \"specificity\": 1.0, \"npv\": 0.48564113210158466, \"accuracy\": 0.6046066280121283, \"f1\": 0.5391530783061567, \"f2\": 0.422365557973267, \"f0_5\": 0.7452096116271896, \"p4\": 0.5909593319827477, \"phi\": 0.4233615583806354}, {\"truth_threshold\": 16.1, \"match_probability\": 0.9999857632490817, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4346, \"tn\": 7018, \"fp\": 0, \"fn\": 7435, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36889907478142775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6311009252185723, \"precision\": 1.0, \"recall\": 0.36889907478142775, \"specificity\": 1.0, \"npv\": 0.4855739292880371, \"accuracy\": 0.6045002393744348, \"f1\": 0.538971910460718, \"f2\": 0.4221876821449388, \"f0_5\": 0.7450711469226813, \"p4\": 0.5908256160623402, \"phi\": 0.4232348913456206}, {\"truth_threshold\": 16.12, \"match_probability\": 0.9999859592478867, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4342, \"tn\": 7018, \"fp\": 0, \"fn\": 7439, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3685595450301333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6314404549698668, \"precision\": 1.0, \"recall\": 0.3685595450301333, \"specificity\": 1.0, \"npv\": 0.4854395794424846, \"accuracy\": 0.6042874620990478, \"f1\": 0.538609439930534, \"f2\": 0.4218318890141064, \"f0_5\": 0.7447939895022128, \"p4\": 0.5905580652120677, \"phi\": 0.42298154869797966}, {\"truth_threshold\": 16.14, \"match_probability\": 0.9999861525483934, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4337, \"tn\": 7018, \"fp\": 0, \"fn\": 7444, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3681351328410152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6318648671589848, \"precision\": 1.0, \"recall\": 0.3681351328410152, \"specificity\": 1.0, \"npv\": 0.4852717466463836, \"accuracy\": 0.6040214905048141, \"f1\": 0.5381560987715598, \"f2\": 0.42138706981986357, \"f0_5\": 0.7444471145593738, \"p4\": 0.5902234030586099, \"phi\": 0.4226648541287268}, {\"truth_threshold\": 16.16, \"match_probability\": 0.9999863431877482, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4327, \"tn\": 7018, \"fp\": 0, \"fn\": 7454, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36728630846277904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6327136915372209, \"precision\": 1.0, \"recall\": 0.36728630846277904, \"specificity\": 1.0, \"npv\": 0.4849364289662797, \"accuracy\": 0.6034895473163466, \"f1\": 0.5372485721380681, \"f2\": 0.4204971720666265, \"f0_5\": 0.7437519337206504, \"p4\": 0.5895533308631162, \"phi\": 0.42203140977200687}, {\"truth_threshold\": 16.18, \"match_probability\": 0.9999865312025857, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4317, \"tn\": 7018, \"fp\": 0, \"fn\": 7464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3664374840845429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6335625159154571, \"precision\": 1.0, \"recall\": 0.3664374840845429, \"specificity\": 1.0, \"npv\": 0.4846015743681812, \"accuracy\": 0.6029576041278791, \"f1\": 0.5363399180022363, \"f2\": 0.41960692832565466, \"f0_5\": 0.7430548383765362, \"p4\": 0.588882256926125, \"phi\": 0.42139788999814043}, {\"truth_threshold\": 16.2, \"match_probability\": 0.9999867166290367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4312, \"tn\": 7018, \"fp\": 0, \"fn\": 7469, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3660130718954248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6339869281045751, \"precision\": 1.0, \"recall\": 0.3660130718954248, \"specificity\": 1.0, \"npv\": 0.4844343204252088, \"accuracy\": 0.6026916325336454, \"f1\": 0.5358851674641149, \"f2\": 0.41916167664670656, \"f0_5\": 0.7427055702917772, \"p4\": 0.5885463425883981, \"phi\": 0.42108110115558883}, {\"truth_threshold\": 16.22, \"match_probability\": 0.9999868995027343, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4303, \"tn\": 7018, \"fp\": 0, \"fn\": 7478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3652491299550123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6347508700449876, \"precision\": 1.0, \"recall\": 0.3652491299550123, \"specificity\": 1.0, \"npv\": 0.4841335540838852, \"accuracy\": 0.6022128836640247, \"f1\": 0.5350659040039791, \"f2\": 0.4183600054446108, \"f0_5\": 0.7420756734384162, \"p4\": 0.5879410600187428, \"phi\": 0.42051083150278895}, {\"truth_threshold\": 16.240000000000002, \"match_probability\": 0.9999870798588212, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4296, \"tn\": 7018, \"fp\": 0, \"fn\": 7485, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.364654952890247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.635345047109753, \"precision\": 1.0, \"recall\": 0.364654952890247, \"specificity\": 1.0, \"npv\": 0.4838998827828725, \"accuracy\": 0.6018405234320975, \"f1\": 0.5344280649374883, \"f2\": 0.4177362893815636, \"f0_5\": 0.7415846711548421, \"p4\": 0.5874697165033012, \"phi\": 0.42006724337870527}, {\"truth_threshold\": 16.26, \"match_probability\": 0.9999872577319563, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4292, \"tn\": 7018, \"fp\": 0, \"fn\": 7489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36431542313895254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6356845768610474, \"precision\": 1.0, \"recall\": 0.36431542313895254, \"specificity\": 1.0, \"npv\": 0.48376645757220654, \"accuracy\": 0.6016277461567104, \"f1\": 0.5340633360293661, \"f2\": 0.4173798039520772, \"f0_5\": 0.7413036719748524, \"p4\": 0.5872001533206904, \"phi\": 0.41981374642911656}, {\"truth_threshold\": 16.28, \"match_probability\": 0.9999874331563213, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4289, \"tn\": 7018, \"fp\": 0, \"fn\": 7492, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3640607758254817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6359392241745183, \"precision\": 1.0, \"recall\": 0.3640607758254817, \"specificity\": 1.0, \"npv\": 0.48366643694004136, \"accuracy\": 0.6014681632001703, \"f1\": 0.533789670192906, \"f2\": 0.41711240347771966, \"f0_5\": 0.7410927186646854, \"p4\": 0.5869978737363566, \"phi\": 0.41962361500890044}, {\"truth_threshold\": 16.3, \"match_probability\": 0.9999876061656275, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4284, \"tn\": 7018, \"fp\": 0, \"fn\": 7497, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36363636363636365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6363636363636364, \"precision\": 1.0, \"recall\": 0.36363636363636365, \"specificity\": 1.0, \"npv\": 0.48349982776438166, \"accuracy\": 0.6012021916059365, \"f1\": 0.5333333333333333, \"f2\": 0.4166666666666667, \"f0_5\": 0.7407407407407407, \"p4\": 0.5866605364625239, \"phi\": 0.41930671254708995}, {\"truth_threshold\": 16.32, \"match_probability\": 0.9999877767931221, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4278, \"tn\": 7018, \"fp\": 0, \"fn\": 7503, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36312706900942193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6368729309905781, \"precision\": 1.0, \"recall\": 0.36312706900942193, \"specificity\": 1.0, \"npv\": 0.48330004820604644, \"accuracy\": 0.600883025692856, \"f1\": 0.5327853540070988, \"f2\": 0.4161316680284814, \"f0_5\": 0.7403177240161977, \"p4\": 0.586255393224753, \"phi\": 0.4189264015995816}, {\"truth_threshold\": 16.34, \"match_probability\": 0.9999879450715947, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4275, \"tn\": 7018, \"fp\": 0, \"fn\": 7506, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36287242169595113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6371275783040489, \"precision\": 1.0, \"recall\": 0.36287242169595113, \"specificity\": 1.0, \"npv\": 0.48320022032497933, \"accuracy\": 0.6007234427363157, \"f1\": 0.5325112107623319, \"f2\": 0.4158641218700753, \"f0_5\": 0.740105952009972, \"p4\": 0.5860526827704062, \"phi\": 0.41873623453594555}, {\"truth_threshold\": 16.36, \"match_probability\": 0.9999881110333831, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4273, \"tn\": 7018, \"fp\": 0, \"fn\": 7508, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3627026568203039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6372973431796961, \"precision\": 1.0, \"recall\": 0.3627026568203039, \"specificity\": 1.0, \"npv\": 0.48313369131212996, \"accuracy\": 0.6006170540986223, \"f1\": 0.5323283916780864, \"f2\": 0.41568574041286455, \"f0_5\": 0.7399646728777751, \"p4\": 0.5859174909435845, \"phi\": 0.41860945216073425}, {\"truth_threshold\": 16.38, \"match_probability\": 0.9999882747103807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4269, \"tn\": 7018, \"fp\": 0, \"fn\": 7512, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3623631270690094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6376368729309906, \"precision\": 1.0, \"recall\": 0.3623631270690094, \"specificity\": 1.0, \"npv\": 0.4830006882312457, \"accuracy\": 0.6004042768232353, \"f1\": 0.53196261682243, \"f2\": 0.41532893584729436, \"f0_5\": 0.7396818796132654, \"p4\": 0.5856469834290742, \"phi\": 0.4183558769324962}, {\"truth_threshold\": 16.4, \"match_probability\": 0.9999884361340411, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4266, \"tn\": 7018, \"fp\": 0, \"fn\": 7515, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36210847975553856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6378915202444614, \"precision\": 1.0, \"recall\": 0.36210847975553856, \"specificity\": 1.0, \"npv\": 0.4829009839675222, \"accuracy\": 0.600244693866695, \"f1\": 0.5316881660123387, \"f2\": 0.415061295971979, \"f0_5\": 0.7394695787831513, \"p4\": 0.5854439942366044, \"phi\": 0.41816568627391365}, {\"truth_threshold\": 16.42, \"match_probability\": 0.9999885953353853, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4262, \"tn\": 7018, \"fp\": 0, \"fn\": 7519, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.36176895000424414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6382310499957559, \"precision\": 1.0, \"recall\": 0.36176895000424414, \"specificity\": 1.0, \"npv\": 0.48276810896333494, \"accuracy\": 0.6000319165913081, \"f1\": 0.5313220719316836, \"f2\": 0.41470439419297084, \"f0_5\": 0.7391862360817233, \"p4\": 0.5851731969467016, \"phi\": 0.4179120862994994}, {\"truth_threshold\": 16.44, \"match_probability\": 0.9999887523450072, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4251, \"tn\": 7018, \"fp\": 0, \"fn\": 7530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3608352431881844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6391647568118156, \"precision\": 1.0, \"recall\": 0.3608352431881844, \"specificity\": 1.0, \"npv\": 0.4824030794610943, \"accuracy\": 0.5994467790839938, \"f1\": 0.530314371257485, \"f2\": 0.4137226277372263, \"f0_5\": 0.7384054194893174, \"p4\": 0.5844276469224624, \"phi\": 0.4172146120308743}, {\"truth_threshold\": 16.46, \"match_probability\": 0.9999889071930795, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4247, \"tn\": 7018, \"fp\": 0, \"fn\": 7534, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3604957134368899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6395042865631101, \"precision\": 1.0, \"recall\": 0.3604957134368899, \"specificity\": 1.0, \"npv\": 0.4822704782847719, \"accuracy\": 0.5992340018086069, \"f1\": 0.5299475917144997, \"f2\": 0.4133655175098791, \"f0_5\": 0.7381208940178664, \"p4\": 0.584156224928316, \"phi\": 0.41696095757135215}, {\"truth_threshold\": 16.48, \"match_probability\": 0.9999890599093596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4242, \"tn\": 7018, \"fp\": 0, \"fn\": 7539, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3600713012477718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6399286987522281, \"precision\": 1.0, \"recall\": 0.3600713012477718, \"specificity\": 1.0, \"npv\": 0.4821048292917497, \"accuracy\": 0.5989680302143731, \"f1\": 0.5294888597640891, \"f2\": 0.4129190515126738, \"f0_5\": 0.7377647918188459, \"p4\": 0.5838167119055473, \"phi\": 0.41664386857472796}, {\"truth_threshold\": 16.5, \"match_probability\": 0.9999892105231952, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4239, \"tn\": 7018, \"fp\": 0, \"fn\": 7542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.359816653934301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.640183346065699, \"precision\": 1.0, \"recall\": 0.359816653934301, \"specificity\": 1.0, \"npv\": 0.4820054945054945, \"accuracy\": 0.5988084472578329, \"f1\": 0.5292134831460674, \"f2\": 0.41265113019099353, \"f0_5\": 0.7375508925775133, \"p4\": 0.5836128781999497, \"phi\": 0.41645360391154634}, {\"truth_threshold\": 16.52, \"match_probability\": 0.9999893590635301, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4237, \"tn\": 7018, \"fp\": 0, \"fn\": 7544, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3596468890586538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6403531109413463, \"precision\": 1.0, \"recall\": 0.3596468890586538, \"specificity\": 1.0, \"npv\": 0.4819392940530147, \"accuracy\": 0.5987020586201394, \"f1\": 0.529029841428393, \"f2\": 0.4124724985884231, \"f0_5\": 0.7374081938111317, \"p4\": 0.5834769365119196, \"phi\": 0.4163267560718269}, {\"truth_threshold\": 16.54, \"match_probability\": 0.9999895055589096, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4231, \"tn\": 7018, \"fp\": 0, \"fn\": 7550, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35913759443171206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6408624055682879, \"precision\": 1.0, \"recall\": 0.35913759443171206, \"specificity\": 1.0, \"npv\": 0.48174080175727624, \"accuracy\": 0.5983828927070589, \"f1\": 0.5284786410192356, \"f2\": 0.41193652029987343, \"f0_5\": 0.7369796202752134, \"p4\": 0.5830688586951736, \"phi\": 0.41594618964802704}, {\"truth_threshold\": 16.56, \"match_probability\": 0.999989650037486, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4226, \"tn\": 7018, \"fp\": 0, \"fn\": 7555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.358713182242594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.641286817757406, \"precision\": 1.0, \"recall\": 0.358713182242594, \"specificity\": 1.0, \"npv\": 0.4815755163658821, \"accuracy\": 0.5981169211128251, \"f1\": 0.5280189916911351, \"f2\": 0.4114897760467381, \"f0_5\": 0.7366219278368485, \"p4\": 0.582728503545906, \"phi\": 0.4156290244505621}, {\"truth_threshold\": 16.580000000000002, \"match_probability\": 0.9999897925270239, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4221, \"tn\": 7018, \"fp\": 0, \"fn\": 7560, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3582887700534759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6417112299465241, \"precision\": 1.0, \"recall\": 0.3582887700534759, \"specificity\": 1.0, \"npv\": 0.4814103443545068, \"accuracy\": 0.5978509495185914, \"f1\": 0.5275590551181102, \"f2\": 0.4110429447852761, \"f0_5\": 0.7362637362637363, \"p4\": 0.5823878837121738, \"phi\": 0.4153118348540004}, {\"truth_threshold\": 16.6, \"match_probability\": 0.999989933054906, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4219, \"tn\": 7018, \"fp\": 0, \"fn\": 7562, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3581190051778287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6418809948221713, \"precision\": 1.0, \"recall\": 0.3581190051778287, \"specificity\": 1.0, \"npv\": 0.4813443072702332, \"accuracy\": 0.5977445608808979, \"f1\": 0.527375, \"f2\": 0.4108641879126658, \"f0_5\": 0.7361203196426702, \"p4\": 0.5822515615041509, \"phi\": 0.4151849521208915}, {\"truth_threshold\": 16.62, \"match_probability\": 0.9999900716481379, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4214, \"tn\": 7018, \"fp\": 0, \"fn\": 7567, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35769459298871065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6423054070112894, \"precision\": 1.0, \"recall\": 0.35769459298871065, \"specificity\": 1.0, \"npv\": 0.48117929379499486, \"accuracy\": 0.5974785892866642, \"f1\": 0.5269146608315098, \"f2\": 0.41041723479683667, \"f0_5\": 0.7357614275238328, \"p4\": 0.5819105698895525, \"phi\": 0.41486772789480253}, {\"truth_threshold\": 16.64, \"match_probability\": 0.9999902083333535, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4203, \"tn\": 7018, \"fp\": 0, \"fn\": 7578, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3567608861726509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6432391138273491, \"precision\": 1.0, \"recall\": 0.3567608861726509, \"specificity\": 1.0, \"npv\": 0.48081666209920526, \"accuracy\": 0.5968934517793499, \"f1\": 0.5259009009009009, \"f2\": 0.4094336314220586, \"f0_5\": 0.7349700975763299, \"p4\": 0.5811594494582029, \"phi\": 0.41416974594613803}, {\"truth_threshold\": 16.66, \"match_probability\": 0.99999034313682, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4187, \"tn\": 7018, \"fp\": 0, \"fn\": 7594, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35540276716747304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6445972328325269, \"precision\": 1.0, \"recall\": 0.35540276716747304, \"specificity\": 1.0, \"npv\": 0.480290172460991, \"accuracy\": 0.596042342677802, \"f1\": 0.5244238476953907, \"f2\": 0.40800218276782757, \"f0_5\": 0.7338147148515546, \"p4\": 0.5800645925779524, \"phi\": 0.4131542766763755}, {\"truth_threshold\": 16.68, \"match_probability\": 0.9999904760844428, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4180, \"tn\": 7018, \"fp\": 0, \"fn\": 7601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35480859010270777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6451914098972923, \"precision\": 1.0, \"recall\": 0.35480859010270777, \"specificity\": 1.0, \"npv\": 0.4800601956358164, \"accuracy\": 0.5956699824458748, \"f1\": 0.523776705720193, \"f2\": 0.4073756432246998, \"f0_5\": 0.7333076032419915, \"p4\": 0.579584723385995, \"phi\": 0.41270992376967874}, {\"truth_threshold\": 16.7, \"match_probability\": 0.9999906072017711, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4171, \"tn\": 7018, \"fp\": 0, \"fn\": 7610, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3540446481622952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6459553518377048, \"precision\": 1.0, \"recall\": 0.3540446481622952, \"specificity\": 1.0, \"npv\": 0.47976483456385016, \"accuracy\": 0.595191233576254, \"f1\": 0.5229438314944834, \"f2\": 0.40656984111511846, \"f0_5\": 0.732654136659055, \"p4\": 0.57896696662259, \"phi\": 0.41213853502651276}, {\"truth_threshold\": 16.72, \"match_probability\": 0.999990736514002, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4166, \"tn\": 7018, \"fp\": 0, \"fn\": 7615, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35362023597317715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6463797640268228, \"precision\": 1.0, \"recall\": 0.35362023597317715, \"specificity\": 1.0, \"npv\": 0.4796009020706622, \"accuracy\": 0.5949252619820203, \"f1\": 0.5224807173763091, \"f2\": 0.40612205108208227, \"f0_5\": 0.7322903849534189, \"p4\": 0.5786233867727159, \"phi\": 0.4118210584260793}, {\"truth_threshold\": 16.740000000000002, \"match_probability\": 0.9999908640459861, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4160, \"tn\": 7018, \"fp\": 0, \"fn\": 7621, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35311094134623544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6468890586537646, \"precision\": 1.0, \"recall\": 0.35311094134623544, \"specificity\": 1.0, \"npv\": 0.4794043308969192, \"accuracy\": 0.5946060960689399, \"f1\": 0.5219245969512578, \"f2\": 0.40558458778566414, \"f0_5\": 0.7318532071355688, \"p4\": 0.57821072979139, \"phi\": 0.4114400497866892}, {\"truth_threshold\": 16.76, \"match_probability\": 0.9999909898222314, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4153, \"tn\": 7018, \"fp\": 0, \"fn\": 7628, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35251676428147016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6474832357185298, \"precision\": 1.0, \"recall\": 0.35251676428147016, \"specificity\": 1.0, \"npv\": 0.479175201420183, \"accuracy\": 0.5942337358370126, \"f1\": 0.5212752604493536, \"f2\": 0.4049573883027478, \"f0_5\": 0.7313422322403409, \"p4\": 0.5777287970344458, \"phi\": 0.4109954884528109}, {\"truth_threshold\": 16.78, \"match_probability\": 0.9999911138669091, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4146, \"tn\": 7018, \"fp\": 0, \"fn\": 7635, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3519225872167049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6480774127832951, \"precision\": 1.0, \"recall\": 0.3519225872167049, \"specificity\": 1.0, \"npv\": 0.4789462908619395, \"accuracy\": 0.5938613756050853, \"f1\": 0.5206253531738557, \"f2\": 0.40433001755412523, \"f0_5\": 0.730830248545743, \"p4\": 0.5772463242556484, \"phi\": 0.41055087116943034}, {\"truth_threshold\": 16.8, \"match_probability\": 0.9999912362038571, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4143, \"tn\": 7018, \"fp\": 0, \"fn\": 7638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.35166793990323403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.648332060096766, \"precision\": 1.0, \"recall\": 0.35166793990323403, \"specificity\": 1.0, \"npv\": 0.47884825327510916, \"accuracy\": 0.5937017926485452, \"f1\": 0.5203466465712132, \"f2\": 0.4040610919304816, \"f0_5\": 0.7306105174055656, \"p4\": 0.5770393843783111, \"phi\": 0.410360303581523}, {\"truth_threshold\": 16.82, \"match_probability\": 0.9999913568565856, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4137, \"tn\": 7018, \"fp\": 0, \"fn\": 7644, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3511586452762923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6488413547237076, \"precision\": 1.0, \"recall\": 0.3511586452762923, \"specificity\": 1.0, \"npv\": 0.47865229845860047, \"accuracy\": 0.5933826267354646, \"f1\": 0.5197889182058048, \"f2\": 0.40352314625153624, \"f0_5\": 0.7301704966641956, \"p4\": 0.5766252052529747, \"phi\": 0.4099791368900443}, {\"truth_threshold\": 16.84, \"match_probability\": 0.9999914758482807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4129, \"tn\": 7018, \"fp\": 0, \"fn\": 7652, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3504795857737034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6495204142262966, \"precision\": 1.0, \"recall\": 0.3504795857737034, \"specificity\": 1.0, \"npv\": 0.47839127471029314, \"accuracy\": 0.5929570721846906, \"f1\": 0.5190446260213702, \"f2\": 0.40280568942305817, \"f0_5\": 0.7295826412693925, \"p4\": 0.5760723435605829, \"phi\": 0.40947084853285654}, {\"truth_threshold\": 16.86, \"match_probability\": 0.9999915932018099, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4124, \"tn\": 7018, \"fp\": 0, \"fn\": 7657, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3500551735845853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6499448264154146, \"precision\": 1.0, \"recall\": 0.3500551735845853, \"specificity\": 1.0, \"npv\": 0.4782282793867121, \"accuracy\": 0.5926911005904569, \"f1\": 0.5185790631876769, \"f2\": 0.4023571651576647, \"f0_5\": 0.7292145559995756, \"p4\": 0.5757264422588176, \"phi\": 0.40915312946838506}, {\"truth_threshold\": 16.88, \"match_probability\": 0.9999917089397252, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4122, \"tn\": 7018, \"fp\": 0, \"fn\": 7659, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34988540870893814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6501145912910619, \"precision\": 1.0, \"recall\": 0.34988540870893814, \"specificity\": 1.0, \"npv\": 0.4781631123526606, \"accuracy\": 0.5925847119527634, \"f1\": 0.5183927560837578, \"f2\": 0.4021777309448542, \"f0_5\": 0.7290671760585801, \"p4\": 0.5755880033930969, \"phi\": 0.40902603339524557}, {\"truth_threshold\": 16.9, \"match_probability\": 0.9999918230842687, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4118, \"tn\": 7018, \"fp\": 0, \"fn\": 7663, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34954587895764366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6504541210423563, \"precision\": 1.0, \"recall\": 0.34954587895764366, \"specificity\": 1.0, \"npv\": 0.47803283155098425, \"accuracy\": 0.5923719346773765, \"f1\": 0.5180200012579408, \"f2\": 0.40181882049880957, \"f0_5\": 0.728772165787704, \"p4\": 0.575310991084191, \"phi\": 0.4087718266650724}, {\"truth_threshold\": 16.92, \"match_probability\": 0.9999919356573761, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4112, \"tn\": 7018, \"fp\": 0, \"fn\": 7669, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.349036584330702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.650963415669298, \"precision\": 1.0, \"recall\": 0.349036584330702, \"specificity\": 1.0, \"npv\": 0.477837543405733, \"accuracy\": 0.592052768764296, \"f1\": 0.5174605172088341, \"f2\": 0.40128034975407917, \"f0_5\": 0.7283290233447873, \"p4\": 0.5748951354342161, \"phi\": 0.40839047982942817}, {\"truth_threshold\": 16.94, \"match_probability\": 0.999992046680681, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4108, \"tn\": 7018, \"fp\": 0, \"fn\": 7673, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34869705457940753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6513029454205925, \"precision\": 1.0, \"recall\": 0.34869705457940753, \"specificity\": 1.0, \"npv\": 0.47770743992920833, \"accuracy\": 0.591839991488909, \"f1\": 0.5170872930958524, \"f2\": 0.4009212991880075, \"f0_5\": 0.7280331761953709, \"p4\": 0.5746176729639179, \"phi\": 0.40813622389342535}, {\"truth_threshold\": 16.96, \"match_probability\": 0.9999921561755195, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4103, \"tn\": 7018, \"fp\": 0, \"fn\": 7678, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34827264239028943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6517273576097106, \"precision\": 1.0, \"recall\": 0.34827264239028943, \"specificity\": 1.0, \"npv\": 0.47754491017964074, \"accuracy\": 0.5915740198946753, \"f1\": 0.5166204986149584, \"f2\": 0.400472407129053, \"f0_5\": 0.7276628950448693, \"p4\": 0.5742705906342643, \"phi\": 0.40781837590807124}, {\"truth_threshold\": 16.98, \"match_probability\": 0.9999922641629336, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4089, \"tn\": 7018, \"fp\": 0, \"fn\": 7692, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3470842882607588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6529157117392411, \"precision\": 1.0, \"recall\": 0.3470842882607588, \"specificity\": 1.0, \"npv\": 0.4770904146838885, \"accuracy\": 0.5908292994308207, \"f1\": 0.5153119092627599, \"f2\": 0.3992150430554742, \"f0_5\": 0.7266233073888474, \"p4\": 0.5732972508859839, \"phi\": 0.4069282332507634}, {\"truth_threshold\": 17.0, \"match_probability\": 0.999992370663676, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4088, \"tn\": 7018, \"fp\": 0, \"fn\": 7693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34699940582293526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6530005941770648, \"precision\": 1.0, \"recall\": 0.34699940582293526, \"specificity\": 1.0, \"npv\": 0.47705798382163006, \"accuracy\": 0.5907761051119741, \"f1\": 0.5152183502426114, \"f2\": 0.3991252050300711, \"f0_5\": 0.7265488927593929, \"p4\": 0.5732276411978905, \"phi\": 0.40686464202384687}, {\"truth_threshold\": 17.02, \"match_probability\": 0.9999924756982134, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4086, \"tn\": 7018, \"fp\": 0, \"fn\": 7695, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.346829640947288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.653170359052712, \"precision\": 1.0, \"recall\": 0.346829640947288, \"specificity\": 1.0, \"npv\": 0.4769931353225039, \"accuracy\": 0.5906697164742806, \"f1\": 0.5150311968235961, \"f2\": 0.3989455184534271, \"f0_5\": 0.7264, \"p4\": 0.5730883875465587, \"phi\": 0.40673745568637415}, {\"truth_threshold\": 17.04, \"match_probability\": 0.9999925792867308, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4085, \"tn\": 7018, \"fp\": 0, \"fn\": 7696, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3467447585094644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6532552414905356, \"precision\": 1.0, \"recall\": 0.3467447585094644, \"specificity\": 1.0, \"npv\": 0.4769607176838385, \"accuracy\": 0.5906165221554338, \"f1\": 0.5149376024202698, \"f2\": 0.39885566990177507, \"f0_5\": 0.7263255218519967, \"p4\": 0.5730187435706978, \"phi\": 0.4066738605710766}, {\"truth_threshold\": 17.06, \"match_probability\": 0.9999926814491356, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4080, \"tn\": 7018, \"fp\": 0, \"fn\": 7701, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3463203463203463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6536796536796536, \"precision\": 1.0, \"recall\": 0.3463203463203463, \"specificity\": 1.0, \"npv\": 0.4767986955635573, \"accuracy\": 0.5903505505612001, \"f1\": 0.5144694533762058, \"f2\": 0.398406374501992, \"f0_5\": 0.7259528130671506, \"p4\": 0.5726703519366537, \"phi\": 0.4063558654340559}, {\"truth_threshold\": 17.1, \"match_probability\": 0.9999928815738692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4075, \"tn\": 7018, \"fp\": 0, \"fn\": 7706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34589593413122827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6541040658687718, \"precision\": 1.0, \"recall\": 0.34589593413122827, \"specificity\": 1.0, \"npv\": 0.47663678348274924, \"accuracy\": 0.5900845789669663, \"f1\": 0.5140010090817356, \"f2\": 0.39795699134748724, \"f0_5\": 0.7255795733770165, \"p4\": 0.5723216734642625, \"phi\": 0.4060378374783187}, {\"truth_threshold\": 17.12, \"match_probability\": 0.9999929795746573, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4069, \"tn\": 7018, \"fp\": 0, \"fn\": 7712, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34538663950428655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6546133604957134, \"precision\": 1.0, \"recall\": 0.34538663950428655, \"specificity\": 1.0, \"npv\": 0.4764426340801086, \"accuracy\": 0.5897654130538859, \"f1\": 0.5134384858044164, \"f2\": 0.39741761568964507, \"f0_5\": 0.7251309833553125, \"p4\": 0.5719028795534598, \"phi\": 0.4056561601917308}, {\"truth_threshold\": 17.14, \"match_probability\": 0.9999930762262584, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4063, \"tn\": 7018, \"fp\": 0, \"fn\": 7718, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3448773448773449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6551226551226551, \"precision\": 1.0, \"recall\": 0.3448773448773449, \"specificity\": 1.0, \"npv\": 0.4762486427795874, \"accuracy\": 0.5894462471408054, \"f1\": 0.5128755364806867, \"f2\": 0.3968781135835271, \"f0_5\": 0.7246816252274105, \"p4\": 0.5714836700771773, \"phi\": 0.4052744347022931}, {\"truth_threshold\": 17.16, \"match_probability\": 0.9999931715472467, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4057, \"tn\": 7018, \"fp\": 0, \"fn\": 7724, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3443680502504032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6556319497495968, \"precision\": 1.0, \"recall\": 0.3443680502504032, \"specificity\": 1.0, \"npv\": 0.4760548093881427, \"accuracy\": 0.5891270812277248, \"f1\": 0.5123121606263417, \"f2\": 0.3963384849846623, \"f0_5\": 0.7242314970188154, \"p4\": 0.5710640436548298, \"phi\": 0.4048926604932745}, {\"truth_threshold\": 17.18, \"match_probability\": 0.9999932655559404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4056, \"tn\": 7018, \"fp\": 0, \"fn\": 7725, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34428316781257956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6557168321874204, \"precision\": 1.0, \"recall\": 0.34428316781257956, \"specificity\": 1.0, \"npv\": 0.476022519161636, \"accuracy\": 0.5890738869088782, \"f1\": 0.5122182231483235, \"f2\": 0.3962485345838218, \"f0_5\": 0.7241564006427423, \"p4\": 0.5709940652841312, \"phi\": 0.40482902668545445}, {\"truth_threshold\": 17.2, \"match_probability\": 0.999993358270406, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4055, \"tn\": 7018, \"fp\": 0, \"fn\": 7726, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34419828537475594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6558017146252441, \"precision\": 1.0, \"recall\": 0.34419828537475594, \"specificity\": 1.0, \"npv\": 0.47599023331524687, \"accuracy\": 0.5890206925900314, \"f1\": 0.5121242738065168, \"f2\": 0.39615858066785203, \"f0_5\": 0.7240812828113282, \"p4\": 0.5709240752866916, \"phi\": 0.40476539150752255}, {\"truth_threshold\": 17.22, \"match_probability\": 0.9999934497084612, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4049, \"tn\": 7018, \"fp\": 0, \"fn\": 7732, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3436889907478143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6563110092521858, \"precision\": 1.0, \"recall\": 0.3436889907478143, \"specificity\": 1.0, \"npv\": 0.47579661016949154, \"accuracy\": 0.5887015266769509, \"f1\": 0.5115603284902085, \"f2\": 0.3956187833427784, \"f0_5\": 0.7236301247453265, \"p4\": 0.5705038907800137, \"phi\": 0.40438355153292743}, {\"truth_threshold\": 17.240000000000002, \"match_probability\": 0.9999935398876778, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4045, \"tn\": 7018, \"fp\": 0, \"fn\": 7736, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3433494609965198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6566505390034801, \"precision\": 1.0, \"recall\": 0.3433494609965198, \"specificity\": 1.0, \"npv\": 0.47566761556188153, \"accuracy\": 0.5884887494015639, \"f1\": 0.5111841273853153, \"f2\": 0.3952588481307041, \"f0_5\": 0.7233289224276671, \"p4\": 0.5702235344245135, \"phi\": 0.4041289638428206}, {\"truth_threshold\": 17.26, \"match_probability\": 0.9999936288253866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4040, \"tn\": 7018, \"fp\": 0, \"fn\": 7741, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34292504880740177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6570749511925983, \"precision\": 1.0, \"recall\": 0.34292504880740177, \"specificity\": 1.0, \"npv\": 0.4755064706280913, \"accuracy\": 0.5882227778073301, \"f1\": 0.5107136084950382, \"f2\": 0.394808849972637, \"f0_5\": 0.7229519344332701, \"p4\": 0.5698728257329557, \"phi\": 0.4038106977884236}, {\"truth_threshold\": 17.28, \"match_probability\": 0.999993716538679, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4037, \"tn\": 7018, \"fp\": 0, \"fn\": 7744, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3426704014939309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6573295985060691, \"precision\": 1.0, \"recall\": 0.3426704014939309, \"specificity\": 1.0, \"npv\": 0.47540983606557374, \"accuracy\": 0.58806319485079, \"f1\": 0.5104311543810849, \"f2\": 0.39453880885831005, \"f0_5\": 0.7227254824734147, \"p4\": 0.5696622598083819, \"phi\": 0.40361972127084433}, {\"truth_threshold\": 17.3, \"match_probability\": 0.9999938030444118, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4032, \"tn\": 7018, \"fp\": 0, \"fn\": 7749, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3422459893048128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6577540106951871, \"precision\": 1.0, \"recall\": 0.3422459893048128, \"specificity\": 1.0, \"npv\": 0.47524886571409225, \"accuracy\": 0.5877972232565561, \"f1\": 0.5099601593625498, \"f2\": 0.39408866995073893, \"f0_5\": 0.7223476297968398, \"p4\": 0.5693110815214601, \"phi\": 0.40330139872347287}, {\"truth_threshold\": 17.32, \"match_probability\": 0.9999938883592091, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4028, \"tn\": 7018, \"fp\": 0, \"fn\": 7753, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3419064595535184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6580935404464816, \"precision\": 1.0, \"recall\": 0.3419064595535184, \"specificity\": 1.0, \"npv\": 0.47512016789655404, \"accuracy\": 0.5875844459811692, \"f1\": 0.5095831488392688, \"f2\": 0.39372849546449795, \"f0_5\": 0.7220449575162227, \"p4\": 0.5690299268514282, \"phi\": 0.4030467149946567}, {\"truth_threshold\": 17.34, \"match_probability\": 0.9999939724994668, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4027, \"tn\": 7018, \"fp\": 0, \"fn\": 7754, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3418215771156948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6581784228843053, \"precision\": 1.0, \"recall\": 0.3418215771156948, \"specificity\": 1.0, \"npv\": 0.47508800433252096, \"accuracy\": 0.5875312516623225, \"f1\": 0.5094888663967612, \"f2\": 0.3936384430411918, \"f0_5\": 0.7219692351823299, \"p4\": 0.5689596086794473, \"phi\": 0.40298304047402583}, {\"truth_threshold\": 17.36, \"match_probability\": 0.9999940554813546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4018, \"tn\": 7018, \"fp\": 0, \"fn\": 7763, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34105763517528226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6589423648247178, \"precision\": 1.0, \"recall\": 0.34105763517528226, \"specificity\": 1.0, \"npv\": 0.4747987280968811, \"accuracy\": 0.5870525027927017, \"f1\": 0.5086397873283119, \"f2\": 0.39282781275663836, \"f0_5\": 0.7212867554661976, \"p4\": 0.5683262126761571, \"phi\": 0.40240990468545146}, {\"truth_threshold\": 17.38, \"match_probability\": 0.9999941373208195, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4014, \"tn\": 7018, \"fp\": 0, \"fn\": 7767, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3407181054239878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6592818945760123, \"precision\": 1.0, \"recall\": 0.3407181054239878, \"specificity\": 1.0, \"npv\": 0.47467027392627664, \"accuracy\": 0.5868397255173148, \"f1\": 0.5082621082621083, \"f2\": 0.39246744104188663, \"f0_5\": 0.720982864532816, \"p4\": 0.5680443949038344, \"phi\": 0.40215513975734074}, {\"truth_threshold\": 17.400000000000002, \"match_probability\": 0.9999942180335896, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4007, \"tn\": 7018, \"fp\": 0, \"fn\": 7774, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.34012392835922245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6598760716407776, \"precision\": 1.0, \"recall\": 0.34012392835922245, \"specificity\": 1.0, \"npv\": 0.47444564629529473, \"accuracy\": 0.5864673652853876, \"f1\": 0.5076007093995439, \"f2\": 0.3918366548669105, \"f0_5\": 0.7204502139595095, \"p4\": 0.5675507553869727, \"phi\": 0.4017092443682194}, {\"truth_threshold\": 17.42, \"match_probability\": 0.9999942976351759, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4005, \"tn\": 7018, \"fp\": 0, \"fn\": 7776, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33995416348357527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6600458365164248, \"precision\": 1.0, \"recall\": 0.33995416348357527, \"specificity\": 1.0, \"npv\": 0.4743815060159524, \"accuracy\": 0.586360976647694, \"f1\": 0.507411630558723, \"f2\": 0.39165639852138706, \"f0_5\": 0.7202978310132729, \"p4\": 0.567409608105265, \"phi\": 0.40158183232030276}, {\"truth_threshold\": 17.44, \"match_probability\": 0.9999943761408759, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3994, \"tn\": 7018, \"fp\": 0, \"fn\": 7787, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3390204566675155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6609795433324845, \"precision\": 1.0, \"recall\": 0.3390204566675155, \"specificity\": 1.0, \"npv\": 0.4740290442418102, \"accuracy\": 0.5857758391403798, \"f1\": 0.5063708399366086, \"f2\": 0.39066473649203803, \"f0_5\": 0.7194581546997154, \"p4\": 0.5666324415040719, \"phi\": 0.4008809587053548}, {\"truth_threshold\": 17.46, \"match_probability\": 0.999994453565777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3991, \"tn\": 7018, \"fp\": 0, \"fn\": 7790, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33876580935404466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6612341906459553, \"precision\": 1.0, \"recall\": 0.33876580935404466, \"specificity\": 1.0, \"npv\": 0.47393300918422476, \"accuracy\": 0.5856162561838396, \"f1\": 0.5060867359878265, \"f2\": 0.3903942091362614, \"f0_5\": 0.7192286898540278, \"p4\": 0.5664202346563442, \"phi\": 0.40068977955008006}, {\"truth_threshold\": 17.48, \"match_probability\": 0.9999945299247582, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3986, \"tn\": 7018, \"fp\": 0, \"fn\": 7795, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33834139716492656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6616586028350734, \"precision\": 1.0, \"recall\": 0.33834139716492656, \"specificity\": 1.0, \"npv\": 0.47377303719705666, \"accuracy\": 0.5853502845896058, \"f1\": 0.5056129891545633, \"f2\": 0.38994325963607906, \"f0_5\": 0.7188458070333634, \"p4\": 0.5660663154261057, \"phi\": 0.40037111702059985}, {\"truth_threshold\": 17.5, \"match_probability\": 0.9999946052324943, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3984, \"tn\": 7018, \"fp\": 0, \"fn\": 7797, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3381716322892793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6618283677107206, \"precision\": 1.0, \"recall\": 0.3381716322892793, \"specificity\": 1.0, \"npv\": 0.47370907863651707, \"accuracy\": 0.5852438959519123, \"f1\": 0.5054234062797336, \"f2\": 0.3897628551303123, \"f0_5\": 0.7186924991882239, \"p4\": 0.5659246631749605, \"phi\": 0.4002436412396349}, {\"truth_threshold\": 17.52, \"match_probability\": 0.9999946795034576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3977, \"tn\": 7018, \"fp\": 0, \"fn\": 7804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33757745522451404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6624225447754859, \"precision\": 1.0, \"recall\": 0.33757745522451404, \"specificity\": 1.0, \"npv\": 0.47348535960059374, \"accuracy\": 0.5848715357199851, \"f1\": 0.5047594872445742, \"f2\": 0.3891313281540479, \"f0_5\": 0.7181552240962115, \"p4\": 0.5654284987929237, \"phi\": 0.3997974271803564}, {\"truth_threshold\": 17.54, \"match_probability\": 0.9999947527519214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3962, \"tn\": 7018, \"fp\": 0, \"fn\": 7819, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3363042186571598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6636957813428401, \"precision\": 1.0, \"recall\": 0.3363042186571598, \"specificity\": 1.0, \"npv\": 0.4730066725079194, \"accuracy\": 0.5840736209372839, \"f1\": 0.5033348154735438, \"f2\": 0.3877774732803508, \"f0_5\": 0.71700025335698, \"p4\": 0.5643632821485367, \"phi\": 0.3988409951564645}, {\"truth_threshold\": 17.56, \"match_probability\": 0.9999948249919623, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3960, \"tn\": 7018, \"fp\": 0, \"fn\": 7821, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33613445378151263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6638655462184874, \"precision\": 1.0, \"recall\": 0.33613445378151263, \"specificity\": 1.0, \"npv\": 0.4729429206819867, \"accuracy\": 0.5839672322995904, \"f1\": 0.5031446540880503, \"f2\": 0.3875968992248062, \"f0_5\": 0.7168458781362007, \"p4\": 0.5642210455334343, \"phi\": 0.39871344385820856}, {\"truth_threshold\": 17.580000000000002, \"match_probability\": 0.9999948962374636, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3955, \"tn\": 7018, \"fp\": 0, \"fn\": 7826, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33571004159239454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6642899584076055, \"precision\": 1.0, \"recall\": 0.33571004159239454, \"specificity\": 1.0, \"npv\": 0.4727836162759364, \"accuracy\": 0.5837012607053567, \"f1\": 0.5026690391459074, \"f2\": 0.3871454022200905, \"f0_5\": 0.7164595485670809, \"p4\": 0.5638652392836957, \"phi\": 0.39839453746781883}, {\"truth_threshold\": 17.6, \"match_probability\": 0.999994966502117, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3950, \"tn\": 7018, \"fp\": 0, \"fn\": 7831, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33528562940327644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6647143705967236, \"precision\": 1.0, \"recall\": 0.33528562940327644, \"specificity\": 1.0, \"npv\": 0.4726244191528049, \"accuracy\": 0.583435289111123, \"f1\": 0.502193121861293, \"f2\": 0.38669381681481774, \"f0_5\": 0.7160726587143323, \"p4\": 0.5635091256193729, \"phi\": 0.39807559061942765}, {\"truth_threshold\": 17.62, \"match_probability\": 0.9999950357994258, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3945, \"tn\": 7018, \"fp\": 0, \"fn\": 7836, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3348612172141584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6651387827858416, \"precision\": 1.0, \"recall\": 0.3348612172141584, \"specificity\": 1.0, \"npv\": 0.47246532920425477, \"accuracy\": 0.5831693175168892, \"f1\": 0.5017169019458222, \"f2\": 0.38624214298302295, \"f0_5\": 0.7156852073582236, \"p4\": 0.5631527036842512, \"phi\": 0.3977566029983975}, {\"truth_threshold\": 17.64, \"match_probability\": 0.9999951041427074, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3940, \"tn\": 7018, \"fp\": 0, \"fn\": 7841, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3344368050250403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6655631949749596, \"precision\": 1.0, \"recall\": 0.3344368050250403, \"specificity\": 1.0, \"npv\": 0.47230634632209434, \"accuracy\": 0.5829033459226555, \"f1\": 0.5012403791107436, \"f2\": 0.385790380698731, \"f0_5\": 0.7152971932754802, \"p4\": 0.5627959726194723, \"phi\": 0.39743757428936105}, {\"truth_threshold\": 17.66, \"match_probability\": 0.9999951715450961, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3928, \"tn\": 7018, \"fp\": 0, \"fn\": 7853, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33341821577115693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6665817842288431, \"precision\": 1.0, \"recall\": 0.33341821577115693, \"specificity\": 1.0, \"npv\": 0.4719252235895367, \"accuracy\": 0.5822650140964944, \"f1\": 0.500095486663696, \"f2\": 0.38470579017472384, \"f0_5\": 0.7143636562033973, \"p4\": 0.561938551654132, \"phi\": 0.3966717358555152}, {\"truth_threshold\": 17.68, \"match_probability\": 0.999995238019545, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3927, \"tn\": 7018, \"fp\": 0, \"fn\": 7854, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3333333333333333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6666666666666666, \"precision\": 1.0, \"recall\": 0.3333333333333333, \"specificity\": 1.0, \"npv\": 0.4718934911242604, \"accuracy\": 0.5822118197776478, \"f1\": 0.5, \"f2\": 0.38461538461538464, \"f0_5\": 0.7142857142857143, \"p4\": 0.5618670189343902, \"phi\": 0.39660790508353894}, {\"truth_threshold\": 17.7, \"match_probability\": 0.9999953035788293, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3922, \"tn\": 7018, \"fp\": 0, \"fn\": 7859, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3329089211442153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6670910788557848, \"precision\": 1.0, \"recall\": 0.3329089211442153, \"specificity\": 1.0, \"npv\": 0.47173489278752434, \"accuracy\": 0.581945848183414, \"f1\": 0.4995223842577851, \"f2\": 0.3841633036868707, \"f0_5\": 0.7138956642032837, \"p4\": 0.5615091678503753, \"phi\": 0.3962887258350618}, {\"truth_threshold\": 17.72, \"match_probability\": 0.9999953682355479, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3920, \"tn\": 7018, \"fp\": 0, \"fn\": 7861, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33273915626856804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.667260843731432, \"precision\": 1.0, \"recall\": 0.33273915626856804, \"specificity\": 1.0, \"npv\": 0.47167148329860875, \"accuracy\": 0.5818394595457205, \"f1\": 0.49933125278644674, \"f2\": 0.3839824465167307, \"f0_5\": 0.7137394850879429, \"p4\": 0.5613659397935143, \"phi\": 0.3961610422400505}, {\"truth_threshold\": 17.740000000000002, \"match_probability\": 0.9999954320021266, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3912, \"tn\": 7018, \"fp\": 0, \"fn\": 7869, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33206009676597914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6679399032340209, \"precision\": 1.0, \"recall\": 0.33206009676597914, \"specificity\": 1.0, \"npv\": 0.471418015718412, \"accuracy\": 0.5814139049949465, \"f1\": 0.49856623972471803, \"f2\": 0.38325887608746767, \"f0_5\": 0.713113857595975, \"p4\": 0.5607925254642347, \"phi\": 0.3956502393739726}, {\"truth_threshold\": 17.76, \"match_probability\": 0.9999954948908198, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3903, \"tn\": 7018, \"fp\": 0, \"fn\": 7878, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33129615482556657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6687038451744334, \"precision\": 1.0, \"recall\": 0.33129615482556657, \"specificity\": 1.0, \"npv\": 0.4711331901181525, \"accuracy\": 0.5809351561253259, \"f1\": 0.4977046671767406, \"f2\": 0.38244458815920984, \"f0_5\": 0.7124082794874603, \"p4\": 0.560146470675911, \"phi\": 0.3950754539285458}, {\"truth_threshold\": 17.78, \"match_probability\": 0.9999955569137137, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3894, \"tn\": 7018, \"fp\": 0, \"fn\": 7887, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.33053221288515405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6694677871148459, \"precision\": 1.0, \"recall\": 0.33053221288515405, \"specificity\": 1.0, \"npv\": 0.4708487084870849, \"accuracy\": 0.5804564072557051, \"f1\": 0.4968421052631579, \"f2\": 0.3816300129366106, \"f0_5\": 0.7117008443908324, \"p4\": 0.5594993905883052, \"phi\": 0.39450052667943675}, {\"truth_threshold\": 17.8, \"match_probability\": 0.9999956180827274, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3886, \"tn\": 7018, \"fp\": 0, \"fn\": 7895, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32985315338256516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6701468466174348, \"precision\": 1.0, \"recall\": 0.32985315338256516, \"specificity\": 1.0, \"npv\": 0.47059612418695096, \"accuracy\": 0.5800308527049312, \"f1\": 0.496074551605285, \"f2\": 0.38090570476377184, \"f0_5\": 0.7110704483074108, \"p4\": 0.5589233433697346, \"phi\": 0.3939893596693685}, {\"truth_threshold\": 17.82, \"match_probability\": 0.9999956784096167, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3876, \"tn\": 7018, \"fp\": 0, \"fn\": 7905, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.329004329004329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.670995670995671, \"precision\": 1.0, \"recall\": 0.329004329004329, \"specificity\": 1.0, \"npv\": 0.47028077464316825, \"accuracy\": 0.5794989095164637, \"f1\": 0.495114006514658, \"f2\": 0.38, \"f0_5\": 0.7102803738317757, \"p4\": 0.5582021338331709, \"phi\": 0.3933502392335762}, {\"truth_threshold\": 17.84, \"match_probability\": 0.999995737905975, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3874, \"tn\": 7018, \"fp\": 0, \"fn\": 7907, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3288345641286818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6711654358713183, \"precision\": 1.0, \"recall\": 0.3288345641286818, \"specificity\": 1.0, \"npv\": 0.4702177554438861, \"accuracy\": 0.5793925208787701, \"f1\": 0.4949217502395401, \"f2\": 0.3798188164241735, \"f0_5\": 0.7101220808739964, \"p4\": 0.5580577379517876, \"phi\": 0.3932223933818589}, {\"truth_threshold\": 17.86, \"match_probability\": 0.9999957965832362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3868, \"tn\": 7018, \"fp\": 0, \"fn\": 7913, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32832526950174007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6716747304982599, \"precision\": 1.0, \"recall\": 0.32832526950174007, \"specificity\": 1.0, \"npv\": 0.4700287991427232, \"accuracy\": 0.5790733549656897, \"f1\": 0.49434468656144165, \"f2\": 0.3792751804204581, \"f0_5\": 0.7096466444061205, \"p4\": 0.5576242413251855, \"phi\": 0.3928388119217778}, {\"truth_threshold\": 17.88, \"match_probability\": 0.9999958544526771, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3861, \"tn\": 7018, \"fp\": 0, \"fn\": 7920, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3277310924369748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6722689075630253, \"precision\": 1.0, \"recall\": 0.3277310924369748, \"specificity\": 1.0, \"npv\": 0.4698085419734904, \"accuracy\": 0.5787009947337625, \"f1\": 0.4936708860759494, \"f2\": 0.3786407766990291, \"f0_5\": 0.7090909090909091, \"p4\": 0.5571179078411177, \"phi\": 0.39239121638639457}, {\"truth_threshold\": 17.900000000000002, \"match_probability\": 0.9999959115254188, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3857, \"tn\": 7018, \"fp\": 0, \"fn\": 7924, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3273915626856803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6726084373143196, \"precision\": 1.0, \"recall\": 0.3273915626856803, \"specificity\": 1.0, \"npv\": 0.46968277339044306, \"accuracy\": 0.5784882174583754, \"f1\": 0.4932855863921218, \"f2\": 0.3782781820678292, \"f0_5\": 0.7087728325186519, \"p4\": 0.5568282894929155, \"phi\": 0.3921354066478076}, {\"truth_threshold\": 17.92, \"match_probability\": 0.9999959678124296, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3843, \"tn\": 7018, \"fp\": 0, \"fn\": 7938, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32620320855614976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6737967914438503, \"precision\": 1.0, \"recall\": 0.32620320855614976, \"specificity\": 1.0, \"npv\": 0.46924311313185346, \"accuracy\": 0.577743496994521, \"f1\": 0.49193548387096775, \"f2\": 0.377008652657602, \"f0_5\": 0.7076566125290024, \"p4\": 0.5558129857787293, \"phi\": 0.3912398357740261}, {\"truth_threshold\": 17.94, \"match_probability\": 0.9999960233245266, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3837, \"tn\": 7018, \"fp\": 0, \"fn\": 7944, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32569391392920805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6743060860707919, \"precision\": 1.0, \"recall\": 0.32569391392920805, \"specificity\": 1.0, \"npv\": 0.4690549391792541, \"accuracy\": 0.5774243310814405, \"f1\": 0.49135612754514024, \"f2\": 0.3764643550950727, \"f0_5\": 0.7071768218511556, \"p4\": 0.5553770713979529, \"phi\": 0.3908559056597686}, {\"truth_threshold\": 17.96, \"match_probability\": 0.9999960780723782, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3827, \"tn\": 7018, \"fp\": 0, \"fn\": 7954, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3248450895509719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6751549104490281, \"precision\": 1.0, \"recall\": 0.3248450895509719, \"specificity\": 1.0, \"npv\": 0.46874165108201976, \"accuracy\": 0.576892387892973, \"f1\": 0.49038954382368016, \"f2\": 0.37555690761712235, \"f0_5\": 0.7063752814795674, \"p4\": 0.5546494959329231, \"phi\": 0.3902158679782373}, {\"truth_threshold\": 17.98, \"match_probability\": 0.999996132066506, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3816, \"tn\": 7018, \"fp\": 0, \"fn\": 7965, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32391138273491216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6760886172650878, \"precision\": 1.0, \"recall\": 0.32391138273491216, \"specificity\": 1.0, \"npv\": 0.4683975171861443, \"accuracy\": 0.5763072503856588, \"f1\": 0.4893248701673399, \"f2\": 0.3745583038869258, \"f0_5\": 0.7054908485856906, \"p4\": 0.5538476371410073, \"phi\": 0.38951160118969985}, {\"truth_threshold\": 18.0, \"match_probability\": 0.9999961853172863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3812, \"tn\": 7018, \"fp\": 0, \"fn\": 7969, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3235718529836177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6764281470163823, \"precision\": 1.0, \"recall\": 0.3235718529836177, \"specificity\": 1.0, \"npv\": 0.468272502835791, \"accuracy\": 0.5760944731102718, \"f1\": 0.48893734367985636, \"f2\": 0.37419506832103033, \"f0_5\": 0.705168522697843, \"p4\": 0.5535556539627238, \"phi\": 0.3892554449765004}, {\"truth_threshold\": 18.02, \"match_probability\": 0.9999962378349528, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3804, \"tn\": 7018, \"fp\": 0, \"fn\": 7977, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3228927934810288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6771072065189713, \"precision\": 1.0, \"recall\": 0.3228927934810288, \"specificity\": 1.0, \"npv\": 0.4680226742247416, \"accuracy\": 0.5756689185594979, \"f1\": 0.4881616939364774, \"f2\": 0.3734684260131951, \"f0_5\": 0.7045227247471941, \"p4\": 0.5529710477983298, \"phi\": 0.3887430368416755}, {\"truth_threshold\": 18.04, \"match_probability\": 0.9999962896295986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3793, \"tn\": 7018, \"fp\": 0, \"fn\": 7988, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32195908666496903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.678040913335031, \"precision\": 1.0, \"recall\": 0.32195908666496903, \"specificity\": 1.0, \"npv\": 0.46767959482873517, \"accuracy\": 0.5750837810521836, \"f1\": 0.4870938744060614, \"f2\": 0.3724689200070703, \"f0_5\": 0.7036322487292694, \"p4\": 0.5521658153947323, \"phi\": 0.38803826512716805}, {\"truth_threshold\": 18.080000000000002, \"match_probability\": 0.9999963910895062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3788, \"tn\": 7018, \"fp\": 0, \"fn\": 7993, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32153467447585093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6784653255241491, \"precision\": 1.0, \"recall\": 0.32153467447585093, \"specificity\": 1.0, \"npv\": 0.4675238158683632, \"accuracy\": 0.5748178094579499, \"f1\": 0.48660800308304963, \"f2\": 0.37201445631678187, \"f0_5\": 0.703226525080756, \"p4\": 0.5517992627789532, \"phi\": 0.3877178328951892}, {\"truth_threshold\": 18.1, \"match_probability\": 0.9999964407742665, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3783, \"tn\": 7018, \"fp\": 0, \"fn\": 7998, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3211102622867329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6788897377132671, \"precision\": 1.0, \"recall\": 0.3211102622867329, \"specificity\": 1.0, \"npv\": 0.46736814064997334, \"accuracy\": 0.5745518378637161, \"f1\": 0.4861218195836546, \"f2\": 0.37155990335317346, \"f0_5\": 0.7028201984171218, \"p4\": 0.5514323726586262, \"phi\": 0.3873973492792325}, {\"truth_threshold\": 18.12, \"match_probability\": 0.999996489775007, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3782, \"tn\": 7018, \"fp\": 0, \"fn\": 7999, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3210253798489093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6789746201510908, \"precision\": 1.0, \"recall\": 0.3210253798489093, \"specificity\": 1.0, \"npv\": 0.4673370180462143, \"accuracy\": 0.5744986435448695, \"f1\": 0.4860245453961318, \"f2\": 0.37146898204533846, \"f0_5\": 0.7027388606042588, \"p4\": 0.5513589540504222, \"phi\": 0.38733324635995614}, {\"truth_threshold\": 18.14, \"match_probability\": 0.9999965381011445, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3779, \"tn\": 7018, \"fp\": 0, \"fn\": 8002, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3207707325354384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6792292674645616, \"precision\": 1.0, \"recall\": 0.3207707325354384, \"specificity\": 1.0, \"npv\": 0.46724367509986686, \"accuracy\": 0.5743390605883292, \"f1\": 0.48573264781491005, \"f2\": 0.371196196687818, \"f0_5\": 0.7024947020113768, \"p4\": 0.5511386169204403, \"phi\": 0.3871409251607671}, {\"truth_threshold\": 18.16, \"match_probability\": 0.9999965857619664, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3772, \"tn\": 7018, \"fp\": 0, \"fn\": 8009, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.32017655547067314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6798234445293269, \"precision\": 1.0, \"recall\": 0.32017655547067314, \"specificity\": 1.0, \"npv\": 0.4670260198309709, \"accuracy\": 0.573966700356402, \"f1\": 0.4850511155404102, \"f2\": 0.37055957246149007, \"f0_5\": 0.7019241505080204, \"p4\": 0.550624021689247, \"phi\": 0.38669210276996674}, {\"truth_threshold\": 18.18, \"match_probability\": 0.999996632766632, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3764, \"tn\": 7018, \"fp\": 0, \"fn\": 8017, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3194974959680842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6805025040319158, \"precision\": 1.0, \"recall\": 0.3194974959680842, \"specificity\": 1.0, \"npv\": 0.46677751912204857, \"accuracy\": 0.573541145805628, \"f1\": 0.4842714699260212, \"f2\": 0.3698317874548027, \"f0_5\": 0.7012706338264336, \"p4\": 0.5500350953628864, \"phi\": 0.3861790368905193}, {\"truth_threshold\": 18.2, \"match_probability\": 0.9999966791241749, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3758, \"tn\": 7018, \"fp\": 0, \"fn\": 8023, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31898820134114253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6810117986588575, \"precision\": 1.0, \"recall\": 0.31898820134114253, \"specificity\": 1.0, \"npv\": 0.4665913170666844, \"accuracy\": 0.5732219798925475, \"f1\": 0.4836862088937512, \"f2\": 0.36928579851420934, \"f0_5\": 0.7007794726438668, \"p4\": 0.5495928261143096, \"phi\": 0.38579414846844995}, {\"truth_threshold\": 18.22, \"match_probability\": 0.999996724843504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3757, \"tn\": 7018, \"fp\": 0, \"fn\": 8024, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3189033189033189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6810966810966811, \"precision\": 1.0, \"recall\": 0.3189033189033189, \"specificity\": 1.0, \"npv\": 0.466560297832735, \"accuracy\": 0.5731687855737008, \"f1\": 0.48358862144420134, \"f2\": 0.36919478783828935, \"f0_5\": 0.7006975269499048, \"p4\": 0.5495190665625482, \"phi\": 0.385729992932077}, {\"truth_threshold\": 18.240000000000002, \"match_probability\": 0.9999967699334056, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3751, \"tn\": 7018, \"fp\": 0, \"fn\": 8030, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3183940242763772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6816059757236228, \"precision\": 1.0, \"recall\": 0.3183940242763772, \"specificity\": 1.0, \"npv\": 0.46637426900584794, \"accuracy\": 0.5728496196606202, \"f1\": 0.4830028328611898, \"f2\": 0.36864864864864866, \"f0_5\": 0.7002053388090349, \"p4\": 0.5490762204855568, \"phi\": 0.3853450146657222}, {\"truth_threshold\": 18.26, \"match_probability\": 0.9999968144025453, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3746, \"tn\": 7018, \"fp\": 0, \"fn\": 8035, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31796961208725916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6820303879127408, \"precision\": 1.0, \"recall\": 0.31796961208725916, \"specificity\": 1.0, \"npv\": 0.466219358267455, \"accuracy\": 0.5725836480663865, \"f1\": 0.48251432987698845, \"f2\": 0.36819343424415174, \"f0_5\": 0.699794507752662, \"p4\": 0.5487068030875938, \"phi\": 0.385024140146918}, {\"truth_threshold\": 18.28, \"match_probability\": 0.999996858259469, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3742, \"tn\": 7018, \"fp\": 0, \"fn\": 8039, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3176300823359647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6823699176640353, \"precision\": 1.0, \"recall\": 0.3176300823359647, \"specificity\": 1.0, \"npv\": 0.4660955037524075, \"accuracy\": 0.5723708707909996, \"f1\": 0.48212330090832956, \"f2\": 0.3678291982856918, \"f0_5\": 0.6994654005757225, \"p4\": 0.5484110203957018, \"phi\": 0.38476740146912153}, {\"truth_threshold\": 18.3, \"match_probability\": 0.9999969015126052, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3737, \"tn\": 7018, \"fp\": 0, \"fn\": 8044, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31720567014684664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6827943298531534, \"precision\": 1.0, \"recall\": 0.31720567014684664, \"specificity\": 1.0, \"npv\": 0.46594077811711593, \"accuracy\": 0.5721048991967658, \"f1\": 0.4816342312153628, \"f2\": 0.3673738227718684, \"f0_5\": 0.699053462531333, \"p4\": 0.5480409802440815, \"phi\": 0.3844464290006905}, {\"truth_threshold\": 18.32, \"match_probability\": 0.9999969441702665, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3730, \"tn\": 7018, \"fp\": 0, \"fn\": 8051, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3166114930820813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6833885069179186, \"precision\": 1.0, \"recall\": 0.3166114930820813, \"specificity\": 1.0, \"npv\": 0.4657243347269228, \"accuracy\": 0.5717325389648386, \"f1\": 0.4809490039326929, \"f2\": 0.3667361466158021, \"f0_5\": 0.6984757125201303, \"p4\": 0.5475223402749586, \"phi\": 0.38399697522578224}, {\"truth_threshold\": 18.34, \"match_probability\": 0.9999969862406507, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3727, \"tn\": 7018, \"fp\": 0, \"fn\": 8054, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31635684576861045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6836431542313895, \"precision\": 1.0, \"recall\": 0.31635684576861045, \"specificity\": 1.0, \"npv\": 0.4656316348195329, \"accuracy\": 0.5715729560082983, \"f1\": 0.48065514573123547, \"f2\": 0.3664628030913846, \"f0_5\": 0.6982277342725467, \"p4\": 0.5472998569285122, \"phi\": 0.3838043189980917}, {\"truth_threshold\": 18.36, \"match_probability\": 0.9999970277318428, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3718, \"tn\": 7018, \"fp\": 0, \"fn\": 8063, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31559290382819793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6844070961718021, \"precision\": 1.0, \"recall\": 0.31559290382819793, \"specificity\": 1.0, \"npv\": 0.4653537563822028, \"accuracy\": 0.5710942071386775, \"f1\": 0.47977288857345635, \"f2\": 0.3656425789701428, \"f0_5\": 0.6974824597606273, \"p4\": 0.5466316515249838, \"phi\": 0.38322622990085004}, {\"truth_threshold\": 18.38, \"match_probability\": 0.999997068651817, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3714, \"tn\": 7018, \"fp\": 0, \"fn\": 8067, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3152533740769035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6847466259230965, \"precision\": 1.0, \"recall\": 0.3152533740769035, \"specificity\": 1.0, \"npv\": 0.4652303612860457, \"accuracy\": 0.5708814298632906, \"f1\": 0.47938044530493706, \"f2\": 0.36527794169715566, \"f0_5\": 0.6971505800202725, \"p4\": 0.5463343065538292, \"phi\": 0.3829692430449771}, {\"truth_threshold\": 18.400000000000002, \"match_probability\": 0.999997109008437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3709, \"tn\": 7018, \"fp\": 0, \"fn\": 8072, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3148289618877854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6851710381122146, \"precision\": 1.0, \"recall\": 0.3148289618877854, \"specificity\": 1.0, \"npv\": 0.46507620941020544, \"accuracy\": 0.5706154582690569, \"f1\": 0.4788896061975468, \"f2\": 0.36482206440697973, \"f0_5\": 0.6967351692527333, \"p4\": 0.5459623085821446, \"phi\": 0.3826479585824564}, {\"truth_threshold\": 18.42, \"match_probability\": 0.9999971488094587, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3701, \"tn\": 7018, \"fp\": 0, \"fn\": 8080, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3141499023851965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6858500976148035, \"precision\": 1.0, \"recall\": 0.3141499023851965, \"specificity\": 1.0, \"npv\": 0.4648297787786462, \"accuracy\": 0.5701899037182829, \"f1\": 0.47810360418550574, \"f2\": 0.3640924741760944, \"f0_5\": 0.6960692119616325, \"p4\": 0.5453663774142854, \"phi\": 0.38213378498772416}, {\"truth_threshold\": 18.44, \"match_probability\": 0.999997188062531, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3693, \"tn\": 7018, \"fp\": 0, \"fn\": 8088, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31347084288260757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6865291571173924, \"precision\": 1.0, \"recall\": 0.31347084288260757, \"specificity\": 1.0, \"npv\": 0.46458360916192243, \"accuracy\": 0.569764349167509, \"f1\": 0.4773167894532765, \"f2\": 0.3633626542298837, \"f0_5\": 0.6954016495311264, \"p4\": 0.544769538764761, \"phi\": 0.381619464327269}, {\"truth_threshold\": 18.46, \"match_probability\": 0.9999972267751978, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3689, \"tn\": 7018, \"fp\": 0, \"fn\": 8092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31313131313131315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6868686868686869, \"precision\": 1.0, \"recall\": 0.31313131313131315, \"specificity\": 1.0, \"npv\": 0.4644606221045665, \"accuracy\": 0.5695515718921219, \"f1\": 0.47692307692307695, \"f2\": 0.3629976580796253, \"f0_5\": 0.695067264573991, \"p4\": 0.5444707778475738, \"phi\": 0.381362248390411}, {\"truth_threshold\": 18.48, \"match_probability\": 0.9999972649548987, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3687, \"tn\": 7018, \"fp\": 0, \"fn\": 8094, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3129615482556659, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6870384517443341, \"precision\": 1.0, \"recall\": 0.3129615482556659, \"specificity\": 1.0, \"npv\": 0.46439915299100054, \"accuracy\": 0.5694451832544284, \"f1\": 0.47672614429790533, \"f2\": 0.3628151384542717, \"f0_5\": 0.6948999208413434, \"p4\": 0.5443213117648827, \"phi\": 0.3812336264401179}, {\"truth_threshold\": 18.5, \"match_probability\": 0.9999973026089712, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3679, \"tn\": 7018, \"fp\": 0, \"fn\": 8102, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.312282488753077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.687717511246923, \"precision\": 1.0, \"recall\": 0.312282488753077, \"specificity\": 1.0, \"npv\": 0.46415343915343915, \"accuracy\": 0.5690196287036544, \"f1\": 0.4759379042690815, \"f2\": 0.36208491624510364, \"f0_5\": 0.694229535419104, \"p4\": 0.5437228750948266, \"phi\": 0.38071904489023906}, {\"truth_threshold\": 18.52, \"match_probability\": 0.9999973397446519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3675, \"tn\": 7018, \"fp\": 0, \"fn\": 8106, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31194295900178254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6880570409982175, \"precision\": 1.0, \"recall\": 0.31194295900178254, \"specificity\": 1.0, \"npv\": 0.4640306797143613, \"accuracy\": 0.5688068514282675, \"f1\": 0.47554347826086957, \"f2\": 0.3617197188921042, \"f0_5\": 0.6938937351308485, \"p4\": 0.5434233124463916, \"phi\": 0.3804616975435324}, {\"truth_threshold\": 18.54, \"match_probability\": 0.9999973763690773, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3664, \"tn\": 7018, \"fp\": 0, \"fn\": 8117, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3110092521857228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6889907478142773, \"precision\": 1.0, \"recall\": 0.3110092521857228, \"specificity\": 1.0, \"npv\": 0.46369342583415923, \"accuracy\": 0.5682217139209532, \"f1\": 0.474457753318226, \"f2\": 0.36071512955816337, \"f0_5\": 0.69296818852366, \"p4\": 0.5425983264268889, \"phi\": 0.3797537960470148}, {\"truth_threshold\": 18.56, \"match_probability\": 0.999997412489286, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3663, \"tn\": 7018, \"fp\": 0, \"fn\": 8118, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31092436974789917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6890756302521008, \"precision\": 1.0, \"recall\": 0.31092436974789917, \"specificity\": 1.0, \"npv\": 0.4636627906976744, \"accuracy\": 0.5681685196021065, \"f1\": 0.47435897435897434, \"f2\": 0.36062378167641324, \"f0_5\": 0.6928838951310862, \"p4\": 0.542523240982269, \"phi\": 0.37968942699688973}, {\"truth_threshold\": 18.580000000000002, \"match_probability\": 0.9999974481122197, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3654, \"tn\": 7018, \"fp\": 0, \"fn\": 8127, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.31016042780748665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6898395721925134, \"precision\": 1.0, \"recall\": 0.31016042780748665, \"specificity\": 1.0, \"npv\": 0.4633872565203037, \"accuracy\": 0.5676897707324857, \"f1\": 0.47346938775510206, \"f2\": 0.3598014888337469, \"f0_5\": 0.6921241050119332, \"p4\": 0.5418468190240889, \"phi\": 0.3791099968648611}, {\"truth_threshold\": 18.62, \"match_probability\": 0.9999975178935521, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3649, \"tn\": 7018, \"fp\": 0, \"fn\": 8132, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30973601561836855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6902639843816314, \"precision\": 1.0, \"recall\": 0.30973601561836855, \"specificity\": 1.0, \"npv\": 0.4632343234323432, \"accuracy\": 0.567423799138252, \"f1\": 0.4729747245625405, \"f2\": 0.35934453351190593, \"f0_5\": 0.691701103233878, \"p4\": 0.5414705197473213, \"phi\": 0.3787880061955561}, {\"truth_threshold\": 18.64, \"match_probability\": 0.9999975520653613, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3646, \"tn\": 7018, \"fp\": 0, \"fn\": 8135, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3094813683048977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6905186316951023, \"precision\": 1.0, \"recall\": 0.3094813683048977, \"specificity\": 1.0, \"npv\": 0.4631426120240216, \"accuracy\": 0.5672642161817117, \"f1\": 0.472677772736112, \"f2\": 0.3590703171164073, \"f0_5\": 0.6914469941209938, \"p4\": 0.5412445650010371, \"phi\": 0.3785947824382932}, {\"truth_threshold\": 18.66, \"match_probability\": 0.9999975857667196, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3641, \"tn\": 7018, \"fp\": 0, \"fn\": 8140, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30905695611577966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6909430438842203, \"precision\": 1.0, \"recall\": 0.30905695611577966, \"specificity\": 1.0, \"npv\": 0.4629898403483309, \"accuracy\": 0.566998244587478, \"f1\": 0.47218259629101283, \"f2\": 0.35861321776814736, \"f0_5\": 0.6910229645093946, \"p4\": 0.5408676810699641, \"phi\": 0.378272693662371}, {\"truth_threshold\": 18.68, \"match_probability\": 0.9999976190041034, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3633, \"tn\": 7018, \"fp\": 0, \"fn\": 8148, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3083778966131907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6916221033868093, \"precision\": 1.0, \"recall\": 0.3083778966131907, \"specificity\": 1.0, \"npv\": 0.46274561519187657, \"accuracy\": 0.5665726900367041, \"f1\": 0.4713896457765668, \"f2\": 0.3578816714935871, \"f0_5\": 0.690343176376696, \"p4\": 0.5402639034807261, \"phi\": 0.37775722293537667}, {\"truth_threshold\": 18.7, \"match_probability\": 0.9999976517839005, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3624, \"tn\": 7018, \"fp\": 0, \"fn\": 8157, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3076139546727782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6923860453272218, \"precision\": 1.0, \"recall\": 0.3076139546727782, \"specificity\": 1.0, \"npv\": 0.46247116968698515, \"accuracy\": 0.5660939411670833, \"f1\": 0.47049659201557936, \"f2\": 0.35705840624261054, \"f0_5\": 0.6895764356661719, \"p4\": 0.539583526064603, \"phi\": 0.3771771273944895}, {\"truth_threshold\": 18.72, \"match_probability\": 0.9999976841124106, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3622, \"tn\": 7018, \"fp\": 0, \"fn\": 8159, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30744418979713095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.692555810202869, \"precision\": 1.0, \"recall\": 0.30744418979713095, \"specificity\": 1.0, \"npv\": 0.4624102259998682, \"accuracy\": 0.5659875525293898, \"f1\": 0.4702979938972927, \"f2\": 0.3568754187522169, \"f0_5\": 0.6894057634474094, \"p4\": 0.5394321683550168, \"phi\": 0.3770481896076916}, {\"truth_threshold\": 18.740000000000002, \"match_probability\": 0.9999977159958466, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3618, \"tn\": 7018, \"fp\": 0, \"fn\": 8163, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30710466004583653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6928953399541635, \"precision\": 1.0, \"recall\": 0.30710466004583653, \"specificity\": 1.0, \"npv\": 0.4622883867992886, \"accuracy\": 0.5657747752540029, \"f1\": 0.46990064289888955, \"f2\": 0.35650940049663, \"f0_5\": 0.6890641069592046, \"p4\": 0.5391292749078961, \"phi\": 0.3767902836740004}, {\"truth_threshold\": 18.76, \"match_probability\": 0.9999977474403359, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3611, \"tn\": 7018, \"fp\": 0, \"fn\": 8170, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3065104829810712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6934895170189288, \"precision\": 1.0, \"recall\": 0.3065104829810712, \"specificity\": 1.0, \"npv\": 0.4620753226231235, \"accuracy\": 0.5654024150220757, \"f1\": 0.4692047817047817, \"f2\": 0.35586872967379524, \"f0_5\": 0.688465204957102, \"p4\": 0.538598638789704, \"phi\": 0.3763388503873177}, {\"truth_threshold\": 18.78, \"match_probability\": 0.9999977784519215, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3607, \"tn\": 7018, \"fp\": 0, \"fn\": 8174, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3061709532297768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6938290467702233, \"precision\": 1.0, \"recall\": 0.3061709532297768, \"specificity\": 1.0, \"npv\": 0.4619536598209584, \"accuracy\": 0.5651896377466886, \"f1\": 0.46880686249025216, \"f2\": 0.355502552679821, \"f0_5\": 0.6881224007020489, \"p4\": 0.538295090024822, \"phi\": 0.37608083223605915}, {\"truth_threshold\": 18.8, \"match_probability\": 0.9999978090365634, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3605, \"tn\": 7018, \"fp\": 0, \"fn\": 8176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30600118835412954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6939988116458705, \"precision\": 1.0, \"recall\": 0.30600118835412954, \"specificity\": 1.0, \"npv\": 0.4618928524417533, \"accuracy\": 0.5650832491089952, \"f1\": 0.46860782529572337, \"f2\": 0.3553194425279426, \"f0_5\": 0.6879508415709324, \"p4\": 0.538143225932099, \"phi\": 0.3759518077353201}, {\"truth_threshold\": 18.82, \"match_probability\": 0.9999978392001393, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3601, \"tn\": 7018, \"fp\": 0, \"fn\": 8180, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30566165860283506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6943383413971649, \"precision\": 1.0, \"recall\": 0.30566165860283506, \"specificity\": 1.0, \"npv\": 0.46177128569548626, \"accuracy\": 0.5648704718336082, \"f1\": 0.4682095956312573, \"f2\": 0.354953178905865, \"f0_5\": 0.6876074088218446, \"p4\": 0.5378393179845276, \"phi\": 0.3756937277635148}, {\"truth_threshold\": 18.84, \"match_probability\": 0.9999978689484461, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3593, \"tn\": 7018, \"fp\": 0, \"fn\": 8188, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30498259910024617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6950174008997538, \"precision\": 1.0, \"recall\": 0.30498259910024617, \"specificity\": 1.0, \"npv\": 0.46152834407470733, \"accuracy\": 0.5644449172828342, \"f1\": 0.4674125146350982, \"f2\": 0.35422047834059583, \"f0_5\": 0.686919282682675, \"p4\": 0.537230781122477, \"phi\": 0.37517744326429986}, {\"truth_threshold\": 18.86, \"match_probability\": 0.999997898287201, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3589, \"tn\": 7018, \"fp\": 0, \"fn\": 8192, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3046430693489517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6953569306510483, \"precision\": 1.0, \"recall\": 0.3046430693489517, \"specificity\": 1.0, \"npv\": 0.4614069690992768, \"accuracy\": 0.5642321400074473, \"f1\": 0.4670136629798308, \"f2\": 0.3538540413700629, \"f0_5\": 0.6865745877491678, \"p4\": 0.5369261511085159, \"phi\": 0.3749192383506088}, {\"truth_threshold\": 18.88, \"match_probability\": 0.9999979272220422, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3586, \"tn\": 7018, \"fp\": 0, \"fn\": 8195, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30438842203548083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6956115779645191, \"precision\": 1.0, \"recall\": 0.30438842203548083, \"specificity\": 1.0, \"npv\": 0.4613159797541576, \"accuracy\": 0.564072557050907, \"f1\": 0.4667143879742305, \"f2\": 0.35357917570498915, \"f0_5\": 0.6863157894736842, \"p4\": 0.5366975199531395, \"phi\": 0.37472555709094607}, {\"truth_threshold\": 18.900000000000002, \"match_probability\": 0.9999979557585305, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3579, \"tn\": 7018, \"fp\": 0, \"fn\": 8202, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30379424497071555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6962057550292844, \"precision\": 1.0, \"recall\": 0.30379424497071555, \"specificity\": 1.0, \"npv\": 0.46110381077529566, \"accuracy\": 0.5637001968189798, \"f1\": 0.466015625, \"f2\": 0.35293769599431984, \"f0_5\": 0.6857110012645131, \"p4\": 0.5361635170284237, \"phi\": 0.3742735417413321}, {\"truth_threshold\": 18.92, \"match_probability\": 0.9999979839021501, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3569, \"tn\": 7018, \"fp\": 0, \"fn\": 8212, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3029454205924794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6970545794075206, \"precision\": 1.0, \"recall\": 0.3029454205924794, \"specificity\": 1.0, \"npv\": 0.460801050558109, \"accuracy\": 0.5631682536305123, \"f1\": 0.46501628664495115, \"f2\": 0.352020989091196, \"f0_5\": 0.6848447634033081, \"p4\": 0.535399363088898, \"phi\": 0.3736275793765534}, {\"truth_threshold\": 18.94, \"match_probability\": 0.9999980116583098, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3558, \"tn\": 7018, \"fp\": 0, \"fn\": 8223, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30201171377641967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6979882862235803, \"precision\": 1.0, \"recall\": 0.30201171377641967, \"specificity\": 1.0, \"npv\": 0.4604684731972968, \"accuracy\": 0.562583116123198, \"f1\": 0.4639155094856249, \"f2\": 0.35101219367822895, \"f0_5\": 0.68388882481836, \"p4\": 0.5345570279075527, \"phi\": 0.3729167101784619}, {\"truth_threshold\": 18.96, \"match_probability\": 0.9999980390323437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3557, \"tn\": 7018, \"fp\": 0, \"fn\": 8224, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30192683133859605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.698073168661404, \"precision\": 1.0, \"recall\": 0.30192683133859605, \"specificity\": 1.0, \"npv\": 0.46043826269518434, \"accuracy\": 0.5625299218043512, \"f1\": 0.4638153605424436, \"f2\": 0.3509204632899903, \"f0_5\": 0.6838017609289092, \"p4\": 0.5344803598637977, \"phi\": 0.37285206943586235}, {\"truth_threshold\": 18.98, \"match_probability\": 0.9999980660295127, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3555, \"tn\": 7018, \"fp\": 0, \"fn\": 8226, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3017570664629488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6982429335370511, \"precision\": 1.0, \"recall\": 0.3017570664629488, \"specificity\": 1.0, \"npv\": 0.46037785358173705, \"accuracy\": 0.5624235331666578, \"f1\": 0.4636150234741784, \"f2\": 0.35073699165334754, \"f0_5\": 0.6836275527864313, \"p4\": 0.534326977593949, \"phi\": 0.3727227797724925}, {\"truth_threshold\": 19.02, \"match_probability\": 0.999998118913938, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3552, \"tn\": 7018, \"fp\": 0, \"fn\": 8229, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30150241914947795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.698497580850522, \"precision\": 1.0, \"recall\": 0.30150241914947795, \"specificity\": 1.0, \"npv\": 0.4602872696268118, \"accuracy\": 0.5622639502101175, \"f1\": 0.46331441987869304, \"f2\": 0.3504617570447549, \"f0_5\": 0.6833660394782408, \"p4\": 0.5340967886009037, \"phi\": 0.3725288247856692}, {\"truth_threshold\": 19.04, \"match_probability\": 0.9999981448113576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3545, \"tn\": 7018, \"fp\": 0, \"fn\": 8236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.3009082420847127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6990917579152873, \"precision\": 1.0, \"recall\": 0.3009082420847127, \"specificity\": 1.0, \"npv\": 0.4600760456273764, \"accuracy\": 0.5618915899781903, \"f1\": 0.46261255383009264, \"f2\": 0.3498194162110955, \"f0_5\": 0.6827549015831439, \"p4\": 0.5335591402998887, \"phi\": 0.37207616708816477}, {\"truth_threshold\": 19.06, \"match_probability\": 0.9999981703522411, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3544, \"tn\": 7018, \"fp\": 0, \"fn\": 8237, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30082335964688905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6991766403531109, \"precision\": 1.0, \"recall\": 0.30082335964688905, \"specificity\": 1.0, \"npv\": 0.46004588659455914, \"accuracy\": 0.5618383956593436, \"f1\": 0.4625122349102773, \"f2\": 0.34972763874634877, \"f0_5\": 0.6826674885387372, \"p4\": 0.5334822714810641, \"phi\": 0.3720114906788593}, {\"truth_threshold\": 19.080000000000002, \"match_probability\": 0.999998195541497, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3536, \"tn\": 7018, \"fp\": 0, \"fn\": 8245, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.30014430014430016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6998556998556998, \"precision\": 1.0, \"recall\": 0.30014430014430016, \"specificity\": 1.0, \"npv\": 0.45980475660093034, \"accuracy\": 0.5614128411085696, \"f1\": 0.46170921198668147, \"f2\": 0.348993288590604, \"f0_5\": 0.6819672131147541, \"p4\": 0.5328667619545987, \"phi\": 0.3714939795918724}, {\"truth_threshold\": 19.1, \"match_probability\": 0.9999982203839662, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3533, \"tn\": 7018, \"fp\": 0, \"fn\": 8248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2998896528308293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7001103471691706, \"precision\": 1.0, \"recall\": 0.2998896528308293, \"specificity\": 1.0, \"npv\": 0.45971439800864666, \"accuracy\": 0.5612532581520293, \"f1\": 0.46140786208697926, \"f2\": 0.3487178474840595, \"f0_5\": 0.6817041639331609, \"p4\": 0.5326356890960052, \"phi\": 0.3712998669810518}, {\"truth_threshold\": 19.12, \"match_probability\": 0.9999982448844231, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3530, \"tn\": 7018, \"fp\": 0, \"fn\": 8251, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29963500551735844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7003649944826416, \"precision\": 1.0, \"recall\": 0.29963500551735844, \"specificity\": 1.0, \"npv\": 0.4596240749230467, \"accuracy\": 0.5610936751954891, \"f1\": 0.46110639409574816, \"f2\": 0.3484423737513326, \"f0_5\": 0.6814408710088413, \"p4\": 0.5324044757965407, \"phi\": 0.3711057291736115}, {\"truth_threshold\": 19.14, \"match_probability\": 0.999998269047576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3517, \"tn\": 7018, \"fp\": 0, \"fn\": 8264, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29853153382565145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7014684661743485, \"precision\": 1.0, \"recall\": 0.29853153382565145, \"specificity\": 1.0, \"npv\": 0.4592330846747808, \"accuracy\": 0.5604021490504814, \"f1\": 0.45979866649235196, \"f2\": 0.34724827708773526, \"f0_5\": 0.6802971101396572, \"p4\": 0.5314009227082828, \"phi\": 0.37026417211424545}, {\"truth_threshold\": 19.16, \"match_probability\": 0.9999982928780689, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3512, \"tn\": 7018, \"fp\": 0, \"fn\": 8269, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2981071216365334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7018928783634666, \"precision\": 1.0, \"recall\": 0.2981071216365334, \"specificity\": 1.0, \"npv\": 0.45908288087917837, \"accuracy\": 0.5601361774562477, \"f1\": 0.45929510233440135, \"f2\": 0.3467888458804013, \"f0_5\": 0.6798559758411088, \"p4\": 0.531014233144402, \"phi\": 0.3699403684534839}, {\"truth_threshold\": 19.18, \"match_probability\": 0.9999983163804814, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3504, \"tn\": 7018, \"fp\": 0, \"fn\": 8277, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29742806213394446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7025719378660555, \"precision\": 1.0, \"recall\": 0.29742806213394446, \"specificity\": 1.0, \"npv\": 0.458842759071592, \"accuracy\": 0.5597106229054737, \"f1\": 0.4584887144259078, \"f2\": 0.34605356719601804, \"f0_5\": 0.679148738225375, \"p4\": 0.5303947080778386, \"phi\": 0.36942213341224694}, {\"truth_threshold\": 19.2, \"match_probability\": 0.9999983395593304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3500, \"tn\": 7018, \"fp\": 0, \"fn\": 8281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29708853238265004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.70291146761735, \"precision\": 1.0, \"recall\": 0.29708853238265004, \"specificity\": 1.0, \"npv\": 0.4587227923393686, \"accuracy\": 0.5594978456300868, \"f1\": 0.45808520384791573, \"f2\": 0.3456858407079646, \"f0_5\": 0.678794461037198, \"p4\": 0.5300845650296611, \"phi\": 0.36916294660566107}, {\"truth_threshold\": 19.22, \"match_probability\": 0.9999983624190703, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3498, \"tn\": 7018, \"fp\": 0, \"fn\": 8283, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2969187675070028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7030812324929971, \"precision\": 1.0, \"recall\": 0.2969187675070028, \"specificity\": 1.0, \"npv\": 0.4586628324946082, \"accuracy\": 0.5593914569923932, \"f1\": 0.45788336933045354, \"f2\": 0.3455019556714472, \"f0_5\": 0.678617157490397, \"p4\": 0.52992939812094, \"phi\": 0.3690333357917276}, {\"truth_threshold\": 19.240000000000002, \"match_probability\": 0.9999983849640944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3496, \"tn\": 7018, \"fp\": 0, \"fn\": 8285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29674900263135556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7032509973686444, \"precision\": 1.0, \"recall\": 0.29674900263135556, \"specificity\": 1.0, \"npv\": 0.45860288832255114, \"accuracy\": 0.5592850683546997, \"f1\": 0.45768148196635466, \"f2\": 0.3453180561043066, \"f0_5\": 0.6784397438385407, \"p4\": 0.5297741675247137, \"phi\": 0.36890371333665917}, {\"truth_threshold\": 19.26, \"match_probability\": 0.9999984071987357, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3488, \"tn\": 7018, \"fp\": 0, \"fn\": 8293, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29606994312876667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7039300568712333, \"precision\": 1.0, \"recall\": 0.29606994312876667, \"specificity\": 1.0, \"npv\": 0.4583632682385213, \"accuracy\": 0.5588595138039257, \"f1\": 0.4568734036282664, \"f2\": 0.34458231249506044, \"f0_5\": 0.6777289861267634, \"p4\": 0.529152606794564, \"phi\": 0.36838510659321533}, {\"truth_threshold\": 19.28, \"match_probability\": 0.9999984291272669, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3480, \"tn\": 7018, \"fp\": 0, \"fn\": 8301, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29539088362617777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7046091163738223, \"precision\": 1.0, \"recall\": 0.29539088362617777, \"specificity\": 1.0, \"npv\": 0.45812389842679024, \"accuracy\": 0.5584339592531518, \"f1\": 0.4560644780813839, \"f2\": 0.3438463362580033, \"f0_5\": 0.6770164585035602, \"p4\": 0.5285300211717017, \"phi\": 0.3678663115406993}, {\"truth_threshold\": 19.32, \"match_probability\": 0.9999984720827987, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3477, \"tn\": 7018, \"fp\": 0, \"fn\": 8304, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2951362363127069, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7048637636872931, \"precision\": 1.0, \"recall\": 0.2951362363127069, \"specificity\": 1.0, \"npv\": 0.45803419919070615, \"accuracy\": 0.5582743762966115, \"f1\": 0.4557609123082973, \"f2\": 0.3435702851722298, \"f0_5\": 0.6767488029896065, \"p4\": 0.5282962863661264, \"phi\": 0.36767171451126035}, {\"truth_threshold\": 19.34, \"match_probability\": 0.9999984931180547, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3473, \"tn\": 7018, \"fp\": 0, \"fn\": 8308, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29479670656141244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7052032934385876, \"precision\": 1.0, \"recall\": 0.29479670656141244, \"specificity\": 1.0, \"npv\": 0.45791465483492105, \"accuracy\": 0.5580615990212245, \"f1\": 0.4553559722040121, \"f2\": 0.3432021661363322, \"f0_5\": 0.6763915397499318, \"p4\": 0.5279844142928972, \"phi\": 0.3674122101013257}, {\"truth_threshold\": 19.36, \"match_probability\": 0.9999985138637129, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3469, \"tn\": 7018, \"fp\": 0, \"fn\": 8312, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29445717681011796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.705542823189882, \"precision\": 1.0, \"recall\": 0.29445717681011796, \"specificity\": 1.0, \"npv\": 0.457795172863666, \"accuracy\": 0.5578488217458375, \"f1\": 0.45495081967213113, \"f2\": 0.34283398889174393, \"f0_5\": 0.6760338309233348, \"p4\": 0.5276722837692643, \"phi\": 0.3671526578396717}, {\"truth_threshold\": 19.38, \"match_probability\": 0.9999985343237603, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3464, \"tn\": 7018, \"fp\": 0, \"fn\": 8317, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2940327646209999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7059672353790001, \"precision\": 1.0, \"recall\": 0.2940327646209999, \"specificity\": 1.0, \"npv\": 0.45764590805347244, \"accuracy\": 0.5575828501516038, \"f1\": 0.4544440800262381, \"f2\": 0.34237368545900215, \"f0_5\": 0.675586067012521, \"p4\": 0.527281756257918, \"phi\": 0.36682814990462553}, {\"truth_threshold\": 19.400000000000002, \"match_probability\": 0.999998554502129, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3459, \"tn\": 7018, \"fp\": 0, \"fn\": 8322, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2936083524318818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7063916475681181, \"precision\": 1.0, \"recall\": 0.2936083524318818, \"specificity\": 1.0, \"npv\": 0.457496740547588, \"accuracy\": 0.5573168785573701, \"f1\": 0.45393700787401575, \"f2\": 0.3419132910266295, \"f0_5\": 0.675137603934887, \"p4\": 0.5268908228123704, \"phi\": 0.36650356646986865}, {\"truth_threshold\": 19.42, \"match_probability\": 0.999998574402697, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3454, \"tn\": 7018, \"fp\": 0, \"fn\": 8327, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2931839402427638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7068160597572363, \"precision\": 1.0, \"recall\": 0.2931839402427638, \"specificity\": 1.0, \"npv\": 0.45734767025089607, \"accuracy\": 0.5570509069631363, \"f1\": 0.45342960288808665, \"f2\": 0.34145280556763813, \"f0_5\": 0.6746884400515686, \"p4\": 0.5264994822574626, \"phi\": 0.3661789071273848}, {\"truth_threshold\": 19.44, \"match_probability\": 0.9999985940292888, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3444, \"tn\": 7018, \"fp\": 0, \"fn\": 8337, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29233511586452765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7076648841354723, \"precision\": 1.0, \"recall\": 0.29233511586452765, \"specificity\": 1.0, \"npv\": 0.4570498209052426, \"accuracy\": 0.5565189637746689, \"f1\": 0.45241379310344826, \"f2\": 0.34053156146179403, \"f0_5\": 0.6737880032867708, \"p4\": 0.525715575099044, \"phi\": 0.3655293590810398}, {\"truth_threshold\": 19.46, \"match_probability\": 0.9999986133856762, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3442, \"tn\": 7018, \"fp\": 0, \"fn\": 8339, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2921653509888804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7078346490111196, \"precision\": 1.0, \"recall\": 0.2921653509888804, \"specificity\": 1.0, \"npv\": 0.4569902975841636, \"accuracy\": 0.5564125751369754, \"f1\": 0.45221047099783224, \"f2\": 0.3403472689158723, \"f0_5\": 0.673607577595992, \"p4\": 0.5255585968552018, \"phi\": 0.3653994125504173}, {\"truth_threshold\": 19.48, \"match_probability\": 0.9999986324755792, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3440, \"tn\": 7018, \"fp\": 0, \"fn\": 8341, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2919955861132332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7080044138867668, \"precision\": 1.0, \"recall\": 0.2919955861132332, \"specificity\": 1.0, \"npv\": 0.45693078976495866, \"accuracy\": 0.5563061864992819, \"f1\": 0.45200709546021944, \"f2\": 0.34016296179099753, \"f0_5\": 0.6734270388786657, \"p4\": 0.5254015528298486, \"phi\": 0.36526945365113905}, {\"truth_threshold\": 19.5, \"match_probability\": 0.9999986513026666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3425, \"tn\": 7018, \"fp\": 0, \"fn\": 8356, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.29072234954587894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7092776504541211, \"precision\": 1.0, \"recall\": 0.29072234954587894, \"specificity\": 1.0, \"npv\": 0.45648497463249643, \"accuracy\": 0.5555082717165807, \"f1\": 0.45048007365513615, \"f2\": 0.3387801934756375, \"f0_5\": 0.6720693850319847, \"p4\": 0.5242216181395665, \"phi\": 0.3642943649818788}, {\"truth_threshold\": 19.52, \"match_probability\": 0.9999986698705566, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3413, \"tn\": 7018, \"fp\": 0, \"fn\": 8368, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28970376029199557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7102962397080044, \"precision\": 1.0, \"recall\": 0.28970376029199557, \"specificity\": 1.0, \"npv\": 0.45612894839464446, \"accuracy\": 0.5548699398904197, \"f1\": 0.44925628537580625, \"f2\": 0.33767338781486833, \"f0_5\": 0.6709786497857114, \"p4\": 0.5232749813944947, \"phi\": 0.3635137845088713}, {\"truth_threshold\": 19.54, \"match_probability\": 0.9999986881828178, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3410, \"tn\": 7018, \"fp\": 0, \"fn\": 8371, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28944911297852477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7105508870214753, \"precision\": 1.0, \"recall\": 0.28944911297852477, \"specificity\": 1.0, \"npv\": 0.45604002859185133, \"accuracy\": 0.5547103569338795, \"f1\": 0.4489500362056481, \"f2\": 0.3373966042664345, \"f0_5\": 0.6707053223712679, \"p4\": 0.5230379465643404, \"phi\": 0.36331856786931827}, {\"truth_threshold\": 19.56, \"match_probability\": 0.9999987062429692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3407, \"tn\": 7018, \"fp\": 0, \"fn\": 8374, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2891944656650539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7108055343349461, \"precision\": 1.0, \"recall\": 0.2891944656650539, \"specificity\": 1.0, \"npv\": 0.45595114345114346, \"accuracy\": 0.5545507739773392, \"f1\": 0.44864366605214645, \"f2\": 0.3371197878530011, \"f0_5\": 0.6704317367861782, \"p4\": 0.5228007609522615, \"phi\": 0.3631233224398066}, {\"truth_threshold\": 19.580000000000002, \"match_probability\": 0.9999987240544819, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3403, \"tn\": 7018, \"fp\": 0, \"fn\": 8378, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28885493591375944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7111450640862406, \"precision\": 1.0, \"recall\": 0.28885493591375944, \"specificity\": 1.0, \"npv\": 0.4558326838139777, \"accuracy\": 0.5543379967019523, \"f1\": 0.4482349841938883, \"f2\": 0.3367506481683061, \"f0_5\": 0.6700665537746623, \"p4\": 0.5224842784649693, \"phi\": 0.3628629502587492}, {\"truth_threshold\": 19.6, \"match_probability\": 0.9999987416207787, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3398, \"tn\": 7018, \"fp\": 0, \"fn\": 8383, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2884305237246414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7115694762753586, \"precision\": 1.0, \"recall\": 0.2884305237246414, \"specificity\": 1.0, \"npv\": 0.4556846957989741, \"accuracy\": 0.5540720251077185, \"f1\": 0.44772382897424073, \"f2\": 0.33628914136415816, \"f0_5\": 0.6696094273440271, \"p4\": 0.5220882967905419, \"phi\": 0.3625374125005611}, {\"truth_threshold\": 19.62, \"match_probability\": 0.9999987589452358, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3391, \"tn\": 7018, \"fp\": 0, \"fn\": 8390, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28783634665987606, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7121636533401239, \"precision\": 1.0, \"recall\": 0.28783634665987606, \"specificity\": 1.0, \"npv\": 0.4554776739356179, \"accuracy\": 0.5536996648757913, \"f1\": 0.44700764566306356, \"f2\": 0.33564287835296447, \"f0_5\": 0.668968238311304, \"p4\": 0.521533213595068, \"phi\": 0.36208152348713746}, {\"truth_threshold\": 19.64, \"match_probability\": 0.9999987760311826, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3390, \"tn\": 7018, \"fp\": 0, \"fn\": 8391, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28775146422205244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7122485357779476, \"precision\": 1.0, \"recall\": 0.28775146422205244, \"specificity\": 1.0, \"npv\": 0.45544811473814006, \"accuracy\": 0.5536464705569445, \"f1\": 0.44690527981016415, \"f2\": 0.33555054044423327, \"f0_5\": 0.6688765242097786, \"p4\": 0.5214538483156448, \"phi\": 0.3620163834594688}, {\"truth_threshold\": 19.66, \"match_probability\": 0.9999987928819026, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3386, \"tn\": 7018, \"fp\": 0, \"fn\": 8395, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.287411934470758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.712588065529242, \"precision\": 1.0, \"recall\": 0.287411934470758, \"specificity\": 1.0, \"npv\": 0.4553299163044183, \"accuracy\": 0.5534336932815576, \"f1\": 0.4464956814135953, \"f2\": 0.3351811522470798, \"f0_5\": 0.6685093780848963, \"p4\": 0.5211362176033458, \"phi\": 0.36175579064814045}, {\"truth_threshold\": 19.68, \"match_probability\": 0.9999988095006345, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3381, \"tn\": 7018, \"fp\": 0, \"fn\": 8400, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28698752228163993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7130124777183601, \"precision\": 1.0, \"recall\": 0.28698752228163993, \"specificity\": 1.0, \"npv\": 0.45518225450771826, \"accuracy\": 0.5531677216873238, \"f1\": 0.44598337950138506, \"f2\": 0.33471933471933474, \"f0_5\": 0.6680497925311203, \"p4\": 0.5207387968833965, \"phi\": 0.3614299758013174}, {\"truth_threshold\": 19.7, \"match_probability\": 0.9999988258905718, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3379, \"tn\": 7018, \"fp\": 0, \"fn\": 8402, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2868177574059927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7131822425940073, \"precision\": 1.0, \"recall\": 0.2868177574059927, \"specificity\": 1.0, \"npv\": 0.4551232166018158, \"accuracy\": 0.5530613330496303, \"f1\": 0.445778364116095, \"f2\": 0.3345345821040334, \"f0_5\": 0.6678657548325888, \"p4\": 0.5205797093940855, \"phi\": 0.36129962680458816}, {\"truth_threshold\": 19.72, \"match_probability\": 0.9999988420548644, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3373, \"tn\": 7018, \"fp\": 0, \"fn\": 8408, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28630846277905103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.713691537220949, \"precision\": 1.0, \"recall\": 0.28630846277905103, \"specificity\": 1.0, \"npv\": 0.4549461947361597, \"accuracy\": 0.5527421671365498, \"f1\": 0.44516299326910386, \"f2\": 0.3339802364496901, \"f0_5\": 0.6673129426660863, \"p4\": 0.5201020372022461, \"phi\": 0.36090850040154043}, {\"truth_threshold\": 19.740000000000002, \"match_probability\": 0.9999988579966191, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3370, \"tn\": 7018, \"fp\": 0, \"fn\": 8411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2860538154655802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7139461845344198, \"precision\": 1.0, \"recall\": 0.2860538154655802, \"specificity\": 1.0, \"npv\": 0.454857735433275, \"accuracy\": 0.5525825841800096, \"f1\": 0.4448551250742525, \"f2\": 0.3337030142195112, \"f0_5\": 0.6670361426705198, \"p4\": 0.5198629701433113, \"phi\": 0.36071289236000664}, {\"truth_threshold\": 19.76, \"match_probability\": 0.9999988737188994, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3362, \"tn\": 7018, \"fp\": 0, \"fn\": 8419, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2853747559629913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7146252440370088, \"precision\": 1.0, \"recall\": 0.2853747559629913, \"specificity\": 1.0, \"npv\": 0.45462201204897323, \"accuracy\": 0.5521570296292356, \"f1\": 0.4440335468533316, \"f2\": 0.3329635938676069, \"f0_5\": 0.6662967220262397, \"p4\": 0.5192247027248313, \"phi\": 0.36019112391045927}, {\"truth_threshold\": 19.78, \"match_probability\": 0.9999988892247269, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3359, \"tn\": 7018, \"fp\": 0, \"fn\": 8422, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2851201086495204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7148798913504796, \"precision\": 1.0, \"recall\": 0.2851201086495204, \"specificity\": 1.0, \"npv\": 0.4545336787564767, \"accuracy\": 0.5519974466726953, \"f1\": 0.4437252311756935, \"f2\": 0.33268625081710673, \"f0_5\": 0.6660189554665503, \"p4\": 0.5189850684473687, \"phi\": 0.35999540534833613}, {\"truth_threshold\": 19.8, \"match_probability\": 0.9999989045170816, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3352, \"tn\": 7018, \"fp\": 0, \"fn\": 8429, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2845259315847551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7154740684152449, \"precision\": 1.0, \"recall\": 0.2845259315847551, \"specificity\": 1.0, \"npv\": 0.45432770117174853, \"accuracy\": 0.5516250864407681, \"f1\": 0.44300535254080486, \"f2\": 0.33203898882637295, \"f0_5\": 0.6653698042796459, \"p4\": 0.5184253172706496, \"phi\": 0.35953861047271685}, {\"truth_threshold\": 19.82, \"match_probability\": 0.9999989195989024, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3349, \"tn\": 7018, \"fp\": 0, \"fn\": 8432, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2842712842712843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7157287157287158, \"precision\": 1.0, \"recall\": 0.2842712842712843, \"specificity\": 1.0, \"npv\": 0.45423948220064725, \"accuracy\": 0.5514655034842278, \"f1\": 0.44269662921348313, \"f2\": 0.33176153587066354, \"f0_5\": 0.6650911546252533, \"p4\": 0.5181851641683414, \"phi\": 0.3593427903435676}, {\"truth_threshold\": 19.84, \"match_probability\": 0.9999989344730877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3347, \"tn\": 7018, \"fp\": 0, \"fn\": 8434, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28410151939563705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.715898480604363, \"precision\": 1.0, \"recall\": 0.28410151939563705, \"specificity\": 1.0, \"npv\": 0.45418068858400207, \"accuracy\": 0.5513591148465344, \"f1\": 0.44249074563722895, \"f2\": 0.3315765489092746, \"f0_5\": 0.6649052405737217, \"p4\": 0.5180249753172141, \"phi\": 0.3592122265553772}, {\"truth_threshold\": 19.86, \"match_probability\": 0.9999989491424962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3343, \"tn\": 7018, \"fp\": 0, \"fn\": 8438, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28376198964434257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7162380103556574, \"precision\": 1.0, \"recall\": 0.28376198964434257, \"specificity\": 1.0, \"npv\": 0.4540631469979296, \"accuracy\": 0.5511463375711474, \"f1\": 0.44207881512827296, \"f2\": 0.3312065310004557, \"f0_5\": 0.6645330576869558, \"p4\": 0.5177043889701958, \"phi\": 0.35895105796794097}, {\"truth_threshold\": 19.88, \"match_probability\": 0.999998963609947, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3340, \"tn\": 7018, \"fp\": 0, \"fn\": 8441, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28350734233087177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7164926576691283, \"precision\": 1.0, \"recall\": 0.28350734233087177, \"specificity\": 1.0, \"npv\": 0.4539750307264377, \"accuracy\": 0.5509867546146071, \"f1\": 0.4417697242245883, \"f2\": 0.3309289790741915, \"f0_5\": 0.6642536096416213, \"p4\": 0.5174637663250676, \"phi\": 0.3587551455321975}, {\"truth_threshold\": 19.900000000000002, \"match_probability\": 0.9999989778782205, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3338, \"tn\": 7018, \"fp\": 0, \"fn\": 8443, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28333757745522453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7166624225447755, \"precision\": 1.0, \"recall\": 0.28333757745522453, \"specificity\": 1.0, \"npv\": 0.4539163055429791, \"accuracy\": 0.5508803659769137, \"f1\": 0.44156359547589125, \"f2\": 0.33074392612262693, \"f0_5\": 0.6640671626944654, \"p4\": 0.5173032639872827, \"phi\": 0.358624520048439}, {\"truth_threshold\": 19.92, \"match_probability\": 0.9999989919500589, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3328, \"tn\": 7018, \"fp\": 0, \"fn\": 8453, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2824887530769884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7175112469230116, \"precision\": 1.0, \"recall\": 0.2824887530769884, \"specificity\": 1.0, \"npv\": 0.45362290737508887, \"accuracy\": 0.5503484227884462, \"f1\": 0.44053213316566286, \"f2\": 0.3298184412907318, \"f0_5\": 0.6631331447017096, \"p4\": 0.5164997023358583, \"phi\": 0.35797118525315286}, {\"truth_threshold\": 19.94, \"match_probability\": 0.9999990058281665, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3325, \"tn\": 7018, \"fp\": 0, \"fn\": 8456, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28223410576351754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7177658942364825, \"precision\": 1.0, \"recall\": 0.28223410576351754, \"specificity\": 1.0, \"npv\": 0.4535349618715264, \"accuracy\": 0.5501888398319059, \"f1\": 0.4402224281742354, \"f2\": 0.3295407242958235, \"f0_5\": 0.6628523583589171, \"p4\": 0.5162582916017256, \"phi\": 0.35777511707258414}, {\"truth_threshold\": 19.96, \"match_probability\": 0.9999990195152105, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3314, \"tn\": 7018, \"fp\": 0, \"fn\": 8467, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2813003989474578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7186996010525423, \"precision\": 1.0, \"recall\": 0.2813003989474578, \"specificity\": 1.0, \"npv\": 0.45321278656764613, \"accuracy\": 0.5496037023245918, \"f1\": 0.4390857899966876, \"f2\": 0.32852214600103097, \"f0_5\": 0.6618205056516355, \"p4\": 0.5153717611536789, \"phi\": 0.35705593073014186}, {\"truth_threshold\": 19.98, \"match_probability\": 0.9999990330138213, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3310, \"tn\": 7018, \"fp\": 0, \"fn\": 8471, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2809608691961633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7190391308038366, \"precision\": 1.0, \"recall\": 0.2809608691961633, \"specificity\": 1.0, \"npv\": 0.45309574536768027, \"accuracy\": 0.5493909250492047, \"f1\": 0.4386720561924326, \"f2\": 0.32815164373240274, \"f0_5\": 0.6614443867151593, \"p4\": 0.5150488555842083, \"phi\": 0.3567943027117823}, {\"truth_threshold\": 20.0, \"match_probability\": 0.9999990463265931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3306, \"tn\": 7018, \"fp\": 0, \"fn\": 8475, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28062133944486883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7193786605551311, \"precision\": 1.0, \"recall\": 0.28062133944486883, \"specificity\": 1.0, \"npv\": 0.4529787646033693, \"accuracy\": 0.5491781477738178, \"f1\": 0.438258103002585, \"f2\": 0.3277810826888757, \"f0_5\": 0.6610677864427115, \"p4\": 0.5147256658347954, \"phi\": 0.3565326179511202}, {\"truth_threshold\": 20.02, \"match_probability\": 0.9999990594560844, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3303, \"tn\": 7018, \"fp\": 0, \"fn\": 8478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.28036669213139803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.719633307868602, \"precision\": 1.0, \"recall\": 0.28036669213139803, \"specificity\": 1.0, \"npv\": 0.45289106866288076, \"accuracy\": 0.5490185648172775, \"f1\": 0.4379474940334129, \"f2\": 0.3275031233267892, \"f0_5\": 0.6607850198055456, \"p4\": 0.5144830866276557, \"phi\": 0.3563363170052496}, {\"truth_threshold\": 20.04, \"match_probability\": 0.9999990724048183, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3298, \"tn\": 7018, \"fp\": 0, \"fn\": 8483, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27994227994227994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7200577200577201, \"precision\": 1.0, \"recall\": 0.27994227994227994, \"specificity\": 1.0, \"npv\": 0.4527449841945681, \"accuracy\": 0.5487525932230438, \"f1\": 0.4374295377677565, \"f2\": 0.3270397842211733, \"f0_5\": 0.6603131381892444, \"p4\": 0.514078431120826, \"phi\": 0.356009077282952}, {\"truth_threshold\": 20.06, \"match_probability\": 0.9999990851752837, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3292, \"tn\": 7018, \"fp\": 0, \"fn\": 8489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2794329853153383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7205670146846618, \"precision\": 1.0, \"recall\": 0.2794329853153383, \"specificity\": 1.0, \"npv\": 0.4525698071838525, \"accuracy\": 0.5484334273099633, \"f1\": 0.4368075366549459, \"f2\": 0.32648365598222784, \"f0_5\": 0.6597458815984608, \"p4\": 0.5135922541284914, \"phi\": 0.3556162711195467}, {\"truth_threshold\": 20.080000000000002, \"match_probability\": 0.9999990977699345, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3282, \"tn\": 7018, \"fp\": 0, \"fn\": 8499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2785841609371021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7214158390628979, \"precision\": 1.0, \"recall\": 0.2785841609371021, \"specificity\": 1.0, \"npv\": 0.4522781465489463, \"accuracy\": 0.5479014841214959, \"f1\": 0.4357697669786895, \"f2\": 0.3255564813712653, \"f0_5\": 0.6587980248103096, \"p4\": 0.5127805220005227, \"phi\": 0.354961304886217}, {\"truth_threshold\": 20.1, \"match_probability\": 0.9999991101911914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3277, \"tn\": 7018, \"fp\": 0, \"fn\": 8504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27815974874798405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.721840251252016, \"precision\": 1.0, \"recall\": 0.27815974874798405, \"specificity\": 1.0, \"npv\": 0.45213245715758277, \"accuracy\": 0.5476355125272621, \"f1\": 0.43525036525434985, \"f2\": 0.3250927560961092, \"f0_5\": 0.6583229539153843, \"p4\": 0.512373979495582, \"phi\": 0.35463368520737265}, {\"truth_threshold\": 20.12, \"match_probability\": 0.9999991224414414, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3272, \"tn\": 7018, \"fp\": 0, \"fn\": 8509, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27773533655886595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.722264663441134, \"precision\": 1.0, \"recall\": 0.27773533655886595, \"specificity\": 1.0, \"npv\": 0.45198686159592966, \"accuracy\": 0.5473695409330284, \"f1\": 0.43473061848136585, \"f2\": 0.32462893880466703, \"f0_5\": 0.657847118903052, \"p4\": 0.5119669842561134, \"phi\": 0.3543059738778491}, {\"truth_threshold\": 20.14, \"match_probability\": 0.999999134523039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3262, \"tn\": 7018, \"fp\": 0, \"fn\": 8519, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2768865121806298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7231134878193701, \"precision\": 1.0, \"recall\": 0.2768865121806298, \"specificity\": 1.0, \"npv\": 0.45169595159940784, \"accuracy\": 0.5468375977445609, \"f1\": 0.43369008841321544, \"f2\": 0.32370102806335094, \"f0_5\": 0.6568931491401184, \"p4\": 0.5111516302239516, \"phi\": 0.3536502744300796}, {\"truth_threshold\": 20.16, \"match_probability\": 0.9999991464383059, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3259, \"tn\": 7018, \"fp\": 0, \"fn\": 8522, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27663186486715896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.723368135132841, \"precision\": 1.0, \"recall\": 0.27663186486715896, \"specificity\": 1.0, \"npv\": 0.45160875160875164, \"accuracy\": 0.5466780147880207, \"f1\": 0.4333776595744681, \"f2\": 0.3234225830141119, \"f0_5\": 0.6566063585445461, \"p4\": 0.5109066682336013, \"phi\": 0.35345349219926875}, {\"truth_threshold\": 20.18, \"match_probability\": 0.9999991581895321, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3251, \"tn\": 7018, \"fp\": 0, \"fn\": 8530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27595280536457006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7240471946354299, \"precision\": 1.0, \"recall\": 0.27595280536457006, \"specificity\": 1.0, \"npv\": 0.4513763828145099, \"accuracy\": 0.5462524602372467, \"f1\": 0.4325439063331559, \"f2\": 0.3226799007444169, \"f0_5\": 0.6558402259431108, \"p4\": 0.5102526301483397, \"phi\": 0.3529285750870509}, {\"truth_threshold\": 20.2, \"match_probability\": 0.999999169778976, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3248, \"tn\": 7018, \"fp\": 0, \"fn\": 8533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2756981580510992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7243018419489008, \"precision\": 1.0, \"recall\": 0.2756981580510992, \"specificity\": 1.0, \"npv\": 0.4512893061539451, \"accuracy\": 0.5460928772807064, \"f1\": 0.43223102002794594, \"f2\": 0.32240133407448585, \"f0_5\": 0.6555524159367053, \"p4\": 0.5100070627402978, \"phi\": 0.35273166919742444}, {\"truth_threshold\": 20.22, \"match_probability\": 0.9999991812088648, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3240, \"tn\": 7018, \"fp\": 0, \"fn\": 8541, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2750190985485103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7249809014514896, \"precision\": 1.0, \"recall\": 0.2750190985485103, \"specificity\": 1.0, \"npv\": 0.4510572658911241, \"accuracy\": 0.5456673227299325, \"f1\": 0.4313960455362493, \"f2\": 0.32165832737669764, \"f0_5\": 0.65478355765733, \"p4\": 0.50935140495108, \"phi\": 0.3522064205251413}, {\"truth_threshold\": 20.240000000000002, \"match_probability\": 0.9999991924813951, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3233, \"tn\": 7018, \"fp\": 0, \"fn\": 8548, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27442492148374503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.725575078516255, \"precision\": 1.0, \"recall\": 0.27442492148374503, \"specificity\": 1.0, \"npv\": 0.45085442631376077, \"accuracy\": 0.5452949624980052, \"f1\": 0.43066471293459435, \"f2\": 0.3210080028595826, \"f0_5\": 0.6541091733095942, \"p4\": 0.508776732833686, \"phi\": 0.35174662833032627}, {\"truth_threshold\": 20.28, \"match_probability\": 0.9999992145630165, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3226, \"tn\": 7018, \"fp\": 0, \"fn\": 8555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2738307444189797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7261692555810203, \"precision\": 1.0, \"recall\": 0.2738307444189797, \"specificity\": 1.0, \"npv\": 0.4506517690875233, \"accuracy\": 0.544922602266078, \"f1\": 0.429932698074232, \"f2\": 0.32035749751737835, \"f0_5\": 0.653433259064209, \"p4\": 0.508201149990203, \"phi\": 0.3512866484837798}, {\"truth_threshold\": 20.3, \"match_probability\": 0.9999992253763512, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3224, \"tn\": 7018, \"fp\": 0, \"fn\": 8557, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27366097954333246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7263390204566675, \"precision\": 1.0, \"recall\": 0.27366097954333246, \"specificity\": 1.0, \"npv\": 0.4505939004815409, \"accuracy\": 0.5448162136283845, \"f1\": 0.42972342552482506, \"f2\": 0.32017160562485103, \"f0_5\": 0.6532398589779957, \"p4\": 0.5080365299438622, \"phi\": 0.35115519102247283}, {\"truth_threshold\": 20.32, \"match_probability\": 0.9999992360408158, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3216, \"tn\": 7018, \"fp\": 0, \"fn\": 8565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27298192004074356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7270180799592564, \"precision\": 1.0, \"recall\": 0.27298192004074356, \"specificity\": 1.0, \"npv\": 0.4503625746005262, \"accuracy\": 0.5443906590776105, \"f1\": 0.4288857771554311, \"f2\": 0.31942789034564956, \"f0_5\": 0.6524650030432136, \"p4\": 0.5073773014477151, \"phi\": 0.35062920632620476}, {\"truth_threshold\": 20.34, \"match_probability\": 0.9999992465584596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3210, \"tn\": 7018, \"fp\": 0, \"fn\": 8571, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2724726254138019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7275273745861981, \"precision\": 1.0, \"recall\": 0.2724726254138019, \"specificity\": 1.0, \"npv\": 0.4501892359997434, \"accuracy\": 0.5440714931645301, \"f1\": 0.4282569541725035, \"f2\": 0.31886994874240077, \"f0_5\": 0.6518825392957232, \"p4\": 0.5068820918594612, \"phi\": 0.35023455435733886}, {\"truth_threshold\": 20.36, \"match_probability\": 0.9999992569313043, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3202, \"tn\": 7018, \"fp\": 0, \"fn\": 8579, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27179356591121295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.728206434088787, \"precision\": 1.0, \"recall\": 0.27179356591121295, \"specificity\": 1.0, \"npv\": 0.4499583253189716, \"accuracy\": 0.5436459386137561, \"f1\": 0.42741774010545286, \"f2\": 0.3181258196558439, \"f0_5\": 0.6511041522632072, \"p4\": 0.5062207568695092, \"phi\": 0.34970813223298214}, {\"truth_threshold\": 20.38, \"match_probability\": 0.9999992671613431, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3196, \"tn\": 7018, \"fp\": 0, \"fn\": 8585, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2712842712842713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7287157287157288, \"precision\": 1.0, \"recall\": 0.2712842712842713, \"specificity\": 1.0, \"npv\": 0.4497852976991604, \"accuracy\": 0.5433267727006755, \"f1\": 0.4267877412031782, \"f2\": 0.31756756756756754, \"f0_5\": 0.6505190311418685, \"p4\": 0.5057239608317907, \"phi\": 0.3493131499395575}, {\"truth_threshold\": 20.400000000000002, \"match_probability\": 0.9999992772505422, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3194, \"tn\": 7018, \"fp\": 0, \"fn\": 8587, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27111450640862406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.728885493591376, \"precision\": 1.0, \"recall\": 0.27111450640862406, \"specificity\": 1.0, \"npv\": 0.44972765139378407, \"accuracy\": 0.5432203840629821, \"f1\": 0.4265776293823038, \"f2\": 0.3173814539528598, \"f0_5\": 0.6503237366127784, \"p4\": 0.5055582102824742, \"phi\": 0.34918145744861007}, {\"truth_threshold\": 20.42, \"match_probability\": 0.9999992872008404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3192, \"tn\": 7018, \"fp\": 0, \"fn\": 8589, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2709447415329768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7290552584670231, \"precision\": 1.0, \"recall\": 0.2709447415329768, \"specificity\": 1.0, \"npv\": 0.449670019862882, \"accuracy\": 0.5431139954252886, \"f1\": 0.426367461430575, \"f2\": 0.31719532554257096, \"f0_5\": 0.6501283147989735, \"p4\": 0.5053923836474814, \"phi\": 0.3490497490428508}, {\"truth_threshold\": 20.44, \"match_probability\": 0.9999992970141501, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3188, \"tn\": 7018, \"fp\": 0, \"fn\": 8593, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2706052117816824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7293947882183176, \"precision\": 1.0, \"recall\": 0.2706052117816824, \"specificity\": 1.0, \"npv\": 0.4495548011017872, \"accuracy\": 0.5429012181499016, \"f1\": 0.42594695704455876, \"f2\": 0.3168230243281921, \"f0_5\": 0.6497370888191416, \"p4\": 0.5050605017580366, \"phi\": 0.348786284362819}, {\"truth_threshold\": 20.46, \"match_probability\": 0.9999993066923574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3185, \"tn\": 7018, \"fp\": 0, \"fn\": 8596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.27035056446821154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7296494355317885, \"precision\": 1.0, \"recall\": 0.27035056446821154, \"specificity\": 1.0, \"npv\": 0.4494684257717433, \"accuracy\": 0.5427416351933614, \"f1\": 0.4256314312441534, \"f2\": 0.3165437595658828, \"f0_5\": 0.6494433342848986, \"p4\": 0.5048113899414609, \"phi\": 0.3485886438454776}, {\"truth_threshold\": 20.48, \"match_probability\": 0.9999993162373221, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3180, \"tn\": 7018, \"fp\": 0, \"fn\": 8601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26992615227909345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7300738477209066, \"precision\": 1.0, \"recall\": 0.26992615227909345, \"specificity\": 1.0, \"npv\": 0.44932454062359944, \"accuracy\": 0.5424756635991276, \"f1\": 0.4251052737116503, \"f2\": 0.3160782442748092, \"f0_5\": 0.6489531039549407, \"p4\": 0.5043958209570718, \"phi\": 0.34825916265778195}, {\"truth_threshold\": 20.5, \"match_probability\": 0.9999993256508786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3175, \"tn\": 7018, \"fp\": 0, \"fn\": 8606, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2695017400899754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7304982599100246, \"precision\": 1.0, \"recall\": 0.2695017400899754, \"specificity\": 1.0, \"npv\": 0.4491807475678443, \"accuracy\": 0.5422096920048939, \"f1\": 0.42457876437550146, \"f2\": 0.31561263643412396, \"f0_5\": 0.6484620726277521, \"p4\": 0.5039797724572204, \"phi\": 0.34792958064017787}, {\"truth_threshold\": 20.52, \"match_probability\": 0.9999993349348361, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3172, \"tn\": 7018, \"fp\": 0, \"fn\": 8609, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26924709277650455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7307529072234955, \"precision\": 1.0, \"recall\": 0.26924709277650455, \"specificity\": 1.0, \"npv\": 0.44909451590196453, \"accuracy\": 0.5420501090483536, \"f1\": 0.4242626897612519, \"f2\": 0.31533322729441704, \"f0_5\": 0.6481670685356983, \"p4\": 0.5037299125948307, \"phi\": 0.3477317828276208}, {\"truth_threshold\": 20.54, \"match_probability\": 0.9999993440909787, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3170, \"tn\": 7018, \"fp\": 0, \"fn\": 8611, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2690773279008573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7309226720991426, \"precision\": 1.0, \"recall\": 0.2690773279008573, \"specificity\": 1.0, \"npv\": 0.4490370465160919, \"accuracy\": 0.5419437204106602, \"f1\": 0.4240519028827503, \"f2\": 0.3151469360162246, \"f0_5\": 0.6479702383385798, \"p4\": 0.503563243010971, \"phi\": 0.3475998973029811}, {\"truth_threshold\": 20.56, \"match_probability\": 0.9999993531210661, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3161, \"tn\": 7018, \"fp\": 0, \"fn\": 8620, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2683133859604448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7316866140395553, \"precision\": 1.0, \"recall\": 0.2683133859604448, \"specificity\": 1.0, \"npv\": 0.4487786161913288, \"accuracy\": 0.5414649715410395, \"f1\": 0.42310266363271315, \"f2\": 0.3143084418812767, \"f0_5\": 0.6470829068577277, \"p4\": 0.5028122734356667, \"phi\": 0.3470062104011084}, {\"truth_threshold\": 20.580000000000002, \"match_probability\": 0.9999993620268339, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3160, \"tn\": 7018, \"fp\": 0, \"fn\": 8621, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2682285035226212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7317714964773788, \"precision\": 1.0, \"recall\": 0.2682285035226212, \"specificity\": 1.0, \"npv\": 0.44874992007161585, \"accuracy\": 0.5414117772221927, \"f1\": 0.4229971220132521, \"f2\": 0.31421525733831834, \"f0_5\": 0.6469841529830883, \"p4\": 0.5027287355299648, \"phi\": 0.3469402247026213}, {\"truth_threshold\": 20.6, \"match_probability\": 0.9999993708099935, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3156, \"tn\": 7018, \"fp\": 0, \"fn\": 8625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2678889737713267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7321110262286733, \"precision\": 1.0, \"recall\": 0.2678889737713267, \"specificity\": 1.0, \"npv\": 0.44863517228153166, \"accuracy\": 0.5411989999468056, \"f1\": 0.4225748142197228, \"f2\": 0.3138424821002387, \"f0_5\": 0.6465888137676705, \"p4\": 0.5023943896833442, \"phi\": 0.34667624074952397}, {\"truth_threshold\": 20.62, \"match_probability\": 0.9999993794722328, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3149, \"tn\": 7018, \"fp\": 0, \"fn\": 8632, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2672947967065614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7327052032934386, \"precision\": 1.0, \"recall\": 0.2672947967065614, \"specificity\": 1.0, \"npv\": 0.44843450479233227, \"accuracy\": 0.5408266397148784, \"f1\": 0.4218352310783657, \"f2\": 0.3131899826944881, \"f0_5\": 0.6458957213767076, \"p4\": 0.5018085349005365, \"phi\": 0.34621410975677175}, {\"truth_threshold\": 20.64, \"match_probability\": 0.9999993880152168, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3141, \"tn\": 7018, \"fp\": 0, \"fn\": 8640, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2666157372039725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7333842627960275, \"precision\": 1.0, \"recall\": 0.2666157372039725, \"specificity\": 1.0, \"npv\": 0.4482053902158641, \"accuracy\": 0.5404010851641045, \"f1\": 0.4209891435464415, \"f2\": 0.3124440465532677, \"f0_5\": 0.6451016635859519, \"p4\": 0.5011378140139566, \"phi\": 0.34568571062628084}, {\"truth_threshold\": 20.66, \"match_probability\": 0.999999396440587, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3131, \"tn\": 7018, \"fp\": 0, \"fn\": 8650, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26576691282573633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7342330871742636, \"precision\": 1.0, \"recall\": 0.26576691282573633, \"specificity\": 1.0, \"npv\": 0.4479193260148073, \"accuracy\": 0.539869141975637, \"f1\": 0.4199302575107296, \"f2\": 0.31151129240871556, \"f0_5\": 0.644106150997737, \"p4\": 0.5002976452685195, \"phi\": 0.3450248345698319}, {\"truth_threshold\": 20.68, \"match_probability\": 0.9999994047499629, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3130, \"tn\": 7018, \"fp\": 0, \"fn\": 8651, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2656820303879127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7343179696120873, \"precision\": 1.0, \"recall\": 0.2656820303879127, \"specificity\": 1.0, \"npv\": 0.4478907396770694, \"accuracy\": 0.5398159476567903, \"f1\": 0.4198242907920327, \"f2\": 0.3114179965773869, \"f0_5\": 0.6440064194889099, \"p4\": 0.5002135199614464, \"phi\": 0.34495872377626263}, {\"truth_threshold\": 20.7, \"match_probability\": 0.9999994129449412, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3121, \"tn\": 7018, \"fp\": 0, \"fn\": 8660, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2649180884475002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7350819115524998, \"precision\": 1.0, \"recall\": 0.2649180884475002, \"specificity\": 1.0, \"npv\": 0.44763362673810436, \"accuracy\": 0.5393371987871696, \"f1\": 0.41886995034223595, \"f2\": 0.31057816698178925, \"f0_5\": 0.6431073562744694, \"p4\": 0.4994555014714355, \"phi\": 0.34436353570069}, {\"truth_threshold\": 20.72, \"match_probability\": 0.999999421027097, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3116, \"tn\": 7018, \"fp\": 0, \"fn\": 8665, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26449367625838216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7355063237416178, \"precision\": 1.0, \"recall\": 0.26449367625838216, \"specificity\": 1.0, \"npv\": 0.4474909137282408, \"accuracy\": 0.5390712271929358, \"f1\": 0.41833926293884677, \"f2\": 0.31011146496815284, \"f0_5\": 0.6426067230356775, \"p4\": 0.49903368522011504, \"phi\": 0.3440327264435826}, {\"truth_threshold\": 20.740000000000002, \"match_probability\": 0.9999994289979836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3109, \"tn\": 7018, \"fp\": 0, \"fn\": 8672, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2638994991936168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7361005008063831, \"precision\": 1.0, \"recall\": 0.2638994991936168, \"specificity\": 1.0, \"npv\": 0.4472912683237731, \"accuracy\": 0.5386988669610085, \"f1\": 0.4175957018132975, \"f2\": 0.30945792606453926, \"f0_5\": 0.6419044472890945, \"p4\": 0.49844230511703463, \"phi\": 0.3435694132258013}, {\"truth_threshold\": 20.78, \"match_probability\": 0.999999444612055, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3100, \"tn\": 7018, \"fp\": 0, \"fn\": 8681, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2631355572532043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7368644427467956, \"precision\": 1.0, \"recall\": 0.2631355572532043, \"specificity\": 1.0, \"npv\": 0.44703484298362955, \"accuracy\": 0.5382201180913878, \"f1\": 0.4166386667562664, \"f2\": 0.308617394074546, \"f0_5\": 0.6409991315495637, \"p4\": 0.4976805177617773, \"phi\": 0.3429734137219619}, {\"truth_threshold\": 20.8, \"match_probability\": 0.9999994522582408, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3098, \"tn\": 7018, \"fp\": 0, \"fn\": 8683, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2629657923775571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7370342076224429, \"precision\": 1.0, \"recall\": 0.2629657923775571, \"specificity\": 1.0, \"npv\": 0.44697789949684735, \"accuracy\": 0.5381137294536944, \"f1\": 0.4164258350695611, \"f2\": 0.3084305682768508, \"f0_5\": 0.6407975840814132, \"p4\": 0.49751101065692416, \"phi\": 0.34284092158965584}, {\"truth_threshold\": 20.82, \"match_probability\": 0.9999994597991594, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3094, \"tn\": 7018, \"fp\": 0, \"fn\": 8687, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26262626262626265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7373737373737373, \"precision\": 1.0, \"recall\": 0.26262626262626265, \"specificity\": 1.0, \"npv\": 0.44686405603311047, \"accuracy\": 0.5379009521783074, \"f1\": 0.416, \"f2\": 0.3080568720379147, \"f0_5\": 0.6403940886699507, \"p4\": 0.49717175460202934, \"phi\": 0.34257588493352625}, {\"truth_threshold\": 20.84, \"match_probability\": 0.99999946723626, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3091, \"tn\": 7018, \"fp\": 0, \"fn\": 8690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2623716153127918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7376283846872083, \"precision\": 1.0, \"recall\": 0.2623716153127918, \"specificity\": 1.0, \"npv\": 0.44677871148459386, \"accuracy\": 0.5377413692217671, \"f1\": 0.4156804733727811, \"f2\": 0.307776560788609, \"f0_5\": 0.6400911161731208, \"p4\": 0.4969171005639163, \"phi\": 0.3423770614681723}, {\"truth_threshold\": 20.86, \"match_probability\": 0.999999474570972, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3088, \"tn\": 7018, \"fp\": 0, \"fn\": 8693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26211696799932094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7378830320006791, \"precision\": 1.0, \"recall\": 0.26211696799932094, \"specificity\": 1.0, \"npv\": 0.44669339952899245, \"accuracy\": 0.5375817862652269, \"f1\": 0.4153608178088641, \"f2\": 0.30749621604397354, \"f0_5\": 0.6397878423735135, \"p4\": 0.4966622644491542, \"phi\": 0.34217819847244624}, {\"truth_threshold\": 20.88, \"match_probability\": 0.999999481804705, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3085, \"tn\": 7018, \"fp\": 0, \"fn\": 8696, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2618623206858501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7381376793141499, \"precision\": 1.0, \"recall\": 0.2618623206858501, \"specificity\": 1.0, \"npv\": 0.44660812014763906, \"accuracy\": 0.5374222033086866, \"f1\": 0.4150410332301897, \"f2\": 0.3072158377980043, \"f0_5\": 0.6394842668214419, \"p4\": 0.4964072459284826, \"phi\": 0.34197929583383513}, {\"truth_threshold\": 20.900000000000002, \"match_probability\": 0.999999488938849, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3079, \"tn\": 7018, \"fp\": 0, \"fn\": 8702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2613530260589084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7386469739410916, \"precision\": 1.0, \"recall\": 0.2613530260589084, \"specificity\": 1.0, \"npv\": 0.44643765903307886, \"accuracy\": 0.5371030373956062, \"f1\": 0.41440107671601617, \"f2\": 0.30665498077804115, \"f0_5\": 0.6388762086566793, \"p4\": 0.4958966603487817, \"phi\": 0.3415813711766939}, {\"truth_threshold\": 20.92, \"match_probability\": 0.9999994959747754, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3075, \"tn\": 7018, \"fp\": 0, \"fn\": 8706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26101349630761395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.738986503692386, \"precision\": 1.0, \"recall\": 0.26101349630761395, \"specificity\": 1.0, \"npv\": 0.4463240905621979, \"accuracy\": 0.5368902601202191, \"f1\": 0.4139741518578352, \"f2\": 0.30628100161357796, \"f0_5\": 0.6384701631992027, \"p4\": 0.4955558625747597, \"phi\": 0.3413159992791949}, {\"truth_threshold\": 20.94, \"match_probability\": 0.9999995029138362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3070, \"tn\": 7018, \"fp\": 0, \"fn\": 8711, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2605890841184959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7394109158815041, \"precision\": 1.0, \"recall\": 0.2605890841184959, \"specificity\": 1.0, \"npv\": 0.4461822112022379, \"accuracy\": 0.5366242885259854, \"f1\": 0.41344017237896435, \"f2\": 0.3058134438379089, \"f0_5\": 0.6379618469722788, \"p4\": 0.49512940566206104, \"phi\": 0.3409841840425395}, {\"truth_threshold\": 20.96, \"match_probability\": 0.999999509757365, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3066, \"tn\": 7018, \"fp\": 0, \"fn\": 8715, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.26024955436720143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7397504456327986, \"precision\": 1.0, \"recall\": 0.26024955436720143, \"specificity\": 1.0, \"npv\": 0.4460687726434882, \"accuracy\": 0.5364115112505984, \"f1\": 0.413012729844413, \"f2\": 0.3054393305439331, \"f0_5\": 0.6375545851528385, \"p4\": 0.49478787141275316, \"phi\": 0.3407186512323508}, {\"truth_threshold\": 20.98, \"match_probability\": 0.9999995165066768, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3058, \"tn\": 7018, \"fp\": 0, \"fn\": 8723, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25957049486461253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7404295051353875, \"precision\": 1.0, \"recall\": 0.25957049486461253, \"specificity\": 1.0, \"npv\": 0.44584206848357794, \"accuracy\": 0.5359859566998244, \"f1\": 0.41215715344699777, \"f2\": 0.3046909250328803, \"f0_5\": 0.6367384333486028, \"p4\": 0.4941038162920206, \"phi\": 0.34018736947121475}, {\"truth_threshold\": 21.0, \"match_probability\": 0.9999995231630692, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3054, \"tn\": 7018, \"fp\": 0, \"fn\": 8727, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25923096511331806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.740769034886682, \"precision\": 1.0, \"recall\": 0.25923096511331806, \"specificity\": 1.0, \"npv\": 0.44572880279453797, \"accuracy\": 0.5357731794244375, \"f1\": 0.41172901921132454, \"f2\": 0.3043166327872773, \"f0_5\": 0.6363295411926491, \"p4\": 0.4937612938281393, \"phi\": 0.339921619976182}, {\"truth_threshold\": 21.02, \"match_probability\": 0.999999529727821, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3049, \"tn\": 7018, \"fp\": 0, \"fn\": 8732, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25880655292419996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7411934470758, \"precision\": 1.0, \"recall\": 0.25880655292419996, \"specificity\": 1.0, \"npv\": 0.4455873015873016, \"accuracy\": 0.5355072078302038, \"f1\": 0.4111935266351989, \"f2\": 0.3038486835549, \"f0_5\": 0.6358176585894816, \"p4\": 0.4933326751839224, \"phi\": 0.3395893307372972}, {\"truth_threshold\": 21.04, \"match_probability\": 0.9999995362021941, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3048, \"tn\": 7018, \"fp\": 0, \"fn\": 8733, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25872167048637634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7412783295136236, \"precision\": 1.0, \"recall\": 0.25872167048637634, \"specificity\": 1.0, \"npv\": 0.4455590121262142, \"accuracy\": 0.535454013511357, \"f1\": 0.41108638478656684, \"f2\": 0.30375508251614447, \"f0_5\": 0.6357151795770242, \"p4\": 0.4932468892545317, \"phi\": 0.339522859197365}, {\"truth_threshold\": 21.06, \"match_probability\": 0.9999995425874326, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3043, \"tn\": 7018, \"fp\": 0, \"fn\": 8738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2582972582972583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7417027417027418, \"precision\": 1.0, \"recall\": 0.2582972582972583, \"specificity\": 1.0, \"npv\": 0.4454176186849454, \"accuracy\": 0.5351880419171232, \"f1\": 0.4105504587155963, \"f2\": 0.30328702134869534, \"f0_5\": 0.6352022711142654, \"p4\": 0.49281764791380983, \"phi\": 0.339190432800831}, {\"truth_threshold\": 21.080000000000002, \"match_probability\": 0.9999995488847637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3029, \"tn\": 7018, \"fp\": 0, \"fn\": 8752, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2571089041677277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7428910958322723, \"precision\": 1.0, \"recall\": 0.2571089041677277, \"specificity\": 1.0, \"npv\": 0.44502219403931514, \"accuracy\": 0.5344433214532688, \"f1\": 0.4090479405806887, \"f2\": 0.30197595358203894, \"f0_5\": 0.6337615600284554, \"p4\": 0.491612997283695, \"phi\": 0.33825902595461693}, {\"truth_threshold\": 21.1, \"match_probability\": 0.9999995550953977, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3025, \"tn\": 7018, \"fp\": 0, \"fn\": 8756, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2567693744164332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7432306255835668, \"precision\": 1.0, \"recall\": 0.2567693744164332, \"specificity\": 1.0, \"npv\": 0.44490934449093444, \"accuracy\": 0.5342305441778818, \"f1\": 0.4086181277860327, \"f2\": 0.30160122833954817, \"f0_5\": 0.6333486872409028, \"p4\": 0.49126805679613145, \"phi\": 0.33799274260990075}, {\"truth_threshold\": 21.12, \"match_probability\": 0.9999995612205282, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3024, \"tn\": 7018, \"fp\": 0, \"fn\": 8757, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25668449197860965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7433155080213903, \"precision\": 1.0, \"recall\": 0.25668449197860965, \"specificity\": 1.0, \"npv\": 0.4448811410459588, \"accuracy\": 0.5341773498590351, \"f1\": 0.4085106382978723, \"f2\": 0.3015075376884422, \"f0_5\": 0.633245382585752, \"p4\": 0.491181769070322, \"phi\": 0.3379261601004665}, {\"truth_threshold\": 21.14, \"match_probability\": 0.9999995672613322, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3018, \"tn\": 7018, \"fp\": 0, \"fn\": 8763, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25617519735166794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7438248026483321, \"precision\": 1.0, \"recall\": 0.25617519735166794, \"specificity\": 1.0, \"npv\": 0.44471199543755147, \"accuracy\": 0.5338581839459545, \"f1\": 0.4078653963105615, \"f2\": 0.3009453153045351, \"f0_5\": 0.6326248270657779, \"p4\": 0.4906635998575846, \"phi\": 0.337526566651973}, {\"truth_threshold\": 21.16, \"match_probability\": 0.9999995732189708, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3013, \"tn\": 7018, \"fp\": 0, \"fn\": 8768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25575078516254984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7442492148374501, \"precision\": 1.0, \"recall\": 0.25575078516254984, \"specificity\": 1.0, \"npv\": 0.4445711389839098, \"accuracy\": 0.5335922123517208, \"f1\": 0.4073272948492632, \"f2\": 0.3004766938588268, \"f0_5\": 0.6321067427516469, \"p4\": 0.49023121083612975, \"phi\": 0.3371934427828394}, {\"truth_threshold\": 21.18, \"match_probability\": 0.9999995790945889, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3009, \"tn\": 7018, \"fp\": 0, \"fn\": 8772, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2554112554112554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7445887445887446, \"precision\": 1.0, \"recall\": 0.2554112554112554, \"specificity\": 1.0, \"npv\": 0.44445851804939834, \"accuracy\": 0.5333794350763339, \"f1\": 0.4068965517241379, \"f2\": 0.30010172939979657, \"f0_5\": 0.6316916488222698, \"p4\": 0.48988491794473177, \"phi\": 0.33692685864030336}, {\"truth_threshold\": 21.2, \"match_probability\": 0.9999995848893156, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3003, \"tn\": 7018, \"fp\": 0, \"fn\": 8778, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2549019607843137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7450980392156863, \"precision\": 1.0, \"recall\": 0.2549019607843137, \"specificity\": 1.0, \"npv\": 0.44428969359331477, \"accuracy\": 0.5330602691632533, \"f1\": 0.40625, \"f2\": 0.2995391705069124, \"f0_5\": 0.6310679611650486, \"p4\": 0.48936484054636104, \"phi\": 0.33652684001903604}, {\"truth_threshold\": 21.22, \"match_probability\": 0.9999995906042648, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2999, \"tn\": 7018, \"fp\": 0, \"fn\": 8782, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2545624310330193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7454375689669808, \"precision\": 1.0, \"recall\": 0.2545624310330193, \"specificity\": 1.0, \"npv\": 0.4441772151898734, \"accuracy\": 0.5328474918878664, \"f1\": 0.4058186738836265, \"f2\": 0.29916405642120386, \"f0_5\": 0.6306514699078942, \"p4\": 0.4890176956967858, \"phi\": 0.3362600655864605}, {\"truth_threshold\": 21.240000000000002, \"match_probability\": 0.9999995962405346, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2993, \"tn\": 7018, \"fp\": 0, \"fn\": 8788, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2540531364060776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7459468635939224, \"precision\": 1.0, \"recall\": 0.2540531364060776, \"specificity\": 1.0, \"npv\": 0.4440086043274706, \"accuracy\": 0.5325283259747859, \"f1\": 0.40517124678489236, \"f2\": 0.29860127302113054, \"f0_5\": 0.6300256809666147, \"p4\": 0.4884963364648063, \"phi\": 0.3358597601986267}, {\"truth_threshold\": 21.26, \"match_probability\": 0.9999996017992082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2988, \"tn\": 7018, \"fp\": 0, \"fn\": 8793, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25362872421695953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7463712757830405, \"precision\": 1.0, \"recall\": 0.25362872421695953, \"specificity\": 1.0, \"npv\": 0.4438681930301689, \"accuracy\": 0.5322623543805521, \"f1\": 0.40463132236441196, \"f2\": 0.29813218390804597, \"f0_5\": 0.6295032233598786, \"p4\": 0.48806128018116685, \"phi\": 0.33552604000096453}, {\"truth_threshold\": 21.28, \"match_probability\": 0.9999996072813541, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2987, \"tn\": 7018, \"fp\": 0, \"fn\": 8794, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2535438417791359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7464561582208641, \"precision\": 1.0, \"recall\": 0.2535438417791359, \"specificity\": 1.0, \"npv\": 0.4438401214267645, \"accuracy\": 0.5322091600617054, \"f1\": 0.40452329360780065, \"f2\": 0.29803835485222807, \"f0_5\": 0.6293986261536516, \"p4\": 0.4879742043755757, \"phi\": 0.33545928146685705}, {\"truth_threshold\": 21.3, \"match_probability\": 0.9999996126880256, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2978, \"tn\": 7018, \"fp\": 0, \"fn\": 8803, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25277989983872334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7472201001612766, \"precision\": 1.0, \"recall\": 0.25277989983872334, \"specificity\": 1.0, \"npv\": 0.4435876366854181, \"accuracy\": 0.5317304111920846, \"f1\": 0.40355037604173727, \"f2\": 0.29719372480140516, \"f0_5\": 0.6284556620098763, \"p4\": 0.48718955093349736, \"phi\": 0.3348582362299545}, {\"truth_threshold\": 21.32, \"match_probability\": 0.9999996180202619, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2971, \"tn\": 7018, \"fp\": 0, \"fn\": 8810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25218572277395807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7478142772260419, \"precision\": 1.0, \"recall\": 0.25218572277395807, \"specificity\": 1.0, \"npv\": 0.4433914581753854, \"accuracy\": 0.5313580509601574, \"f1\": 0.40279284164859, \"f2\": 0.2965365804970556, \"f0_5\": 0.627720261990281, \"p4\": 0.4865780521387585, \"phi\": 0.3343904833450838}, {\"truth_threshold\": 21.34, \"match_probability\": 0.9999996232790879, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2970, \"tn\": 7018, \"fp\": 0, \"fn\": 8811, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25210084033613445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7478991596638656, \"precision\": 1.0, \"recall\": 0.25210084033613445, \"specificity\": 1.0, \"npv\": 0.443363446838082, \"accuracy\": 0.5313048566413107, \"f1\": 0.40268456375838924, \"f2\": 0.2964426877470356, \"f0_5\": 0.6276150627615062, \"p4\": 0.48649060824034773, \"phi\": 0.3343236418834384}, {\"truth_threshold\": 21.36, \"match_probability\": 0.999999628465514, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2965, \"tn\": 7018, \"fp\": 0, \"fn\": 8816, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2516764281470164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7483235718529836, \"precision\": 1.0, \"recall\": 0.2516764281470164, \"specificity\": 1.0, \"npv\": 0.4432234432234432, \"accuracy\": 0.531038885047077, \"f1\": 0.4021429540214295, \"f2\": 0.2959731677613847, \"f0_5\": 0.6270885326339833, \"p4\": 0.48605306190465225, \"phi\": 0.333989360701053}, {\"truth_threshold\": 21.38, \"match_probability\": 0.9999996335805373, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2959, \"tn\": 7018, \"fp\": 0, \"fn\": 8822, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2511671335200747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7488328664799253, \"precision\": 1.0, \"recall\": 0.2511671335200747, \"specificity\": 1.0, \"npv\": 0.44305555555555554, \"accuracy\": 0.5307197191339965, \"f1\": 0.4014925373134328, \"f2\": 0.29540962003074894, \"f0_5\": 0.6264555193292967, \"p4\": 0.4855272854837181, \"phi\": 0.3335880601565846}, {\"truth_threshold\": 21.400000000000002, \"match_probability\": 0.9999996386251405, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2954, \"tn\": 7018, \"fp\": 0, \"fn\": 8827, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25074272133095665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7492572786690433, \"precision\": 1.0, \"recall\": 0.25074272133095665, \"specificity\": 1.0, \"npv\": 0.44291574629220576, \"accuracy\": 0.5304537475397627, \"f1\": 0.4009501187648456, \"f2\": 0.2949398937657255, \"f0_5\": 0.625927024621774, \"p4\": 0.4850885358204528, \"phi\": 0.33325350642662294}, {\"truth_threshold\": 21.42, \"match_probability\": 0.9999996436002931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2948, \"tn\": 7018, \"fp\": 0, \"fn\": 8833, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.25023342670401494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7497665732959851, \"precision\": 1.0, \"recall\": 0.25023342670401494, \"specificity\": 1.0, \"npv\": 0.44274809160305345, \"accuracy\": 0.5301345816266823, \"f1\": 0.40029873039581776, \"f2\": 0.29437609841827767, \"f0_5\": 0.6252916472235185, \"p4\": 0.4845613105350936, \"phi\": 0.33285187715933817}, {\"truth_threshold\": 21.44, \"match_probability\": 0.9999996485069516, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2944, \"tn\": 7018, \"fp\": 0, \"fn\": 8837, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2498938969527205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7501061030472795, \"precision\": 1.0, \"recall\": 0.2498938969527205, \"specificity\": 1.0, \"npv\": 0.44263639230526647, \"accuracy\": 0.5299218043512953, \"f1\": 0.3998641765704584, \"f2\": 0.29400015978269556, \"f0_5\": 0.6248673430402852, \"p4\": 0.4842093858498429, \"phi\": 0.33258402397928893}, {\"truth_threshold\": 21.46, \"match_probability\": 0.9999996533460586, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2942, \"tn\": 7018, \"fp\": 0, \"fn\": 8839, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24972413207707325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7502758679229268, \"precision\": 1.0, \"recall\": 0.24972413207707325, \"specificity\": 1.0, \"npv\": 0.44258056378886296, \"accuracy\": 0.5298154157136018, \"f1\": 0.3996468111118658, \"f2\": 0.29381216793832143, \"f0_5\": 0.6246549747335344, \"p4\": 0.48403329083371166, \"phi\": 0.33245006717754705}, {\"truth_threshold\": 21.48, \"match_probability\": 0.9999996581185442, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2939, \"tn\": 7018, \"fp\": 0, \"fn\": 8842, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24946948476360242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7505305152363976, \"precision\": 1.0, \"recall\": 0.24946948476360242, \"specificity\": 1.0, \"npv\": 0.4424968474148802, \"accuracy\": 0.5296558327570615, \"f1\": 0.39932065217391305, \"f2\": 0.2935301520084693, \"f0_5\": 0.6243361515911119, \"p4\": 0.48376898216208913, \"phi\": 0.33224909410577563}, {\"truth_threshold\": 21.5, \"match_probability\": 0.9999996628253256, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2936, \"tn\": 7018, \"fp\": 0, \"fn\": 8845, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24921483745013157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7507851625498684, \"precision\": 1.0, \"recall\": 0.24921483745013157, \"specificity\": 1.0, \"npv\": 0.4424131627056673, \"accuracy\": 0.5294962498005213, \"f1\": 0.3989943602636407, \"f2\": 0.2932481022772673, \"f0_5\": 0.6240170031880977, \"p4\": 0.4835044737869125, \"phi\": 0.3320480754792768}, {\"truth_threshold\": 21.52, \"match_probability\": 0.9999996674673074, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2930, \"tn\": 7018, \"fp\": 0, \"fn\": 8851, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24870554282318988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7512944571768101, \"precision\": 1.0, \"recall\": 0.24870554282318988, \"specificity\": 1.0, \"npv\": 0.44224588820971705, \"accuracy\": 0.5291770838874408, \"f1\": 0.39834137720073415, \"f2\": 0.2926839013865026, \"f0_5\": 0.6233777286072933, \"p4\": 0.4829748564521529, \"phi\": 0.3316459010579227}, {\"truth_threshold\": 21.54, \"match_probability\": 0.9999996720453818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2925, \"tn\": 7018, \"fp\": 0, \"fn\": 8856, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2482811306340718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7517188693659282, \"precision\": 1.0, \"recall\": 0.2482811306340718, \"specificity\": 1.0, \"npv\": 0.44210658939145775, \"accuracy\": 0.5289111122932071, \"f1\": 0.397796817625459, \"f2\": 0.29221363064197087, \"f0_5\": 0.6228440015331544, \"p4\": 0.48253289521006476, \"phi\": 0.33131061539721973}, {\"truth_threshold\": 21.56, \"match_probability\": 0.9999996765604284, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2922, \"tn\": 7018, \"fp\": 0, \"fn\": 8859, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24802648332060095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.751973516679399, \"precision\": 1.0, \"recall\": 0.24802648332060095, \"specificity\": 1.0, \"npv\": 0.4420230522138943, \"accuracy\": 0.5287515293366668, \"f1\": 0.39746990410120386, \"f2\": 0.2919314230907565, \"f0_5\": 0.6225233286462993, \"p4\": 0.48226745000277627, \"phi\": 0.3311093825116567}, {\"truth_threshold\": 21.580000000000002, \"match_probability\": 0.9999996810133152, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2919, \"tn\": 7018, \"fp\": 0, \"fn\": 8862, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24777183600713013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7522281639928698, \"precision\": 1.0, \"recall\": 0.24777183600713013, \"specificity\": 1.0, \"npv\": 0.44193954659949625, \"accuracy\": 0.5285919463801266, \"f1\": 0.39714285714285713, \"f2\": 0.29164918170373477, \"f0_5\": 0.622202327663384, \"p4\": 0.4820018029943343, \"phi\": 0.33090810335365894}, {\"truth_threshold\": 21.6, \"match_probability\": 0.9999996854048978, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2916, \"tn\": 7018, \"fp\": 0, \"fn\": 8865, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2475171886936593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7524828113063408, \"precision\": 1.0, \"recall\": 0.2475171886936593, \"specificity\": 1.0, \"npv\": 0.4418560725303784, \"accuracy\": 0.5284323634235863, \"f1\": 0.3968156766687079, \"f2\": 0.29136690647482016, \"f0_5\": 0.6218809980806143, \"p4\": 0.4817359538117949, \"phi\": 0.33070677779558866}, {\"truth_threshold\": 21.62, \"match_probability\": 0.9999996897360202, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2905, \"tn\": 7018, \"fp\": 0, \"fn\": 8876, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24658348187759951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7534165181224005, \"precision\": 1.0, \"recall\": 0.24658348187759951, \"specificity\": 1.0, \"npv\": 0.441550270542343, \"accuracy\": 0.5278472259162721, \"f1\": 0.3956148713060057, \"f2\": 0.29033160766755284, \"f0_5\": 0.6206999700867484, \"p4\": 0.48075943771447666, \"phi\": 0.32996818503353775}, {\"truth_threshold\": 21.64, \"match_probability\": 0.9999996940075148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2902, \"tn\": 7018, \"fp\": 0, \"fn\": 8879, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24632883456412868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7536711654358713, \"precision\": 1.0, \"recall\": 0.24632883456412868, \"specificity\": 1.0, \"npv\": 0.4414669434484494, \"accuracy\": 0.5276876429597319, \"f1\": 0.3952870666757475, \"f2\": 0.2900491744292968, \"f0_5\": 0.6203771003463167, \"p4\": 0.4804926400969222, \"phi\": 0.329766641245358}, {\"truth_threshold\": 21.66, \"match_probability\": 0.9999996982202024, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2897, \"tn\": 7018, \"fp\": 0, \"fn\": 8884, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24590442237501062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7540955776249894, \"precision\": 1.0, \"recall\": 0.24590442237501062, \"specificity\": 1.0, \"npv\": 0.44132813482580807, \"accuracy\": 0.5274216713654981, \"f1\": 0.3947404278512059, \"f2\": 0.2895783770816257, \"f0_5\": 0.6198382472506312, \"p4\": 0.48004752320655747, \"phi\": 0.3294306301365754}, {\"truth_threshold\": 21.7, \"match_probability\": 0.9999997064723845, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2895, \"tn\": 7018, \"fp\": 0, \"fn\": 8886, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24573465749936338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7542653425006366, \"precision\": 1.0, \"recall\": 0.24573465749936338, \"specificity\": 1.0, \"npv\": 0.44127263581488935, \"accuracy\": 0.5273152827278047, \"f1\": 0.39452166802943583, \"f2\": 0.2893900317879206, \"f0_5\": 0.6196224476691923, \"p4\": 0.47986931715499664, \"phi\": 0.3292961889026551}, {\"truth_threshold\": 21.72, \"match_probability\": 0.9999997105134647, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2891, \"tn\": 7018, \"fp\": 0, \"fn\": 8890, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24539512774806893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7546048722519311, \"precision\": 1.0, \"recall\": 0.24539512774806893, \"specificity\": 1.0, \"npv\": 0.4411616796580337, \"accuracy\": 0.5271025054524177, \"f1\": 0.39408396946564883, \"f2\": 0.28901329601119663, \"f0_5\": 0.6191904047976012, \"p4\": 0.47951263135508293, \"phi\": 0.329027243153566}, {\"truth_threshold\": 21.740000000000002, \"match_probability\": 0.9999997144989102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2886, \"tn\": 7018, \"fp\": 0, \"fn\": 8895, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24497071555895086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7550292844410491, \"precision\": 1.0, \"recall\": 0.24497071555895086, \"specificity\": 1.0, \"npv\": 0.44102306290454346, \"accuracy\": 0.526836533858184, \"f1\": 0.3935365105338515, \"f2\": 0.28854229154169164, \"f0_5\": 0.6186495176848874, \"p4\": 0.4790662597596933, \"phi\": 0.32869094191615045}, {\"truth_threshold\": 21.76, \"match_probability\": 0.999999718429487, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2884, \"tn\": 7018, \"fp\": 0, \"fn\": 8897, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24480095068330363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7551990493166963, \"precision\": 1.0, \"recall\": 0.24480095068330363, \"specificity\": 1.0, \"npv\": 0.44096764059063775, \"accuracy\": 0.5267301452204904, \"f1\": 0.3933174224343675, \"f2\": 0.2883538633818589, \"f0_5\": 0.6184329030321225, \"p4\": 0.4788875507399123, \"phi\": 0.3285563842587167}, {\"truth_threshold\": 21.78, \"match_probability\": 0.9999997223059504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2879, \"tn\": 7018, \"fp\": 0, \"fn\": 8902, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24437653849418556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7556234615058145, \"precision\": 1.0, \"recall\": 0.24437653849418556, \"specificity\": 1.0, \"npv\": 0.44082914572864323, \"accuracy\": 0.5264641736262567, \"f1\": 0.3927694406548431, \"f2\": 0.2878827270363778, \"f0_5\": 0.6178907155427737, \"p4\": 0.47844037624333285, \"phi\": 0.3282198968687223}, {\"truth_threshold\": 21.8, \"match_probability\": 0.9999997261290454, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2876, \"tn\": 7018, \"fp\": 0, \"fn\": 8905, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2441218911807147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7558781088192853, \"precision\": 1.0, \"recall\": 0.2441218911807147, \"specificity\": 1.0, \"npv\": 0.440746090560824, \"accuracy\": 0.5263045906697165, \"f1\": 0.392440472129358, \"f2\": 0.2876, \"f0_5\": 0.6175649559802447, \"p4\": 0.4781717953554235, \"phi\": 0.3280179402993301}, {\"truth_threshold\": 21.82, \"match_probability\": 0.9999997298995067, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2875, \"tn\": 7018, \"fp\": 0, \"fn\": 8906, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2440370087428911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7559629912571089, \"precision\": 1.0, \"recall\": 0.2440370087428911, \"specificity\": 1.0, \"npv\": 0.4407184124591811, \"accuracy\": 0.5262513963508697, \"f1\": 0.39233078602620086, \"f2\": 0.2875057501150023, \"f0_5\": 0.6174562948326962, \"p4\": 0.478082222275588, \"phi\": 0.3279506107243197}, {\"truth_threshold\": 21.84, \"match_probability\": 0.999999733618059, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2870, \"tn\": 7018, \"fp\": 0, \"fn\": 8911, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24361259655377301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.756387403446227, \"precision\": 1.0, \"recall\": 0.24361259655377301, \"specificity\": 1.0, \"npv\": 0.44058007407872435, \"accuracy\": 0.525985424756636, \"f1\": 0.3917821309125657, \"f2\": 0.287034444133296, \"f0_5\": 0.6169124285284382, \"p4\": 0.477634010354176, \"phi\": 0.3276138822397056}, {\"truth_threshold\": 21.86, \"match_probability\": 0.999999737285417, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2864, \"tn\": 7018, \"fp\": 0, \"fn\": 8917, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24310330192683133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7568966980731686, \"precision\": 1.0, \"recall\": 0.24310330192683133, \"specificity\": 1.0, \"npv\": 0.4404141826168811, \"accuracy\": 0.5256662588435556, \"f1\": 0.3911232502560601, \"f2\": 0.28646875250060017, \"f0_5\": 0.6162585531695142, \"p4\": 0.4770953918073608, \"phi\": 0.3272096300685086}, {\"truth_threshold\": 21.88, \"match_probability\": 0.9999997409022854, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2861, \"tn\": 7018, \"fp\": 0, \"fn\": 8920, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2428486546133605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7571513453866395, \"precision\": 1.0, \"recall\": 0.2428486546133605, \"specificity\": 1.0, \"npv\": 0.4403312837244322, \"accuracy\": 0.5255066758870153, \"f1\": 0.39079360743067887, \"f2\": 0.286185855756727, \"f0_5\": 0.6159311087190528, \"p4\": 0.4768257689841911, \"phi\": 0.32700743085846273}, {\"truth_threshold\": 21.900000000000002, \"match_probability\": 0.9999997444693592, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2857, \"tn\": 7018, \"fp\": 0, \"fn\": 8924, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24250912486206605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.757490875137934, \"precision\": 1.0, \"recall\": 0.24250912486206605, \"specificity\": 1.0, \"npv\": 0.4402208004014553, \"accuracy\": 0.5252938986116282, \"f1\": 0.3903538734799836, \"f2\": 0.2858086072707629, \"f0_5\": 0.6154939894006636, \"p4\": 0.4764659458488115, \"phi\": 0.3267377557789047}, {\"truth_threshold\": 21.92, \"match_probability\": 0.9999997479873242, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2850, \"tn\": 7018, \"fp\": 0, \"fn\": 8931, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24191494779730074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7580850522026993, \"precision\": 1.0, \"recall\": 0.24191494779730074, \"specificity\": 1.0, \"npv\": 0.4400275879365477, \"accuracy\": 0.524921538379701, \"f1\": 0.38958376050850935, \"f2\": 0.2851482771040941, \"f0_5\": 0.6147275786204219, \"p4\": 0.4758353561563871, \"phi\": 0.3262656141321701}, {\"truth_threshold\": 21.94, \"match_probability\": 0.9999997514568563, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2842, \"tn\": 7018, \"fp\": 0, \"fn\": 8939, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24123588829471182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7587641117052881, \"precision\": 1.0, \"recall\": 0.24123588829471182, \"specificity\": 1.0, \"npv\": 0.439806981262142, \"accuracy\": 0.524495983828927, \"f1\": 0.3887027285782671, \"f2\": 0.2843933875035024, \"f0_5\": 0.6138494103416994, \"p4\": 0.47511327533764997, \"phi\": 0.32572569410930496}, {\"truth_threshold\": 21.96, \"match_probability\": 0.9999997548786224, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2835, \"tn\": 7018, \"fp\": 0, \"fn\": 8946, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24064171122994651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7593582887700535, \"precision\": 1.0, \"recall\": 0.24064171122994651, \"specificity\": 1.0, \"npv\": 0.43961413179654224, \"accuracy\": 0.5241236235969998, \"f1\": 0.3879310344827586, \"f2\": 0.2837326607818411, \"f0_5\": 0.6130790190735694, \"p4\": 0.4744802179715336, \"phi\": 0.32525297378561685}, {\"truth_threshold\": 21.98, \"match_probability\": 0.99999975825328, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2834, \"tn\": 7018, \"fp\": 0, \"fn\": 8947, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24055682879212292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7594431712078771, \"precision\": 1.0, \"recall\": 0.24055682879212292, \"specificity\": 1.0, \"npv\": 0.4395865956780457, \"accuracy\": 0.5240704292781531, \"f1\": 0.3878207321245296, \"f2\": 0.28363825613515353, \"f0_5\": 0.6129688108318554, \"p4\": 0.47438968667091724, \"phi\": 0.325185420084966}, {\"truth_threshold\": 22.0, \"match_probability\": 0.9999997615814777, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2832, \"tn\": 7018, \"fp\": 0, \"fn\": 8949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.24038706391647569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7596129360835243, \"precision\": 1.0, \"recall\": 0.24038706391647569, \"specificity\": 1.0, \"npv\": 0.4395315337884387, \"accuracy\": 0.5239640406404596, \"f1\": 0.3876000821186615, \"f2\": 0.28344943550324286, \"f0_5\": 0.6127482798909516, \"p4\": 0.47420855302189496, \"phi\": 0.3250502959637293}, {\"truth_threshold\": 22.02, \"match_probability\": 0.9999997648638552, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2823, \"tn\": 7018, \"fp\": 0, \"fn\": 8958, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23962312197606314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7603768780239368, \"precision\": 1.0, \"recall\": 0.23962312197606314, \"specificity\": 1.0, \"npv\": 0.43928392588883325, \"accuracy\": 0.5234852917708389, \"f1\": 0.3866064092029581, \"f2\": 0.28259955552886057, \"f0_5\": 0.6117539981796906, \"p4\": 0.4733922763862669, \"phi\": 0.324441960534367}, {\"truth_threshold\": 22.04, \"match_probability\": 0.9999997681010433, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2820, \"tn\": 7018, \"fp\": 0, \"fn\": 8961, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2393684746625923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7606315253374077, \"precision\": 1.0, \"recall\": 0.2393684746625923, \"specificity\": 1.0, \"npv\": 0.43920145190562615, \"accuracy\": 0.5233257088142986, \"f1\": 0.38627491267721387, \"f2\": 0.2823161941374339, \"f0_5\": 0.6114218810979576, \"p4\": 0.47311975557836433, \"phi\": 0.3242390809452889}, {\"truth_threshold\": 22.06, \"match_probability\": 0.999999771293664, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2812, \"tn\": 7018, \"fp\": 0, \"fn\": 8969, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2386894151600034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7613105848399966, \"precision\": 1.0, \"recall\": 0.2386894151600034, \"specificity\": 1.0, \"npv\": 0.4389816726089948, \"accuracy\": 0.5229001542635247, \"f1\": 0.38539025560200096, \"f2\": 0.281560397308555, \"f0_5\": 0.6105345434017977, \"p4\": 0.47239198137846516, \"phi\": 0.3236978200436343}, {\"truth_threshold\": 22.080000000000002, \"match_probability\": 0.999999774442331, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2809, \"tn\": 7018, \"fp\": 0, \"fn\": 8972, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23843476784653256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7615652321534675, \"precision\": 1.0, \"recall\": 0.23843476784653256, \"specificity\": 1.0, \"npv\": 0.4388993120700438, \"accuracy\": 0.5227405713069844, \"f1\": 0.3850582590815627, \"f2\": 0.2812769110608215, \"f0_5\": 0.6102011556675501, \"p4\": 0.47211867038523264, \"phi\": 0.3234947535608943}, {\"truth_threshold\": 22.1, \"match_probability\": 0.9999997775476493, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2806, \"tn\": 7018, \"fp\": 0, \"fn\": 8975, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2381801205330617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7618198794669383, \"precision\": 1.0, \"recall\": 0.2381801205330617, \"specificity\": 1.0, \"npv\": 0.43881698242981304, \"accuracy\": 0.5225809883504442, \"f1\": 0.3847261260026051, \"f2\": 0.2809933907470459, \"f0_5\": 0.6098674201260595, \"p4\": 0.47184514294296304, \"phi\": 0.32329163578275155}, {\"truth_threshold\": 22.12, \"match_probability\": 0.999999780610216, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2800, \"tn\": 7018, \"fp\": 0, \"fn\": 8981, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23767082590612001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.76232917409388, \"precision\": 1.0, \"recall\": 0.23767082590612001, \"specificity\": 1.0, \"npv\": 0.438652415775986, \"accuracy\": 0.5222618224373637, \"f1\": 0.3840614498319731, \"f2\": 0.28042624789680315, \"f0_5\": 0.6091989034419738, \"p4\": 0.47129743708514155, \"phi\": 0.32288524578121147}, {\"truth_threshold\": 22.14, \"match_probability\": 0.9999997836306193, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2796, \"tn\": 7018, \"fp\": 0, \"fn\": 8985, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23733129615482557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7626687038451744, \"precision\": 1.0, \"recall\": 0.23733129615482557, \"specificity\": 1.0, \"npv\": 0.4385427732300194, \"accuracy\": 0.5220490451619767, \"f1\": 0.38361802840090553, \"f2\": 0.2800480769230769, \"f0_5\": 0.6087524493794906, \"p4\": 0.4709318163351977, \"phi\": 0.32261420425953385}, {\"truth_threshold\": 22.18, \"match_probability\": 0.9999997895472501, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2791, \"tn\": 7018, \"fp\": 0, \"fn\": 8990, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2369068839657075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7630931160342925, \"precision\": 1.0, \"recall\": 0.2369068839657075, \"specificity\": 1.0, \"npv\": 0.4384057971014493, \"accuracy\": 0.521783073567743, \"f1\": 0.38306340927806753, \"f2\": 0.2795752779725533, \"f0_5\": 0.6081935062105034, \"p4\": 0.47047424474242655, \"phi\": 0.3222752725602859}, {\"truth_threshold\": 22.2, \"match_probability\": 0.9999997924446148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2789, \"tn\": 7018, \"fp\": 0, \"fn\": 8992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23673711909006026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7632628809099398, \"precision\": 1.0, \"recall\": 0.23673711909006026, \"specificity\": 1.0, \"npv\": 0.43835103060587133, \"accuracy\": 0.5216766849300495, \"f1\": 0.3828414550446122, \"f2\": 0.2793861318694528, \"f0_5\": 0.6079696560143001, \"p4\": 0.47029104595560844, \"phi\": 0.32213965936499156}, {\"truth_threshold\": 22.22, \"match_probability\": 0.9999997953020905, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2786, \"tn\": 7018, \"fp\": 0, \"fn\": 8995, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23648247177658943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7635175282234106, \"precision\": 1.0, \"recall\": 0.23648247177658943, \"specificity\": 1.0, \"npv\": 0.4382689065134578, \"accuracy\": 0.5215171019735092, \"f1\": 0.3825084094185488, \"f2\": 0.2791023842917251, \"f0_5\": 0.6076335877862595, \"p4\": 0.4700160650909629, \"phi\": 0.32193619603133394}, {\"truth_threshold\": 22.240000000000002, \"match_probability\": 0.9999997981202265, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2777, \"tn\": 7018, \"fp\": 0, \"fn\": 9004, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2357185298361769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7642814701638231, \"precision\": 1.0, \"recall\": 0.2357185298361769, \"specificity\": 1.0, \"npv\": 0.4380227187617027, \"accuracy\": 0.5210383531038885, \"f1\": 0.3815084489627696, \"f2\": 0.2782509368549728, \"f0_5\": 0.6066232688190833, \"p4\": 0.4691898033130568, \"phi\": 0.32132549121000925}, {\"truth_threshold\": 22.26, \"match_probability\": 0.9999998008995644, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2773, \"tn\": 7018, \"fp\": 0, \"fn\": 9008, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23537900008488244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7646209999151176, \"precision\": 1.0, \"recall\": 0.23537900008488244, \"specificity\": 1.0, \"npv\": 0.4379133907400474, \"accuracy\": 0.5208255758285015, \"f1\": 0.38106362512024183, \"f2\": 0.27787241717938954, \"f0_5\": 0.606173217330477, \"p4\": 0.4688219385642764, \"phi\": 0.3210539145317695}, {\"truth_threshold\": 22.28, \"match_probability\": 0.9999998036406385, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2770, \"tn\": 7018, \"fp\": 0, \"fn\": 9011, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23512435277141158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7648756472285884, \"precision\": 1.0, \"recall\": 0.23512435277141158, \"specificity\": 1.0, \"npv\": 0.43783143053216045, \"accuracy\": 0.5206659928719612, \"f1\": 0.38072984674592814, \"f2\": 0.27758848759369864, \"f0_5\": 0.6058352652989808, \"p4\": 0.4685457817717362, \"phi\": 0.3208501702147834}, {\"truth_threshold\": 22.3, \"match_probability\": 0.9999998063439753, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2766, \"tn\": 7018, \"fp\": 0, \"fn\": 9015, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23478482302011713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7652151769798828, \"precision\": 1.0, \"recall\": 0.23478482302011713, \"specificity\": 1.0, \"npv\": 0.4377221979666937, \"accuracy\": 0.5204532155965743, \"f1\": 0.38028459476180654, \"f2\": 0.2772098616957306, \"f0_5\": 0.6053841103086014, \"p4\": 0.4681772276128793, \"phi\": 0.3205784284408214}, {\"truth_threshold\": 22.32, \"match_probability\": 0.9999998090100946, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2762, \"tn\": 7018, \"fp\": 0, \"fn\": 9019, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23444529326882269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7655547067311773, \"precision\": 1.0, \"recall\": 0.23444529326882269, \"specificity\": 1.0, \"npv\": 0.4376130198915009, \"accuracy\": 0.5202404383211873, \"f1\": 0.3798390978477618, \"f2\": 0.27683117507918054, \"f0_5\": 0.6049323229225985, \"p4\": 0.4678082781412921, \"phi\": 0.32030659185648686}, {\"truth_threshold\": 22.34, \"match_probability\": 0.9999998116395085, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2754, \"tn\": 7018, \"fp\": 0, \"fn\": 9027, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23376623376623376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7662337662337663, \"precision\": 1.0, \"recall\": 0.23376623376623376, \"specificity\": 1.0, \"npv\": 0.4373948270489249, \"accuracy\": 0.5198148837704133, \"f1\": 0.37894736842105264, \"f2\": 0.27607361963190186, \"f0_5\": 0.6040268456375839, \"p4\": 0.46706918927312996, \"phi\": 0.319762632882675}, {\"truth_threshold\": 22.36, \"match_probability\": 0.9999998142327226, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2747, \"tn\": 7018, \"fp\": 0, \"fn\": 9034, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23317205670146846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7668279432985315, \"precision\": 1.0, \"recall\": 0.23317205670146846, \"specificity\": 1.0, \"npv\": 0.43720408671816596, \"accuracy\": 0.5194425235384861, \"f1\": 0.37816629955947134, \"f2\": 0.2754105592428465, \"f0_5\": 0.6032324651939039, \"p4\": 0.4664211798317499, \"phi\": 0.3192863543879724}, {\"truth_threshold\": 22.38, \"match_probability\": 0.9999998167902351, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2742, \"tn\": 7018, \"fp\": 0, \"fn\": 9039, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2327476445123504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7672523554876496, \"precision\": 1.0, \"recall\": 0.2327476445123504, \"specificity\": 1.0, \"npv\": 0.4370679454443545, \"accuracy\": 0.5191765519442524, \"f1\": 0.37760793224540384, \"f2\": 0.2749368307062929, \"f0_5\": 0.6026638533561914, \"p4\": 0.4659575661265892, \"phi\": 0.3189459747261689}, {\"truth_threshold\": 22.400000000000002, \"match_probability\": 0.9999998193125376, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2732, \"tn\": 7018, \"fp\": 0, \"fn\": 9049, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23189882013411425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7681011798658858, \"precision\": 1.0, \"recall\": 0.23189882013411425, \"specificity\": 1.0, \"npv\": 0.43679591709715565, \"accuracy\": 0.5186446087557849, \"f1\": 0.37649004340935716, \"f2\": 0.2739890885750963, \"f0_5\": 0.6015236249944955, \"p4\": 0.46502845547587446, \"phi\": 0.3182647605598659}, {\"truth_threshold\": 22.42, \"match_probability\": 0.9999998218001148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2724, \"tn\": 7018, \"fp\": 0, \"fn\": 9057, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23121976063152533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7687802393684746, \"precision\": 1.0, \"recall\": 0.23121976063152533, \"specificity\": 1.0, \"npv\": 0.43657853810264385, \"accuracy\": 0.5182190542050109, \"f1\": 0.3755946225439504, \"f2\": 0.27323062108810786, \"f0_5\": 0.600608546103982, \"p4\": 0.46428335026761336, \"phi\": 0.31771934954760717}, {\"truth_threshold\": 22.44, \"match_probability\": 0.9999998242534449, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2718, \"tn\": 7018, \"fp\": 0, \"fn\": 9063, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23071046600458364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7692895339954163, \"precision\": 1.0, \"recall\": 0.23071046600458364, \"specificity\": 1.0, \"npv\": 0.43641564579317205, \"accuracy\": 0.5178998882919305, \"f1\": 0.3749224084419615, \"f2\": 0.2726616106897797, \"f0_5\": 0.5999205403257847, \"p4\": 0.4637234562542091, \"phi\": 0.31731003295300014}, {\"truth_threshold\": 22.46, \"match_probability\": 0.9999998266729992, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2717, \"tn\": 7018, \"fp\": 0, \"fn\": 9064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.23062558356676005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.76937441643324, \"precision\": 1.0, \"recall\": 0.23062558356676005, \"specificity\": 1.0, \"npv\": 0.4363885088919289, \"accuracy\": 0.5178466939730837, \"f1\": 0.37481031866464337, \"f2\": 0.27256676230412713, \"f0_5\": 0.5998057309373482, \"p4\": 0.4636300515451785, \"phi\": 0.3172417918954395}, {\"truth_threshold\": 22.48, \"match_probability\": 0.9999998290592429, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2709, \"tn\": 7018, \"fp\": 0, \"fn\": 9072, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22994652406417113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7700534759358288, \"precision\": 1.0, \"recall\": 0.22994652406417113, \"specificity\": 1.0, \"npv\": 0.43617153511497825, \"accuracy\": 0.5174211394223097, \"f1\": 0.3739130434782609, \"f2\": 0.2718078381795196, \"f0_5\": 0.5988857938718662, \"p4\": 0.46288189512628347, \"phi\": 0.31669564000065237}, {\"truth_threshold\": 22.5, \"match_probability\": 0.9999998314126344, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2702, \"tn\": 7018, \"fp\": 0, \"fn\": 9079, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22935234699940582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7706476530005941, \"precision\": 1.0, \"recall\": 0.22935234699940582, \"specificity\": 1.0, \"npv\": 0.4359818599739082, \"accuracy\": 0.5170487791903825, \"f1\": 0.3731271145480909, \"f2\": 0.2711435796572071, \"f0_5\": 0.5980787108769755, \"p4\": 0.46222591388202483, \"phi\": 0.31621742968119604}, {\"truth_threshold\": 22.52, \"match_probability\": 0.9999998337336261, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2699, \"tn\": 7018, \"fp\": 0, \"fn\": 9082, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.229097699685935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.770902300314065, \"precision\": 1.0, \"recall\": 0.229097699685935, \"specificity\": 1.0, \"npv\": 0.4359006211180124, \"accuracy\": 0.5168891962338422, \"f1\": 0.3727900552486188, \"f2\": 0.270858840294643, \"f0_5\": 0.5977322053417194, \"p4\": 0.46194439349078137, \"phi\": 0.3160123883486325}, {\"truth_threshold\": 22.54, \"match_probability\": 0.999999836022664, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2693, \"tn\": 7018, \"fp\": 0, \"fn\": 9088, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2285884050589933, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7714115949410068, \"precision\": 1.0, \"recall\": 0.2285884050589933, \"specificity\": 1.0, \"npv\": 0.4357382341984354, \"accuracy\": 0.5165700303207618, \"f1\": 0.37211551747961863, \"f2\": 0.27028925868679365, \"f0_5\": 0.5970380880592382, \"p4\": 0.4613806563241937, \"phi\": 0.3156021355736403}, {\"truth_threshold\": 22.56, \"match_probability\": 0.9999998382801881, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2691, \"tn\": 7018, \"fp\": 0, \"fn\": 9090, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22841864018334607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.771581359816654, \"precision\": 1.0, \"recall\": 0.22841864018334607, \"specificity\": 1.0, \"npv\": 0.4356841321082692, \"accuracy\": 0.5164636416830682, \"f1\": 0.3718905472636816, \"f2\": 0.27009936766034326, \"f0_5\": 0.5968063872255489, \"p4\": 0.4611925371180868, \"phi\": 0.31546533407909044}, {\"truth_threshold\": 22.580000000000002, \"match_probability\": 0.9999998405066322, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2683, \"tn\": 7018, \"fp\": 0, \"fn\": 9098, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22773958068075714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7722604193192428, \"precision\": 1.0, \"recall\": 0.22773958068075714, \"specificity\": 1.0, \"npv\": 0.43546785802928767, \"accuracy\": 0.5160380871322943, \"f1\": 0.3709900442477876, \"f2\": 0.26933965105306484, \"f0_5\": 0.5958779371918447, \"p4\": 0.4604390226946139, \"phi\": 0.31491787403629135}, {\"truth_threshold\": 22.6, \"match_probability\": 0.9999998427024241, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2679, \"tn\": 7018, \"fp\": 0, \"fn\": 9102, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2274000509294627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7725999490705373, \"precision\": 1.0, \"recall\": 0.2274000509294627, \"specificity\": 1.0, \"npv\": 0.43535980148883374, \"accuracy\": 0.5158253098569073, \"f1\": 0.37053941908713695, \"f2\": 0.2689597012228179, \"f0_5\": 0.5954127216962262, \"p4\": 0.4600616410719567, \"phi\": 0.31464399093451884}, {\"truth_threshold\": 22.62, \"match_probability\": 0.999999844867986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2677, \"tn\": 7018, \"fp\": 0, \"fn\": 9104, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22723028605381546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7727697139461845, \"precision\": 1.0, \"recall\": 0.22723028605381546, \"specificity\": 1.0, \"npv\": 0.4353057933258901, \"accuracy\": 0.5157189212192138, \"f1\": 0.3703140130031816, \"f2\": 0.26876970341961004, \"f0_5\": 0.5951798657121259, \"p4\": 0.45987279369356565, \"phi\": 0.3145070109525781}, {\"truth_threshold\": 22.64, \"match_probability\": 0.999999847003734, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2664, \"tn\": 7018, \"fp\": 0, \"fn\": 9117, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2261268143621085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7738731856378915, \"precision\": 1.0, \"recall\": 0.2261268143621085, \"specificity\": 1.0, \"npv\": 0.4349550666253486, \"accuracy\": 0.515027395074206, \"f1\": 0.36884735202492214, \"f2\": 0.2675343456254519, \"f0_5\": 0.5936622543120738, \"p4\": 0.4586427312244766, \"phi\": 0.31361601299463127}, {\"truth_threshold\": 22.66, \"match_probability\": 0.9999998491100784, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2647, \"tn\": 7018, \"fp\": 0, \"fn\": 9134, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22468381291910702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.775316187080893, \"precision\": 1.0, \"recall\": 0.22468381291910702, \"specificity\": 1.0, \"npv\": 0.4344972758791481, \"accuracy\": 0.5141230916538114, \"f1\": 0.36692542278902135, \"f2\": 0.26591790400032145, \"f0_5\": 0.5916670392060441, \"p4\": 0.4570274613001234, \"phi\": 0.3124492033075011}, {\"truth_threshold\": 22.68, \"match_probability\": 0.9999998511874243, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2643, \"tn\": 7018, \"fp\": 0, \"fn\": 9138, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22434428316781257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7756557168321874, \"precision\": 1.0, \"recall\": 0.22434428316781257, \"specificity\": 1.0, \"npv\": 0.43438970042089625, \"accuracy\": 0.5139103143784244, \"f1\": 0.36647254575707155, \"f2\": 0.2655374043040569, \"f0_5\": 0.5911958126425984, \"p4\": 0.4566462818127671, \"phi\": 0.312174383888888}, {\"truth_threshold\": 22.7, \"match_probability\": 0.9999998532361707, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2640, \"tn\": 7018, \"fp\": 0, \"fn\": 9141, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22408963585434175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7759103641456583, \"precision\": 1.0, \"recall\": 0.22408963585434175, \"specificity\": 1.0, \"npv\": 0.4343090537780803, \"accuracy\": 0.5137507314218841, \"f1\": 0.36613272311212813, \"f2\": 0.26525198938992045, \"f0_5\": 0.5908419497784343, \"p4\": 0.45636011677239663, \"phi\": 0.3119681998367361}, {\"truth_threshold\": 22.72, \"match_probability\": 0.9999998552567114, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2639, \"tn\": 7018, \"fp\": 0, \"fn\": 9142, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22400475341651813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7759952465834818, \"precision\": 1.0, \"recall\": 0.22400475341651813, \"specificity\": 1.0, \"npv\": 0.4342821782178218, \"accuracy\": 0.5136975371030374, \"f1\": 0.36601941747572814, \"f2\": 0.26515684343789564, \"f0_5\": 0.5907239109996866, \"p4\": 0.4562646749200459, \"phi\": 0.3118994585517447}, {\"truth_threshold\": 22.740000000000002, \"match_probability\": 0.9999998572494347, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2634, \"tn\": 7018, \"fp\": 0, \"fn\": 9147, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22358034122740006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7764196587726, \"precision\": 1.0, \"recall\": 0.22358034122740006, \"specificity\": 1.0, \"npv\": 0.43414785029384473, \"accuracy\": 0.5134315655088036, \"f1\": 0.36545265348595213, \"f2\": 0.26468105631255273, \"f0_5\": 0.5901330824035489, \"p4\": 0.4557870635942298, \"phi\": 0.31155565235097243}, {\"truth_threshold\": 22.76, \"match_probability\": 0.9999998592147237, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2632, \"tn\": 7018, \"fp\": 0, \"fn\": 9149, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22341057635175282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7765894236482471, \"precision\": 1.0, \"recall\": 0.22341057635175282, \"specificity\": 1.0, \"npv\": 0.4340941423888167, \"accuracy\": 0.5133251768711101, \"f1\": 0.3652258377853327, \"f2\": 0.2644907146876759, \"f0_5\": 0.5898964543457798, \"p4\": 0.4555958311129213, \"phi\": 0.3114180831968584}, {\"truth_threshold\": 22.78, \"match_probability\": 0.9999998611529559, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2628, \"tn\": 7018, \"fp\": 0, \"fn\": 9153, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22307104660045837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7769289533995416, \"precision\": 1.0, \"recall\": 0.22307104660045837, \"specificity\": 1.0, \"npv\": 0.4339867664337394, \"accuracy\": 0.5131123995957232, \"f1\": 0.36477201748906934, \"f2\": 0.26410998552821996, \"f0_5\": 0.5894226887363746, \"p4\": 0.4552130431899673, \"phi\": 0.3111428646122596}, {\"truth_threshold\": 22.8, \"match_probability\": 0.999999863064504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2623, \"tn\": 7018, \"fp\": 0, \"fn\": 9158, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2226466344113403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7773533655886598, \"precision\": 1.0, \"recall\": 0.2226466344113403, \"specificity\": 1.0, \"npv\": 0.4338526211671612, \"accuracy\": 0.5128464280014895, \"f1\": 0.36420438767009167, \"f2\": 0.26363398797917464, \"f0_5\": 0.5888295245364342, \"p4\": 0.45473395130863375, \"phi\": 0.3107986903662991}, {\"truth_threshold\": 22.82, \"match_probability\": 0.9999998649497351, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2614, \"tn\": 7018, \"fp\": 0, \"fn\": 9167, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22188269247092776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7781173075290723, \"precision\": 1.0, \"recall\": 0.22188269247092776, \"specificity\": 1.0, \"npv\": 0.4336113685511276, \"accuracy\": 0.5123676791318688, \"f1\": 0.36318166029871485, \"f2\": 0.26277695122441597, \"f0_5\": 0.5877591401717858, \"p4\": 0.4538698798204457, \"phi\": 0.3101787515935416}, {\"truth_threshold\": 22.84, \"match_probability\": 0.9999998668090118, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2611, \"tn\": 7018, \"fp\": 0, \"fn\": 9170, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22162804515745693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7783719548425431, \"precision\": 1.0, \"recall\": 0.22162804515745693, \"specificity\": 1.0, \"npv\": 0.4335310106251544, \"accuracy\": 0.5122080961753285, \"f1\": 0.36284046692607, \"f2\": 0.2624912033779029, \"f0_5\": 0.5874015748031496, \"p4\": 0.45358136675462335, \"phi\": 0.3099719832500829}, {\"truth_threshold\": 22.86, \"match_probability\": 0.9999998686426912, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2610, \"tn\": 7018, \"fp\": 0, \"fn\": 9171, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2215431627196333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7784568372803667, \"precision\": 1.0, \"recall\": 0.2215431627196333, \"specificity\": 1.0, \"npv\": 0.433504231268145, \"accuracy\": 0.5121549018564817, \"f1\": 0.3627267041901188, \"f2\": 0.2623959464350344, \"f0_5\": 0.587282300526529, \"p4\": 0.4534851412213987, \"phi\": 0.30990304685092757}, {\"truth_threshold\": 22.88, \"match_probability\": 0.9999998704511259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2605, \"tn\": 7018, \"fp\": 0, \"fn\": 9176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22111875053051525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7788812494694848, \"precision\": 1.0, \"recall\": 0.22111875053051525, \"specificity\": 1.0, \"npv\": 0.43337038409287393, \"accuracy\": 0.511888930262248, \"f1\": 0.3621576532740164, \"f2\": 0.26191960425506244, \"f0_5\": 0.5866852844466466, \"p4\": 0.45300360393023753, \"phi\": 0.3095582624443188}, {\"truth_threshold\": 22.900000000000002, \"match_probability\": 0.9999998722346632, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2599, \"tn\": 7018, \"fp\": 0, \"fn\": 9182, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22060945590357356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7793905440964265, \"precision\": 1.0, \"recall\": 0.22060945590357356, \"specificity\": 1.0, \"npv\": 0.43320987654320986, \"accuracy\": 0.5115697643491675, \"f1\": 0.36147426981919334, \"f2\": 0.26134786718420044, \"f0_5\": 0.5859674437480272, \"p4\": 0.452424855680265, \"phi\": 0.3091442950407654}, {\"truth_threshold\": 22.92, \"match_probability\": 0.9999998739936462, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2595, \"tn\": 7018, \"fp\": 0, \"fn\": 9186, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.22026992615227908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7797300738477209, \"precision\": 1.0, \"recall\": 0.22026992615227908, \"specificity\": 1.0, \"npv\": 0.43310293754628487, \"accuracy\": 0.5113569870737805, \"f1\": 0.36101836393989983, \"f2\": 0.26096663247450674, \"f0_5\": 0.5854880194937051, \"p4\": 0.45203847417012094, \"phi\": 0.3088681791147403}, {\"truth_threshold\": 22.94, \"match_probability\": 0.9999998757284128, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2591, \"tn\": 7018, \"fp\": 0, \"fn\": 9190, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21993039640098463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7800696035990153, \"precision\": 1.0, \"recall\": 0.21993039640098463, \"specificity\": 1.0, \"npv\": 0.4329960513326752, \"accuracy\": 0.5111442097983935, \"f1\": 0.3605622042861119, \"f2\": 0.2605853364175802, \"f0_5\": 0.5850079024610522, \"p4\": 0.45165165186050266, \"phi\": 0.30859195260028466}, {\"truth_threshold\": 22.96, \"match_probability\": 0.9999998774392962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2590, \"tn\": 7018, \"fp\": 0, \"fn\": 9191, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21984551396316102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780154486036839, \"precision\": 1.0, \"recall\": 0.21984551396316102, \"specificity\": 1.0, \"npv\": 0.4329693380220865, \"accuracy\": 0.5110910154795468, \"f1\": 0.3604481246955675, \"f2\": 0.2604900028161081, \"f0_5\": 0.5848877647802719, \"p4\": 0.45155487727472077, \"phi\": 0.30852287864557987}, {\"truth_threshold\": 22.98, \"match_probability\": 0.9999998791266254, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2582, \"tn\": 7018, \"fp\": 0, \"fn\": 9199, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21916645446057212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7808335455394279, \"precision\": 1.0, \"recall\": 0.21916645446057212, \"specificity\": 1.0, \"npv\": 0.4327557501387433, \"accuracy\": 0.5106654609287729, \"f1\": 0.359534916103878, \"f2\": 0.25972719591196236, \"f0_5\": 0.5839250983762269, \"p4\": 0.4507796840823924, \"phi\": 0.3079700365381892}, {\"truth_threshold\": 23.0, \"match_probability\": 0.9999998807907247, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2581, \"tn\": 7018, \"fp\": 0, \"fn\": 9200, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2190815720227485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7809184279772515, \"precision\": 1.0, \"recall\": 0.2190815720227485, \"specificity\": 1.0, \"npv\": 0.43272906646935505, \"accuracy\": 0.5106122666099261, \"f1\": 0.35942069349672745, \"f2\": 0.2596318277839252, \"f0_5\": 0.5838045691020132, \"p4\": 0.4506826601015079, \"phi\": 0.3079008998720899}, {\"truth_threshold\": 23.02, \"match_probability\": 0.9999998824319137, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2577, \"tn\": 7018, \"fp\": 0, \"fn\": 9204, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21874204227145402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.781257957728546, \"precision\": 1.0, \"recall\": 0.21874204227145402, \"specificity\": 1.0, \"npv\": 0.43262236468992726, \"accuracy\": 0.510399489334539, \"f1\": 0.35896364396155456, \"f2\": 0.2592503168950323, \"f0_5\": 0.5833220154828195, \"p4\": 0.4502942859957781, \"phi\": 0.3076242831516726}, {\"truth_threshold\": 23.04, \"match_probability\": 0.9999998840505082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2573, \"tn\": 7018, \"fp\": 0, \"fn\": 9208, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21840251252015958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7815974874798404, \"precision\": 1.0, \"recall\": 0.21840251252015958, \"specificity\": 1.0, \"npv\": 0.432515715518304, \"accuracy\": 0.5101867120591521, \"f1\": 0.3585063396962519, \"f2\": 0.2588687445922289, \"f0_5\": 0.5828387622887691, \"p4\": 0.4499054659337017, \"phi\": 0.307347554038831}, {\"truth_threshold\": 23.06, \"match_probability\": 0.999999885646819, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2568, \"tn\": 7018, \"fp\": 0, \"fn\": 9213, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2179781003310415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7820218996689585, \"precision\": 1.0, \"recall\": 0.2179781003310415, \"specificity\": 1.0, \"npv\": 0.43238247797424684, \"accuracy\": 0.5099207404649183, \"f1\": 0.3579343508258415, \"f2\": 0.2583916928278194, \"f0_5\": 0.5822337096993606, \"p4\": 0.44941881196833156, \"phi\": 0.3070014839789129}, {\"truth_threshold\": 23.080000000000002, \"match_probability\": 0.9999998872211527, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2563, \"tn\": 7018, \"fp\": 0, \"fn\": 9218, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21755368814192344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7824463118580766, \"precision\": 1.0, \"recall\": 0.21755368814192344, \"specificity\": 1.0, \"npv\": 0.43224932249322495, \"accuracy\": 0.5096547688706846, \"f1\": 0.35736196319018404, \"f2\": 0.25791454505202566, \"f0_5\": 0.581627558662007, \"p4\": 0.44893145712314103, \"phi\": 0.306655236878891}, {\"truth_threshold\": 23.1, \"match_probability\": 0.9999998887738123, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2558, \"tn\": 7018, \"fp\": 0, \"fn\": 9223, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21712927595280537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7828707240471946, \"precision\": 1.0, \"recall\": 0.21712927595280537, \"specificity\": 1.0, \"npv\": 0.43211624899944584, \"accuracy\": 0.5093887972764509, \"f1\": 0.3567891763721319, \"f2\": 0.25743730123586006, \"f0_5\": 0.5810203061827102, \"p4\": 0.44844339912268977, \"phi\": 0.3063088119409754}, {\"truth_threshold\": 23.12, \"match_probability\": 0.999999890305096, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2556, \"tn\": 7018, \"fp\": 0, \"fn\": 9225, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21695951107715813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7830404889228418, \"precision\": 1.0, \"recall\": 0.21695951107715813, \"specificity\": 1.0, \"npv\": 0.43206304254140243, \"accuracy\": 0.5092824086387574, \"f1\": 0.35655994978028877, \"f2\": 0.2572463768115942, \"f0_5\": 0.5807770961145194, \"p4\": 0.448247978527587, \"phi\": 0.3061701919917941}, {\"truth_threshold\": 23.14, \"match_probability\": 0.9999998918152979, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2549, \"tn\": 7018, \"fp\": 0, \"fn\": 9232, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21636533401239283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7836346659876071, \"precision\": 1.0, \"recall\": 0.21636533401239283, \"specificity\": 1.0, \"npv\": 0.4318769230769231, \"accuracy\": 0.5089100484068302, \"f1\": 0.35575715282623865, \"f2\": 0.256578020252451, \"f0_5\": 0.5799244664876917, \"p4\": 0.44756311547214556, \"phi\": 0.30568479634058177}, {\"truth_threshold\": 23.16, \"match_probability\": 0.9999998933047085, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2545, \"tn\": 7018, \"fp\": 0, \"fn\": 9236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21602580426109838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7839741957389016, \"precision\": 1.0, \"recall\": 0.21602580426109838, \"specificity\": 1.0, \"npv\": 0.43177064107296664, \"accuracy\": 0.5086972711314431, \"f1\": 0.35529805947228815, \"f2\": 0.2561960176367553, \"f0_5\": 0.5794362733937435, \"p4\": 0.4471711411337558, \"phi\": 0.3054072690590675}, {\"truth_threshold\": 23.18, \"match_probability\": 0.999999894773614, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2538, \"tn\": 7018, \"fp\": 0, \"fn\": 9243, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21543162719633308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7845683728036669, \"precision\": 1.0, \"recall\": 0.21543162719633308, \"specificity\": 1.0, \"npv\": 0.43158477338417073, \"accuracy\": 0.5083249108995159, \"f1\": 0.35449402891263354, \"f2\": 0.25552736498731426, \"f0_5\": 0.5785802215839146, \"p4\": 0.4464840897364717, \"phi\": 0.30492131772526593}, {\"truth_threshold\": 23.2, \"match_probability\": 0.9999998962222966, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2531, \"tn\": 7018, \"fp\": 0, \"fn\": 9250, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21483745013156777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7851625498684323, \"precision\": 1.0, \"recall\": 0.21483745013156777, \"specificity\": 1.0, \"npv\": 0.4313990656503565, \"accuracy\": 0.5079525506675887, \"f1\": 0.35368921185019564, \"f2\": 0.2548585238143188, \"f0_5\": 0.5777219812828122, \"p4\": 0.4457956375817408, \"phi\": 0.30443500990106803}, {\"truth_threshold\": 23.22, \"match_probability\": 0.9999998976510348, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2524, \"tn\": 7018, \"fp\": 0, \"fn\": 9257, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2142432730668025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7857567269331975, \"precision\": 1.0, \"recall\": 0.2142432730668025, \"specificity\": 1.0, \"npv\": 0.43121351766513055, \"accuracy\": 0.5075801904356615, \"f1\": 0.352883607130374, \"f2\": 0.2541894940380277, \"f0_5\": 0.5768615440873978, \"p4\": 0.4451057782671178, \"phi\": 0.3039483433335787}, {\"truth_threshold\": 23.240000000000002, \"match_probability\": 0.9999998990601031, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2517, \"tn\": 7018, \"fp\": 0, \"fn\": 9264, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2136490960020372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7863509039979628, \"precision\": 1.0, \"recall\": 0.2136490960020372, \"specificity\": 1.0, \"npv\": 0.43102812922245426, \"accuracy\": 0.5072078302037343, \"f1\": 0.35207721359630717, \"f2\": 0.25352027557865475, \"f0_5\": 0.5759989015515584, \"p4\": 0.44441450535363775, \"phi\": 0.30346131575511665}, {\"truth_threshold\": 23.26, \"match_probability\": 0.9999999004497723, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2515, \"tn\": 7018, \"fp\": 0, \"fn\": 9266, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21347933112638995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.78652066887361, \"precision\": 1.0, \"recall\": 0.21347933112638995, \"specificity\": 1.0, \"npv\": 0.43097519037091625, \"accuracy\": 0.5071014415660408, \"f1\": 0.35184667039731393, \"f2\": 0.2533290356373013, \"f0_5\": 0.5757520260061353, \"p4\": 0.44421673826101926, \"phi\": 0.3033220983912181}, {\"truth_threshold\": 23.28, \"match_probability\": 0.9999999018203096, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2511, \"tn\": 7018, \"fp\": 0, \"fn\": 9270, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2131398013750955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7868601986249045, \"precision\": 1.0, \"recall\": 0.2131398013750955, \"specificity\": 1.0, \"npv\": 0.43086935166994106, \"accuracy\": 0.5068886642906537, \"f1\": 0.3513853904282116, \"f2\": 0.25294650951949227, \"f0_5\": 0.5752577319587628, \"p4\": 0.4438208556964889, \"phi\": 0.30304357447988794}, {\"truth_threshold\": 23.3, \"match_probability\": 0.9999999031719783, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2508, \"tn\": 7018, \"fp\": 0, \"fn\": 9273, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21288515406162464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7871148459383753, \"precision\": 1.0, \"recall\": 0.21288515406162464, \"specificity\": 1.0, \"npv\": 0.4307900067521945, \"accuracy\": 0.5067290813341135, \"f1\": 0.3510392609699769, \"f2\": 0.2526595744680851, \"f0_5\": 0.5748865355521936, \"p4\": 0.44352363834273195, \"phi\": 0.3028346032996382}, {\"truth_threshold\": 23.32, \"match_probability\": 0.9999999045050382, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2506, \"tn\": 7018, \"fp\": 0, \"fn\": 9275, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21271538918597743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7872846108140226, \"precision\": 1.0, \"recall\": 0.21271538918597743, \"specificity\": 1.0, \"npv\": 0.43073712637328915, \"accuracy\": 0.50662269269642, \"f1\": 0.35080842724154826, \"f2\": 0.2524682651622003, \"f0_5\": 0.5746388443017657, \"p4\": 0.44332534771156973, \"phi\": 0.3026952518182995}, {\"truth_threshold\": 23.34, \"match_probability\": 0.9999999058197454, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2501, \"tn\": 7018, \"fp\": 0, \"fn\": 9280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21229097699685934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7877090230031406, \"precision\": 1.0, \"recall\": 0.21229097699685934, \"specificity\": 1.0, \"npv\": 0.4306049822064057, \"accuracy\": 0.5063567211021863, \"f1\": 0.35023106007561966, \"f2\": 0.25198992443324936, \"f0_5\": 0.5740188202891898, \"p4\": 0.4428291099694021, \"phi\": 0.3023467419574967}, {\"truth_threshold\": 23.36, \"match_probability\": 0.9999999071163527, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2492, \"tn\": 7018, \"fp\": 0, \"fn\": 9289, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21152703505644682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7884729649435532, \"precision\": 1.0, \"recall\": 0.21152703505644682, \"specificity\": 1.0, \"npv\": 0.4303673269148219, \"accuracy\": 0.5058779722325656, \"f1\": 0.3491907797940167, \"f2\": 0.25112866817155755, \"f0_5\": 0.5728999034438365, \"p4\": 0.4419340354007769, \"phi\": 0.30171894976527547}, {\"truth_threshold\": 23.38, \"match_probability\": 0.9999999083951091, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2485, \"tn\": 7018, \"fp\": 0, \"fn\": 9296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.21093285799168152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7890671420083185, \"precision\": 1.0, \"recall\": 0.21093285799168152, \"specificity\": 1.0, \"npv\": 0.43018266519553755, \"accuracy\": 0.5055056120006384, \"f1\": 0.34838076545632973, \"f2\": 0.2504585861436433, \"f0_5\": 0.5720270705768611, \"p4\": 0.44123621729013923, \"phi\": 0.3012302425523928}, {\"truth_threshold\": 23.400000000000002, \"match_probability\": 0.9999999096562606, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2478, \"tn\": 7018, \"fp\": 0, \"fn\": 9303, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2103386809269162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7896613190730838, \"precision\": 1.0, \"recall\": 0.2103386809269162, \"specificity\": 1.0, \"npv\": 0.42999816187733597, \"accuracy\": 0.5051332517687112, \"f1\": 0.3475699558173785, \"f2\": 0.2497883149872989, \"f0_5\": 0.5711519845111326, \"p4\": 0.44053694902559093, \"phi\": 0.30074116141671964}, {\"truth_threshold\": 23.42, \"match_probability\": 0.9999999109000495, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2471, \"tn\": 7018, \"fp\": 0, \"fn\": 9310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20974450386215093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7902554961378491, \"precision\": 1.0, \"recall\": 0.20974450386215093, \"specificity\": 1.0, \"npv\": 0.42981381675649194, \"accuracy\": 0.5047608915367838, \"f1\": 0.3467583497053045, \"f2\": 0.2491178546224418, \"f0_5\": 0.5702746365105008, \"p4\": 0.4398362239215233, \"phi\": 0.30025170398964907}, {\"truth_threshold\": 23.44, \"match_probability\": 0.9999999121267147, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2468, \"tn\": 7018, \"fp\": 0, \"fn\": 9313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20948985654868008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7905101434513199, \"precision\": 1.0, \"recall\": 0.20948985654868008, \"specificity\": 1.0, \"npv\": 0.4297348600820525, \"accuracy\": 0.5046013085802437, \"f1\": 0.34641027440522143, \"f2\": 0.24883045652524602, \"f0_5\": 0.5698979356209302, \"p4\": 0.43953546552638595, \"phi\": 0.3000418207393034}, {\"truth_threshold\": 23.46, \"match_probability\": 0.9999999133364921, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2460, \"tn\": 7018, \"fp\": 0, \"fn\": 9321, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20881079704609115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7911892029539088, \"precision\": 1.0, \"recall\": 0.20881079704609115, \"specificity\": 1.0, \"npv\": 0.42952445070077727, \"accuracy\": 0.5041757540294697, \"f1\": 0.3454813566463029, \"f2\": 0.24806389157792835, \"f0_5\": 0.5688913556264743, \"p4\": 0.4387321248751553, \"phi\": 0.2994817906010544}, {\"truth_threshold\": 23.48, \"match_probability\": 0.9999999145296141, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2454, \"tn\": 7018, \"fp\": 0, \"fn\": 9327, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20830150241914946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7916984975808505, \"precision\": 1.0, \"recall\": 0.20830150241914946, \"specificity\": 1.0, \"npv\": 0.4293667788314469, \"accuracy\": 0.5038565881163891, \"f1\": 0.3447839831401475, \"f2\": 0.2474888055185768, \"f0_5\": 0.5681344631198778, \"p4\": 0.43812835633446073, \"phi\": 0.29906144037548715}, {\"truth_threshold\": 23.5, \"match_probability\": 0.9999999157063101, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2449, \"tn\": 7018, \"fp\": 0, \"fn\": 9332, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2078770902300314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7921229097699686, \"precision\": 1.0, \"recall\": 0.2078770902300314, \"specificity\": 1.0, \"npv\": 0.4292354740061162, \"accuracy\": 0.5035906165221554, \"f1\": 0.3442023893183415, \"f2\": 0.24700946079519093, \"f0_5\": 0.5675024331464059, \"p4\": 0.4376243854235593, \"phi\": 0.29871093277598615}, {\"truth_threshold\": 23.54, \"match_probability\": 0.9999999180113253, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2445, \"tn\": 7018, \"fp\": 0, \"fn\": 9336, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20753756047873695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.792462439521263, \"precision\": 1.0, \"recall\": 0.20753756047873695, \"specificity\": 1.0, \"npv\": 0.42913048795401737, \"accuracy\": 0.5033778392467685, \"f1\": 0.34373681990721217, \"f2\": 0.24662591539066755, \"f0_5\": 0.5669959649366912, \"p4\": 0.43722066332341736, \"phi\": 0.29843038484213835}, {\"truth_threshold\": 23.56, \"match_probability\": 0.9999999191400875, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2443, \"tn\": 7018, \"fp\": 0, \"fn\": 9338, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2073677956030897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7926322043969103, \"precision\": 1.0, \"recall\": 0.2073677956030897, \"specificity\": 1.0, \"npv\": 0.42907801418439717, \"accuracy\": 0.503271450609075, \"f1\": 0.343503937007874, \"f2\": 0.24643411947465046, \"f0_5\": 0.5667424488470283, \"p4\": 0.4370186200419643, \"phi\": 0.29829006343351383}, {\"truth_threshold\": 23.580000000000002, \"match_probability\": 0.9999999202533097, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2442, \"tn\": 7018, \"fp\": 0, \"fn\": 9339, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20728291316526612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7927170868347339, \"precision\": 1.0, \"recall\": 0.20728291316526612, \"specificity\": 1.0, \"npv\": 0.42905178211163414, \"accuracy\": 0.5032182562902282, \"f1\": 0.3433874709976798, \"f2\": 0.24633821571238348, \"f0_5\": 0.5666156202143952, \"p4\": 0.4369175527730735, \"phi\": 0.29821989084373385}, {\"truth_threshold\": 23.6, \"match_probability\": 0.9999999213512059, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2441, \"tn\": 7018, \"fp\": 0, \"fn\": 9340, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2071980307274425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7928019692725575, \"precision\": 1.0, \"recall\": 0.2071980307274425, \"specificity\": 1.0, \"npv\": 0.42902555324611813, \"accuracy\": 0.5031650619713814, \"f1\": 0.343270988609197, \"f2\": 0.2462423080802986, \"f0_5\": 0.5664887444882803, \"p4\": 0.4368164550585739, \"phi\": 0.2981497103207501}, {\"truth_threshold\": 23.62, \"match_probability\": 0.9999999224339869, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2436, \"tn\": 7018, \"fp\": 0, \"fn\": 9345, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20677361853832443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7932263814616756, \"precision\": 1.0, \"recall\": 0.20677361853832443, \"specificity\": 1.0, \"npv\": 0.42889445700666134, \"accuracy\": 0.5028990903771478, \"f1\": 0.34268833087149186, \"f2\": 0.2457627118644068, \"f0_5\": 0.5658536585365853, \"p4\": 0.43631050909627833, \"phi\": 0.29779868845630797}, {\"truth_threshold\": 23.64, \"match_probability\": 0.9999999235018612, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2432, \"tn\": 7018, \"fp\": 0, \"fn\": 9349, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20643408878702996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.79356591121297, \"precision\": 1.0, \"recall\": 0.20643408878702996, \"specificity\": 1.0, \"npv\": 0.42878963768558687, \"accuracy\": 0.5026863131017607, \"f1\": 0.342221909519454, \"f2\": 0.24537896521107433, \"f0_5\": 0.5653447394114092, \"p4\": 0.43590520224620805, \"phi\": 0.29751772743308064}, {\"truth_threshold\": 23.66, \"match_probability\": 0.9999999245550335, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2430, \"tn\": 7018, \"fp\": 0, \"fn\": 9351, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20626432391138275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7937356760886173, \"precision\": 1.0, \"recall\": 0.20626432391138275, \"specificity\": 1.0, \"npv\": 0.42873724723562834, \"accuracy\": 0.5025799244640672, \"f1\": 0.34198860037998735, \"f2\": 0.24518706865237921, \"f0_5\": 0.5650899958141482, \"p4\": 0.4357023650154128, \"phi\": 0.2973771989186195}, {\"truth_threshold\": 23.68, \"match_probability\": 0.9999999255937067, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2428, \"tn\": 7018, \"fp\": 0, \"fn\": 9353, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2060945590357355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7939054409642645, \"precision\": 1.0, \"recall\": 0.2060945590357355, \"specificity\": 1.0, \"npv\": 0.42868486958646385, \"accuracy\": 0.5024735358263738, \"f1\": 0.341755225561264, \"f2\": 0.24499515660316434, \"f0_5\": 0.5648350625785139, \"p4\": 0.43549940503077256, \"phi\": 0.2972366383249448}, {\"truth_threshold\": 23.7, \"match_probability\": 0.99999992661808, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2426, \"tn\": 7018, \"fp\": 0, \"fn\": 9355, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20592479416008827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7940752058399118, \"precision\": 1.0, \"recall\": 0.20592479416008827, \"specificity\": 1.0, \"npv\": 0.42863250473340253, \"accuracy\": 0.5023671471886803, \"f1\": 0.34152178503554587, \"f2\": 0.244803229061554, \"f0_5\": 0.5645799394926693, \"p4\": 0.4352963221294459, \"phi\": 0.2970960455939274}, {\"truth_threshold\": 23.72, \"match_probability\": 0.9999999276283504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2424, \"tn\": 7018, \"fp\": 0, \"fn\": 9357, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20575502928444106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.794244970715559, \"precision\": 1.0, \"recall\": 0.20575502928444106, \"specificity\": 1.0, \"npv\": 0.4285801526717557, \"accuracy\": 0.5022607585509867, \"f1\": 0.3412882787750792, \"f2\": 0.2446112860256721, \"f0_5\": 0.5643246263444616, \"p4\": 0.4350931161483206, \"phi\": 0.29695542066732394}, {\"truth_threshold\": 23.740000000000002, \"match_probability\": 0.9999999286247123, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2422, \"tn\": 7018, \"fp\": 0, \"fn\": 9359, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20558526440879382, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7944147355912062, \"precision\": 1.0, \"recall\": 0.20558526440879382, \"specificity\": 1.0, \"npv\": 0.42852781339683704, \"accuracy\": 0.5021543699132932, \"f1\": 0.34105470675209465, \"f2\": 0.24441932749364229, \"f0_5\": 0.5640691229214216, \"p4\": 0.4348897869240132, \"phi\": 0.2968147634867764}, {\"truth_threshold\": 23.76, \"match_probability\": 0.9999999296073568, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2417, \"tn\": 7018, \"fp\": 0, \"fn\": 9364, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20516085221967575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7948391477803243, \"precision\": 1.0, \"recall\": 0.20516085221967575, \"specificity\": 1.0, \"npv\": 0.4283970211207423, \"accuracy\": 0.5018883983190595, \"f1\": 0.3404704888012396, \"f2\": 0.24393936335560445, \"f0_5\": 0.563429530514243, \"p4\": 0.4343809235996633, \"phi\": 0.29646297904038865}, {\"truth_threshold\": 23.78, \"match_probability\": 0.9999999305764732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2414, \"tn\": 7018, \"fp\": 0, \"fn\": 9367, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2049062049062049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7950937950937951, \"precision\": 1.0, \"recall\": 0.2049062049062049, \"specificity\": 1.0, \"npv\": 0.4283185840707965, \"accuracy\": 0.5017288153625192, \"f1\": 0.3401197604790419, \"f2\": 0.24365133836650651, \"f0_5\": 0.56304520222046, \"p4\": 0.4340752343177627, \"phi\": 0.2962518110539515}, {\"truth_threshold\": 23.8, \"match_probability\": 0.9999999315322473, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2404, \"tn\": 7018, \"fp\": 0, \"fn\": 9377, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20405738052796876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7959426194720313, \"precision\": 1.0, \"recall\": 0.20405738052796876, \"specificity\": 1.0, \"npv\": 0.42805733455321743, \"accuracy\": 0.5011968721740518, \"f1\": 0.3389495946422277, \"f2\": 0.2426910030689711, \"f0_5\": 0.5617609945319437, \"p4\": 0.4330542508687159, \"phi\": 0.29554738774808}, {\"truth_threshold\": 23.82, \"match_probability\": 0.999999932474863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2396, \"tn\": 7018, \"fp\": 0, \"fn\": 9385, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20337832102537984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7966216789746201, \"precision\": 1.0, \"recall\": 0.20337832102537984, \"specificity\": 1.0, \"npv\": 0.42784856428702067, \"accuracy\": 0.5007713176232779, \"f1\": 0.3380122734005784, \"f2\": 0.24192245557350567, \"f0_5\": 0.5607301661596068, \"p4\": 0.4322352170415412, \"phi\": 0.2949832582669965}, {\"truth_threshold\": 23.84, \"match_probability\": 0.9999999334045014, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2394, \"tn\": 7018, \"fp\": 0, \"fn\": 9387, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20320855614973263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7967914438502673, \"precision\": 1.0, \"recall\": 0.20320855614973263, \"specificity\": 1.0, \"npv\": 0.42779640353550746, \"accuracy\": 0.5006649289855843, \"f1\": 0.3377777777777778, \"f2\": 0.24173027989821882, \"f0_5\": 0.56047197640118, \"p4\": 0.4320301451040936, \"phi\": 0.2948421433385988}, {\"truth_threshold\": 23.86, \"match_probability\": 0.9999999343213413, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2386, \"tn\": 7018, \"fp\": 0, \"fn\": 9395, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2025294966471437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7974705033528563, \"precision\": 1.0, \"recall\": 0.2025294966471437, \"specificity\": 1.0, \"npv\": 0.4275878876500335, \"accuracy\": 0.5002393744348104, \"f1\": 0.336839133196866, \"f2\": 0.24096142193496264, \"f0_5\": 0.5594372801875732, \"p4\": 0.43120859840598336, \"phi\": 0.29427735158889945}, {\"truth_threshold\": 23.88, \"match_probability\": 0.9999999352255587, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2382, \"tn\": 7018, \"fp\": 0, \"fn\": 9399, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20218996689584925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7978100331041508, \"precision\": 1.0, \"recall\": 0.20218996689584925, \"specificity\": 1.0, \"npv\": 0.4274837059146007, \"accuracy\": 0.5000265971594233, \"f1\": 0.33636941325990255, \"f2\": 0.24057689976972488, \"f0_5\": 0.558918766718288, \"p4\": 0.43079706733178497, \"phi\": 0.29399475564606264}, {\"truth_threshold\": 23.900000000000002, \"match_probability\": 0.9999999361173275, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2376, \"tn\": 7018, \"fp\": 0, \"fn\": 9405, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20168067226890757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7983193277310925, \"precision\": 1.0, \"recall\": 0.20168067226890757, \"specificity\": 1.0, \"npv\": 0.4273275284661755, \"accuracy\": 0.49970743124634287, \"f1\": 0.3356643356643357, \"f2\": 0.24, \"f0_5\": 0.5581395348837209, \"p4\": 0.43017881976148, \"phi\": 0.2935706102798252}, {\"truth_threshold\": 23.92, \"match_probability\": 0.9999999369968191, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2373, \"tn\": 7018, \"fp\": 0, \"fn\": 9408, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2014260249554367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7985739750445633, \"precision\": 1.0, \"recall\": 0.2014260249554367, \"specificity\": 1.0, \"npv\": 0.4272494825277, \"accuracy\": 0.49954784828980264, \"f1\": 0.3353115727002967, \"f2\": 0.23971149766652525, \"f0_5\": 0.5577492596248766, \"p4\": 0.42986926680348175, \"phi\": 0.2933584239966903}, {\"truth_threshold\": 23.94, \"match_probability\": 0.9999999378642025, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2370, \"tn\": 7018, \"fp\": 0, \"fn\": 9411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20117137764196588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7988286223580341, \"precision\": 1.0, \"recall\": 0.20117137764196588, \"specificity\": 1.0, \"npv\": 0.427171465092215, \"accuracy\": 0.4993882653332624, \"f1\": 0.33495866016535936, \"f2\": 0.23942296035883137, \"f0_5\": 0.5573585438126146, \"p4\": 0.4295594269638102, \"phi\": 0.293146161704256}, {\"truth_threshold\": 23.96, \"match_probability\": 0.9999999387196443, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2365, \"tn\": 7018, \"fp\": 0, \"fn\": 9416, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.20074696545284781, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7992530345471522, \"precision\": 1.0, \"recall\": 0.20074696545284781, \"specificity\": 1.0, \"npv\": 0.42704149933065594, \"accuracy\": 0.49912229373902867, \"f1\": 0.3343701399688958, \"f2\": 0.23894198710824627, \"f0_5\": 0.5567063697566028, \"p4\": 0.4290423881493344, \"phi\": 0.29279222174276337}, {\"truth_threshold\": 24.0, \"match_probability\": 0.9999999403953588, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2357, \"tn\": 7018, \"fp\": 0, \"fn\": 9424, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.2000679059502589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7999320940497411, \"precision\": 1.0, \"recall\": 0.2000679059502589, \"specificity\": 1.0, \"npv\": 0.4268337185257268, \"accuracy\": 0.4986967391882547, \"f1\": 0.3334276418163814, \"f2\": 0.23817222772377275, \"f0_5\": 0.555660332877552, \"p4\": 0.4282134584844528, \"phi\": 0.29222547502639873}, {\"truth_threshold\": 24.02, \"match_probability\": 0.9999999412159535, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2355, \"tn\": 7018, \"fp\": 0, \"fn\": 9426, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19989814107461165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8001018589253883, \"precision\": 1.0, \"recall\": 0.19989814107461165, \"specificity\": 1.0, \"npv\": 0.4267818049136463, \"accuracy\": 0.4985903505505612, \"f1\": 0.3331918505942275, \"f2\": 0.23797974898441762, \"f0_5\": 0.5553983302674402, \"p4\": 0.42800590430661745, \"phi\": 0.29208370280915275}, {\"truth_threshold\": 24.04, \"match_probability\": 0.9999999420252508, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2354, \"tn\": 7018, \"fp\": 0, \"fn\": 9427, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19981325863678806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.800186741363212, \"precision\": 1.0, \"recall\": 0.19981325863678806, \"specificity\": 1.0, \"npv\": 0.42675585284280937, \"accuracy\": 0.49853715623171446, \"f1\": 0.3330739299610895, \"f2\": 0.23788350377945755, \"f0_5\": 0.5552672548002076, \"p4\": 0.42790207883462406, \"phi\": 0.2920128038268927}, {\"truth_threshold\": 24.060000000000002, \"match_probability\": 0.9999999428234062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2348, \"tn\": 7018, \"fp\": 0, \"fn\": 9433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19930396400984637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8006960359901536, \"precision\": 1.0, \"recall\": 0.19930396400984637, \"specificity\": 1.0, \"npv\": 0.4266002066743663, \"accuracy\": 0.49821799031863395, \"f1\": 0.332366055630264, \"f2\": 0.2373059508408797, \"f0_5\": 0.554479761960988, \"p4\": 0.42727844727352915, \"phi\": 0.29158722920872393}, {\"truth_threshold\": 24.080000000000002, \"match_probability\": 0.9999999436105732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2343, \"tn\": 7018, \"fp\": 0, \"fn\": 9438, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19887955182072828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8011204481792717, \"precision\": 1.0, \"recall\": 0.19887955182072828, \"specificity\": 1.0, \"npv\": 0.4264705882352941, \"accuracy\": 0.49795201872440026, \"f1\": 0.3317757009345794, \"f2\": 0.23682454969979988, \"f0_5\": 0.5538221528861155, \"p4\": 0.4267578631017151, \"phi\": 0.2912323461653215}, {\"truth_threshold\": 24.1, \"match_probability\": 0.9999999443869031, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2340, \"tn\": 7018, \"fp\": 0, \"fn\": 9441, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19862490450725745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8013750954927426, \"precision\": 1.0, \"recall\": 0.19862490450725745, \"specificity\": 1.0, \"npv\": 0.42639285497296314, \"accuracy\": 0.49779243576786, \"f1\": 0.331421287444232, \"f2\": 0.23653566229985443, \"f0_5\": 0.5534269902085994, \"p4\": 0.4264451224877539, \"phi\": 0.2910193122484858}, {\"truth_threshold\": 24.12, \"match_probability\": 0.999999945152545, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2334, \"tn\": 7018, \"fp\": 0, \"fn\": 9447, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19811560988031576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8018843901196843, \"precision\": 1.0, \"recall\": 0.19811560988031576, \"specificity\": 1.0, \"npv\": 0.42623747342848467, \"accuracy\": 0.4974732698547795, \"f1\": 0.33071200850159405, \"f2\": 0.23595778236079099, \"f0_5\": 0.5526353175166927, \"p4\": 0.42581876074977115, \"phi\": 0.2905930092106985}, {\"truth_threshold\": 24.14, \"match_probability\": 0.9999999459076461, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2330, \"tn\": 7018, \"fp\": 0, \"fn\": 9451, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19777608012902131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8022239198709787, \"precision\": 1.0, \"recall\": 0.19777608012902131, \"specificity\": 1.0, \"npv\": 0.4261339486307608, \"accuracy\": 0.49726049257939253, \"f1\": 0.33023882077811634, \"f2\": 0.2355724511667408, \"f0_5\": 0.552106535235297, \"p4\": 0.4254005321220335, \"phi\": 0.29030863226933784}, {\"truth_threshold\": 24.16, \"match_probability\": 0.9999999466523515, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2325, \"tn\": 7018, \"fp\": 0, \"fn\": 9456, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19735166793990325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8026483320600968, \"precision\": 1.0, \"recall\": 0.19735166793990325, \"specificity\": 1.0, \"npv\": 0.4260046133300959, \"accuracy\": 0.4969945209851588, \"f1\": 0.3296469587409613, \"f2\": 0.2350906995085846, \"f0_5\": 0.5514444286324178, \"p4\": 0.42487700795095223, \"phi\": 0.2899529634109435}, {\"truth_threshold\": 24.18, \"match_probability\": 0.9999999473868042, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2322, \"tn\": 7018, \"fp\": 0, \"fn\": 9459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1970970206264324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8029029793735676, \"precision\": 1.0, \"recall\": 0.1970970206264324, \"specificity\": 1.0, \"npv\": 0.4259270498270316, \"accuracy\": 0.49683493802861856, \"f1\": 0.32929164007657946, \"f2\": 0.23480160174736076, \"f0_5\": 0.5510465612985903, \"p4\": 0.42456249857845596, \"phi\": 0.2897394562794545}, {\"truth_threshold\": 24.2, \"match_probability\": 0.9999999481111456, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2321, \"tn\": 7018, \"fp\": 0, \"fn\": 9460, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19701213818860877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8029878618113913, \"precision\": 1.0, \"recall\": 0.19701213818860877, \"specificity\": 1.0, \"npv\": 0.4259012016021362, \"accuracy\": 0.4967817437097718, \"f1\": 0.3291731669266771, \"f2\": 0.2347052280311457, \"f0_5\": 0.5509138381201044, \"p4\": 0.42445759617597817, \"phi\": 0.2896682695511101}, {\"truth_threshold\": 24.22, \"match_probability\": 0.9999999488255148, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2319, \"tn\": 7018, \"fp\": 0, \"fn\": 9462, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19684237331296156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8031576266870385, \"precision\": 1.0, \"recall\": 0.19684237331296156, \"specificity\": 1.0, \"npv\": 0.4258495145631068, \"accuracy\": 0.49667535507207833, \"f1\": 0.32893617021276594, \"f2\": 0.23451246890358596, \"f0_5\": 0.5506482404900983, \"p4\": 0.4242476923199041, \"phi\": 0.28952586951907167}, {\"truth_threshold\": 24.240000000000002, \"match_probability\": 0.999999949530049, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2315, \"tn\": 7018, \"fp\": 0, \"fn\": 9466, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19650284356166708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8034971564383329, \"precision\": 1.0, \"recall\": 0.19650284356166708, \"specificity\": 1.0, \"npv\": 0.4257461781121087, \"accuracy\": 0.49646257779669134, \"f1\": 0.3284619750283768, \"f2\": 0.23412690386132406, \"f0_5\": 0.5501164393327314, \"p4\": 0.4238274877782556, \"phi\": 0.289240962926314}, {\"truth_threshold\": 24.26, \"match_probability\": 0.9999999502248836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2314, \"tn\": 7018, \"fp\": 0, \"fn\": 9467, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19641796112384347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8035820388761565, \"precision\": 1.0, \"recall\": 0.19641796112384347, \"specificity\": 1.0, \"npv\": 0.4257203518350015, \"accuracy\": 0.4964093834778446, \"f1\": 0.3283433841787868, \"f2\": 0.23403050285205712, \"f0_5\": 0.5499833626467652, \"p4\": 0.42372235383959517, \"phi\": 0.28916971403720043}, {\"truth_threshold\": 24.28, \"match_probability\": 0.9999999509101524, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2313, \"tn\": 7018, \"fp\": 0, \"fn\": 9468, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19633307868601987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8036669213139801, \"precision\": 1.0, \"recall\": 0.19633307868601987, \"specificity\": 1.0, \"npv\": 0.42569452869101054, \"accuracy\": 0.4963561891589978, \"f1\": 0.3282247765006386, \"f2\": 0.23393409794283634, \"f0_5\": 0.5498502353444588, \"p4\": 0.4236171867348384, \"phi\": 0.28909845623541525}, {\"truth_threshold\": 24.3, \"match_probability\": 0.9999999515859868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2302, \"tn\": 7018, \"fp\": 0, \"fn\": 9479, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1953993718699601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8046006281300399, \"precision\": 1.0, \"recall\": 0.1953993718699601, \"specificity\": 1.0, \"npv\": 0.4254106807298297, \"accuracy\": 0.4957710516516836, \"f1\": 0.3269189803308954, \"f2\": 0.23287338647675312, \"f0_5\": 0.5483824860641289, \"p4\": 0.42245815319093344, \"phi\": 0.2883140298379197}, {\"truth_threshold\": 24.32, \"match_probability\": 0.9999999522525168, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2297, \"tn\": 7018, \"fp\": 0, \"fn\": 9484, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19497495968084202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.805025040319158, \"precision\": 1.0, \"recall\": 0.19497495968084202, \"specificity\": 1.0, \"npv\": 0.42528178402617867, \"accuracy\": 0.49550508005744986, \"f1\": 0.3263247620400625, \"f2\": 0.23239108880840129, \"f0_5\": 0.5477132910486909, \"p4\": 0.42192998410651084, \"phi\": 0.28795711259404716}, {\"truth_threshold\": 24.34, \"match_probability\": 0.9999999529098704, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2292, \"tn\": 7018, \"fp\": 0, \"fn\": 9489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19455054749172396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.805449452508276, \"precision\": 1.0, \"recall\": 0.19455054749172396, \"specificity\": 1.0, \"npv\": 0.4251529654086145, \"accuracy\": 0.4952391084632161, \"f1\": 0.32573012150927305, \"f2\": 0.23190869354055366, \"f0_5\": 0.5470428182729485, \"p4\": 0.42140097626979145, \"phi\": 0.2875999690333362}, {\"truth_threshold\": 24.36, \"match_probability\": 0.9999999535581742, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2283, \"tn\": 7018, \"fp\": 0, \"fn\": 9498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19378660555131144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8062133944486886, \"precision\": 1.0, \"recall\": 0.19378660555131144, \"specificity\": 1.0, \"npv\": 0.424921288447566, \"accuracy\": 0.4947603595935954, \"f1\": 0.3246587030716723, \"f2\": 0.23104013601311554, \"f0_5\": 0.5458327356189929, \"p4\": 0.42044663940339966, \"phi\": 0.2869565369785876}, {\"truth_threshold\": 24.400000000000002, \"match_probability\": 0.9999999548281283, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2280, \"tn\": 7018, \"fp\": 0, \"fn\": 9501, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19353195823784058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8064680417621594, \"precision\": 1.0, \"recall\": 0.19353195823784058, \"specificity\": 1.0, \"npv\": 0.42484411889339546, \"accuracy\": 0.49460077663705515, \"f1\": 0.32430125880093874, \"f2\": 0.23075054651445226, \"f0_5\": 0.5454284483995981, \"p4\": 0.4201279182732069, \"phi\": 0.28674189487284346}, {\"truth_threshold\": 24.44, \"match_probability\": 0.9999999560633555, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2277, \"tn\": 7018, \"fp\": 0, \"fn\": 9504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19327731092436976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8067226890756303, \"precision\": 1.0, \"recall\": 0.19327731092436976, \"specificity\": 1.0, \"npv\": 0.4247669773635153, \"accuracy\": 0.4944411936805149, \"f1\": 0.323943661971831, \"f2\": 0.23046092184368738, \"f0_5\": 0.5450236966824644, \"p4\": 0.41980889168621616, \"phi\": 0.2865271700106167}, {\"truth_threshold\": 24.46, \"match_probability\": 0.9999999566682441, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2273, \"tn\": 7018, \"fp\": 0, \"fn\": 9508, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19293778117307528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8070622188269247, \"precision\": 1.0, \"recall\": 0.19293778117307528, \"specificity\": 1.0, \"npv\": 0.42466416555730363, \"accuracy\": 0.49422841640512793, \"f1\": 0.32346662871780274, \"f2\": 0.23007470089276677, \"f0_5\": 0.5444833037895846, \"p4\": 0.41938304666968185, \"phi\": 0.2862407410665744}, {\"truth_threshold\": 24.48, \"match_probability\": 0.9999999572648053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2270, \"tn\": 7018, \"fp\": 0, \"fn\": 9511, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19268313385960445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8073168661403956, \"precision\": 1.0, \"recall\": 0.19268313385960445, \"specificity\": 1.0, \"npv\": 0.4245870893580979, \"accuracy\": 0.4940688334485877, \"f1\": 0.32310867553910755, \"f2\": 0.22978499412884157, \"f0_5\": 0.5440774651263123, \"p4\": 0.41906330492046356, \"phi\": 0.28602582221513884}, {\"truth_threshold\": 24.5, \"match_probability\": 0.9999999578531533, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2264, \"tn\": 7018, \"fp\": 0, \"fn\": 9517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19217383923266276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8078261607673373, \"precision\": 1.0, \"recall\": 0.19217383923266276, \"specificity\": 1.0, \"npv\": 0.4244330208648322, \"accuracy\": 0.4937496675355072, \"f1\": 0.3223923104307583, \"f2\": 0.2292054750141735, \"f0_5\": 0.5432643854681576, \"p4\": 0.418422898162733, \"phi\": 0.2855957337158797}, {\"truth_threshold\": 24.52, \"match_probability\": 0.9999999584334013, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2260, \"tn\": 7018, \"fp\": 0, \"fn\": 9521, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19183430948136831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8081656905186317, \"precision\": 1.0, \"recall\": 0.19183430948136831, \"specificity\": 1.0, \"npv\": 0.42433037063909546, \"accuracy\": 0.4935368902601202, \"f1\": 0.32191439356171214, \"f2\": 0.22881905070468167, \"f0_5\": 0.5427212910042746, \"p4\": 0.4179952744049657, \"phi\": 0.2853088215312032}, {\"truth_threshold\": 24.54, \"match_probability\": 0.999999959005661, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2252, \"tn\": 7018, \"fp\": 0, \"fn\": 9529, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1911552499787794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8088447500212206, \"precision\": 1.0, \"recall\": 0.1911552499787794, \"specificity\": 1.0, \"npv\": 0.42412521907294376, \"accuracy\": 0.49311133570934623, \"f1\": 0.32095774246419156, \"f2\": 0.22804601425793908, \"f0_5\": 0.5416325941603732, \"p4\": 0.4171383739284056, \"phi\": 0.2847345470331852}, {\"truth_threshold\": 24.560000000000002, \"match_probability\": 0.9999999595700421, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2248, \"tn\": 7018, \"fp\": 0, \"fn\": 9533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19081572022748494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8091842797725151, \"precision\": 1.0, \"recall\": 0.19081572022748494, \"specificity\": 1.0, \"npv\": 0.4240227176605643, \"accuracy\": 0.49289855843395924, \"f1\": 0.3204790077696201, \"f2\": 0.2276594020902536, \"f0_5\": 0.5410869879170076, \"p4\": 0.41670909419322943, \"phi\": 0.28444718360921784}, {\"truth_threshold\": 24.580000000000002, \"match_probability\": 0.9999999601266533, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2240, \"tn\": 7018, \"fp\": 0, \"fn\": 9541, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.19013666072489602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.809863339275104, \"precision\": 1.0, \"recall\": 0.19013666072489602, \"specificity\": 1.0, \"npv\": 0.4238178633975482, \"accuracy\": 0.49247300388318527, \"f1\": 0.3195207189216176, \"f2\": 0.22688598979013047, \"f0_5\": 0.5399932500843739, \"p4\": 0.41584886814895167, \"phi\": 0.283872001616873}, {\"truth_threshold\": 24.6, \"match_probability\": 0.9999999606756014, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2236, \"tn\": 7018, \"fp\": 0, \"fn\": 9545, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18979713097360157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8102028690263985, \"precision\": 1.0, \"recall\": 0.18979713097360157, \"specificity\": 1.0, \"npv\": 0.4237155104751555, \"accuracy\": 0.4922602266077983, \"f1\": 0.3190411643004923, \"f2\": 0.22649918962722854, \"f0_5\": 0.5394451145958987, \"p4\": 0.4154179187920308, \"phi\": 0.28358418192346263}, {\"truth_threshold\": 24.62, \"match_probability\": 0.999999961216992, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2234, \"tn\": 7018, \"fp\": 0, \"fn\": 9547, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18962736609795433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8103726339020456, \"precision\": 1.0, \"recall\": 0.18962736609795433, \"specificity\": 1.0, \"npv\": 0.4236643525505584, \"accuracy\": 0.4921538379701048, \"f1\": 0.31880128433820903, \"f2\": 0.22630576603590097, \"f0_5\": 0.5391707293527055, \"p4\": 0.4152022343605632, \"phi\": 0.28344021465515}, {\"truth_threshold\": 24.64, \"match_probability\": 0.9999999617509291, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2227, \"tn\": 7018, \"fp\": 0, \"fn\": 9554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18903318903318903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.810966810966811, \"precision\": 1.0, \"recall\": 0.18903318903318903, \"specificity\": 1.0, \"npv\": 0.42348539705527394, \"accuracy\": 0.49178147773817754, \"f1\": 0.3179611650485437, \"f2\": 0.22562866000688941, \"f0_5\": 0.5382087099424815, \"p4\": 0.4144462343693685, \"phi\": 0.2829360265401787}, {\"truth_threshold\": 24.66, \"match_probability\": 0.9999999622775153, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2220, \"tn\": 7018, \"fp\": 0, \"fn\": 9561, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18843901196842372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8115609880315763, \"precision\": 1.0, \"recall\": 0.18843901196842372, \"specificity\": 1.0, \"npv\": 0.42330659267748355, \"accuracy\": 0.4914091175062503, \"f1\": 0.31712020569959287, \"f2\": 0.22495136186770429, \"f0_5\": 0.5372440830550312, \"p4\": 0.4136885099938492, \"phi\": 0.28243136526219076}, {\"truth_threshold\": 24.68, \"match_probability\": 0.9999999627968519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2216, \"tn\": 7018, \"fp\": 0, \"fn\": 9565, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18809948221712927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8119005177828708, \"precision\": 1.0, \"recall\": 0.18809948221712927, \"specificity\": 1.0, \"npv\": 0.42320448652234216, \"accuracy\": 0.49119634023086334, \"f1\": 0.31663927984568124, \"f2\": 0.22456424807458453, \"f0_5\": 0.5366916929038508, \"p4\": 0.41325474722568667, \"phi\": 0.2821427737632467}, {\"truth_threshold\": 24.7, \"match_probability\": 0.9999999633090386, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2214, \"tn\": 7018, \"fp\": 0, \"fn\": 9567, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18792971734148206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.812070282658518, \"precision\": 1.0, \"recall\": 0.18792971734148206, \"specificity\": 1.0, \"npv\": 0.4231534519143805, \"accuracy\": 0.49108995159316987, \"f1\": 0.3163987138263666, \"f2\": 0.2243706676395476, \"f0_5\": 0.5364151766245093, \"p4\": 0.41303765318797503, \"phi\": 0.2819984195174539}, {\"truth_threshold\": 24.72, \"match_probability\": 0.9999999638141739, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2212, \"tn\": 7018, \"fp\": 0, \"fn\": 9569, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18775995246583482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8122400475341652, \"precision\": 1.0, \"recall\": 0.18775995246583482, \"specificity\": 1.0, \"npv\": 0.42310242961355277, \"accuracy\": 0.49098356295547635, \"f1\": 0.31615807903951976, \"f2\": 0.22417707150964813, \"f0_5\": 0.5361384458771632, \"p4\": 0.41282041712083145, \"phi\": 0.2818540261774167}, {\"truth_threshold\": 24.740000000000002, \"match_probability\": 0.9999999643123548, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2206, \"tn\": 7018, \"fp\": 0, \"fn\": 9575, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18725065783889314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8127493421611068, \"precision\": 1.0, \"recall\": 0.18725065783889314, \"specificity\": 1.0, \"npv\": 0.42294943650937145, \"accuracy\": 0.4906643970423959, \"f1\": 0.3154357617787946, \"f2\": 0.22359618893168456, \"f0_5\": 0.5353069643290463, \"p4\": 0.412167854784259, \"phi\": 0.28142061086382597}, {\"truth_threshold\": 24.76, \"match_probability\": 0.9999999648036773, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2204, \"tn\": 7018, \"fp\": 0, \"fn\": 9577, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1870808929632459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8129191070367541, \"precision\": 1.0, \"recall\": 0.1870808929632459, \"specificity\": 1.0, \"npv\": 0.42289846339258813, \"accuracy\": 0.4905580084047024, \"f1\": 0.31519485162674293, \"f2\": 0.2234025300032436, \"f0_5\": 0.5350293732096907, \"p4\": 0.4119500486391278, \"phi\": 0.28127606041799924}, {\"truth_threshold\": 24.8, \"match_probability\": 0.9999999657661225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2203, \"tn\": 7018, \"fp\": 0, \"fn\": 9578, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18699601052542228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8130039894745777, \"precision\": 1.0, \"recall\": 0.18699601052542228, \"specificity\": 1.0, \"npv\": 0.42287298144131114, \"accuracy\": 0.4905048140858556, \"f1\": 0.31507437070938216, \"f2\": 0.22330569464998884, \"f0_5\": 0.5348904967707473, \"p4\": 0.4118410919496637, \"phi\": 0.281203770402383}, {\"truth_threshold\": 24.82, \"match_probability\": 0.9999999662374304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2199, \"tn\": 7018, \"fp\": 0, \"fn\": 9582, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18665648077412783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8133435192258721, \"precision\": 1.0, \"recall\": 0.18665648077412783, \"specificity\": 1.0, \"npv\": 0.4227710843373494, \"accuracy\": 0.4902920368104686, \"f1\": 0.31459227467811157, \"f2\": 0.22291831397116962, \"f0_5\": 0.5343344510861642, \"p4\": 0.41140490717007167, \"phi\": 0.2809145115074542}, {\"truth_threshold\": 24.84, \"match_probability\": 0.9999999667022497, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2193, \"tn\": 7018, \"fp\": 0, \"fn\": 9588, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18614718614718614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8138528138528138, \"precision\": 1.0, \"recall\": 0.18614718614718614, \"specificity\": 1.0, \"npv\": 0.42261833072383476, \"accuracy\": 0.48997287089738817, \"f1\": 0.31386861313868614, \"f2\": 0.22233712512926576, \"f0_5\": 0.533498759305211, \"p4\": 0.41074955321352785, \"phi\": 0.2804803256530888}, {\"truth_threshold\": 24.86, \"match_probability\": 0.9999999671606695, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2184, \"tn\": 7018, \"fp\": 0, \"fn\": 9597, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18538324420677363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8146167557932263, \"precision\": 1.0, \"recall\": 0.18538324420677363, \"specificity\": 1.0, \"npv\": 0.4223894071622028, \"accuracy\": 0.48949412202776743, \"f1\": 0.31278195488721805, \"f2\": 0.22146507666098808, \"f0_5\": 0.5322415557830092, \"p4\": 0.40976408888275073, \"phi\": 0.2798283735047341}, {\"truth_threshold\": 24.88, \"match_probability\": 0.9999999676127783, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2180, \"tn\": 7018, \"fp\": 0, \"fn\": 9601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18504371445547915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8149562855445208, \"precision\": 1.0, \"recall\": 0.18504371445547915, \"specificity\": 1.0, \"npv\": 0.4222877429448222, \"accuracy\": 0.48928134475238044, \"f1\": 0.3122985459494306, \"f2\": 0.22107739737141002, \"f0_5\": 0.5316813813960295, \"p4\": 0.4093251633144726, \"phi\": 0.2795383560864778}, {\"truth_threshold\": 24.900000000000002, \"match_probability\": 0.9999999680586628, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2176, \"tn\": 7018, \"fp\": 0, \"fn\": 9605, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1847041847041847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8152958152958153, \"precision\": 1.0, \"recall\": 0.1847041847041847, \"specificity\": 1.0, \"npv\": 0.4221861276544547, \"accuracy\": 0.48906856747699345, \"f1\": 0.3118148599269184, \"f2\": 0.2206896551724138, \"f0_5\": 0.5311203319502075, \"p4\": 0.40888565613383787, \"phi\": 0.2792481772578523}, {\"truth_threshold\": 24.92, \"match_probability\": 0.9999999684984086, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2175, \"tn\": 7018, \"fp\": 0, \"fn\": 9606, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18461930226636108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8153806977336389, \"precision\": 1.0, \"recall\": 0.18461930226636108, \"specificity\": 1.0, \"npv\": 0.4221607314725698, \"accuracy\": 0.4890153731581467, \"f1\": 0.3116938950988822, \"f2\": 0.22059270979127366, \"f0_5\": 0.5309799326204775, \"p4\": 0.40877568827271593, \"phi\": 0.2791756072595213}, {\"truth_threshold\": 24.94, \"match_probability\": 0.9999999689321003, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2171, \"tn\": 7018, \"fp\": 0, \"fn\": 9610, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18427977251506664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8157202274849333, \"precision\": 1.0, \"recall\": 0.18427977251506664, \"specificity\": 1.0, \"npv\": 0.42205917729131587, \"accuracy\": 0.4888025958827597, \"f1\": 0.3112098623853211, \"f2\": 0.22020488893396897, \"f0_5\": 0.5304177864646958, \"p4\": 0.4083354518060838, \"phi\": 0.2788852258172524}, {\"truth_threshold\": 24.96, \"match_probability\": 0.9999999693598213, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2163, \"tn\": 7018, \"fp\": 0, \"fn\": 9618, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1836007130124777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8163992869875223, \"precision\": 1.0, \"recall\": 0.1836007130124777, \"specificity\": 1.0, \"npv\": 0.421856215436403, \"accuracy\": 0.48837704133198573, \"f1\": 0.3102409638554217, \"f2\": 0.2194290583723903, \"f0_5\": 0.5292908530318602, \"p4\": 0.4074532214893535, \"phi\": 0.2783039739976219}, {\"truth_threshold\": 24.98, \"match_probability\": 0.9999999697816536, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2158, \"tn\": 7018, \"fp\": 0, \"fn\": 9623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18317630082335964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8168236991766403, \"precision\": 1.0, \"recall\": 0.18317630082335964, \"specificity\": 1.0, \"npv\": 0.42172946337359535, \"accuracy\": 0.48811106973775203, \"f1\": 0.30963483750627735, \"f2\": 0.21894403636216062, \"f0_5\": 0.5285847254200754, \"p4\": 0.40690063295529827, \"phi\": 0.2779403587984223}, {\"truth_threshold\": 25.0, \"match_probability\": 0.9999999701976785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2154, \"tn\": 7018, \"fp\": 0, \"fn\": 9627, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1828367710720652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8171632289279348, \"precision\": 1.0, \"recall\": 0.1828367710720652, \"specificity\": 1.0, \"npv\": 0.421628116551517, \"accuracy\": 0.48789829246236505, \"f1\": 0.3091496232508073, \"f2\": 0.21855594788749544, \"f0_5\": 0.528018826297985, \"p4\": 0.4064578979009791, \"phi\": 0.2776492813307388}, {\"truth_threshold\": 25.02, \"match_probability\": 0.9999999706079759, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2151, \"tn\": 7018, \"fp\": 0, \"fn\": 9630, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18258212375859434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8174178762414056, \"precision\": 1.0, \"recall\": 0.18258212375859434, \"specificity\": 1.0, \"npv\": 0.4215521383950024, \"accuracy\": 0.48773870950582476, \"f1\": 0.3087855297157623, \"f2\": 0.2182648401826484, \"f0_5\": 0.5275938189845475, \"p4\": 0.40612545806492695, \"phi\": 0.27743086472693773}, {\"truth_threshold\": 25.04, \"match_probability\": 0.9999999710126245, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2149, \"tn\": 7018, \"fp\": 0, \"fn\": 9632, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18241235888294713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8175876411170528, \"precision\": 1.0, \"recall\": 0.18241235888294713, \"specificity\": 1.0, \"npv\": 0.4215015015015015, \"accuracy\": 0.4876323208681313, \"f1\": 0.3085427135678392, \"f2\": 0.21807074868589288, \"f0_5\": 0.5273102026794916, \"p4\": 0.4059036460992462, \"phi\": 0.277285201843865}, {\"truth_threshold\": 25.060000000000002, \"match_probability\": 0.9999999714117023, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2148, \"tn\": 7018, \"fp\": 0, \"fn\": 9633, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1823274764451235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8176725235548765, \"precision\": 1.0, \"recall\": 0.1823274764451235, \"specificity\": 1.0, \"npv\": 0.42147618761635935, \"accuracy\": 0.48757912654928454, \"f1\": 0.30842127934525093, \"f2\": 0.21797369702873842, \"f0_5\": 0.5271683109998527, \"p4\": 0.40579268441639393, \"phi\": 0.27721235482893297}, {\"truth_threshold\": 25.080000000000002, \"match_probability\": 0.9999999718052858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2147, \"tn\": 7018, \"fp\": 0, \"fn\": 9634, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1822425940072999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8177574059927001, \"precision\": 1.0, \"recall\": 0.1822425940072999, \"specificity\": 1.0, \"npv\": 0.42145087677155896, \"accuracy\": 0.4875259322304378, \"f1\": 0.3082998276852384, \"f2\": 0.21787664143207972, \"f0_5\": 0.5270263635917325, \"p4\": 0.4056816855656947, \"phi\": 0.27713949741871835}, {\"truth_threshold\": 25.1, \"match_probability\": 0.9999999721934507, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2146, \"tn\": 7018, \"fp\": 0, \"fn\": 9635, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18215771156947627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8178422884305238, \"precision\": 1.0, \"recall\": 0.18215771156947627, \"specificity\": 1.0, \"npv\": 0.4214255689665526, \"accuracy\": 0.48747273791159107, \"f1\": 0.30817835858404535, \"f2\": 0.2177795818956769, \"f0_5\": 0.5268843604222931, \"p4\": 0.40557064952124056, \"phi\": 0.2770666296034434}, {\"truth_threshold\": 25.14, \"match_probability\": 0.9999999729538223, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2143, \"tn\": 7018, \"fp\": 0, \"fn\": 9638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18190306425600544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8180969357439946, \"precision\": 1.0, \"recall\": 0.18190306425600544, \"specificity\": 1.0, \"npv\": 0.4213496637848223, \"accuracy\": 0.4873131549550508, \"f1\": 0.3078138465958058, \"f2\": 0.21748837964560455, \"f0_5\": 0.5264580160172947, \"p4\": 0.4052373179659253, \"phi\": 0.2768479636293119}, {\"truth_threshold\": 25.16, \"match_probability\": 0.999999973326175, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2136, \"tn\": 7018, \"fp\": 0, \"fn\": 9645, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18130888719124014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8186911128087598, \"precision\": 1.0, \"recall\": 0.18130888719124014, \"specificity\": 1.0, \"npv\": 0.42117265798475667, \"accuracy\": 0.48694079472312357, \"f1\": 0.3069627074800604, \"f2\": 0.21680876979293545, \"f0_5\": 0.5254612546125461, \"p4\": 0.40445823770401074, \"phi\": 0.27633737701330413}, {\"truth_threshold\": 25.18, \"match_probability\": 0.9999999736934014, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2133, \"tn\": 7018, \"fp\": 0, \"fn\": 9648, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18105423987776928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8189457601222307, \"precision\": 1.0, \"recall\": 0.18105423987776928, \"specificity\": 1.0, \"npv\": 0.42109684387375496, \"accuracy\": 0.48678121176658334, \"f1\": 0.30659767141009053, \"f2\": 0.21651744929654668, \"f0_5\": 0.5250332299512628, \"p4\": 0.4041237844816988, \"phi\": 0.2761183966752132}, {\"truth_threshold\": 25.2, \"match_probability\": 0.9999999740555722, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2129, \"tn\": 7018, \"fp\": 0, \"fn\": 9652, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18071471012647483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8192852898735251, \"precision\": 1.0, \"recall\": 0.18071471012647483, \"specificity\": 1.0, \"npv\": 0.420995800839832, \"accuracy\": 0.48656843449119636, \"f1\": 0.3061107117181884, \"f2\": 0.21612896676344587, \"f0_5\": 0.524461743114746, \"p4\": 0.40367732090477426, \"phi\": 0.2758262752408359}, {\"truth_threshold\": 25.22, \"match_probability\": 0.9999999744127567, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2127, \"tn\": 7018, \"fp\": 0, \"fn\": 9654, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1805449452508276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8194550547491724, \"precision\": 1.0, \"recall\": 0.1805449452508276, \"specificity\": 1.0, \"npv\": 0.4209452975047985, \"accuracy\": 0.48646204585350283, \"f1\": 0.3058671268334771, \"f2\": 0.2159347018334653, \"f0_5\": 0.5241756616885997, \"p4\": 0.40345386323727456, \"phi\": 0.2756801510656819}, {\"truth_threshold\": 25.240000000000002, \"match_probability\": 0.9999999747650239, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2125, \"tn\": 7018, \"fp\": 0, \"fn\": 9656, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18037518037518038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8196248196248196, \"precision\": 1.0, \"recall\": 0.18037518037518038, \"specificity\": 1.0, \"npv\": 0.4208948062852345, \"accuracy\": 0.48635565721580937, \"f1\": 0.3056234718826406, \"f2\": 0.21574042112530203, \"f0_5\": 0.5238893545683152, \"p4\": 0.4032302547027059, \"phi\": 0.27553398447864064}, {\"truth_threshold\": 25.26, \"match_probability\": 0.9999999751124412, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2122, \"tn\": 7018, \"fp\": 0, \"fn\": 9659, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.18012053306170953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8198794669382905, \"precision\": 1.0, \"recall\": 0.18012053306170953, \"specificity\": 1.0, \"npv\": 0.420819092162859, \"accuracy\": 0.4861960742592691, \"f1\": 0.3052578580162555, \"f2\": 0.21544897047475936, \"f0_5\": 0.5234594701267946, \"p4\": 0.4028945585628833, \"phi\": 0.27531465490038637}, {\"truth_threshold\": 25.28, \"match_probability\": 0.9999999754550756, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2119, \"tn\": 7018, \"fp\": 0, \"fn\": 9662, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1798658857482387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8201341142517613, \"precision\": 1.0, \"recall\": 0.1798658857482387, \"specificity\": 1.0, \"npv\": 0.42074340527577936, \"accuracy\": 0.48603649130272886, \"f1\": 0.30489208633093523, \"f2\": 0.21515748431249113, \"f0_5\": 0.5230290763686627, \"p4\": 0.40255852178219137, \"phi\": 0.2750952294436569}, {\"truth_threshold\": 25.3, \"match_probability\": 0.9999999757929928, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2112, \"tn\": 7018, \"fp\": 0, \"fn\": 9669, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1792717086834734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8207282913165266, \"precision\": 1.0, \"recall\": 0.1792717086834734, \"specificity\": 1.0, \"npv\": 0.4205669083717864, \"accuracy\": 0.48566413107080164, \"f1\": 0.30403800475059384, \"f2\": 0.21447721179624665, \"f0_5\": 0.5220228384991843, \"p4\": 0.40177310721788456, \"phi\": 0.2745828623194389}, {\"truth_threshold\": 25.32, \"match_probability\": 0.9999999761262578, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2109, \"tn\": 7018, \"fp\": 0, \"fn\": 9672, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17901706137000253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8209829386299975, \"precision\": 1.0, \"recall\": 0.17901706137000253, \"specificity\": 1.0, \"npv\": 0.42049131216297186, \"accuracy\": 0.4855045481142614, \"f1\": 0.30367170626349893, \"f2\": 0.21418560721467308, \"f0_5\": 0.5215907404659444, \"p4\": 0.40143592978235343, \"phi\": 0.2743631152961922}, {\"truth_threshold\": 25.34, \"match_probability\": 0.9999999764549347, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2101, \"tn\": 7018, \"fp\": 0, \"fn\": 9680, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17833800186741364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8216619981325863, \"precision\": 1.0, \"recall\": 0.17833800186741364, \"specificity\": 1.0, \"npv\": 0.42028985507246375, \"accuracy\": 0.48507899356348744, \"f1\": 0.30269413629160064, \"f2\": 0.21340782122905028, \"f0_5\": 0.5204359673024523, \"p4\": 0.40053510738303566, \"phi\": 0.27377664794274925}, {\"truth_threshold\": 25.38, \"match_probability\": 0.9999999770987757, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2096, \"tn\": 7018, \"fp\": 0, \"fn\": 9685, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17791358967829557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8220864103217045, \"precision\": 1.0, \"recall\": 0.17791358967829557, \"specificity\": 1.0, \"npv\": 0.420164042387595, \"accuracy\": 0.4848130219692537, \"f1\": 0.3020825826907833, \"f2\": 0.21292157659488012, \"f0_5\": 0.5197123729233821, \"p4\": 0.39997084590952436, \"phi\": 0.2734097529989019}, {\"truth_threshold\": 25.400000000000002, \"match_probability\": 0.9999999774140637, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2092, \"tn\": 7018, \"fp\": 0, \"fn\": 9689, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1775740599270011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8224259400729989, \"precision\": 1.0, \"recall\": 0.1775740599270011, \"specificity\": 1.0, \"npv\": 0.42006344645956784, \"accuracy\": 0.4846002446938667, \"f1\": 0.3015930224176458, \"f2\": 0.21253250975292587, \"f0_5\": 0.519132463149536, \"p4\": 0.3995187430642301, \"phi\": 0.2731160405665583}, {\"truth_threshold\": 25.42, \"match_probability\": 0.9999999777250109, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2088, \"tn\": 7018, \"fp\": 0, \"fn\": 9693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17723453017570664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8227654698242933, \"precision\": 1.0, \"recall\": 0.17723453017570664, \"specificity\": 1.0, \"npv\": 0.41996289868948594, \"accuracy\": 0.4843874674184797, \"f1\": 0.3011031797534069, \"f2\": 0.2121433796634967, \"f0_5\": 0.5185516316495307, \"p4\": 0.3990660217430707, \"phi\": 0.27282215276707084}, {\"truth_threshold\": 25.44, \"match_probability\": 0.9999999780316773, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2087, \"tn\": 7018, \"fp\": 0, \"fn\": 9694, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17714964773788303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.822850352262117, \"precision\": 1.0, \"recall\": 0.17714964773788303, \"specificity\": 1.0, \"npv\": 0.41993776926759213, \"accuracy\": 0.48433427309963295, \"f1\": 0.3009806749351024, \"f2\": 0.2120460872569141, \"f0_5\": 0.5184062794972428, \"p4\": 0.3989527445715507, \"phi\": 0.2727486533378054}, {\"truth_threshold\": 25.46, \"match_probability\": 0.9999999783341216, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2084, \"tn\": 7018, \"fp\": 0, \"fn\": 9697, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1768950004244122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8231049995755878, \"precision\": 1.0, \"recall\": 0.1768950004244122, \"specificity\": 1.0, \"npv\": 0.41986239904277595, \"accuracy\": 0.4841746901430927, \"f1\": 0.3006130544536603, \"f2\": 0.2117541863111689, \"f0_5\": 0.5179698762240891, \"p4\": 0.3986126802008627, \"phi\": 0.2725280889318871}, {\"truth_threshold\": 25.48, \"match_probability\": 0.9999999786324022, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2081, \"tn\": 7018, \"fp\": 0, \"fn\": 9700, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17664035311094134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8233596468890586, \"precision\": 1.0, \"recall\": 0.17664035311094134, \"specificity\": 1.0, \"npv\": 0.4197870558679268, \"accuracy\": 0.4840151071865525, \"f1\": 0.3002452748521137, \"f2\": 0.21146224977136469, \"f0_5\": 0.5175329520019896, \"p4\": 0.398272265970772, \"phi\": 0.27230742512813166}, {\"truth_threshold\": 25.5, \"match_probability\": 0.9999999789265762, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2079, \"tn\": 7018, \"fp\": 0, \"fn\": 9702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17647058823529413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8235294117647058, \"precision\": 1.0, \"recall\": 0.17647058823529413, \"specificity\": 1.0, \"npv\": 0.41973684210526313, \"accuracy\": 0.483908718548859, \"f1\": 0.3, \"f2\": 0.2112676056338028, \"f0_5\": 0.5172413793103449, \"p4\": 0.3980451284184257, \"phi\": 0.27216026056414}, {\"truth_threshold\": 25.52, \"match_probability\": 0.9999999792167003, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2076, \"tn\": 7018, \"fp\": 0, \"fn\": 9705, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17621594092182327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8237840590781768, \"precision\": 1.0, \"recall\": 0.17621594092182327, \"specificity\": 1.0, \"npv\": 0.4196615439813431, \"accuracy\": 0.48374913559231875, \"f1\": 0.29963195496860795, \"f2\": 0.21097560975609755, \"f0_5\": 0.5168035847647499, \"p4\": 0.3977041294411942, \"phi\": 0.27193943046453833}, {\"truth_threshold\": 25.54, \"match_probability\": 0.99999997950283, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2072, \"tn\": 7018, \"fp\": 0, \"fn\": 9709, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17587641117052882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8241235888294712, \"precision\": 1.0, \"recall\": 0.17587641117052882, \"specificity\": 1.0, \"npv\": 0.41956118849763857, \"accuracy\": 0.48353635831693176, \"f1\": 0.2991409802930773, \"f2\": 0.2105862265224815, \"f0_5\": 0.5162190442971748, \"p4\": 0.39724891670190887, \"phi\": 0.2716448344795211}, {\"truth_threshold\": 25.560000000000002, \"match_probability\": 0.9999999797850206, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2066, \"tn\": 7018, \"fp\": 0, \"fn\": 9715, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17536711654358714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8246328834564128, \"precision\": 1.0, \"recall\": 0.17536711654358714, \"specificity\": 1.0, \"npv\": 0.4194107452339688, \"accuracy\": 0.48321719240385125, \"f1\": 0.29840398642305194, \"f2\": 0.21000203293352307, \"f0_5\": 0.5153404839111998, \"p4\": 0.3965649209165604, \"phi\": 0.27120260514802974}, {\"truth_threshold\": 25.580000000000002, \"match_probability\": 0.9999999800633262, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2061, \"tn\": 7018, \"fp\": 0, \"fn\": 9720, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17494270435446907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.825057295645531, \"precision\": 1.0, \"recall\": 0.17494270435446907, \"specificity\": 1.0, \"npv\": 0.4192854582387382, \"accuracy\": 0.48295122080961755, \"f1\": 0.2977893368010403, \"f2\": 0.20951509606587373, \"f0_5\": 0.5146067415730337, \"p4\": 0.39599384198704335, \"phi\": 0.27083377182468893}, {\"truth_threshold\": 25.6, \"match_probability\": 0.9999999803378004, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2058, \"tn\": 7018, \"fp\": 0, \"fn\": 9723, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1746880570409982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8253119429590018, \"precision\": 1.0, \"recall\": 0.1746880570409982, \"specificity\": 1.0, \"npv\": 0.4192103219640404, \"accuracy\": 0.48279163785307727, \"f1\": 0.29742033383915023, \"f2\": 0.20922288642186165, \"f0_5\": 0.5141657922350472, \"p4\": 0.3956507207283392, \"phi\": 0.270612336443536}, {\"truth_threshold\": 25.62, \"match_probability\": 0.9999999806084956, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2054, \"tn\": 7018, \"fp\": 0, \"fn\": 9727, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17434852728970376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8256514727102963, \"precision\": 1.0, \"recall\": 0.17434852728970376, \"specificity\": 1.0, \"npv\": 0.41911018214392354, \"accuracy\": 0.4825788605776903, \"f1\": 0.2969280809541019, \"f2\": 0.208833218105657, \"f0_5\": 0.5135770365554834, \"p4\": 0.3951926712631013, \"phi\": 0.2703169307108095}, {\"truth_threshold\": 25.64, \"match_probability\": 0.9999999808754642, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2049, \"tn\": 7018, \"fp\": 0, \"fn\": 9732, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1739241151005857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8260758848994143, \"precision\": 1.0, \"recall\": 0.1739241151005857, \"specificity\": 1.0, \"npv\": 0.4189850746268657, \"accuracy\": 0.4823128889834566, \"f1\": 0.2963123644251627, \"f2\": 0.20834604356049052, \"f0_5\": 0.5128397657305902, \"p4\": 0.39461921581383347, \"phi\": 0.2699474177406231}, {\"truth_threshold\": 25.66, \"match_probability\": 0.9999999811387573, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2045, \"tn\": 7018, \"fp\": 0, \"fn\": 9736, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17358458534929122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8264154146507088, \"precision\": 1.0, \"recall\": 0.17358458534929122, \"specificity\": 1.0, \"npv\": 0.4188850423779396, \"accuracy\": 0.4821001117080696, \"f1\": 0.29581947056270796, \"f2\": 0.20795623258557222, \"f0_5\": 0.5122488853263865, \"p4\": 0.3941597343583087, \"phi\": 0.26965160186840154}, {\"truth_threshold\": 25.68, \"match_probability\": 0.9999999813984256, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2042, \"tn\": 7018, \"fp\": 0, \"fn\": 9739, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1733299380358204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8266700619641796, \"precision\": 1.0, \"recall\": 0.1733299380358204, \"specificity\": 1.0, \"npv\": 0.41881004953153905, \"accuracy\": 0.4819405287515293, \"f1\": 0.29544961296390077, \"f2\": 0.20766383272993533, \"f0_5\": 0.5118051030126823, \"p4\": 0.3938147037706469, \"phi\": 0.26942961963021167}, {\"truth_threshold\": 25.7, \"match_probability\": 0.999999981654519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2041, \"tn\": 7018, \"fp\": 0, \"fn\": 9740, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17324505559799677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8267549444020033, \"precision\": 1.0, \"recall\": 0.17324505559799677, \"specificity\": 1.0, \"npv\": 0.41878505788280224, \"accuracy\": 0.4818873344326826, \"f1\": 0.2953262914194762, \"f2\": 0.20756635818163327, \"f0_5\": 0.5116570569064929, \"p4\": 0.39369961351920596, \"phi\": 0.2693556025712411}, {\"truth_threshold\": 25.72, \"match_probability\": 0.9999999819070866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2035, \"tn\": 7018, \"fp\": 0, \"fn\": 9746, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17273576097105509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8272642390289449, \"precision\": 1.0, \"recall\": 0.17273576097105509, \"specificity\": 1.0, \"npv\": 0.41863517060367456, \"accuracy\": 0.4815681685196021, \"f1\": 0.2945859872611465, \"f2\": 0.20698142761244126, \"f0_5\": 0.5107675317504141, \"p4\": 0.3930082294318312, \"phi\": 0.2689112581568001}, {\"truth_threshold\": 25.740000000000002, \"match_probability\": 0.9999999821561771, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2033, \"tn\": 7018, \"fp\": 0, \"fn\": 9748, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17256599609540785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8274340039045921, \"precision\": 1.0, \"recall\": 0.17256599609540785, \"specificity\": 1.0, \"npv\": 0.4185852320171776, \"accuracy\": 0.48146177988190864, \"f1\": 0.2943390762994064, \"f2\": 0.20678641902475742, \"f0_5\": 0.5104705468789233, \"p4\": 0.3927774464009944, \"phi\": 0.26876305087171426}, {\"truth_threshold\": 25.76, \"match_probability\": 0.9999999824018383, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2030, \"tn\": 7018, \"fp\": 0, \"fn\": 9751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17231134878193702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.827688651218063, \"precision\": 1.0, \"recall\": 0.17231134878193702, \"specificity\": 1.0, \"npv\": 0.4185103464726579, \"accuracy\": 0.48130219692536835, \"f1\": 0.2939685757729346, \"f2\": 0.2064938763884933, \"f0_5\": 0.5100246218782976, \"p4\": 0.3924309695024436, \"phi\": 0.2685406529371288}, {\"truth_threshold\": 25.78, \"match_probability\": 0.9999999826441174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2024, \"tn\": 7018, \"fp\": 0, \"fn\": 9757, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17180205415499533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8281979458450047, \"precision\": 1.0, \"recall\": 0.17180205415499533, \"specificity\": 1.0, \"npv\": 0.4183606557377049, \"accuracy\": 0.4809830310122879, \"f1\": 0.2932270916334661, \"f2\": 0.20590868397493287, \"f0_5\": 0.509131156613171, \"p4\": 0.3917369243886202, \"phi\": 0.2680955427331244}, {\"truth_threshold\": 25.8, \"match_probability\": 0.9999999828830609, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2019, \"tn\": 7018, \"fp\": 0, \"fn\": 9762, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17137764196587726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8286223580341228, \"precision\": 1.0, \"recall\": 0.17137764196587726, \"specificity\": 1.0, \"npv\": 0.41823599523241956, \"accuracy\": 0.48071705941805415, \"f1\": 0.2926086956521739, \"f2\": 0.20542091447408584, \"f0_5\": 0.5083849524097296, \"p4\": 0.3911574382282445, \"phi\": 0.26772429596169256}, {\"truth_threshold\": 25.82, \"match_probability\": 0.9999999831187149, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2013, \"tn\": 7018, \"fp\": 0, \"fn\": 9768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17086834733893558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8291316526610645, \"precision\": 1.0, \"recall\": 0.17086834733893558, \"specificity\": 1.0, \"npv\": 0.418086500655308, \"accuracy\": 0.4803978935049737, \"f1\": 0.291866028708134, \"f2\": 0.20483546004029551, \"f0_5\": 0.5074875207986689, \"p4\": 0.3904607111325146, \"phi\": 0.267278411795063}, {\"truth_threshold\": 25.84, \"match_probability\": 0.9999999833511245, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2009, \"tn\": 7018, \"fp\": 0, \"fn\": 9772, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17052881758764113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8294711824123588, \"precision\": 1.0, \"recall\": 0.17052881758764113, \"specificity\": 1.0, \"npv\": 0.41798689696247765, \"accuracy\": 0.4801851162295867, \"f1\": 0.2913705583756345, \"f2\": 0.20444507764638836, \"f0_5\": 0.5068880254327093, \"p4\": 0.38999540912161645, \"phi\": 0.26698091936716845}, {\"truth_threshold\": 25.86, \"match_probability\": 0.9999999835803345, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2006, \"tn\": 7018, \"fp\": 0, \"fn\": 9775, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17027417027417027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8297258297258298, \"precision\": 1.0, \"recall\": 0.17027417027417027, \"specificity\": 1.0, \"npv\": 0.4179122253319836, \"accuracy\": 0.4800255332730464, \"f1\": 0.2909987669543773, \"f2\": 0.2041522491349481, \"f0_5\": 0.5064377682403434, \"p4\": 0.3896460022095455, \"phi\": 0.2667576754581498}, {\"truth_threshold\": 25.88, \"match_probability\": 0.9999999838063889, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2004, \"tn\": 7018, \"fp\": 0, \"fn\": 9777, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.17010440539852303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.829895594601477, \"precision\": 1.0, \"recall\": 0.17010440539852303, \"specificity\": 1.0, \"npv\": 0.417862459065198, \"accuracy\": 0.47991914463535296, \"f1\": 0.29075081610446135, \"f2\": 0.2039570102589155, \"f0_5\": 0.5061372935293226, \"p4\": 0.38941285887340726, \"phi\": 0.2666087866850044}, {\"truth_threshold\": 25.900000000000002, \"match_probability\": 0.9999999840293311, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2001, \"tn\": 7018, \"fp\": 0, \"fn\": 9780, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1698497580850522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8301502419149478, \"precision\": 1.0, \"recall\": 0.1698497580850522, \"specificity\": 1.0, \"npv\": 0.41778783188474816, \"accuracy\": 0.47975956167881273, \"f1\": 0.29037875489769266, \"f2\": 0.2036641221374046, \"f0_5\": 0.5056861258529188, \"p4\": 0.389062835188091, \"phi\": 0.2663853640433403}, {\"truth_threshold\": 25.92, \"match_probability\": 0.999999984249204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 2000, \"tn\": 7018, \"fp\": 0, \"fn\": 9781, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16976487564722859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8302351243527714, \"precision\": 1.0, \"recall\": 0.16976487564722859, \"specificity\": 1.0, \"npv\": 0.4177629620810763, \"accuracy\": 0.47970636735996597, \"f1\": 0.29025469849793195, \"f2\": 0.20356648481394024, \"f0_5\": 0.5055356149840756, \"p4\": 0.38894607819331944, \"phi\": 0.2663108659212233}, {\"truth_threshold\": 25.94, \"match_probability\": 0.9999999844660499, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1998, \"tn\": 7018, \"fp\": 0, \"fn\": 9783, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16959511077158135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8304048892284186, \"precision\": 1.0, \"recall\": 0.16959511077158135, \"specificity\": 1.0, \"npv\": 0.4177132313552765, \"accuracy\": 0.47959997872227245, \"f1\": 0.29000653167864143, \"f2\": 0.20337119824111397, \"f0_5\": 0.5052344105598543, \"p4\": 0.38871244037689734, \"phi\": 0.26616183374491037}, {\"truth_threshold\": 25.96, \"match_probability\": 0.9999999846799104, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1995, \"tn\": 7018, \"fp\": 0, \"fn\": 9786, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16934046345811052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8306595365418895, \"precision\": 1.0, \"recall\": 0.16934046345811052, \"specificity\": 1.0, \"npv\": 0.41763865746250894, \"accuracy\": 0.4794403957657322, \"f1\": 0.2896341463414634, \"f2\": 0.20307823856348867, \"f0_5\": 0.5047821466524973, \"p4\": 0.38836167364070356, \"phi\": 0.2659381954754231}, {\"truth_threshold\": 25.98, \"match_probability\": 0.9999999848908265, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1992, \"tn\": 7018, \"fp\": 0, \"fn\": 9789, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16908581614463966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8309141838553603, \"precision\": 1.0, \"recall\": 0.16908581614463966, \"specificity\": 1.0, \"npv\": 0.4175641101921818, \"accuracy\": 0.479280812809192, \"f1\": 0.2892615987802222, \"f2\": 0.20278524309797213, \"f0_5\": 0.5043293331307914, \"p4\": 0.3880105341781892, \"phi\": 0.265714448919428}, {\"truth_threshold\": 26.0, \"match_probability\": 0.999999985098839, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1989, \"tn\": 7018, \"fp\": 0, \"fn\": 9792, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16883116883116883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8311688311688312, \"precision\": 1.0, \"recall\": 0.16883116883116883, \"specificity\": 1.0, \"npv\": 0.4174895895300416, \"accuracy\": 0.47912122985265176, \"f1\": 0.28888888888888886, \"f2\": 0.20249221183800623, \"f0_5\": 0.5038759689922481, \"p4\": 0.3876590211858285, \"phi\": 0.26549059376030976}, {\"truth_threshold\": 26.02, \"match_probability\": 0.9999999853039877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1979, \"tn\": 7018, \"fp\": 0, \"fn\": 9802, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1679823444529327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8320176555470673, \"precision\": 1.0, \"recall\": 0.1679823444529327, \"specificity\": 1.0, \"npv\": 0.41724137931034483, \"accuracy\": 0.47858928666418427, \"f1\": 0.2876453488372093, \"f2\": 0.20151518237174917, \"f0_5\": 0.5023607655988221, \"p4\": 0.38648460313380506, \"phi\": 0.2647436214516359}, {\"truth_threshold\": 26.04, \"match_probability\": 0.9999999855063121, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1978, \"tn\": 7018, \"fp\": 0, \"fn\": 9803, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16789746201510908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.832102537984891, \"precision\": 1.0, \"recall\": 0.16789746201510908, \"specificity\": 1.0, \"npv\": 0.4172165745199453, \"accuracy\": 0.4785360923453375, \"f1\": 0.2875208954139109, \"f2\": 0.2014174575373712, \"f0_5\": 0.5022089067181232, \"p4\": 0.38636693141340434, \"phi\": 0.264668857201856}, {\"truth_threshold\": 26.060000000000002, \"match_probability\": 0.9999999857058509, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1977, \"tn\": 7018, \"fp\": 0, \"fn\": 9804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16781257957728546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8321874204227145, \"precision\": 1.0, \"recall\": 0.16781257957728546, \"specificity\": 1.0, \"npv\": 0.4171917726786351, \"accuracy\": 0.47848289802649074, \"f1\": 0.28739642389882253, \"f2\": 0.2013197287224293, \"f0_5\": 0.5020569861343898, \"p4\": 0.3862492177697981, \"phi\": 0.26459408071916923}, {\"truth_threshold\": 26.080000000000002, \"match_probability\": 0.9999999859026427, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1976, \"tn\": 7018, \"fp\": 0, \"fn\": 9805, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16772769713946184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8322723028605381, \"precision\": 1.0, \"recall\": 0.16772769713946184, \"specificity\": 1.0, \"npv\": 0.41716697378588835, \"accuracy\": 0.47842970370764404, \"f1\": 0.28727193428799885, \"f2\": 0.20122199592668025, \"f0_5\": 0.5019050038100076, \"p4\": 0.3861314621727858, \"phi\": 0.26451929199161506}, {\"truth_threshold\": 26.1, \"match_probability\": 0.9999999860967251, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1971, \"tn\": 7018, \"fp\": 0, \"fn\": 9810, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16730328495034377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8326967150496563, \"precision\": 1.0, \"recall\": 0.16730328495034377, \"specificity\": 1.0, \"npv\": 0.41704302353220823, \"accuracy\": 0.4781637321134103, \"f1\": 0.28664921465968585, \"f2\": 0.20073327222731438, \"f0_5\": 0.5011441647597255, \"p4\": 0.3855420538276652, \"phi\": 0.2641451642611728}, {\"truth_threshold\": 26.12, \"match_probability\": 0.9999999862881357, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1964, \"tn\": 7018, \"fp\": 0, \"fn\": 9817, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16670910788557847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8332908921144215, \"precision\": 1.0, \"recall\": 0.16670910788557847, \"specificity\": 1.0, \"npv\": 0.4168696168696169, \"accuracy\": 0.4777913718814831, \"f1\": 0.2857766460531102, \"f2\": 0.20004889178617993, \"f0_5\": 0.5000763864134032, \"p4\": 0.3847151116119131, \"phi\": 0.2636208677873145}, {\"truth_threshold\": 26.14, \"match_probability\": 0.999999986476911, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1962, \"tn\": 7018, \"fp\": 0, \"fn\": 9819, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16653934300993126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8334606569900688, \"precision\": 1.0, \"recall\": 0.16653934300993126, \"specificity\": 1.0, \"npv\": 0.41682009859238583, \"accuracy\": 0.47768498324378955, \"f1\": 0.28552717747216766, \"f2\": 0.19985331866519984, \"f0_5\": 0.49977074736359467, \"p4\": 0.3844784617282939, \"phi\": 0.26347095736135834}, {\"truth_threshold\": 26.16, \"match_probability\": 0.9999999866630873, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1960, \"tn\": 7018, \"fp\": 0, \"fn\": 9821, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16636957813428402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.833630421865716, \"precision\": 1.0, \"recall\": 0.16636957813428402, \"specificity\": 1.0, \"npv\": 0.4167705920779144, \"accuracy\": 0.4775785946060961, \"f1\": 0.28527763627101377, \"f2\": 0.19965772960638906, \"f0_5\": 0.4994648590795576, \"p4\": 0.3842416422055725, \"phi\": 0.2633209972310951}, {\"truth_threshold\": 26.18, \"match_probability\": 0.9999999868467006, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1952, \"tn\": 7018, \"fp\": 0, \"fn\": 9829, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1656905186316951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8343094813683049, \"precision\": 1.0, \"recall\": 0.1656905186316951, \"specificity\": 1.0, \"npv\": 0.41657268356383925, \"accuracy\": 0.4771530400553221, \"f1\": 0.284278744629724, \"f2\": 0.19887521395386748, \"f0_5\": 0.49823880749400173, \"p4\": 0.3832926628107138, \"phi\": 0.2627206577098374}, {\"truth_threshold\": 26.2, \"match_probability\": 0.9999999870277859, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1950, \"tn\": 7018, \"fp\": 0, \"fn\": 9831, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16552075375604788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8344792462439521, \"precision\": 1.0, \"recall\": 0.16552075375604788, \"specificity\": 1.0, \"npv\": 0.4165232358003442, \"accuracy\": 0.4770466514176286, \"f1\": 0.28402883985143107, \"f2\": 0.19867954517667197, \"f0_5\": 0.4979316684541137, \"p4\": 0.3830549914037882, \"phi\": 0.262570447588035}, {\"truth_threshold\": 26.22, \"match_probability\": 0.9999999872063782, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1949, \"tn\": 7018, \"fp\": 0, \"fn\": 9832, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16543587131822426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8345641286817758, \"precision\": 1.0, \"recall\": 0.16543587131822426, \"specificity\": 1.0, \"npv\": 0.4164985163204748, \"accuracy\": 0.4769934570987818, \"f1\": 0.28390386016023306, \"f2\": 0.1985817048071241, \"f0_5\": 0.4977780048015528, \"p4\": 0.38293609154665387, \"phi\": 0.26249532367306166}, {\"truth_threshold\": 26.240000000000002, \"match_probability\": 0.9999999873825117, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1943, \"tn\": 7018, \"fp\": 0, \"fn\": 9838, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16492657669128258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8350734233087175, \"precision\": 1.0, \"recall\": 0.16492657669128258, \"specificity\": 1.0, \"npv\": 0.4163502610346464, \"accuracy\": 0.47667429118570137, \"f1\": 0.28315359953366365, \"f2\": 0.19799457884117636, \"f0_5\": 0.4968547026031811, \"p4\": 0.382221792298191, \"phi\": 0.2620443154448616}, {\"truth_threshold\": 26.26, \"match_probability\": 0.9999999875562204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1932, \"tn\": 7018, \"fp\": 0, \"fn\": 9849, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16399286987522282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8360071301247772, \"precision\": 1.0, \"recall\": 0.16399286987522282, \"specificity\": 1.0, \"npv\": 0.4160787336218652, \"accuracy\": 0.47608915367838717, \"f1\": 0.28177641653905056, \"f2\": 0.1969178082191781, \"f0_5\": 0.4951560818083961, \"p4\": 0.3809082185796412, \"phi\": 0.2612162813086084}, {\"truth_threshold\": 26.28, \"match_probability\": 0.9999999877275376, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1927, \"tn\": 7018, \"fp\": 0, \"fn\": 9854, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16356845768610476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8364315423138953, \"precision\": 1.0, \"recall\": 0.16356845768610476, \"specificity\": 1.0, \"npv\": 0.41595542911332384, \"accuracy\": 0.4758231820841534, \"f1\": 0.28114969360957104, \"f2\": 0.19642820737599642, \"f0_5\": 0.4943814459438658, \"p4\": 0.38030940845989014, \"phi\": 0.2608393912088975}, {\"truth_threshold\": 26.3, \"match_probability\": 0.9999999878964962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1923, \"tn\": 7018, \"fp\": 0, \"fn\": 9858, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16322892793481028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8367710720651897, \"precision\": 1.0, \"recall\": 0.16322892793481028, \"specificity\": 1.0, \"npv\": 0.415856838113297, \"accuracy\": 0.47561040480876643, \"f1\": 0.28064798598949214, \"f2\": 0.19603645482904153, \"f0_5\": 0.4937605915883531, \"p4\": 0.3798295775610554, \"phi\": 0.2605376476818531}, {\"truth_threshold\": 26.32, \"match_probability\": 0.9999999880631287, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1921, \"tn\": 7018, \"fp\": 0, \"fn\": 9860, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16305916305916307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.836940836940837, \"precision\": 1.0, \"recall\": 0.16305916305916307, \"specificity\": 1.0, \"npv\": 0.41580756013745707, \"accuracy\": 0.4755040161710729, \"f1\": 0.2803970223325062, \"f2\": 0.19584055459272098, \"f0_5\": 0.49344978165938863, \"p4\": 0.37958940048028206, \"phi\": 0.260386698488395}, {\"truth_threshold\": 26.34, \"match_probability\": 0.9999999882274672, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1917, \"tn\": 7018, \"fp\": 0, \"fn\": 9864, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1627196333078686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8372803666921314, \"precision\": 1.0, \"recall\": 0.1627196333078686, \"specificity\": 1.0, \"npv\": 0.41570903921336333, \"accuracy\": 0.4752912388956859, \"f1\": 0.27989487516425754, \"f2\": 0.19544870618462104, \"f0_5\": 0.4928273947246645, \"p4\": 0.3791085217842955, \"phi\": 0.26008464472852844}, {\"truth_threshold\": 26.38, \"match_probability\": 0.9999999885493878, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1914, \"tn\": 7018, \"fp\": 0, \"fn\": 9867, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16246498599439776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8375350140056023, \"precision\": 1.0, \"recall\": 0.16246498599439776, \"specificity\": 1.0, \"npv\": 0.41563517915309445, \"accuracy\": 0.4751316559391457, \"f1\": 0.27951807228915665, \"f2\": 0.19515477792732167, \"f0_5\": 0.4923599320882852, \"p4\": 0.37874740279014546, \"phi\": 0.25985796805156175}, {\"truth_threshold\": 26.400000000000002, \"match_probability\": 0.9999999887070317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1909, \"tn\": 7018, \"fp\": 0, \"fn\": 9872, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1620405738052797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8379594261947203, \"precision\": 1.0, \"recall\": 0.1620405738052797, \"specificity\": 1.0, \"npv\": 0.41551213735938425, \"accuracy\": 0.47486568434491194, \"f1\": 0.2788897005113221, \"f2\": 0.19466481757183937, \"f0_5\": 0.4915795436988206, \"p4\": 0.3781446591029241, \"phi\": 0.2594799128271258}, {\"truth_threshold\": 26.42, \"match_probability\": 0.9999999888625053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1901, \"tn\": 7018, \"fp\": 0, \"fn\": 9880, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16136151430269077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8386384856973093, \"precision\": 1.0, \"recall\": 0.16136151430269077, \"specificity\": 1.0, \"npv\": 0.41531542194342524, \"accuracy\": 0.47444012979413797, \"f1\": 0.2778833503873703, \"f2\": 0.19388067312595614, \"f0_5\": 0.49032757286561773, \"p4\": 0.377177975676673, \"phi\": 0.25887434287324046}, {\"truth_threshold\": 26.46, \"match_probability\": 0.9999999891670607, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1897, \"tn\": 7018, \"fp\": 0, \"fn\": 9884, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16102198455139632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8389780154486037, \"precision\": 1.0, \"recall\": 0.16102198455139632, \"specificity\": 1.0, \"npv\": 0.4152171340669743, \"accuracy\": 0.474227352518751, \"f1\": 0.2773797338792221, \"f2\": 0.19348850492646008, \"f0_5\": 0.48970003614022406, \"p4\": 0.37669357102070106, \"phi\": 0.2585712415316278}, {\"truth_threshold\": 26.48, \"match_probability\": 0.9999999893162009, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1893, \"tn\": 7018, \"fp\": 0, \"fn\": 9888, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16068245480010185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8393175451998981, \"precision\": 1.0, \"recall\": 0.16068245480010185, \"specificity\": 1.0, \"npv\": 0.41511889270081626, \"accuracy\": 0.474014575243364, \"f1\": 0.2768758227292672, \"f2\": 0.1930962727217088, \"f0_5\": 0.48907146178886995, \"p4\": 0.37620845496678196, \"phi\": 0.2582679281542082}, {\"truth_threshold\": 26.54, \"match_probability\": 0.9999999897514149, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1886, \"tn\": 7018, \"fp\": 0, \"fn\": 9895, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.16008827773533657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8399117222646635, \"precision\": 1.0, \"recall\": 0.16008827773533657, \"specificity\": 1.0, \"npv\": 0.41494708212617515, \"accuracy\": 0.4736422150114368, \"f1\": 0.2759932684568669, \"f2\": 0.1924097123036115, \"f0_5\": 0.4879689521345407, \"p4\": 0.37535778379000434, \"phi\": 0.2577366169733797}, {\"truth_threshold\": 26.560000000000002, \"match_probability\": 0.9999999898925103, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1883, \"tn\": 7018, \"fp\": 0, \"fn\": 9898, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1598336304218657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8401663695781343, \"precision\": 1.0, \"recall\": 0.1598336304218657, \"specificity\": 1.0, \"npv\": 0.4148734925514306, \"accuracy\": 0.47348263205489655, \"f1\": 0.27561475409836067, \"f2\": 0.192115412083988, \"f0_5\": 0.48749546937296123, \"p4\": 0.37499253875205824, \"phi\": 0.2575087114648629}, {\"truth_threshold\": 26.580000000000002, \"match_probability\": 0.9999999900316631, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1882, \"tn\": 7018, \"fp\": 0, \"fn\": 9899, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1597487479840421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8402512520159579, \"precision\": 1.0, \"recall\": 0.1597487479840421, \"specificity\": 1.0, \"npv\": 0.41484896849323166, \"accuracy\": 0.4734294377360498, \"f1\": 0.2754885457073849, \"f2\": 0.1920173040035914, \"f0_5\": 0.4873375110052307, \"p4\": 0.3748707006080722, \"phi\": 0.2574327161012467}, {\"truth_threshold\": 26.6, \"match_probability\": 0.9999999901689001, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1877, \"tn\": 7018, \"fp\": 0, \"fn\": 9904, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15932433579492403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.840675664205076, \"precision\": 1.0, \"recall\": 0.15932433579492403, \"specificity\": 1.0, \"npv\": 0.4147263916794705, \"accuracy\": 0.47316346614181604, \"f1\": 0.27485722653389955, \"f2\": 0.1915267035366625, \"f0_5\": 0.4865467364819327, \"p4\": 0.37426083491780476, \"phi\": 0.2570525372194508}, {\"truth_threshold\": 26.62, \"match_probability\": 0.9999999903042477, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1875, \"tn\": 7018, \"fp\": 0, \"fn\": 9906, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1591545709192768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8408454290807232, \"precision\": 1.0, \"recall\": 0.1591545709192768, \"specificity\": 1.0, \"npv\": 0.41467738123375086, \"accuracy\": 0.47305707750412257, \"f1\": 0.27460456942003514, \"f2\": 0.19133043531500643, \"f0_5\": 0.4862299673253462, \"p4\": 0.3740165730378157, \"phi\": 0.2569003711172621}, {\"truth_threshold\": 26.64, \"match_probability\": 0.999999990437732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1873, \"tn\": 7018, \"fp\": 0, \"fn\": 9908, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15898480604362958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8410151939563705, \"precision\": 1.0, \"recall\": 0.15898480604362958, \"specificity\": 1.0, \"npv\": 0.41462838237031785, \"accuracy\": 0.47295068886642905, \"f1\": 0.27435183828914605, \"f2\": 0.1911341510704737, \"f0_5\": 0.4859129351943133, \"p4\": 0.37377213041470614, \"phi\": 0.2567481508235821}, {\"truth_threshold\": 26.66, \"match_probability\": 0.9999999905693786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1870, \"tn\": 7018, \"fp\": 0, \"fn\": 9911, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15873015873015872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8412698412698413, \"precision\": 1.0, \"recall\": 0.15873015873015872, \"specificity\": 1.0, \"npv\": 0.41455490578297594, \"accuracy\": 0.4727911059098888, \"f1\": 0.273972602739726, \"f2\": 0.19083969465648856, \"f0_5\": 0.4854368932038835, \"p4\": 0.37340512700456513, \"phi\": 0.2565197185350432}, {\"truth_threshold\": 26.68, \"match_probability\": 0.9999999906992127, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1869, \"tn\": 7018, \"fp\": 0, \"fn\": 9912, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1586452762923351, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8413547237076648, \"precision\": 1.0, \"recall\": 0.1586452762923351, \"specificity\": 1.0, \"npv\": 0.4145304193738925, \"accuracy\": 0.47273791159104206, \"f1\": 0.27384615384615385, \"f2\": 0.19074153450492928, \"f0_5\": 0.48527808069792805, \"p4\": 0.3732827018744158, \"phi\": 0.2564435472246255}, {\"truth_threshold\": 26.7, \"match_probability\": 0.9999999908272594, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1864, \"tn\": 7018, \"fp\": 0, \"fn\": 9917, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15822086410321703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.841779135896783, \"precision\": 1.0, \"recall\": 0.15822086410321703, \"specificity\": 1.0, \"npv\": 0.4144080307056392, \"accuracy\": 0.47247193999680837, \"f1\": 0.27321363136680105, \"f2\": 0.19025067363435944, \"f0_5\": 0.4844830274990903, \"p4\": 0.3726698947692827, \"phi\": 0.25606248594739284}, {\"truth_threshold\": 26.72, \"match_probability\": 0.9999999909535432, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1862, \"tn\": 7018, \"fp\": 0, \"fn\": 9919, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15805109922756982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8419489007724302, \"precision\": 1.0, \"recall\": 0.15805109922756982, \"specificity\": 1.0, \"npv\": 0.41435909547145305, \"accuracy\": 0.47236555135911484, \"f1\": 0.2729604925602873, \"f2\": 0.19005430122892256, \"f0_5\": 0.4841645431379687, \"p4\": 0.372424453289837, \"phi\": 0.2559099656406618}, {\"truth_threshold\": 26.740000000000002, \"match_probability\": 0.9999999910780885, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1856, \"tn\": 7018, \"fp\": 0, \"fn\": 9925, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15754180460062814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8424581953993718, \"precision\": 1.0, \"recall\": 0.15754180460062814, \"specificity\": 1.0, \"npv\": 0.41421235908634835, \"accuracy\": 0.4720463854460344, \"f1\": 0.27220063063723693, \"f2\": 0.18946508779093507, \"f0_5\": 0.4832074980473835, \"p4\": 0.3716870328848255, \"phi\": 0.25545207483664467}, {\"truth_threshold\": 26.76, \"match_probability\": 0.9999999912009191, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1850, \"tn\": 7018, \"fp\": 0, \"fn\": 9931, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15703250997368645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8429674900263135, \"precision\": 1.0, \"recall\": 0.15703250997368645, \"specificity\": 1.0, \"npv\": 0.41406572659153934, \"accuracy\": 0.4717272195329539, \"f1\": 0.2714400997725772, \"f2\": 0.18887572997917262, \"f0_5\": 0.4822480579740368, \"p4\": 0.3709479628576042, \"phi\": 0.254993686864494}, {\"truth_threshold\": 26.78, \"match_probability\": 0.9999999913220586, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1845, \"tn\": 7018, \"fp\": 0, \"fn\": 9936, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15660809778456838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8433919022154316, \"precision\": 1.0, \"recall\": 0.15660809778456838, \"specificity\": 1.0, \"npv\": 0.4139436121269317, \"accuracy\": 0.47146124793872013, \"f1\": 0.27080581241743723, \"f2\": 0.18838448814556147, \"f0_5\": 0.4814466885861907, \"p4\": 0.37033080575503274, \"phi\": 0.2546113149199618}, {\"truth_threshold\": 26.8, \"match_probability\": 0.9999999914415304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1843, \"tn\": 7018, \"fp\": 0, \"fn\": 9938, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15643833290892115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8435616670910788, \"precision\": 1.0, \"recall\": 0.15643833290892115, \"specificity\": 1.0, \"npv\": 0.4138947865062515, \"accuracy\": 0.47135485930102666, \"f1\": 0.2705519671168526, \"f2\": 0.18818796332223742, \"f0_5\": 0.48112567221845143, \"p4\": 0.3700836197754129, \"phi\": 0.25445826848568276}, {\"truth_threshold\": 26.82, \"match_probability\": 0.9999999915593574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1841, \"tn\": 7018, \"fp\": 0, \"fn\": 9940, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1562685680332739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8437314319667261, \"precision\": 1.0, \"recall\": 0.1562685680332739, \"specificity\": 1.0, \"npv\": 0.41384597240240595, \"accuracy\": 0.47124847066333314, \"f1\": 0.27029804727646456, \"f2\": 0.1879914224446033, \"f0_5\": 0.48080438756855576, \"p4\": 0.36983624873489157, \"phi\": 0.2543051660774153}, {\"truth_threshold\": 26.86, \"match_probability\": 0.9999999917901672, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1839, \"tn\": 7018, \"fp\": 0, \"fn\": 9942, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1560988031576267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8439011968423733, \"precision\": 1.0, \"recall\": 0.1560988031576267, \"specificity\": 1.0, \"npv\": 0.41379716981132075, \"accuracy\": 0.4711420820256397, \"f1\": 0.27004405286343613, \"f2\": 0.18779486551069174, \"f0_5\": 0.480482834300047, \"p4\": 0.36958869235923514, \"phi\": 0.2541520075812119}, {\"truth_threshold\": 26.900000000000002, \"match_probability\": 0.9999999920146655, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1832, \"tn\": 7018, \"fp\": 0, \"fn\": 9949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1555046260928614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8444953739071386, \"precision\": 1.0, \"recall\": 0.1555046260928614, \"specificity\": 1.0, \"npv\": 0.41362645134673187, \"accuracy\": 0.47076972179371246, \"f1\": 0.2691544846837582, \"f2\": 0.18710678977040607, \"f0_5\": 0.4793552776178764, \"p4\": 0.3687207815587414, \"phi\": 0.2536155094996965}, {\"truth_threshold\": 26.92, \"match_probability\": 0.999999992124602, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1826, \"tn\": 7018, \"fp\": 0, \"fn\": 9955, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1549953314659197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8450046685340803, \"precision\": 1.0, \"recall\": 0.1549953314659197, \"specificity\": 1.0, \"npv\": 0.4134802333117304, \"accuracy\": 0.47045055588063195, \"f1\": 0.26839126919967665, \"f2\": 0.18651685393258427, \"f0_5\": 0.4783861671469741, \"p4\": 0.36797503934846587, \"phi\": 0.2531551022925619}, {\"truth_threshold\": 26.94, \"match_probability\": 0.9999999922330249, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1818, \"tn\": 7018, \"fp\": 0, \"fn\": 9963, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15431627196333078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8456837280366692, \"precision\": 1.0, \"recall\": 0.15431627196333078, \"specificity\": 1.0, \"npv\": 0.4132854366645074, \"accuracy\": 0.47002500132985797, \"f1\": 0.2673726009265387, \"f2\": 0.18573004781169547, \"f0_5\": 0.4770902220122815, \"p4\": 0.36697809137408527, \"phi\": 0.25254042813538596}, {\"truth_threshold\": 26.96, \"match_probability\": 0.9999999923399552, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1815, \"tn\": 7018, \"fp\": 0, \"fn\": 9966, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15406162464985995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.84593837535014, \"precision\": 1.0, \"recall\": 0.15406162464985995, \"specificity\": 1.0, \"npv\": 0.41321243523316065, \"accuracy\": 0.46986541837331774, \"f1\": 0.2669902912621359, \"f2\": 0.18543492919757248, \"f0_5\": 0.47660311958405543, \"p4\": 0.3666034591737057, \"phi\": 0.2523096888697415}, {\"truth_threshold\": 26.98, \"match_probability\": 0.9999999924454133, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1812, \"tn\": 7018, \"fp\": 0, \"fn\": 9969, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1538069773363891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8461930226636108, \"precision\": 1.0, \"recall\": 0.1538069773363891, \"specificity\": 1.0, \"npv\": 0.4131394595867428, \"accuracy\": 0.46970583541677746, \"f1\": 0.26660781284484664, \"f2\": 0.1851397743992153, \"f0_5\": 0.4761154028062431, \"p4\": 0.36622840183994076, \"phi\": 0.25207882000958787}, {\"truth_threshold\": 27.0, \"match_probability\": 0.9999999925494194, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1808, \"tn\": 7018, \"fp\": 0, \"fn\": 9973, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15346744758509465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8465325524149053, \"precision\": 1.0, \"recall\": 0.15346744758509465, \"specificity\": 1.0, \"npv\": 0.4130421988111353, \"accuracy\": 0.4694930581413905, \"f1\": 0.26609757892412983, \"f2\": 0.18474617836998283, \"f0_5\": 0.4754641561037185, \"p4\": 0.3657276624321602, \"phi\": 0.2517707925802359}, {\"truth_threshold\": 27.02, \"match_probability\": 0.9999999926519938, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1804, \"tn\": 7018, \"fp\": 0, \"fn\": 9977, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1531279178338002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8468720821661998, \"precision\": 1.0, \"recall\": 0.1531279178338002, \"specificity\": 1.0, \"npv\": 0.4129449838187702, \"accuracy\": 0.4692802808660035, \"f1\": 0.26558704453441295, \"f2\": 0.1843525179856115, \"f0_5\": 0.4748118123914302, \"p4\": 0.3652261632787698, \"phi\": 0.2514625330980355}, {\"truth_threshold\": 27.04, \"match_probability\": 0.999999992753156, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1802, \"tn\": 7018, \"fp\": 0, \"fn\": 9979, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15295815295815296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.847041847041847, \"precision\": 1.0, \"recall\": 0.15295815295815296, \"specificity\": 1.0, \"npv\": 0.41289639348120255, \"accuracy\": 0.46917389222831, \"f1\": 0.26533166458072593, \"f2\": 0.1841556636553162, \"f0_5\": 0.4744852282900627, \"p4\": 0.3649751280882603, \"phi\": 0.25130831603822323}, {\"truth_threshold\": 27.060000000000002, \"match_probability\": 0.9999999928529254, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1796, \"tn\": 7018, \"fp\": 0, \"fn\": 9985, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15244885833121127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8475511416687888, \"precision\": 1.0, \"recall\": 0.15244885833121127, \"specificity\": 1.0, \"npv\": 0.4127506910545198, \"accuracy\": 0.4688547263152295, \"f1\": 0.2645650732857038, \"f2\": 0.18356500408830745, \"f0_5\": 0.47350382283153175, \"p4\": 0.36422087664417974, \"phi\": 0.2508453141413649}, {\"truth_threshold\": 27.080000000000002, \"match_probability\": 0.9999999929513212, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1790, \"tn\": 7018, \"fp\": 0, \"fn\": 9991, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1519395637042696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8480604362957305, \"precision\": 1.0, \"recall\": 0.1519395637042696, \"specificity\": 1.0, \"npv\": 0.41260509142218826, \"accuracy\": 0.46853556040214905, \"f1\": 0.2637978041411834, \"f2\": 0.18297419961565195, \"f0_5\": 0.47251993030990974, \"p4\": 0.3634649003851063, \"phi\": 0.25038178362821756}, {\"truth_threshold\": 27.1, \"match_probability\": 0.9999999930483625, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1789, \"tn\": 7018, \"fp\": 0, \"fn\": 9992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15185468126644597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.848145318733554, \"precision\": 1.0, \"recall\": 0.15185468126644597, \"specificity\": 1.0, \"npv\": 0.412580834803057, \"accuracy\": 0.4684823660833023, \"f1\": 0.2636698599852616, \"f2\": 0.18287571811174944, \"f0_5\": 0.4723557057612082, \"p4\": 0.3633387361074005, \"phi\": 0.2503044769189365}, {\"truth_threshold\": 27.12, \"match_probability\": 0.9999999931440678, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1786, \"tn\": 7018, \"fp\": 0, \"fn\": 9995, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15160003395297514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8483999660470248, \"precision\": 1.0, \"recall\": 0.15160003395297514, \"specificity\": 1.0, \"npv\": 0.4125080820548992, \"accuracy\": 0.46832278312676207, \"f1\": 0.26328591435099874, \"f2\": 0.1825802494377428, \"f0_5\": 0.47186261558784676, \"p4\": 0.3629599541518709, \"phi\": 0.2500724679875803}, {\"truth_threshold\": 27.14, \"match_probability\": 0.9999999932384555, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1783, \"tn\": 7018, \"fp\": 0, \"fn\": 9998, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15134538663950428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8486546133604957, \"precision\": 1.0, \"recall\": 0.15134538663950428, \"specificity\": 1.0, \"npv\": 0.41243535496003764, \"accuracy\": 0.46816320017022184, \"f1\": 0.26290179887938664, \"f2\": 0.1822847445151001, \"f0_5\": 0.47136889969862, \"p4\": 0.3625807377539696, \"phi\": 0.2498403255285825}, {\"truth_threshold\": 27.16, \"match_probability\": 0.9999999933315437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1779, \"tn\": 7018, \"fp\": 0, \"fn\": 10002, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15100585688820983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8489941431117902, \"precision\": 1.0, \"recall\": 0.15100585688820983, \"specificity\": 1.0, \"npv\": 0.41233842538190363, \"accuracy\": 0.46795042289483485, \"f1\": 0.26238938053097344, \"f2\": 0.18189068155327895, \"f0_5\": 0.4707096364502302, \"p4\": 0.36207443840026254, \"phi\": 0.24953059382113754}, {\"truth_threshold\": 27.18, \"match_probability\": 0.9999999934233502, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1778, \"tn\": 7018, \"fp\": 0, \"fn\": 10003, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1509209744503862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8490790255496138, \"precision\": 1.0, \"recall\": 0.1509209744503862, \"specificity\": 1.0, \"npv\": 0.4123142001057517, \"accuracy\": 0.4678972285759881, \"f1\": 0.2622612287041817, \"f2\": 0.18179215574005153, \"f0_5\": 0.4705446461652464, \"p4\": 0.36194774233935295, \"phi\": 0.24945312357172758}, {\"truth_threshold\": 27.240000000000002, \"match_probability\": 0.9999999936912558, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1773, \"tn\": 7018, \"fp\": 0, \"fn\": 10008, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15049656226126815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8495034377387318, \"precision\": 1.0, \"recall\": 0.15049656226126815, \"specificity\": 1.0, \"npv\": 0.4121931164101962, \"accuracy\": 0.46763125698175434, \"f1\": 0.26162018592297476, \"f2\": 0.18129946622492177, \"f0_5\": 0.46971864568431093, \"p4\": 0.3613135328780455, \"phi\": 0.2490655476124573}, {\"truth_threshold\": 27.26, \"match_probability\": 0.9999999937781102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1771, \"tn\": 7018, \"fp\": 0, \"fn\": 10010, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1503267973856209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8496732026143791, \"precision\": 1.0, \"recall\": 0.1503267973856209, \"specificity\": 1.0, \"npv\": 0.41214470284237725, \"accuracy\": 0.4675248683440609, \"f1\": 0.26136363636363635, \"f2\": 0.18110236220472442, \"f0_5\": 0.46938775510204084, \"p4\": 0.36105950813823307, \"phi\": 0.24891041207177933}, {\"truth_threshold\": 27.28, \"match_probability\": 0.9999999938637688, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1768, \"tn\": 7018, \"fp\": 0, \"fn\": 10013, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.15007215007215008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.84992784992785, \"precision\": 1.0, \"recall\": 0.15007215007215008, \"specificity\": 1.0, \"npv\": 0.41207210381069814, \"accuracy\": 0.4673652853875206, \"f1\": 0.26097867001254704, \"f2\": 0.1808066759388039, \"f0_5\": 0.4688908926961226, \"p4\": 0.36067810480327117, \"phi\": 0.24867759570099132}, {\"truth_threshold\": 27.3, \"match_probability\": 0.9999999939482481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1763, \"tn\": 7018, \"fp\": 0, \"fn\": 10018, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.149647737883032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.850352262116968, \"precision\": 1.0, \"recall\": 0.149647737883032, \"specificity\": 1.0, \"npv\": 0.4119511622446584, \"accuracy\": 0.4670993137932869, \"f1\": 0.2603366804489073, \"f2\": 0.1803137848507783, \"f0_5\": 0.46806138161737376, \"p4\": 0.36004145352613304, \"phi\": 0.2482892658738976}, {\"truth_threshold\": 27.32, \"match_probability\": 0.9999999940315644, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1756, \"tn\": 7018, \"fp\": 0, \"fn\": 10025, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1490535608182667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8509464391817333, \"precision\": 1.0, \"recall\": 0.1490535608182667, \"specificity\": 1.0, \"npv\": 0.41178196326937744, \"accuracy\": 0.4667269535613596, \"f1\": 0.2594370983231144, \"f2\": 0.17962356792144027, \"f0_5\": 0.46689710183461847, \"p4\": 0.35914807797427395, \"phi\": 0.24774496545043537}, {\"truth_threshold\": 27.34, \"match_probability\": 0.9999999941137335, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1755, \"tn\": 7018, \"fp\": 0, \"fn\": 10026, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1489686783804431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.851031321619557, \"precision\": 1.0, \"recall\": 0.1489686783804431, \"specificity\": 1.0, \"npv\": 0.411757803332551, \"accuracy\": 0.4666737592425129, \"f1\": 0.25930851063829785, \"f2\": 0.17952494936475788, \"f0_5\": 0.46673049305887987, \"p4\": 0.35902025570397955, \"phi\": 0.24766714714568935}, {\"truth_threshold\": 27.36, \"match_probability\": 0.9999999941947715, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1752, \"tn\": 7018, \"fp\": 0, \"fn\": 10029, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14871403106697223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8512859689330278, \"precision\": 1.0, \"recall\": 0.14871403106697223, \"specificity\": 1.0, \"npv\": 0.41168534052912537, \"accuracy\": 0.46651417628597264, \"f1\": 0.258922633562403, \"f2\": 0.17922906948195433, \"f0_5\": 0.4662302410985151, \"p4\": 0.3586364922872379, \"phi\": 0.24743360022694047}, {\"truth_threshold\": 27.38, \"match_probability\": 0.9999999942746939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1748, \"tn\": 7018, \"fp\": 0, \"fn\": 10033, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14837450131567778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8516254986843222, \"precision\": 1.0, \"recall\": 0.14837450131567778, \"specificity\": 1.0, \"npv\": 0.4115887631223975, \"accuracy\": 0.46630139901058565, \"f1\": 0.25840786458718307, \"f2\": 0.17883450646587004, \"f0_5\": 0.46556224364779203, \"p4\": 0.3581241142569183, \"phi\": 0.24712198905686716}, {\"truth_threshold\": 27.400000000000002, \"match_probability\": 0.9999999943535158, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1739, \"tn\": 7018, \"fp\": 0, \"fn\": 10042, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14761055937526527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8523894406247348, \"precision\": 1.0, \"recall\": 0.14761055937526527, \"specificity\": 1.0, \"npv\": 0.41137162954279016, \"accuracy\": 0.46582265014096497, \"f1\": 0.25724852071005916, \"f2\": 0.17794650348934776, \"f0_5\": 0.4640550781875434, \"p4\": 0.35696835425442064, \"phi\": 0.2464199593132132}, {\"truth_threshold\": 27.42, \"match_probability\": 0.9999999944312526, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1733, \"tn\": 7018, \"fp\": 0, \"fn\": 10048, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14710126474832358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8528987352516765, \"precision\": 1.0, \"recall\": 0.14710126474832358, \"specificity\": 1.0, \"npv\": 0.4112270010547287, \"accuracy\": 0.46550348422788446, \"f1\": 0.25647476690839127, \"f2\": 0.17735431974947294, \"f0_5\": 0.4630470795703522, \"p4\": 0.3561955988140592, \"phi\": 0.24595123897596202}, {\"truth_threshold\": 27.44, \"match_probability\": 0.9999999945079192, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1731, \"tn\": 7018, \"fp\": 0, \"fn\": 10050, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14693149987267634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8530685001273236, \"precision\": 1.0, \"recall\": 0.14693149987267634, \"specificity\": 1.0, \"npv\": 0.4111788141551441, \"accuracy\": 0.465397095590191, \"f1\": 0.2562166962699822, \"f2\": 0.17715689284617747, \"f0_5\": 0.46271050521251, \"p4\": 0.35593761216756375, \"phi\": 0.24579487358300164}, {\"truth_threshold\": 27.46, \"match_probability\": 0.9999999945835303, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1725, \"tn\": 7018, \"fp\": 0, \"fn\": 10056, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14642220524573465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8535777947542653, \"precision\": 1.0, \"recall\": 0.14642220524573465, \"specificity\": 1.0, \"npv\": 0.4110343211901136, \"accuracy\": 0.4650779296771105, \"f1\": 0.2554420257663261, \"f2\": 0.176564515138488, \"f0_5\": 0.4616990525132488, \"p4\": 0.35516244346057874, \"phi\": 0.24532539970484105}, {\"truth_threshold\": 27.48, \"match_probability\": 0.9999999946581004, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1717, \"tn\": 7018, \"fp\": 0, \"fn\": 10064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14574314574314573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8542568542568543, \"precision\": 1.0, \"recall\": 0.14574314574314573, \"specificity\": 1.0, \"npv\": 0.4108418218007259, \"accuracy\": 0.4646523751263365, \"f1\": 0.25440806045340053, \"f2\": 0.17577445179255133, \"f0_5\": 0.4603463992707384, \"p4\": 0.35412605328342656, \"phi\": 0.24469854824269535}, {\"truth_threshold\": 27.5, \"match_probability\": 0.9999999947316439, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1715, \"tn\": 7018, \"fp\": 0, \"fn\": 10066, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14557338086749852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8544266191325015, \"precision\": 1.0, \"recall\": 0.14557338086749852, \"specificity\": 1.0, \"npv\": 0.41079372512292206, \"accuracy\": 0.46454598648864304, \"f1\": 0.254149377593361, \"f2\": 0.17557689551383115, \"f0_5\": 0.46000751032669923, \"p4\": 0.35386644798997147, \"phi\": 0.24454167621347822}, {\"truth_threshold\": 27.52, \"match_probability\": 0.999999994804175, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1710, \"tn\": 7018, \"fp\": 0, \"fn\": 10071, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14514896867838045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8548510313216195, \"precision\": 1.0, \"recall\": 0.14514896867838045, \"specificity\": 1.0, \"npv\": 0.41067353268184215, \"accuracy\": 0.4642800148944093, \"f1\": 0.25350233488992663, \"f2\": 0.17508293402137856, \"f0_5\": 0.45915901401643305, \"p4\": 0.3532165428105062, \"phi\": 0.24414921612054494}, {\"truth_threshold\": 27.54, \"match_probability\": 0.9999999948757075, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1707, \"tn\": 7018, \"fp\": 0, \"fn\": 10074, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1448943213649096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8551056786350903, \"precision\": 1.0, \"recall\": 0.1448943213649096, \"specificity\": 1.0, \"npv\": 0.4106014509712146, \"accuracy\": 0.46412043193786906, \"f1\": 0.2531138790035587, \"f2\": 0.17478650857037537, \"f0_5\": 0.4586490407867161, \"p4\": 0.35282598652866026, \"phi\": 0.24391354736857349}, {\"truth_threshold\": 27.560000000000002, \"match_probability\": 0.9999999949462551, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1705, \"tn\": 7018, \"fp\": 0, \"fn\": 10076, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14472455648926238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8552754435107376, \"precision\": 1.0, \"recall\": 0.14472455648926238, \"specificity\": 1.0, \"npv\": 0.41055341055341055, \"accuracy\": 0.46401404330017554, \"f1\": 0.2528548123980424, \"f2\": 0.1745888713674251, \"f0_5\": 0.4583086930810171, \"p4\": 0.35256535953537954, \"phi\": 0.24375635429152692}, {\"truth_threshold\": 27.580000000000002, \"match_probability\": 0.9999999950158315, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1701, \"tn\": 7018, \"fp\": 0, \"fn\": 10080, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1443850267379679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8556149732620321, \"precision\": 1.0, \"recall\": 0.1443850267379679, \"specificity\": 1.0, \"npv\": 0.4104573634343198, \"accuracy\": 0.46380126602478855, \"f1\": 0.2523364485981308, \"f2\": 0.17419354838709677, \"f0_5\": 0.4576271186440678, \"p4\": 0.3520434894081888, \"phi\": 0.24344177413554163}, {\"truth_threshold\": 27.6, \"match_probability\": 0.99999999508445, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1699, \"tn\": 7018, \"fp\": 0, \"fn\": 10082, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1442152618623207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8557847381376793, \"precision\": 1.0, \"recall\": 0.1442152618623207, \"specificity\": 1.0, \"npv\": 0.4104093567251462, \"accuracy\": 0.4636948773870951, \"f1\": 0.25207715133531156, \"f2\": 0.1739958626057391, \"f0_5\": 0.4572858911557302, \"p4\": 0.3517822456469367, \"phi\": 0.24328438677988265}, {\"truth_threshold\": 27.62, \"match_probability\": 0.9999999951521238, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1690, \"tn\": 7018, \"fp\": 0, \"fn\": 10091, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14345131992190815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8565486800780918, \"precision\": 1.0, \"recall\": 0.14345131992190815, \"specificity\": 1.0, \"npv\": 0.41019346542755275, \"accuracy\": 0.46321612851747435, \"f1\": 0.25090936084923166, \"f2\": 0.17310607612570164, \"f0_5\": 0.45574672347769807, \"p4\": 0.3506040922207461, \"phi\": 0.24257533683151722}, {\"truth_threshold\": 27.64, \"match_probability\": 0.999999995218866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1684, \"tn\": 7018, \"fp\": 0, \"fn\": 10097, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14294202529496647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8570579747050335, \"precision\": 1.0, \"recall\": 0.14294202529496647, \"specificity\": 1.0, \"npv\": 0.4100496640373941, \"accuracy\": 0.46289696260439384, \"f1\": 0.2501299665800223, \"f2\": 0.17251270283560072, \"f0_5\": 0.45471728681751905, \"p4\": 0.3498163224196018, \"phi\": 0.24210189889595182}, {\"truth_threshold\": 27.66, \"match_probability\": 0.9999999952846893, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1679, \"tn\": 7018, \"fp\": 0, \"fn\": 10102, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1425176131058484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8574823868941516, \"precision\": 1.0, \"recall\": 0.1425176131058484, \"specificity\": 1.0, \"npv\": 0.4099299065420561, \"accuracy\": 0.46263099101016014, \"f1\": 0.24947994056463596, \"f2\": 0.1720181136405549, \"f0_5\": 0.45385738227820727, \"p4\": 0.3491584138443696, \"phi\": 0.24170691306017156}, {\"truth_threshold\": 27.68, \"match_probability\": 0.9999999953496064, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1676, \"tn\": 7018, \"fp\": 0, \"fn\": 10105, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14226296579237754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8577370342076225, \"precision\": 1.0, \"recall\": 0.14226296579237754, \"specificity\": 1.0, \"npv\": 0.40985808561583836, \"accuracy\": 0.46247140805361986, \"f1\": 0.24908969309652967, \"f2\": 0.17172131147540984, \"f0_5\": 0.45334054638896404, \"p4\": 0.3487630408257305, \"phi\": 0.24146972235395345}, {\"truth_threshold\": 27.7, \"match_probability\": 0.9999999954136297, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1674, \"tn\": 7018, \"fp\": 0, \"fn\": 10107, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14209320091673033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8579067990832697, \"precision\": 1.0, \"recall\": 0.14209320091673033, \"specificity\": 1.0, \"npv\": 0.4098102189781022, \"accuracy\": 0.4623650194159264, \"f1\": 0.24882943143812708, \"f2\": 0.1715234230911103, \"f0_5\": 0.4529956161714564, \"p4\": 0.3484991965297132, \"phi\": 0.24131151191558337}, {\"truth_threshold\": 27.72, \"match_probability\": 0.9999999954767717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1670, \"tn\": 7018, \"fp\": 0, \"fn\": 10111, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14175367116543588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8582463288345641, \"precision\": 1.0, \"recall\": 0.14175367116543588, \"specificity\": 1.0, \"npv\": 0.40971451923638275, \"accuracy\": 0.4621522421405394, \"f1\": 0.24830867593487474, \"f2\": 0.17112759765544944, \"f0_5\": 0.4523048588917177, \"p4\": 0.3479708770056321, \"phi\": 0.24099489046770028}, {\"truth_threshold\": 27.740000000000002, \"match_probability\": 0.9999999955390442, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1666, \"tn\": 7018, \"fp\": 0, \"fn\": 10115, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1414141414141414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8585858585858586, \"precision\": 1.0, \"recall\": 0.1414141414141414, \"specificity\": 1.0, \"npv\": 0.40961886418023696, \"accuracy\": 0.4619394648651524, \"f1\": 0.24778761061946902, \"f2\": 0.17073170731707318, \"f0_5\": 0.45161290322580644, \"p4\": 0.3474417140816233, \"phi\": 0.24067800062549136}, {\"truth_threshold\": 27.76, \"match_probability\": 0.9999999956004595, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1662, \"tn\": 7018, \"fp\": 0, \"fn\": 10119, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14107461166284696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.858925388337153, \"precision\": 1.0, \"recall\": 0.14107461166284696, \"specificity\": 1.0, \"npv\": 0.4095232537783743, \"accuracy\": 0.4617266875897654, \"f1\": 0.2472662352153537, \"f2\": 0.17033575206001722, \"f0_5\": 0.45091974605241736, \"p4\": 0.3469117051600454, \"phi\": 0.24036084122354387}, {\"truth_threshold\": 27.78, \"match_probability\": 0.9999999956610293, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1660, \"tn\": 7018, \"fp\": 0, \"fn\": 10121, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14090484678719972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8590951532128003, \"precision\": 1.0, \"recall\": 0.14090484678719972, \"specificity\": 1.0, \"npv\": 0.40947546531302875, \"accuracy\": 0.4616202989520719, \"f1\": 0.2470054311435161, \"f2\": 0.1701377500819941, \"f0_5\": 0.4505727159220455, \"p4\": 0.3466463826355808, \"phi\": 0.2402021600715731}, {\"truth_threshold\": 27.8, \"match_probability\": 0.9999999957207651, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1653, \"tn\": 7018, \"fp\": 0, \"fn\": 10128, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14031066972243442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8596893302775656, \"precision\": 1.0, \"recall\": 0.14031066972243442, \"specificity\": 1.0, \"npv\": 0.40930829347952874, \"accuracy\": 0.4612479387201447, \"f1\": 0.24609200535953552, \"f2\": 0.16944461528999324, \"f0_5\": 0.4493557331593541, \"p4\": 0.34571607838256874, \"phi\": 0.23964624090742467}, {\"truth_threshold\": 27.82, \"match_probability\": 0.9999999957796787, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1652, \"tn\": 7018, \"fp\": 0, \"fn\": 10129, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.14022578728461083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8597742127153892, \"precision\": 1.0, \"recall\": 0.14022578728461083, \"specificity\": 1.0, \"npv\": 0.409284422931125, \"accuracy\": 0.46119474440129793, \"f1\": 0.24596143824908806, \"f2\": 0.169345579793341, \"f0_5\": 0.4491815759421393, \"p4\": 0.34558296447632353, \"phi\": 0.2395667556837647}, {\"truth_threshold\": 27.84, \"match_probability\": 0.9999999958377811, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1648, \"tn\": 7018, \"fp\": 0, \"fn\": 10133, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13988625753331635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8601137424666836, \"precision\": 1.0, \"recall\": 0.13988625753331635, \"specificity\": 1.0, \"npv\": 0.40918896857326104, \"accuracy\": 0.46098196712591094, \"f1\": 0.24543897535185047, \"f2\": 0.16894939719511196, \"f0_5\": 0.44848418875523866, \"p4\": 0.34504997395715903, \"phi\": 0.2392486435439735}, {\"truth_threshold\": 27.86, \"match_probability\": 0.9999999958950836, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1645, \"tn\": 7018, \"fp\": 0, \"fn\": 10136, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13963161021984552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8603683897801545, \"precision\": 1.0, \"recall\": 0.13963161021984552, \"specificity\": 1.0, \"npv\": 0.40911740701877114, \"accuracy\": 0.4608223841693707, \"f1\": 0.24504692387904067, \"f2\": 0.16865221759724416, \"f0_5\": 0.44796035074342355, \"p4\": 0.34464966827132454, \"phi\": 0.23900987910753593}, {\"truth_threshold\": 27.88, \"match_probability\": 0.9999999959515972, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1639, \"tn\": 7018, \"fp\": 0, \"fn\": 10142, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13912231559290383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8608776844070962, \"precision\": 1.0, \"recall\": 0.13912231559290383, \"specificity\": 1.0, \"npv\": 0.40897435897435896, \"accuracy\": 0.4605032182562902, \"f1\": 0.2442622950819672, \"f2\": 0.16805774870291, \"f0_5\": 0.4469106178764247, \"p4\": 0.3438476048548553, \"phi\": 0.23853188432290623}, {\"truth_threshold\": 27.900000000000002, \"match_probability\": 0.9999999960073327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1638, \"tn\": 7018, \"fp\": 0, \"fn\": 10143, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13903743315508021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8609625668449198, \"precision\": 1.0, \"recall\": 0.13903743315508021, \"specificity\": 1.0, \"npv\": 0.40895052735854553, \"accuracy\": 0.4604500239374435, \"f1\": 0.24413145539906103, \"f2\": 0.16795865633074936, \"f0_5\": 0.44673539518900346, \"p4\": 0.3437137389050468, \"phi\": 0.23845215790876914}, {\"truth_threshold\": 27.92, \"match_probability\": 0.9999999960623009, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1634, \"tn\": 7018, \"fp\": 0, \"fn\": 10147, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13869790340378577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8613020965962143, \"precision\": 1.0, \"recall\": 0.13869790340378577, \"specificity\": 1.0, \"npv\": 0.40885522866297697, \"accuracy\": 0.4602372466620565, \"f1\": 0.24360790160268356, \"f2\": 0.16756224619549612, \"f0_5\": 0.446033739149424, \"p4\": 0.34317773439189203, \"phi\": 0.2381330783642422}, {\"truth_threshold\": 27.94, \"match_probability\": 0.9999999961165125, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1633, \"tn\": 7018, \"fp\": 0, \"fn\": 10148, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13861302096596215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8613869790340378, \"precision\": 1.0, \"recall\": 0.13861302096596215, \"specificity\": 1.0, \"npv\": 0.4088314109285798, \"accuracy\": 0.46018405234320975, \"f1\": 0.2434769643655882, \"f2\": 0.16746313349877967, \"f0_5\": 0.445858133566319, \"p4\": 0.34304359787560945, \"phi\": 0.2380532649105807}, {\"truth_threshold\": 27.96, \"match_probability\": 0.9999999961699776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1632, \"tn\": 7018, \"fp\": 0, \"fn\": 10149, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13852813852813853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8614718614718615, \"precision\": 1.0, \"recall\": 0.13852813852813853, \"specificity\": 1.0, \"npv\": 0.4088075959690103, \"accuracy\": 0.460130858024363, \"f1\": 0.24334600760456274, \"f2\": 0.16736401673640167, \"f0_5\": 0.4456824512534819, \"p4\": 0.3429094071201769, \"phi\": 0.23797343399159146}, {\"truth_threshold\": 27.98, \"match_probability\": 0.9999999962227066, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1630, \"tn\": 7018, \"fp\": 0, \"fn\": 10151, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1383583736524913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8616416263475087, \"precision\": 1.0, \"recall\": 0.1383583736524913, \"specificity\": 1.0, \"npv\": 0.4087599743724154, \"accuracy\": 0.4600244693866695, \"f1\": 0.2430840354932518, \"f2\": 0.16716577101366042, \"f0_5\": 0.44533085623736407, \"p4\": 0.34264086272362126, \"phi\": 0.23781371968076487}, {\"truth_threshold\": 28.0, \"match_probability\": 0.9999999962747097, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1624, \"tn\": 7018, \"fp\": 0, \"fn\": 10157, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1378490790255496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8621509209744503, \"precision\": 1.0, \"recall\": 0.1378490790255496, \"specificity\": 1.0, \"npv\": 0.4086171761280932, \"accuracy\": 0.459705303473589, \"f1\": 0.2422976501305483, \"f2\": 0.1665709362435382, \"f0_5\": 0.44427422443508235, \"p4\": 0.34183392341249424, \"phi\": 0.23733415557664353}, {\"truth_threshold\": 28.02, \"match_probability\": 0.9999999963259969, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1622, \"tn\": 7018, \"fp\": 0, \"fn\": 10159, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1376793141499024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8623206858500976, \"precision\": 1.0, \"recall\": 0.1376793141499024, \"specificity\": 1.0, \"npv\": 0.4085695988822262, \"accuracy\": 0.45959891483589554, \"f1\": 0.24203536521674252, \"f2\": 0.16637262544619047, \"f0_5\": 0.4439213969018556, \"p4\": 0.34156450714077474, \"phi\": 0.2371741599681669}, {\"truth_threshold\": 28.04, \"match_probability\": 0.999999996376578, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1620, \"tn\": 7018, \"fp\": 0, \"fn\": 10161, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13750954927425516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8624904507257448, \"precision\": 1.0, \"recall\": 0.13750954927425516, \"specificity\": 1.0, \"npv\": 0.40852203271436055, \"accuracy\": 0.459492526198202, \"f1\": 0.24177300201477503, \"f2\": 0.16617429837518463, \"f0_5\": 0.44356826022671264, \"p4\": 0.3412948720529228, \"phi\": 0.23701409364667378}, {\"truth_threshold\": 28.060000000000002, \"match_probability\": 0.9999999964264626, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1615, \"tn\": 7018, \"fp\": 0, \"fn\": 10166, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1370851370851371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.862914862914863, \"precision\": 1.0, \"recall\": 0.1370851370851371, \"specificity\": 1.0, \"npv\": 0.40840316573556795, \"accuracy\": 0.4592265546039683, \"f1\": 0.24111675126903553, \"f2\": 0.16567840948726892, \"f0_5\": 0.4426840633737186, \"p4\": 0.3406198247778175, \"phi\": 0.23661361744596252}, {\"truth_threshold\": 28.080000000000002, \"match_probability\": 0.9999999964756606, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1610, \"tn\": 7018, \"fp\": 0, \"fn\": 10171, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13666072489601902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.863339275103981, \"precision\": 1.0, \"recall\": 0.13666072489601902, \"specificity\": 1.0, \"npv\": 0.4082843679097097, \"accuracy\": 0.4589605830097346, \"f1\": 0.24046001045478307, \"f2\": 0.16518241884515944, \"f0_5\": 0.4417979254706108, \"p4\": 0.33994340243722915, \"phi\": 0.236212695853237}, {\"truth_threshold\": 28.1, \"match_probability\": 0.9999999965241813, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1605, \"tn\": 7018, \"fp\": 0, \"fn\": 10176, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13623631270690095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.863763687293099, \"precision\": 1.0, \"recall\": 0.13623631270690095, \"specificity\": 1.0, \"npv\": 0.40816563917645693, \"accuracy\": 0.45869461141550083, \"f1\": 0.2398027790228597, \"f2\": 0.1646863264175337, \"f0_5\": 0.4409098401186748, \"p4\": 0.33926559966834535, \"phi\": 0.23581132639263935}, {\"truth_threshold\": 28.12, \"match_probability\": 0.9999999965720339, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1600, \"tn\": 7018, \"fp\": 0, \"fn\": 10181, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13581190051778286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8641880994822171, \"precision\": 1.0, \"recall\": 0.13581190051778286, \"specificity\": 1.0, \"npv\": 0.4080469794755509, \"accuracy\": 0.4584286398212671, \"f1\": 0.23914505642328676, \"f2\": 0.1641901321730564, \"f0_5\": 0.4400198008910401, \"p4\": 0.33858641108128723, \"phi\": 0.23540950656911738}, {\"truth_threshold\": 28.14, \"match_probability\": 0.9999999966192277, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1598, \"tn\": 7018, \"fp\": 0, \"fn\": 10183, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13564213564213565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8643578643578643, \"precision\": 1.0, \"recall\": 0.13564213564213565, \"specificity\": 1.0, \"npv\": 0.407999534910761, \"accuracy\": 0.4583222511835736, \"f1\": 0.2388818297331639, \"f2\": 0.16399162595952546, \"f0_5\": 0.43966323666978485, \"p4\": 0.3383143464048601, \"phi\": 0.235248651975508}, {\"truth_threshold\": 28.16, \"match_probability\": 0.9999999966657718, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1597, \"tn\": 7018, \"fp\": 0, \"fn\": 10184, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13555725320431203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.864442746795688, \"precision\": 1.0, \"recall\": 0.13555725320431203, \"specificity\": 1.0, \"npv\": 0.4079758167654924, \"accuracy\": 0.45826905686472685, \"f1\": 0.2387501868739722, \"f2\": 0.16389236674124094, \"f0_5\": 0.43948483680995104, \"p4\": 0.3381782304839462, \"phi\": 0.23516819745559953}, {\"truth_threshold\": 28.18, \"match_probability\": 0.999999996711675, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1593, \"tn\": 7018, \"fp\": 0, \"fn\": 10188, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13521772345301758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8647822765469825, \"precision\": 1.0, \"recall\": 0.13521772345301758, \"specificity\": 1.0, \"npv\": 0.4078809717540393, \"accuracy\": 0.45805627958933987, \"f1\": 0.23822341857335128, \"f2\": 0.1634952891187881, \"f0_5\": 0.43877045116509666, \"p4\": 0.3376332085654667, \"phi\": 0.23484619741521418}, {\"truth_threshold\": 28.2, \"match_probability\": 0.9999999967569464, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1592, \"tn\": 7018, \"fp\": 0, \"fn\": 10189, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13513284101519396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.864867158984806, \"precision\": 1.0, \"recall\": 0.13513284101519396, \"specificity\": 1.0, \"npv\": 0.407857267391178, \"accuracy\": 0.4580030852704931, \"f1\": 0.23809167726015104, \"f2\": 0.16339600952459152, \"f0_5\": 0.43859165794258637, \"p4\": 0.33749681330880954, \"phi\": 0.23476565181317202}, {\"truth_threshold\": 28.22, \"match_probability\": 0.9999999968015946, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1589, \"tn\": 7018, \"fp\": 0, \"fn\": 10192, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1348781937017231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8651218062982768, \"precision\": 1.0, \"recall\": 0.1348781937017231, \"specificity\": 1.0, \"npv\": 0.4077861708309123, \"accuracy\": 0.4578435023139529, \"f1\": 0.23769633507853402, \"f2\": 0.16309814628538583, \"f0_5\": 0.4380548050945581, \"p4\": 0.33708729137369725, \"phi\": 0.23452390525960407}, {\"truth_threshold\": 28.240000000000002, \"match_probability\": 0.9999999968456279, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1583, \"tn\": 7018, \"fp\": 0, \"fn\": 10198, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13436889907478142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8656311009252186, \"precision\": 1.0, \"recall\": 0.13436889907478142, \"specificity\": 1.0, \"npv\": 0.4076440520446097, \"accuracy\": 0.45752433640087237, \"f1\": 0.23690511822807542, \"f2\": 0.16250230972960766, \"f0_5\": 0.43697896538397835, \"p4\": 0.33626673080744757, \"phi\": 0.234039916440801}, {\"truth_threshold\": 28.26, \"match_probability\": 0.999999996889055, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1580, \"tn\": 7018, \"fp\": 0, \"fn\": 10201, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1341142517613106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8658857482386895, \"precision\": 1.0, \"recall\": 0.1341142517613106, \"specificity\": 1.0, \"npv\": 0.4075730297926709, \"accuracy\": 0.45736475344433214, \"f1\": 0.23650924332011078, \"f2\": 0.16220433639947437, \"f0_5\": 0.4364399756919507, \"p4\": 0.33585568979675434, \"phi\": 0.23379767306099178}, {\"truth_threshold\": 28.28, \"match_probability\": 0.9999999969318843, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1578, \"tn\": 7018, \"fp\": 0, \"fn\": 10203, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13394448688566335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8660555131143366, \"precision\": 1.0, \"recall\": 0.13394448688566335, \"specificity\": 1.0, \"npv\": 0.4075256953719296, \"accuracy\": 0.4572583648066387, \"f1\": 0.23624522793622277, \"f2\": 0.16200566711839348, \"f0_5\": 0.4360802520311723, \"p4\": 0.33558137989459663, \"phi\": 0.23363608488270016}, {\"truth_threshold\": 28.3, \"match_probability\": 0.999999996974124, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1574, \"tn\": 7018, \"fp\": 0, \"fn\": 10207, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1336049571343689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8663950428656311, \"precision\": 1.0, \"recall\": 0.1336049571343689, \"specificity\": 1.0, \"npv\": 0.4074310595065312, \"accuracy\": 0.4570455875312517, \"f1\": 0.23571695994009734, \"f2\": 0.16160827960080495, \"f0_5\": 0.4353598495325552, \"p4\": 0.3350320803441379, \"phi\": 0.23331268555434487}, {\"truth_threshold\": 28.32, \"match_probability\": 0.9999999970157821, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1572, \"tn\": 7018, \"fp\": 0, \"fn\": 10209, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13343519225872166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8665648077412783, \"precision\": 1.0, \"recall\": 0.13343519225872166, \"specificity\": 1.0, \"npv\": 0.4073837580542172, \"accuracy\": 0.45693919889355816, \"f1\": 0.23545270725679623, \"f2\": 0.161409561360276, \"f0_5\": 0.4349991698489125, \"p4\": 0.33475708998359593, \"phi\": 0.2331508740687991}, {\"truth_threshold\": 28.34, \"match_probability\": 0.9999999970568668, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1564, \"tn\": 7018, \"fp\": 0, \"fn\": 10217, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13275613275613277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8672438672438673, \"precision\": 1.0, \"recall\": 0.13275613275613277, \"specificity\": 1.0, \"npv\": 0.40719466202494925, \"accuracy\": 0.4565136443427842, \"f1\": 0.23439490445859873, \"f2\": 0.16061452513966482, \"f0_5\": 0.43355325164938735, \"p4\": 0.33365484962933467, \"phi\": 0.23250287871201245}, {\"truth_threshold\": 28.36, \"match_probability\": 0.9999999970973857, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1561, \"tn\": 7018, \"fp\": 0, \"fn\": 10220, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1325014854426619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8674985145573381, \"precision\": 1.0, \"recall\": 0.1325014854426619, \"specificity\": 1.0, \"npv\": 0.40712379626406775, \"accuracy\": 0.45635406138624396, \"f1\": 0.23399790136411333, \"f2\": 0.16031631919482386, \"f0_5\": 0.4330097087378641, \"p4\": 0.33324056623560133, \"phi\": 0.23225956980078266}, {\"truth_threshold\": 28.38, \"match_probability\": 0.9999999971373469, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1559, \"tn\": 7018, \"fp\": 0, \"fn\": 10222, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13233172056701467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8676682794329853, \"precision\": 1.0, \"recall\": 0.13233172056701467, \"specificity\": 1.0, \"npv\": 0.40707656612529003, \"accuracy\": 0.45624767274855044, \"f1\": 0.23373313343328336, \"f2\": 0.16011749481338455, \"f0_5\": 0.4326469445523672, \"p4\": 0.3329640904934726, \"phi\": 0.23209726925983373}, {\"truth_threshold\": 28.400000000000002, \"match_probability\": 0.9999999971767579, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1558, \"tn\": 7018, \"fp\": 0, \"fn\": 10223, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13224683812919108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.867753161870809, \"precision\": 1.0, \"recall\": 0.13224683812919108, \"specificity\": 1.0, \"npv\": 0.4070529551650136, \"accuracy\": 0.45619447842970373, \"f1\": 0.23360071969413, \"f2\": 0.16001807649644634, \"f0_5\": 0.4324654416254927, \"p4\": 0.3328257664428478, \"phi\": 0.23201609054485084}, {\"truth_threshold\": 28.42, \"match_probability\": 0.9999999972156263, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1554, \"tn\": 7018, \"fp\": 0, \"fn\": 10227, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1319073083778966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8680926916221033, \"precision\": 1.0, \"recall\": 0.1319073083778966, \"specificity\": 1.0, \"npv\": 0.40695853870687154, \"accuracy\": 0.45598170115431674, \"f1\": 0.23307086614173228, \"f2\": 0.15962036238136323, \"f0_5\": 0.43173862310385064, \"p4\": 0.3322718946520509, \"phi\": 0.23169118555142637}, {\"truth_threshold\": 28.44, \"match_probability\": 0.9999999972539596, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1552, \"tn\": 7018, \"fp\": 0, \"fn\": 10229, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1317375435022494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8682624564977506, \"precision\": 1.0, \"recall\": 0.1317375435022494, \"specificity\": 1.0, \"npv\": 0.4069113469009103, \"accuracy\": 0.4558753125166232, \"f1\": 0.23280582014550363, \"f2\": 0.15942148081189908, \"f0_5\": 0.4313747290010562, \"p4\": 0.3319946127674777, \"phi\": 0.23152861867146698}, {\"truth_threshold\": 28.46, \"match_probability\": 0.9999999972917651, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1548, \"tn\": 7018, \"fp\": 0, \"fn\": 10233, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13139801375095492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.868601986249045, \"precision\": 1.0, \"recall\": 0.13139801375095492, \"specificity\": 1.0, \"npv\": 0.4068169961161672, \"accuracy\": 0.45566253524123623, \"f1\": 0.23227548953409857, \"f2\": 0.15902366863905326, \"f0_5\": 0.43064596895343016, \"p4\": 0.33143935519716394, \"phi\": 0.2312032552750811}, {\"truth_threshold\": 28.48, \"match_probability\": 0.9999999973290502, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1545, \"tn\": 7018, \"fp\": 0, \"fn\": 10236, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1311433664374841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.868856633562516, \"precision\": 1.0, \"recall\": 0.1311433664374841, \"specificity\": 1.0, \"npv\": 0.40674626173640893, \"accuracy\": 0.455502952284696, \"f1\": 0.23187753264295363, \"f2\": 0.158725266596807, \"f0_5\": 0.4300985468515116, \"p4\": 0.3310223035031615, \"phi\": 0.23095903110719593}, {\"truth_threshold\": 28.5, \"match_probability\": 0.999999997365822, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1543, \"tn\": 7018, \"fp\": 0, \"fn\": 10238, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13097360156183685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8690263984381631, \"precision\": 1.0, \"recall\": 0.13097360156183685, \"specificity\": 1.0, \"npv\": 0.4066991191469634, \"accuracy\": 0.4553965636470025, \"f1\": 0.23161212848994295, \"f2\": 0.15852631146362012, \"f0_5\": 0.4297331922241408, \"p4\": 0.3307439785830787, \"phi\": 0.23079611865606492}, {\"truth_threshold\": 28.52, \"match_probability\": 0.9999999974020874, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1540, \"tn\": 7018, \"fp\": 0, \"fn\": 10241, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13071895424836602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.869281045751634, \"precision\": 1.0, \"recall\": 0.13071895424836602, \"specificity\": 1.0, \"npv\": 0.40662842574888464, \"accuracy\": 0.45523698069046226, \"f1\": 0.23121387283236994, \"f2\": 0.15822784810126583, \"f0_5\": 0.4291845493562232, \"p4\": 0.33032605459699443, \"phi\": 0.23055160502922886}, {\"truth_threshold\": 28.54, \"match_probability\": 0.9999999974378537, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1538, \"tn\": 7018, \"fp\": 0, \"fn\": 10243, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13054918937271878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8694508106272812, \"precision\": 1.0, \"recall\": 0.13054918937271878, \"specificity\": 1.0, \"npv\": 0.4065813104686866, \"accuracy\": 0.4551305920527688, \"f1\": 0.2309482693895938, \"f2\": 0.15802885208170647, \"f0_5\": 0.428818379523783, \"p4\": 0.3300471469976832, \"phi\": 0.23038849905276249}, {\"truth_threshold\": 28.580000000000002, \"match_probability\": 0.9999999975079157, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1534, \"tn\": 7018, \"fp\": 0, \"fn\": 10247, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.13020965962142433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8697903403785757, \"precision\": 1.0, \"recall\": 0.13020965962142433, \"specificity\": 1.0, \"npv\": 0.40648711265566173, \"accuracy\": 0.4549178147773818, \"f1\": 0.23041682313180623, \"f2\": 0.15763081096633647, \"f0_5\": 0.42808505888262544, \"p4\": 0.32948863027380615, \"phi\": 0.2300620537580878}, {\"truth_threshold\": 28.6, \"match_probability\": 0.999999997542225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1530, \"tn\": 7018, \"fp\": 0, \"fn\": 10251, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12987012987012986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8701298701298701, \"precision\": 1.0, \"recall\": 0.12987012987012986, \"specificity\": 1.0, \"npv\": 0.4063929584805142, \"accuracy\": 0.4547050375019948, \"f1\": 0.22988505747126436, \"f2\": 0.15723270440251572, \"f0_5\": 0.42735042735042733, \"p4\": 0.32892917570854757, \"phi\": 0.22973529614791602}, {\"truth_threshold\": 28.62, \"match_probability\": 0.999999997576062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1525, \"tn\": 7018, \"fp\": 0, \"fn\": 10256, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1294457176810118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8705542823189882, \"precision\": 1.0, \"recall\": 0.1294457176810118, \"specificity\": 1.0, \"npv\": 0.40627532708116243, \"accuracy\": 0.45443906590776106, \"f1\": 0.2292199007966331, \"f2\": 0.1567349791362618, \"f0_5\": 0.42643028913371733, \"p4\": 0.3282285341216048, \"phi\": 0.22932640774692495}, {\"truth_threshold\": 28.64, \"match_probability\": 0.999999997609433, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1522, \"tn\": 7018, \"fp\": 0, \"fn\": 10259, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12919107036754096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.870808929632459, \"precision\": 1.0, \"recall\": 0.12919107036754096, \"specificity\": 1.0, \"npv\": 0.40620478092261386, \"accuracy\": 0.45427948295122084, \"f1\": 0.22882056678944598, \"f2\": 0.15643629486494265, \"f0_5\": 0.4258772175275617, \"p4\": 0.3278074411218314, \"phi\": 0.22908083821176525}, {\"truth_threshold\": 28.66, \"match_probability\": 0.9999999976423446, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1521, \"tn\": 7018, \"fp\": 0, \"fn\": 10260, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12910618792971734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8708938120702827, \"precision\": 1.0, \"recall\": 0.12910618792971734, \"specificity\": 1.0, \"npv\": 0.40618127098043755, \"accuracy\": 0.4542262886323741, \"f1\": 0.22868741542625168, \"f2\": 0.15633672525439407, \"f0_5\": 0.4256926952141058, \"p4\": 0.32766695849910643, \"phi\": 0.22899894214762612}, {\"truth_threshold\": 28.68, \"match_probability\": 0.9999999976748032, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1518, \"tn\": 7018, \"fp\": 0, \"fn\": 10263, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12885154061624648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8711484593837535, \"precision\": 1.0, \"recall\": 0.12885154061624648, \"specificity\": 1.0, \"npv\": 0.4061107574793125, \"accuracy\": 0.45406670567583385, \"f1\": 0.228287841191067, \"f2\": 0.1560379918588874, \"f0_5\": 0.42513863216266173, \"p4\": 0.32724515510358826, \"phi\": 0.22875313497751298}, {\"truth_threshold\": 28.72, \"match_probability\": 0.9999999977383858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1508, \"tn\": 7018, \"fp\": 0, \"fn\": 10273, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12800271623801035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8719972837619896, \"precision\": 1.0, \"recall\": 0.12800271623801035, \"specificity\": 1.0, \"npv\": 0.40587588919090856, \"accuracy\": 0.45353476248736635, \"f1\": 0.22695462412521633, \"f2\": 0.1550419476887646, \"f0_5\": 0.4232863638915399, \"p4\": 0.3258352778991814, \"phi\": 0.2279324818273034}, {\"truth_threshold\": 28.740000000000002, \"match_probability\": 0.9999999977695221, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1506, \"tn\": 7018, \"fp\": 0, \"fn\": 10275, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12783295136236314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8721670486376368, \"precision\": 1.0, \"recall\": 0.12783295136236314, \"specificity\": 1.0, \"npv\": 0.40582894812930087, \"accuracy\": 0.45342837384967283, \"f1\": 0.22668773989613908, \"f2\": 0.15484268969771744, \"f0_5\": 0.42291491154170174, \"p4\": 0.32555258590808794, \"phi\": 0.22776811055907695}, {\"truth_threshold\": 28.76, \"match_probability\": 0.9999999978002297, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1503, \"tn\": 7018, \"fp\": 0, \"fn\": 10278, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12757830404889228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8724216959511077, \"precision\": 1.0, \"recall\": 0.12757830404889228, \"specificity\": 1.0, \"npv\": 0.4057585568917669, \"accuracy\": 0.4532687908931326, \"f1\": 0.22628726287262874, \"f2\": 0.15454377197853045, \"f0_5\": 0.4223571067273647, \"p4\": 0.32512809828916084, \"phi\": 0.22752140238135313}, {\"truth_threshold\": 28.78, \"match_probability\": 0.9999999978305146, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1501, \"tn\": 7018, \"fp\": 0, \"fn\": 10280, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12740853917324504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.872591460826755, \"precision\": 1.0, \"recall\": 0.12740853917324504, \"specificity\": 1.0, \"npv\": 0.40571164296450457, \"accuracy\": 0.45316240225543913, \"f1\": 0.22602017768408372, \"f2\": 0.1543444730077121, \"f0_5\": 0.4219848186674164, \"p4\": 0.3248448062295099, \"phi\": 0.2273568291379977}, {\"truth_threshold\": 28.82, \"match_probability\": 0.9999999978898393, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1497, \"tn\": 7018, \"fp\": 0, \"fn\": 10284, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1270690094219506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8729309905780493, \"precision\": 1.0, \"recall\": 0.1270690094219506, \"specificity\": 1.0, \"npv\": 0.4056178476476708, \"accuracy\": 0.45294962498005215, \"f1\": 0.2254857659286037, \"f2\": 0.15394582587770717, \"f0_5\": 0.42123923687320614, \"p4\": 0.3242774996279864, \"phi\": 0.22702743910032813}, {\"truth_threshold\": 28.84, \"match_probability\": 0.9999999979188905, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1494, \"tn\": 7018, \"fp\": 0, \"fn\": 10287, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12681436210847977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8731856378915203, \"precision\": 1.0, \"recall\": 0.12681436210847977, \"specificity\": 1.0, \"npv\": 0.405547529615718, \"accuracy\": 0.45279004202351186, \"f1\": 0.22508474576271187, \"f2\": 0.15364679748241392, \"f0_5\": 0.42067916877850986, \"p4\": 0.3238513859870147, \"phi\": 0.2267801827164073}, {\"truth_threshold\": 28.86, \"match_probability\": 0.9999999979475418, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1492, \"tn\": 7018, \"fp\": 0, \"fn\": 10289, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12664459723283253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8733554027671675, \"precision\": 1.0, \"recall\": 0.12664459723283253, \"specificity\": 1.0, \"npv\": 0.4055006644710233, \"accuracy\": 0.4526836533858184, \"f1\": 0.224817298274693, \"f2\": 0.15344742471614284, \"f0_5\": 0.4203053693165812, \"p4\": 0.3235670077444392, \"phi\": 0.2266152429329914}, {\"truth_threshold\": 28.88, \"match_probability\": 0.9999999979757986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1486, \"tn\": 7018, \"fp\": 0, \"fn\": 10295, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12613530260589084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8738646973941092, \"precision\": 1.0, \"recall\": 0.12613530260589084, \"specificity\": 1.0, \"npv\": 0.4053601340033501, \"accuracy\": 0.4523644874727379, \"f1\": 0.224014471998191, \"f2\": 0.15284920798189672, \"f0_5\": 0.4191819464033851, \"p4\": 0.32271241683432916, \"phi\": 0.22611993093683058}, {\"truth_threshold\": 28.900000000000002, \"match_probability\": 0.9999999980036663, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1485, \"tn\": 7018, \"fp\": 0, \"fn\": 10296, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12605042016806722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8739495798319328, \"precision\": 1.0, \"recall\": 0.12605042016806722, \"specificity\": 1.0, \"npv\": 0.40533672172808133, \"accuracy\": 0.4523112931538912, \"f1\": 0.22388059701492538, \"f2\": 0.15274949083503056, \"f0_5\": 0.41899441340782123, \"p4\": 0.32256977214507215, \"phi\": 0.22603730683975953}, {\"truth_threshold\": 28.92, \"match_probability\": 0.9999999980311505, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1482, \"tn\": 7018, \"fp\": 0, \"fn\": 10299, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1257957728545964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8742042271454036, \"precision\": 1.0, \"recall\": 0.1257957728545964, \"specificity\": 1.0, \"npv\": 0.4052665011260611, \"accuracy\": 0.4521517101973509, \"f1\": 0.22347885093870165, \"f2\": 0.15245031477595358, \"f0_5\": 0.4184313061155345, \"p4\": 0.3221414721794251, \"phi\": 0.2257893104671499}, {\"truth_threshold\": 28.94, \"match_probability\": 0.9999999980582562, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1474, \"tn\": 7018, \"fp\": 0, \"fn\": 10307, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12511671335200747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8748832866479925, \"precision\": 1.0, \"recall\": 0.12511671335200747, \"specificity\": 1.0, \"npv\": 0.4050793650793651, \"accuracy\": 0.4517261556465769, \"f1\": 0.22240663900414936, \"f2\": 0.1516523313716614, \"f0_5\": 0.4169259489732421, \"p4\": 0.3209966470546271, \"phi\": 0.2251270725733538}, {\"truth_threshold\": 28.96, \"match_probability\": 0.9999999980849887, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1471, \"tn\": 7018, \"fp\": 0, \"fn\": 10310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12486206603853663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8751379339614633, \"precision\": 1.0, \"recall\": 0.12486206603853663, \"specificity\": 1.0, \"npv\": 0.40500923361034163, \"accuracy\": 0.4515665726900367, \"f1\": 0.22200422577724116, \"f2\": 0.15135301985801008, \"f0_5\": 0.41636003396546845, \"p4\": 0.3205663243853989, \"phi\": 0.22487838863099224}, {\"truth_threshold\": 29.0, \"match_probability\": 0.9999999981373549, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1469, \"tn\": 7018, \"fp\": 0, \"fn\": 10312, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1246923011628894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8753076988371106, \"precision\": 1.0, \"recall\": 0.1246923011628894, \"specificity\": 1.0, \"npv\": 0.4049624927870744, \"accuracy\": 0.4514601840523432, \"f1\": 0.22173584905660376, \"f2\": 0.15115345831704155, \"f0_5\": 0.4159823299541258, \"p4\": 0.3202791344899712, \"phi\": 0.22471249433505094}, {\"truth_threshold\": 29.02, \"match_probability\": 0.9999999981629984, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1463, \"tn\": 7018, \"fp\": 0, \"fn\": 10318, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12418300653594772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8758169934640523, \"precision\": 1.0, \"recall\": 0.12418300653594772, \"specificity\": 1.0, \"npv\": 0.40482233502538073, \"accuracy\": 0.4511410181392627, \"f1\": 0.22093023255813954, \"f2\": 0.15055467511885895, \"f0_5\": 0.4148471615720524, \"p4\": 0.31941608147455236, \"phi\": 0.22421430524467983}, {\"truth_threshold\": 29.04, \"match_probability\": 0.999999998188289, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1459, \"tn\": 7018, \"fp\": 0, \"fn\": 10322, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12384347678465325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8761565232153468, \"precision\": 1.0, \"recall\": 0.12384347678465325, \"specificity\": 1.0, \"npv\": 0.4047289504036909, \"accuracy\": 0.45092824086387573, \"f1\": 0.220392749244713, \"f2\": 0.1501554041537163, \"f0_5\": 0.4140886643582903, \"p4\": 0.31883947269927854, \"phi\": 0.2238817553383852}, {\"truth_threshold\": 29.060000000000002, \"match_probability\": 0.9999999982132314, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1456, \"tn\": 7018, \"fp\": 0, \"fn\": 10325, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12358882947118241, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8764111705288176, \"precision\": 1.0, \"recall\": 0.12358882947118241, \"specificity\": 1.0, \"npv\": 0.40465894020642335, \"accuracy\": 0.4507686579073355, \"f1\": 0.21998942358540455, \"f2\": 0.14985590778097982, \"f0_5\": 0.4135188866799205, \"p4\": 0.31840636278756074, \"phi\": 0.22363211923863052}, {\"truth_threshold\": 29.080000000000002, \"match_probability\": 0.9999999982378304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1453, \"tn\": 7018, \"fp\": 0, \"fn\": 10328, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12333418215771157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8766658178422885, \"precision\": 1.0, \"recall\": 0.12333418215771157, \"specificity\": 1.0, \"npv\": 0.4045889542257581, \"accuracy\": 0.4506090749507953, \"f1\": 0.21958591506725103, \"f2\": 0.14955637441587583, \"f0_5\": 0.4129483317228443, \"p4\": 0.31797269136977085, \"phi\": 0.22338229065769222}, {\"truth_threshold\": 29.1, \"match_probability\": 0.9999999982620906, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1451, \"tn\": 7018, \"fp\": 0, \"fn\": 10330, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12316441728206434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8768355827179357, \"precision\": 1.0, \"recall\": 0.12316441728206434, \"specificity\": 1.0, \"npv\": 0.40454231035277843, \"accuracy\": 0.45050268631310175, \"f1\": 0.21931680773881498, \"f2\": 0.14935666495110653, \"f0_5\": 0.41256752914415695, \"p4\": 0.31768326447078, \"phi\": 0.2232156309950985}, {\"truth_threshold\": 29.12, \"match_probability\": 0.9999999982860169, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1450, \"tn\": 7018, \"fp\": 0, \"fn\": 10331, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12307953484424072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8769204651557593, \"precision\": 1.0, \"recall\": 0.12307953484424072, \"specificity\": 1.0, \"npv\": 0.40451899244913253, \"accuracy\": 0.450449491994255, \"f1\": 0.21918222356586803, \"f2\": 0.1492568040515502, \"f0_5\": 0.41237699789545534, \"p4\": 0.3175384570834423, \"phi\": 0.2231322689041192}, {\"truth_threshold\": 29.14, \"match_probability\": 0.9999999983096138, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1449, \"tn\": 7018, \"fp\": 0, \"fn\": 10332, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12299465240641712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8770053475935828, \"precision\": 1.0, \"recall\": 0.12299465240641712, \"specificity\": 1.0, \"npv\": 0.4044956772334294, \"accuracy\": 0.4503962976754083, \"f1\": 0.21904761904761905, \"f2\": 0.14915693904020752, \"f0_5\": 0.4121863799283154, \"p4\": 0.317393587003329, \"phi\": 0.22304888527231856}, {\"truth_threshold\": 29.16, \"match_probability\": 0.9999999983328859, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1447, \"tn\": 7018, \"fp\": 0, \"fn\": 10334, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12282488753076988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8771751124692301, \"precision\": 1.0, \"recall\": 0.12282488753076988, \"specificity\": 1.0, \"npv\": 0.40444905486399263, \"accuracy\": 0.45028990903771476, \"f1\": 0.21877834895675838, \"f2\": 0.14895719668114718, \"f0_5\": 0.4118048836017986, \"p4\": 0.3171036585618139, \"phi\": 0.22288205328288788}, {\"truth_threshold\": 29.2, \"match_probability\": 0.9999999983784732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1443, \"tn\": 7018, \"fp\": 0, \"fn\": 10338, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12248535777947543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8775146422205246, \"precision\": 1.0, \"recall\": 0.12248535777947543, \"specificity\": 1.0, \"npv\": 0.4043558423599908, \"accuracy\": 0.4500771317623278, \"f1\": 0.21823956442831216, \"f2\": 0.14855766261041448, \"f0_5\": 0.41104084771833876, \"p4\": 0.31652304712990886, \"phi\": 0.22254812967464954}, {\"truth_threshold\": 29.22, \"match_probability\": 0.9999999984007972, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1437, \"tn\": 7018, \"fp\": 0, \"fn\": 10344, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12197606315253375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8780239368474663, \"precision\": 1.0, \"recall\": 0.12197606315253375, \"specificity\": 1.0, \"npv\": 0.40421610413546827, \"accuracy\": 0.4497579658492473, \"f1\": 0.2174307762142533, \"f2\": 0.14795823809229627, \"f0_5\": 0.409892178675338, \"p4\": 0.31565023748731436, \"phi\": 0.22204659205963742}, {\"truth_threshold\": 29.26, \"match_probability\": 0.9999999984445276, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1430, \"tn\": 7018, \"fp\": 0, \"fn\": 10351, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12138188608776844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8786181139122315, \"precision\": 1.0, \"recall\": 0.12138188608776844, \"specificity\": 1.0, \"npv\": 0.40405319822672575, \"accuracy\": 0.44938560561732005, \"f1\": 0.21648626144879268, \"f2\": 0.14725872224739464, \"f0_5\": 0.4085480829666876, \"p4\": 0.31462907606633994, \"phi\": 0.22146046888904336}, {\"truth_threshold\": 29.28, \"match_probability\": 0.9999999984659422, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1427, \"tn\": 7018, \"fp\": 0, \"fn\": 10354, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1211272387742976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8788727612257023, \"precision\": 1.0, \"recall\": 0.1211272387742976, \"specificity\": 1.0, \"npv\": 0.40398342159797374, \"accuracy\": 0.4492260226607798, \"f1\": 0.21608116293155663, \"f2\": 0.14695886799448002, \"f0_5\": 0.40797072445537197, \"p4\": 0.31419048072760575, \"phi\": 0.2212089427865779}, {\"truth_threshold\": 29.3, \"match_probability\": 0.999999998487062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1421, \"tn\": 7018, \"fp\": 0, \"fn\": 10360, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12061794414735591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8793820558526441, \"precision\": 1.0, \"recall\": 0.12061794414735591, \"specificity\": 1.0, \"npv\": 0.40384394061457013, \"accuracy\": 0.44890685674769937, \"f1\": 0.21527041357370094, \"f2\": 0.14635904830569574, \"f0_5\": 0.40681362725450904, \"p4\": 0.313311564070512, \"phi\": 0.22070529190143207}, {\"truth_threshold\": 29.32, \"match_probability\": 0.9999999985078911, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1420, \"tn\": 7018, \"fp\": 0, \"fn\": 10361, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.12053306170953229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8794669382904677, \"precision\": 1.0, \"recall\": 0.12053306170953229, \"specificity\": 1.0, \"npv\": 0.40382070314747687, \"accuracy\": 0.4488536624288526, \"f1\": 0.21513521702901295, \"f2\": 0.14625906394199076, \"f0_5\": 0.4066204684725961, \"p4\": 0.31316485361528507, \"phi\": 0.2206212721658126}, {\"truth_threshold\": 29.34, \"match_probability\": 0.9999999985284334, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1413, \"tn\": 7018, \"fp\": 0, \"fn\": 10368, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.119938884644767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.880061115355233, \"precision\": 1.0, \"recall\": 0.119938884644767, \"specificity\": 1.0, \"npv\": 0.4036581157252962, \"accuracy\": 0.4484813021969254, \"f1\": 0.21418826739427013, \"f2\": 0.14555905803819766, \"f0_5\": 0.40526587506453277, \"p4\": 0.31213607882708955, \"phi\": 0.22003250709361177}, {\"truth_threshold\": 29.38, \"match_probability\": 0.9999999985686735, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1412, \"tn\": 7018, \"fp\": 0, \"fn\": 10369, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11985400220694338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8801459977930566, \"precision\": 1.0, \"recall\": 0.11985400220694338, \"specificity\": 1.0, \"npv\": 0.4036348996376603, \"accuracy\": 0.44842810787807863, \"f1\": 0.21405290684453876, \"f2\": 0.1454590407120488, \"f0_5\": 0.4050720064260715, \"p4\": 0.3119888529982613, \"phi\": 0.21994830790886188}, {\"truth_threshold\": 29.400000000000002, \"match_probability\": 0.999999998588379, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1411, \"tn\": 7018, \"fp\": 0, \"fn\": 10370, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11976911976911978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8802308802308803, \"precision\": 1.0, \"recall\": 0.11976911976911978, \"specificity\": 1.0, \"npv\": 0.40361168622038185, \"accuracy\": 0.44837491355923187, \"f1\": 0.21391752577319587, \"f2\": 0.14535901926444833, \"f0_5\": 0.40487804878048783, \"p4\": 0.31184156251095807, \"phi\": 0.21986408616949088}, {\"truth_threshold\": 29.42, \"match_probability\": 0.9999999986078132, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1408, \"tn\": 7018, \"fp\": 0, \"fn\": 10373, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11951447245564893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.880485527544351, \"precision\": 1.0, \"recall\": 0.11951447245564893, \"specificity\": 1.0, \"npv\": 0.4035420619860848, \"accuracy\": 0.44821533060269164, \"f1\": 0.213511259382819, \"f2\": 0.14505893019038985, \"f0_5\": 0.40429564118761846, \"p4\": 0.3113993025698908, \"phi\": 0.2196112853473876}, {\"truth_threshold\": 29.46, \"match_probability\": 0.9999999986458826, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1401, \"tn\": 7018, \"fp\": 0, \"fn\": 10380, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11892029539088363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8810797046091163, \"precision\": 1.0, \"recall\": 0.11892029539088363, \"specificity\": 1.0, \"npv\": 0.40337969881595587, \"accuracy\": 0.4478429703707644, \"f1\": 0.21256258534365044, \"f2\": 0.14435857805255023, \"f0_5\": 0.4029335634167386, \"p4\": 0.3103650897773934, \"phi\": 0.21902062217489734}, {\"truth_threshold\": 29.48, \"match_probability\": 0.9999999986645252, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1400, \"tn\": 7018, \"fp\": 0, \"fn\": 10381, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11883541295306001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.88116458704694, \"precision\": 1.0, \"recall\": 0.11883541295306001, \"specificity\": 1.0, \"npv\": 0.40335651474222656, \"accuracy\": 0.44778977605191767, \"f1\": 0.21242697822623474, \"f2\": 0.14425851125216388, \"f0_5\": 0.4027386226339106, \"p4\": 0.31021708454951613, \"phi\": 0.21893615050214876}, {\"truth_threshold\": 29.5, \"match_probability\": 0.999999998682911, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1388, \"tn\": 7018, \"fp\": 0, \"fn\": 10393, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11781682369917663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8821831763008233, \"precision\": 1.0, \"recall\": 0.11781682369917663, \"specificity\": 1.0, \"npv\": 0.4030785135833668, \"accuracy\": 0.4471514442257567, \"f1\": 0.21079808641506567, \"f2\": 0.14305738786279684, \"f0_5\": 0.4003923152368315, \"p4\": 0.30843591340456733, \"phi\": 0.21792069697891872}, {\"truth_threshold\": 29.52, \"match_probability\": 0.9999999987010437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1387, \"tn\": 7018, \"fp\": 0, \"fn\": 10394, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11773194126135303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.882268058738647, \"precision\": 1.0, \"recall\": 0.11773194126135303, \"specificity\": 1.0, \"npv\": 0.4030553641167011, \"accuracy\": 0.44709824990690994, \"f1\": 0.2106622114216282, \"f2\": 0.14295726742388323, \"f0_5\": 0.4001962028968781, \"p4\": 0.30828705514317895, \"phi\": 0.2178359255340145}, {\"truth_threshold\": 29.54, \"match_probability\": 0.9999999987189269, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1380, \"tn\": 7018, \"fp\": 0, \"fn\": 10401, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11713776419658772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8828622358034123, \"precision\": 1.0, \"recall\": 0.11713776419658772, \"specificity\": 1.0, \"npv\": 0.4028933922728056, \"accuracy\": 0.4467258896749827, \"f1\": 0.20971050832003646, \"f2\": 0.14225630875804057, \"f0_5\": 0.3988208774059303, \"p4\": 0.30724319639783837, \"phi\": 0.21724187253017135}, {\"truth_threshold\": 29.560000000000002, \"match_probability\": 0.9999999987365638, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1376, \"tn\": 7018, \"fp\": 0, \"fn\": 10405, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11679823444529328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8832017655547068, \"precision\": 1.0, \"recall\": 0.11679823444529328, \"specificity\": 1.0, \"npv\": 0.40280089536819147, \"accuracy\": 0.44651311239959574, \"f1\": 0.20916622330318463, \"f2\": 0.14185567010309277, \"f0_5\": 0.3980329765692797, \"p4\": 0.30664524660425574, \"phi\": 0.21690189812905758}, {\"truth_threshold\": 29.580000000000002, \"match_probability\": 0.9999999987539578, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1375, \"tn\": 7018, \"fp\": 0, \"fn\": 10406, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11671335200746966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8832866479925303, \"precision\": 1.0, \"recall\": 0.11671335200746966, \"specificity\": 1.0, \"npv\": 0.4027777777777778, \"accuracy\": 0.446459918080749, \"f1\": 0.20903010033444816, \"f2\": 0.1417555001134044, \"f0_5\": 0.39783577339274345, \"p4\": 0.30649559280475175, \"phi\": 0.21681684565218676}, {\"truth_threshold\": 29.62, \"match_probability\": 0.9999999987880309, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1372, \"tn\": 7018, \"fp\": 0, \"fn\": 10409, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11645870469399881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8835412953060012, \"precision\": 1.0, \"recall\": 0.11645870469399881, \"specificity\": 1.0, \"npv\": 0.4027084409250014, \"accuracy\": 0.44630033512420875, \"f1\": 0.2086216072378925, \"f2\": 0.14145496535796767, \"f0_5\": 0.39724361572760436, \"p4\": 0.3060462312859209, \"phi\": 0.21656154644688289}, {\"truth_threshold\": 29.64, \"match_probability\": 0.9999999988047165, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1371, \"tn\": 7018, \"fp\": 0, \"fn\": 10410, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1163738222561752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8836261777438248, \"precision\": 1.0, \"recall\": 0.1163738222561752, \"specificity\": 1.0, \"npv\": 0.40268533394537526, \"accuracy\": 0.446247140805362, \"f1\": 0.208485401459854, \"f2\": 0.1413547788431797, \"f0_5\": 0.3970460469157255, \"p4\": 0.30589631055625094, \"phi\": 0.21647639935505128}, {\"truth_threshold\": 29.66, \"match_probability\": 0.9999999988211723, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1369, \"tn\": 7018, \"fp\": 0, \"fn\": 10412, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11620405738052797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.883795942619472, \"precision\": 1.0, \"recall\": 0.11620405738052797, \"specificity\": 1.0, \"npv\": 0.40263912794033274, \"accuracy\": 0.4461407521676685, \"f1\": 0.20821292775665398, \"f2\": 0.14115439341760666, \"f0_5\": 0.3966506345251202, \"p4\": 0.3055962684312858, \"phi\": 0.216306033958427}, {\"truth_threshold\": 29.68, \"match_probability\": 0.9999999988374015, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1368, \"tn\": 7018, \"fp\": 0, \"fn\": 10413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11611917494270435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8838808250572956, \"precision\": 1.0, \"recall\": 0.11611917494270435, \"specificity\": 1.0, \"npv\": 0.4026160289140038, \"accuracy\": 0.44608755784882176, \"f1\": 0.2080766598220397, \"f2\": 0.14105419450631032, \"f0_5\": 0.396452790818988, \"p4\": 0.3054461469256052, \"phi\": 0.21622081559415623}, {\"truth_threshold\": 29.7, \"match_probability\": 0.9999999988534074, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1362, \"tn\": 7018, \"fp\": 0, \"fn\": 10419, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11560988031576266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8843901196842373, \"precision\": 1.0, \"recall\": 0.11560988031576266, \"specificity\": 1.0, \"npv\": 0.4024774903939898, \"accuracy\": 0.44576839193574125, \"f1\": 0.2072586167541657, \"f2\": 0.1404529142432867, \"f0_5\": 0.3952637994079749, \"p4\": 0.30454400820026023, \"phi\": 0.21570900420297176}, {\"truth_threshold\": 29.72, \"match_probability\": 0.9999999988691929, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1359, \"tn\": 7018, \"fp\": 0, \"fn\": 10422, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11535523300229182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8846447669977082, \"precision\": 1.0, \"recall\": 0.11535523300229182, \"specificity\": 1.0, \"npv\": 0.40240825688073395, \"accuracy\": 0.445608808979201, \"f1\": 0.20684931506849316, \"f2\": 0.1401522183033228, \"f0_5\": 0.3946680606377418, \"p4\": 0.30409203010910485, \"phi\": 0.21545277495201395}, {\"truth_threshold\": 29.740000000000002, \"match_probability\": 0.9999999988847611, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1356, \"tn\": 7018, \"fp\": 0, \"fn\": 10425, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11510058568882098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.884899414311179, \"precision\": 1.0, \"recall\": 0.11510058568882098, \"specificity\": 1.0, \"npv\": 0.4023390471822508, \"accuracy\": 0.4454492260226608, \"f1\": 0.2064398264443937, \"f2\": 0.13985148514851486, \"f0_5\": 0.3940714908456844, \"p4\": 0.30363944419325706, \"phi\": 0.21519632890957793}, {\"truth_threshold\": 29.76, \"match_probability\": 0.9999999989001149, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1348, \"tn\": 7018, \"fp\": 0, \"fn\": 10433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11442152618623207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.885578473813768, \"precision\": 1.0, \"recall\": 0.11442152618623207, \"specificity\": 1.0, \"npv\": 0.4021546043206693, \"accuracy\": 0.4450236714718868, \"f1\": 0.2053469418843781, \"f2\": 0.13904934807724048, \"f0_5\": 0.39247656204507075, \"p4\": 0.30242956532861354, \"phi\": 0.21451140666452043}, {\"truth_threshold\": 29.78, \"match_probability\": 0.9999999989152574, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1345, \"tn\": 7018, \"fp\": 0, \"fn\": 10436, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11416687887276122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8858331211272388, \"precision\": 1.0, \"recall\": 0.11416687887276122, \"specificity\": 1.0, \"npv\": 0.4020854818379741, \"accuracy\": 0.44486408851534653, \"f1\": 0.2049367667225354, \"f2\": 0.1387484784088799, \"f0_5\": 0.39187693024882, \"p4\": 0.3019747377630571, \"phi\": 0.21425415865623665}, {\"truth_threshold\": 29.8, \"match_probability\": 0.9999999989301913, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1344, \"tn\": 7018, \"fp\": 0, \"fn\": 10437, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1140819964349376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8859180035650623, \"precision\": 1.0, \"recall\": 0.1140819964349376, \"specificity\": 1.0, \"npv\": 0.4020624462904612, \"accuracy\": 0.44481089419649983, \"f1\": 0.2048, \"f2\": 0.1386481802426343, \"f0_5\": 0.39167686658506734, \"p4\": 0.3018229920023815, \"phi\": 0.2141683603250739}, {\"truth_threshold\": 29.84, \"match_probability\": 0.9999999989594452, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1341, \"tn\": 7018, \"fp\": 0, \"fn\": 10440, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11382734912146678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8861726508785333, \"precision\": 1.0, \"recall\": 0.11382734912146678, \"specificity\": 1.0, \"npv\": 0.4019933554817276, \"accuracy\": 0.44465131123995955, \"f1\": 0.20438957475994513, \"f2\": 0.13834726090993502, \"f0_5\": 0.3910761154855643, \"p4\": 0.30136734420968175, \"phi\": 0.2139108179100078}, {\"truth_threshold\": 29.86, \"match_probability\": 0.9999999989737709, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1334, \"tn\": 7018, \"fp\": 0, \"fn\": 10447, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11323317205670147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8867668279432985, \"precision\": 1.0, \"recall\": 0.11323317205670147, \"specificity\": 1.0, \"npv\": 0.40183223590037215, \"accuracy\": 0.44427895100803233, \"f1\": 0.20343118566526877, \"f2\": 0.13764497090263733, \"f0_5\": 0.38967108722322835, \"p4\": 0.30030176407333126, \"phi\": 0.21330902162270562}, {\"truth_threshold\": 29.88, \"match_probability\": 0.9999999989878993, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1323, \"tn\": 7018, \"fp\": 0, \"fn\": 10458, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11229946524064172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8877005347593583, \"precision\": 1.0, \"recall\": 0.11229946524064172, \"specificity\": 1.0, \"npv\": 0.4015793087663081, \"accuracy\": 0.4436938135007181, \"f1\": 0.20192307692307693, \"f2\": 0.13654096228868662, \"f0_5\": 0.3874538745387454, \"p4\": 0.2986204472073098, \"phi\": 0.21236087593095615}, {\"truth_threshold\": 29.900000000000002, \"match_probability\": 0.9999999990018332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1317, \"tn\": 7018, \"fp\": 0, \"fn\": 10464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11179017061370003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8882098293863, \"precision\": 1.0, \"recall\": 0.11179017061370003, \"specificity\": 1.0, \"npv\": 0.401441482667887, \"accuracy\": 0.4433746475876376, \"f1\": 0.201099404489235, \"f2\": 0.1359385644392147, \"f0_5\": 0.3862396621502727, \"p4\": 0.2976998212971235, \"phi\": 0.21184242218889912}, {\"truth_threshold\": 29.92, \"match_probability\": 0.9999999990155752, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1315, \"tn\": 7018, \"fp\": 0, \"fn\": 10466, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11162040573805279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8883795942619472, \"precision\": 1.0, \"recall\": 0.11162040573805279, \"specificity\": 1.0, \"npv\": 0.4013955616563715, \"accuracy\": 0.44326825894994415, \"f1\": 0.20082467929138667, \"f2\": 0.13573773199281572, \"f0_5\": 0.38583416466169823, \"p4\": 0.29739238713037325, \"phi\": 0.21166940131615097}, {\"truth_threshold\": 29.94, \"match_probability\": 0.9999999990291281, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1311, \"tn\": 7018, \"fp\": 0, \"fn\": 10470, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11128087598675834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8887191240132417, \"precision\": 1.0, \"recall\": 0.11128087598675834, \"specificity\": 1.0, \"npv\": 0.40130375114364136, \"accuracy\": 0.44305548167455716, \"f1\": 0.2002749770852429, \"f2\": 0.1353360173428306, \"f0_5\": 0.38502202643171807, \"p4\": 0.2967766776949131, \"phi\": 0.2113230535555373}, {\"truth_threshold\": 29.96, \"match_probability\": 0.9999999990424944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1309, \"tn\": 7018, \"fp\": 0, \"fn\": 10472, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1111111111111111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8888888888888888, \"precision\": 1.0, \"recall\": 0.1111111111111111, \"specificity\": 1.0, \"npv\": 0.40125786163522015, \"accuracy\": 0.44294909303686364, \"f1\": 0.2, \"f2\": 0.13513513513513514, \"f0_5\": 0.38461538461538464, \"p4\": 0.29646840148698883, \"phi\": 0.21114972613848637}, {\"truth_threshold\": 29.98, \"match_probability\": 0.9999999990556766, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1307, \"tn\": 7018, \"fp\": 0, \"fn\": 10474, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11094134623546388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8890586537645361, \"precision\": 1.0, \"recall\": 0.11094134623546388, \"specificity\": 1.0, \"npv\": 0.4012119826206266, \"accuracy\": 0.4428427043991702, \"f1\": 0.19972493887530562, \"f2\": 0.13493423633623092, \"f0_5\": 0.38420836027985183, \"p4\": 0.2961598436577505, \"phi\": 0.21097629600912954}, {\"truth_threshold\": 30.04, \"match_probability\": 0.9999999990941445, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1305, \"tn\": 7018, \"fp\": 0, \"fn\": 10476, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11077158135981666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8892284186401833, \"precision\": 1.0, \"recall\": 0.11077158135981666, \"specificity\": 1.0, \"npv\": 0.4011661140962616, \"accuracy\": 0.44273631576147665, \"f1\": 0.19944979367262725, \"f2\": 0.13473332094406243, \"f0_5\": 0.3838009528851244, \"p4\": 0.2958510037350241, \"phi\": 0.2108027629003366}, {\"truth_threshold\": 30.060000000000002, \"match_probability\": 0.9999999991066156, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1303, \"tn\": 7018, \"fp\": 0, \"fn\": 10478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11060181648416942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8893981835158306, \"precision\": 1.0, \"recall\": 0.11060181648416942, \"specificity\": 1.0, \"npv\": 0.4011202560585277, \"accuracy\": 0.4426299271237832, \"f1\": 0.19917456435340875, \"f2\": 0.13453238895657382, \"f0_5\": 0.38339316189019007, \"p4\": 0.2955418812456039, \"phi\": 0.21062912654395244}, {\"truth_threshold\": 30.080000000000002, \"match_probability\": 0.9999999991189151, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1298, \"tn\": 7018, \"fp\": 0, \"fn\": 10483, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.11017740429505135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8898225957049486, \"precision\": 1.0, \"recall\": 0.11017740429505135, \"specificity\": 1.0, \"npv\": 0.4010056568196103, \"accuracy\": 0.44236395552954944, \"f1\": 0.1984861227922624, \"f2\": 0.1340299863698319, \"f0_5\": 0.38237200259235254, \"p4\": 0.29476783567801224, \"phi\": 0.21019458217569933}, {\"truth_threshold\": 30.1, \"match_probability\": 0.9999999991310453, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1295, \"tn\": 7018, \"fp\": 0, \"fn\": 10486, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10992275698158051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8900772430184195, \"precision\": 1.0, \"recall\": 0.10992275698158051, \"specificity\": 1.0, \"npv\": 0.400936928702011, \"accuracy\": 0.4422043725730092, \"f1\": 0.1980728051391863, \"f2\": 0.13372849501228856, \"f0_5\": 0.38175815105241434, \"p4\": 0.2943025561206003, \"phi\": 0.2099335432432188}, {\"truth_threshold\": 30.14, \"match_probability\": 0.999999999154807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1292, \"tn\": 7018, \"fp\": 0, \"fn\": 10489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10966810966810966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8903318903318903, \"precision\": 1.0, \"recall\": 0.10966810966810966, \"specificity\": 1.0, \"npv\": 0.4008682241389159, \"accuracy\": 0.442044789616469, \"f1\": 0.1976592977893368, \"f2\": 0.13342696629213482, \"f0_5\": 0.3811434302908726, \"p4\": 0.2938366354292716, \"phi\": 0.20967226895163554}, {\"truth_threshold\": 30.16, \"match_probability\": 0.999999999166443, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1287, \"tn\": 7018, \"fp\": 0, \"fn\": 10494, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1092436974789916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8907563025210085, \"precision\": 1.0, \"recall\": 0.1092436974789916, \"specificity\": 1.0, \"npv\": 0.4007537688442211, \"accuracy\": 0.44177881802223523, \"f1\": 0.19696969696969696, \"f2\": 0.1329243353783231, \"f0_5\": 0.38011695906432746, \"p4\": 0.29305867180184797, \"phi\": 0.20923628625834437}, {\"truth_threshold\": 30.18, \"match_probability\": 0.9999999991779188, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1284, \"tn\": 7018, \"fp\": 0, \"fn\": 10497, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10898905016552075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8910109498344793, \"precision\": 1.0, \"recall\": 0.10898905016552075, \"specificity\": 1.0, \"npv\": 0.40068512703397086, \"accuracy\": 0.441619235065695, \"f1\": 0.1965556831228473, \"f2\": 0.13262270699058007, \"f0_5\": 0.3794999113317964, \"p4\": 0.29259103349021715, \"phi\": 0.20897437979542732}, {\"truth_threshold\": 30.2, \"match_probability\": 0.9999999991892367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1278, \"tn\": 7018, \"fp\": 0, \"fn\": 10503, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10847975553857907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.891520244461421, \"precision\": 1.0, \"recall\": 0.10847975553857907, \"specificity\": 1.0, \"npv\": 0.4005479139318532, \"accuracy\": 0.4413000691526145, \"f1\": 0.19572708476912473, \"f2\": 0.1320193380438825, \"f0_5\": 0.3782631859350027, \"p4\": 0.29165381393854223, \"phi\": 0.20844984956774432}, {\"truth_threshold\": 30.22, \"match_probability\": 0.9999999992003986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1274, \"tn\": 7018, \"fp\": 0, \"fn\": 10507, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1081402257872846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8918597742127153, \"precision\": 1.0, \"recall\": 0.1081402257872846, \"specificity\": 1.0, \"npv\": 0.4004564907275321, \"accuracy\": 0.4410872918772275, \"f1\": 0.19517426273458446, \"f2\": 0.1316170089673127, \"f0_5\": 0.37743674823724593, \"p4\": 0.29102755642766476, \"phi\": 0.2080996283640578}, {\"truth_threshold\": 30.26, \"match_probability\": 0.9999999992222638, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1267, \"tn\": 7018, \"fp\": 0, \"fn\": 10514, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10754604872251931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8924539512774807, \"precision\": 1.0, \"recall\": 0.10754604872251931, \"specificity\": 1.0, \"npv\": 0.4002966005019393, \"accuracy\": 0.4407149316453003, \"f1\": 0.194206008583691, \"f2\": 0.1309127730363084, \"f0_5\": 0.3759867054424595, \"p4\": 0.28992881182660163, \"phi\": 0.20748570481129638}, {\"truth_threshold\": 30.28, \"match_probability\": 0.9999999992329711, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1264, \"tn\": 7018, \"fp\": 0, \"fn\": 10517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10729140140904847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8927085985909515, \"precision\": 1.0, \"recall\": 0.10729140140904847, \"specificity\": 1.0, \"npv\": 0.4002281151981751, \"accuracy\": 0.44055534868876006, \"f1\": 0.19379072441548487, \"f2\": 0.13061089526328842, \"f0_5\": 0.37536378214646315, \"p4\": 0.28945682842478304, \"phi\": 0.20722218839427956}, {\"truth_threshold\": 30.3, \"match_probability\": 0.999999999243531, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1263, \"tn\": 7018, \"fp\": 0, \"fn\": 10518, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10720651897122485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8927934810287751, \"precision\": 1.0, \"recall\": 0.10720651897122485, \"specificity\": 1.0, \"npv\": 0.4002052919708029, \"accuracy\": 0.4405021543699133, \"f1\": 0.1936522539098436, \"f2\": 0.13051026102052204, \"f0_5\": 0.37515594368205313, \"p4\": 0.2892993544569651, \"phi\": 0.2071342951470192}, {\"truth_threshold\": 30.32, \"match_probability\": 0.9999999992539456, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1261, \"tn\": 7018, \"fp\": 0, \"fn\": 10520, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10703675409557763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8929632459044223, \"precision\": 1.0, \"recall\": 0.10703675409557763, \"specificity\": 1.0, \"npv\": 0.4001596533242103, \"accuracy\": 0.4403957657322198, \"f1\": 0.19337524919490875, \"f2\": 0.1303089800558024, \"f0_5\": 0.374739970282318, \"p4\": 0.2889841868987536, \"phi\": 0.20695842677174345}, {\"truth_threshold\": 30.34, \"match_probability\": 0.9999999992642167, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1255, \"tn\": 7018, \"fp\": 0, \"fn\": 10526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10652745946863594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.893472540531364, \"precision\": 1.0, \"recall\": 0.10652745946863594, \"specificity\": 1.0, \"npv\": 0.40002279981760147, \"accuracy\": 0.4400765998191393, \"f1\": 0.19254372506903958, \"f2\": 0.12970503730957647, \"f0_5\": 0.3734896732337361, \"p4\": 0.2880369227676005, \"phi\": 0.2064301639637478}, {\"truth_threshold\": 30.38, \"match_probability\": 0.9999999992843367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1251, \"tn\": 7018, \"fp\": 0, \"fn\": 10530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10618792971734148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8938120702826585, \"precision\": 1.0, \"recall\": 0.10618792971734148, \"specificity\": 1.0, \"npv\": 0.3999316161385913, \"accuracy\": 0.43986382254375234, \"f1\": 0.1919889502762431, \"f2\": 0.12930232558139534, \"f0_5\": 0.3726541554959786, \"p4\": 0.28740394047524526, \"phi\": 0.20607743774190207}, {\"truth_threshold\": 30.42, \"match_probability\": 0.9999999993039066, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1249, \"tn\": 7018, \"fp\": 0, \"fn\": 10532, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10601816484169425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8939818351583058, \"precision\": 1.0, \"recall\": 0.10601816484169425, \"specificity\": 1.0, \"npv\": 0.3998860398860399, \"accuracy\": 0.4397574339060588, \"f1\": 0.19171143514965464, \"f2\": 0.12910094474190148, \"f0_5\": 0.37223579901055015, \"p4\": 0.2870870059644327, \"phi\": 0.20590090843541825}, {\"truth_threshold\": 30.44, \"match_probability\": 0.9999999993134899, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1247, \"tn\": 7018, \"fp\": 0, \"fn\": 10534, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10584839996604703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.894151600033953, \"precision\": 1.0, \"recall\": 0.10584839996604703, \"specificity\": 1.0, \"npv\": 0.3998404740200547, \"accuracy\": 0.43965104526836535, \"f1\": 0.19143383481731654, \"f2\": 0.12889954724938496, \"f0_5\": 0.3718170433538076, \"p4\": 0.28676977520653146, \"phi\": 0.20572426793329118}, {\"truth_threshold\": 30.46, \"match_probability\": 0.9999999993229413, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1246, \"tn\": 7018, \"fp\": 0, \"fn\": 10535, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10576351752822341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8942364824717766, \"precision\": 1.0, \"recall\": 0.10576351752822341, \"specificity\": 1.0, \"npv\": 0.39981769498091496, \"accuracy\": 0.4395978509495186, \"f1\": 0.19129500268672756, \"f2\": 0.1287988422575977, \"f0_5\": 0.37160751565762007, \"p4\": 0.28661104857734276, \"phi\": 0.20563590589001687}, {\"truth_threshold\": 30.48, \"match_probability\": 0.9999999993322626, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1243, \"tn\": 7018, \"fp\": 0, \"fn\": 10538, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10550887021475257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8944911297852475, \"precision\": 1.0, \"recall\": 0.10550887021475257, \"specificity\": 1.0, \"npv\": 0.39974937343358397, \"accuracy\": 0.43943826799297836, \"f1\": 0.19087837837837837, \"f2\": 0.1284967022970207, \"f0_5\": 0.37097833223900195, \"p4\": 0.2861344229307604, \"phi\": 0.20537065213908406}, {\"truth_threshold\": 30.5, \"match_probability\": 0.9999999993414554, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1239, \"tn\": 7018, \"fp\": 0, \"fn\": 10542, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1051693404634581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8948306595365418, \"precision\": 1.0, \"recall\": 0.1051693404634581, \"specificity\": 1.0, \"npv\": 0.39965831435079724, \"accuracy\": 0.43922549071759137, \"f1\": 0.19032258064516128, \"f2\": 0.12809379070777246, \"f0_5\": 0.370138017565872, \"p4\": 0.28549787959930095, \"phi\": 0.20501658794109995}, {\"truth_threshold\": 30.54, \"match_probability\": 0.9999999993594634, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1235, \"tn\": 7018, \"fp\": 0, \"fn\": 10546, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10482981071216366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8951701892878363, \"precision\": 1.0, \"recall\": 0.10482981071216366, \"specificity\": 1.0, \"npv\": 0.39956729674333863, \"accuracy\": 0.4390127134422044, \"f1\": 0.18976644130301168, \"f2\": 0.12769081246510475, \"f0_5\": 0.36929609473117636, \"p4\": 0.28486014114548963, \"phi\": 0.20466207290158847}, {\"truth_threshold\": 30.560000000000002, \"match_probability\": 0.9999999993682819, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1230, \"tn\": 7018, \"fp\": 0, \"fn\": 10551, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10440539852304558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8955946014769545, \"precision\": 1.0, \"recall\": 0.10440539852304558, \"specificity\": 1.0, \"npv\": 0.39945358301553874, \"accuracy\": 0.43874674184797063, \"f1\": 0.18907078625778187, \"f2\": 0.12718699590519916, \"f0_5\": 0.36824142266930127, \"p4\": 0.28406128121275087, \"phi\": 0.20421829136048464}, {\"truth_threshold\": 30.580000000000002, \"match_probability\": 0.9999999993769789, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1227, \"tn\": 7018, \"fp\": 0, \"fn\": 10554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10415075120957473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8958492487904253, \"precision\": 1.0, \"recall\": 0.10415075120957473, \"specificity\": 1.0, \"npv\": 0.3993853858411109, \"accuracy\": 0.4385871588914304, \"f1\": 0.1886531365313653, \"f2\": 0.1268846559533412, \"f0_5\": 0.36760740607585835, \"p4\": 0.28358106251339, \"phi\": 0.20395168044779025}, {\"truth_threshold\": 30.6, \"match_probability\": 0.9999999993855563, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1226, \"tn\": 7018, \"fp\": 0, \"fn\": 10555, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10406586877175113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8959341312282488, \"precision\": 1.0, \"recall\": 0.10406586877175113, \"specificity\": 1.0, \"npv\": 0.3993626586240255, \"accuracy\": 0.43853396457258365, \"f1\": 0.1885138771430768, \"f2\": 0.1267838676318511, \"f0_5\": 0.3673958645489961, \"p4\": 0.283420838770821, \"phi\": 0.20386275291162306}, {\"truth_threshold\": 30.62, \"match_probability\": 0.9999999993940155, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1221, \"tn\": 7018, \"fp\": 0, \"fn\": 10560, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10364145658263306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.896358543417367, \"precision\": 1.0, \"recall\": 0.10364145658263306, \"specificity\": 1.0, \"npv\": 0.3992490613266583, \"accuracy\": 0.4382679929783499, \"f1\": 0.18781725888324874, \"f2\": 0.12627986348122866, \"f0_5\": 0.36633663366336633, \"p4\": 0.28261858582956206, \"phi\": 0.20341768422421846}, {\"truth_threshold\": 30.64, \"match_probability\": 0.9999999994023583, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1217, \"tn\": 7018, \"fp\": 0, \"fn\": 10564, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1033019268313386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8966980731686615, \"precision\": 1.0, \"recall\": 0.1033019268313386, \"specificity\": 1.0, \"npv\": 0.3991582300079627, \"accuracy\": 0.4380552157029629, \"f1\": 0.18725957839667642, \"f2\": 0.12587658509339897, \"f0_5\": 0.36548741666166135, \"p4\": 0.2819754185116242, \"phi\": 0.20306110969461677}, {\"truth_threshold\": 30.66, \"match_probability\": 0.9999999994105861, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1215, \"tn\": 7018, \"fp\": 0, \"fn\": 10566, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10313216195569137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8968678380443086, \"precision\": 1.0, \"recall\": 0.10313216195569137, \"specificity\": 1.0, \"npv\": 0.39911282984531393, \"accuracy\": 0.43794882706526944, \"f1\": 0.18698060941828254, \"f2\": 0.12567492087134613, \"f0_5\": 0.3650621957815035, \"p4\": 0.28165337843291344, \"phi\": 0.20288264836156197}, {\"truth_threshold\": 30.68, \"match_probability\": 0.9999999994187008, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1213, \"tn\": 7018, \"fp\": 0, \"fn\": 10568, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10296239708004414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8970376029199558, \"precision\": 1.0, \"recall\": 0.10296239708004414, \"specificity\": 1.0, \"npv\": 0.39906744000909816, \"accuracy\": 0.4378424384275759, \"f1\": 0.18670155456364476, \"f2\": 0.1254732399611064, \"f0_5\": 0.3646365658630433, \"p4\": 0.28133103337782017, \"phi\": 0.20270407055590534}, {\"truth_threshold\": 30.7, \"match_probability\": 0.9999999994267037, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1209, \"tn\": 7018, \"fp\": 0, \"fn\": 10572, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10262286732874969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8973771326712503, \"precision\": 1.0, \"recall\": 0.10262286732874969, \"specificity\": 1.0, \"npv\": 0.3989766913018761, \"accuracy\": 0.43762966115218893, \"f1\": 0.1861431870669746, \"f2\": 0.12506982806777978, \"f0_5\": 0.3637840765481134, \"p4\": 0.28068542624179, \"phi\": 0.20234656423753766}, {\"truth_threshold\": 30.72, \"match_probability\": 0.9999999994345965, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1200, \"tn\": 7018, \"fp\": 0, \"fn\": 10581, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10185892538833716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8981410746116628, \"precision\": 1.0, \"recall\": 0.10185892538833716, \"specificity\": 1.0, \"npv\": 0.3987726575373601, \"accuracy\": 0.43715091228256825, \"f1\": 0.18488560203374163, \"f2\": 0.12416190712689347, \"f0_5\": 0.3618599601954044, \"p4\": 0.2792283204280254, \"phi\": 0.20154045343554947}, {\"truth_threshold\": 30.740000000000002, \"match_probability\": 0.9999999994423805, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1196, \"tn\": 7018, \"fp\": 0, \"fn\": 10585, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.1015193956370427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8984806043629573, \"precision\": 1.0, \"recall\": 0.1015193956370427, \"specificity\": 1.0, \"npv\": 0.3986820428336079, \"accuracy\": 0.4369381350071812, \"f1\": 0.18432611543500038, \"f2\": 0.12375827814569536, \"f0_5\": 0.3610021128886206, \"p4\": 0.2785787126447181, \"phi\": 0.20118141077099902}, {\"truth_threshold\": 30.76, \"match_probability\": 0.9999999994500575, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1188, \"tn\": 7018, \"fp\": 0, \"fn\": 10593, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10084033613445378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8991596638655462, \"precision\": 1.0, \"recall\": 0.10084033613445378, \"specificity\": 1.0, \"npv\": 0.3985009369144285, \"accuracy\": 0.43651258045640723, \"f1\": 0.183206106870229, \"f2\": 0.12295081967213115, \"f0_5\": 0.3592814371257485, \"p4\": 0.27727577277583615, \"phi\": 0.20046188772019913}, {\"truth_threshold\": 30.78, \"match_probability\": 0.9999999994576286, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1183, \"tn\": 7018, \"fp\": 0, \"fn\": 10598, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10041592394533572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8995840760546643, \"precision\": 1.0, \"recall\": 0.10041592394533572, \"specificity\": 1.0, \"npv\": 0.39838782924613986, \"accuracy\": 0.43624660886217353, \"f1\": 0.18250539956803455, \"f2\": 0.12244602231560643, \"f0_5\": 0.3582026282323018, \"p4\": 0.2764589013292284, \"phi\": 0.20001120459196223}, {\"truth_threshold\": 30.8, \"match_probability\": 0.9999999994650957, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1180, \"tn\": 7018, \"fp\": 0, \"fn\": 10601, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.10016127663186487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8998387233681351, \"precision\": 1.0, \"recall\": 0.10016127663186487, \"specificity\": 1.0, \"npv\": 0.3983199954594472, \"accuracy\": 0.43608702590563325, \"f1\": 0.1820847156855181, \"f2\": 0.12214309373964889, \"f0_5\": 0.3575540876310527, \"p4\": 0.2759678384984772, \"phi\": 0.19974042969117908}, {\"truth_threshold\": 30.82, \"match_probability\": 0.9999999994724599, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1176, \"tn\": 7018, \"fp\": 0, \"fn\": 10605, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09982174688057041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9001782531194296, \"precision\": 1.0, \"recall\": 0.09982174688057041, \"specificity\": 1.0, \"npv\": 0.3982295863360381, \"accuracy\": 0.43587424863024626, \"f1\": 0.18152350081037277, \"f2\": 0.12173913043478261, \"f0_5\": 0.35668789808917195, \"p4\": 0.275311987631528, \"phi\": 0.1993789682177894}, {\"truth_threshold\": 30.84, \"match_probability\": 0.9999999994797226, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1172, \"tn\": 7018, \"fp\": 0, \"fn\": 10609, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09948221712927595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.900517782870724, \"precision\": 1.0, \"recall\": 0.09948221712927595, \"specificity\": 1.0, \"npv\": 0.3981392182447382, \"accuracy\": 0.4356614713548593, \"f1\": 0.18096193931907667, \"f2\": 0.12133510021533875, \"f0_5\": 0.35582002550245917, \"p4\": 0.2746548751330829, \"phi\": 0.199017014742718}, {\"truth_threshold\": 30.86, \"match_probability\": 0.9999999994868854, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1170, \"tn\": 7018, \"fp\": 0, \"fn\": 10611, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09931245225362872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9006875477463713, \"precision\": 1.0, \"recall\": 0.09931245225362872, \"specificity\": 1.0, \"npv\": 0.39809404957740085, \"accuracy\": 0.4355550827171658, \"f1\": 0.18068102849200834, \"f2\": 0.12113306000745434, \"f0_5\": 0.3553854565336249, \"p4\": 0.2743258444027563, \"phi\": 0.1988358526300258}, {\"truth_threshold\": 30.88, \"match_probability\": 0.9999999994939497, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1169, \"tn\": 7018, \"fp\": 0, \"fn\": 10612, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0992275698158051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9007724301841948, \"precision\": 1.0, \"recall\": 0.0992275698158051, \"specificity\": 1.0, \"npv\": 0.39807146908678387, \"accuracy\": 0.43550188839831905, \"f1\": 0.18054054054054053, \"f2\": 0.12103203362806204, \"f0_5\": 0.35516801361122924, \"p4\": 0.274161210176943, \"phi\": 0.1987452250759473}, {\"truth_threshold\": 30.900000000000002, \"match_probability\": 0.9999999995009166, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1167, \"tn\": 7018, \"fp\": 0, \"fn\": 10614, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09905780494015788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9009421950598421, \"precision\": 1.0, \"recall\": 0.09905780494015788, \"specificity\": 1.0, \"npv\": 0.3980263157894737, \"accuracy\": 0.4353954997606256, \"f1\": 0.18025949953660797, \"f2\": 0.12082996831707772, \"f0_5\": 0.3547328105051979, \"p4\": 0.273831703659748, \"phi\": 0.1985638767513451}, {\"truth_threshold\": 30.92, \"match_probability\": 0.9999999995077876, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1161, \"tn\": 7018, \"fp\": 0, \"fn\": 10620, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0985485103132162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9014514896867838, \"precision\": 1.0, \"recall\": 0.0985485103132162, \"specificity\": 1.0, \"npv\": 0.3978909173375666, \"accuracy\": 0.43507633384754507, \"f1\": 0.17941585535465926, \"f2\": 0.12022367194780988, \"f0_5\": 0.35342465753424657, \"p4\": 0.27284127461064633, \"phi\": 0.1980190828450032}, {\"truth_threshold\": 30.94, \"match_probability\": 0.9999999995145641, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1158, \"tn\": 7018, \"fp\": 0, \"fn\": 10623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09829386299974535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9017061370002546, \"precision\": 1.0, \"recall\": 0.09829386299974535, \"specificity\": 1.0, \"npv\": 0.3978232526500765, \"accuracy\": 0.43491675089100484, \"f1\": 0.17899373985624856, \"f2\": 0.1199204672548776, \"f0_5\": 0.35276914640833484, \"p4\": 0.27234498256315226, \"phi\": 0.19774626240235163}, {\"truth_threshold\": 30.96, \"match_probability\": 0.9999999995212472, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1156, \"tn\": 7018, \"fp\": 0, \"fn\": 10625, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09812409812409813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9018759018759018, \"precision\": 1.0, \"recall\": 0.09812409812409813, \"specificity\": 1.0, \"npv\": 0.39777815564246444, \"accuracy\": 0.4348103622533113, \"f1\": 0.17871222076215507, \"f2\": 0.11971830985915492, \"f0_5\": 0.35233160621761656, \"p4\": 0.2720137208402932, \"phi\": 0.19756422443318009}, {\"truth_threshold\": 30.98, \"match_probability\": 0.9999999995278384, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1152, \"tn\": 7018, \"fp\": 0, \"fn\": 10629, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09778456837280367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9022154316271963, \"precision\": 1.0, \"recall\": 0.09778456837280367, \"specificity\": 1.0, \"npv\": 0.39768799229330765, \"accuracy\": 0.43459758497792433, \"f1\": 0.1781489213639527, \"f2\": 0.11931394481730052, \"f0_5\": 0.3514552443712246, \"p4\": 0.2713502340207881, \"phi\": 0.19719976844166923}, {\"truth_threshold\": 31.0, \"match_probability\": 0.9999999995343387, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1151, \"tn\": 7018, \"fp\": 0, \"fn\": 10630, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09769968593498005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.90230031406502, \"precision\": 1.0, \"recall\": 0.09769968593498005, \"specificity\": 1.0, \"npv\": 0.39766545784224844, \"accuracy\": 0.43454439065907763, \"f1\": 0.1780080420661924, \"f2\": 0.1192128430864837, \"f0_5\": 0.351235886481538, \"p4\": 0.2711841612043683, \"phi\": 0.19710857499961212}, {\"truth_threshold\": 31.02, \"match_probability\": 0.9999999995407496, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1147, \"tn\": 7018, \"fp\": 0, \"fn\": 10634, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0973601561836856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9026398438163145, \"precision\": 1.0, \"recall\": 0.0973601561836856, \"specificity\": 1.0, \"npv\": 0.3975753455699071, \"accuracy\": 0.43433161338369064, \"f1\": 0.17744430693069307, \"f2\": 0.11880839427399474, \"f0_5\": 0.350357382857841, \"p4\": 0.2705190633841773, \"phi\": 0.19674348207620226}, {\"truth_threshold\": 31.04, \"match_probability\": 0.9999999995470722, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1143, \"tn\": 7018, \"fp\": 0, \"fn\": 10638, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09702062643239114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9029793735676088, \"precision\": 1.0, \"recall\": 0.09702062643239114, \"specificity\": 1.0, \"npv\": 0.39748527412777523, \"accuracy\": 0.43411883610830365, \"f1\": 0.17688022284122562, \"f2\": 0.11840387842625397, \"f0_5\": 0.3494771601541002, \"p4\": 0.2698526716908959, \"phi\": 0.19637787628327044}, {\"truth_threshold\": 31.060000000000002, \"match_probability\": 0.9999999995533079, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1139, \"tn\": 7018, \"fp\": 0, \"fn\": 10642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09668109668109669, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9033189033189033, \"precision\": 1.0, \"recall\": 0.09668109668109669, \"specificity\": 1.0, \"npv\": 0.39739524348810873, \"accuracy\": 0.43390605883291666, \"f1\": 0.1763157894736842, \"f2\": 0.11799929552659387, \"f0_5\": 0.3485952133194589, \"p4\": 0.2691849815932376, \"phi\": 0.1960117546380364}, {\"truth_threshold\": 31.080000000000002, \"match_probability\": 0.9999999995594576, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1136, \"tn\": 7018, \"fp\": 0, \"fn\": 10645, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09642644936762584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9035735506323742, \"precision\": 1.0, \"recall\": 0.09642644936762584, \"specificity\": 1.0, \"npv\": 0.39732774726830095, \"accuracy\": 0.4337464758763764, \"f1\": 0.17589223503909576, \"f2\": 0.1176958143389971, \"f0_5\": 0.3479326186830015, \"p4\": 0.2686833592045613, \"phi\": 0.19573682306689166}, {\"truth_threshold\": 31.1, \"match_probability\": 0.9999999995655227, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1131, \"tn\": 7018, \"fp\": 0, \"fn\": 10650, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09600203717850776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039979628214923, \"precision\": 1.0, \"recall\": 0.09600203717850776, \"specificity\": 1.0, \"npv\": 0.39721530450532033, \"accuracy\": 0.4334805042821427, \"f1\": 0.17518587360594795, \"f2\": 0.11718992850481816, \"f0_5\": 0.3468261269549218, \"p4\": 0.26784568795569275, \"phi\": 0.19527795172776688}, {\"truth_threshold\": 31.16, \"match_probability\": 0.9999999995832215, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1129, \"tn\": 7018, \"fp\": 0, \"fn\": 10652, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09583227230286054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9041677276971395, \"precision\": 1.0, \"recall\": 0.09583227230286054, \"specificity\": 1.0, \"npv\": 0.3971703452178834, \"accuracy\": 0.43337411564444916, \"f1\": 0.17490317583268783, \"f2\": 0.11698754481586637, \"f0_5\": 0.34638276983493893, \"p4\": 0.26751004590566735, \"phi\": 0.19509417385852743}, {\"truth_threshold\": 31.18, \"match_probability\": 0.9999999995889594, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1127, \"tn\": 7018, \"fp\": 0, \"fn\": 10654, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09566250742721331, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9043374925727867, \"precision\": 1.0, \"recall\": 0.09566250742721331, \"specificity\": 1.0, \"npv\": 0.39712539610683567, \"accuracy\": 0.4332677270067557, \"f1\": 0.17462039045553146, \"f2\": 0.11678514434933991, \"f0_5\": 0.34593897722389344, \"p4\": 0.2671740752489229, \"phi\": 0.19491026436441256}, {\"truth_threshold\": 31.2, \"match_probability\": 0.9999999995946183, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1123, \"tn\": 7018, \"fp\": 0, \"fn\": 10658, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09532297767591885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9046770223240811, \"precision\": 1.0, \"recall\": 0.09532297767591885, \"specificity\": 1.0, \"npv\": 0.39703552840009054, \"accuracy\": 0.4330549497313687, \"f1\": 0.1740545567265964, \"f2\": 0.1163802930752171, \"f0_5\": 0.34505008295950346, \"p4\": 0.2665011458037683, \"phi\": 0.19454204895145027}, {\"truth_threshold\": 31.220000000000002, \"match_probability\": 0.9999999996001994, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1119, \"tn\": 7018, \"fp\": 0, \"fn\": 10662, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09498344792462439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9050165520753756, \"precision\": 1.0, \"recall\": 0.09498344792462439, \"specificity\": 1.0, \"npv\": 0.39694570135746604, \"accuracy\": 0.4328421724559817, \"f1\": 0.17348837209302326, \"f2\": 0.11597537466575462, \"f0_5\": 0.34415943901088764, \"p4\": 0.26582689498390877, \"phi\": 0.1941733023713363}, {\"truth_threshold\": 31.240000000000002, \"match_probability\": 0.9999999996057035, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1115, \"tn\": 7018, \"fp\": 0, \"fn\": 10666, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09464391817332994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.90535608182667, \"precision\": 1.0, \"recall\": 0.09464391817332994, \"specificity\": 1.0, \"npv\": 0.39685591495136846, \"accuracy\": 0.43262939518059473, \"f1\": 0.17292183622828783, \"f2\": 0.11557038910425174, \"f0_5\": 0.3432670402068838, \"p4\": 0.26515131813165244, \"phi\": 0.19380402147855266}, {\"truth_threshold\": 31.26, \"match_probability\": 0.9999999996111318, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1113, \"tn\": 7018, \"fp\": 0, \"fn\": 10668, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0944741532976827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9055258467023173, \"precision\": 1.0, \"recall\": 0.0944741532976827, \"specificity\": 1.0, \"npv\": 0.396811036978401, \"accuracy\": 0.4325230065429012, \"f1\": 0.17263843648208468, \"f2\": 0.11536787113626469, \"f0_5\": 0.3428201811125485, \"p4\": 0.2648130309819727, \"phi\": 0.19361917967419934}, {\"truth_threshold\": 31.3, \"match_probability\": 0.9999999996217656, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1109, \"tn\": 7018, \"fp\": 0, \"fn\": 10672, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09413462354638825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9058653764536118, \"precision\": 1.0, \"recall\": 0.09413462354638825, \"specificity\": 1.0, \"npv\": 0.39672131147540984, \"accuracy\": 0.4323102292675142, \"f1\": 0.1720713731574864, \"f2\": 0.11496278481537536, \"f0_5\": 0.34192514028488624, \"p4\": 0.264135456300895, \"phi\": 0.19324909135250065}, {\"truth_threshold\": 31.32, \"match_probability\": 0.9999999996269727, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1106, \"tn\": 7018, \"fp\": 0, \"fn\": 10675, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09387997623291741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9061200237670826, \"precision\": 1.0, \"recall\": 0.09387997623291741, \"specificity\": 1.0, \"npv\": 0.3966540439721924, \"accuracy\": 0.432150646310974, \"f1\": 0.17164584464964694, \"f2\": 0.11465892597968069, \"f0_5\": 0.3412526997840173, \"p4\": 0.26362639763639595, \"phi\": 0.19297116940310022}, {\"truth_threshold\": 31.34, \"match_probability\": 0.9999999996321084, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1102, \"tn\": 7018, \"fp\": 0, \"fn\": 10679, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09354044648162295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.906459553518377, \"precision\": 1.0, \"recall\": 0.09354044648162295, \"specificity\": 1.0, \"npv\": 0.39656438944453865, \"accuracy\": 0.431937869035587, \"f1\": 0.17107816502367462, \"f2\": 0.11425372205864057, \"f0_5\": 0.3403545617394527, \"p4\": 0.26294647875103283, \"phi\": 0.19260012992559053}, {\"truth_threshold\": 31.36, \"match_probability\": 0.9999999996371732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1099, \"tn\": 7018, \"fp\": 0, \"fn\": 10682, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0932857991681521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9067142008318478, \"precision\": 1.0, \"recall\": 0.0932857991681521, \"specificity\": 1.0, \"npv\": 0.39649717514124294, \"accuracy\": 0.4317782860790468, \"f1\": 0.17065217391304346, \"f2\": 0.11394977500362898, \"f0_5\": 0.3396797922977066, \"p4\": 0.26243565648988326, \"phi\": 0.19232149087131586}, {\"truth_threshold\": 31.38, \"match_probability\": 0.9999999996421683, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1098, \"tn\": 7018, \"fp\": 0, \"fn\": 10683, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0932009167303285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9067990832696715, \"precision\": 1.0, \"recall\": 0.0932009167303285, \"specificity\": 1.0, \"npv\": 0.396474775436416, \"accuracy\": 0.4317250917602, \"f1\": 0.17051013277428373, \"f2\": 0.11384845091452034, \"f0_5\": 0.3394546466332777, \"p4\": 0.26226521379677076, \"phi\": 0.19222854244655008}, {\"truth_threshold\": 31.400000000000002, \"match_probability\": 0.9999999996470947, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1097, \"tn\": 7018, \"fp\": 0, \"fn\": 10684, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09311603429250488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9068839657074951, \"precision\": 1.0, \"recall\": 0.09311603429250488, \"specificity\": 1.0, \"npv\": 0.39645237826234325, \"accuracy\": 0.43167189744135326, \"f1\": 0.17036806957602113, \"f2\": 0.11374712262292362, \"f0_5\": 0.339229389572639, \"p4\": 0.26209468667621416, \"phi\": 0.1921355595656917}, {\"truth_threshold\": 31.42, \"match_probability\": 0.9999999996519533, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1095, \"tn\": 7018, \"fp\": 0, \"fn\": 10686, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09294626941685766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9070537305831423, \"precision\": 1.0, \"recall\": 0.09294626941685766, \"specificity\": 1.0, \"npv\": 0.3964075915047447, \"accuracy\": 0.4315655088036598, \"f1\": 0.1700838769804287, \"f2\": 0.11354445343122006, \"f0_5\": 0.33877854093187304, \"p4\": 0.26175337885357197, \"phi\": 0.1919494902282568}, {\"truth_threshold\": 31.44, \"match_probability\": 0.9999999996567449, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1094, \"tn\": 7018, \"fp\": 0, \"fn\": 10687, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09286138697903404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.907138613020966, \"precision\": 1.0, \"recall\": 0.09286138697903404, \"specificity\": 1.0, \"npv\": 0.3963852019203615, \"accuracy\": 0.43151231448481303, \"f1\": 0.16994174757281552, \"f2\": 0.11344311253059024, \"f0_5\": 0.3385529491861113, \"p4\": 0.2615825980016714, \"phi\": 0.19185640366766296}, {\"truth_threshold\": 31.46, \"match_probability\": 0.9999999996614707, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1091, \"tn\": 7018, \"fp\": 0, \"fn\": 10690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0926067396655632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9073932603344368, \"precision\": 1.0, \"recall\": 0.0926067396655632, \"specificity\": 1.0, \"npv\": 0.39631804833973344, \"accuracy\": 0.4313527315282728, \"f1\": 0.16951522684897452, \"f2\": 0.11313906460645028, \"f0_5\": 0.33787550325178073, \"p4\": 0.26106974678293554, \"phi\": 0.1915769357917643}, {\"truth_threshold\": 31.48, \"match_probability\": 0.9999999996661313, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1089, \"tn\": 7018, \"fp\": 0, \"fn\": 10692, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09243697478991597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.907563025210084, \"precision\": 1.0, \"recall\": 0.09243697478991597, \"specificity\": 1.0, \"npv\": 0.39627329192546584, \"accuracy\": 0.4312463428905793, \"f1\": 0.16923076923076924, \"f2\": 0.11293634496919917, \"f0_5\": 0.3374233128834356, \"p4\": 0.2607274213322436, \"phi\": 0.19139044985482243}, {\"truth_threshold\": 31.5, \"match_probability\": 0.9999999996707277, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1084, \"tn\": 7018, \"fp\": 0, \"fn\": 10697, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09201256260079789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9079874373992021, \"precision\": 1.0, \"recall\": 0.09201256260079789, \"specificity\": 1.0, \"npv\": 0.39616144510302004, \"accuracy\": 0.43098037129634553, \"f1\": 0.16851923824329576, \"f2\": 0.11242947228675738, \"f0_5\": 0.3362908729912515, \"p4\": 0.2598701170691254, \"phi\": 0.1909236228641291}, {\"truth_threshold\": 31.52, \"match_probability\": 0.999999999675261, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1079, \"tn\": 7018, \"fp\": 0, \"fn\": 10702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09158815041167982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9084118495883202, \"precision\": 1.0, \"recall\": 0.09158815041167982, \"specificity\": 1.0, \"npv\": 0.39604966139954856, \"accuracy\": 0.43071439970211184, \"f1\": 0.16780715396578538, \"f2\": 0.11192249445055287, \"f0_5\": 0.33515561905945207, \"p4\": 0.2590106757450345, \"phi\": 0.19045591605081927}, {\"truth_threshold\": 31.54, \"match_probability\": 0.9999999996797317, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1078, \"tn\": 7018, \"fp\": 0, \"fn\": 10703, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0915032679738562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9084967320261438, \"precision\": 1.0, \"recall\": 0.0915032679738562, \"specificity\": 1.0, \"npv\": 0.3960273122284296, \"accuracy\": 0.4306612053832651, \"f1\": 0.16766467065868262, \"f2\": 0.11182108626198083, \"f0_5\": 0.3349282296650718, \"p4\": 0.2588385301958966, \"phi\": 0.19036226851927357}, {\"truth_threshold\": 31.580000000000002, \"match_probability\": 0.9999999996884895, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1075, \"tn\": 7018, \"fp\": 0, \"fn\": 10706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09124862066038536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9087513793396146, \"precision\": 1.0, \"recall\": 0.09124862066038536, \"specificity\": 1.0, \"npv\": 0.39596027984653576, \"accuracy\": 0.43050162242672485, \"f1\": 0.16723708774113255, \"f2\": 0.11151683644888898, \"f0_5\": 0.334245382749829, \"p4\": 0.25832157760461305, \"phi\": 0.1900811126132646}, {\"truth_threshold\": 31.6, \"match_probability\": 0.9999999996927781, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1074, \"tn\": 7018, \"fp\": 0, \"fn\": 10707, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09116373822256175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9088362617774383, \"precision\": 1.0, \"recall\": 0.09116373822256175, \"specificity\": 1.0, \"npv\": 0.39593794076163613, \"accuracy\": 0.4304484281078781, \"f1\": 0.16709451575262543, \"f2\": 0.11141541142786007, \"f0_5\": 0.3340175405859302, \"p4\": 0.2581490878374803, \"phi\": 0.18998732269278906}, {\"truth_threshold\": 31.62, \"match_probability\": 0.9999999996970077, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1072, \"tn\": 7018, \"fp\": 0, \"fn\": 10709, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09099397334691452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9090060266530855, \"precision\": 1.0, \"recall\": 0.09099397334691452, \"specificity\": 1.0, \"npv\": 0.3958932701528741, \"accuracy\": 0.43034203947018457, \"f1\": 0.16680930522057108, \"f2\": 0.11121254875923313, \"f0_5\": 0.3335615159624121, \"p4\": 0.2578038494874718, \"phi\": 0.18979963559636637}, {\"truth_threshold\": 31.64, \"match_probability\": 0.9999999997011791, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1069, \"tn\": 7018, \"fp\": 0, \"fn\": 10712, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09073932603344369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9092606739665563, \"precision\": 1.0, \"recall\": 0.09073932603344369, \"specificity\": 1.0, \"npv\": 0.3958262831359278, \"accuracy\": 0.43018245651364434, \"f1\": 0.16638132295719843, \"f2\": 0.11090822318593986, \"f0_5\": 0.3328766270162546, \"p4\": 0.2572853437683604, \"phi\": 0.1895178359893262}, {\"truth_threshold\": 31.66, \"match_probability\": 0.9999999997052931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1067, \"tn\": 7018, \"fp\": 0, \"fn\": 10714, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09056956115779645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9094304388422035, \"precision\": 1.0, \"recall\": 0.09056956115779645, \"specificity\": 1.0, \"npv\": 0.3957816377171216, \"accuracy\": 0.4300760678759509, \"f1\": 0.1660958904109589, \"f2\": 0.11070531842045195, \"f0_5\": 0.33241946538725153, \"p4\": 0.25693924025932235, \"phi\": 0.18932978963267685}, {\"truth_threshold\": 31.68, \"match_probability\": 0.9999999997093504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1061, \"tn\": 7018, \"fp\": 0, \"fn\": 10720, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.09006026653085476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9099397334691453, \"precision\": 1.0, \"recall\": 0.09006026653085476, \"specificity\": 1.0, \"npv\": 0.3956477618671778, \"accuracy\": 0.42975690196287036, \"f1\": 0.16523905933655195, \"f2\": 0.11009650306111861, \"f0_5\": 0.3310452418096724, \"p4\": 0.255898844373829, \"phi\": 0.18876478190089957}, {\"truth_threshold\": 31.7, \"match_probability\": 0.9999999997133519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1060, \"tn\": 7018, \"fp\": 0, \"fn\": 10721, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08997538409303116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9100246159069688, \"precision\": 1.0, \"recall\": 0.08997538409303116, \"specificity\": 1.0, \"npv\": 0.39562545803032867, \"accuracy\": 0.4297037076440236, \"f1\": 0.16509617631025622, \"f2\": 0.10999501909347502, \"f0_5\": 0.3308158042569128, \"p4\": 0.255725140128668, \"phi\": 0.18867048667785905}, {\"truth_threshold\": 31.720000000000002, \"match_probability\": 0.9999999997172982, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1059, \"tn\": 7018, \"fp\": 0, \"fn\": 10722, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08989050165520754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9101094983447925, \"precision\": 1.0, \"recall\": 0.08989050165520754, \"specificity\": 1.0, \"npv\": 0.3956031567080045, \"accuracy\": 0.4296505133251769, \"f1\": 0.1649532710280374, \"f2\": 0.10989353091339268, \"f0_5\": 0.33058625210713616, \"p4\": 0.25555134855250644, \"phi\": 0.1885761549424163}, {\"truth_threshold\": 31.740000000000002, \"match_probability\": 0.9999999997211902, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1055, \"tn\": 7018, \"fp\": 0, \"fn\": 10726, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08955097190391308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.910449028096087, \"precision\": 1.0, \"recall\": 0.08955097190391308, \"specificity\": 1.0, \"npv\": 0.39551397655545534, \"accuracy\": 0.4294377360497899, \"f1\": 0.16438142723589905, \"f2\": 0.10948753606343012, \"f0_5\": 0.3296668958190113, \"p4\": 0.25485530737324696, \"phi\": 0.1881984617421793}, {\"truth_threshold\": 31.76, \"match_probability\": 0.9999999997250287, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1047, \"tn\": 7018, \"fp\": 0, \"fn\": 10734, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08887191240132417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9111280875986758, \"precision\": 1.0, \"recall\": 0.08887191240132417, \"specificity\": 1.0, \"npv\": 0.3953357368183867, \"accuracy\": 0.42901218149901593, \"f1\": 0.16323666978484566, \"f2\": 0.10867534408669116, \"f0_5\": 0.3278226563967687, \"p4\": 0.25345900927771514, \"phi\": 0.18744130540421608}, {\"truth_threshold\": 31.78, \"match_probability\": 0.9999999997288144, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1041, \"tn\": 7018, \"fp\": 0, \"fn\": 10740, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08836261777438248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9116373822256175, \"precision\": 1.0, \"recall\": 0.08836261777438248, \"specificity\": 1.0, \"npv\": 0.3952021624056763, \"accuracy\": 0.4286930155859354, \"f1\": 0.16237716424894713, \"f2\": 0.10806602304578013, \"f0_5\": 0.3264346190028222, \"p4\": 0.25240807703027274, \"phi\": 0.18687187487758075}, {\"truth_threshold\": 31.8, \"match_probability\": 0.9999999997325478, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1037, \"tn\": 7018, \"fp\": 0, \"fn\": 10744, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08802308802308802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.911976911976912, \"precision\": 1.0, \"recall\": 0.08802308802308802, \"specificity\": 1.0, \"npv\": 0.39511316293210225, \"accuracy\": 0.42848023831054843, \"f1\": 0.16180371352785147, \"f2\": 0.107659724673491, \"f0_5\": 0.3255069370330843, \"p4\": 0.2517056799554089, \"phi\": 0.18649150307682427}, {\"truth_threshold\": 31.82, \"match_probability\": 0.9999999997362299, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1033, \"tn\": 7018, \"fp\": 0, \"fn\": 10748, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08768355827179357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9123164417282065, \"precision\": 1.0, \"recall\": 0.08768355827179357, \"specificity\": 1.0, \"npv\": 0.39502420353484186, \"accuracy\": 0.42826746103516145, \"f1\": 0.16122990479163415, \"f2\": 0.10725335880557343, \"f0_5\": 0.3245773895557092, \"p4\": 0.2510018564444493, \"phi\": 0.18611052568142442}, {\"truth_threshold\": 31.84, \"match_probability\": 0.9999999997398613, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1030, \"tn\": 7018, \"fp\": 0, \"fn\": 10751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08742891095832273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9125710890416773, \"precision\": 1.0, \"recall\": 0.08742891095832273, \"specificity\": 1.0, \"npv\": 0.39495751027069614, \"accuracy\": 0.4281078780786212, \"f1\": 0.160799313090313, \"f2\": 0.10694854010051086, \"f0_5\": 0.32387900132067166, \"p4\": 0.2504730496162934, \"phi\": 0.18582439290302424}, {\"truth_threshold\": 31.86, \"match_probability\": 0.9999999997434427, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1027, \"tn\": 7018, \"fp\": 0, \"fn\": 10754, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08717426364485188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9128257363551481, \"precision\": 1.0, \"recall\": 0.08717426364485188, \"specificity\": 1.0, \"npv\": 0.3948908395228449, \"accuracy\": 0.42794829512208094, \"f1\": 0.160368519675203, \"f2\": 0.10664368341259788, \"f0_5\": 0.3231795581849078, \"p4\": 0.24994343534125893, \"phi\": 0.1855379156816778}, {\"truth_threshold\": 31.88, \"match_probability\": 0.9999999997469748, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1022, \"tn\": 7018, \"fp\": 0, \"fn\": 10759, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08674985145573381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9132501485442662, \"precision\": 1.0, \"recall\": 0.08674985145573381, \"specificity\": 1.0, \"npv\": 0.39477977161500816, \"accuracy\": 0.42768232352784724, \"f1\": 0.15965008201202843, \"f2\": 0.10613550450712417, \"f0_5\": 0.3220114689016321, \"p4\": 0.2490589446081403, \"phi\": 0.18505968373832934}, {\"truth_threshold\": 31.900000000000002, \"match_probability\": 0.9999999997504583, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1020, \"tn\": 7018, \"fp\": 0, \"fn\": 10761, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08658008658008658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9134199134199135, \"precision\": 1.0, \"recall\": 0.08658008658008658, \"specificity\": 1.0, \"npv\": 0.3947353619438664, \"accuracy\": 0.4275759348901537, \"f1\": 0.1593625498007968, \"f2\": 0.1059322033898305, \"f0_5\": 0.3215434083601286, \"p4\": 0.2487045163187975, \"phi\": 0.18486812005676306}, {\"truth_threshold\": 31.92, \"match_probability\": 0.9999999997538939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1017, \"tn\": 7018, \"fp\": 0, \"fn\": 10764, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08632543926661573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9136745607333843, \"precision\": 1.0, \"recall\": 0.08632543926661573, \"specificity\": 1.0, \"npv\": 0.3946687661680351, \"accuracy\": 0.4274163519336135, \"f1\": 0.1589310829817159, \"f2\": 0.10562722004112918, \"f0_5\": 0.32084043157296993, \"p4\": 0.2481721947026114, \"phi\": 0.1845804827284534}, {\"truth_threshold\": 31.94, \"match_probability\": 0.999999999757282, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1015, \"tn\": 7018, \"fp\": 0, \"fn\": 10766, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08615567439096851, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9138443256090315, \"precision\": 1.0, \"recall\": 0.08615567439096851, \"specificity\": 1.0, \"npv\": 0.3946243814664867, \"accuracy\": 0.42730996329591997, \"f1\": 0.1586433260393873, \"f2\": 0.10542387669041733, \"f0_5\": 0.32037118868758285, \"p4\": 0.24781685988001115, \"phi\": 0.18438852924291135}, {\"truth_threshold\": 31.96, \"match_probability\": 0.9999999997606236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1011, \"tn\": 7018, \"fp\": 0, \"fn\": 10770, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08581614463967405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.914183855360326, \"precision\": 1.0, \"recall\": 0.08581614463967405, \"specificity\": 1.0, \"npv\": 0.3945356420058466, \"accuracy\": 0.427097186020533, \"f1\": 0.15806754221388367, \"f2\": 0.10501713929573075, \"f0_5\": 0.3194312796208531, \"p4\": 0.24710509828370186, \"phi\": 0.18400415136588738}, {\"truth_threshold\": 31.98, \"match_probability\": 0.9999999997639192, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1010, \"tn\": 7018, \"fp\": 0, \"fn\": 10771, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08573126220185044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9142687377981495, \"precision\": 1.0, \"recall\": 0.08573126220185044, \"specificity\": 1.0, \"npv\": 0.39451346337624377, \"accuracy\": 0.4270439917016863, \"f1\": 0.1579235399890548, \"f2\": 0.1049154443844268, \"f0_5\": 0.3191960053093989, \"p4\": 0.2469269299133057, \"phi\": 0.18390795842178465}, {\"truth_threshold\": 32.0, \"match_probability\": 0.9999999997671694, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1008, \"tn\": 7018, \"fp\": 0, \"fn\": 10773, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0855614973262032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9144385026737968, \"precision\": 1.0, \"recall\": 0.0855614973262032, \"specificity\": 1.0, \"npv\": 0.3944691135967624, \"accuracy\": 0.42693760306399275, \"f1\": 0.15763546798029557, \"f2\": 0.10471204188481675, \"f0_5\": 0.3187250996015936, \"p4\": 0.2465703190275791, \"phi\": 0.183715453917952}, {\"truth_threshold\": 32.02, \"match_probability\": 0.9999999997703748, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1006, \"tn\": 7018, \"fp\": 0, \"fn\": 10775, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08539173245055598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.914608267549444, \"precision\": 1.0, \"recall\": 0.08539173245055598, \"specificity\": 1.0, \"npv\": 0.3944247737874445, \"accuracy\": 0.4268312144262993, \"f1\": 0.15734730585751153, \"f2\": 0.10450862248078122, \"f0_5\": 0.3182537171781082, \"p4\": 0.2462133420620324, \"phi\": 0.18352279083298764}, {\"truth_threshold\": 32.04, \"match_probability\": 0.9999999997735362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1005, \"tn\": 7018, \"fp\": 0, \"fn\": 10776, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08530685001273236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9146931499872676, \"precision\": 1.0, \"recall\": 0.08530685001273236, \"specificity\": 1.0, \"npv\": 0.39440260762054624, \"accuracy\": 0.4267780201074525, \"f1\": 0.15720319099014546, \"f2\": 0.10440690643894533, \"f0_5\": 0.31801784697171065, \"p4\": 0.2460347160914907, \"phi\": 0.18342639966187113}, {\"truth_threshold\": 32.06, \"match_probability\": 0.9999999997766539, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1001, \"tn\": 7018, \"fp\": 0, \"fn\": 10780, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08496732026143791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9150326797385621, \"precision\": 1.0, \"recall\": 0.08496732026143791, \"specificity\": 1.0, \"npv\": 0.3943139678615575, \"accuracy\": 0.42656524283206554, \"f1\": 0.1566265060240964, \"f2\": 0.104, \"f0_5\": 0.3170731707317073, \"p4\": 0.24531929367919786, \"phi\": 0.18304043594476954}, {\"truth_threshold\": 32.08, \"match_probability\": 0.9999999997797288, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 1000, \"tn\": 7018, \"fp\": 0, \"fn\": 10781, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08488243782361429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9151175621763857, \"precision\": 1.0, \"recall\": 0.08488243782361429, \"specificity\": 1.0, \"npv\": 0.3942918141468622, \"accuracy\": 0.4265120485132188, \"f1\": 0.15648227838197323, \"f2\": 0.10389826282104563, \"f0_5\": 0.3168367023636018, \"p4\": 0.24514020802581288, \"phi\": 0.182943844932485}, {\"truth_threshold\": 32.1, \"match_probability\": 0.9999999997827613, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 995, \"tn\": 7018, \"fp\": 0, \"fn\": 10786, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08445802563449623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9155419743655038, \"precision\": 1.0, \"recall\": 0.08445802563449623, \"specificity\": 1.0, \"npv\": 0.39418108290271847, \"accuracy\": 0.42624607691898503, \"f1\": 0.1557608015028178, \"f2\": 0.10338951349778673, \"f0_5\": 0.31565256011674386, \"p4\": 0.24424339526549604, \"phi\": 0.18246028610202078}, {\"truth_threshold\": 32.12, \"match_probability\": 0.9999999997857522, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 992, \"tn\": 7018, \"fp\": 0, \"fn\": 10789, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08420337832102538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9157966216789746, \"precision\": 1.0, \"recall\": 0.08420337832102538, \"specificity\": 1.0, \"npv\": 0.3941146740046049, \"accuracy\": 0.4260864939624448, \"f1\": 0.15532764424958898, \"f2\": 0.10308421315155042, \"f0_5\": 0.3149406311511842, \"p4\": 0.24370419698497509, \"phi\": 0.18216966541407859}, {\"truth_threshold\": 32.160000000000004, \"match_probability\": 0.9999999997916107, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 989, \"tn\": 7018, \"fp\": 0, \"fn\": 10792, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08394873100755454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9160512689924455, \"precision\": 1.0, \"recall\": 0.08394873100755454, \"specificity\": 1.0, \"npv\": 0.39404828747894444, \"accuracy\": 0.4259269110059046, \"f1\": 0.154894283476899, \"f2\": 0.10277887473240081, \"f0_5\": 0.31422761644531993, \"p4\": 0.24316416294909052, \"phi\": 0.18187867849079348}, {\"truth_threshold\": 32.18, \"match_probability\": 0.9999999997944797, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 988, \"tn\": 7018, \"fp\": 0, \"fn\": 10793, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08386384856973092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.916136151430269, \"precision\": 1.0, \"recall\": 0.08386384856973092, \"specificity\": 1.0, \"npv\": 0.39402616360675985, \"accuracy\": 0.4258737166870578, \"f1\": 0.15474978463466207, \"f2\": 0.10267708679747256, \"f0_5\": 0.31398970317167735, \"p4\": 0.24298396548482917, \"phi\": 0.18178160115157235}, {\"truth_threshold\": 32.2, \"match_probability\": 0.9999999997973091, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 986, \"tn\": 7018, \"fp\": 0, \"fn\": 10795, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0836940836940837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9163059163059163, \"precision\": 1.0, \"recall\": 0.0836940836940837, \"specificity\": 1.0, \"npv\": 0.39398192331443327, \"accuracy\": 0.42576732804936435, \"f1\": 0.15446071904127828, \"f2\": 0.10247349823321555, \"f0_5\": 0.31351351351351353, \"p4\": 0.2426232908679193, \"phi\": 0.18158732352186438}, {\"truth_threshold\": 32.22, \"match_probability\": 0.9999999998000997, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 985, \"tn\": 7018, \"fp\": 0, \"fn\": 10796, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08360920125626008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91639079874374, \"precision\": 1.0, \"recall\": 0.08360920125626008, \"specificity\": 1.0, \"npv\": 0.3939598068934546, \"accuracy\": 0.4257141337305176, \"f1\": 0.1543161522794924, \"f2\": 0.10237169760335904, \"f0_5\": 0.3132752369442147, \"p4\": 0.2424428135449354, \"phi\": 0.1814901230960853}, {\"truth_threshold\": 32.24, \"match_probability\": 0.9999999998028517, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 977, \"tn\": 7018, \"fp\": 0, \"fn\": 10804, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08293014175367117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9170698582463288, \"precision\": 1.0, \"recall\": 0.08293014175367117, \"specificity\": 1.0, \"npv\": 0.39378296487487374, \"accuracy\": 0.4252885791797436, \"f1\": 0.15315880232011286, \"f2\": 0.10155714018419576, \"f0_5\": 0.3113646503919944, \"p4\": 0.24099562332974273, \"phi\": 0.18071103202974131}, {\"truth_threshold\": 32.26, \"match_probability\": 0.999999999805566, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 976, \"tn\": 7018, \"fp\": 0, \"fn\": 10805, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08284525931584755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9171547406841525, \"precision\": 1.0, \"recall\": 0.08284525931584755, \"specificity\": 1.0, \"npv\": 0.3937608707849408, \"accuracy\": 0.42523538486089685, \"f1\": 0.153014031512111, \"f2\": 0.10145530145530146, \"f0_5\": 0.31112527892891295, \"p4\": 0.24081430181219268, \"phi\": 0.18061345865857384}, {\"truth_threshold\": 32.3, \"match_probability\": 0.9999999998108827, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 975, \"tn\": 7018, \"fp\": 0, \"fn\": 10806, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08276037687802394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917239623121976, \"precision\": 1.0, \"recall\": 0.08276037687802394, \"specificity\": 1.0, \"npv\": 0.39373877917414724, \"accuracy\": 0.4251821905420501, \"f1\": 0.1528692380056444, \"f2\": 0.10135345849186053, \"f0_5\": 0.31088578534532235, \"p4\": 0.24063288606538988, \"phi\": 0.18051584350395802}, {\"truth_threshold\": 32.32, \"match_probability\": 0.9999999998134864, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 974, \"tn\": 7018, \"fp\": 0, \"fn\": 10807, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08267549444020032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9173245055597997, \"precision\": 1.0, \"recall\": 0.08267549444020032, \"specificity\": 1.0, \"npv\": 0.3937166900420757, \"accuracy\": 0.4251289962232034, \"f1\": 0.15272442179537438, \"f2\": 0.10125161129360888, \"f0_5\": 0.3106461695477451, \"p4\": 0.2404513760029841, \"phi\": 0.180418186496228}, {\"truth_threshold\": 32.36, \"match_probability\": 0.9999999998185866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 972, \"tn\": 7018, \"fp\": 0, \"fn\": 10809, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0825057295645531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917494270435447, \"precision\": 1.0, \"recall\": 0.0825057295645531, \"specificity\": 1.0, \"npv\": 0.39367251921243057, \"accuracy\": 0.42502260758550986, \"f1\": 0.1524347212420607, \"f2\": 0.10104790419161677, \"f0_5\": 0.31016657093624356, \"p4\": 0.24008807258544385, \"phi\": 0.18022274664186294}, {\"truth_threshold\": 32.38, \"match_probability\": 0.9999999998210842, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 970, \"tn\": 7018, \"fp\": 0, \"fn\": 10811, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08233596468890586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9176640353110941, \"precision\": 1.0, \"recall\": 0.08233596468890586, \"specificity\": 1.0, \"npv\": 0.39362835829266923, \"accuracy\": 0.4249162189478164, \"f1\": 0.1521449298094267, \"f2\": 0.1008441801472117, \"f0_5\": 0.3096864823446779, \"p4\": 0.23972439086669178, \"phi\": 0.18002713853454763}, {\"truth_threshold\": 32.4, \"match_probability\": 0.9999999998235474, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 966, \"tn\": 7018, \"fp\": 0, \"fn\": 10815, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08199643493761141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9180035650623886, \"precision\": 1.0, \"recall\": 0.08199643493761141, \"specificity\": 1.0, \"npv\": 0.39354006616946113, \"accuracy\": 0.4247034416724294, \"f1\": 0.1515650741350906, \"f2\": 0.10043668122270742, \"f0_5\": 0.3087248322147651, \"p4\": 0.23899588974568542, \"phi\": 0.17963541530279464}, {\"truth_threshold\": 32.44, \"match_probability\": 0.9999999998283725, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 963, \"tn\": 7018, \"fp\": 0, \"fn\": 10818, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08174178762414057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9182582123758595, \"precision\": 1.0, \"recall\": 0.08174178762414057, \"specificity\": 1.0, \"npv\": 0.3934738730657098, \"accuracy\": 0.4245438587158891, \"f1\": 0.15112994350282485, \"f2\": 0.10013101253977166, \"f0_5\": 0.3080023028209557, \"p4\": 0.238448515686362, \"phi\": 0.1793411770001114}, {\"truth_threshold\": 32.46, \"match_probability\": 0.9999999998307353, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 957, \"tn\": 7018, \"fp\": 0, \"fn\": 10824, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08123249299719888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9187675070028011, \"precision\": 1.0, \"recall\": 0.08123249299719888, \"specificity\": 1.0, \"npv\": 0.3933415536374846, \"accuracy\": 0.42422469280280867, \"f1\": 0.15025906735751296, \"f2\": 0.09951956074124914, \"f0_5\": 0.30655391120507397, \"p4\": 0.23735119047619047, \"phi\": 0.17875154545168076}, {\"truth_threshold\": 32.480000000000004, \"match_probability\": 0.9999999998330656, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 953, \"tn\": 7018, \"fp\": 0, \"fn\": 10828, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08089296324590442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9191070367540956, \"precision\": 1.0, \"recall\": 0.08089296324590442, \"specificity\": 1.0, \"npv\": 0.39325339011543203, \"accuracy\": 0.4240119155274217, \"f1\": 0.14967802732841212, \"f2\": 0.09911184142105373, \"f0_5\": 0.3055858397999102, \"p4\": 0.2366177237524089, \"phi\": 0.17835759594963976}, {\"truth_threshold\": 32.5, \"match_probability\": 0.9999999998353639, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 949, \"tn\": 7018, \"fp\": 0, \"fn\": 10832, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08055343349460997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91944656650539, \"precision\": 1.0, \"recall\": 0.08055343349460997, \"specificity\": 1.0, \"npv\": 0.3931652661064426, \"accuracy\": 0.4237991382520347, \"f1\": 0.1490966221523959, \"f2\": 0.09870405425082687, \"f0_5\": 0.3046157796751621, \"p4\": 0.2358827171569413, \"phi\": 0.17796295152558003}, {\"truth_threshold\": 32.52, \"match_probability\": 0.9999999998376304, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 947, \"tn\": 7018, \"fp\": 0, \"fn\": 10834, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08038366861896273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9196163313810373, \"precision\": 1.0, \"recall\": 0.08038366861896273, \"specificity\": 1.0, \"npv\": 0.3931212189110464, \"accuracy\": 0.42369274961434117, \"f1\": 0.14880578252671275, \"f2\": 0.0985001352166587, \"f0_5\": 0.30413000192690604, \"p4\": 0.2355146346296217, \"phi\": 0.17776536723453265}, {\"truth_threshold\": 32.54, \"match_probability\": 0.9999999998398659, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 945, \"tn\": 7018, \"fp\": 0, \"fn\": 10836, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.08021390374331551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9197860962566845, \"precision\": 1.0, \"recall\": 0.08021390374331551, \"specificity\": 1.0, \"npv\": 0.39307718158395877, \"accuracy\": 0.4235863609766477, \"f1\": 0.1485148514851485, \"f2\": 0.0982961992136304, \"f0_5\": 0.30364372469635625, \"p4\": 0.23514616499768806, \"phi\": 0.1775676074267754}, {\"truth_threshold\": 32.58, \"match_probability\": 0.9999999998442447, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 942, \"tn\": 7018, \"fp\": 0, \"fn\": 10839, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07995925642984467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9200407435701553, \"precision\": 1.0, \"recall\": 0.07995925642984467, \"specificity\": 1.0, \"npv\": 0.3930111440891527, \"accuracy\": 0.4234267780201075, \"f1\": 0.1480782834237208, \"f2\": 0.09799026338784171, \"f0_5\": 0.30291337063476753, \"p4\": 0.23459273316227927, \"phi\": 0.17727063730356246}, {\"truth_threshold\": 32.6, \"match_probability\": 0.9999999998463891, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 937, \"tn\": 7018, \"fp\": 0, \"fn\": 10844, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0795348442407266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9204651557592735, \"precision\": 1.0, \"recall\": 0.0795348442407266, \"specificity\": 1.0, \"npv\": 0.39290113089239725, \"accuracy\": 0.4231608064258737, \"f1\": 0.14735021229753106, \"f2\": 0.09748028547054785, \"f0_5\": 0.30169360551226737, \"p4\": 0.2336684010810795, \"phi\": 0.17677480094043987}, {\"truth_threshold\": 32.62, \"match_probability\": 0.9999999998485039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 934, \"tn\": 7018, \"fp\": 0, \"fn\": 10847, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07928019692725576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9207198030727443, \"precision\": 1.0, \"recall\": 0.07928019692725576, \"specificity\": 1.0, \"npv\": 0.39283515253288553, \"accuracy\": 0.4230012234693335, \"f1\": 0.14691309476995673, \"f2\": 0.09717424778392775, \"f0_5\": 0.3009602371592447, \"p4\": 0.2331126304507955, \"phi\": 0.176476764059056}, {\"truth_threshold\": 32.660000000000004, \"match_probability\": 0.9999999998526465, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 932, \"tn\": 7018, \"fp\": 0, \"fn\": 10849, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07911043205160852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9208895679483915, \"precision\": 1.0, \"recall\": 0.07911043205160852, \"specificity\": 1.0, \"npv\": 0.3927911792690435, \"accuracy\": 0.42289483483164, \"f1\": 0.1466215684732164, \"f2\": 0.09697020143166306, \"f0_5\": 0.30047069443548907, \"p4\": 0.2327416271125491, \"phi\": 0.1762778485744447}, {\"truth_threshold\": 32.68, \"match_probability\": 0.9999999998546752, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 928, \"tn\": 7018, \"fp\": 0, \"fn\": 10853, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07877090230031407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921229097699686, \"precision\": 1.0, \"recall\": 0.07877090230031407, \"specificity\": 1.0, \"npv\": 0.3927032622684797, \"accuracy\": 0.422682057556253, \"f1\": 0.14603824061688567, \"f2\": 0.09656205777074836, \"f0_5\": 0.29949009229974827, \"p4\": 0.23199844215922102, \"phi\": 0.1758794766456991}, {\"truth_threshold\": 32.7, \"match_probability\": 0.999999999856676, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 926, \"tn\": 7018, \"fp\": 0, \"fn\": 10855, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07860113742466683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9213988625753332, \"precision\": 1.0, \"recall\": 0.07860113742466683, \"specificity\": 1.0, \"npv\": 0.3926593185251497, \"accuracy\": 0.4225756689185595, \"f1\": 0.1457464389706461, \"f2\": 0.0963579604578564, \"f0_5\": 0.2989990313206329, \"p4\": 0.23162625908437265, \"phi\": 0.17568001894487406}, {\"truth_threshold\": 32.72, \"match_probability\": 0.9999999998586491, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 923, \"tn\": 7018, \"fp\": 0, \"fn\": 10858, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07834649011119599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921653509888804, \"precision\": 1.0, \"recall\": 0.07834649011119599, \"specificity\": 1.0, \"npv\": 0.3925934213470575, \"accuracy\": 0.42241608596201924, \"f1\": 0.14530856423173805, \"f2\": 0.0960517826295086, \"f0_5\": 0.2982614877528598, \"p4\": 0.23106724416468272, \"phi\": 0.17538049094265828}, {\"truth_threshold\": 32.74, \"match_probability\": 0.9999999998605952, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 922, \"tn\": 7018, \"fp\": 0, \"fn\": 10859, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07826160767337238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9217383923266276, \"precision\": 1.0, \"recall\": 0.07826160767337238, \"specificity\": 1.0, \"npv\": 0.3925714605358841, \"accuracy\": 0.42236289164317253, \"f1\": 0.1451625600251909, \"f2\": 0.09594971485659576, \"f0_5\": 0.2980153856099295, \"p4\": 0.23088070807552394, \"phi\": 0.17528055690298952}, {\"truth_threshold\": 32.76, \"match_probability\": 0.9999999998625143, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 920, \"tn\": 7018, \"fp\": 0, \"fn\": 10861, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07809184279772514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9219081572022748, \"precision\": 1.0, \"recall\": 0.07809184279772514, \"specificity\": 1.0, \"npv\": 0.3925275462833492, \"accuracy\": 0.422256503005479, \"f1\": 0.14487048263916227, \"f2\": 0.09574556656398302, \"f0_5\": 0.2975227993014682, \"p4\": 0.23050733867104087, \"phi\": 0.17508055128464753}, {\"truth_threshold\": 32.78, \"match_probability\": 0.9999999998644071, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 917, \"tn\": 7018, \"fp\": 0, \"fn\": 10864, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0778371954842543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9221628045157457, \"precision\": 1.0, \"recall\": 0.0778371954842543, \"specificity\": 1.0, \"npv\": 0.39246169332289454, \"accuracy\": 0.4220969200489388, \"f1\": 0.1444321940463065, \"f2\": 0.09543931225411628, \"f0_5\": 0.2967829632985954, \"p4\": 0.22994654011442325, \"phi\": 0.17478019780071086}, {\"truth_threshold\": 32.8, \"match_probability\": 0.9999999998662739, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 916, \"tn\": 7018, \"fp\": 0, \"fn\": 10865, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0777523130464307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9222476869535693, \"precision\": 1.0, \"recall\": 0.0777523130464307, \"specificity\": 1.0, \"npv\": 0.3924397472459878, \"accuracy\": 0.422043725730092, \"f1\": 0.14428605182326534, \"f2\": 0.09533721898417985, \"f0_5\": 0.29653609582389123, \"p4\": 0.2297594083722612, \"phi\": 0.17467998763376466}, {\"truth_threshold\": 32.84, \"match_probability\": 0.9999999998699307, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 914, \"tn\": 7018, \"fp\": 0, \"fn\": 10867, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07758254817078346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9224174518292165, \"precision\": 1.0, \"recall\": 0.07758254817078346, \"specificity\": 1.0, \"npv\": 0.39239586245457087, \"accuracy\": 0.42193733709239856, \"f1\": 0.14399369830641984, \"f2\": 0.09513301969274325, \"f0_5\": 0.29604197706808316, \"p4\": 0.22938484599666717, \"phi\": 0.17447942830287436}, {\"truth_threshold\": 32.86, \"match_probability\": 0.9999999998717214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 910, \"tn\": 7018, \"fp\": 0, \"fn\": 10871, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07724301841948901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.922756981580511, \"precision\": 1.0, \"recall\": 0.07724301841948901, \"specificity\": 1.0, \"npv\": 0.39230812230979933, \"accuracy\": 0.42172455981701157, \"f1\": 0.14340871483728626, \"f2\": 0.09472457009618188, \"f0_5\": 0.29505220154335, \"p4\": 0.22863452307621368, \"phi\": 0.1740777513575212}, {\"truth_threshold\": 32.88, \"match_probability\": 0.9999999998734874, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 906, \"tn\": 7018, \"fp\": 0, \"fn\": 10875, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07690348866819455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9230965113318055, \"precision\": 1.0, \"recall\": 0.07690348866819455, \"specificity\": 1.0, \"npv\": 0.39222042139384117, \"accuracy\": 0.4215117825416246, \"f1\": 0.14282336249704422, \"f2\": 0.09431605246720799, \"f0_5\": 0.2940603700097371, \"p4\": 0.22788259761964896, \"phi\": 0.17367532562829918}, {\"truth_threshold\": 32.92, \"match_probability\": 0.9999999998769469, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 904, \"tn\": 7018, \"fp\": 0, \"fn\": 10877, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07673372379254732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9232662762074527, \"precision\": 1.0, \"recall\": 0.07673372379254732, \"specificity\": 1.0, \"npv\": 0.3921765856384465, \"accuracy\": 0.42140539390393106, \"f1\": 0.14253054789121009, \"f2\": 0.09411176813525443, \"f0_5\": 0.29356368123660453, \"p4\": 0.22750603206704198, \"phi\": 0.17347383030383814}, {\"truth_threshold\": 32.96, \"match_probability\": 0.9999999998803119, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 900, \"tn\": 7018, \"fp\": 0, \"fn\": 10881, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07639419404125286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9236058059587471, \"precision\": 1.0, \"recall\": 0.07639419404125286, \"specificity\": 1.0, \"npv\": 0.39208894351639756, \"accuracy\": 0.42119261662854407, \"f1\": 0.14194464158977999, \"f2\": 0.0937031484257871, \"f0_5\": 0.29256875365710944, \"p4\": 0.22675169155049466, \"phi\": 0.17307027137097092}, {\"truth_threshold\": 32.980000000000004, \"match_probability\": 0.9999999998819595, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 899, \"tn\": 7018, \"fp\": 0, \"fn\": 10882, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07630931160342926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9236906883965708, \"precision\": 1.0, \"recall\": 0.07630931160342926, \"specificity\": 1.0, \"npv\": 0.39206703910614527, \"accuracy\": 0.4211394223096973, \"f1\": 0.1417981072555205, \"f2\": 0.09360098286237845, \"f0_5\": 0.2923196982506341, \"p4\": 0.2265628539100832, \"phi\": 0.1729692627508851}, {\"truth_threshold\": 33.0, \"match_probability\": 0.9999999998835847, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 898, \"tn\": 7018, \"fp\": 0, \"fn\": 10883, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07622442916560564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9237755708343943, \"precision\": 1.0, \"recall\": 0.07622442916560564, \"specificity\": 1.0, \"npv\": 0.39204513714317635, \"accuracy\": 0.4210862279908506, \"f1\": 0.14165154980676709, \"f2\": 0.0934988130440215, \"f0_5\": 0.29207051323749433, \"p4\": 0.22637391507592722, \"phi\": 0.1728682064056031}, {\"truth_threshold\": 33.02, \"match_probability\": 0.9999999998851874, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 896, \"tn\": 7018, \"fp\": 0, \"fn\": 10885, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07605466428995841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9239453357100416, \"precision\": 1.0, \"recall\": 0.07605466428995841, \"specificity\": 1.0, \"npv\": 0.39200134055744845, \"accuracy\": 0.4209798393531571, \"f1\": 0.1413583655438984, \"f2\": 0.09329446064139942, \"f0_5\": 0.29157175398633256, \"p4\": 0.22599573344698062, \"phi\": 0.17266595019664532}, {\"truth_threshold\": 33.04, \"match_probability\": 0.999999999886768, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 895, \"tn\": 7018, \"fp\": 0, \"fn\": 10886, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0759697818521348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9240302181478652, \"precision\": 1.0, \"recall\": 0.0759697818521348, \"specificity\": 1.0, \"npv\": 0.3919794459338695, \"accuracy\": 0.4209266450343103, \"f1\": 0.14121173871883874, \"f2\": 0.0931922780566026, \"f0_5\": 0.2913221795456025, \"p4\": 0.22580649046219758, \"phi\": 0.17256475016096634}, {\"truth_threshold\": 33.06, \"match_probability\": 0.999999999888327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 894, \"tn\": 7018, \"fp\": 0, \"fn\": 10887, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07588489941431117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241151005856888, \"precision\": 1.0, \"recall\": 0.07588489941431117, \"specificity\": 1.0, \"npv\": 0.3919575537559341, \"accuracy\": 0.4208734507154636, \"f1\": 0.14106508875739646, \"f2\": 0.09309009121579408, \"f0_5\": 0.29107247509279155, \"p4\": 0.22561714590368484, \"phi\": 0.17246350205608293}, {\"truth_threshold\": 33.1, \"match_probability\": 0.9999999998913807, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 892, \"tn\": 7018, \"fp\": 0, \"fn\": 10889, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07571513453866395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.924284865461336, \"precision\": 1.0, \"recall\": 0.07571513453866395, \"specificity\": 1.0, \"npv\": 0.3919137767353549, \"accuracy\": 0.4207670620777701, \"f1\": 0.14077171940345617, \"f2\": 0.0928857047650783, \"f0_5\": 0.29057267574434814, \"p4\": 0.22523815168419692, \"phi\": 0.1722608612920338}, {\"truth_threshold\": 33.12, \"match_probability\": 0.999999999892876, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 887, \"tn\": 7018, \"fp\": 0, \"fn\": 10894, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07529072234954588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9247092776504541, \"precision\": 1.0, \"recall\": 0.07529072234954588, \"specificity\": 1.0, \"npv\": 0.39180437695399734, \"accuracy\": 0.42050109048353634, \"f1\": 0.14003789074834228, \"f2\": 0.09237466413946804, \"f0_5\": 0.2893208950355535, \"p4\": 0.2242888819105741, \"phi\": 0.17175341207842199}, {\"truth_threshold\": 33.14, \"match_probability\": 0.9999999998943508, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 885, \"tn\": 7018, \"fp\": 0, \"fn\": 10896, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07512095747389864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9248790425261013, \"precision\": 1.0, \"recall\": 0.07512095747389864, \"specificity\": 1.0, \"npv\": 0.3917606341408954, \"accuracy\": 0.4203947018458429, \"f1\": 0.1397441970630033, \"f2\": 0.09217021808410923, \"f0_5\": 0.288819267671823, \"p4\": 0.22390845829772424, \"phi\": 0.17155009162703985}, {\"truth_threshold\": 33.160000000000004, \"match_probability\": 0.9999999998958053, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 883, \"tn\": 7018, \"fp\": 0, \"fn\": 10898, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07495119259825142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9250488074017486, \"precision\": 1.0, \"recall\": 0.07495119259825142, \"specificity\": 1.0, \"npv\": 0.3917169010939942, \"accuracy\": 0.42028831320814936, \"f1\": 0.1394504106127606, \"f2\": 0.09196575499406337, \"f0_5\": 0.28831711617579836, \"p4\": 0.22352762455705597, \"phi\": 0.1713465753900152}, {\"truth_threshold\": 33.18, \"match_probability\": 0.9999999998972399, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 876, \"tn\": 7018, \"fp\": 0, \"fn\": 10905, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07435701553348611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9256429844665138, \"precision\": 1.0, \"recall\": 0.07435701553348611, \"specificity\": 1.0, \"npv\": 0.3915639122914691, \"accuracy\": 0.41991595297622214, \"f1\": 0.1384214268784072, \"f2\": 0.09125, \"f0_5\": 0.28655544651619236, \"p4\": 0.22219146554155766, \"phi\": 0.17063271640752065}, {\"truth_threshold\": 33.2, \"match_probability\": 0.9999999998986546, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 874, \"tn\": 7018, \"fp\": 0, \"fn\": 10907, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07418725065783889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9258127493421611, \"precision\": 1.0, \"recall\": 0.07418725065783889, \"specificity\": 1.0, \"npv\": 0.39152022315202234, \"accuracy\": 0.4198095643385286, \"f1\": 0.13812722244172265, \"f2\": 0.09104546022750948, \"f0_5\": 0.28605092622897166, \"p4\": 0.22180877664149554, \"phi\": 0.17042831024390312}, {\"truth_threshold\": 33.22, \"match_probability\": 0.9999999999000498, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 870, \"tn\": 7018, \"fp\": 0, \"fn\": 10911, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07384772090654444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9261522790934555, \"precision\": 1.0, \"recall\": 0.07384772090654444, \"specificity\": 1.0, \"npv\": 0.391432874114563, \"accuracy\": 0.41959678706314163, \"f1\": 0.13753853450320133, \"f2\": 0.09063632954119265, \"f0_5\": 0.28504029880086496, \"p4\": 0.22104215486179354, \"phi\": 0.1700188978944952}, {\"truth_threshold\": 33.24, \"match_probability\": 0.9999999999014259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 867, \"tn\": 7018, \"fp\": 0, \"fn\": 10914, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0735930735930736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9264069264069265, \"precision\": 1.0, \"recall\": 0.0735930735930736, \"specificity\": 1.0, \"npv\": 0.3913673879098818, \"accuracy\": 0.4194372041066014, \"f1\": 0.13709677419354838, \"f2\": 0.09032943676939426, \"f0_5\": 0.2842809364548495, \"p4\": 0.2204660969577024, \"phi\": 0.16971131070256015}, {\"truth_threshold\": 33.26, \"match_probability\": 0.999999999902783, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 866, \"tn\": 7018, \"fp\": 0, \"fn\": 10915, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07350819115524998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.92649180884475, \"precision\": 1.0, \"recall\": 0.07350819115524998, \"specificity\": 1.0, \"npv\": 0.39134556404394133, \"accuracy\": 0.41938400978775464, \"f1\": 0.13694947418360084, \"f2\": 0.09022713065221921, \"f0_5\": 0.28402755001639884, \"p4\": 0.22027386921405284, \"phi\": 0.1696086805841646}, {\"truth_threshold\": 33.28, \"match_probability\": 0.9999999999041214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 864, \"tn\": 7018, \"fp\": 0, \"fn\": 10917, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07333842627960276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9266615737203973, \"precision\": 1.0, \"recall\": 0.07333842627960276, \"specificity\": 1.0, \"npv\": 0.3913019236130471, \"accuracy\": 0.4192776211500612, \"f1\": 0.13665480427046264, \"f2\": 0.0900225056264066, \"f0_5\": 0.2835203780271707, \"p4\": 0.2198891004716306, \"phi\": 0.1694032682033089}, {\"truth_threshold\": 33.3, \"match_probability\": 0.9999999999054414, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 861, \"tn\": 7018, \"fp\": 0, \"fn\": 10920, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07308377896613191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9269162210338681, \"precision\": 1.0, \"recall\": 0.07308377896613191, \"specificity\": 1.0, \"npv\": 0.39123648121306726, \"accuracy\": 0.41911803819352095, \"f1\": 0.1362126245847176, \"f2\": 0.08971553610503283, \"f0_5\": 0.2827586206896552, \"p4\": 0.2193111627368126, \"phi\": 0.16909476785655736}, {\"truth_threshold\": 33.32, \"match_probability\": 0.9999999999067432, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 856, \"tn\": 7018, \"fp\": 0, \"fn\": 10925, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07265936677701383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9273406332229862, \"precision\": 1.0, \"recall\": 0.07265936677701383, \"specificity\": 1.0, \"npv\": 0.39112745917628045, \"accuracy\": 0.4188520665992872, \"f1\": 0.13547519189681095, \"f2\": 0.08920383493122135, \"f0_5\": 0.28148635317329823, \"p4\": 0.21834583424024417, \"phi\": 0.16857957620320105}, {\"truth_threshold\": 33.34, \"match_probability\": 0.9999999999080271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 851, \"tn\": 7018, \"fp\": 0, \"fn\": 10930, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07223495458789576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9277650454121043, \"precision\": 1.0, \"recall\": 0.07223495458789576, \"specificity\": 1.0, \"npv\": 0.39101849788277243, \"accuracy\": 0.41858609500505345, \"f1\": 0.13473717542748576, \"f2\": 0.08869202709744659, \"f0_5\": 0.2802107342772473, \"p4\": 0.21737787127019753, \"phi\": 0.16806309362138164}, {\"truth_threshold\": 33.36, \"match_probability\": 0.9999999999092933, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 846, \"tn\": 7018, \"fp\": 0, \"fn\": 10935, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0718105423987777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281894576012223, \"precision\": 1.0, \"recall\": 0.0718105423987777, \"specificity\": 1.0, \"npv\": 0.39090959728179137, \"accuracy\": 0.4183201234108197, \"f1\": 0.13399857448325017, \"f2\": 0.08818011257035648, \"f0_5\": 0.2789317507418398, \"p4\": 0.21640726129468027, \"phi\": 0.16754530793099873}, {\"truth_threshold\": 33.38, \"match_probability\": 0.9999999999105421, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 844, \"tn\": 7018, \"fp\": 0, \"fn\": 10937, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07164077752313046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9283592224768695, \"precision\": 1.0, \"recall\": 0.07164077752313046, \"specificity\": 1.0, \"npv\": 0.39086605402394875, \"accuracy\": 0.41821373477312623, \"f1\": 0.1337029702970297, \"f2\": 0.08797531687791861, \"f0_5\": 0.27841921224516725, \"p4\": 0.216018273320852, \"phi\": 0.16733782602171454}, {\"truth_threshold\": 33.4, \"match_probability\": 0.9999999999117737, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 840, \"tn\": 7018, \"fp\": 0, \"fn\": 10941, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07130124777183601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.928698752228164, \"precision\": 1.0, \"recall\": 0.07130124777183601, \"specificity\": 1.0, \"npv\": 0.39077899660337434, \"accuracy\": 0.41800095749773925, \"f1\": 0.13311148086522462, \"f2\": 0.08756567425569177, \"f0_5\": 0.27739251040221913, \"p4\": 0.2152390175157728, \"phi\": 0.16692222758172937}, {\"truth_threshold\": 33.42, \"match_probability\": 0.9999999999129883, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 835, \"tn\": 7018, \"fp\": 0, \"fn\": 10946, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07087683558271794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.929123164417282, \"precision\": 1.0, \"recall\": 0.07087683558271794, \"specificity\": 1.0, \"npv\": 0.39067022934758405, \"accuracy\": 0.4177349859035055, \"f1\": 0.1323715916296766, \"f2\": 0.08705352488583999, \"f0_5\": 0.2761060776403677, \"p4\": 0.21426253962808345, \"phi\": 0.1664015312806088}, {\"truth_threshold\": 33.44, \"match_probability\": 0.9999999999141862, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 832, \"tn\": 7018, \"fp\": 0, \"fn\": 10949, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0706221882692471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.929377811730753, \"precision\": 1.0, \"recall\": 0.0706221882692471, \"specificity\": 1.0, \"npv\": 0.3906049980519842, \"accuracy\": 0.41757540294696527, \"f1\": 0.13192737651629272, \"f2\": 0.08674618400200183, \"f0_5\": 0.27533258322853926, \"p4\": 0.21367536365078027, \"phi\": 0.16608846953156056}, {\"truth_threshold\": 33.46, \"match_probability\": 0.9999999999153677, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 830, \"tn\": 7018, \"fp\": 0, \"fn\": 10951, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07045242339359986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9295475766064001, \"precision\": 1.0, \"recall\": 0.07045242339359986, \"specificity\": 1.0, \"npv\": 0.39056152262229393, \"accuracy\": 0.41746901430927175, \"f1\": 0.13163111569264926, \"f2\": 0.08654126871585269, \"f0_5\": 0.2748162373352758, \"p4\": 0.21328337410230575, \"phi\": 0.1658794916589597}, {\"truth_threshold\": 33.480000000000004, \"match_probability\": 0.9999999999165328, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 827, \"tn\": 7018, \"fp\": 0, \"fn\": 10954, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.07019777608012902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.929802223919871, \"precision\": 1.0, \"recall\": 0.07019777608012902, \"specificity\": 1.0, \"npv\": 0.3904963276207434, \"accuracy\": 0.4173094313527315, \"f1\": 0.13118654822335024, \"f2\": 0.08623386373589706, \"f0_5\": 0.27404069189475777, \"p4\": 0.2126945793718083, \"phi\": 0.1655656177061942}, {\"truth_threshold\": 33.5, \"match_probability\": 0.999999999917682, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 820, \"tn\": 7018, \"fp\": 0, \"fn\": 10961, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06960359901536373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9303964009846363, \"precision\": 1.0, \"recall\": 0.06960359901536373, \"specificity\": 1.0, \"npv\": 0.3903442905612103, \"accuracy\": 0.4169370711208043, \"f1\": 0.13014840092056185, \"f2\": 0.08551643584181545, \"f0_5\": 0.2722262797954983, \"p4\": 0.2113169285927749, \"phi\": 0.16483133039006603}, {\"truth_threshold\": 33.56, \"match_probability\": 0.9999999999210353, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 819, \"tn\": 7018, \"fp\": 0, \"fn\": 10962, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06951871657754011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.93048128342246, \"precision\": 1.0, \"recall\": 0.06951871657754011, \"specificity\": 1.0, \"npv\": 0.3903225806451613, \"accuracy\": 0.41688387680195754, \"f1\": 0.13, \"f2\": 0.08541392904073587, \"f0_5\": 0.2719665271966527, \"p4\": 0.2111196859376573, \"phi\": 0.16472621181125063}, {\"truth_threshold\": 33.58, \"match_probability\": 0.9999999999221224, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 818, \"tn\": 7018, \"fp\": 0, \"fn\": 10963, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06943383413971649, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9305661658602835, \"precision\": 1.0, \"recall\": 0.06943383413971649, \"specificity\": 1.0, \"npv\": 0.39030087314387407, \"accuracy\": 0.4168306824831108, \"f1\": 0.12985157552186682, \"f2\": 0.08531141796337241, \"f0_5\": 0.27170663655085364, \"p4\": 0.21092233411902403, \"phi\": 0.16462103781248094}, {\"truth_threshold\": 33.6, \"match_probability\": 0.9999999999231945, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 811, \"tn\": 7018, \"fp\": 0, \"fn\": 10970, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0688396570749512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9311603429250488, \"precision\": 1.0, \"recall\": 0.0688396570749512, \"specificity\": 1.0, \"npv\": 0.3901489882143651, \"accuracy\": 0.41645832225118357, \"f1\": 0.12881194409148666, \"f2\": 0.08459372066339835, \"f0_5\": 0.26988352745424293, \"p4\": 0.20953780599415803, \"phi\": 0.1638832589278602}, {\"truth_threshold\": 33.62, \"match_probability\": 0.9999999999242519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 809, \"tn\": 7018, \"fp\": 0, \"fn\": 10972, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06866989219930396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.931330107800696, \"precision\": 1.0, \"recall\": 0.06866989219930396, \"specificity\": 1.0, \"npv\": 0.39010561423012785, \"accuracy\": 0.4163519336134901, \"f1\": 0.1285146942017474, \"f2\": 0.08438862579016544, \"f0_5\": 0.26936139042418594, \"p4\": 0.2091412380650357, \"phi\": 0.16367195995504585}, {\"truth_threshold\": 33.64, \"match_probability\": 0.9999999999252948, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 805, \"tn\": 7018, \"fp\": 0, \"fn\": 10976, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06833036244800951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9316696375519905, \"precision\": 1.0, \"recall\": 0.06833036244800951, \"specificity\": 1.0, \"npv\": 0.39001889518728466, \"accuracy\": 0.4161391563381031, \"f1\": 0.12791991101223582, \"f2\": 0.08397838469402658, \"f0_5\": 0.26831544563695753, \"p4\": 0.20834677875284677, \"phi\": 0.1632486829034752}, {\"truth_threshold\": 33.660000000000004, \"match_probability\": 0.9999999999263233, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 803, \"tn\": 7018, \"fp\": 0, \"fn\": 10978, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06816059757236227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9318394024276377, \"precision\": 1.0, \"recall\": 0.06816059757236227, \"specificity\": 1.0, \"npv\": 0.3899755501222494, \"accuracy\": 0.4160327677004096, \"f1\": 0.12762237762237763, \"f2\": 0.08377323846683497, \"f0_5\": 0.2677916360968452, \"p4\": 0.2079488856691901, \"phi\": 0.16303670303015586}, {\"truth_threshold\": 33.7, \"match_probability\": 0.999999999928338, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 797, \"tn\": 7018, \"fp\": 0, \"fn\": 10984, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0676513029454206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9323486970545795, \"precision\": 1.0, \"recall\": 0.0676513029454206, \"specificity\": 1.0, \"npv\": 0.3898455727141429, \"accuracy\": 0.41571360178732913, \"f1\": 0.12672920973127683, \"f2\": 0.08315769704305002, \"f0_5\": 0.26621684815284924, \"p4\": 0.20675254245908897, \"phi\": 0.16239938713435917}, {\"truth_threshold\": 33.72, \"match_probability\": 0.9999999999293245, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 789, \"tn\": 7018, \"fp\": 0, \"fn\": 10992, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06697224344283167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9330277565571683, \"precision\": 1.0, \"recall\": 0.06697224344283167, \"specificity\": 1.0, \"npv\": 0.38967240421987787, \"accuracy\": 0.41528804723655516, \"f1\": 0.12553699284009545, \"f2\": 0.08233673533279068, \"f0_5\": 0.2641092588873268, \"p4\": 0.20515117018597198, \"phi\": 0.1615463868935705}, {\"truth_threshold\": 33.74, \"match_probability\": 0.9999999999302975, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 788, \"tn\": 7018, \"fp\": 0, \"fn\": 10993, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06688736100500807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.933112638994992, \"precision\": 1.0, \"recall\": 0.06688736100500807, \"specificity\": 1.0, \"npv\": 0.38965076897451556, \"accuracy\": 0.4152348529177084, \"f1\": 0.12538785901821942, \"f2\": 0.08223409584237769, \"f0_5\": 0.263845175115516, \"p4\": 0.20495049415051653, \"phi\": 0.16143949842054583}, {\"truth_threshold\": 33.76, \"match_probability\": 0.9999999999312572, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 785, \"tn\": 7018, \"fp\": 0, \"fn\": 10996, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06663271369153723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9333672863084628, \"precision\": 1.0, \"recall\": 0.06663271369153723, \"specificity\": 1.0, \"npv\": 0.3895858776507161, \"accuracy\": 0.41507526996116817, \"f1\": 0.12494031513608149, \"f2\": 0.08192615166252687, \"f0_5\": 0.2630520742577575, \"p4\": 0.2043477907683789, \"phi\": 0.16111847890222405}, {\"truth_threshold\": 33.78, \"match_probability\": 0.9999999999322036, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 784, \"tn\": 7018, \"fp\": 0, \"fn\": 10997, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06654783125371361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9334521687462864, \"precision\": 1.0, \"recall\": 0.06654783125371361, \"specificity\": 1.0, \"npv\": 0.38956425201221206, \"accuracy\": 0.4150220756423214, \"f1\": 0.12479108635097493, \"f2\": 0.08182349503214495, \"f0_5\": 0.2627874237447208, \"p4\": 0.20414666418544347, \"phi\": 0.16101135396420915}, {\"truth_threshold\": 33.8, \"match_probability\": 0.9999999999331369, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 782, \"tn\": 7018, \"fp\": 0, \"fn\": 10999, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06637806637806638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9336219336219336, \"precision\": 1.0, \"recall\": 0.06637806637806638, \"specificity\": 1.0, \"npv\": 0.38952100793694844, \"accuracy\": 0.4149156870046279, \"f1\": 0.12449255751014884, \"f2\": 0.08161816891412349, \"f0_5\": 0.26225769669327254, \"p4\": 0.20374407218023854, \"phi\": 0.16079692571840445}, {\"truth_threshold\": 33.82, \"match_probability\": 0.9999999999340575, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 781, \"tn\": 7018, \"fp\": 0, \"fn\": 11000, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06629318394024276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9337068160597572, \"precision\": 1.0, \"recall\": 0.06629318394024276, \"specificity\": 1.0, \"npv\": 0.3894993894993895, \"accuracy\": 0.4148624926857812, \"f1\": 0.1243432574430823, \"f2\": 0.08151549942594719, \"f0_5\": 0.26199261992619927, \"p4\": 0.2035426065388141, \"phi\": 0.16068962216862448}, {\"truth_threshold\": 33.84, \"match_probability\": 0.9999999999349654, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 780, \"tn\": 7018, \"fp\": 0, \"fn\": 11001, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06620830150241915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9337916984975808, \"precision\": 1.0, \"recall\": 0.06620830150241915, \"specificity\": 1.0, \"npv\": 0.3894777734613464, \"accuracy\": 0.4148092983669344, \"f1\": 0.12419393360401242, \"f2\": 0.0814128256513026, \"f0_5\": 0.2617274008455808, \"p4\": 0.20334102765850523, \"phi\": 0.1605822588389506}, {\"truth_threshold\": 33.86, \"match_probability\": 0.9999999999358606, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 779, \"tn\": 7018, \"fp\": 0, \"fn\": 11002, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06612341906459554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9338765809354045, \"precision\": 1.0, \"recall\": 0.06612341906459554, \"specificity\": 1.0, \"npv\": 0.38945615982241955, \"accuracy\": 0.41475610404808766, \"f1\": 0.12404458598726115, \"f2\": 0.0813101475899213, \"f0_5\": 0.2614620393367792, \"p4\": 0.20313933542938445, \"phi\": 0.1604748356074121}, {\"truth_threshold\": 33.88, \"match_probability\": 0.9999999999367437, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 778, \"tn\": 7018, \"fp\": 0, \"fn\": 11003, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06603853662677192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.933961463373228, \"precision\": 1.0, \"recall\": 0.06603853662677192, \"specificity\": 1.0, \"npv\": 0.38943454858220966, \"accuracy\": 0.4147029097292409, \"f1\": 0.12389521458714865, \"f2\": 0.0812074652415348, \"f0_5\": 0.2611965352850332, \"p4\": 0.20293752974138382, \"phi\": 0.16036735235164495}, {\"truth_threshold\": 33.9, \"match_probability\": 0.9999999999376146, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 776, \"tn\": 7018, \"fp\": 0, \"fn\": 11005, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0658687717511247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9341312282488753, \"precision\": 1.0, \"recall\": 0.0658687717511247, \"specificity\": 1.0, \"npv\": 0.38939133329634357, \"accuracy\": 0.41459652109154743, \"f1\": 0.12359640041411166, \"f2\": 0.08100208768267224, \"f0_5\": 0.2606650990930467, \"p4\": 0.2025335775477677, \"phi\": 0.16015220527599042}, {\"truth_threshold\": 33.94, \"match_probability\": 0.9999999999393205, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 772, \"tn\": 7018, \"fp\": 0, \"fn\": 11009, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06552924199983023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9344707580001698, \"precision\": 1.0, \"recall\": 0.06552924199983023, \"specificity\": 1.0, \"npv\": 0.3893049314916514, \"accuracy\": 0.41438374381616044, \"f1\": 0.12299848641758943, \"f2\": 0.08059128110906966, \"f0_5\": 0.25960051113054006, \"p4\": 0.2017243067953485, \"phi\": 0.15972118540583072}, {\"truth_threshold\": 33.96, \"match_probability\": 0.9999999999401559, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 767, \"tn\": 7018, \"fp\": 0, \"fn\": 11014, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06510482981071217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9348951701892878, \"precision\": 1.0, \"recall\": 0.06510482981071217, \"specificity\": 1.0, \"npv\": 0.38919698314108253, \"accuracy\": 0.4141177722219267, \"f1\": 0.12225055785782594, \"f2\": 0.08007767639013594, \"f0_5\": 0.2582665499360226, \"p4\": 0.200710147266637, \"phi\": 0.15918103954379362}, {\"truth_threshold\": 33.980000000000004, \"match_probability\": 0.9999999999409798, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 765, \"tn\": 7018, \"fp\": 0, \"fn\": 11016, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06493506493506493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.935064935064935, \"precision\": 1.0, \"recall\": 0.06493506493506493, \"specificity\": 1.0, \"npv\": 0.38915382056116227, \"accuracy\": 0.41401138358423323, \"f1\": 0.12195121951219512, \"f2\": 0.07987220447284345, \"f0_5\": 0.25773195876288657, \"p4\": 0.20030368070143392, \"phi\": 0.1589645514190748}, {\"truth_threshold\": 34.0, \"match_probability\": 0.9999999999417923, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 762, \"tn\": 7018, \"fp\": 0, \"fn\": 11019, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06468041762159409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.935319582378406, \"precision\": 1.0, \"recall\": 0.06468041762159409, \"specificity\": 1.0, \"npv\": 0.38908909463879804, \"accuracy\": 0.41385180062769295, \"f1\": 0.12150203300645779, \"f2\": 0.07956396441548678, \"f0_5\": 0.2569289904916043, \"p4\": 0.19969311796250222, \"phi\": 0.15863935556237427}, {\"truth_threshold\": 34.02, \"match_probability\": 0.9999999999425937, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 759, \"tn\": 7018, \"fp\": 0, \"fn\": 11022, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06442577030812324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9355742296918768, \"precision\": 1.0, \"recall\": 0.06442577030812324, \"specificity\": 1.0, \"npv\": 0.38902439024390245, \"accuracy\": 0.4136922176711527, \"f1\": 0.12105263157894737, \"f2\": 0.07925568573397657, \"f0_5\": 0.2561247216035635, \"p4\": 0.19908151705705585, \"phi\": 0.1583136002057668}, {\"truth_threshold\": 34.04, \"match_probability\": 0.9999999999433841, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 758, \"tn\": 7018, \"fp\": 0, \"fn\": 11023, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06434088787029964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9356591121297003, \"precision\": 1.0, \"recall\": 0.06434088787029964, \"specificity\": 1.0, \"npv\": 0.3890028268942963, \"accuracy\": 0.41363902335230596, \"f1\": 0.1209027833160539, \"f2\": 0.07915291758907314, \"f0_5\": 0.2558563424019442, \"p4\": 0.19887741885893848, \"phi\": 0.15820489014703526}, {\"truth_threshold\": 34.08, \"match_probability\": 0.9999999999449322, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 752, \"tn\": 7018, \"fp\": 0, \"fn\": 11029, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06383159324335795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936168406756642, \"precision\": 1.0, \"recall\": 0.06383159324335795, \"specificity\": 1.0, \"npv\": 0.3888734969801075, \"accuracy\": 0.4133198574392255, \"f1\": 0.120003191574244, \"f2\": 0.07853621856462528, \"f0_5\": 0.25424301845966596, \"p4\": 0.1976503938365556, \"phi\": 0.15755130872943077}, {\"truth_threshold\": 34.12, \"match_probability\": 0.9999999999464381, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 751, \"tn\": 7018, \"fp\": 0, \"fn\": 11030, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06374671080553433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9362532891944657, \"precision\": 1.0, \"recall\": 0.06374671080553433, \"specificity\": 1.0, \"npv\": 0.38885195035460995, \"accuracy\": 0.41326666312037874, \"f1\": 0.11985317586977338, \"f2\": 0.07843342036553524, \"f0_5\": 0.2539736219141021, \"p4\": 0.197445482633801, \"phi\": 0.15744215707815779}, {\"truth_threshold\": 34.14, \"match_probability\": 0.9999999999471755, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 749, \"tn\": 7018, \"fp\": 0, \"fn\": 11032, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06357694592988711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936423054070113, \"precision\": 1.0, \"recall\": 0.06357694592988711, \"specificity\": 1.0, \"npv\": 0.388808864265928, \"accuracy\": 0.4131602744826853, \"f1\": 0.11955307262569832, \"f2\": 0.07822781108349174, \"f0_5\": 0.2534343912837518, \"p4\": 0.19703531031790097, \"phi\": 0.15722366278806674}, {\"truth_threshold\": 34.160000000000004, \"match_probability\": 0.9999999999479027, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 746, \"tn\": 7018, \"fp\": 0, \"fn\": 11035, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06332229861641626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9366777013835837, \"precision\": 1.0, \"recall\": 0.06332229861641626, \"specificity\": 1.0, \"npv\": 0.38874425303273696, \"accuracy\": 0.413000691526145, \"f1\": 0.11910273808573481, \"f2\": 0.07791936494673073, \"f0_5\": 0.25262444971215714, \"p4\": 0.19641917535226786, \"phi\": 0.15689544185843848}, {\"truth_threshold\": 34.18, \"match_probability\": 0.9999999999486199, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 739, \"tn\": 7018, \"fp\": 0, \"fn\": 11042, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06272812155165096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.937271878448349, \"precision\": 1.0, \"recall\": 0.06272812155165096, \"specificity\": 1.0, \"npv\": 0.38859357696567, \"accuracy\": 0.4126283312942178, \"f1\": 0.11805111821086262, \"f2\": 0.07719950692601801, \"f0_5\": 0.25072945647010925, \"p4\": 0.19497742072261845, \"phi\": 0.15612733626784703}, {\"truth_threshold\": 34.2, \"match_probability\": 0.9999999999493273, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 736, \"tn\": 7018, \"fp\": 0, \"fn\": 11045, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06247347423818012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9375265257618198, \"precision\": 1.0, \"recall\": 0.06247347423818012, \"specificity\": 1.0, \"npv\": 0.3885290372584842, \"accuracy\": 0.41246874833767755, \"f1\": 0.11760006391307821, \"f2\": 0.0768909318846636, \"f0_5\": 0.2499151103565365, \"p4\": 0.19435775850302117, \"phi\": 0.15579717198958665}, {\"truth_threshold\": 34.22, \"match_probability\": 0.9999999999500249, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 733, \"tn\": 7018, \"fp\": 0, \"fn\": 11048, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06221882692470928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9377811730752907, \"precision\": 1.0, \"recall\": 0.06221882692470928, \"specificity\": 1.0, \"npv\": 0.3884645189859404, \"accuracy\": 0.4123091653811373, \"f1\": 0.11714879335144639, \"f2\": 0.0765823181561736, \"f0_5\": 0.24909943587303746, \"p4\": 0.19373703133148965, \"phi\": 0.1554664165444636}, {\"truth_threshold\": 34.26, \"match_probability\": 0.9999999999513914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 732, \"tn\": 7018, \"fp\": 0, \"fn\": 11049, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06213394448688566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9378660555131143, \"precision\": 1.0, \"recall\": 0.06213394448688566, \"specificity\": 1.0, \"npv\": 0.3884430176565008, \"accuracy\": 0.41225597106229056, \"f1\": 0.1169983217453848, \"f2\": 0.07647943831494483, \"f0_5\": 0.24882724862329186, \"p4\": 0.19352988507442387, \"phi\": 0.15535603269711598}, {\"truth_threshold\": 34.300000000000004, \"match_probability\": 0.9999999999527207, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 730, \"tn\": 7018, \"fp\": 0, \"fn\": 11051, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.061964179611238436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9380358203887615, \"precision\": 1.0, \"recall\": 0.061964179611238436, \"specificity\": 1.0, \"npv\": 0.38840002213736236, \"accuracy\": 0.41214958242459704, \"f1\": 0.11669730637039405, \"f2\": 0.07627366573327203, \"f0_5\": 0.24828242976668255, \"p4\": 0.19311523605911388, \"phi\": 0.155135066096381}, {\"truth_threshold\": 34.32, \"match_probability\": 0.9999999999533716, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 729, \"tn\": 7018, \"fp\": 0, \"fn\": 11052, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.061879297173414824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9381207028265852, \"precision\": 1.0, \"recall\": 0.061879297173414824, \"specificity\": 1.0, \"npv\": 0.3883785279468733, \"accuracy\": 0.41209638810575033, \"f1\": 0.11654676258992806, \"f2\": 0.07617077299228889, \"f0_5\": 0.24800979791794245, \"p4\": 0.1929077330665569, \"phi\": 0.15502448305541278}, {\"truth_threshold\": 34.34, \"match_probability\": 0.9999999999540136, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 725, \"tn\": 7018, \"fp\": 0, \"fn\": 11056, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06153976742212036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9384602325778796, \"precision\": 1.0, \"recall\": 0.06153976742212036, \"specificity\": 1.0, \"npv\": 0.38829257496956954, \"accuracy\": 0.41188361083036334, \"f1\": 0.11594434671357748, \"f2\": 0.07575915902108717, \"f0_5\": 0.24691778489203733, \"p4\": 0.192076528456228, \"phi\": 0.15458148257590087}, {\"truth_threshold\": 34.36, \"match_probability\": 0.9999999999546466, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 722, \"tn\": 7018, \"fp\": 0, \"fn\": 11059, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06128512010864952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9387148798913505, \"precision\": 1.0, \"recall\": 0.06128512010864952, \"specificity\": 1.0, \"npv\": 0.3882281351994247, \"accuracy\": 0.41172402787382306, \"f1\": 0.11549228185235544, \"f2\": 0.07545040337750282, \"f0_5\": 0.2460972118072125, \"p4\": 0.1914518694267748, \"phi\": 0.15424852639572856}, {\"truth_threshold\": 34.38, \"match_probability\": 0.999999999955271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 717, \"tn\": 7018, \"fp\": 0, \"fn\": 11064, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06086070791953145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9391392920804685, \"precision\": 1.0, \"recall\": 0.06086070791953145, \"specificity\": 1.0, \"npv\": 0.38812078309921466, \"accuracy\": 0.4114580562795893, \"f1\": 0.11473835813730197, \"f2\": 0.07493572458769675, \"f0_5\": 0.24472660249846406, \"p4\": 0.19040837001184702, \"phi\": 0.15369224319301583}, {\"truth_threshold\": 34.44, \"match_probability\": 0.9999999999570931, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 714, \"tn\": 7018, \"fp\": 0, \"fn\": 11067, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06060606060606061, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9393939393939394, \"precision\": 1.0, \"recall\": 0.06060606060606061, \"specificity\": 1.0, \"npv\": 0.38805640033176664, \"accuracy\": 0.4112984733230491, \"f1\": 0.11428571428571428, \"f2\": 0.07462686567164178, \"f0_5\": 0.24390243902439024, \"p4\": 0.18978082451087766, \"phi\": 0.1533576529459054}, {\"truth_threshold\": 34.46, \"match_probability\": 0.9999999999576838, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 713, \"tn\": 7018, \"fp\": 0, \"fn\": 11068, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06052117816823699, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.939478821831763, \"precision\": 1.0, \"recall\": 0.06052117816823699, \"specificity\": 1.0, \"npv\": 0.38803494415570056, \"accuracy\": 0.4112452790042023, \"f1\": 0.11413478469665439, \"f2\": 0.0745239040909756, \"f0_5\": 0.243627417481036, \"p4\": 0.1895714009855691, \"phi\": 0.15324598523533672}, {\"truth_threshold\": 34.480000000000004, \"match_probability\": 0.9999999999582664, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 712, \"tn\": 7018, \"fp\": 0, \"fn\": 11069, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.06043629573041338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9395637042695866, \"precision\": 1.0, \"recall\": 0.06043629573041338, \"specificity\": 1.0, \"npv\": 0.38801349035218663, \"accuracy\": 0.4111920846853556, \"f1\": 0.11398383094532938, \"f2\": 0.07442093820553558, \"f0_5\": 0.24335224553968146, \"p4\": 0.18936185641480846, \"phi\": 0.15313424845642679}, {\"truth_threshold\": 34.5, \"match_probability\": 0.9999999999588409, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 710, \"tn\": 7018, \"fp\": 0, \"fn\": 11071, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.060266530854766145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9397334691452338, \"precision\": 1.0, \"recall\": 0.060266530854766145, \"specificity\": 1.0, \"npv\": 0.38797058986124167, \"accuracy\": 0.4110856960476621, \"f1\": 0.11368185093267152, \"f2\": 0.07421499351925409, \"f0_5\": 0.24280144996922234, \"p4\": 0.18894240365673348, \"phi\": 0.15291056707963102}, {\"truth_threshold\": 34.52, \"match_probability\": 0.9999999999594076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 705, \"tn\": 7018, \"fp\": 0, \"fn\": 11076, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05984211866564808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.940157881334352, \"precision\": 1.0, \"recall\": 0.05984211866564808, \"specificity\": 1.0, \"npv\": 0.38786338012600863, \"accuracy\": 0.41081972445342835, \"f1\": 0.11292647765497357, \"f2\": 0.07370005645110707, \"f0_5\": 0.2414218204232587, \"p4\": 0.18789164504619107, \"phi\": 0.15235014414026649}, {\"truth_threshold\": 34.54, \"match_probability\": 0.9999999999599665, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 702, \"tn\": 7018, \"fp\": 0, \"fn\": 11079, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.059587471352177235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9404125286478228, \"precision\": 1.0, \"recall\": 0.059587471352177235, \"specificity\": 1.0, \"npv\": 0.387799082720893, \"accuracy\": 0.4106601414968881, \"f1\": 0.11247296322999278, \"f2\": 0.07339104252916824, \"f0_5\": 0.2405922270203578, \"p4\": 0.1872597267273164, \"phi\": 0.15201304790060563}, {\"truth_threshold\": 34.6, \"match_probability\": 0.9999999999615973, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 693, \"tn\": 7018, \"fp\": 0, \"fn\": 11088, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.058823529411764705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9411764705882353, \"precision\": 1.0, \"recall\": 0.058823529411764705, \"specificity\": 1.0, \"npv\": 0.38760631834750914, \"accuracy\": 0.4101813926272674, \"f1\": 0.1111111111111111, \"f2\": 0.07246376811594203, \"f0_5\": 0.23809523809523808, \"p4\": 0.18535735037768739, \"phi\": 0.15099791941447582}, {\"truth_threshold\": 34.62, \"match_probability\": 0.999999999962126, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 691, \"tn\": 7018, \"fp\": 0, \"fn\": 11090, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.058653764536117474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9413462354638825, \"precision\": 1.0, \"recall\": 0.058653764536117474, \"specificity\": 1.0, \"npv\": 0.38756350784183785, \"accuracy\": 0.4100750039895739, \"f1\": 0.11080821039127646, \"f2\": 0.07225765973021019, \"f0_5\": 0.23753867308353385, \"p4\": 0.18493324499491193, \"phi\": 0.1507715448343847}, {\"truth_threshold\": 34.64, \"match_probability\": 0.9999999999626474, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 689, \"tn\": 7018, \"fp\": 0, \"fn\": 11092, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05848399966047025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9415160003395298, \"precision\": 1.0, \"recall\": 0.05848399966047025, \"specificity\": 1.0, \"npv\": 0.3875207067918277, \"accuracy\": 0.4099686153518804, \"f1\": 0.11050521251002406, \"f2\": 0.07205153410160417, \"f0_5\": 0.23698149549425604, \"p4\": 0.18450864472286377, \"phi\": 0.1505448799675314}, {\"truth_threshold\": 34.660000000000004, \"match_probability\": 0.9999999999631617, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 688, \"tn\": 7018, \"fp\": 0, \"fn\": 11093, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05839911722264664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9416008827773533, \"precision\": 1.0, \"recall\": 0.05839911722264664, \"specificity\": 1.0, \"npv\": 0.38749930981171665, \"accuracy\": 0.4099154210330337, \"f1\": 0.11035367711925576, \"f2\": 0.07194846482054715, \"f0_5\": 0.23670267666689604, \"p4\": 0.18429615869446556, \"phi\": 0.15043143826138572}, {\"truth_threshold\": 34.68, \"match_probability\": 0.9999999999636688, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 687, \"tn\": 7018, \"fp\": 0, \"fn\": 11094, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05831423478482302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.941685765215177, \"precision\": 1.0, \"recall\": 0.05831423478482302, \"specificity\": 1.0, \"npv\": 0.38747791519434627, \"accuracy\": 0.40986222671418693, \"f1\": 0.11020211742059673, \"f2\": 0.07184539122796009, \"f0_5\": 0.2364237043155069, \"p4\": 0.18408354857274778, \"phi\": 0.150317923484117}, {\"truth_threshold\": 34.7, \"match_probability\": 0.999999999964169, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 686, \"tn\": 7018, \"fp\": 0, \"fn\": 11095, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.058229352346999406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9417706476530006, \"precision\": 1.0, \"recall\": 0.058229352346999406, \"specificity\": 1.0, \"npv\": 0.38745652293932537, \"accuracy\": 0.40980903239534017, \"f1\": 0.11005053340819765, \"f2\": 0.07174231332357248, \"f0_5\": 0.236144578313253, \"p4\": 0.18387081423370408, \"phi\": 0.1502043354679792}, {\"truth_threshold\": 34.72, \"match_probability\": 0.9999999999646623, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 680, \"tn\": 7018, \"fp\": 0, \"fn\": 11101, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05772005772005772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9422799422799423, \"precision\": 1.0, \"recall\": 0.05772005772005772, \"specificity\": 1.0, \"npv\": 0.3873282189966334, \"accuracy\": 0.4094898664822597, \"f1\": 0.10914051841746249, \"f2\": 0.07112375533428165, \"f0_5\": 0.23446658851113716, \"p4\": 0.18259179267063588, \"phi\": 0.1495212598833117}, {\"truth_threshold\": 34.74, \"match_probability\": 0.9999999999651488, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 678, \"tn\": 7018, \"fp\": 0, \"fn\": 11103, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05755029284441049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9424497071555895, \"precision\": 1.0, \"recall\": 0.05755029284441049, \"specificity\": 1.0, \"npv\": 0.3872854698968048, \"accuracy\": 0.4093834778445662, \"f1\": 0.10883698531182277, \"f2\": 0.07091753483117862, \"f0_5\": 0.23390602359759885, \"p4\": 0.18216445276285456, \"phi\": 0.14929297440585151}, {\"truth_threshold\": 34.76, \"match_probability\": 0.9999999999656286, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 675, \"tn\": 7018, \"fp\": 0, \"fn\": 11106, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.057295645530939646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9427043544690603, \"precision\": 1.0, \"recall\": 0.057295645530939646, \"specificity\": 1.0, \"npv\": 0.3872213639373207, \"accuracy\": 0.40922389488802596, \"f1\": 0.10838150289017341, \"f2\": 0.07060817171907362, \"f0_5\": 0.23306401491609696, \"p4\": 0.1815225025309172, \"phi\": 0.14894998492836345}, {\"truth_threshold\": 34.800000000000004, \"match_probability\": 0.9999999999665685, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 674, \"tn\": 7018, \"fp\": 0, \"fn\": 11107, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.057210763093116034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.942789236906884, \"precision\": 1.0, \"recall\": 0.057210763093116034, \"specificity\": 1.0, \"npv\": 0.3872, \"accuracy\": 0.4091707005691792, \"f1\": 0.10822962665596146, \"f2\": 0.0705050420519687, \"f0_5\": 0.23278303515921808, \"p4\": 0.18130826785176357, \"phi\": 0.14883550473477264}, {\"truth_threshold\": 34.82, \"match_probability\": 0.9999999999670287, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 673, \"tn\": 7018, \"fp\": 0, \"fn\": 11108, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05712588065529242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9428741193447076, \"precision\": 1.0, \"recall\": 0.05712588065529242, \"specificity\": 1.0, \"npv\": 0.38717863841994926, \"accuracy\": 0.40911750625033244, \"f1\": 0.10807772603179701, \"f2\": 0.07040190806954412, \"f0_5\": 0.23250190008982244, \"p4\": 0.18109390732824454, \"phi\": 0.1487209490645371}, {\"truth_threshold\": 34.84, \"match_probability\": 0.9999999999674827, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 671, \"tn\": 7018, \"fp\": 0, \"fn\": 11110, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05695611577964519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9430438842203548, \"precision\": 1.0, \"recall\": 0.05695611577964519, \"specificity\": 1.0, \"npv\": 0.3871359223300971, \"accuracy\": 0.409011117612639, \"f1\": 0.10777385159010601, \"f2\": 0.07019562715765247, \"f0_5\": 0.23193916349809887, \"p4\": 0.1806648082426752, \"phi\": 0.148491610586904}, {\"truth_threshold\": 34.88, \"match_probability\": 0.9999999999683719, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 668, \"tn\": 7018, \"fp\": 0, \"fn\": 11113, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05670146846617435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9432985315338257, \"precision\": 1.0, \"recall\": 0.05670146846617435, \"specificity\": 1.0, \"npv\": 0.38707186586509296, \"accuracy\": 0.40885153465609875, \"f1\": 0.10731785685597237, \"f2\": 0.06988617341814529, \"f0_5\": 0.23109389054175603, \"p4\": 0.1800202126182195, \"phi\": 0.14814703235803556}, {\"truth_threshold\": 34.92, \"match_probability\": 0.9999999999692367, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 667, \"tn\": 7018, \"fp\": 0, \"fn\": 11114, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.056616586028350735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9433834139716493, \"precision\": 1.0, \"recall\": 0.056616586028350735, \"specificity\": 1.0, \"npv\": 0.3870505184204721, \"accuracy\": 0.408798340337252, \"f1\": 0.10716580976863753, \"f2\": 0.06978301353811388, \"f0_5\": 0.23081182088725863, \"p4\": 0.1798050943699932, \"phi\": 0.1480320200952159}, {\"truth_threshold\": 34.94, \"match_probability\": 0.9999999999696603, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 666, \"tn\": 7018, \"fp\": 0, \"fn\": 11115, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05653170359052712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9434682964094728, \"precision\": 1.0, \"recall\": 0.05653170359052712, \"specificity\": 1.0, \"npv\": 0.3870291733303921, \"accuracy\": 0.4087451460184052, \"f1\": 0.10701373825018076, \"f2\": 0.0696798493408663, \"f0_5\": 0.23052959501557632, \"p4\": 0.17958984938966382, \"phi\": 0.14791693110526757}, {\"truth_threshold\": 34.96, \"match_probability\": 0.9999999999700779, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 665, \"tn\": 7018, \"fp\": 0, \"fn\": 11116, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.056446821152703504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9435531788472965, \"precision\": 1.0, \"recall\": 0.056446821152703504, \"specificity\": 1.0, \"npv\": 0.3870078305944634, \"accuracy\": 0.40869195169955846, \"f1\": 0.10686164229471316, \"f2\": 0.06957668082613154, \"f0_5\": 0.23024721279689772, \"p4\": 0.17937447754973887, \"phi\": 0.14780176520685215}, {\"truth_threshold\": 34.980000000000004, \"match_probability\": 0.9999999999704899, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 662, \"tn\": 7018, \"fp\": 0, \"fn\": 11119, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05619217383923266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9438078261607673, \"precision\": 1.0, \"recall\": 0.05619217383923266, \"specificity\": 1.0, \"npv\": 0.38694381650769144, \"accuracy\": 0.40853236874301824, \"f1\": 0.10640520774732781, \"f2\": 0.06926714937429372, \"f0_5\": 0.22939912675861113, \"p4\": 0.17872759959492807, \"phi\": 0.14745580423712165}, {\"truth_threshold\": 35.0, \"match_probability\": 0.9999999999708962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 658, \"tn\": 7018, \"fp\": 0, \"fn\": 11123, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.055852644087938205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9441473559120618, \"precision\": 1.0, \"recall\": 0.055852644087938205, \"specificity\": 1.0, \"npv\": 0.38685849732649796, \"accuracy\": 0.40831959146763125, \"f1\": 0.10579628587507034, \"f2\": 0.06885438031057721, \"f0_5\": 0.22826614861583294, \"p4\": 0.17786331185664642, \"phi\": 0.14699343510365176}, {\"truth_threshold\": 35.06, \"match_probability\": 0.9999999999720818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 657, \"tn\": 7018, \"fp\": 0, \"fn\": 11124, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05576776165011459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9442322383498855, \"precision\": 1.0, \"recall\": 0.05576776165011459, \"specificity\": 1.0, \"npv\": 0.38683717340976737, \"accuracy\": 0.4082663971487845, \"f1\": 0.10564399421128799, \"f2\": 0.06875117724618572, \"f0_5\": 0.22798251093066832, \"p4\": 0.1776469205298817, \"phi\": 0.14687764732633743}, {\"truth_threshold\": 35.08, \"match_probability\": 0.9999999999724661, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 652, \"tn\": 7018, \"fp\": 0, \"fn\": 11129, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05534334946099652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9446566505390035, \"precision\": 1.0, \"recall\": 0.05534334946099652, \"specificity\": 1.0, \"npv\": 0.38673058907808455, \"accuracy\": 0.4080004255545508, \"f1\": 0.10488216842274592, \"f2\": 0.06823509711989283, \"f0_5\": 0.2265619570505247, \"p4\": 0.1765630410895278, \"phi\": 0.14629752608504862}, {\"truth_threshold\": 35.12, \"match_probability\": 0.999999999973219, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 651, \"tn\": 7018, \"fp\": 0, \"fn\": 11130, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05525846702317291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9447415329768271, \"precision\": 1.0, \"recall\": 0.05525846702317291, \"specificity\": 1.0, \"npv\": 0.3867092792594225, \"accuracy\": 0.40794723123570403, \"f1\": 0.10472972972972973, \"f2\": 0.06813186813186813, \"f0_5\": 0.22627737226277372, \"p4\": 0.17634587973337126, \"phi\": 0.14618126403719378}, {\"truth_threshold\": 35.14, \"match_probability\": 0.9999999999735877, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 649, \"tn\": 7018, \"fp\": 0, \"fn\": 11132, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.055088702147525676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9449112978524743, \"precision\": 1.0, \"recall\": 0.055088702147525676, \"specificity\": 1.0, \"npv\": 0.38666666666666666, \"accuracy\": 0.4078408425980105, \"f1\": 0.10442477876106195, \"f2\": 0.06792539719088188, \"f0_5\": 0.22570772762050498, \"p4\": 0.17591117051354546, \"phi\": 0.14594850061023784}, {\"truth_threshold\": 35.160000000000004, \"match_probability\": 0.9999999999739514, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 647, \"tn\": 7018, \"fp\": 0, \"fn\": 11134, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05491893727187845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9450810627281215, \"precision\": 1.0, \"recall\": 0.05491893727187845, \"specificity\": 1.0, \"npv\": 0.38662406346408107, \"accuracy\": 0.40773445396031704, \"f1\": 0.1041197296427422, \"f2\": 0.06771890896150384, \"f0_5\": 0.22513744867422925, \"p4\": 0.17547594508129263, \"phi\": 0.1457154167862228}, {\"truth_threshold\": 35.18, \"match_probability\": 0.99999999997431, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 643, \"tn\": 7018, \"fp\": 0, \"fn\": 11138, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05457940752058399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.945420592479416, \"precision\": 1.0, \"recall\": 0.05457940752058399, \"specificity\": 1.0, \"npv\": 0.38653888521700813, \"accuracy\": 0.40752167668493006, \"f1\": 0.10350933676754669, \"f2\": 0.06730588062888605, \"f0_5\": 0.22399498362711628, \"p4\": 0.17460394139540447, \"phi\": 0.14524828170691495}, {\"truth_threshold\": 35.2, \"match_probability\": 0.9999999999746636, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 642, \"tn\": 7018, \"fp\": 0, \"fn\": 11139, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05449452508276038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9455054749172396, \"precision\": 1.0, \"recall\": 0.05449452508276038, \"specificity\": 1.0, \"npv\": 0.3865175965192488, \"accuracy\": 0.4074684823660833, \"f1\": 0.10335667713112774, \"f2\": 0.06720261273709333, \"f0_5\": 0.22370896926615094, \"p4\": 0.1743856162044586, \"phi\": 0.14513129524140014}, {\"truth_threshold\": 35.22, \"match_probability\": 0.9999999999750124, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 641, \"tn\": 7018, \"fp\": 0, \"fn\": 11140, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.054409642644936765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9455903573550632, \"precision\": 1.0, \"recall\": 0.054409642644936765, \"specificity\": 1.0, \"npv\": 0.38649631016631786, \"accuracy\": 0.40741528804723653, \"f1\": 0.10320399291579456, \"f2\": 0.0670993405213022, \"f0_5\": 0.22342279539909377, \"p4\": 0.17416716104273, \"phi\": 0.1450142273011031}, {\"truth_threshold\": 35.24, \"match_probability\": 0.9999999999753565, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 639, \"tn\": 7018, \"fp\": 0, \"fn\": 11142, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.054239877769289534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9457601222307105, \"precision\": 1.0, \"recall\": 0.054239877769289534, \"specificity\": 1.0, \"npv\": 0.3864537444933921, \"accuracy\": 0.40730889940954307, \"f1\": 0.10289855072463767, \"f2\": 0.0668927831166384, \"f0_5\": 0.22284996861268047, \"p4\": 0.17372986027953158, \"phi\": 0.144779846196927}, {\"truth_threshold\": 35.26, \"match_probability\": 0.9999999999756958, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 637, \"tn\": 7018, \"fp\": 0, \"fn\": 11144, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0540701128936423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9459298871063577, \"precision\": 1.0, \"recall\": 0.0540701128936423, \"specificity\": 1.0, \"npv\": 0.3864111881951327, \"accuracy\": 0.40720251077184955, \"f1\": 0.10259301014656144, \"f2\": 0.06668620841272167, \"f0_5\": 0.22227650219833903, \"p4\": 0.1732920380492591, \"phi\": 0.14454513678805417}, {\"truth_threshold\": 35.300000000000004, \"match_probability\": 0.9999999999763604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 633, \"tn\": 7018, \"fp\": 0, \"fn\": 11148, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05373058314234785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9462694168576522, \"precision\": 1.0, \"recall\": 0.05373058314234785, \"specificity\": 1.0, \"npv\": 0.3863261037102279, \"accuracy\": 0.40698973349646256, \"f1\": 0.10198163363943934, \"f2\": 0.06627300709843584, \"f0_5\": 0.22112764619576608, \"p4\": 0.17241482494713617, \"phi\": 0.14407472656736747}, {\"truth_threshold\": 35.32, \"match_probability\": 0.9999999999766858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 630, \"tn\": 7018, \"fp\": 0, \"fn\": 11151, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.053475935828877004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.946524064171123, \"precision\": 1.0, \"recall\": 0.053475935828877004, \"specificity\": 1.0, \"npv\": 0.38626231493202706, \"accuracy\": 0.40683015053992233, \"f1\": 0.10152284263959391, \"f2\": 0.06596306068601583, \"f0_5\": 0.22026431718061673, \"p4\": 0.17175553836966842, \"phi\": 0.1437210449670422}, {\"truth_threshold\": 35.34, \"match_probability\": 0.9999999999770067, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 629, \"tn\": 7018, \"fp\": 0, \"fn\": 11152, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05339105339105339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9466089466089466, \"precision\": 1.0, \"recall\": 0.05339105339105339, \"specificity\": 1.0, \"npv\": 0.38624105668684644, \"accuracy\": 0.40677695622107557, \"f1\": 0.10136986301369863, \"f2\": 0.06585973656105376, \"f0_5\": 0.21997621878715815, \"p4\": 0.17153551322720564, \"phi\": 0.14360298353232184}, {\"truth_threshold\": 35.38, \"match_probability\": 0.9999999999776356, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 628, \"tn\": 7018, \"fp\": 0, \"fn\": 11153, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05330617095322978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9466938290467702, \"precision\": 1.0, \"recall\": 0.05330617095322978, \"specificity\": 1.0, \"npv\": 0.38621980078146495, \"accuracy\": 0.40672376190222886, \"f1\": 0.1012168587315658, \"f2\": 0.0657564081085609, \"f0_5\": 0.21968795914083816, \"p4\": 0.17131535638667464, \"phi\": 0.14348483796547676}, {\"truth_threshold\": 35.4, \"match_probability\": 0.9999999999779434, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 623, \"tn\": 7018, \"fp\": 0, \"fn\": 11158, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.052881758764111705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9471182412358883, \"precision\": 1.0, \"recall\": 0.052881758764111705, \"specificity\": 1.0, \"npv\": 0.3861135563380282, \"accuracy\": 0.4064577903079951, \"f1\": 0.10045146726862303, \"f2\": 0.06523970092361824, \"f0_5\": 0.21824423737126042, \"p4\": 0.17021259201254216, \"phi\": 0.1428928407647523}, {\"truth_threshold\": 35.42, \"match_probability\": 0.9999999999782471, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 622, \"tn\": 7018, \"fp\": 0, \"fn\": 11159, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05279687632628809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.947203123673712, \"precision\": 1.0, \"recall\": 0.05279687632628809, \"specificity\": 1.0, \"npv\": 0.3860923144633328, \"accuracy\": 0.40640459598914835, \"f1\": 0.10029831492380875, \"f2\": 0.06513634650023038, \"f0_5\": 0.21795500735860956, \"p4\": 0.1699916421608009, \"phi\": 0.14277418596248734}, {\"truth_threshold\": 35.480000000000004, \"match_probability\": 0.9999999999791332, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 620, \"tn\": 7018, \"fp\": 0, \"fn\": 11161, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05262711145064086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9473728885493591, \"precision\": 1.0, \"recall\": 0.05262711145064086, \"specificity\": 1.0, \"npv\": 0.38604983772484736, \"accuracy\": 0.4062982073514549, \"f1\": 0.09999193613418272, \"f2\": 0.06492962466487935, \"f0_5\": 0.21737606058481174, \"p4\": 0.1695493443998627, \"phi\": 0.14253661927886238}, {\"truth_threshold\": 35.5, \"match_probability\": 0.9999999999794205, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 619, \"tn\": 7018, \"fp\": 0, \"fn\": 11162, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05254222901281725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9474577709871828, \"precision\": 1.0, \"recall\": 0.05254222901281725, \"specificity\": 1.0, \"npv\": 0.386028602860286, \"accuracy\": 0.4062450130326081, \"f1\": 0.09983870967741935, \"f2\": 0.06482625725237208, \"f0_5\": 0.21708634355053658, \"p4\": 0.16932799621971234, \"phi\": 0.14241770696434847}, {\"truth_threshold\": 35.52, \"match_probability\": 0.9999999999797038, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 616, \"tn\": 7018, \"fp\": 0, \"fn\": 11165, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05228758169934641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9477124183006536, \"precision\": 1.0, \"recall\": 0.05228758169934641, \"specificity\": 1.0, \"npv\": 0.38596491228070173, \"accuracy\": 0.4060854300760679, \"f1\": 0.09937888198757763, \"f2\": 0.06451612903225806, \"f0_5\": 0.21621621621621623, \"p4\": 0.16866315285098227, \"phi\": 0.1420604515125806}, {\"truth_threshold\": 35.54, \"match_probability\": 0.9999999999799832, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 613, \"tn\": 7018, \"fp\": 0, \"fn\": 11168, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.052032934385875564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9479670656141245, \"precision\": 1.0, \"recall\": 0.052032934385875564, \"specificity\": 1.0, \"npv\": 0.38590124271417575, \"accuracy\": 0.4059258471195276, \"f1\": 0.09891883169275456, \"f2\": 0.06420596183254079, \"f0_5\": 0.2153446216539029, \"p4\": 0.16799710837945928, \"phi\": 0.14170241367589526}, {\"truth_threshold\": 35.56, \"match_probability\": 0.9999999999802588, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 612, \"tn\": 7018, \"fp\": 0, \"fn\": 11169, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05194805194805195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948051948051948, \"precision\": 1.0, \"recall\": 0.05194805194805195, \"specificity\": 1.0, \"npv\": 0.38588002419310496, \"accuracy\": 0.4058726528006809, \"f1\": 0.09876543209876543, \"f2\": 0.0641025641025641, \"f0_5\": 0.21505376344086022, \"p4\": 0.1677748260065324, \"phi\": 0.14158289283136913}, {\"truth_threshold\": 35.58, \"match_probability\": 0.9999999999805306, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 610, \"tn\": 7018, \"fp\": 0, \"fn\": 11171, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05177828707240472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9482217129275953, \"precision\": 1.0, \"recall\": 0.05177828707240472, \"specificity\": 1.0, \"npv\": 0.3858375941503106, \"accuracy\": 0.4057662641629874, \"f1\": 0.09845855863126463, \"f2\": 0.06389575564587087, \"f0_5\": 0.2144715561493566, \"p4\": 0.16732985911510506, \"phi\": 0.1413435874500176}, {\"truth_threshold\": 35.62, \"match_probability\": 0.999999999981063, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 609, \"tn\": 7018, \"fp\": 0, \"fn\": 11172, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05169340463458111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948306595365419, \"precision\": 1.0, \"recall\": 0.05169340463458111, \"specificity\": 1.0, \"npv\": 0.3858163826278175, \"accuracy\": 0.40571306984414063, \"f1\": 0.09830508474576272, \"f2\": 0.06379234491860977, \"f0_5\": 0.21418020679468242, \"p4\": 0.1671071743219754, \"phi\": 0.14122380246201466}, {\"truth_threshold\": 35.660000000000004, \"match_probability\": 0.9999999999815808, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 608, \"tn\": 7018, \"fp\": 0, \"fn\": 11173, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05160852219675749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9483914778032425, \"precision\": 1.0, \"recall\": 0.05160852219675749, \"specificity\": 1.0, \"npv\": 0.3857951734374141, \"accuracy\": 0.4056598755252939, \"f1\": 0.09815158608442974, \"f2\": 0.06368892985837593, \"f0_5\": 0.21388869344965877, \"p4\": 0.16688435511383964, \"phi\": 0.14110392897345803}, {\"truth_threshold\": 35.68, \"match_probability\": 0.9999999999818344, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 606, \"tn\": 7018, \"fp\": 0, \"fn\": 11175, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.051438757321110265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9485612426788897, \"precision\": 1.0, \"recall\": 0.051438757321110265, \"specificity\": 1.0, \"npv\": 0.3857527620513384, \"accuracy\": 0.4055534868876004, \"f1\": 0.09784451441026883, \"f2\": 0.06348208673790069, \"f0_5\": 0.2133051742344245, \"p4\": 0.16643831290124808, \"phi\": 0.14086391558204958}, {\"truth_threshold\": 35.74, \"match_probability\": 0.9999999999825744, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 602, \"tn\": 7018, \"fp\": 0, \"fn\": 11179, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0510992275698158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9489007724301842, \"precision\": 1.0, \"recall\": 0.0510992275698158, \"specificity\": 1.0, \"npv\": 0.3856679672473485, \"accuracy\": 0.4053407096122134, \"f1\": 0.09723007348784624, \"f2\": 0.06306834848929305, \"f0_5\": 0.2121361618154909, \"p4\": 0.16554460942122143, \"phi\": 0.14038281670047986}, {\"truth_threshold\": 35.76, \"match_probability\": 0.9999999999828143, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 597, \"tn\": 7018, \"fp\": 0, \"fn\": 11184, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.050674815380697735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9493251846193023, \"precision\": 1.0, \"recall\": 0.050674815380697735, \"specificity\": 1.0, \"npv\": 0.3855620261509724, \"accuracy\": 0.40507473801797966, \"f1\": 0.09646146388754241, \"f2\": 0.06255107814169862, \"f0_5\": 0.21067118356976497, \"p4\": 0.1644244328955768, \"phi\": 0.1397794136953231}, {\"truth_threshold\": 35.78, \"match_probability\": 0.9999999999830509, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 592, \"tn\": 7018, \"fp\": 0, \"fn\": 11189, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05025040319157966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9497495968084203, \"precision\": 1.0, \"recall\": 0.05025040319157966, \"specificity\": 1.0, \"npv\": 0.38545614324161037, \"accuracy\": 0.40480876642374597, \"f1\": 0.09569223308817587, \"f2\": 0.06203369938804594, \"f0_5\": 0.20920206375008835, \"p4\": 0.16330085434250272, \"phi\": 0.13917372816218657}, {\"truth_threshold\": 35.800000000000004, \"match_probability\": 0.9999999999832843, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 591, \"tn\": 7018, \"fp\": 0, \"fn\": 11190, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.05016552075375605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.949834479246244, \"precision\": 1.0, \"recall\": 0.05016552075375605, \"specificity\": 1.0, \"npv\": 0.3854349736379613, \"accuracy\": 0.4047555721048992, \"f1\": 0.09553831231813772, \"f2\": 0.061930210625589434, \"f0_5\": 0.20890774125132555, \"p4\": 0.1630757288461104, \"phi\": 0.13905231450521982}, {\"truth_threshold\": 35.82, \"match_probability\": 0.9999999999835144, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 587, \"tn\": 7018, \"fp\": 0, \"fn\": 11194, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04982599100246159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9501740089975385, \"precision\": 1.0, \"recall\": 0.04982599100246159, \"specificity\": 1.0, \"npv\": 0.3853503184713376, \"accuracy\": 0.4045427948295122, \"f1\": 0.09492238033635188, \"f2\": 0.0615162121942529, \"f0_5\": 0.207728784768915, \"p4\": 0.1621738562098965, \"phi\": 0.13856572989360888}, {\"truth_threshold\": 35.84, \"match_probability\": 0.9999999999837413, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 585, \"tn\": 7018, \"fp\": 0, \"fn\": 11196, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04965622612681436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9503437738731857, \"precision\": 1.0, \"recall\": 0.04965622612681436, \"specificity\": 1.0, \"npv\": 0.38530800483144834, \"accuracy\": 0.4044364061918187, \"f1\": 0.09461426491994178, \"f2\": 0.061309186945859274, \"f0_5\": 0.207138304652645, \"p4\": 0.16172209552015934, \"phi\": 0.13832187613093627}, {\"truth_threshold\": 35.86, \"match_probability\": 0.9999999999839652, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 582, \"tn\": 7018, \"fp\": 0, \"fn\": 11199, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04940157881334352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9505984211866565, \"precision\": 1.0, \"recall\": 0.04940157881334352, \"specificity\": 1.0, \"npv\": 0.38524455179228195, \"accuracy\": 0.40427682323527847, \"f1\": 0.09415190487745692, \"f2\": 0.06099861652622312, \"f0_5\": 0.20625132893897513, \"p4\": 0.16104342082602335, \"phi\": 0.13795538803460203}, {\"truth_threshold\": 35.88, \"match_probability\": 0.9999999999841859, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 579, \"tn\": 7018, \"fp\": 0, \"fn\": 11202, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.049146931499872676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9508530685001273, \"precision\": 1.0, \"recall\": 0.049146931499872676, \"specificity\": 1.0, \"npv\": 0.38518111964873764, \"accuracy\": 0.40411724027873824, \"f1\": 0.09368932038834951, \"f2\": 0.06068800704358217, \"f0_5\": 0.20536284315811876, \"p4\": 0.16036350231850768, \"phi\": 0.13758804491096155}, {\"truth_threshold\": 35.9, \"match_probability\": 0.9999999999844037, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 576, \"tn\": 7018, \"fp\": 0, \"fn\": 11205, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04889228418640183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9511077158135982, \"precision\": 1.0, \"recall\": 0.04889228418640183, \"specificity\": 1.0, \"npv\": 0.38511770839049553, \"accuracy\": 0.403957657322198, \"f1\": 0.09322651128914786, \"f2\": 0.06037735849056604, \"f0_5\": 0.20447284345047922, \"p4\": 0.15968233613346489, \"phi\": 0.13721983983318134}, {\"truth_threshold\": 35.92, \"match_probability\": 0.9999999999846184, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 571, \"tn\": 7018, \"fp\": 0, \"fn\": 11210, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.048467871997283765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9515321280027162, \"precision\": 1.0, \"recall\": 0.048467871997283765, \"specificity\": 1.0, \"npv\": 0.38501206934386656, \"accuracy\": 0.40369168572796427, \"f1\": 0.09245466321243523, \"f2\": 0.059859524059125695, \"f0_5\": 0.20298613579808034, \"p4\": 0.15854427599618848, \"phi\": 0.13660423014814682}, {\"truth_threshold\": 35.94, \"match_probability\": 0.9999999999848301, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 570, \"tn\": 7018, \"fp\": 0, \"fn\": 11211, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.048382989559460146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9516170104405398, \"precision\": 1.0, \"recall\": 0.048382989559460146, \"specificity\": 1.0, \"npv\": 0.3849909484886719, \"accuracy\": 0.4036384914091175, \"f1\": 0.09230021860578091, \"f2\": 0.059755944143917473, \"f0_5\": 0.20268828675058673, \"p4\": 0.1583162451948701, \"phi\": 0.13648081565265527}, {\"truth_threshold\": 35.96, \"match_probability\": 0.999999999985039, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 569, \"tn\": 7018, \"fp\": 0, \"fn\": 11212, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.048298107121636534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9517018928783635, \"precision\": 1.0, \"recall\": 0.048298107121636534, \"specificity\": 1.0, \"npv\": 0.38496982995063084, \"accuracy\": 0.40358529709027074, \"f1\": 0.09214574898785426, \"f2\": 0.05965235988509844, \"f0_5\": 0.20239026819378245, \"p4\": 0.15808807446419487, \"phi\": 0.1363573030151072}, {\"truth_threshold\": 35.980000000000004, \"match_probability\": 0.9999999999852449, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 568, \"tn\": 7018, \"fp\": 0, \"fn\": 11213, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04821322468381292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.951786775316187, \"precision\": 1.0, \"recall\": 0.04821322468381292, \"specificity\": 1.0, \"npv\": 0.38494871372936207, \"accuracy\": 0.40353210277142404, \"f1\": 0.09199125435257915, \"f2\": 0.05954877128239537, \"f0_5\": 0.2020920799829218, \"p4\": 0.15785976365887916, \"phi\": 0.13623369196633597}, {\"truth_threshold\": 36.0, \"match_probability\": 0.9999999999854481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 566, \"tn\": 7018, \"fp\": 0, \"fn\": 11215, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04804345980816569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9519565401918343, \"precision\": 1.0, \"recall\": 0.04804345980816569, \"specificity\": 1.0, \"npv\": 0.38490648823561674, \"accuracy\": 0.4034257141337305, \"f1\": 0.09168219000566939, \"f2\": 0.05934158104424408, \"f0_5\": 0.20149519401922392, \"p4\": 0.15740272124219581, \"phi\": 0.1359861735524978}, {\"truth_threshold\": 36.02, \"match_probability\": 0.9999999999856485, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 562, \"tn\": 7018, \"fp\": 0, \"fn\": 11219, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.047703930056871235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9522960699431288, \"precision\": 1.0, \"recall\": 0.047703930056871235, \"specificity\": 1.0, \"npv\": 0.384822065032626, \"accuracy\": 0.40321293685834353, \"f1\": 0.09106376083610143, \"f2\": 0.05892714842930839, \"f0_5\": 0.20029937985601254, \"p4\": 0.15648694909852243, \"phi\": 0.1354899438137648}, {\"truth_threshold\": 36.04, \"match_probability\": 0.999999999985846, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 561, \"tn\": 7018, \"fp\": 0, \"fn\": 11220, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.047619047619047616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9523809523809523, \"precision\": 1.0, \"recall\": 0.047619047619047616, \"specificity\": 1.0, \"npv\": 0.3848009650180941, \"accuracy\": 0.40315974253949677, \"f1\": 0.09090909090909091, \"f2\": 0.058823529411764705, \"f0_5\": 0.2, \"p4\": 0.15625765368601519, \"phi\": 0.13536563624883569}, {\"truth_threshold\": 36.06, \"match_probability\": 0.9999999999860408, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 559, \"tn\": 7018, \"fp\": 0, \"fn\": 11222, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04744928274340039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9525507172565996, \"precision\": 1.0, \"recall\": 0.04744928274340039, \"specificity\": 1.0, \"npv\": 0.38475877192982455, \"accuracy\": 0.4030533539018033, \"f1\": 0.0905996758508914, \"f2\": 0.05861627833819181, \"f0_5\": 0.19940072768780767, \"p4\": 0.15579863898159738, \"phi\": 0.13511671901471614}, {\"truth_threshold\": 36.08, \"match_probability\": 0.999999999986233, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 557, \"tn\": 7018, \"fp\": 0, \"fn\": 11224, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04727951786775316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9527204821322468, \"precision\": 1.0, \"recall\": 0.04727951786775316, \"specificity\": 1.0, \"npv\": 0.3847165880934108, \"accuracy\": 0.4029469652641098, \"f1\": 0.09029016047981844, \"f2\": 0.05840900987814853, \"f0_5\": 0.19880077093297166, \"p4\": 0.15533905812304616, \"phi\": 0.134867397100943}, {\"truth_threshold\": 36.1, \"match_probability\": 0.9999999999864225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 555, \"tn\": 7018, \"fp\": 0, \"fn\": 11226, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04710975299210593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.952890247007894, \"precision\": 1.0, \"recall\": 0.04710975299210593, \"specificity\": 1.0, \"npv\": 0.3846744135058101, \"accuracy\": 0.4028405766264163, \"f1\": 0.08998054474708171, \"f2\": 0.05820172402944693, \"f0_5\": 0.19820012856224556, \"p4\": 0.15487890992961065, \"phi\": 0.13461766824099256}, {\"truth_threshold\": 36.14, \"match_probability\": 0.9999999999867939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 553, \"tn\": 7018, \"fp\": 0, \"fn\": 11228, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.046939988116458706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9530600118835413, \"precision\": 1.0, \"recall\": 0.046939988116458706, \"specificity\": 1.0, \"npv\": 0.38463224816398117, \"accuracy\": 0.4027341879887228, \"f1\": 0.08967082860385925, \"f2\": 0.05799442078989869, \"f0_5\": 0.19759879939969985, \"p4\": 0.15441819321728847, \"phi\": 0.13436753014781536}, {\"truth_threshold\": 36.2, \"match_probability\": 0.9999999999873318, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 551, \"tn\": 7018, \"fp\": 0, \"fn\": 11230, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.046770223240811475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9532297767591885, \"precision\": 1.0, \"recall\": 0.046770223240811475, \"specificity\": 1.0, \"npv\": 0.3845900920648838, \"accuracy\": 0.4026277993510293, \"f1\": 0.08936101200129744, \"f2\": 0.057787100157315155, \"f0_5\": 0.19699678226671433, \"p4\": 0.15395690679881469, \"phi\": 0.13411698051357573}, {\"truth_threshold\": 36.22, \"match_probability\": 0.9999999999875062, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 547, \"tn\": 7018, \"fp\": 0, \"fn\": 11234, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04643069348951702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.953569306510483, \"precision\": 1.0, \"recall\": 0.04643069348951702, \"specificity\": 1.0, \"npv\": 0.3845058075827307, \"accuracy\": 0.40241502207564234, \"f1\": 0.08874107722258273, \"f2\": 0.057372406704285624, \"f0_5\": 0.1957906793614432, \"p4\": 0.15303262007797164, \"phi\": 0.13361463728504064}, {\"truth_threshold\": 36.24, \"match_probability\": 0.9999999999876782, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 546, \"tn\": 7018, \"fp\": 0, \"fn\": 11235, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04634581105169341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9536541889483066, \"precision\": 1.0, \"recall\": 0.04634581105169341, \"specificity\": 1.0, \"npv\": 0.3844847422341533, \"accuracy\": 0.4023618277567956, \"f1\": 0.08858603066439523, \"f2\": 0.05726872246696035, \"f0_5\": 0.19548872180451127, \"p4\": 0.15280119046721818, \"phi\": 0.13348879059997176}, {\"truth_threshold\": 36.300000000000004, \"match_probability\": 0.9999999999881801, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 543, \"tn\": 7018, \"fp\": 0, \"fn\": 11238, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.046091163738222564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9539088362617775, \"precision\": 1.0, \"recall\": 0.046091163738222564, \"specificity\": 1.0, \"npv\": 0.38442156003505695, \"accuracy\": 0.40220224480025535, \"f1\": 0.0881207400194742, \"f2\": 0.05695764365284159, \"f0_5\": 0.19458181036336272, \"p4\": 0.15210604020328017, \"phi\": 0.1331106196667973}, {\"truth_threshold\": 36.32, \"match_probability\": 0.9999999999883429, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 541, \"tn\": 7018, \"fp\": 0, \"fn\": 11240, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04592139886257533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9540786011374247, \"precision\": 1.0, \"recall\": 0.04592139886257533, \"specificity\": 1.0, \"npv\": 0.384379450104064, \"accuracy\": 0.4020958561625618, \"f1\": 0.08781042038630092, \"f2\": 0.05675023602223854, \"f0_5\": 0.1939763356041592, \"p4\": 0.15164188733009104, \"phi\": 0.13285797696339538}, {\"truth_threshold\": 36.34, \"match_probability\": 0.9999999999885034, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 540, \"tn\": 7018, \"fp\": 0, \"fn\": 11241, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04583651642475172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9541634835752483, \"precision\": 1.0, \"recall\": 0.04583651642475172, \"specificity\": 1.0, \"npv\": 0.3843583985979517, \"accuracy\": 0.40204266184371507, \"f1\": 0.08765522279035792, \"f2\": 0.05664652567975831, \"f0_5\": 0.19367333763718528, \"p4\": 0.15140959463198547, \"phi\": 0.13273149607506984}, {\"truth_threshold\": 36.36, \"match_probability\": 0.9999999999886616, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 539, \"tn\": 7018, \"fp\": 0, \"fn\": 11242, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0457516339869281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.954248366013072, \"precision\": 1.0, \"recall\": 0.0457516339869281, \"specificity\": 1.0, \"npv\": 0.38433734939759034, \"accuracy\": 0.40198946752486836, \"f1\": 0.0875, \"f2\": 0.05654281098546042, \"f0_5\": 0.19337016574585636, \"p4\": 0.15117715755801162, \"phi\": 0.13260490842025666}, {\"truth_threshold\": 36.38, \"match_probability\": 0.9999999999888177, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 537, \"tn\": 7018, \"fp\": 0, \"fn\": 11244, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04558186911128088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9544181308887191, \"precision\": 1.0, \"recall\": 0.04558186911128088, \"specificity\": 1.0, \"npv\": 0.38429525791260544, \"accuracy\": 0.40188307888717484, \"f1\": 0.08718947881149537, \"f2\": 0.05633536854031598, \"f0_5\": 0.1927632995907818, \"p4\": 0.15071184967662066, \"phi\": 0.13235141157637234}, {\"truth_threshold\": 36.4, \"match_probability\": 0.9999999999889717, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 534, \"tn\": 7018, \"fp\": 0, \"fn\": 11247, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.045327221797810034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.95467277820219, \"precision\": 1.0, \"recall\": 0.045327221797810034, \"specificity\": 1.0, \"npv\": 0.3842321379687928, \"accuracy\": 0.4017234959306346, \"f1\": 0.08672350791717418, \"f2\": 0.05602417222711822, \"f0_5\": 0.19185169217503772, \"p4\": 0.15001280124352193, \"phi\": 0.13197035780643399}, {\"truth_threshold\": 36.42, \"match_probability\": 0.9999999999891236, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 533, \"tn\": 7018, \"fp\": 0, \"fn\": 11248, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04524233935998642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9547576606400136, \"precision\": 1.0, \"recall\": 0.04524233935998642, \"specificity\": 1.0, \"npv\": 0.3842111025949852, \"accuracy\": 0.40167030161178785, \"f1\": 0.0865681338314114, \"f2\": 0.05592043141616132, \"f0_5\": 0.19154747358585494, \"p4\": 0.1497794947274378, \"phi\": 0.13184312302686432}, {\"truth_threshold\": 36.44, \"match_probability\": 0.9999999999892732, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 532, \"tn\": 7018, \"fp\": 0, \"fn\": 11249, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0451574569221628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9548425430778372, \"precision\": 1.0, \"recall\": 0.0451574569221628, \"specificity\": 1.0, \"npv\": 0.38419006952427875, \"accuracy\": 0.4016171072929411, \"f1\": 0.08641273450824331, \"f2\": 0.05581668625146886, \"f0_5\": 0.19124308002013085, \"p4\": 0.14954604277122022, \"phi\": 0.1317157792918728}, {\"truth_threshold\": 36.46, \"match_probability\": 0.9999999999894209, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 524, \"tn\": 7018, \"fp\": 0, \"fn\": 11257, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04447839741957389, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9555216025804261, \"precision\": 1.0, \"recall\": 0.04447839741957389, \"specificity\": 1.0, \"npv\": 0.3840218878248974, \"accuracy\": 0.4011915527421671, \"f1\": 0.08516863063795205, \"f2\": 0.054986568166554735, \"f0_5\": 0.18880161418173957, \"p4\": 0.14767317288615797, \"phi\": 0.13069306846382792}, {\"truth_threshold\": 36.480000000000004, \"match_probability\": 0.9999999999895666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 523, \"tn\": 7018, \"fp\": 0, \"fn\": 11258, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04439351498175027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9556064850182497, \"precision\": 1.0, \"recall\": 0.04439351498175027, \"specificity\": 1.0, \"npv\": 0.3840008754650908, \"accuracy\": 0.4011383584233204, \"f1\": 0.08501300390117035, \"f2\": 0.05488278380590593, \"f0_5\": 0.18849563901102862, \"p4\": 0.14743840506350012, \"phi\": 0.13056472960935786}, {\"truth_threshold\": 36.5, \"match_probability\": 0.9999999999897102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 521, \"tn\": 7018, \"fp\": 0, \"fn\": 11260, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04422375010610305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.955776249893897, \"precision\": 1.0, \"recall\": 0.04422375010610305, \"specificity\": 1.0, \"npv\": 0.3839588576430682, \"accuracy\": 0.4010319697856269, \"f1\": 0.08470167452446757, \"f2\": 0.05467520201490188, \"f0_5\": 0.1878831590335377, \"p4\": 0.14696842832751905, \"phi\": 0.1303077149344268}, {\"truth_threshold\": 36.52, \"match_probability\": 0.9999999999898519, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 520, \"tn\": 7018, \"fp\": 0, \"fn\": 11261, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04413886766827943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9558611323317205, \"precision\": 1.0, \"recall\": 0.04413886766827943, \"specificity\": 1.0, \"npv\": 0.3839378521800974, \"accuracy\": 0.4009787754667801, \"f1\": 0.08454597187220551, \"f2\": 0.054571404583997986, \"f0_5\": 0.1875766539210735, \"p4\": 0.1467332191039385, \"phi\": 0.13017903844406267}, {\"truth_threshold\": 36.54, \"match_probability\": 0.9999999999899916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 519, \"tn\": 7018, \"fp\": 0, \"fn\": 11262, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04405398523045582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9559460147695442, \"precision\": 1.0, \"recall\": 0.04405398523045582, \"specificity\": 1.0, \"npv\": 0.3839168490153173, \"accuracy\": 0.4009255811479334, \"f1\": 0.08439024390243903, \"f2\": 0.05446760279579371, \"f0_5\": 0.18726997185537994, \"p4\": 0.14649786243609947, \"phi\": 0.13005024873580182}, {\"truth_threshold\": 36.58, \"match_probability\": 0.9999999999902653, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 518, \"tn\": 7018, \"fp\": 0, \"fn\": 11263, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.043969102792632206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9560308972073678, \"precision\": 1.0, \"recall\": 0.043969102792632206, \"specificity\": 1.0, \"npv\": 0.38389584814835076, \"accuracy\": 0.40087238682908666, \"f1\": 0.0842344906089926, \"f2\": 0.054363796650014694, \"f0_5\": 0.1869631126831733, \"p4\": 0.14626235816833244, \"phi\": 0.12992134547063294}, {\"truth_threshold\": 36.6, \"match_probability\": 0.9999999999903993, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 517, \"tn\": 7018, \"fp\": 0, \"fn\": 11264, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04388422035480859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9561157796451915, \"precision\": 1.0, \"recall\": 0.04388422035480859, \"specificity\": 1.0, \"npv\": 0.3838748495788207, \"accuracy\": 0.4008191925102399, \"f1\": 0.08407871198568873, \"f2\": 0.05425998614638652, \"f0_5\": 0.18665607625099284, \"p4\": 0.1460267061447508, \"phi\": 0.12979232830790105}, {\"truth_threshold\": 36.62, \"match_probability\": 0.9999999999905315, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 514, \"tn\": 7018, \"fp\": 0, \"fn\": 11267, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04362957304133775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9563704269586623, \"precision\": 1.0, \"recall\": 0.04362957304133775, \"specificity\": 1.0, \"npv\": 0.3838118676510801, \"accuracy\": 0.40065960955369967, \"f1\": 0.08361122407482717, \"f2\": 0.05394852848566271, \"f0_5\": 0.185733901857339, \"p4\": 0.14531886197698884, \"phi\": 0.12940459000288612}, {\"truth_threshold\": 36.64, \"match_probability\": 0.9999999999906618, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 510, \"tn\": 7018, \"fp\": 0, \"fn\": 11271, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04329004329004329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9567099567099567, \"precision\": 1.0, \"recall\": 0.04329004329004329, \"specificity\": 1.0, \"npv\": 0.38372792388867627, \"accuracy\": 0.4004468322783127, \"f1\": 0.08298755186721991, \"f2\": 0.05353319057815846, \"f0_5\": 0.18450184501845018, \"p4\": 0.144372991676644, \"phi\": 0.1288859900716103}, {\"truth_threshold\": 36.68, \"match_probability\": 0.9999999999909172, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 505, \"tn\": 7018, \"fp\": 0, \"fn\": 11276, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04286563110092522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9571343688990748, \"precision\": 1.0, \"recall\": 0.04286563110092522, \"specificity\": 1.0, \"npv\": 0.38362304580736856, \"accuracy\": 0.40018086068407893, \"f1\": 0.08220739052580173, \"f2\": 0.05301392009070104, \"f0_5\": 0.18295775668429823, \"p4\": 0.14318729986759957, \"phi\": 0.12823511205357133}, {\"truth_threshold\": 36.7, \"match_probability\": 0.9999999999910423, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 504, \"tn\": 7018, \"fp\": 0, \"fn\": 11277, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0427807486631016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9572192513368984, \"precision\": 1.0, \"recall\": 0.0427807486631016, \"specificity\": 1.0, \"npv\": 0.38360207707023775, \"accuracy\": 0.40012766636523217, \"f1\": 0.08205128205128205, \"f2\": 0.05291005291005291, \"f0_5\": 0.182648401826484, \"p4\": 0.14294971273330473, \"phi\": 0.12810458245428058}, {\"truth_threshold\": 36.74, \"match_probability\": 0.9999999999912872, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 503, \"tn\": 7018, \"fp\": 0, \"fn\": 11278, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04269586622527799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.957304133774722, \"precision\": 1.0, \"recall\": 0.04269586622527799, \"specificity\": 1.0, \"npv\": 0.3835811106252733, \"accuracy\": 0.40007447204638547, \"f1\": 0.0818951481602084, \"f2\": 0.05280618136771159, \"f0_5\": 0.18233886754150655, \"p4\": 0.14271197563778087, \"phi\": 0.12797393400923573}, {\"truth_threshold\": 36.76, \"match_probability\": 0.9999999999914071, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 500, \"tn\": 7018, \"fp\": 0, \"fn\": 11281, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.042441218911807146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9575587810881928, \"precision\": 1.0, \"recall\": 0.042441218911807146, \"specificity\": 1.0, \"npv\": 0.38351822503961963, \"accuracy\": 0.3999148890898452, \"f1\": 0.0814265939255761, \"f2\": 0.05249454056778095, \"f0_5\": 0.18140918656120747, \"p4\": 0.1419978629908388, \"phi\": 0.12758127192332822}, {\"truth_threshold\": 36.78, \"match_probability\": 0.9999999999915254, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 496, \"tn\": 7018, \"fp\": 0, \"fn\": 11285, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04210168916051269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9578983108394873, \"precision\": 1.0, \"recall\": 0.04210168916051269, \"specificity\": 1.0, \"npv\": 0.38343440965961867, \"accuracy\": 0.3997021118144582, \"f1\": 0.08080149873747658, \"f2\": 0.052078958420831586, \"f0_5\": 0.18016709044678533, \"p4\": 0.1410436036547378, \"phi\": 0.12705603617669625}, {\"truth_threshold\": 36.800000000000004, \"match_probability\": 0.9999999999916421, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 494, \"tn\": 7018, \"fp\": 0, \"fn\": 11287, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04193192428486546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9580680757151345, \"precision\": 1.0, \"recall\": 0.04193192428486546, \"specificity\": 1.0, \"npv\": 0.38339251570609123, \"accuracy\": 0.3995957231767647, \"f1\": 0.0804887983706721, \"f2\": 0.05187114116510563, \"f0_5\": 0.17954495892999928, \"p4\": 0.1405655671829061, \"phi\": 0.12679268882696632}, {\"truth_threshold\": 36.82, \"match_probability\": 0.9999999999917571, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 491, \"tn\": 7018, \"fp\": 0, \"fn\": 11290, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04167727697139462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9583227230286053, \"precision\": 1.0, \"recall\": 0.04167727697139462, \"specificity\": 1.0, \"npv\": 0.38332969193795063, \"accuracy\": 0.3994361402202245, \"f1\": 0.08001955671447197, \"f2\": 0.05155938254751654, \"f0_5\": 0.1786104037831939, \"p4\": 0.13984737534699943, \"phi\": 0.1263967473563198}, {\"truth_threshold\": 36.84, \"match_probability\": 0.9999999999918706, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 490, \"tn\": 7018, \"fp\": 0, \"fn\": 11291, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.041592394533571005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.958407605466429, \"precision\": 1.0, \"recall\": 0.041592394533571005, \"specificity\": 1.0, \"npv\": 0.38330875525697744, \"accuracy\": 0.39938294590137774, \"f1\": 0.07986309184255562, \"f2\": 0.051455454278153484, \"f0_5\": 0.1782985226693836, \"p4\": 0.13960767418775563, \"phi\": 0.1262645198653217}, {\"truth_threshold\": 36.88, \"match_probability\": 0.999999999992093, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 487, \"tn\": 7018, \"fp\": 0, \"fn\": 11294, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04133774722010016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9586622527798998, \"precision\": 1.0, \"recall\": 0.04133774722010016, \"specificity\": 1.0, \"npv\": 0.38324595893403235, \"accuracy\": 0.3992233629448375, \"f1\": 0.07939354417998044, \"f2\": 0.05114364327571359, \"f0_5\": 0.17736178891397772, \"p4\": 0.1388876567985134, \"phi\": 0.12586709090759154}, {\"truth_threshold\": 36.9, \"match_probability\": 0.9999999999922018, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 486, \"tn\": 7018, \"fp\": 0, \"fn\": 11295, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04125286478227655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9587471352177235, \"precision\": 1.0, \"recall\": 0.04125286478227655, \"specificity\": 1.0, \"npv\": 0.3832250313984601, \"accuracy\": 0.39917016862599075, \"f1\": 0.07923697725605282, \"f2\": 0.05103969754253308, \"f0_5\": 0.17704918032786884, \"p4\": 0.13864734582300414, \"phi\": 0.12573436444132668}, {\"truth_threshold\": 36.92, \"match_probability\": 0.9999999999923092, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 483, \"tn\": 7018, \"fp\": 0, \"fn\": 11298, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.040998217468805706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9590017825311943, \"precision\": 1.0, \"recall\": 0.040998217468805706, \"specificity\": 1.0, \"npv\": 0.38316226250272983, \"accuracy\": 0.3990105856694505, \"f1\": 0.07876712328767123, \"f2\": 0.050727834142037936, \"f0_5\": 0.17611026033690658, \"p4\": 0.13792549507668342, \"phi\": 0.12533542900523592}, {\"truth_threshold\": 36.96, \"match_probability\": 0.9999999999925195, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 481, \"tn\": 7018, \"fp\": 0, \"fn\": 11300, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.040828452593158475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9591715474068415, \"precision\": 1.0, \"recall\": 0.040828452593158475, \"specificity\": 1.0, \"npv\": 0.3831204279943225, \"accuracy\": 0.398904197031757, \"f1\": 0.07845375958244985, \"f2\": 0.05051990337149459, \"f0_5\": 0.17548340021889822, \"p4\": 0.1374434947604334, \"phi\": 0.1250688379726812}, {\"truth_threshold\": 36.980000000000004, \"match_probability\": 0.9999999999926225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 477, \"tn\": 7018, \"fp\": 0, \"fn\": 11304, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.04048892284186402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.959511077158136, \"precision\": 1.0, \"recall\": 0.04048892284186402, \"specificity\": 1.0, \"npv\": 0.3830367863770331, \"accuracy\": 0.39869141975637, \"f1\": 0.07782672540381791, \"f2\": 0.05010398941198714, \"f0_5\": 0.17422748191978962, \"p4\": 0.13647764865428139, \"phi\": 0.12453411937784457}, {\"truth_threshold\": 37.0, \"match_probability\": 0.999999999992724, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 474, \"tn\": 7018, \"fp\": 0, \"fn\": 11307, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.040234275528393176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9597657244716068, \"precision\": 1.0, \"recall\": 0.040234275528393176, \"specificity\": 1.0, \"npv\": 0.38297407912687587, \"accuracy\": 0.3985318367998298, \"f1\": 0.07735618115055079, \"f2\": 0.04979200806756586, \"f0_5\": 0.17328361482781313, \"p4\": 0.13575164409309734, \"phi\": 0.1241317228585158}, {\"truth_threshold\": 37.02, \"match_probability\": 0.9999999999928242, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 473, \"tn\": 7018, \"fp\": 0, \"fn\": 11308, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.040149393090569564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9598506069094305, \"precision\": 1.0, \"recall\": 0.040149393090569564, \"specificity\": 1.0, \"npv\": 0.382953181272509, \"accuracy\": 0.398478642480983, \"f1\": 0.07719928186714542, \"f2\": 0.04968800554656806, \"f0_5\": 0.17296862429605792, \"p4\": 0.13550933312258276, \"phi\": 0.12399732985106618}, {\"truth_threshold\": 37.04, \"match_probability\": 0.999999999992923, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 472, \"tn\": 7018, \"fp\": 0, \"fn\": 11309, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.040064510652745945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.959935489347254, \"precision\": 1.0, \"recall\": 0.040064510652745945, \"specificity\": 1.0, \"npv\": 0.3829322856986959, \"accuracy\": 0.39842544816213626, \"f1\": 0.07704235697380234, \"f2\": 0.04958399865534919, \"f0_5\": 0.17265344941107616, \"p4\": 0.13526686715044145, \"phi\": 0.12386280571525803}, {\"truth_threshold\": 37.1, \"match_probability\": 0.9999999999932113, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 471, \"tn\": 7018, \"fp\": 0, \"fn\": 11310, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03997962821492233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9600203717850777, \"precision\": 1.0, \"recall\": 0.03997962821492233, \"specificity\": 1.0, \"npv\": 0.3829113924050633, \"accuracy\": 0.39837225384328956, \"f1\": 0.07688540646425074, \"f2\": 0.04947998739363379, \"f0_5\": 0.17233809001097694, \"p4\": 0.13502424601038074, \"phi\": 0.12372815002097406}, {\"truth_threshold\": 37.14, \"match_probability\": 0.999999999993397, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 470, \"tn\": 7018, \"fp\": 0, \"fn\": 11311, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03989474577709872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9601052542229013, \"precision\": 1.0, \"recall\": 0.03989474577709872, \"specificity\": 1.0, \"npv\": 0.3828905013912379, \"accuracy\": 0.3983190595244428, \"f1\": 0.07672843033221778, \"f2\": 0.049375971761146366, \"f0_5\": 0.17202254593367983, \"p4\": 0.1347814695358721, \"phi\": 0.12359336233580386}, {\"truth_threshold\": 37.2, \"match_probability\": 0.999999999993666, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 469, \"tn\": 7018, \"fp\": 0, \"fn\": 11312, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0398098633392751, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.960190136660725, \"precision\": 1.0, \"recall\": 0.0398098633392751, \"specificity\": 1.0, \"npv\": 0.3828696126568467, \"accuracy\": 0.39826586520559604, \"f1\": 0.07657142857142857, \"f2\": 0.04927195175761141, \"f0_5\": 0.1717068170169144, \"p4\": 0.134538537560151, \"phi\": 0.12345844222502672}, {\"truth_threshold\": 37.22, \"match_probability\": 0.9999999999937531, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 468, \"tn\": 7018, \"fp\": 0, \"fn\": 11313, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03972498090145149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9602750190985485, \"precision\": 1.0, \"recall\": 0.03972498090145149, \"specificity\": 1.0, \"npv\": 0.38284872620151655, \"accuracy\": 0.3982126708867493, \"f1\": 0.07641440117560618, \"f2\": 0.049167927382753406, \"f0_5\": 0.17139090309822017, \"p4\": 0.13429544991621623, \"phi\": 0.12332338925159443}, {\"truth_threshold\": 37.24, \"match_probability\": 0.9999999999938392, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 467, \"tn\": 7018, \"fp\": 0, \"fn\": 11314, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03964009846362788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9603599015363721, \"precision\": 1.0, \"recall\": 0.03964009846362788, \"specificity\": 1.0, \"npv\": 0.3828278420248745, \"accuracy\": 0.39815947656790257, \"f1\": 0.07625734813847158, \"f2\": 0.04906389863629678, \"f0_5\": 0.17107480401494615, \"p4\": 0.13405220643682964, \"phi\": 0.12318820297611376}, {\"truth_threshold\": 37.26, \"match_probability\": 0.999999999993924, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 459, \"tn\": 7018, \"fp\": 0, \"fn\": 11322, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03896103896103896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.961038961038961, \"precision\": 1.0, \"recall\": 0.03896103896103896, \"specificity\": 1.0, \"npv\": 0.3826608505997819, \"accuracy\": 0.3977339220171286, \"f1\": 0.075, \"f2\": 0.04823151125401929, \"f0_5\": 0.16853932584269662, \"p4\": 0.13210062837835718, \"phi\": 0.12210186038337995}, {\"truth_threshold\": 37.28, \"match_probability\": 0.9999999999940076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 457, \"tn\": 7018, \"fp\": 0, \"fn\": 11324, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03879127408539173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9612087259146083, \"precision\": 1.0, \"recall\": 0.03879127408539173, \"specificity\": 1.0, \"npv\": 0.38261912550430704, \"accuracy\": 0.39762753337943507, \"f1\": 0.07468540611210982, \"f2\": 0.048023370673167864, \"f0_5\": 0.16790359321037548, \"p4\": 0.13161116373043716, \"phi\": 0.12182891022967608}, {\"truth_threshold\": 37.36, \"match_probability\": 0.9999999999943309, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 455, \"tn\": 7018, \"fp\": 0, \"fn\": 11326, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.038621509209744505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9613784907902555, \"precision\": 1.0, \"recall\": 0.038621509209744505, \"specificity\": 1.0, \"npv\": 0.3825774095071958, \"accuracy\": 0.3975211447417416, \"f1\": 0.07437070938215103, \"f2\": 0.04781521259379138, \"f0_5\": 0.16726711271230058, \"p4\": 0.13112106831894293, \"phi\": 0.12155540689217555}, {\"truth_threshold\": 37.38, \"match_probability\": 0.9999999999944089, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 454, \"tn\": 7018, \"fp\": 0, \"fn\": 11327, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03853662677192089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9614633732280791, \"precision\": 1.0, \"recall\": 0.03853662677192089, \"specificity\": 1.0, \"npv\": 0.3825565549195966, \"accuracy\": 0.39746795042289484, \"f1\": 0.07421332243563547, \"f2\": 0.047711126991466644, \"f0_5\": 0.16694859160108846, \"p4\": 0.13087578365141633, \"phi\": 0.12141844660548227}, {\"truth_threshold\": 37.42, \"match_probability\": 0.9999999999945618, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 453, \"tn\": 7018, \"fp\": 0, \"fn\": 11328, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.038451744334097274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9615482556659027, \"precision\": 1.0, \"recall\": 0.038451744334097274, \"specificity\": 1.0, \"npv\": 0.3825357026054726, \"accuracy\": 0.3974147561040481, \"f1\": 0.07405590975968612, \"f2\": 0.04760703701368308, \"f0_5\": 0.16662988302802914, \"p4\": 0.1306303407819838, \"phi\": 0.12128134660882481}, {\"truth_threshold\": 37.44, \"match_probability\": 0.9999999999946366, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 452, \"tn\": 7018, \"fp\": 0, \"fn\": 11329, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03836686189627366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9616331381037263, \"precision\": 1.0, \"recall\": 0.03836686189627366, \"specificity\": 1.0, \"npv\": 0.38251485256445195, \"accuracy\": 0.3973615617852013, \"f1\": 0.07389847134799313, \"f2\": 0.04750294266016479, \"f0_5\": 0.16631098682758114, \"p4\": 0.13038473953980148, \"phi\": 0.12114410642542132}, {\"truth_threshold\": 37.46, \"match_probability\": 0.9999999999947105, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 451, \"tn\": 7018, \"fp\": 0, \"fn\": 11330, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03828197945845005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96171802054155, \"precision\": 1.0, \"recall\": 0.03828197945845005, \"specificity\": 1.0, \"npv\": 0.3824940047961631, \"accuracy\": 0.3973083674663546, \"f1\": 0.0737410071942446, \"f2\": 0.047398843930635835, \"f0_5\": 0.1659919028340081, \"p4\": 0.13013897975378172, \"phi\": 0.12100672557584148}, {\"truth_threshold\": 37.480000000000004, \"match_probability\": 0.9999999999947833, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 448, \"tn\": 7018, \"fp\": 0, \"fn\": 11333, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.038027332144979206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9619726678550208, \"precision\": 1.0, \"recall\": 0.038027332144979206, \"specificity\": 1.0, \"npv\": 0.38243147512397146, \"accuracy\": 0.39714878450981433, \"f1\": 0.07326846021751574, \"f2\": 0.047086521483225424, \"f0_5\": 0.16503352243424446, \"p4\": 0.12940074741815472, \"phi\": 0.12059373419557756}, {\"truth_threshold\": 37.5, \"match_probability\": 0.9999999999948551, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 445, \"tn\": 7018, \"fp\": 0, \"fn\": 11336, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03777268483150836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9622273151684917, \"precision\": 1.0, \"recall\": 0.03777268483150836, \"specificity\": 1.0, \"npv\": 0.38236896589299335, \"accuracy\": 0.3969892015532741, \"f1\": 0.07279568133486014, \"f2\": 0.04677415964178352, \"f0_5\": 0.1640734459110685, \"p4\": 0.1286610820053366, \"phi\": 0.12017945930160365}, {\"truth_threshold\": 37.54, \"match_probability\": 0.9999999999949958, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 442, \"tn\": 7018, \"fp\": 0, \"fn\": 11339, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03751803751803752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9624819624819625, \"precision\": 1.0, \"recall\": 0.03751803751803752, \"specificity\": 1.0, \"npv\": 0.382306477093207, \"accuracy\": 0.3968296185967339, \"f1\": 0.07232267037552156, \"f2\": 0.04646175839885633, \"f0_5\": 0.16311166875784192, \"p4\": 0.12791997885620185, \"phi\": 0.11976388750776125}, {\"truth_threshold\": 37.6, \"match_probability\": 0.9999999999951996, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 439, \"tn\": 7018, \"fp\": 0, \"fn\": 11342, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.037263390204566677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9627366097954333, \"precision\": 1.0, \"recall\": 0.037263390204566677, \"specificity\": 1.0, \"npv\": 0.38224400871459696, \"accuracy\": 0.39667003564019365, \"f1\": 0.0718494271685761, \"f2\": 0.0461493177469882, \"f0_5\": 0.1621481864519465, \"p4\": 0.12717743329159104, \"phi\": 0.1193470051995014}, {\"truth_threshold\": 37.62, \"match_probability\": 0.9999999999952658, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 437, \"tn\": 7018, \"fp\": 0, \"fn\": 11344, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.037093625328919445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629063746710805, \"precision\": 1.0, \"recall\": 0.037093625328919445, \"specificity\": 1.0, \"npv\": 0.38220237446901206, \"accuracy\": 0.39656364700250013, \"f1\": 0.071533802586348, \"f2\": 0.045941002081537397, \"f0_5\": 0.16150491536698944, \"p4\": 0.12668159925344227, \"phi\": 0.119068348768163}, {\"truth_threshold\": 37.64, \"match_probability\": 0.999999999995331, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 436, \"tn\": 7018, \"fp\": 0, \"fn\": 11345, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03700874289109583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629912571089042, \"precision\": 1.0, \"recall\": 0.03700874289109583, \"specificity\": 1.0, \"npv\": 0.3821815607471546, \"accuracy\": 0.39651045268365337, \"f1\": 0.07137595154293198, \"f2\": 0.04583683767872161, \"f0_5\": 0.16118299445471349, \"p4\": 0.12643344061220296, \"phi\": 0.11892879852840171}, {\"truth_threshold\": 37.68, \"match_probability\": 0.9999999999954586, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 434, \"tn\": 7018, \"fp\": 0, \"fn\": 11347, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0368389780154486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9631610219845514, \"precision\": 1.0, \"recall\": 0.0368389780154486, \"specificity\": 1.0, \"npv\": 0.38213994010345764, \"accuracy\": 0.3964040640459599, \"f1\": 0.07106017191977078, \"f2\": 0.045628495731527816, \"f0_5\": 0.16053858104609012, \"p4\": 0.12593663921015075, \"phi\": 0.1186492513768887}, {\"truth_threshold\": 37.7, \"match_probability\": 0.9999999999955211, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 433, \"tn\": 7018, \"fp\": 0, \"fn\": 11348, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03675409557762499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.963245904422375, \"precision\": 1.0, \"recall\": 0.03675409557762499, \"specificity\": 1.0, \"npv\": 0.3821191331808777, \"accuracy\": 0.39635086972711314, \"f1\": 0.07090224332732929, \"f2\": 0.045524318186597135, \"f0_5\": 0.16021608821135203, \"p4\": 0.12568799609848602, \"phi\": 0.11850925340651335}, {\"truth_threshold\": 37.72, \"match_probability\": 0.9999999999955828, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 428, \"tn\": 7018, \"fp\": 0, \"fn\": 11353, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.036329683388506916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.963670316611493, \"precision\": 1.0, \"recall\": 0.036329683388506916, \"specificity\": 1.0, \"npv\": 0.38201513254586034, \"accuracy\": 0.3960848981328794, \"f1\": 0.07011221230239986, \"f2\": 0.04500336473755047, \"f0_5\": 0.15860075594752834, \"p4\": 0.12444234939402017, \"phi\": 0.11780699815804498}, {\"truth_threshold\": 37.74, \"match_probability\": 0.9999999999956436, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 424, \"tn\": 7018, \"fp\": 0, \"fn\": 11357, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03599015363721246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9640098463627875, \"precision\": 1.0, \"recall\": 0.03599015363721246, \"specificity\": 1.0, \"npv\": 0.38193197278911567, \"accuracy\": 0.3958721208574924, \"f1\": 0.06947972142564522, \"f2\": 0.04458652309245394, \"f0_5\": 0.1573050382132522, \"p4\": 0.12344290404979098, \"phi\": 0.11724244274000742}, {\"truth_threshold\": 37.76, \"match_probability\": 0.9999999999957035, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 421, \"tn\": 7018, \"fp\": 0, \"fn\": 11360, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03573550632374162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9642644936762583, \"precision\": 1.0, \"recall\": 0.03573550632374162, \"specificity\": 1.0, \"npv\": 0.3818696267276091, \"accuracy\": 0.3957125379009522, \"f1\": 0.0690050811342403, \"f2\": 0.04427384583026606, \"f0_5\": 0.15633122911251393, \"p4\": 0.12269160459439588, \"phi\": 0.11681739793699107}, {\"truth_threshold\": 37.78, \"match_probability\": 0.9999999999957627, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 418, \"tn\": 7018, \"fp\": 0, \"fn\": 11363, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.035480859010270774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9645191409897292, \"precision\": 1.0, \"recall\": 0.035480859010270774, \"specificity\": 1.0, \"npv\": 0.3818073010173549, \"accuracy\": 0.39555295494441195, \"f1\": 0.06853020739404869, \"f2\": 0.04396112910689495, \"f0_5\": 0.1553556827473426, \"p4\": 0.12193882939930893, \"phi\": 0.11639094043991904}, {\"truth_threshold\": 37.800000000000004, \"match_probability\": 0.999999999995821, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 410, \"tn\": 7018, \"fp\": 0, \"fn\": 11371, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03480179950768186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9651982004923182, \"precision\": 1.0, \"recall\": 0.03480179950768186, \"specificity\": 1.0, \"npv\": 0.381641198542607, \"accuracy\": 0.395127400393638, \"f1\": 0.06726273480436387, \"f2\": 0.04312702486641141, \"f0_5\": 0.15274569704194918, \"p4\": 0.11992417725144995, \"phi\": 0.11524669398968118}, {\"truth_threshold\": 37.82, \"match_probability\": 0.9999999999958786, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 408, \"tn\": 7018, \"fp\": 0, \"fn\": 11373, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03463203463203463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9653679653679653, \"precision\": 1.0, \"recall\": 0.03463203463203463, \"specificity\": 1.0, \"npv\": 0.3815996955032353, \"accuracy\": 0.39502101175594445, \"f1\": 0.06694560669456066, \"f2\": 0.04291845493562232, \"f0_5\": 0.1520912547528517, \"p4\": 0.11941885828475773, \"phi\": 0.11495900952183745}, {\"truth_threshold\": 37.84, \"match_probability\": 0.9999999999959354, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 405, \"tn\": 7018, \"fp\": 0, \"fn\": 11376, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03437738731856379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9656226126814362, \"precision\": 1.0, \"recall\": 0.03437738731856379, \"specificity\": 1.0, \"npv\": 0.3815374578666957, \"accuracy\": 0.3948614287994042, \"f1\": 0.06646971935007386, \"f2\": 0.04260556712743799, \"f0_5\": 0.1511081262592344, \"p4\": 0.11865963197892299, \"phi\": 0.11452624575014939}, {\"truth_threshold\": 37.86, \"match_probability\": 0.9999999999959913, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 403, \"tn\": 7018, \"fp\": 0, \"fn\": 11378, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03420762244291656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9657923775570835, \"precision\": 1.0, \"recall\": 0.03420762244291656, \"specificity\": 1.0, \"npv\": 0.38149597738638835, \"accuracy\": 0.3947550401617107, \"f1\": 0.06615233092580433, \"f2\": 0.04239695331074968, \"f0_5\": 0.15045172851489585, \"p4\": 0.1181526470719522, \"phi\": 0.11423690453581542}, {\"truth_threshold\": 37.88, \"match_probability\": 0.9999999999960465, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 401, \"tn\": 7018, \"fp\": 0, \"fn\": 11380, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03403785756726933, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9659621424327307, \"precision\": 1.0, \"recall\": 0.03403785756726933, \"specificity\": 1.0, \"npv\": 0.38145450592455704, \"accuracy\": 0.39464865152401724, \"f1\": 0.06583483828599573, \"f2\": 0.04218832193582325, \"f0_5\": 0.14979454613373178, \"p4\": 0.11764499322423183, \"phi\": 0.11394689175687578}, {\"truth_threshold\": 37.9, \"match_probability\": 0.9999999999961009, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 397, \"tn\": 7018, \"fp\": 0, \"fn\": 11384, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03369832781597488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9663016721840251, \"precision\": 1.0, \"recall\": 0.03369832781597488, \"specificity\": 1.0, \"npv\": 0.3813715900445604, \"accuracy\": 0.39443587424863025, \"f1\": 0.06519954015437675, \"f2\": 0.041771006502388415, \"f0_5\": 0.14847782182661382, \"p4\": 0.11662767281465175, \"phi\": 0.113364830794304}, {\"truth_threshold\": 37.96, \"match_probability\": 0.9999999999962598, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 396, \"tn\": 7018, \"fp\": 0, \"fn\": 11385, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03361344537815126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9663865546218487, \"precision\": 1.0, \"recall\": 0.03361344537815126, \"specificity\": 1.0, \"npv\": 0.38135086670651525, \"accuracy\": 0.3943826799297835, \"f1\": 0.06504065040650407, \"f2\": 0.041666666666666664, \"f0_5\": 0.14814814814814814, \"p4\": 0.11637292231925032, \"phi\": 0.11321888768200336}, {\"truth_threshold\": 37.980000000000004, \"match_probability\": 0.9999999999963113, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 395, \"tn\": 7018, \"fp\": 0, \"fn\": 11386, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03352856294032765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9664714370596723, \"precision\": 1.0, \"recall\": 0.03352856294032765, \"specificity\": 1.0, \"npv\": 0.38133014562051726, \"accuracy\": 0.3943294856109367, \"f1\": 0.06488173455978975, \"f2\": 0.04156232243944528, \"f0_5\": 0.14781827707506923, \"p4\": 0.11611800329612085, \"phi\": 0.11307277209161284}, {\"truth_threshold\": 38.0, \"match_probability\": 0.999999999996362, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 394, \"tn\": 7018, \"fp\": 0, \"fn\": 11387, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.033443680502504035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.966556319497496, \"precision\": 1.0, \"recall\": 0.033443680502504035, \"specificity\": 1.0, \"npv\": 0.3813094267861994, \"accuracy\": 0.39427629129209, \"f1\": 0.06472279260780288, \"f2\": 0.04145797382044699, \"f0_5\": 0.14748820843003668, \"p4\": 0.11586291555952824, \"phi\": 0.11292648335103066}, {\"truth_threshold\": 38.02, \"match_probability\": 0.9999999999964121, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 392, \"tn\": 7018, \"fp\": 0, \"fn\": 11389, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.033273915626856804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9667260843731432, \"precision\": 1.0, \"recall\": 0.033273915626856804, \"specificity\": 1.0, \"npv\": 0.38126799587113597, \"accuracy\": 0.3941699026543965, \"f1\": 0.06440483036227718, \"f2\": 0.04124926340601061, \"f0_5\": 0.14682747771368643, \"p4\": 0.11535223320165934, \"phi\": 0.11263338370943565}, {\"truth_threshold\": 38.04, \"match_probability\": 0.9999999999964615, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 386, \"tn\": 7018, \"fp\": 0, \"fn\": 11395, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03276462099991512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9672353790000848, \"precision\": 1.0, \"recall\": 0.03276462099991512, \"specificity\": 1.0, \"npv\": 0.381143757128116, \"accuracy\": 0.39385073674131604, \"f1\": 0.06345031642968686, \"f2\": 0.040623026731214484, \"f0_5\": 0.1448405253283302, \"p4\": 0.113816117604347, \"phi\": 0.11174985793631426}, {\"truth_threshold\": 38.06, \"match_probability\": 0.9999999999965102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 385, \"tn\": 7018, \"fp\": 0, \"fn\": 11396, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.032679738562091505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9673202614379085, \"precision\": 1.0, \"recall\": 0.032679738562091505, \"specificity\": 1.0, \"npv\": 0.3811230585424134, \"accuracy\": 0.3937975424224693, \"f1\": 0.06329113924050633, \"f2\": 0.04051863857374392, \"f0_5\": 0.14450867052023122, \"p4\": 0.11355950304367947, \"phi\": 0.11160197988006648}, {\"truth_threshold\": 38.08, \"match_probability\": 0.9999999999965583, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 382, \"tn\": 7018, \"fp\": 0, \"fn\": 11399, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03242509124862066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9675749087513793, \"precision\": 1.0, \"recall\": 0.03242509124862066, \"specificity\": 1.0, \"npv\": 0.3810609762719227, \"accuracy\": 0.39363795946592905, \"f1\": 0.06281345062895667, \"f2\": 0.04020544773291795, \"f0_5\": 0.1435119092343527, \"p4\": 0.11278863509173662, \"phi\": 0.11115726214200117}, {\"truth_threshold\": 38.12, \"match_probability\": 0.9999999999966523, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 378, \"tn\": 7018, \"fp\": 0, \"fn\": 11403, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03208556149732621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9679144385026738, \"precision\": 1.0, \"recall\": 0.03208556149732621, \"specificity\": 1.0, \"npv\": 0.3809782313663753, \"accuracy\": 0.39342518219054207, \"f1\": 0.06217616580310881, \"f2\": 0.03978779840848806, \"f0_5\": 0.14218009478672985, \"p4\": 0.11175841412825092, \"phi\": 0.1105617495865926}, {\"truth_threshold\": 38.14, \"match_probability\": 0.9999999999966984, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 375, \"tn\": 7018, \"fp\": 0, \"fn\": 11406, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03183091418385536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9681690858161447, \"precision\": 1.0, \"recall\": 0.03183091418385536, \"specificity\": 1.0, \"npv\": 0.38091619626574036, \"accuracy\": 0.3932655992340018, \"f1\": 0.061697926949654494, \"f2\": 0.039474515252952695, \"f0_5\": 0.141179128077705, \"p4\": 0.11098394398540085, \"phi\": 0.11011317248438256}, {\"truth_threshold\": 38.160000000000004, \"match_probability\": 0.9999999999967439, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 373, \"tn\": 7018, \"fp\": 0, \"fn\": 11408, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03166114930820813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9683388506917918, \"precision\": 1.0, \"recall\": 0.03166114930820813, \"specificity\": 1.0, \"npv\": 0.38087485075436883, \"accuracy\": 0.3931592105963083, \"f1\": 0.061378969886457135, \"f2\": 0.03926563782975767, \"f0_5\": 0.14051081142168312, \"p4\": 0.1104667684467376, \"phi\": 0.10981318462496005}, {\"truth_threshold\": 38.18, \"match_probability\": 0.9999999999967888, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 370, \"tn\": 7018, \"fp\": 0, \"fn\": 11411, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03140650199473729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9685934980052627, \"precision\": 1.0, \"recall\": 0.03140650199473729, \"specificity\": 1.0, \"npv\": 0.38081284931358184, \"accuracy\": 0.3929996276397681, \"f1\": 0.06090033742078841, \"f2\": 0.03895228871015286, \"f0_5\": 0.13950682452303748, \"p4\": 0.10968970814028282, \"phi\": 0.10936178268293088}, {\"truth_threshold\": 38.2, \"match_probability\": 0.999999999996833, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 368, \"tn\": 7018, \"fp\": 0, \"fn\": 11413, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03123673711909006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96876326288091, \"precision\": 1.0, \"recall\": 0.03123673711909006, \"specificity\": 1.0, \"npv\": 0.38077152623297705, \"accuracy\": 0.39289323900207457, \"f1\": 0.06058111778747222, \"f2\": 0.038743367303966984, \"f0_5\": 0.1388364898513544, \"p4\": 0.10917080102601677, \"phi\": 0.10905989211151004}, {\"truth_threshold\": 38.24, \"match_probability\": 0.9999999999969196, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 366, \"tn\": 7018, \"fp\": 0, \"fn\": 11415, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03106697224344283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9689330277565572, \"precision\": 1.0, \"recall\": 0.03106697224344283, \"specificity\": 1.0, \"npv\": 0.38073021211956815, \"accuracy\": 0.3927868503643811, \"f1\": 0.06026179303531736, \"f2\": 0.03853442830069488, \"f0_5\": 0.13816534541336353, \"p4\": 0.10865119858237568, \"phi\": 0.10875722933285274}, {\"truth_threshold\": 38.26, \"match_probability\": 0.999999999996962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 365, \"tn\": 7018, \"fp\": 0, \"fn\": 11416, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.030982089805619218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9690179101943808, \"precision\": 1.0, \"recall\": 0.030982089805619218, \"specificity\": 1.0, \"npv\": 0.3807095584246501, \"accuracy\": 0.39273365604553434, \"f1\": 0.06010209122344805, \"f2\": 0.03842995219945672, \"f0_5\": 0.13782946907333282, \"p4\": 0.10839113612809938, \"phi\": 0.10860560634226092}, {\"truth_threshold\": 38.28, \"match_probability\": 0.9999999999970038, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 363, \"tn\": 7018, \"fp\": 0, \"fn\": 11418, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.03081232492997199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969187675070028, \"precision\": 1.0, \"recall\": 0.03081232492997199, \"specificity\": 1.0, \"npv\": 0.38066825775656327, \"accuracy\": 0.3926272674078408, \"f1\": 0.059782608695652176, \"f2\": 0.03822098679638638, \"f0_5\": 0.1371571072319202, \"p4\": 0.10787048778425902, \"phi\": 0.10830177306268608}, {\"truth_threshold\": 38.300000000000004, \"match_probability\": 0.999999999997045, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 362, \"tn\": 7018, \"fp\": 0, \"fn\": 11419, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.030727442492148375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9692725575078516, \"precision\": 1.0, \"recall\": 0.030727442492148375, \"specificity\": 1.0, \"npv\": 0.3806476107826653, \"accuracy\": 0.3925740730889941, \"f1\": 0.059622827966729804, \"f2\": 0.03811649749399823, \"f0_5\": 0.1368206213621589, \"p4\": 0.10760990150568622, \"phi\": 0.10814956111837914}, {\"truth_threshold\": 38.38, \"match_probability\": 0.9999999999972045, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 358, \"tn\": 7018, \"fp\": 0, \"fn\": 11423, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.030387912740853916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969612087259146, \"precision\": 1.0, \"recall\": 0.030387912740853916, \"specificity\": 1.0, \"npv\": 0.38056504527954016, \"accuracy\": 0.3923612958136071, \"f1\": 0.058983441799159736, \"f2\": 0.0376984962722716, \"f0_5\": 0.13547264058124575, \"p4\": 0.10656580446187501, \"phi\": 0.10753872506299202}, {\"truth_threshold\": 38.4, \"match_probability\": 0.9999999999972429, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 357, \"tn\": 7018, \"fp\": 0, \"fn\": 11424, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.030303030303030304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9696969696969697, \"precision\": 1.0, \"recall\": 0.030303030303030304, \"specificity\": 1.0, \"npv\": 0.38054440950005425, \"accuracy\": 0.39230810149476036, \"f1\": 0.058823529411764705, \"f2\": 0.03759398496240601, \"f0_5\": 0.13513513513513514, \"p4\": 0.1063043412402678, \"phi\": 0.10738551472488697}, {\"truth_threshold\": 38.42, \"match_probability\": 0.9999999999972808, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 353, \"tn\": 7018, \"fp\": 0, \"fn\": 11428, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.029963500551735845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9700364994482642, \"precision\": 1.0, \"recall\": 0.029963500551735845, \"specificity\": 1.0, \"npv\": 0.38046188875636994, \"accuracy\": 0.3920953242193734, \"f1\": 0.058183616284819516, \"f2\": 0.03717589569686375, \"f0_5\": 0.13378306677783672, \"p4\": 0.10525672661987115, \"phi\": 0.10677064209634571}, {\"truth_threshold\": 38.44, \"match_probability\": 0.9999999999973184, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 350, \"tn\": 7018, \"fp\": 0, \"fn\": 11431, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.029708853238265002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970291146761735, \"precision\": 1.0, \"recall\": 0.029708853238265002, \"specificity\": 1.0, \"npv\": 0.3804000216813919, \"accuracy\": 0.39193574126283315, \"f1\": 0.05770340450086555, \"f2\": 0.03686228251253318, \"f0_5\": 0.1327668613913967, \"p4\": 0.10446916031088879, \"phi\": 0.10630733001992523}, {\"truth_threshold\": 38.480000000000004, \"match_probability\": 0.9999999999973916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 348, \"tn\": 7018, \"fp\": 0, \"fn\": 11433, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.029539088362617774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9704609116373822, \"precision\": 1.0, \"recall\": 0.029539088362617774, \"specificity\": 1.0, \"npv\": 0.38035878814156415, \"accuracy\": 0.3918293526251396, \"f1\": 0.05738313133811526, \"f2\": 0.03665318503538928, \"f0_5\": 0.13208836255978137, \"p4\": 0.10394322963818707, \"phi\": 0.10599741436663386}, {\"truth_threshold\": 38.56, \"match_probability\": 0.9999999999975323, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 345, \"tn\": 7018, \"fp\": 0, \"fn\": 11436, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02928444104914693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970715558950853, \"precision\": 1.0, \"recall\": 0.02928444104914693, \"specificity\": 1.0, \"npv\": 0.38029695458979085, \"accuracy\": 0.3916697696685994, \"f1\": 0.05690252350321623, \"f2\": 0.036339505782721354, \"f0_5\": 0.1310690677000228, \"p4\": 0.10315299995181498, \"phi\": 0.10553096108656851}, {\"truth_threshold\": 38.58, \"match_probability\": 0.9999999999975663, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 341, \"tn\": 7018, \"fp\": 0, \"fn\": 11440, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.028944911297852476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9710550887021475, \"precision\": 1.0, \"recall\": 0.028944911297852476, \"specificity\": 1.0, \"npv\": 0.3802145411203814, \"accuracy\": 0.3914569923932124, \"f1\": 0.056261343012704176, \"f2\": 0.03592120509849363, \"f0_5\": 0.1297071129707113, \"p4\": 0.10209686244954005, \"phi\": 0.10490603494024126}, {\"truth_threshold\": 38.64, \"match_probability\": 0.9999999999976654, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 340, \"tn\": 7018, \"fp\": 0, \"fn\": 11441, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02886002886002886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9711399711399712, \"precision\": 1.0, \"recall\": 0.02886002886002886, \"specificity\": 1.0, \"npv\": 0.3801939433338751, \"accuracy\": 0.39140379807436565, \"f1\": 0.056100981767180924, \"f2\": 0.03581661891117478, \"f0_5\": 0.129366106080207, \"p4\": 0.1018323806801425, \"phi\": 0.10474926337222526}, {\"truth_threshold\": 38.660000000000004, \"match_probability\": 0.9999999999976976, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 336, \"tn\": 7018, \"fp\": 0, \"fn\": 11445, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0285204991087344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9714795008912656, \"precision\": 1.0, \"recall\": 0.0285204991087344, \"specificity\": 1.0, \"npv\": 0.38011157450035205, \"accuracy\": 0.39119102079897866, \"f1\": 0.05545927209705372, \"f2\": 0.035398230088495575, \"f0_5\": 0.128, \"p4\": 0.1007726579856507, \"phi\": 0.10411998761888575}, {\"truth_threshold\": 38.7, \"match_probability\": 0.9999999999977606, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 333, \"tn\": 7018, \"fp\": 0, \"fn\": 11448, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02826585179526356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9717341482047365, \"precision\": 1.0, \"recall\": 0.02826585179526356, \"specificity\": 1.0, \"npv\": 0.3800498212931875, \"accuracy\": 0.39103143784243843, \"f1\": 0.0549777117384844, \"f2\": 0.03508439218661104, \"f0_5\": 0.1269732326698696, \"p4\": 0.09997597490301408, \"phi\": 0.103645703835179}, {\"truth_threshold\": 38.72, \"match_probability\": 0.9999999999977914, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 332, \"tn\": 7018, \"fp\": 0, \"fn\": 11449, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.028180969357439946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.97181903064256, \"precision\": 1.0, \"recall\": 0.028180969357439946, \"specificity\": 1.0, \"npv\": 0.3800292413494341, \"accuracy\": 0.3909782435235917, \"f1\": 0.05481713861140923, \"f2\": 0.034979770734996626, \"f0_5\": 0.1266305591578305, \"p4\": 0.0997100525907474, \"phi\": 0.10348716058236186}, {\"truth_threshold\": 38.76, \"match_probability\": 0.9999999999978518, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 330, \"tn\": 7018, \"fp\": 0, \"fn\": 11451, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.028011204481792718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9719887955182073, \"precision\": 1.0, \"recall\": 0.028011204481792718, \"specificity\": 1.0, \"npv\": 0.37998808814770696, \"accuracy\": 0.3908718548858982, \"f1\": 0.05449591280653951, \"f2\": 0.03477051460361613, \"f0_5\": 0.12594458438287154, \"p4\": 0.09917766481680113, \"phi\": 0.10316939486955856}, {\"truth_threshold\": 38.84, \"match_probability\": 0.9999999999979676, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 329, \"tn\": 7018, \"fp\": 0, \"fn\": 11452, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.027926322043969103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.972073677956031, \"precision\": 1.0, \"recall\": 0.027926322043969103, \"specificity\": 1.0, \"npv\": 0.3799675148890092, \"accuracy\": 0.39081866056705145, \"f1\": 0.05433526011560694, \"f2\": 0.03466587992329252, \"f0_5\": 0.12560128273650453, \"p4\": 0.0989111989466137, \"phi\": 0.10301017030874716}, {\"truth_threshold\": 38.86, \"match_probability\": 0.9999999999979956, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 327, \"tn\": 7018, \"fp\": 0, \"fn\": 11454, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.027756557168321875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9722434428316781, \"precision\": 1.0, \"recall\": 0.027756557168321875, \"specificity\": 1.0, \"npv\": 0.379926375054136, \"accuracy\": 0.3907122719293579, \"f1\": 0.05401387512388504, \"f2\": 0.03445659733198457, \"f0_5\": 0.12491404996561999, \"p4\": 0.09837772221625282, \"phi\": 0.10269103246605042}, {\"truth_threshold\": 38.88, \"match_probability\": 0.9999999999980232, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 324, \"tn\": 7018, \"fp\": 0, \"fn\": 11457, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02750190985485103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.972498090145149, \"precision\": 1.0, \"recall\": 0.02750190985485103, \"specificity\": 1.0, \"npv\": 0.37986468200270634, \"accuracy\": 0.3905526889728177, \"f1\": 0.053531598513011154, \"f2\": 0.03414264036418816, \"f0_5\": 0.12388162422573985, \"p4\": 0.09757614156589223, \"phi\": 0.1022105877171249}, {\"truth_threshold\": 38.9, \"match_probability\": 0.9999999999980504, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 322, \"tn\": 7018, \"fp\": 0, \"fn\": 11459, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.027332144979203804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9726678550207962, \"precision\": 1.0, \"recall\": 0.027332144979203804, \"specificity\": 1.0, \"npv\": 0.3798235644314553, \"accuracy\": 0.39044630033512423, \"f1\": 0.05320994794679005, \"f2\": 0.03393331366184715, \"f0_5\": 0.12319228709159079, \"p4\": 0.09704084169316171, \"phi\": 0.10188911978007512}, {\"truth_threshold\": 38.92, \"match_probability\": 0.9999999999980773, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 319, \"tn\": 7018, \"fp\": 0, \"fn\": 11462, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02707749766573296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.972922502334267, \"precision\": 1.0, \"recall\": 0.02707749766573296, \"specificity\": 1.0, \"npv\": 0.37976190476190474, \"accuracy\": 0.39028671737858395, \"f1\": 0.05272727272727273, \"f2\": 0.0336192905170415, \"f0_5\": 0.12215669755686605, \"p4\": 0.09623651859114564, \"phi\": 0.101405138379299}, {\"truth_threshold\": 38.94, \"match_probability\": 0.9999999999981037, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 317, \"tn\": 7018, \"fp\": 0, \"fn\": 11464, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02690773279008573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9730922672099143, \"precision\": 1.0, \"recall\": 0.02690773279008573, \"specificity\": 1.0, \"npv\": 0.37972080943620823, \"accuracy\": 0.3901803287408905, \"f1\": 0.0524053562572326, \"f2\": 0.03340991968971986, \"f0_5\": 0.12146524637903287, \"p4\": 0.0956993852405422, \"phi\": 0.10108128449492791}, {\"truth_threshold\": 39.0, \"match_probability\": 0.999999999998181, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 314, \"tn\": 7018, \"fp\": 0, \"fn\": 11467, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02665308547661489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9733469145233851, \"precision\": 1.0, \"recall\": 0.02665308547661489, \"specificity\": 1.0, \"npv\": 0.3796591831214498, \"accuracy\": 0.39002074578435025, \"f1\": 0.051922281934683755, \"f2\": 0.033095830346979216, \"f0_5\": 0.12042647848431387, \"p4\": 0.09489230412550016, \"phi\": 0.10059368101286377}, {\"truth_threshold\": 39.02, \"match_probability\": 0.9999999999982061, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 313, \"tn\": 7018, \"fp\": 0, \"fn\": 11468, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.026568203038791274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9734317969612087, \"precision\": 1.0, \"recall\": 0.026568203038791274, \"specificity\": 1.0, \"npv\": 0.3796386454614303, \"accuracy\": 0.3899675514655035, \"f1\": 0.0517612039027617, \"f2\": 0.032991125071146994, \"f0_5\": 0.12007979743727461, \"p4\": 0.09462290796085276, \"phi\": 0.10043065574808807}, {\"truth_threshold\": 39.06, \"match_probability\": 0.9999999999982551, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 310, \"tn\": 7018, \"fp\": 0, \"fn\": 11471, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02631355572532043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9736864442746795, \"precision\": 1.0, \"recall\": 0.02631355572532043, \"specificity\": 1.0, \"npv\": 0.37957704581102275, \"accuracy\": 0.38980796850896327, \"f1\": 0.05127780994127864, \"f2\": 0.03267698275498587, \"f0_5\": 0.11903847630750326, \"p4\": 0.09381360915259435, \"phi\": 0.09994009078943672}, {\"truth_threshold\": 39.1, \"match_probability\": 0.9999999999983028, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 305, \"tn\": 7018, \"fp\": 0, \"fn\": 11476, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02588914353620236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9741108564637977, \"precision\": 1.0, \"recall\": 0.02588914353620236, \"specificity\": 1.0, \"npv\": 0.3794744241375581, \"accuracy\": 0.3895419969147295, \"f1\": 0.05047162005626345, \"f2\": 0.032153323915747746, \"f0_5\": 0.11729866933312823, \"p4\": 0.09246106412058966, \"phi\": 0.09911744465438452}, {\"truth_threshold\": 39.12, \"match_probability\": 0.9999999999983262, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 304, \"tn\": 7018, \"fp\": 0, \"fn\": 11477, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.025804261098378745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9741957389016213, \"precision\": 1.0, \"recall\": 0.025804261098378745, \"specificity\": 1.0, \"npv\": 0.37945390646120575, \"accuracy\": 0.38948880259588275, \"f1\": 0.05031030202730658, \"f2\": 0.032048578898540944, \"f0_5\": 0.11695006539970762, \"p4\": 0.09218999615873576, \"phi\": 0.09895214842096527}, {\"truth_threshold\": 39.14, \"match_probability\": 0.9999999999983492, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 303, \"tn\": 7018, \"fp\": 0, \"fn\": 11478, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.025719378660555132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9742806213394448, \"precision\": 1.0, \"recall\": 0.025719378660555132, \"specificity\": 1.0, \"npv\": 0.3794333910034602, \"accuracy\": 0.389435608277036, \"f1\": 0.05014895729890765, \"f2\": 0.03194382946422924, \"f0_5\": 0.11660124682521357, \"p4\": 0.09191874138324208, \"phi\": 0.09878659352197779}, {\"truth_threshold\": 39.160000000000004, \"match_probability\": 0.999999999998372, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 302, \"tn\": 7018, \"fp\": 0, \"fn\": 11479, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.025634496222731517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9743655037772685, \"precision\": 1.0, \"recall\": 0.025634496222731517, \"specificity\": 1.0, \"npv\": 0.3794128777639617, \"accuracy\": 0.3893824139581893, \"f1\": 0.04998758586443764, \"f2\": 0.03183907561253321, \"f0_5\": 0.11625221341134806, \"p4\": 0.09164729958125929, \"phi\": 0.09862077865184382}, {\"truth_threshold\": 39.18, \"match_probability\": 0.9999999999983944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 301, \"tn\": 7018, \"fp\": 0, \"fn\": 11480, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0255496137849079, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9744503862150921, \"precision\": 1.0, \"recall\": 0.0255496137849079, \"specificity\": 1.0, \"npv\": 0.37939236674235055, \"accuracy\": 0.3893292196393425, \"f1\": 0.04982618771726535, \"f2\": 0.03173431734317343, \"f0_5\": 0.11590296495956873, \"p4\": 0.0913756705396171, \"phi\": 0.09845470249413785}, {\"truth_threshold\": 39.2, \"match_probability\": 0.9999999999984165, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 300, \"tn\": 7018, \"fp\": 0, \"fn\": 11481, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02546473134708429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9745352686529157, \"precision\": 1.0, \"recall\": 0.02546473134708429, \"specificity\": 1.0, \"npv\": 0.37937185793826694, \"accuracy\": 0.38927602532049577, \"f1\": 0.04966476285075739, \"f2\": 0.031629554655870445, \"f0_5\": 0.11555350127108852, \"p4\": 0.09110385404482353, \"phi\": 0.09828836372146091}, {\"truth_threshold\": 39.22, \"match_probability\": 0.9999999999984382, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 299, \"tn\": 7018, \"fp\": 0, \"fn\": 11482, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.025379848909260674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9746201510907393, \"precision\": 1.0, \"recall\": 0.025379848909260674, \"specificity\": 1.0, \"npv\": 0.37935135135135134, \"accuracy\": 0.389222831001649, \"f1\": 0.04950331125827814, \"f2\": 0.03152478755034477, \"f0_5\": 0.11520382214687525, \"p4\": 0.09083184988306446, \"phi\": 0.09812176099531213}, {\"truth_threshold\": 39.24, \"match_probability\": 0.9999999999984598, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 297, \"tn\": 7018, \"fp\": 0, \"fn\": 11484, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.025210084033613446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9747899159663865, \"precision\": 1.0, \"recall\": 0.025210084033613446, \"specificity\": 1.0, \"npv\": 0.3793103448275862, \"accuracy\": 0.38911644236395554, \"f1\": 0.04918032786885246, \"f2\": 0.031315240083507306, \"f0_5\": 0.11450381679389313, \"p4\": 0.09028727770177838, \"phi\": 0.09778775827230289}, {\"truth_threshold\": 39.26, \"match_probability\": 0.999999999998481, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 296, \"tn\": 7018, \"fp\": 0, \"fn\": 11485, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02512520159578983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9748747984042102, \"precision\": 1.0, \"recall\": 0.02512520159578983, \"specificity\": 1.0, \"npv\": 0.3792898448900178, \"accuracy\": 0.3890632480451088, \"f1\": 0.04901879605862383, \"f2\": 0.03121045972163644, \"f0_5\": 0.11415349016583108, \"p4\": 0.0900147092530065, \"phi\": 0.09762035554174936}, {\"truth_threshold\": 39.28, \"match_probability\": 0.9999999999985019, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 293, \"tn\": 7018, \"fp\": 0, \"fn\": 11488, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.024870554282318987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.975129445717681, \"precision\": 1.0, \"recall\": 0.024870554282318987, \"specificity\": 1.0, \"npv\": 0.3792283583702583, \"accuracy\": 0.38890366508856855, \"f1\": 0.048534040086135495, \"f2\": 0.030896092118860324, \"f0_5\": 0.11310121207442292, \"p4\": 0.08919587189188818, \"phi\": 0.09711652522738974}, {\"truth_threshold\": 39.300000000000004, \"match_probability\": 0.9999999999985225, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 292, \"tn\": 7018, \"fp\": 0, \"fn\": 11489, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.024785671844495375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9752143281555046, \"precision\": 1.0, \"recall\": 0.024785671844495375, \"specificity\": 1.0, \"npv\": 0.3792078672934565, \"accuracy\": 0.3888504707697218, \"f1\": 0.048372401225875925, \"f2\": 0.03079129407794837, \"f0_5\": 0.11275001930651016, \"p4\": 0.0889225480473796, \"phi\": 0.09694803638850331}, {\"truth_threshold\": 39.4, \"match_probability\": 0.9999999999986214, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 288, \"tn\": 7018, \"fp\": 0, \"fn\": 11493, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.024446142093200916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.975553857906799, \"precision\": 1.0, \"recall\": 0.024446142093200916, \"specificity\": 1.0, \"npv\": 0.379125925125601, \"accuracy\": 0.3886376934943348, \"f1\": 0.047725577926920205, \"f2\": 0.030372057706909643, \"f0_5\": 0.11134307585247043, \"p4\": 0.0878273566087665, \"phi\": 0.09627131575311876}, {\"truth_threshold\": 39.42, \"match_probability\": 0.9999999999986404, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 286, \"tn\": 7018, \"fp\": 0, \"fn\": 11495, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02427637721755369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9757236227824463, \"precision\": 1.0, \"recall\": 0.02427637721755369, \"specificity\": 1.0, \"npv\": 0.3790849673202614, \"accuracy\": 0.38853130485664134, \"f1\": 0.04740200546946217, \"f2\": 0.030162412993039442, \"f0_5\": 0.11063829787234042, \"p4\": 0.08727862021067254, \"phi\": 0.09593127573513593}, {\"truth_threshold\": 39.44, \"match_probability\": 0.9999999999986592, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 285, \"tn\": 7018, \"fp\": 0, \"fn\": 11496, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.024191494779730073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.97580850522027, \"precision\": 1.0, \"recall\": 0.024191494779730073, \"specificity\": 1.0, \"npv\": 0.37906449173598356, \"accuracy\": 0.3884781105377946, \"f1\": 0.04724017901541522, \"f2\": 0.0300575840030374, \"f0_5\": 0.1102855816113304, \"p4\": 0.08700396607901048, \"phi\": 0.09576083057812354}, {\"truth_threshold\": 39.46, \"match_probability\": 0.9999999999986776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 283, \"tn\": 7018, \"fp\": 0, \"fn\": 11498, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.024021729904082845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9759782700959172, \"precision\": 1.0, \"recall\": 0.024021729904082845, \"specificity\": 1.0, \"npv\": 0.37902354720241954, \"accuracy\": 0.38837172190010105, \"f1\": 0.04691644562334218, \"f2\": 0.029847912755500243, \"f0_5\": 0.10957949353364826, \"p4\": 0.08645408485684941, \"phi\": 0.09541908235873953}, {\"truth_threshold\": 39.480000000000004, \"match_probability\": 0.9999999999986958, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 282, \"tn\": 7018, \"fp\": 0, \"fn\": 11499, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02393684746625923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9760631525337408, \"precision\": 1.0, \"recall\": 0.02393684746625923, \"specificity\": 1.0, \"npv\": 0.3790030782524167, \"accuracy\": 0.38831852758125435, \"f1\": 0.04675453867197214, \"f2\": 0.02974307049740539, \"f0_5\": 0.10922612131071345, \"p4\": 0.08617885732791093, \"phi\": 0.09524777621220774}, {\"truth_threshold\": 39.5, \"match_probability\": 0.9999999999987138, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 281, \"tn\": 7018, \"fp\": 0, \"fn\": 11500, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.023851965028435618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9761480349715644, \"precision\": 1.0, \"recall\": 0.023851965028435618, \"specificity\": 1.0, \"npv\": 0.37898261151312235, \"accuracy\": 0.3882653332624076, \"f1\": 0.04659260487481346, \"f2\": 0.029638223816053157, \"f0_5\": 0.10887253002712127, \"p4\": 0.0859034382275523, \"phi\": 0.09507617996215559}, {\"truth_threshold\": 39.54, \"match_probability\": 0.999999999998749, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 280, \"tn\": 7018, \"fp\": 0, \"fn\": 11501, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.023767082590612002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.976232917409388, \"precision\": 1.0, \"recall\": 0.023767082590612002, \"specificity\": 1.0, \"npv\": 0.3789621469841784, \"accuracy\": 0.3882121389435608, \"f1\": 0.046430644225188625, \"f2\": 0.029533372711163616, \"f0_5\": 0.10851871947911014, \"p4\": 0.08562782733571998, \"phi\": 0.09490429203196561}, {\"truth_threshold\": 39.56, \"match_probability\": 0.9999999999987662, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 277, \"tn\": 7018, \"fp\": 0, \"fn\": 11504, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02351243527714116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9764875647228588, \"precision\": 1.0, \"recall\": 0.02351243527714116, \"specificity\": 1.0, \"npv\": 0.3789007666558687, \"accuracy\": 0.3880525559870206, \"f1\": 0.04594460109470891, \"f2\": 0.029218792852471465, \"f0_5\": 0.10745597020715339, \"p4\": 0.08479984170582217, \"phi\": 0.0943868621814248}, {\"truth_threshold\": 39.6, \"match_probability\": 0.9999999999988, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 276, \"tn\": 7018, \"fp\": 0, \"fn\": 11505, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.023427552839317547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9765724471606825, \"precision\": 1.0, \"recall\": 0.023427552839317547, \"specificity\": 1.0, \"npv\": 0.37888031096474656, \"accuracy\": 0.38799936166817384, \"f1\": 0.0457825329684001, \"f2\": 0.02911392405063291, \"f0_5\": 0.10710128055878929, \"p4\": 0.08452346144085733, \"phi\": 0.09421379147929279}, {\"truth_threshold\": 39.62, \"match_probability\": 0.9999999999988164, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 275, \"tn\": 7018, \"fp\": 0, \"fn\": 11506, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02334267040149393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.976657329598506, \"precision\": 1.0, \"recall\": 0.02334267040149393, \"specificity\": 1.0, \"npv\": 0.37885985748218526, \"accuracy\": 0.3879461673493271, \"f1\": 0.04562043795620438, \"f2\": 0.029009050823857043, \"f0_5\": 0.1067463706233988, \"p4\": 0.08424688827911865, \"phi\": 0.09404042099843883}, {\"truth_threshold\": 39.64, \"match_probability\": 0.9999999999988327, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 273, \"tn\": 7018, \"fp\": 0, \"fn\": 11508, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.023172905525846704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9768270944741533, \"precision\": 1.0, \"recall\": 0.023172905525846704, \"specificity\": 1.0, \"npv\": 0.3788189571413149, \"accuracy\": 0.3878397787116336, \"f1\": 0.04529616724738676, \"f2\": 0.028799291094373063, \"f0_5\": 0.10603588907014681, \"p4\": 0.0836931623766972, \"phi\": 0.09369277402892638}, {\"truth_threshold\": 39.660000000000004, \"match_probability\": 0.9999999999988488, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 270, \"tn\": 7018, \"fp\": 0, \"fn\": 11511, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02291825821237586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9770817417876242, \"precision\": 1.0, \"recall\": 0.02291825821237586, \"specificity\": 1.0, \"npv\": 0.3787576231852771, \"accuracy\": 0.3876801957550934, \"f1\": 0.04480955937266617, \"f2\": 0.0284846183061147, \"f0_5\": 0.10496850944716585, \"p4\": 0.08286112123447092, \"phi\": 0.0931690131324033}, {\"truth_threshold\": 39.68, \"match_probability\": 0.9999999999988647, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 269, \"tn\": 7018, \"fp\": 0, \"fn\": 11512, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.022833375774552245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9771666242254478, \"precision\": 1.0, \"recall\": 0.022833375774552245, \"specificity\": 1.0, \"npv\": 0.3787371829465731, \"accuracy\": 0.3876270014362466, \"f1\": 0.04464730290456431, \"f2\": 0.028379718523832635, \"f0_5\": 0.10461227346970522, \"p4\": 0.08258338601672768, \"phi\": 0.09299380849290152}, {\"truth_threshold\": 39.72, \"match_probability\": 0.9999999999988957, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 266, \"tn\": 7018, \"fp\": 0, \"fn\": 11515, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0225787284610814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9774212715389186, \"precision\": 1.0, \"recall\": 0.0225787284610814, \"specificity\": 1.0, \"npv\": 0.37867587546538606, \"accuracy\": 0.3874674184797064, \"f1\": 0.044160371876815804, \"f2\": 0.028064992614475627, \"f0_5\": 0.10354223433242507, \"p4\": 0.08174901271492589, \"phi\": 0.0924663169316007}, {\"truth_threshold\": 39.74, \"match_probability\": 0.9999999999989109, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 264, \"tn\": 7018, \"fp\": 0, \"fn\": 11517, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.022408963585434174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9775910364145658, \"precision\": 1.0, \"recall\": 0.022408963585434174, \"specificity\": 1.0, \"npv\": 0.37863501483679524, \"accuracy\": 0.38736102984201287, \"f1\": 0.043835616438356165, \"f2\": 0.027855153203342618, \"f0_5\": 0.10282776349614396, \"p4\": 0.08119178855774814, \"phi\": 0.09211307322876636}, {\"truth_threshold\": 39.76, \"match_probability\": 0.9999999999989259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 263, \"tn\": 7018, \"fp\": 0, \"fn\": 11518, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02232408114761056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9776759188523895, \"precision\": 1.0, \"recall\": 0.02232408114761056, \"specificity\": 1.0, \"npv\": 0.37861458782908936, \"accuracy\": 0.3873078355231661, \"f1\": 0.043673198272999, \"f2\": 0.02775022685546669, \"f0_5\": 0.10247019403101379, \"p4\": 0.08091288321590982, \"phi\": 0.09193597110144491}, {\"truth_threshold\": 39.78, \"match_probability\": 0.9999999999989407, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 261, \"tn\": 7018, \"fp\": 0, \"fn\": 11520, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02215431627196333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9778456837280367, \"precision\": 1.0, \"recall\": 0.02215431627196333, \"specificity\": 1.0, \"npv\": 0.3785737404250728, \"accuracy\": 0.38720144688547264, \"f1\": 0.043348281016442454, \"f2\": 0.027540360873694207, \"f0_5\": 0.10175438596491228, \"p4\": 0.08035448487485401, \"phi\": 0.09158079699171226}, {\"truth_threshold\": 39.84, \"match_probability\": 0.9999999999989838, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 257, \"tn\": 7018, \"fp\": 0, \"fn\": 11524, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.021814786520668875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9781852134793311, \"precision\": 1.0, \"recall\": 0.021814786520668875, \"specificity\": 1.0, \"npv\": 0.37849207205263724, \"accuracy\": 0.38698866961008566, \"f1\": 0.042698122611729526, \"f2\": 0.027120575758215318, \"f0_5\": 0.10032008743851979, \"p4\": 0.07923533120844307, \"phi\": 0.09086651611894175}, {\"truth_threshold\": 39.86, \"match_probability\": 0.9999999999989978, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 255, \"tn\": 7018, \"fp\": 0, \"fn\": 11526, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.021645021645021644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9783549783549783, \"precision\": 1.0, \"recall\": 0.021645021645021644, \"specificity\": 1.0, \"npv\": 0.37845125107851596, \"accuracy\": 0.38688228097239213, \"f1\": 0.0423728813559322, \"f2\": 0.02691065662002153, \"f0_5\": 0.099601593625498, \"p4\": 0.07867457223924335, \"phi\": 0.09050737826928808}, {\"truth_threshold\": 39.88, \"match_probability\": 0.9999999999990116, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 254, \"tn\": 7018, \"fp\": 0, \"fn\": 11527, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.021560139207198032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.978439860792802, \"precision\": 1.0, \"recall\": 0.021560139207198032, \"specificity\": 1.0, \"npv\": 0.37843084389323267, \"accuracy\": 0.38682908665354543, \"f1\": 0.04221022019110927, \"f2\": 0.026805690404829247, \"f0_5\": 0.09924200984605767, \"p4\": 0.0783938964208002, \"phi\": 0.09032730304086092}, {\"truth_threshold\": 39.9, \"match_probability\": 0.9999999999990252, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 252, \"tn\": 7018, \"fp\": 0, \"fn\": 11529, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0213903743315508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9786096256684492, \"precision\": 1.0, \"recall\": 0.0213903743315508, \"specificity\": 1.0, \"npv\": 0.3783900361244406, \"accuracy\": 0.3867226980158519, \"f1\": 0.041884816753926704, \"f2\": 0.026595744680851064, \"f0_5\": 0.09852216748768473, \"p4\": 0.0778319509696416, \"phi\": 0.08996612982690105}, {\"truth_threshold\": 39.96, \"match_probability\": 0.999999999999065, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 251, \"tn\": 7018, \"fp\": 0, \"fn\": 11530, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.02130549189372719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9786945081062728, \"precision\": 1.0, \"recall\": 0.02130549189372719, \"specificity\": 1.0, \"npv\": 0.37836963554021996, \"accuracy\": 0.38666950369700515, \"f1\": 0.0417220744680851, \"f2\": 0.026490765171503956, \"f0_5\": 0.09816190848650763, \"p4\": 0.0775506808772343, \"phi\": 0.08978502772085481}, {\"truth_threshold\": 39.980000000000004, \"match_probability\": 0.9999999999990778, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 250, \"tn\": 7018, \"fp\": 0, \"fn\": 11531, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.021220609455903573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9787793905440965, \"precision\": 1.0, \"recall\": 0.021220609455903573, \"specificity\": 1.0, \"npv\": 0.37834923715564184, \"accuracy\": 0.38661630937815844, \"f1\": 0.04155930512841825, \"f2\": 0.026385781230210664, \"f0_5\": 0.09780142398873327, \"p4\": 0.0772692122332247, \"phi\": 0.08960357916745802}, {\"truth_threshold\": 40.02, \"match_probability\": 0.999999999999103, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 248, \"tn\": 7018, \"fp\": 0, \"fn\": 11533, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.021050844580256346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9789491554197437, \"precision\": 1.0, \"recall\": 0.021050844580256346, \"specificity\": 1.0, \"npv\": 0.3783084469839901, \"accuracy\": 0.3865099207404649, \"f1\": 0.04123368526062017, \"f2\": 0.026175800050662838, \"f0_5\": 0.09707977765599311, \"p4\": 0.07670567836712115, \"phi\": 0.08923963424879174}, {\"truth_threshold\": 40.08, \"match_probability\": 0.9999999999991396, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 246, \"tn\": 7018, \"fp\": 0, \"fn\": 11535, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.020881079704609118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9791189202953909, \"precision\": 1.0, \"recall\": 0.020881079704609118, \"specificity\": 1.0, \"npv\": 0.37826766560664044, \"accuracy\": 0.3864035321027714, \"f1\": 0.040907957096532804, \"f2\": 0.025965801139962, \"f0_5\": 0.0963572267920094, \"p4\": 0.07614134752122123, \"phi\": 0.08887427791666544}, {\"truth_threshold\": 40.1, \"match_probability\": 0.9999999999991515, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 245, \"tn\": 7018, \"fp\": 0, \"fn\": 11536, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.020796197266785502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9792038027332145, \"precision\": 1.0, \"recall\": 0.020796197266785502, \"specificity\": 1.0, \"npv\": 0.3782472782149402, \"accuracy\": 0.3863503377839247, \"f1\": 0.04074505238649592, \"f2\": 0.025860795034727352, \"f0_5\": 0.09599561162918267, \"p4\": 0.07585888265112943, \"phi\": 0.08869106501436654}, {\"truth_threshold\": 40.12, \"match_probability\": 0.9999999999991631, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 243, \"tn\": 7018, \"fp\": 0, \"fn\": 11538, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.020626432391138275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9793735676088617, \"precision\": 1.0, \"recall\": 0.020626432391138275, \"specificity\": 1.0, \"npv\": 0.37820651002371203, \"accuracy\": 0.38624394914623117, \"f1\": 0.040419161676646706, \"f2\": 0.025650769523085693, \"f0_5\": 0.09527170077628794, \"p4\": 0.07529335285409712, \"phi\": 0.08832355862901163}, {\"truth_threshold\": 40.14, \"match_probability\": 0.9999999999991747, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 237, \"tn\": 7018, \"fp\": 0, \"fn\": 11544, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.020117137764196588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798828622358035, \"precision\": 1.0, \"recall\": 0.020117137764196588, \"specificity\": 1.0, \"npv\": 0.378084258161836, \"accuracy\": 0.3859247832331507, \"f1\": 0.03944083874188717, \"f2\": 0.02502058655856084, \"f0_5\": 0.09309450860240395, \"p4\": 0.07359194619612165, \"phi\": 0.08721223026568993}, {\"truth_threshold\": 40.18, \"match_probability\": 0.9999999999991972, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 234, \"tn\": 7018, \"fp\": 0, \"fn\": 11547, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019862490450725745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9801375095492743, \"precision\": 1.0, \"recall\": 0.019862490450725745, \"specificity\": 1.0, \"npv\": 0.37802316186372203, \"accuracy\": 0.38576520027661043, \"f1\": 0.03895131086142322, \"f2\": 0.024705435195743062, \"f0_5\": 0.09200283085633404, \"p4\": 0.07273852154255032, \"phi\": 0.08665149417448803}, {\"truth_threshold\": 40.2, \"match_probability\": 0.9999999999992082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 232, \"tn\": 7018, \"fp\": 0, \"fn\": 11549, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019692725575078517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803072744249215, \"precision\": 1.0, \"recall\": 0.019692725575078517, \"specificity\": 1.0, \"npv\": 0.3779824419669306, \"accuracy\": 0.38565881163891697, \"f1\": 0.038624823108299344, \"f2\": 0.024495312104062843, \"f0_5\": 0.09127390038555354, \"p4\": 0.07216855955313697, \"phi\": 0.0862757468924657}, {\"truth_threshold\": 40.22, \"match_probability\": 0.9999999999992192, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 231, \"tn\": 7018, \"fp\": 0, \"fn\": 11550, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0196078431372549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803921568627451, \"precision\": 1.0, \"recall\": 0.0196078431372549, \"specificity\": 1.0, \"npv\": 0.37796208530805686, \"accuracy\": 0.3856056173200702, \"f1\": 0.038461538461538464, \"f2\": 0.024390243902439025, \"f0_5\": 0.09090909090909091, \"p4\": 0.07188327418173623, \"phi\": 0.08608728872807028}, {\"truth_threshold\": 40.24, \"match_probability\": 0.9999999999992298, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 230, \"tn\": 7018, \"fp\": 0, \"fn\": 11551, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019522960699431286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9804770393005687, \"precision\": 1.0, \"recall\": 0.019522960699431286, \"specificity\": 1.0, \"npv\": 0.37794173084172544, \"accuracy\": 0.38555242300122344, \"f1\": 0.03829822662559321, \"f2\": 0.024285171263251255, \"f0_5\": 0.09054405164947642, \"p4\": 0.07159778557586773, \"phi\": 0.0858984374590018}, {\"truth_threshold\": 40.26, \"match_probability\": 0.9999999999992405, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 229, \"tn\": 7018, \"fp\": 0, \"fn\": 11552, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019438078261607674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9805619217383923, \"precision\": 1.0, \"recall\": 0.019438078261607674, \"specificity\": 1.0, \"npv\": 0.3779213785675821, \"accuracy\": 0.38549922868237674, \"f1\": 0.03813488759367194, \"f2\": 0.0241800941862184, \"f0_5\": 0.09017878238954084, \"p4\": 0.07131209349756737, \"phi\": 0.08570919048346753}, {\"truth_threshold\": 40.28, \"match_probability\": 0.9999999999992509, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 227, \"tn\": 7018, \"fp\": 0, \"fn\": 11554, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019268313385960446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9807316866140395, \"precision\": 1.0, \"recall\": 0.019268313385960446, \"specificity\": 1.0, \"npv\": 0.37788068059444324, \"accuracy\": 0.3853928400446832, \"f1\": 0.037808127914723516, \"f2\": 0.023969926717492766, \"f0_5\": 0.08944755299866025, \"p4\": 0.07074009796996869, \"phi\": 0.08532949886290059}, {\"truth_threshold\": 40.300000000000004, \"match_probability\": 0.9999999999992613, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 225, \"tn\": 7018, \"fp\": 0, \"fn\": 11556, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.019098548510313215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9809014514896868, \"precision\": 1.0, \"recall\": 0.019098548510313215, \"specificity\": 1.0, \"npv\": 0.3778399913858081, \"accuracy\": 0.38528645140698975, \"f1\": 0.037481259370314844, \"f2\": 0.023759741494012544, \"f0_5\": 0.0887154009936125, \"p4\": 0.07016728568783337, \"phi\": 0.08494819247410851}, {\"truth_threshold\": 40.34, \"match_probability\": 0.9999999999992815, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 221, \"tn\": 7018, \"fp\": 0, \"fn\": 11560, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01875901875901876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9812409812409812, \"precision\": 1.0, \"recall\": 0.01875901875901876, \"specificity\": 1.0, \"npv\": 0.37775863925072667, \"accuracy\": 0.38507367413160276, \"f1\": 0.036827195467422094, \"f2\": 0.02333931777378815, \"f0_5\": 0.087248322147651, \"p4\": 0.06901920318580429, \"phi\": 0.08418064742021043}, {\"truth_threshold\": 40.36, \"match_probability\": 0.9999999999992913, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 220, \"tn\": 7018, \"fp\": 0, \"fn\": 11561, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.018674136321195144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9813258636788048, \"precision\": 1.0, \"recall\": 0.018674136321195144, \"specificity\": 1.0, \"npv\": 0.3777383066903493, \"accuracy\": 0.385020479812756, \"f1\": 0.03666361136571952, \"f2\": 0.023234200743494422, \"f0_5\": 0.08688097306689835, \"p4\": 0.06873166908610041, \"phi\": 0.08398771715478998}, {\"truth_threshold\": 40.42, \"match_probability\": 0.9999999999993202, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 219, \"tn\": 7018, \"fp\": 0, \"fn\": 11562, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01858925388337153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9814107461166285, \"precision\": 1.0, \"recall\": 0.01858925388337153, \"specificity\": 1.0, \"npv\": 0.3777179763186222, \"accuracy\": 0.38496728549390924, \"f1\": 0.0365, \"f2\": 0.023129079272542933, \"f0_5\": 0.08651339179900451, \"p4\": 0.06844392911390647, \"phi\": 0.08379436352225718}, {\"truth_threshold\": 40.480000000000004, \"match_probability\": 0.999999999999348, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 218, \"tn\": 7018, \"fp\": 0, \"fn\": 11563, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.018504371445547917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.981495628554452, \"precision\": 1.0, \"recall\": 0.018504371445547917, \"specificity\": 1.0, \"npv\": 0.37769764813519185, \"accuracy\": 0.3849140911750625, \"f1\": 0.03633636136344695, \"f2\": 0.023023953360652275, \"f0_5\": 0.08614557812376511, \"p4\": 0.06815598302715893, \"phi\": 0.0836005835817158}, {\"truth_threshold\": 40.56, \"match_probability\": 0.999999999999383, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 213, \"tn\": 7018, \"fp\": 0, \"fn\": 11568, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.018079959256429846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9819200407435702, \"precision\": 1.0, \"recall\": 0.018079959256429846, \"specificity\": 1.0, \"npv\": 0.3775960400301302, \"accuracy\": 0.3846481195808288, \"f1\": 0.03551775887943972, \"f2\": 0.022498257177260915, \"f0_5\": 0.08430301591071004, \"p4\": 0.06671315237646142, \"phi\": 0.08262518392798897}, {\"truth_threshold\": 40.58, \"match_probability\": 0.9999999999993916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 211, \"tn\": 7018, \"fp\": 0, \"fn\": 11570, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.017910194380782615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9820898056192174, \"precision\": 1.0, \"recall\": 0.017910194380782615, \"specificity\": 1.0, \"npv\": 0.377555412093824, \"accuracy\": 0.38454173094313526, \"f1\": 0.03519012675116744, \"f2\": 0.02228794760747861, \"f0_5\": 0.08356435643564357, \"p4\": 0.06613456879972898, \"phi\": 0.08223193309242384}, {\"truth_threshold\": 40.6, \"match_probability\": 0.9999999999993999, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 209, \"tn\": 7018, \"fp\": 0, \"fn\": 11572, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.017740429505135387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9822595704948646, \"precision\": 1.0, \"recall\": 0.017740429505135387, \"specificity\": 1.0, \"npv\": 0.37751479289940826, \"accuracy\": 0.3844353423054418, \"f1\": 0.03486238532110092, \"f2\": 0.022077620264931444, \"f0_5\": 0.08282476024411509, \"p4\": 0.06555515296382623, \"phi\": 0.08183687781543073}, {\"truth_threshold\": 40.62, \"match_probability\": 0.9999999999994083, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 208, \"tn\": 7018, \"fp\": 0, \"fn\": 11573, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.017655547067311775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9823444529326882, \"precision\": 1.0, \"recall\": 0.017655547067311775, \"specificity\": 1.0, \"npv\": 0.3774944865795277, \"accuracy\": 0.38438214798659504, \"f1\": 0.034698473600800736, \"f2\": 0.02197244992816699, \"f0_5\": 0.08245461032268295, \"p4\": 0.06526513233473731, \"phi\": 0.08163866532137541}, {\"truth_threshold\": 40.72, \"match_probability\": 0.9999999999994479, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 206, \"tn\": 7018, \"fp\": 0, \"fn\": 11575, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.017485782191664544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9825142178083355, \"precision\": 1.0, \"recall\": 0.017485782191664544, \"specificity\": 1.0, \"npv\": 0.37745388049265854, \"accuracy\": 0.3842757593489015, \"f1\": 0.03437056811545841, \"f2\": 0.021762095922248044, \"f0_5\": 0.08171360571201904, \"p4\": 0.06468446442302556, \"phi\": 0.08124085389564295}, {\"truth_threshold\": 40.74, \"match_probability\": 0.9999999999994554, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 205, \"tn\": 7018, \"fp\": 0, \"fn\": 11576, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01740089975384093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.982599100246159, \"precision\": 1.0, \"recall\": 0.01740089975384093, \"specificity\": 1.0, \"npv\": 0.377433580724965, \"accuracy\": 0.3842225650300548, \"f1\": 0.03420657433672618, \"f2\": 0.02165691225253016, \"f0_5\": 0.08134275057535116, \"p4\": 0.0643938166467431, \"phi\": 0.08104124815134787}, {\"truth_threshold\": 40.800000000000004, \"match_probability\": 0.9999999999994776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 201, \"tn\": 7018, \"fp\": 0, \"fn\": 11580, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.017061370002546473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9829386299974535, \"precision\": 1.0, \"recall\": 0.017061370002546473, \"specificity\": 1.0, \"npv\": 0.3773524034842456, \"accuracy\": 0.3840097877546678, \"f1\": 0.03355032548823235, \"f2\": 0.021236133122028527, \"f0_5\": 0.07985697258641239, \"p4\": 0.06322912762801954, \"phi\": 0.08023807685379132}, {\"truth_threshold\": 40.82, \"match_probability\": 0.9999999999994849, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 200, \"tn\": 7018, \"fp\": 0, \"fn\": 11581, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016976487564722857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9830235124352772, \"precision\": 1.0, \"recall\": 0.016976487564722857, \"specificity\": 1.0, \"npv\": 0.3773321146298188, \"accuracy\": 0.38395659343582106, \"f1\": 0.033386194808446706, \"f2\": 0.021130927225086638, \"f0_5\": 0.07948493760432399, \"p4\": 0.06293742965303993, \"phi\": 0.08003607906303069}, {\"truth_threshold\": 40.84, \"match_probability\": 0.999999999999492, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 199, \"tn\": 7018, \"fp\": 0, \"fn\": 11582, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016891605126899245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9831083948731008, \"precision\": 1.0, \"recall\": 0.016891605126899245, \"specificity\": 1.0, \"npv\": 0.37731182795698925, \"accuracy\": 0.3839033991169743, \"f1\": 0.0332220367278798, \"f2\": 0.02102571688185449, \"f0_5\": 0.07911266597757811, \"p4\": 0.06264552089181709, \"phi\": 0.07983359197454418}, {\"truth_threshold\": 40.9, \"match_probability\": 0.9999999999995126, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 197, \"tn\": 7018, \"fp\": 0, \"fn\": 11584, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016721840251252017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983278159748748, \"precision\": 1.0, \"recall\": 0.016721840251252017, \"specificity\": 1.0, \"npv\": 0.37727126115471454, \"accuracy\": 0.38379701047928083, \"f1\": 0.032893638336951074, \"f2\": 0.020815282855391897, \"f0_5\": 0.07836741188638714, \"p4\": 0.062061070011266234, \"phi\": 0.0794271349125569}, {\"truth_threshold\": 40.92, \"match_probability\": 0.9999999999995193, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 196, \"tn\": 7018, \"fp\": 0, \"fn\": 11585, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016636957813428402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9833630421865716, \"precision\": 1.0, \"recall\": 0.016636957813428402, \"specificity\": 1.0, \"npv\": 0.37725098102456595, \"accuracy\": 0.38374381616043407, \"f1\": 0.03272939801285798, \"f2\": 0.020710059171597635, \"f0_5\": 0.07799442896935933, \"p4\": 0.06176852739126957, \"phi\": 0.0792231573239806}, {\"truth_threshold\": 40.94, \"match_probability\": 0.9999999999995259, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 195, \"tn\": 7018, \"fp\": 0, \"fn\": 11586, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016552075375604786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9834479246243952, \"precision\": 1.0, \"recall\": 0.016552075375604786, \"specificity\": 1.0, \"npv\": 0.3772307030746076, \"accuracy\": 0.3836906218415873, \"f1\": 0.03256513026052104, \"f2\": 0.02060483104038547, \"f0_5\": 0.07762120850250777, \"p4\": 0.0614757729836908, \"phi\": 0.07901867520582266}, {\"truth_threshold\": 41.0, \"match_probability\": 0.9999999999995453, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 194, \"tn\": 7018, \"fp\": 0, \"fn\": 11587, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016467192937781174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9835328070622188, \"precision\": 1.0, \"recall\": 0.016467192937781174, \"specificity\": 1.0, \"npv\": 0.37721042730448806, \"accuracy\": 0.38363742752274055, \"f1\": 0.032400835073068894, \"f2\": 0.020499598461473437, \"f0_5\": 0.07724775025881978, \"p4\": 0.061182806537211205, \"phi\": 0.0788136846275181}, {\"truth_threshold\": 41.08, \"match_probability\": 0.9999999999995698, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 191, \"tn\": 7018, \"fp\": 0, \"fn\": 11590, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01621254562431033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9837874543756897, \"precision\": 1.0, \"recall\": 0.01621254562431033, \"specificity\": 1.0, \"npv\": 0.37714961306964745, \"accuracy\": 0.3834778445662003, \"f1\": 0.03190778483127297, \"f2\": 0.02018387403571806, \"f0_5\": 0.07612594659226783, \"p4\": 0.06030263244524809, \"phi\": 0.0781956220582882}, {\"truth_threshold\": 41.1, \"match_probability\": 0.9999999999995757, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 190, \"tn\": 7018, \"fp\": 0, \"fn\": 11591, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016127663186486715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9838723368135133, \"precision\": 1.0, \"recall\": 0.016127663186486715, \"specificity\": 1.0, \"npv\": 0.3771293460153689, \"accuracy\": 0.38342465024735356, \"f1\": 0.03174337983460029, \"f2\": 0.02007862366318637, \"f0_5\": 0.07575153496531377, \"p4\": 0.06000881532206303, \"phi\": 0.0779885573034652}, {\"truth_threshold\": 41.12, \"match_probability\": 0.9999999999995816, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 189, \"tn\": 7018, \"fp\": 0, \"fn\": 11592, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.016042780748663103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983957219251337, \"precision\": 1.0, \"recall\": 0.016042780748663103, \"specificity\": 1.0, \"npv\": 0.37710908113917246, \"accuracy\": 0.38337145592850685, \"f1\": 0.031578947368421054, \"f2\": 0.019973368841544607, \"f0_5\": 0.07537688442211055, \"p4\": 0.05971478489744055, \"phi\": 0.07778096365464719}, {\"truth_threshold\": 41.24, \"match_probability\": 0.999999999999615, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 188, \"tn\": 7018, \"fp\": 0, \"fn\": 11593, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.015957898310839488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9840421016891605, \"precision\": 1.0, \"recall\": 0.015957898310839488, \"specificity\": 1.0, \"npv\": 0.37708881844070713, \"accuracy\": 0.3833182616096601, \"f1\": 0.03141448742585011, \"f2\": 0.01986810957051065, \"f0_5\": 0.0750019947339025, \"p4\": 0.05942054091767928, \"phi\": 0.07757283686208348}, {\"truth_threshold\": 41.28, \"match_probability\": 0.9999999999996255, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 185, \"tn\": 7018, \"fp\": 0, \"fn\": 11596, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.015703250997368644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9842967490026313, \"precision\": 1.0, \"recall\": 0.015703250997368644, \"specificity\": 1.0, \"npv\": 0.3770280434081874, \"accuracy\": 0.38315867865311987, \"f1\": 0.030920942670900887, \"f2\": 0.019552305058234163, \"f0_5\": 0.07387588850730772, \"p4\": 0.05853652510454658, \"phi\": 0.0769452142675915}, {\"truth_threshold\": 41.300000000000004, \"match_probability\": 0.9999999999996306, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 181, \"tn\": 7018, \"fp\": 0, \"fn\": 11600, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.015363721246074187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9846362787539258, \"precision\": 1.0, \"recall\": 0.015363721246074187, \"specificity\": 1.0, \"npv\": 0.37694704049844235, \"accuracy\": 0.3829459013777329, \"f1\": 0.030262497910048487, \"f2\": 0.019131170066589154, \"f0_5\": 0.07237105157936825, \"p4\": 0.05735483212038203, \"phi\": 0.0761006521309161}, {\"truth_threshold\": 41.32, \"match_probability\": 0.9999999999996357, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 179, \"tn\": 7018, \"fp\": 0, \"fn\": 11602, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.015193956370426958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984806043629573, \"precision\": 1.0, \"recall\": 0.015193956370426958, \"specificity\": 1.0, \"npv\": 0.376906552094522, \"accuracy\": 0.38283951274003936, \"f1\": 0.029933110367892975, \"f2\": 0.018920575861996067, \"f0_5\": 0.07161718812515004, \"p4\": 0.056762693059305334, \"phi\": 0.07567497412125242}, {\"truth_threshold\": 41.36, \"match_probability\": 0.9999999999996457, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 174, \"tn\": 7018, \"fp\": 0, \"fn\": 11607, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.014769544181308887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9852304558186911, \"precision\": 1.0, \"recall\": 0.014769544181308887, \"specificity\": 1.0, \"npv\": 0.3768053691275168, \"accuracy\": 0.3825735411458056, \"f1\": 0.029109159347553325, \"f2\": 0.0183940124318153, \"f0_5\": 0.06972830007213272, \"p4\": 0.0552785588821412, \"phi\": 0.07460055996494439}, {\"truth_threshold\": 41.4, \"match_probability\": 0.9999999999996554, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 173, \"tn\": 7018, \"fp\": 0, \"fn\": 11608, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.014684661743485273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9853153382565147, \"precision\": 1.0, \"recall\": 0.014684661743485273, \"specificity\": 1.0, \"npv\": 0.37678513905293676, \"accuracy\": 0.3825203468269589, \"f1\": 0.02894428643132006, \"f2\": 0.01828868638602871, \"f0_5\": 0.06934979555840616, \"p4\": 0.05498108085734899, \"phi\": 0.0743838847934446}, {\"truth_threshold\": 41.44, \"match_probability\": 0.9999999999996648, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 172, \"tn\": 7018, \"fp\": 0, \"fn\": 11609, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01459977930566166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9854002206943383, \"precision\": 1.0, \"recall\": 0.01459977930566166, \"specificity\": 1.0, \"npv\": 0.3767649111504805, \"accuracy\": 0.38246715250811214, \"f1\": 0.028779385928218857, \"f2\": 0.018183355886332884, \"f0_5\": 0.06897104819953484, \"p4\": 0.05468338516327616, \"phi\": 0.07416659998216339}, {\"truth_threshold\": 41.5, \"match_probability\": 0.9999999999996785, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 170, \"tn\": 7018, \"fp\": 0, \"fn\": 11611, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01443001443001443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9855699855699855, \"precision\": 1.0, \"recall\": 0.01443001443001443, \"specificity\": 1.0, \"npv\": 0.37672446186054004, \"accuracy\": 0.3823607638704186, \"f1\": 0.02844950213371266, \"f2\": 0.017972681524083392, \"f0_5\": 0.06821282401091405, \"p4\": 0.05408733972444589, \"phi\": 0.07373017985049957}, {\"truth_threshold\": 41.54, \"match_probability\": 0.9999999999996873, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 169, \"tn\": 7018, \"fp\": 0, \"fn\": 11612, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.014345131992190816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856548680078092, \"precision\": 1.0, \"recall\": 0.014345131992190816, \"specificity\": 1.0, \"npv\": 0.3767042404723564, \"accuracy\": 0.3823075695515719, \"f1\": 0.02828451882845188, \"f2\": 0.017867337660964624, \"f0_5\": 0.06783334671269166, \"p4\": 0.05378898945723253, \"phi\": 0.07351103353642868}, {\"truth_threshold\": 41.56, \"match_probability\": 0.9999999999996916, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 168, \"tn\": 7018, \"fp\": 0, \"fn\": 11613, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0142602495543672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9857397504456328, \"precision\": 1.0, \"recall\": 0.0142602495543672, \"specificity\": 1.0, \"npv\": 0.37668402125489775, \"accuracy\": 0.38225437523272515, \"f1\": 0.028119507908611598, \"f2\": 0.017761989342806393, \"f0_5\": 0.06745362563237774, \"p4\": 0.053490420475825036, \"phi\": 0.07329125559190128}, {\"truth_threshold\": 41.58, \"match_probability\": 0.9999999999996958, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 167, \"tn\": 7018, \"fp\": 0, \"fn\": 11614, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.014175367116543587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9858246328834565, \"precision\": 1.0, \"recall\": 0.014175367116543587, \"specificity\": 1.0, \"npv\": 0.37666380420781453, \"accuracy\": 0.3822011809138784, \"f1\": 0.02795446936725812, \"f2\": 0.017656636569326086, \"f0_5\": 0.06707366053498273, \"p4\": 0.05319163251795713, \"phi\": 0.07307084031376446}, {\"truth_threshold\": 41.6, \"match_probability\": 0.9999999999997, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 165, \"tn\": 7018, \"fp\": 0, \"fn\": 11616, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.014005602240896359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9859943977591037, \"precision\": 1.0, \"recall\": 0.014005602240896359, \"specificity\": 1.0, \"npv\": 0.37662337662337664, \"accuracy\": 0.3820947922761849, \"f1\": 0.027624309392265192, \"f2\": 0.017445917655268667, \"f0_5\": 0.06631299734748011, \"p4\": 0.05259339862169024, \"phi\": 0.07262807451399436}, {\"truth_threshold\": 41.64, \"match_probability\": 0.9999999999997082, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 164, \"tn\": 7018, \"fp\": 0, \"fn\": 11617, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013920719803072744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9860792801969273, \"precision\": 1.0, \"recall\": 0.013920719803072744, \"specificity\": 1.0, \"npv\": 0.3766031660853233, \"accuracy\": 0.38204159795733816, \"f1\": 0.027459187944746756, \"f2\": 0.017340551514126206, \"f0_5\": 0.06593229878588083, \"p4\": 0.0522939521566714, \"phi\": 0.07240571215051927}, {\"truth_threshold\": 41.68, \"match_probability\": 0.9999999999997161, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 163, \"tn\": 7018, \"fp\": 0, \"fn\": 11618, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01383583736524913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9861641626347508, \"precision\": 1.0, \"recall\": 0.01383583736524913, \"specificity\": 1.0, \"npv\": 0.3765829577162481, \"accuracy\": 0.3819884036384914, \"f1\": 0.027294038847957135, \"f2\": 0.017235180916530972, \"f0_5\": 0.0655513552642162, \"p4\": 0.05199428566195079, \"phi\": 0.07218268876598113}, {\"truth_threshold\": 41.74, \"match_probability\": 0.9999999999997278, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 162, \"tn\": 7018, \"fp\": 0, \"fn\": 11619, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013750954927425516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9862490450725745, \"precision\": 1.0, \"recall\": 0.013750954927425516, \"specificity\": 1.0, \"npv\": 0.3765627515158019, \"accuracy\": 0.38193520931964464, \"f1\": 0.027128862094951016, \"f2\": 0.01712980586220023, \"f0_5\": 0.06517016654598118, \"p4\": 0.05169439887316981, \"phi\": 0.0719589982103776}, {\"truth_threshold\": 41.78, \"match_probability\": 0.9999999999997352, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 160, \"tn\": 7018, \"fp\": 0, \"fn\": 11621, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013581190051778286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9864188099482217, \"precision\": 1.0, \"recall\": 0.013581190051778286, \"specificity\": 1.0, \"npv\": 0.3765223456194002, \"accuracy\": 0.3818288206819512, \"f1\": 0.02679842559249644, \"f2\": 0.01691904238220117, \"f0_5\": 0.06440705257225667, \"p4\": 0.05109396335388678, \"phi\": 0.07150959050783624}, {\"truth_threshold\": 41.82, \"match_probability\": 0.9999999999997424, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 159, \"tn\": 7018, \"fp\": 0, \"fn\": 11622, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013496307613954673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9865036923860453, \"precision\": 1.0, \"recall\": 0.013496307613954673, \"specificity\": 1.0, \"npv\": 0.3765021459227468, \"accuracy\": 0.3817756263631044, \"f1\": 0.026633165829145728, \"f2\": 0.01681365395596726, \"f0_5\": 0.06402512684223242, \"p4\": 0.050793414092559365, \"phi\": 0.07128386057648281}, {\"truth_threshold\": 41.84, \"match_probability\": 0.999999999999746, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 158, \"tn\": 7018, \"fp\": 0, \"fn\": 11623, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013411425176131059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.986588574823869, \"precision\": 1.0, \"recall\": 0.013411425176131059, \"specificity\": 1.0, \"npv\": 0.37648194839332655, \"accuracy\": 0.38172243204425765, \"f1\": 0.02646787838177402, \"f2\": 0.01670826107186667, \"f0_5\": 0.06364295496656731, \"p4\": 0.05049264347551919, \"phi\": 0.07105743790090616}, {\"truth_threshold\": 41.86, \"match_probability\": 0.9999999999997494, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 157, \"tn\": 7018, \"fp\": 0, \"fn\": 11624, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013326542738307445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9866734572616925, \"precision\": 1.0, \"recall\": 0.013326542738307445, \"specificity\": 1.0, \"npv\": 0.3764617530307907, \"accuracy\": 0.38166923772541095, \"f1\": 0.026302563243424358, \"f2\": 0.016602863729616547, \"f0_5\": 0.06326053670722863, \"p4\": 0.050191651236294425, \"phi\": 0.07083031583370905}, {\"truth_threshold\": 41.980000000000004, \"match_probability\": 0.9999999999997694, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 154, \"tn\": 7018, \"fp\": 0, \"fn\": 11627, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.013071895424836602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9869281045751634, \"precision\": 1.0, \"recall\": 0.013071895424836602, \"specificity\": 1.0, \"npv\": 0.376401179941003, \"accuracy\": 0.38150965476887067, \"f1\": 0.025806451612903226, \"f2\": 0.016286644951140065, \"f0_5\": 0.062111801242236024, \"p4\": 0.04928734211441153, \"phi\": 0.07014468520118894}, {\"truth_threshold\": 42.0, \"match_probability\": 0.9999999999997726, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 152, \"tn\": 7018, \"fp\": 0, \"fn\": 11629, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012902130549189372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9870978694508106, \"precision\": 1.0, \"recall\": 0.012902130549189372, \"specificity\": 1.0, \"npv\": 0.37636080870917576, \"accuracy\": 0.3814032661311772, \"f1\": 0.025475571943350372, \"f2\": 0.01607581013622134, \"f0_5\": 0.06134474130276858, \"p4\": 0.04868335635107762, \"phi\": 0.06968397439558305}, {\"truth_threshold\": 42.08, \"match_probability\": 0.9999999999997848, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 151, \"tn\": 7018, \"fp\": 0, \"fn\": 11630, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012817248111365758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9871827518886342, \"precision\": 1.0, \"recall\": 0.012817248111365758, \"specificity\": 1.0, \"npv\": 0.3763406263406263, \"accuracy\": 0.38135007181233044, \"f1\": 0.02531009051290647, \"f2\": 0.015970386039132735, \"f0_5\": 0.060960839725474364, \"p4\": 0.04838102875896734, \"phi\": 0.06945251026560954}, {\"truth_threshold\": 42.1, \"match_probability\": 0.9999999999997878, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 149, \"tn\": 7018, \"fp\": 0, \"fn\": 11632, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012647483235718529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873525167642815, \"precision\": 1.0, \"recall\": 0.012647483235718529, \"specificity\": 1.0, \"npv\": 0.37630026809651473, \"accuracy\": 0.38124368317463697, \"f1\": 0.024979044425817266, \"f2\": 0.015759524464281936, \"f0_5\": 0.06019229215480326, \"p4\": 0.04777570280652933, \"phi\": 0.0689873273315256}, {\"truth_threshold\": 42.12, \"match_probability\": 0.9999999999997907, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 147, \"tn\": 7018, \"fp\": 0, \"fn\": 11634, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012477718360071301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9875222816399287, \"precision\": 1.0, \"recall\": 0.012477718360071301, \"specificity\": 1.0, \"npv\": 0.37625991850739865, \"accuracy\": 0.38113729453694345, \"f1\": 0.02464788732394366, \"f2\": 0.015548645046645935, \"f0_5\": 0.059422750424448216, \"p4\": 0.047169480694992744, \"phi\": 0.06851908707300981}, {\"truth_threshold\": 42.160000000000004, \"match_probability\": 0.9999999999997965, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 146, \"tn\": 7018, \"fp\": 0, \"fn\": 11635, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012392835922247688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876071640777523, \"precision\": 1.0, \"recall\": 0.012392835922247688, \"specificity\": 1.0, \"npv\": 0.37623974695759393, \"accuracy\": 0.3810841002180967, \"f1\": 0.02448226712501048, \"f2\": 0.015443198646075735, \"f0_5\": 0.059037606146380914, \"p4\": 0.04686603290238588, \"phi\": 0.06828380079838446}, {\"truth_threshold\": 42.2, \"match_probability\": 0.999999999999802, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 145, \"tn\": 7018, \"fp\": 0, \"fn\": 11636, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012307953484424072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.987692046515576, \"precision\": 1.0, \"recall\": 0.012307953484424072, \"specificity\": 1.0, \"npv\": 0.3762195775704943, \"accuracy\": 0.38103090589925, \"f1\": 0.024316619151433842, \"f2\": 0.015337747783959889, \"f0_5\": 0.05865221260415824, \"p4\": 0.046562360256524236, \"phi\": 0.06804772634458345}, {\"truth_threshold\": 42.22, \"match_probability\": 0.9999999999998048, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 144, \"tn\": 7018, \"fp\": 0, \"fn\": 11637, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.012223071046600458, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9877769289533995, \"precision\": 1.0, \"recall\": 0.012223071046600458, \"specificity\": 1.0, \"npv\": 0.37619941034575183, \"accuracy\": 0.3809777115804032, \"f1\": 0.024150943396226414, \"f2\": 0.015232292460015232, \"f0_5\": 0.05826656955571741, \"p4\": 0.04625846248534186, \"phi\": 0.067810855475693}, {\"truth_threshold\": 42.24, \"match_probability\": 0.9999999999998075, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 142, \"tn\": 7018, \"fp\": 0, \"fn\": 11639, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01205330617095323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9879466938290468, \"precision\": 1.0, \"recall\": 0.01205330617095323, \"specificity\": 1.0, \"npv\": 0.3761590823819478, \"accuracy\": 0.3808713229427097, \"f1\": 0.023819508512958148, \"f2\": 0.015021368425506706, \"f0_5\": 0.05749453397036197, \"p4\": 0.04564999047656828, \"phi\": 0.06733469082823827}, {\"truth_threshold\": 42.26, \"match_probability\": 0.9999999999998102, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 141, \"tn\": 7018, \"fp\": 0, \"fn\": 11640, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011968423733129615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9880315762668704, \"precision\": 1.0, \"recall\": 0.011968423733129615, \"specificity\": 1.0, \"npv\": 0.37613892164219104, \"accuracy\": 0.380818128623863, \"f1\": 0.02365374937091092, \"f2\": 0.014915899714376388, \"f0_5\": 0.05710814094775213, \"p4\": 0.0453454156926598, \"phi\": 0.06709537984642594}, {\"truth_threshold\": 42.300000000000004, \"match_probability\": 0.9999999999998154, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 140, \"tn\": 7018, \"fp\": 0, \"fn\": 11641, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011883541295306001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.988116458704694, \"precision\": 1.0, \"recall\": 0.011883541295306001, \"specificity\": 1.0, \"npv\": 0.37611876306340103, \"accuracy\": 0.38076493430501623, \"f1\": 0.023487962419260128, \"f2\": 0.01481042654028436, \"f0_5\": 0.05672149744753262, \"p4\": 0.04504061469079422, \"phi\": 0.06685523803564938}, {\"truth_threshold\": 42.34, \"match_probability\": 0.9999999999998204, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 139, \"tn\": 7018, \"fp\": 0, \"fn\": 11642, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011798658857482387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9882013411425176, \"precision\": 1.0, \"recall\": 0.011798658857482387, \"specificity\": 1.0, \"npv\": 0.3760986066452304, \"accuracy\": 0.3807117399861695, \"f1\": 0.023322147651006712, \"f2\": 0.014704948902947337, \"f0_5\": 0.056334603226067925, \"p4\": 0.04473558719671495, \"phi\": 0.06661425640642948}, {\"truth_threshold\": 42.42, \"match_probability\": 0.99999999999983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 136, \"tn\": 7018, \"fp\": 0, \"fn\": 11645, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011544011544011544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884559884559885, \"precision\": 1.0, \"recall\": 0.011544011544011544, \"specificity\": 1.0, \"npv\": 0.3760381503509618, \"accuracy\": 0.38055215702962925, \"f1\": 0.02282453637660485, \"f2\": 0.014388489208633094, \"f0_5\": 0.05517241379310345, \"p4\": 0.043819143012011945, \"phi\": 0.06588618025534833}, {\"truth_threshold\": 42.56, \"match_probability\": 0.9999999999998458, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 134, \"tn\": 7018, \"fp\": 0, \"fn\": 11647, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011374246668364315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9886257533316357, \"precision\": 1.0, \"recall\": 0.011374246668364315, \"specificity\": 1.0, \"npv\": 0.37599785695151355, \"accuracy\": 0.3804457683919357, \"f1\": 0.022492656315568613, \"f2\": 0.014177493757670658, \"f0_5\": 0.05439636275066981, \"p4\": 0.043207042713227985, \"phi\": 0.06539642476269536}, {\"truth_threshold\": 42.6, \"match_probability\": 0.99999999999985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 133, \"tn\": 7018, \"fp\": 0, \"fn\": 11648, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0112893642305407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887106357694593, \"precision\": 1.0, \"recall\": 0.0112893642305407, \"specificity\": 1.0, \"npv\": 0.3759777134897675, \"accuracy\": 0.380392574073089, \"f1\": 0.022326674500587545, \"f2\": 0.014071989334913345, \"f0_5\": 0.05400795906765207, \"p4\": 0.042900650481732264, \"phi\": 0.06515020606377128}, {\"truth_threshold\": 42.64, \"match_probability\": 0.9999999999998541, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 132, \"tn\": 7018, \"fp\": 0, \"fn\": 11649, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011204481792717087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.988795518207283, \"precision\": 1.0, \"recall\": 0.011204481792717087, \"specificity\": 1.0, \"npv\": 0.37595757218621095, \"accuracy\": 0.38033937975424226, \"f1\": 0.0221606648199446, \"f2\": 0.013966480446927373, \"f0_5\": 0.05361930294906166, \"p4\": 0.04259402982583515, \"phi\": 0.06490307983751249}, {\"truth_threshold\": 42.68, \"match_probability\": 0.9999999999998581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 131, \"tn\": 7018, \"fp\": 0, \"fn\": 11650, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.011119599354893473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9888804006451065, \"precision\": 1.0, \"recall\": 0.011119599354893473, \"specificity\": 1.0, \"npv\": 0.3759374330404971, \"accuracy\": 0.3802861854353955, \"f1\": 0.021994627266621894, \"f2\": 0.013860967093429266, \"f0_5\": 0.05323039414872003, \"p4\": 0.0422871804677289, \"phi\": 0.06465503567331334}, {\"truth_threshold\": 42.7, \"match_probability\": 0.99999999999986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 129, \"tn\": 7018, \"fp\": 0, \"fn\": 11652, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010949834479246244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9890501655207538, \"precision\": 1.0, \"recall\": 0.010949834479246244, \"specificity\": 1.0, \"npv\": 0.3758971612212105, \"accuracy\": 0.38017979679770203, \"f1\": 0.021662468513853905, \"f2\": 0.013649926988762618, \"f0_5\": 0.05245181751646743, \"p4\": 0.04167279453141755, \"phi\": 0.06415615088665151}, {\"truth_threshold\": 42.78, \"match_probability\": 0.9999999999998676, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 126, \"tn\": 7018, \"fp\": 0, \"fn\": 11655, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0106951871657754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9893048128342246, \"precision\": 1.0, \"recall\": 0.0106951871657754, \"specificity\": 1.0, \"npv\": 0.3758367696674343, \"accuracy\": 0.38002021384116175, \"f1\": 0.021164021164021163, \"f2\": 0.013333333333333334, \"f0_5\": 0.05128205128205128, \"p4\": 0.040749493389384696, \"phi\": 0.06340066715243325}, {\"truth_threshold\": 42.88, \"match_probability\": 0.9999999999998764, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 125, \"tn\": 7018, \"fp\": 0, \"fn\": 11656, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010610304727951787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9893896952720482, \"precision\": 1.0, \"recall\": 0.010610304727951787, \"specificity\": 1.0, \"npv\": 0.3758166434614973, \"accuracy\": 0.37996701952231504, \"f1\": 0.02099781622711238, \"f2\": 0.01322779318080806, \"f0_5\": 0.05089162120348506, \"p4\": 0.04044126595891416, \"phi\": 0.06314688518812701}, {\"truth_threshold\": 42.92, \"match_probability\": 0.9999999999998799, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 124, \"tn\": 7018, \"fp\": 0, \"fn\": 11657, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010525422290128173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9894745777098718, \"precision\": 1.0, \"recall\": 0.010525422290128173, \"specificity\": 1.0, \"npv\": 0.37579651941097725, \"accuracy\": 0.3799138252034683, \"f1\": 0.020831583368332632, \"f2\": 0.013122248560785641, \"f0_5\": 0.050500936710922865, \"p4\": 0.040132807868987756, \"phi\": 0.0628921065155309}, {\"truth_threshold\": 42.94, \"match_probability\": 0.9999999999998815, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 122, \"tn\": 7018, \"fp\": 0, \"fn\": 11659, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010355657414480943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989644342585519, \"precision\": 1.0, \"recall\": 0.010355657414480943, \"specificity\": 1.0, \"npv\": 0.37575627777480325, \"accuracy\": 0.37980743656577476, \"f1\": 0.020499033857010837, \"f2\": 0.012911145917114676, \"f0_5\": 0.04971880348846687, \"p4\": 0.03951519858464592, \"phi\": 0.06237951012933976}, {\"truth_threshold\": 42.96, \"match_probability\": 0.9999999999998831, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 121, \"tn\": 7018, \"fp\": 0, \"fn\": 11660, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.01027077497665733, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897292250233427, \"precision\": 1.0, \"recall\": 0.01027077497665733, \"specificity\": 1.0, \"npv\": 0.375736160188457, \"accuracy\": 0.37975424224692805, \"f1\": 0.02033271719038817, \"f2\": 0.012805587892898719, \"f0_5\": 0.04932735426008968, \"p4\": 0.03920604682603085, \"phi\": 0.06212166733023925}, {\"truth_threshold\": 42.980000000000004, \"match_probability\": 0.9999999999998848, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 120, \"tn\": 7018, \"fp\": 0, \"fn\": 11661, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010185892538833716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9898141074611663, \"precision\": 1.0, \"recall\": 0.010185892538833716, \"specificity\": 1.0, \"npv\": 0.3757160447561433, \"accuracy\": 0.3797010479280813, \"f1\": 0.0201663725737333, \"f2\": 0.0127000254000508, \"f0_5\": 0.048935649620748714, \"p4\": 0.03889666327955875, \"phi\": 0.06186277763729748}, {\"truth_threshold\": 43.0, \"match_probability\": 0.9999999999998863, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 118, \"tn\": 7018, \"fp\": 0, \"fn\": 11663, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.010016127663186486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9899838723368135, \"precision\": 1.0, \"recall\": 0.010016127663186486, \"specificity\": 1.0, \"npv\": 0.3756758203522295, \"accuracy\": 0.37959465929038777, \"f1\": 0.019833599462139674, \"f2\": 0.012488887007323991, \"f0_5\": 0.04815147310862646, \"p4\": 0.038277199689612844, \"phi\": 0.06134180447802496}, {\"truth_threshold\": 43.08, \"match_probability\": 0.9999999999998924, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 117, \"tn\": 7018, \"fp\": 0, \"fn\": 11664, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.009931245225362872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9900687547746372, \"precision\": 1.0, \"recall\": 0.009931245225362872, \"specificity\": 1.0, \"npv\": 0.3756557113799379, \"accuracy\": 0.37954146497154106, \"f1\": 0.019667170953101363, \"f2\": 0.012383311106877501, \"f0_5\": 0.04775900073475386, \"p4\": 0.037967119078275505, \"phi\": 0.06107969376169384}, {\"truth_threshold\": 43.12, \"match_probability\": 0.9999999999998954, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 114, \"tn\": 7018, \"fp\": 0, \"fn\": 11667, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.00967659791189203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990323402088108, \"precision\": 1.0, \"recall\": 0.00967659791189203, \"specificity\": 1.0, \"npv\": 0.3755953973775756, \"accuracy\": 0.3793818820150008, \"f1\": 0.019167717528373266, \"f2\": 0.012066556585799568, \"f0_5\": 0.04658004412846286, \"p4\": 0.037035478561948436, \"phi\": 0.06028669536456701}, {\"truth_threshold\": 43.2, \"match_probability\": 0.9999999999999011, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 113, \"tn\": 7018, \"fp\": 0, \"fn\": 11668, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.009591715474068415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9904082845259315, \"precision\": 1.0, \"recall\": 0.009591715474068415, \"specificity\": 1.0, \"npv\": 0.37557529701380715, \"accuracy\": 0.3793286876961541, \"f1\": 0.019001177064065917, \"f2\": 0.011960962804581154, \"f0_5\": 0.04618654459249571, \"p4\": 0.036724464543910734, \"phi\": 0.06002009153646115}, {\"truth_threshold\": 43.28, \"match_probability\": 0.9999999999999064, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 112, \"tn\": 7018, \"fp\": 0, \"fn\": 11669, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.009506833036244802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9904931669637552, \"precision\": 1.0, \"recall\": 0.009506833036244802, \"specificity\": 1.0, \"npv\": 0.3755551988013057, \"accuracy\": 0.3792754933773073, \"f1\": 0.01883460859329017, \"f2\": 0.011855364552459988, \"f0_5\": 0.04579278763594734, \"p4\": 0.03641321645917076, \"phi\": 0.059752326907809516}, {\"truth_threshold\": 43.300000000000004, \"match_probability\": 0.9999999999999076, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 111, \"tn\": 7018, \"fp\": 0, \"fn\": 11670, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.009421950598421186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905780494015788, \"precision\": 1.0, \"recall\": 0.009421950598421186, \"specificity\": 1.0, \"npv\": 0.375535102739726, \"accuracy\": 0.37922229905846055, \"f1\": 0.01866801210898083, \"f2\": 0.011749761829152112, \"f0_5\": 0.04539877300613497, \"p4\": 0.03610173402078812, \"phi\": 0.05948338579794129}, {\"truth_threshold\": 43.44, \"match_probability\": 0.9999999999999162, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 108, \"tn\": 7018, \"fp\": 0, \"fn\": 11673, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.009167303284950344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908326967150497, \"precision\": 1.0, \"recall\": 0.009167303284950344, \"specificity\": 1.0, \"npv\": 0.3754748274570649, \"accuracy\": 0.3790627161019203, \"f1\": 0.018168054504163512, \"f2\": 0.011432926829268292, \"f0_5\": 0.04421518054532056, \"p4\": 0.03516587770737819, \"phi\": 0.058669341390229654}, {\"truth_threshold\": 43.46, \"match_probability\": 0.9999999999999174, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 106, \"tn\": 7018, \"fp\": 0, \"fn\": 11675, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008997538409303115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9910024615906969, \"precision\": 1.0, \"recall\": 0.008997538409303115, \"specificity\": 1.0, \"npv\": 0.3754346546835714, \"accuracy\": 0.3789563274642268, \"f1\": 0.017834609236981578, \"f2\": 0.011221681134871904, \"f0_5\": 0.043424825891028265, \"p4\": 0.03454079644861841, \"phi\": 0.058120458753341625}, {\"truth_threshold\": 43.480000000000004, \"match_probability\": 0.9999999999999185, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 103, \"tn\": 7018, \"fp\": 0, \"fn\": 11678, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008742891095832272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912571089041677, \"precision\": 1.0, \"recall\": 0.008742891095832272, \"specificity\": 1.0, \"npv\": 0.3753744116388532, \"accuracy\": 0.3787967445076866, \"f1\": 0.01733423089868731, \"f2\": 0.01090477904588477, \"f0_5\": 0.04223734929877799, \"p4\": 0.033601403195385814, \"phi\": 0.05728749951883577}, {\"truth_threshold\": 43.54, \"match_probability\": 0.9999999999999218, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 101, \"tn\": 7018, \"fp\": 0, \"fn\": 11680, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008573126220185044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991426873779815, \"precision\": 1.0, \"recall\": 0.008573126220185044, \"specificity\": 1.0, \"npv\": 0.3753342603487004, \"accuracy\": 0.3786903558699931, \"f1\": 0.017000504965494025, \"f2\": 0.010693488618316569, \"f0_5\": 0.041444398851046366, \"p4\": 0.03297395672501377, \"phi\": 0.05672554969966534}, {\"truth_threshold\": 43.62, \"match_probability\": 0.9999999999999261, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 100, \"tn\": 7018, \"fp\": 0, \"fn\": 11681, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008488243782361429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9915117562176385, \"precision\": 1.0, \"recall\": 0.008488243782361429, \"specificity\": 1.0, \"npv\": 0.37531418792448795, \"accuracy\": 0.37863716155114635, \"f1\": 0.0168335998653312, \"f2\": 0.010587836693206844, \"f0_5\": 0.0410475330432641, \"p4\": 0.0326598773244189, \"phi\": 0.056442522286677295}, {\"truth_threshold\": 43.64, \"match_probability\": 0.9999999999999271, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 98, \"tn\": 7018, \"fp\": 0, \"fn\": 11683, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008318478906714201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9916815210932858, \"precision\": 1.0, \"recall\": 0.008318478906714201, \"specificity\": 1.0, \"npv\": 0.3752740495160687, \"accuracy\": 0.37853077291345283, \"f1\": 0.016499705362404242, \"f2\": 0.010376519418914912, \"f0_5\": 0.04025301897642323, \"p4\": 0.032031004729407904, \"phi\": 0.05587225845745488}, {\"truth_threshold\": 43.68, \"match_probability\": 0.9999999999999291, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 97, \"tn\": 7018, \"fp\": 0, \"fn\": 11684, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008233596468890587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9917664035311095, \"precision\": 1.0, \"recall\": 0.008233596468890587, \"specificity\": 1.0, \"npv\": 0.3752539835311731, \"accuracy\": 0.3784775785946061, \"f1\": 0.016332715945445362, \"f2\": 0.010270854069164143, \"f0_5\": 0.03985537020297477, \"p4\": 0.03171621094835592, \"phi\": 0.05558497884986009}, {\"truth_threshold\": 43.88, \"match_probability\": 0.9999999999999383, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 96, \"tn\": 7018, \"fp\": 0, \"fn\": 11685, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008148714031066972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991851285968933, \"precision\": 1.0, \"recall\": 0.008148714031066972, \"specificity\": 1.0, \"npv\": 0.375233919692028, \"accuracy\": 0.37842438427575936, \"f1\": 0.016165698408689064, \"f2\": 0.010165184243964422, \"f0_5\": 0.03945745992601726, \"p4\": 0.031401178453049836, \"phi\": 0.055296237723073766}, {\"truth_threshold\": 43.9, \"match_probability\": 0.999999999999939, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 95, \"tn\": 7018, \"fp\": 0, \"fn\": 11686, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.008063831593243358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9919361684067567, \"precision\": 1.0, \"recall\": 0.008063831593243358, \"specificity\": 1.0, \"npv\": 0.37521385799828916, \"accuracy\": 0.3783711899569126, \"f1\": 0.015998652745031997, \"f2\": 0.010059509943031408, \"f0_5\": 0.03905928788750925, \"p4\": 0.031085906948971457, \"phi\": 0.05500601205640463}, {\"truth_threshold\": 43.94, \"match_probability\": 0.9999999999999407, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 94, \"tn\": 7018, \"fp\": 0, \"fn\": 11687, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007978949155419744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9920210508445803, \"precision\": 1.0, \"recall\": 0.007978949155419744, \"specificity\": 1.0, \"npv\": 0.3751937984496124, \"accuracy\": 0.37831799563806584, \"f1\": 0.015831578947368422, \"f2\": 0.009953831166080732, \"f0_5\": 0.03866085382906967, \"p4\": 0.030770396141120707, \"phi\": 0.054714278221121224}, {\"truth_threshold\": 44.04, \"match_probability\": 0.9999999999999447, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 92, \"tn\": 7018, \"fp\": 0, \"fn\": 11689, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007809184279772515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921908157202275, \"precision\": 1.0, \"recall\": 0.007809184279772515, \"specificity\": 1.0, \"npv\": 0.3751536857860694, \"accuracy\": 0.3782116070003724, \"f1\": 0.015497346921586793, \"f2\": 0.009742460182988818, \"f0_5\": 0.037863198617170135, \"p4\": 0.03013865543168654, \"phi\": 0.054126188352213486}, {\"truth_threshold\": 44.06, \"match_probability\": 0.9999999999999455, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 91, \"tn\": 7018, \"fp\": 0, \"fn\": 11690, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007724301841948901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9922756981580511, \"precision\": 1.0, \"recall\": 0.007724301841948901, \"specificity\": 1.0, \"npv\": 0.3751336326705153, \"accuracy\": 0.3781584126815256, \"f1\": 0.015330188679245283, \"f2\": 0.009636767976278725, \"f0_5\": 0.037463976945244955, \"p4\": 0.029822424937684718, \"phi\": 0.053829781810944055}, {\"truth_threshold\": 44.14, \"match_probability\": 0.9999999999999484, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 89, \"tn\": 7018, \"fp\": 0, \"fn\": 11692, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007554536966301672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924454630336983, \"precision\": 1.0, \"recall\": 0.007554536966301672, \"specificity\": 1.0, \"npv\": 0.3750935328701229, \"accuracy\": 0.3780520240438321, \"f1\": 0.014995787700084246, \"f2\": 0.009425370131107957, \"f0_5\": 0.03666474417071764, \"p4\": 0.029189242186423325, \"phi\": 0.05323211399041029}, {\"truth_threshold\": 44.160000000000004, \"match_probability\": 0.9999999999999492, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 88, \"tn\": 7018, \"fp\": 0, \"fn\": 11693, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007469654528478058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.992530345471522, \"precision\": 1.0, \"recall\": 0.007469654528478058, \"specificity\": 1.0, \"npv\": 0.3750734861845973, \"accuracy\": 0.3779988297249854, \"f1\": 0.014828544949026877, \"f2\": 0.009319664492078284, \"f0_5\": 0.03626473254759746, \"p4\": 0.02887228933382736, \"phi\": 0.052930797883565195}, {\"truth_threshold\": 44.22, \"match_probability\": 0.9999999999999512, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 87, \"tn\": 7018, \"fp\": 0, \"fn\": 11694, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0073847720906544435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926152279093455, \"precision\": 1.0, \"recall\": 0.0073847720906544435, \"specificity\": 1.0, \"npv\": 0.3750534416417272, \"accuracy\": 0.3779456354061386, \"f1\": 0.014661274014155713, \"f2\": 0.009213954375039714, \"f0_5\": 0.035864457086322035, \"p4\": 0.0285550950988829, \"phi\": 0.05262778912646552}, {\"truth_threshold\": 44.24, \"match_probability\": 0.9999999999999518, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 86, \"tn\": 7018, \"fp\": 0, \"fn\": 11695, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.00729988965283083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927001103471692, \"precision\": 1.0, \"recall\": 0.00729988965283083, \"specificity\": 1.0, \"npv\": 0.37503339924116924, \"accuracy\": 0.37789244108729186, \"f1\": 0.014493974888345832, \"f2\": 0.00910823977970769, \"f0_5\": 0.03546391752577319, \"p4\": 0.028237659182699174, \"phi\": 0.05232305830689357}, {\"truth_threshold\": 44.26, \"match_probability\": 0.9999999999999525, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 85, \"tn\": 7018, \"fp\": 0, \"fn\": 11696, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.007215007215007215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927849927849928, \"precision\": 1.0, \"recall\": 0.007215007215007215, \"specificity\": 1.0, \"npv\": 0.37501335898257987, \"accuracy\": 0.3778392467684451, \"f1\": 0.014326647564469915, \"f2\": 0.009002520705797623, \"f0_5\": 0.03506311360448808, \"p4\": 0.02791998128589456, \"phi\": 0.05201657515430447}, {\"truth_threshold\": 44.32, \"match_probability\": 0.9999999999999545, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 84, \"tn\": 7018, \"fp\": 0, \"fn\": 11697, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0071301247771836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928698752228164, \"precision\": 1.0, \"recall\": 0.0071301247771836, \"specificity\": 1.0, \"npv\": 0.3749933208656158, \"accuracy\": 0.3777860524495984, \"f1\": 0.01415929203539823, \"f2\": 0.008896797153024912, \"f0_5\": 0.03466204506065858, \"p4\": 0.027602061108595605, \"phi\": 0.051708308504362116}, {\"truth_threshold\": 44.34, \"match_probability\": 0.999999999999955, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 83, \"tn\": 7018, \"fp\": 0, \"fn\": 11698, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0070452423393599865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.99295475766064, \"precision\": 1.0, \"recall\": 0.0070452423393599865, \"specificity\": 1.0, \"npv\": 0.37497328488993376, \"accuracy\": 0.37773285813075164, \"f1\": 0.013991908293998651, \"f2\": 0.008791069121104922, \"f0_5\": 0.03426071163213077, \"p4\": 0.027283898350435987, \"phi\": 0.05139822626156914}, {\"truth_threshold\": 44.38, \"match_probability\": 0.9999999999999564, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 82, \"tn\": 7018, \"fp\": 0, \"fn\": 11699, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006960359901536372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930396400984637, \"precision\": 1.0, \"recall\": 0.006960359901536372, \"specificity\": 1.0, \"npv\": 0.37495325105519045, \"accuracy\": 0.3776796638119049, \"f1\": 0.013824496333136644, \"f2\": 0.008685336609752998, \"f0_5\": 0.03385911305640433, \"p4\": 0.02696549271055551, \"phi\": 0.051086295359863865}, {\"truth_threshold\": 44.44, \"match_probability\": 0.9999999999999581, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 81, \"tn\": 7018, \"fp\": 0, \"fn\": 11700, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006875477463712758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931245225362872, \"precision\": 1.0, \"recall\": 0.006875477463712758, \"specificity\": 1.0, \"npv\": 0.37493321936104285, \"accuracy\": 0.3776264694930581, \"f1\": 0.013657056145675266, \"f2\": 0.008579599618684462, \"f0_5\": 0.03345724907063197, \"p4\": 0.026646843887599105, \"phi\": 0.050772481721047695}, {\"truth_threshold\": 44.52, \"match_probability\": 0.9999999999999604, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 80, \"tn\": 7018, \"fp\": 0, \"fn\": 11701, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006790595025889143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932094049741108, \"precision\": 1.0, \"recall\": 0.006790595025889143, \"specificity\": 1.0, \"npv\": 0.37491318980714783, \"accuracy\": 0.3775732751742114, \"f1\": 0.01348958772447517, \"f2\": 0.008473858147614609, \"f0_5\": 0.03305511941161887, \"p4\": 0.02632795157971578, \"phi\": 0.05045675021089498}, {\"truth_threshold\": 44.6, \"match_probability\": 0.9999999999999625, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 79, \"tn\": 7018, \"fp\": 0, \"fn\": 11702, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006705712588065529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932942874119345, \"precision\": 1.0, \"recall\": 0.006705712588065529, \"specificity\": 1.0, \"npv\": 0.3748931623931624, \"accuracy\": 0.37752008085536465, \"f1\": 0.013322091062394605, \"f2\": 0.008368112196258713, \"f0_5\": 0.032652723815822106, \"p4\": 0.02600881548455763, \"phi\": 0.05013906459278557}, {\"truth_threshold\": 44.62, \"match_probability\": 0.999999999999963, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 78, \"tn\": 7018, \"fp\": 0, \"fn\": 11703, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006620830150241915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993379169849758, \"precision\": 1.0, \"recall\": 0.006620830150241915, \"specificity\": 1.0, \"npv\": 0.37487313711874365, \"accuracy\": 0.3774668865365179, \"f1\": 0.013154566152289401, \"f2\": 0.00826236176433202, \"f0_5\": 0.03225006201935004, \"p4\": 0.025689435299278796, \"phi\": 0.049819387478686944}, {\"truth_threshold\": 44.64, \"match_probability\": 0.9999999999999635, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 77, \"tn\": 7018, \"fp\": 0, \"fn\": 11704, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006535947712418301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9934640522875817, \"precision\": 1.0, \"recall\": 0.006535947712418301, \"specificity\": 1.0, \"npv\": 0.37485311398354876, \"accuracy\": 0.3774136922176711, \"f1\": 0.012987012987012988, \"f2\": 0.008156606851549755, \"f0_5\": 0.03184713375796178, \"p4\": 0.025369810720534437, \"phi\": 0.049497680277298374}, {\"truth_threshold\": 44.660000000000004, \"match_probability\": 0.999999999999964, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 75, \"tn\": 7018, \"fp\": 0, \"fn\": 11706, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006366182836771072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993633817163229, \"precision\": 1.0, \"recall\": 0.006366182836771072, \"specificity\": 1.0, \"npv\": 0.3748130741294595, \"accuracy\": 0.37730730357997766, \"f1\": 0.012651821862348178, \"f2\": 0.007945083582279286, \"f0_5\": 0.031040476781723367, \"p4\": 0.02472982716676875, \"phi\": 0.04884801489846203}, {\"truth_threshold\": 44.7, \"match_probability\": 0.999999999999965, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 72, \"tn\": 7018, \"fp\": 0, \"fn\": 11709, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006111535523300229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938884644766998, \"precision\": 1.0, \"recall\": 0.006111535523300229, \"specificity\": 1.0, \"npv\": 0.37475303038393765, \"accuracy\": 0.37714772062343743, \"f1\": 0.012148823082763858, \"f2\": 0.007627765064836003, \"f0_5\": 0.02982848620432513, \"p4\": 0.02376801127270241, \"phi\": 0.047857250836794256}, {\"truth_threshold\": 44.74, \"match_probability\": 0.9999999999999659, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 71, \"tn\": 7018, \"fp\": 0, \"fn\": 11710, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.006026653085476615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939733469145234, \"precision\": 1.0, \"recall\": 0.006026653085476615, \"specificity\": 1.0, \"npv\": 0.37473302007689024, \"accuracy\": 0.37709452630459067, \"f1\": 0.011981100236247048, \"f2\": 0.007521983260938659, \"f0_5\": 0.029423953584749276, \"p4\": 0.023446913934850794, \"phi\": 0.047522477962290234}, {\"truth_threshold\": 44.92, \"match_probability\": 0.9999999999999699, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 70, \"tn\": 7018, \"fp\": 0, \"fn\": 11711, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0059417706476530005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994058229352347, \"precision\": 1.0, \"recall\": 0.0059417706476530005, \"specificity\": 1.0, \"npv\": 0.3747130119066688, \"accuracy\": 0.3770413319857439, \"f1\": 0.011813349084465446, \"f2\": 0.007416196974191634, \"f0_5\": 0.02901915264074289, \"p4\": 0.02312557006606176, \"phi\": 0.047185366115361387}, {\"truth_threshold\": 44.94, \"match_probability\": 0.9999999999999704, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 69, \"tn\": 7018, \"fp\": 0, \"fn\": 11712, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005856888209829387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941431117901706, \"precision\": 1.0, \"recall\": 0.005856888209829387, \"specificity\": 1.0, \"npv\": 0.37469300587293114, \"accuracy\": 0.37698813766689715, \"f1\": 0.011645569620253165, \"f2\": 0.0073104062043099615, \"f0_5\": 0.02861408310525006, \"p4\": 0.022803979358961425, \"phi\": 0.04684586479512042}, {\"truth_threshold\": 44.980000000000004, \"match_probability\": 0.9999999999999711, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 68, \"tn\": 7018, \"fp\": 0, \"fn\": 11713, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005772005772005772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942279942279942, \"precision\": 1.0, \"recall\": 0.005772005772005772, \"specificity\": 1.0, \"npv\": 0.374673001975335, \"accuracy\": 0.37693494334805044, \"f1\": 0.011477761836441894, \"f2\": 0.007204610951008645, \"f0_5\": 0.028208744710860368, \"p4\": 0.02248214150566759, \"phi\": 0.04650392166276263}, {\"truth_threshold\": 45.08, \"match_probability\": 0.9999999999999731, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 67, \"tn\": 7018, \"fp\": 0, \"fn\": 11714, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005687123334182157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943128766658178, \"precision\": 1.0, \"recall\": 0.005687123334182157, \"specificity\": 1.0, \"npv\": 0.3746530002135383, \"accuracy\": 0.3768817490292037, \"f1\": 0.011309925725860905, \"f2\": 0.00709881121400267, \"f0_5\": 0.027803137189808282, \"p4\": 0.022160056197788654, \"phi\": 0.0461594824465761}, {\"truth_threshold\": 45.14, \"match_probability\": 0.9999999999999742, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 64, \"tn\": 7018, \"fp\": 0, \"fn\": 11717, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005432476020711315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945675239792887, \"precision\": 1.0, \"recall\": 0.005432476020711315, \"specificity\": 1.0, \"npv\": 0.374593007739525, \"accuracy\": 0.37672216607266346, \"f1\": 0.010806247361756015, \"f2\": 0.006781385097906247, \"f0_5\": 0.026584697183683642, \"p4\": 0.021192312455062673, \"phi\": 0.04511061440582579}, {\"truth_threshold\": 45.24, \"match_probability\": 0.9999999999999759, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 63, \"tn\": 7018, \"fp\": 0, \"fn\": 11718, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0053475935828877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946524064171123, \"precision\": 1.0, \"recall\": 0.0053475935828877, \"specificity\": 1.0, \"npv\": 0.3745730145175064, \"accuracy\": 0.3766689717538167, \"f1\": 0.010638297872340425, \"f2\": 0.006675567423230975, \"f0_5\": 0.02617801047120419, \"p4\": 0.020869234234703056, \"phi\": 0.04475560578024521}, {\"truth_threshold\": 45.26, \"match_probability\": 0.9999999999999762, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 62, \"tn\": 7018, \"fp\": 0, \"fn\": 11719, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005262711145064086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994737288854936, \"precision\": 1.0, \"recall\": 0.005262711145064086, \"specificity\": 1.0, \"npv\": 0.37455302342957786, \"accuracy\": 0.37661577743496993, \"f1\": 0.010470320020265135, \"f2\": 0.006569745263425592, \"f0_5\": 0.025771053287887605, \"p4\": 0.020545907010122797, \"phi\": 0.04439779691403943}, {\"truth_threshold\": 45.34, \"match_probability\": 0.9999999999999776, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 61, \"tn\": 7018, \"fp\": 0, \"fn\": 11720, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005177828707240472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9948221712927595, \"precision\": 1.0, \"recall\": 0.005177828707240472, \"specificity\": 1.0, \"npv\": 0.3745330344753976, \"accuracy\": 0.3765625831161232, \"f1\": 0.010302313798344875, \"f2\": 0.006463918618204938, \"f0_5\": 0.025363825363825365, \"p4\": 0.020222330469851817, \"phi\": 0.04403711954381893}, {\"truth_threshold\": 45.5, \"match_probability\": 0.9999999999999799, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 60, \"tn\": 7018, \"fp\": 0, \"fn\": 11721, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005092946269416858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949070537305832, \"precision\": 1.0, \"recall\": 0.005092946269416858, \"specificity\": 1.0, \"npv\": 0.37451304765462406, \"accuracy\": 0.37650938879727647, \"f1\": 0.010134279199391943, \"f2\": 0.006358087487283825, \"f0_5\": 0.02495632642874969, \"p4\": 0.019898504301903236, \"phi\": 0.04367350259482923}, {\"truth_threshold\": 45.58, \"match_probability\": 0.999999999999981, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 59, \"tn\": 7018, \"fp\": 0, \"fn\": 11722, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.005008063831593243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949919361684068, \"precision\": 1.0, \"recall\": 0.005008063831593243, \"specificity\": 1.0, \"npv\": 0.3744930629669157, \"accuracy\": 0.3764561944784297, \"f1\": 0.009966216216216217, \"f2\": 0.0062522518703770425, \"f0_5\": 0.024548556212032953, \"p4\": 0.019574428193772288, \"phi\": 0.04330687201619601}, {\"truth_threshold\": 45.64, \"match_probability\": 0.9999999999999818, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 58, \"tn\": 7018, \"fp\": 0, \"fn\": 11723, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004923181393769629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950768186062303, \"precision\": 1.0, \"recall\": 0.004923181393769629, \"specificity\": 1.0, \"npv\": 0.37447308041193106, \"accuracy\": 0.37640300015958295, \"f1\": 0.009798124841625138, \"f2\": 0.006146411767199355, \"f0_5\": 0.02414051444268709, \"p4\": 0.01925010183243524, \"phi\": 0.04293715060354631}, {\"truth_threshold\": 45.74, \"match_probability\": 0.999999999999983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 57, \"tn\": 7018, \"fp\": 0, \"fn\": 11724, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004838298955946015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995161701044054, \"precision\": 1.0, \"recall\": 0.004838298955946015, \"specificity\": 1.0, \"npv\": 0.3744530999893288, \"accuracy\": 0.3763498058407362, \"f1\": 0.00963000506842372, \"f2\": 0.006040567177465505, \"f0_5\": 0.023732200849362978, \"p4\": 0.018925524904348335, \"phi\": 0.04256425780780299}, {\"truth_threshold\": 45.78, \"match_probability\": 0.9999999999999835, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 56, \"tn\": 7018, \"fp\": 0, \"fn\": 11725, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004753416518122401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952465834818776, \"precision\": 1.0, \"recall\": 0.004753416518122401, \"specificity\": 1.0, \"npv\": 0.3744331216987675, \"accuracy\": 0.3762966115218895, \"f1\": 0.009461856889414548, \"f2\": 0.005934718100890208, \"f0_5\": 0.023323615160349854, \"p4\": 0.01860069709544668, \"phi\": 0.04218810952881222}, {\"truth_threshold\": 45.88, \"match_probability\": 0.9999999999999846, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 55, \"tn\": 7018, \"fp\": 0, \"fn\": 11726, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004668534080298786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9953314659197012, \"precision\": 1.0, \"recall\": 0.004668534080298786, \"specificity\": 1.0, \"npv\": 0.3744131455399061, \"accuracy\": 0.3762434172030427, \"f1\": 0.00929368029739777, \"f2\": 0.0058288645371881555, \"f0_5\": 0.022914757103574702, \"p4\": 0.0182756180911432, \"phi\": 0.04180861789230686}, {\"truth_threshold\": 45.9, \"match_probability\": 0.9999999999999848, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 54, \"tn\": 7018, \"fp\": 0, \"fn\": 11727, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004583651642475172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954163483575248, \"precision\": 1.0, \"recall\": 0.004583651642475172, \"specificity\": 1.0, \"npv\": 0.3743931715124033, \"accuracy\": 0.37619022288419596, \"f1\": 0.009125475285171103, \"f2\": 0.005723006486074018, \"f0_5\": 0.02250562640660165, \"p4\": 0.017950287576327516, \"phi\": 0.041425691008531364}, {\"truth_threshold\": 45.92, \"match_probability\": 0.999999999999985, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 53, \"tn\": 7018, \"fp\": 0, \"fn\": 11728, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0044987692046515575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955012307953485, \"precision\": 1.0, \"recall\": 0.0044987692046515575, \"specificity\": 1.0, \"npv\": 0.3743731996159181, \"accuracy\": 0.3761370285653492, \"f1\": 0.00895724184552983, \"f2\": 0.0056171439472624375, \"f0_5\": 0.022096222796631367, \"p4\": 0.017624705235364874, \"phi\": 0.04103923271065095}, {\"truth_threshold\": 45.94, \"match_probability\": 0.9999999999999852, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 51, \"tn\": 7018, \"fp\": 0, \"fn\": 11730, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004329004329004329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956709956709957, \"precision\": 1.0, \"recall\": 0.004329004329004329, \"specificity\": 1.0, \"npv\": 0.37433326221463625, \"accuracy\": 0.37603063992765573, \"f1\": 0.008620689655172414, \"f2\": 0.005405405405405406, \"f0_5\": 0.02127659574468085, \"p4\": 0.0169727838098313, \"phi\": 0.040255314091650965}, {\"truth_threshold\": 46.0, \"match_probability\": 0.9999999999999858, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 48, \"tn\": 7018, \"fp\": 0, \"fn\": 11733, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.004074357015533486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9959256429844665, \"precision\": 1.0, \"recall\": 0.004074357015533486, \"specificity\": 1.0, \"npv\": 0.37427337208682204, \"accuracy\": 0.3758710569711155, \"f1\": 0.008115647983768704, \"f2\": 0.005087763927753753, \"f0_5\": 0.020045101478326235, \"p4\": 0.015993005054286958, \"phi\": 0.039050266827376716}, {\"truth_threshold\": 46.02, \"match_probability\": 0.999999999999986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 46, \"tn\": 7018, \"fp\": 0, \"fn\": 11735, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0039045921398862577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960954078601137, \"precision\": 1.0, \"recall\": 0.0039045921398862577, \"specificity\": 1.0, \"npv\": 0.3742334559803765, \"accuracy\": 0.375764668333422, \"f1\": 0.007778811194723937, \"f2\": 0.004875980496078016, \"f0_5\": 0.0192227329711659, \"p4\": 0.01533855109256792, \"phi\": 0.03822602530611111}, {\"truth_threshold\": 46.04, \"match_probability\": 0.9999999999999862, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 45, \"tn\": 7018, \"fp\": 0, \"fn\": 11736, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0038197097020626434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961802902979373, \"precision\": 1.0, \"recall\": 0.0038197097020626434, \"specificity\": 1.0, \"npv\": 0.3742135011197611, \"accuracy\": 0.3757114740145752, \"f1\": 0.0076103500761035, \"f2\": 0.004770082045411181, \"f0_5\": 0.018811136192626036, \"p4\": 0.0150109427162919, \"phi\": 0.03780723397539129}, {\"truth_threshold\": 46.08, \"match_probability\": 0.9999999999999866, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 44, \"tn\": 7018, \"fp\": 0, \"fn\": 11737, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.003734827264239029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996265172735761, \"precision\": 1.0, \"recall\": 0.003734827264239029, \"specificity\": 1.0, \"npv\": 0.3741935483870968, \"accuracy\": 0.3756582796957285, \"f1\": 0.0074418604651162795, \"f2\": 0.0046641791044776115, \"f0_5\": 0.01839926402943882, \"p4\": 0.014683079649378185, \"phi\": 0.03738379684593949}, {\"truth_threshold\": 46.1, \"match_probability\": 0.9999999999999868, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 43, \"tn\": 7018, \"fp\": 0, \"fn\": 11738, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.003649944826415415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963500551735845, \"precision\": 1.0, \"recall\": 0.003649944826415415, \"specificity\": 1.0, \"npv\": 0.37417359778204307, \"accuracy\": 0.37560508537688175, \"f1\": 0.007273342354533153, \"f2\": 0.00455827167299171, \"f0_5\": 0.017987116205136787, \"p4\": 0.01435496157088776, \"phi\": 0.0369555542159201}, {\"truth_threshold\": 46.34, \"match_probability\": 0.9999999999999888, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 42, \"tn\": 7018, \"fp\": 0, \"fn\": 11739, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0035650623885918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964349376114082, \"precision\": 1.0, \"recall\": 0.0035650623885918, \"specificity\": 1.0, \"npv\": 0.37415364930425976, \"accuracy\": 0.375551891058035, \"f1\": 0.007104795737122558, \"f2\": 0.004452359750667854, \"f0_5\": 0.01757469244288225, \"p4\": 0.01402658815934508, \"phi\": 0.03652233703761279}, {\"truth_threshold\": 46.38, \"match_probability\": 0.9999999999999891, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 41, \"tn\": 7018, \"fp\": 0, \"fn\": 11740, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.003480179950768186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965198200492318, \"precision\": 1.0, \"recall\": 0.003480179950768186, \"specificity\": 1.0, \"npv\": 0.37413370295340653, \"accuracy\": 0.37549869673918823, \"f1\": 0.006936220605650482, \"f2\": 0.004346443337220397, \"f0_5\": 0.01716199246546672, \"p4\": 0.013697959092736932, \"phi\": 0.03608396613352121}, {\"truth_threshold\": 46.42, \"match_probability\": 0.9999999999999893, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 39, \"tn\": 7018, \"fp\": 0, \"fn\": 11742, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0033104150751209573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996689584924879, \"precision\": 1.0, \"recall\": 0.0033104150751209573, \"specificity\": 1.0, \"npv\": 0.37409381663113006, \"accuracy\": 0.37539230810149476, \"f1\": 0.006598984771573604, \"f2\": 0.004134597035811971, \"f0_5\": 0.01633576275446092, \"p4\": 0.013039932703576363, \"phi\": 0.035190990467522054}, {\"truth_threshold\": 46.58, \"match_probability\": 0.9999999999999905, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 38, \"tn\": 7018, \"fp\": 0, \"fn\": 11743, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.003225532637297343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967744673627027, \"precision\": 1.0, \"recall\": 0.003225532637297343, \"specificity\": 1.0, \"npv\": 0.3740738766590267, \"accuracy\": 0.375339113782648, \"f1\": 0.0064303240544885355, \"f2\": 0.004028667147279589, \"f0_5\": 0.015922232464593983, \"p4\": 0.012710534734299093, \"phi\": 0.03473596836024629}, {\"truth_threshold\": 46.62, \"match_probability\": 0.9999999999999908, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 37, \"tn\": 7018, \"fp\": 0, \"fn\": 11744, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.003140650199473729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968593498005263, \"precision\": 1.0, \"recall\": 0.003140650199473729, \"specificity\": 1.0, \"npv\": 0.3740539388124933, \"accuracy\": 0.37528591946380124, \"f1\": 0.006261634794381452, \"f2\": 0.003922732766480779, \"f0_5\": 0.015508424847011485, \"p4\": 0.0123808798165044, \"phi\": 0.03427495554403231}, {\"truth_threshold\": 46.800000000000004, \"match_probability\": 0.9999999999999918, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 36, \"tn\": 7018, \"fp\": 0, \"fn\": 11745, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0030557677616501145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969442322383499, \"precision\": 1.0, \"recall\": 0.0030557677616501145, \"specificity\": 1.0, \"npv\": 0.3740340030911901, \"accuracy\": 0.37523272514495454, \"f1\": 0.006092916984006093, \"f2\": 0.003816793893129771, \"f0_5\": 0.01509433962264151, \"p4\": 0.012050967625473853, \"phi\": 0.033807706938019294}, {\"truth_threshold\": 46.92, \"match_probability\": 0.9999999999999925, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 33, \"tn\": 7018, \"fp\": 0, \"fn\": 11748, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0028011204481792717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971988795518207, \"precision\": 1.0, \"recall\": 0.0028011204481792717, \"specificity\": 1.0, \"npv\": 0.37397420867526376, \"accuracy\": 0.37507314218841425, \"f1\": 0.00558659217877095, \"f2\": 0.0034989503149055285, \"f0_5\": 0.013850415512465374, \"p4\": 0.011059684157609167, \"phi\": 0.032365827704724986}, {\"truth_threshold\": 47.02, \"match_probability\": 0.999999999999993, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 32, \"tn\": 7018, \"fp\": 0, \"fn\": 11749, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0027162380103556575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972837619896443, \"precision\": 1.0, \"recall\": 0.0027162380103556575, \"specificity\": 1.0, \"npv\": 0.37395428145148396, \"accuracy\": 0.37501994786956755, \"f1\": 0.005417760094810801, \"f2\": 0.0033929934684875734, \"f0_5\": 0.01343521706272567, \"p4\": 0.01072873961554474, \"phi\": 0.03187081475917675}, {\"truth_threshold\": 47.24, \"match_probability\": 0.999999999999994, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 31, \"tn\": 7018, \"fp\": 0, \"fn\": 11750, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.002631355572532043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997368644427468, \"precision\": 1.0, \"recall\": 0.002631355572532043, \"specificity\": 1.0, \"npv\": 0.3739343563512361, \"accuracy\": 0.3749667535507208, \"f1\": 0.005248899424314257, \"f2\": 0.0032870321280882198, \"f0_5\": 0.013019739605207897, \"p4\": 0.010397536168462663, \"phi\": 0.03136804508326918}, {\"truth_threshold\": 47.300000000000004, \"match_probability\": 0.9999999999999942, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 30, \"tn\": 7018, \"fp\": 0, \"fn\": 11751, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.002546473134708429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974535268652915, \"precision\": 1.0, \"recall\": 0.002546473134708429, \"specificity\": 1.0, \"npv\": 0.37391443337418084, \"accuracy\": 0.374913559231874, \"f1\": 0.00508001016002032, \"f2\": 0.003181066293421555, \"f0_5\": 0.012603982858583312, \"p4\": 0.010066073488360618, \"phi\": 0.03085713951854702}, {\"truth_threshold\": 47.34, \"match_probability\": 0.9999999999999943, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 29, \"tn\": 7018, \"fp\": 0, \"fn\": 11752, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0024615906968848147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975384093031152, \"precision\": 1.0, \"recall\": 0.0024615906968848147, \"specificity\": 1.0, \"npv\": 0.3738945125199787, \"accuracy\": 0.37486036491302727, \"f1\": 0.004911092294665537, \"f2\": 0.0030750959642016416, \"f0_5\": 0.012187946541144827, \"p4\": 0.009734351246684939, \"phi\": 0.030337687018549428}, {\"truth_threshold\": 47.36, \"match_probability\": 0.9999999999999944, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 28, \"tn\": 7018, \"fp\": 0, \"fn\": 11753, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0023767082590612004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976232917409388, \"precision\": 1.0, \"recall\": 0.0023767082590612004, \"specificity\": 1.0, \"npv\": 0.37387459378829047, \"accuracy\": 0.37480717059418056, \"f1\": 0.004742145820983995, \"f2\": 0.0029691211401425177, \"f0_5\": 0.011771630370806356, \"p4\": 0.009402369114329453, \"phi\": 0.029809240763725958}, {\"truth_threshold\": 47.38, \"match_probability\": 0.9999999999999946, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 27, \"tn\": 7018, \"fp\": 0, \"fn\": 11754, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.002291825821237586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977081741787625, \"precision\": 1.0, \"recall\": 0.002291825821237586, \"specificity\": 1.0, \"npv\": 0.3738546771787769, \"accuracy\": 0.3747539762753338, \"f1\": 0.004573170731707317, \"f2\": 0.002863141820958198, \"f0_5\": 0.011355034065102196, \"p4\": 0.00907012676163432, \"phi\": 0.02927131364576525}, {\"truth_threshold\": 47.44, \"match_probability\": 0.9999999999999948, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 26, \"tn\": 7018, \"fp\": 0, \"fn\": 11755, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.002206943383413972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997793056616586, \"precision\": 1.0, \"recall\": 0.002206943383413972, \"specificity\": 1.0, \"npv\": 0.37383476269109894, \"accuracy\": 0.37470078195648704, \"f1\": 0.004404167019564665, \"f2\": 0.002757158006362672, \"f0_5\": 0.01093815734118637, \"p4\": 0.00873762385838487, \"phi\": 0.028723372991542147}, {\"truth_threshold\": 47.92, \"match_probability\": 0.9999999999999962, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 24, \"tn\": 7018, \"fp\": 0, \"fn\": 11757, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.002037178507766743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979628214922333, \"precision\": 1.0, \"recall\": 0.002037178507766743, \"specificity\": 1.0, \"npv\": 0.3737949400798935, \"accuracy\": 0.3745943933187936, \"f1\": 0.004066073697585769, \"f2\": 0.0025451768897938407, \"f0_5\": 0.010103561505430665, \"p4\": 0.00807183507658316, \"phi\": 0.027595054235183457}, {\"truth_threshold\": 47.94, \"match_probability\": 0.9999999999999963, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 23, \"tn\": 7018, \"fp\": 0, \"fn\": 11758, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0019522960699431288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980477039300568, \"precision\": 1.0, \"recall\": 0.0019522960699431288, \"specificity\": 1.0, \"npv\": 0.3737750319556881, \"accuracy\": 0.3745411989999468, \"f1\": 0.003896984073195527, \"f2\": 0.0024391795872483932, \"f0_5\": 0.009685841825991746, \"p4\": 0.007738548534816864, \"phi\": 0.027013321268032877}, {\"truth_threshold\": 47.980000000000004, \"match_probability\": 0.9999999999999964, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 22, \"tn\": 7018, \"fp\": 0, \"fn\": 11759, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0018674136321195146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981325863678805, \"precision\": 1.0, \"recall\": 0.0018674136321195146, \"specificity\": 1.0, \"npv\": 0.37375512595196253, \"accuracy\": 0.37448800468110005, \"f1\": 0.003727865796831314, \"f2\": 0.0023331777881474567, \"f0_5\": 0.009267840593141797, \"p4\": 0.007405000116065832, \"phi\": 0.026418845873301143}, {\"truth_threshold\": 48.2, \"match_probability\": 0.9999999999999969, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 21, \"tn\": 7018, \"fp\": 0, \"fn\": 11760, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0017825311942959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982174688057041, \"precision\": 1.0, \"recall\": 0.0017825311942959, \"specificity\": 1.0, \"npv\": 0.3737352220683779, \"accuracy\": 0.3744348103622533, \"f1\": 0.0035587188612099642, \"f2\": 0.0022271714922048997, \"f0_5\": 0.008849557522123894, \"p4\": 0.007071189487323649, \"phi\": 0.025810747601415752}, {\"truth_threshold\": 48.22, \"match_probability\": 0.999999999999997, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 20, \"tn\": 7018, \"fp\": 0, \"fn\": 11761, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0016976487564722858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983023512435277, \"precision\": 1.0, \"recall\": 0.0016976487564722858, \"specificity\": 1.0, \"npv\": 0.37371532030459553, \"accuracy\": 0.3743816160434066, \"f1\": 0.0033895432590458434, \"f2\": 0.0021211606991345666, \"f0_5\": 0.008430992327796982, \"p4\": 0.00673711631502201, \"phi\": 0.025188039796493467}, {\"truth_threshold\": 48.36, \"match_probability\": 0.9999999999999972, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 19, \"tn\": 7018, \"fp\": 0, \"fn\": 11762, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0016127663186486715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983872336813513, \"precision\": 1.0, \"recall\": 0.0016127663186486715, \"specificity\": 1.0, \"npv\": 0.3736954206602769, \"accuracy\": 0.3743284217245598, \"f1\": 0.0032203389830508474, \"f2\": 0.0020151454086502767, \"f0_5\": 0.008012144724635236, \"p4\": 0.006402780265029544, \"phi\": 0.024549610747914955}, {\"truth_threshold\": 48.480000000000004, \"match_probability\": 0.9999999999999974, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 18, \"tn\": 7018, \"fp\": 0, \"fn\": 11763, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0015278838808250573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998472116119175, \"precision\": 1.0, \"recall\": 0.0015278838808250573, \"specificity\": 1.0, \"npv\": 0.37367552313508334, \"accuracy\": 0.37427522740571306, \"f1\": 0.0030511060259344014, \"f2\": 0.0019091256204658267, \"f0_5\": 0.007593014426727411, \"p4\": 0.006068181002650614, \"phi\": 0.02389420031005358}, {\"truth_threshold\": 48.620000000000005, \"match_probability\": 0.9999999999999977, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 17, \"tn\": 7018, \"fp\": 0, \"fn\": 11764, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.001443001443001443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985569985569985, \"precision\": 1.0, \"recall\": 0.001443001443001443, \"specificity\": 1.0, \"npv\": 0.3736556277286764, \"accuracy\": 0.3742220330868663, \"f1\": 0.002881844380403458, \"f2\": 0.0018031013342949874, \"f0_5\": 0.007173601147776184, \"p4\": 0.005733318192624133, \"phi\": 0.02322037058270367}, {\"truth_threshold\": 48.72, \"match_probability\": 0.9999999999999979, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 16, \"tn\": 7018, \"fp\": 0, \"fn\": 11765, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0013581190051778287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986418809948222, \"precision\": 1.0, \"recall\": 0.0013581190051778287, \"specificity\": 1.0, \"npv\": 0.3736357344407177, \"accuracy\": 0.3741688387680196, \"f1\": 0.002712554039162499, \"f2\": 0.0016970725498515061, \"f0_5\": 0.006753904601097509, \"p4\": 0.005398191499122363, \"phi\": 0.022526468697013188}, {\"truth_threshold\": 48.94, \"match_probability\": 0.9999999999999981, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 15, \"tn\": 7018, \"fp\": 0, \"fn\": 11766, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0012732365673542145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987267634326458, \"precision\": 1.0, \"recall\": 0.0012732365673542145, \"specificity\": 1.0, \"npv\": 0.37361584327086883, \"accuracy\": 0.37411564444917284, \"f1\": 0.00254323499491353, \"f2\": 0.0015910392668491058, \"f0_5\": 0.006333924499619965, \"p4\": 0.005062800585749724, \"phi\": 0.021810578942232397}, {\"truth_threshold\": 49.02, \"match_probability\": 0.9999999999999982, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 14, \"tn\": 7018, \"fp\": 0, \"fn\": 11767, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0011883541295306002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988116458704694, \"precision\": 1.0, \"recall\": 0.0011883541295306002, \"specificity\": 1.0, \"npv\": 0.3735959542187916, \"accuracy\": 0.3740624501303261, \"f1\": 0.002373887240356083, \"f2\": 0.001485001485001485, \"f0_5\": 0.0059136605558840925, \"p4\": 0.004727145115541584, \"phi\": 0.02107046024584717}, {\"truth_threshold\": 49.06, \"match_probability\": 0.9999999999999983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 13, \"tn\": 7018, \"fp\": 0, \"fn\": 11768, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.001103471691706986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998896528308293, \"precision\": 1.0, \"recall\": 0.001103471691706986, \"specificity\": 1.0, \"npv\": 0.3735760672841478, \"accuracy\": 0.3740092558114793, \"f1\": 0.0022045107681872137, \"f2\": 0.0013789592040223178, \"f0_5\": 0.005493112482041747, \"p4\": 0.0043912247509630626, \"phi\": 0.020303463126946628}, {\"truth_threshold\": 49.1, \"match_probability\": 0.9999999999999983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 12, \"tn\": 7018, \"fp\": 0, \"fn\": 11769, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0010185892538833714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989814107461167, \"precision\": 1.0, \"recall\": 0.0010185892538833714, \"specificity\": 1.0, \"npv\": 0.3735561824665992, \"accuracy\": 0.3739560614926326, \"f1\": 0.002035105571101501, \"f2\": 0.0012729124236252546, \"f0_5\": 0.00507227998985544, \"p4\": 0.004055039153907818, \"phi\": 0.01950641723080315}, {\"truth_threshold\": 49.14, \"match_probability\": 0.9999999999999983, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 11, \"tn\": 7018, \"fp\": 0, \"fn\": 11770, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0009337068160597573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990662931839402, \"precision\": 1.0, \"recall\": 0.0009337068160597573, \"specificity\": 1.0, \"npv\": 0.373536299765808, \"accuracy\": 0.37390286717378585, \"f1\": 0.0018656716417910447, \"f2\": 0.0011668611435239206, \"f0_5\": 0.004651162790697674, \"p4\": 0.0037185879856968416, \"phi\": 0.018675475606716837}, {\"truth_threshold\": 49.34, \"match_probability\": 0.9999999999999986, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 8, \"tn\": 7018, \"fp\": 0, \"fn\": 11773, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0006790595025889144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999320940497411, \"precision\": 1.0, \"recall\": 0.0006790595025889144, \"specificity\": 1.0, \"npv\": 0.3734766643605982, \"accuracy\": 0.3737432842172456, \"f1\": 0.0013571973873950293, \"f2\": 0.0008486803021301876, \"f0_5\": 0.003386100059256751, \"p4\": 0.0027076376587238885, \"phi\": 0.01592522771985615}, {\"truth_threshold\": 49.980000000000004, \"match_probability\": 0.9999999999999991, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 7, \"tn\": 7018, \"fp\": 0, \"fn\": 11774, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0005941770647653001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994058229352347, \"precision\": 1.0, \"recall\": 0.0005941770647653001, \"specificity\": 1.0, \"npv\": 0.3734567901234568, \"accuracy\": 0.37369008989839886, \"f1\": 0.0011876484560570072, \"f2\": 0.0007426110203475419, \"f0_5\": 0.002963841138114997, \"p4\": 0.0023701208076039744, \"phi\": 0.014896290121108217}, {\"truth_threshold\": 51.24, \"match_probability\": 0.9999999999999997, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 6, \"tn\": 7018, \"fp\": 0, \"fn\": 11775, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0005092946269416857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994907053730583, \"precision\": 1.0, \"recall\": 0.0005092946269416857, \"specificity\": 1.0, \"npv\": 0.3734369180013835, \"accuracy\": 0.3736368955795521, \"f1\": 0.0010180707559175363, \"f2\": 0.0006365372374283895, \"f0_5\": 0.0025412960609911056, \"p4\": 0.002032336683300668, \"phi\": 0.013790917875173048}, {\"truth_threshold\": 51.88, \"match_probability\": 0.9999999999999998, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 5, \"tn\": 7018, \"fp\": 0, \"fn\": 11776, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.00042441218911807145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999575587810882, \"precision\": 1.0, \"recall\": 0.00042441218911807145, \"specificity\": 1.0, \"npv\": 0.37341704799404063, \"accuracy\": 0.37358370126070534, \"f1\": 0.0008484642796538266, \"f2\": 0.0005304589530862101, \"f0_5\": 0.002118464536903652, \"p4\": 0.0016942849436733546, \"phi\": 0.012588993080987801}, {\"truth_threshold\": 52.34, \"match_probability\": 0.9999999999999998, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 4, \"tn\": 7018, \"fp\": 0, \"fn\": 11777, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.0003395297512944572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996604702487055, \"precision\": 1.0, \"recall\": 0.0003395297512944572, \"specificity\": 1.0, \"npv\": 0.37339718010109074, \"accuracy\": 0.37353050694185863, \"f1\": 0.0006788290199406025, \"f2\": 0.00042437616703445936, \"f0_5\": 0.0016953462744765618, \"p4\": 0.0013559652460001935, \"phi\": 0.011259638168865596}, {\"truth_threshold\": 53.84, \"match_probability\": 1.0, \"row_count\": 18799, \"p\": 11781, \"n\": 7018, \"tp\": 3, \"tn\": 7018, \"fp\": 0, \"fn\": 11778, \"P_rate\": 0, \"N_rate\": 0.37331772966647164, \"tp_rate\": 0.00025464731347084286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997453526865292, \"precision\": 1.0, \"recall\": 0.00025464731347084286, \"specificity\": 1.0, \"npv\": 0.37337731432219623, \"accuracy\": 0.37347731262301187, \"f1\": 0.0005091649694501018, \"f2\": 0.0003182888789865682, \"f0_5\": 0.0012719409819384382, \"p4\": 0.0010173772469768798, \"phi\": 0.009750873294382699}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.roc_chart_from_labels_column(\"cluster\",match_weight_round_to_nearest=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-dd5fecbcf26441179696c3c99a6e2e7d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-dd5fecbcf26441179696c3c99a6e2e7d.vega-embed details,\n",
       "  #altair-viz-dd5fecbcf26441179696c3c99a6e2e7d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-dd5fecbcf26441179696c3c99a6e2e7d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dd5fecbcf26441179696c3c99a6e2e7d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dd5fecbcf26441179696c3c99a6e2e7d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-e0f8afebca08d9e8b961c13cb1c9a4f6\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 0, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-e0f8afebca08d9e8b961c13cb1c9a4f6\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.839869680552132, \"bayes_factor\": 1.7898884529308656, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.79 times more likely to be a match\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -7.464561609204118, \"bayes_factor\": 0.005661650431871289, \"comparison_vector_value\": 0, \"m_probability\": 0.0050748169841719325, \"u_probability\": 0.8963494029239464, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  176.63 times less likely to be a match\", \"value_l\": \"1544-01-01\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.0050748169841719325, \"u_probability\": 0.8963494029239464, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  176.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"log2_bayes_factor\": 12.155156695958162, \"bayes_factor\": 4561.070314541897, \"comparison_vector_value\": 3, \"m_probability\": 0.6782020576745722, \"u_probability\": 0.00014869362033562275, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 4,561.07 times more likely to be a match\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 7.391818276393672, \"bayes_factor\": 167.9418850931352, \"comparison_vector_value\": 1, \"m_probability\": 0.8446977877170962, \"u_probability\": 0.005029702907339964, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 167.94 times more likely to be a match\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"log2_bayes_factor\": 1.1984112555564117, \"bayes_factor\": 2.294868131775271, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.29 times more likely to be a match\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 14.513676628206374, \"bayes_factor\": 23391.17361852464, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.999,\n",
    "    include_false_negatives=False,\n",
    "    include_false_positives=True,\n",
    ").as_record_dict()\n",
    "linker.waterfall_chart(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9bdadf440d8349e19b289c3f60d74f48.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9bdadf440d8349e19b289c3f60d74f48.vega-embed details,\n",
       "  #altair-viz-9bdadf440d8349e19b289c3f60d74f48.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9bdadf440d8349e19b289c3f60d74f48\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9bdadf440d8349e19b289c3f60d74f48\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9bdadf440d8349e19b289c3f60d74f48\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-6289e08f68cbe4734216537925e704f4\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 49, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-6289e08f68cbe4734216537925e704f4\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"pearce\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.6195619380851652, \"bayes_factor\": 0.6508685283384966, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.54 times less likely to be a match\", \"value_l\": \"pearce\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"tf2 9tu\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"oakengates\", \"value_r\": \"telford and wrekin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.84420477291392, \"bayes_factor\": 0.13925443948530114, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"pearce\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.6195619380851652, \"bayes_factor\": 0.6508685283384966, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.54 times less likely to be a match\", \"value_l\": \"pearce\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1845-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"tf2 9tu\", \"value_r\": \"tf11 8qn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"oakengates\", \"value_r\": \"telford and wrekin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.320647062882574, \"bayes_factor\": 0.025022208451526536, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.9864183014141511, \"bayes_factor\": 0.5047292841279694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.98 times less likely to be a match\", \"value_l\": \"charles\", \"value_r\": \"charles\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.03251475849452756, \"bayes_factor\": 1.0227934016747802, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.02 times more likely to be a match\", \"value_l\": \"bartlett\", \"value_r\": \"bartlett\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1860-86-01\", \"value_r\": \"1860-06-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"dt6 5lb\", \"value_r\": \"dt6 3je\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"bridport\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 2}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 2}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"printmaker\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.017639139480308947, \"bayes_factor\": 0.9878479204045152, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"james\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.8733245225685148, \"bayes_factor\": 0.5458874660954862, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.83 times less likely to be a match\", \"value_l\": \"james\", \"value_r\": \"james\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"grant\", \"value_r\": \"grant\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7450928201690246, \"bayes_factor\": 0.5966294843102884, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.68 times less likely to be a match\", \"value_l\": \"grant\", \"value_r\": \"grant\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1808-07-22\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ph2 8pz\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"perth and kinross\", \"value_r\": \"bridge of earn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 3}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 3}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"soldier\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.738524776859503, \"bayes_factor\": 0.2996759522113937, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.2427580546739367, \"bayes_factor\": 0.42256405182806733, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.37 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"whittle\", \"value_r\": \"whittle\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"whittle\", \"value_r\": \"whittle\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sk13 6jj\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"charlesworth\", \"value_r\": \"high peak\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 4}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 4}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.8449239031311305, \"bayes_factor\": 0.5567401743409016, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"mackenzie\", \"value_r\": \"mackenzie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.6195619380851652, \"bayes_factor\": 0.6508685283384966, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.54 times less likely to be a match\", \"value_l\": \"mackenzie\", \"value_r\": \"mackenzie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 5}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"tw20 8te\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"stoczek klasztorny\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 5}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 5}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"economist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.16462969656476498, \"bayes_factor\": 0.8921574843619563, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.2045244388063217, \"bayes_factor\": 0.2169561761128322, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.61 times less likely to be a match\", \"value_l\": \"jones\", \"value_r\": \"jones\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1858-03-28\", \"value_r\": \"1858-03-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 6}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"sa32 8bt\", \"value_r\": \"sa18 2ga\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"carmarthenshire\", \"value_r\": \"llandybie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 6}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 6}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"auctioneer\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -6.11432042499324, \"bayes_factor\": 0.014434646379210448, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"ian\", \"value_r\": \"ian\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.5645968673836672, \"bayes_factor\": 2.957948362796471, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.96 times more likely to be a match\", \"value_l\": \"ian\", \"value_r\": \"ian\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"marshall\", \"value_r\": \"marshall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.0670209150563865, \"bayes_factor\": 0.2386517937241154, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.19 times less likely to be a match\", \"value_l\": \"marshall\", \"value_r\": \"marshall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1800-01-04\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 7}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"tr27 6ea\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"cornwall\", \"value_r\": \"towednack\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 7}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 7}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.6225314817946828, \"bayes_factor\": 0.6495302033977185, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.3470054323110405, \"bayes_factor\": 5.08767118400993, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.09 times more likely to be a match\", \"value_l\": \"reginald\", \"value_r\": \"reginald\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"marriott\", \"value_r\": \"marriott\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7450928201690246, \"bayes_factor\": 0.5966294843102884, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.68 times less likely to be a match\", \"value_l\": \"marriott\", \"value_r\": \"marriott\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.1434194243149958, \"bayes_factor\": 0.45268536642780777, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"1857-01-04\", \"value_r\": \"1847-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 8}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"st14 5bu\", \"value_r\": \"de13 9jl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"tutbury\", \"value_r\": \"east staffordshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 8}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 8}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.1380565362635977, \"bayes_factor\": 0.22718562599834244, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"stuart\", \"value_r\": \"stuart\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.03251475849452756, \"bayes_factor\": 1.0227934016747802, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.02 times more likely to be a match\", \"value_l\": \"stuart\", \"value_r\": \"stuart\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1800-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 9}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sn12 8dz\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"melksham\", \"value_r\": \"wiltshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 9}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 9}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.2540779889045135, \"bayes_factor\": 0.2096307136309874, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"bell\", \"value_r\": \"bell\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.683692275504881, \"bayes_factor\": 0.31128494833580267, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.21 times less likely to be a match\", \"value_l\": \"bell\", \"value_r\": \"bell\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1811-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 10}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"nr31 9hy\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"great yarmouth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 10}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 10}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.2287600339844809, \"bayes_factor\": 0.42668401426006597, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"frank\", \"value_r\": \"frank\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.2095019085611056, \"bayes_factor\": 2.312577810913605, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.31 times more likely to be a match\", \"value_l\": \"frank\", \"value_r\": \"frank\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"hall\", \"value_r\": \"hall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.3300553208901804, \"bayes_factor\": 0.39775298954019234, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.51 times less likely to be a match\", \"value_l\": \"hall\", \"value_r\": \"hall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1808-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 11}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"hu12 8rh\", \"value_r\": \"hu6 8rf\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"kingston upon hull, city of\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 11}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 11}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"hydrographer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.03752806007053763, \"bayes_factor\": 0.9743229406712467, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1864-02-14\", \"value_r\": \"1861-02-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 12}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"co5 9bs\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"great braxted\", \"value_r\": \"maldon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 12}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 12}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.3286330407719387, \"bayes_factor\": 0.39814530745915655, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"1st\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.1328806269581935, \"bayes_factor\": 4.38592343449132, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 4.39 times more likely to be a match\", \"value_l\": \"1st\", \"value_r\": \"1st\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1857-01-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 13}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ta3 7ne\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"trull\", \"value_r\": \"somerset west and taunton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 13}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 13}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.113141411273725, \"bayes_factor\": 0.2311431620367054, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.7450928201690246, \"bayes_factor\": 0.2983147421551442, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1838-12-04\", \"value_r\": \"1830-12-04\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 14}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"sw1v 1dl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 14}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 14}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"publisher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.044462260506297174, \"bayes_factor\": 0.9696511702020829, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"arthur\", \"value_r\": \"arthur\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -0.053532497272688224, \"bayes_factor\": 0.9635740878806687, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.04 times less likely to be a match\", \"value_l\": \"arthur\", \"value_r\": \"arthur\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"brown\", \"value_r\": \"brown\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.3300553208901804, \"bayes_factor\": 0.39775298954019234, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.51 times less likely to be a match\", \"value_l\": \"brown\", \"value_r\": \"brown\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1862-01-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 15}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"b6 7nx\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"birmingham\", \"value_r\": \"aston\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 15}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 15}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.503695252284832, \"bayes_factor\": 0.3526489740669432, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"marie\", \"value_r\": \"marie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 3.290421903944673, \"bayes_factor\": 9.783983046172944, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 9.78 times more likely to be a match\", \"value_l\": \"marie\", \"value_r\": \"marie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"wight\", \"value_r\": \"wight\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.8605700375889603, \"bayes_factor\": 0.5507349085941124, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.82 times less likely to be a match\", \"value_l\": \"wight\", \"value_r\": \"wight\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.1434194243149958, \"bayes_factor\": 0.45268536642780777, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"1861-12-15\", \"value_r\": \"1861-15-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 16}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"cm19 5fz\", \"value_r\": \"e16 2hj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"woolwich\", \"value_r\": \"newham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 16}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 16}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.3101172820499007, \"bayes_factor\": 0.40328809348818195, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"francis\", \"value_r\": \"francis\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.4362727704081281, \"bayes_factor\": 1.3531040383005137, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.35 times more likely to be a match\", \"value_l\": \"francis\", \"value_r\": \"francis\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"bruton\", \"value_r\": \"bruton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"bruton\", \"value_r\": \"bruton\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1860-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 17}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"cw12 2sd\", \"value_r\": \"sk11 0ar\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"congleton\", \"value_r\": \"cheshire east\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 17}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 17}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"teacher\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.9053697738515141, \"bayes_factor\": 0.5338958448682096, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"george\", \"value_r\": \"george\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.25706589135782, \"bayes_factor\": 0.41839401184292196, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.39 times less likely to be a match\", \"value_l\": \"george\", \"value_r\": \"george\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"chalmers\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.03251475849452756, \"bayes_factor\": 1.0227934016747802, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.02 times more likely to be a match\", \"value_l\": \"chalmers\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1720-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 18}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"eh2 2ah\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"city of edinburgh\", \"value_r\": \"edinburgh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 18}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 18}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.344658566985256, \"bayes_factor\": 0.39374716277399285, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"williams\", \"value_r\": \"williams\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.2045244388063217, \"bayes_factor\": 0.2169561761128322, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.61 times less likely to be a match\", \"value_l\": \"williams\", \"value_r\": \"williams\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1848-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 19}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ub7 8dx\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"hillingdon\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 19}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 19}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.8115421098562077, \"bayes_factor\": 0.2848862486549854, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0370443744841191, \"bayes_factor\": 0.4873248260545911, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.05 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"edridge\", \"value_r\": \"edridge\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.2549071798309754, \"bayes_factor\": 1.1932589686205768, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.19 times more likely to be a match\", \"value_l\": \"edridge\", \"value_r\": \"edridge\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1768-21-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 20}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"nw8 7hg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"london paddington station\", \"value_r\": \"westminster\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 20}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 20}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.902244628775107, \"bayes_factor\": 0.5350536158257068, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"lane-mitchell\", \"value_r\": \"lane-mitchell\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"lane-mitchell\", \"value_r\": \"lane-mitchell\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 21}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"ab51 6an\", \"value_r\": \"ab51 4sf\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"garioch\", \"value_r\": \"aberdeenshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 21}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 21}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.5081278575367203, \"bayes_factor\": 0.08789178531981029, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.3761517779705572, \"bayes_factor\": 2.5957506040866996, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.60 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.7450928201690246, \"bayes_factor\": 0.2983147421551442, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1677-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 22}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ne26 4pu\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"northumberland\", \"value_r\": \"seaton valley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 22}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 22}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"poet\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.623032732201422, \"bayes_factor\": 0.08116307120304705, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"booth\", \"value_r\": \"booth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.7450928201690246, \"bayes_factor\": 0.5966294843102884, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.68 times less likely to be a match\", \"value_l\": \"booth\", \"value_r\": \"booth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1853-03-08\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 23}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"calderdale\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 23}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 23}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.35211049121891086, \"bayes_factor\": 0.7834371838012096, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1858-02-07\", \"value_r\": \"1857-02-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 24}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"ta4 3lt\", \"value_r\": \"ta3 7na\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"trull\", \"value_r\": \"somerset west and taunton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 24}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 24}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.523498802605118, \"bayes_factor\": 22.998993205382362, \"comparison_vector_value\": 1, \"m_probability\": 0.8904967227894447, \"u_probability\": 0.03871894368754565, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 23.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.1976701822182274, \"bayes_factor\": 0.43597877847276745, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.29 times less likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.47924671035370175, \"bayes_factor\": 0.7173520848828441, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0370443744841191, \"bayes_factor\": 0.4873248260545911, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.05 times less likely to be a match\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"fox\", \"value_r\": \"fox\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.9674852415054724, \"bayes_factor\": 0.5113967008373901, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.96 times less likely to be a match\", \"value_l\": \"fox\", \"value_r\": \"fox\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1841-10-21\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 25}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"ct4 6uj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"machilipatnam\", \"value_r\": \"india\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 25}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 25}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"colonial administrator\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.124637050111555, \"bayes_factor\": 0.2293086924967315, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.2427580546739367, \"bayes_factor\": 0.42256405182806733, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.37 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"strong\", \"value_r\": \"strong\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.3300553208901805, \"bayes_factor\": 0.7955059790803847, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.26 times less likely to be a match\", \"value_l\": \"strong\", \"value_r\": \"strong\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1861-10-21\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 26}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"np11 7np\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"abercarn\", \"value_r\": \"caerphilly\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 26}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 26}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.6929208096860808, \"bayes_factor\": 0.3093000968560564, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.7450928201690246, \"bayes_factor\": 0.2983147421551442, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1838-12-04\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 27}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sw1v 1qt\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"westminster\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 27}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 27}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.3521104912189108, \"bayes_factor\": 0.3917185919006048, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"burt\", \"value_r\": \"burt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"burt\", \"value_r\": \"burt\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.1434194243149958, \"bayes_factor\": 0.45268536642780777, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"1821-01-01\", \"value_r\": \"1807-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 28}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"wv2 2eb\", \"value_r\": \"b43 7ey\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"wolverhampton\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 28}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 28}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.64698788709848, \"bayes_factor\": 0.1596530603446489, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1860-06-06\", \"value_r\": \"1880-06-06\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 29}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"np23 5hl\", \"value_r\": \"cf45 4hg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"badminton\", \"value_r\": \"blaenau gwent\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 29}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 29}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.8050753307405927, \"bayes_factor\": 0.07154152437841463, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"roach\", \"value_r\": \"roach\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"roach\", \"value_r\": \"roach\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1862-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 30}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"le17 6qu\", \"value_r\": \"le8 0rd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"harborough\", \"value_r\": \"kibworth beauchamp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 30}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 30}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"association football manager\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -6.5801622008474245, \"bayes_factor\": 0.010451383916439518, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"hare\", \"value_r\": \"hare\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.03251475849452756, \"bayes_factor\": 1.0227934016747802, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.02 times more likely to be a match\", \"value_l\": \"hare\", \"value_r\": \"hare\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1857-05-31\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 31}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ct4 6jn\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"canterbury\", \"value_r\": \"kingston\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 31}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 31}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"religious\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.1921280763342272, \"bayes_factor\": 0.21882840490547315, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"frederick\", \"value_r\": \"frederick\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.37615177797055716, \"bayes_factor\": 1.2978753020433498, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.30 times more likely to be a match\", \"value_l\": \"frederick\", \"value_r\": \"frederick\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"gibbins\", \"value_r\": \"gibbins\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"gibbins\", \"value_r\": \"gibbins\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.1434194243149958, \"bayes_factor\": 0.45268536642780777, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"1861-04-21\", \"value_r\": \"1861-04-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 32}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"st15 0lj\", \"value_r\": \"ln4 4es\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"stafford\", \"value_r\": \"stone\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 32}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 32}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.108910190604081, \"bayes_factor\": 0.23182206734524746, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"williams\", \"value_r\": \"williams\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.2045244388063217, \"bayes_factor\": 0.2169561761128322, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.61 times less likely to be a match\", \"value_l\": \"williams\", \"value_r\": \"williams\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1848-81-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 33}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ub7 8dx\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"hillingdon\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 33}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 33}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.8115421098562077, \"bayes_factor\": 0.2848862486549854, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.3761517779705572, \"bayes_factor\": 2.5957506040866996, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.60 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.7450928201690246, \"bayes_factor\": 0.2983147421551442, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1677-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 34}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"ne26 4pu\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"northumberland\", \"value_r\": \"seaton valley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 34}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 34}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"poet\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.623032732201422, \"bayes_factor\": 0.08116307120304705, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1853-24-24\", \"value_r\": \"1853-04-24\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 35}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"somerford keynes\", \"value_r\": \"cotswold\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 35}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 35}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.3286330407719387, \"bayes_factor\": 0.39814530745915655, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"joan\", \"value_r\": \"joan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.9684938090573108, \"bayes_factor\": 1.9567966092345888, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.96 times more likely to be a match\", \"value_l\": \"joan\", \"value_r\": \"joan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"benbow\", \"value_r\": \"benbow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.2549071798309754, \"bayes_factor\": 2.3865179372411536, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.39 times more likely to be a match\", \"value_l\": \"benbow\", \"value_r\": \"benbow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 36}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"tf10 8bg\", \"value_r\": \"sy3 7qn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"shrewsbury\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 36}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 36}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.3731487352023314, \"bayes_factor\": 0.7720955295017184, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.3761517779705572, \"bayes_factor\": 2.5957506040866996, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.60 times more likely to be a match\", \"value_l\": \"elizabeth\", \"value_r\": \"elizabeth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.7450928201690246, \"bayes_factor\": 0.2983147421551442, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.35 times less likely to be a match\", \"value_l\": \"thomas\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 37}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"northumberland\", \"value_r\": \"seaton valley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 37}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 37}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"poet\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.623032732201422, \"bayes_factor\": 0.08116307120304705, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.166485313277078, \"bayes_factor\": 0.2227526788095416, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.49 times less likely to be a match\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"illingworth\", \"value_r\": \"illingworth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 1.839869680552132, \"bayes_factor\": 3.5797769058617313, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 3.58 times more likely to be a match\", \"value_l\": \"illingworth\", \"value_r\": \"illingworth\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1764-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 38}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"co6 3dp\", \"value_r\": \"co6 4hr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"colchester\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 38}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 38}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.24359028046640874, \"bayes_factor\": 0.8446407279023941, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"mary\", \"value_r\": \"mary\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.6870808739086623, \"bayes_factor\": 1.610022526585421, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.61 times more likely to be a match\", \"value_l\": \"mary\", \"value_r\": \"mary\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"marshall\", \"value_r\": \"marshall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -2.0670209150563865, \"bayes_factor\": 0.2386517937241154, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  4.19 times less likely to be a match\", \"value_l\": \"marshall\", \"value_r\": \"marshall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1850-10-24\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 39}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"cb4 3es\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"lincolnshire\", \"value_r\": \"coningsby\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 39}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 39}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.5000474752696875, \"bayes_factor\": 0.35354175627977086, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"alexander\", \"value_r\": \"alexander\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.2629411675225661, \"bayes_factor\": 2.399844898117892, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.40 times more likely to be a match\", \"value_l\": \"alexander\", \"value_r\": \"alexander\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"sinclair\", \"value_r\": \"sinclair\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.9674852415054724, \"bayes_factor\": 0.5113967008373901, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.96 times less likely to be a match\", \"value_l\": \"sinclair\", \"value_r\": \"sinclair\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1859-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 40}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"de55 3dd\", \"value_r\": \"ng16 5ll\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"selston\", \"value_r\": \"ashfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 40}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 40}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.301093798073524, \"bayes_factor\": 0.20290920249708233, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"alexander\", \"value_r\": \"alexander\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 1.2629411675225661, \"bayes_factor\": 2.399844898117892, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 2.40 times more likely to be a match\", \"value_l\": \"alexander\", \"value_r\": \"alexander\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"sinclair\", \"value_r\": \"sinclair\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.9674852415054724, \"bayes_factor\": 0.5113967008373901, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.96 times less likely to be a match\", \"value_l\": \"sinclair\", \"value_r\": \"sinclair\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 41}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"de55 3dd\", \"value_r\": \"ng16 5ll\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"selston\", \"value_r\": \"ashfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 41}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 41}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"painter\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.301093798073524, \"bayes_factor\": 0.20290920249708233, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"willie\", \"value_r\": \"willie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 0.3470054323110404, \"bayes_factor\": 1.2719177960024826, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 1.27 times more likely to be a match\", \"value_l\": \"willie\", \"value_r\": \"willie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"barrie\", \"value_r\": \"barrie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"barrie\", \"value_r\": \"barrie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": -1.1434194243149958, \"bayes_factor\": 0.45268536642780777, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"1849-04-20\", \"value_r\": \"1879-04-21\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 2\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 2\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 1, \"m_probability\": 0.036618466234483886, \"u_probability\": 0.08089165002934469, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 2` then comparison is  2.21 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 42}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"wc1b 3qe\", \"value_r\": \"wc1a 1eu\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"london\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 42}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 42}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.8750221304298034, \"bayes_factor\": 0.13631137559900552, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1861-02-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 43}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"co5 9bw\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"great braxted\", \"value_r\": \"maldon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 43}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 43}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.315856347833707, \"bayes_factor\": 0.025105437075147778, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1849-04-24\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 44}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"st11 9fn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"forsbrook\", \"value_r\": \"staffordshire moorlands\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 44}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 44}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.523498802605118, \"bayes_factor\": 22.998993205382362, \"comparison_vector_value\": 1, \"m_probability\": 0.8904967227894447, \"u_probability\": 0.03871894368754565, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 23.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.1976701822182274, \"bayes_factor\": 0.43597877847276745, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.29 times less likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.9900277274468163, \"bayes_factor\": 0.2517340493402469, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1849-04-24\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 45}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"st11 9fn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"forsbrook\", \"value_r\": \"staffordshire moorlands\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 45}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 45}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.523498802605118, \"bayes_factor\": 22.998993205382362, \"comparison_vector_value\": 1, \"m_probability\": 0.8904967227894447, \"u_probability\": 0.03871894368754565, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 23.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.1976701822182274, \"bayes_factor\": 0.43597877847276745, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.29 times less likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -1.9900277274468163, \"bayes_factor\": 0.2517340493402469, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"column_name\": \"dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 3.9872233070617686, \"bayes_factor\": 15.858927540970248, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"1857-02-07\", \"value_r\": \"1858-02-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 2, \"m_probability\": 0.3295022683996789, \"u_probability\": 0.020777083919983657, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 15.86 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 46}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"ta3 7na\", \"value_r\": \"ta4 3lt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"somerset west and taunton\", \"value_r\": \"trull\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 46}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 46}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": 4.523498802605118, \"bayes_factor\": 22.998993205382362, \"comparison_vector_value\": 1, \"m_probability\": 0.8904967227894447, \"u_probability\": 0.03871894368754565, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 23.00 times more likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"log2_bayes_factor\": -1.1976701822182274, \"bayes_factor\": 0.43597877847276745, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.29 times less likely to be a match\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.47924671035370175, \"bayes_factor\": 0.7173520848828441, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"bobby\", \"value_r\": \"bobby\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 2.4672996660287523, \"bayes_factor\": 5.530077373923838, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.53 times more likely to be a match\", \"value_l\": \"bobby\", \"value_r\": \"bobby\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"peel\", \"value_r\": \"peel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 0.5179415856647696, \"bayes_factor\": 1.4319107623446925, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.43 times more likely to be a match\", \"value_l\": \"peel\", \"value_r\": \"peel\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1857-02-12\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 47}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.4764422899686545, \"bayes_factor\": 0.17968697115877388, \"comparison_vector_value\": 0, \"m_probability\": 0.1795675566878993, \"u_probability\": 0.9993354305540102, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.57 times less likely to be a match\", \"value_l\": \"wf6 1al\", \"value_r\": \"ls27 7tg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.679575076349155, \"bayes_factor\": 0.15608728495383487, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"churwell\", \"value_r\": \"leeds\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 47}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.15530221228290375, \"u_probability\": 0.99497029709266, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.41 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 47}, {\"column_name\": \"occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.1339842558809914, \"bayes_factor\": 0.11391390321433996, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"cricket umpire\", \"value_r\": \"cricketer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.1095032772105554, \"u_probability\": 0.9612810563124543, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  8.78 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.7452927282780863, \"bayes_factor\": 0.14913670440762833, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -1.0698343096017886, \"bayes_factor\": 0.47637370636797105, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -4.125914604109955, \"bayes_factor\": 0.057276430493787694, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  17.46 times less likely to be a match\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"1807-04-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 48}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"eh8 8dz\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"lochend\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 48}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 48}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.6362812714845525, \"bayes_factor\": 0.16084229463388433, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.862989789260947, \"bayes_factor\": 0.000134231437002546, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"column_name\": \"first_name\", \"label_for_charts\": \"Exact match first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": 5.460558126754405, \"bayes_factor\": 44.0343701977073, \"comparison_vector_value\": 3, \"m_probability\": 0.5608100439593999, \"u_probability\": 0.01273573441476402, \"bayes_factor_description\": \"If comparison level is `exact match first_name` then comparison is 44.03 times more likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"log2_bayes_factor\": -2.104535400706791, \"bayes_factor\": 0.23252610530209922, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.30 times less likely to be a match\", \"value_l\": \"john\", \"value_r\": \"john\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 9.961899304733734, \"bayes_factor\": 997.3107596190212, \"comparison_vector_value\": 3, \"m_probability\": 0.7800196690521285, \"u_probability\": 0.0007821229857683485, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 997.31 times more likely to be a match\", \"value_l\": \"lewis\", \"value_r\": \"lewis\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.8605700375889603, \"bayes_factor\": 0.5507349085941124, \"comparison_vector_value\": 3, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.82 times less likely to be a match\", \"value_l\": \"lewis\", \"value_r\": \"lewis\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"column_name\": \"dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"1859-12-25\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 49}, {\"column_name\": \"postcode_fake\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"sa15 3jz\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"column_name\": \"birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"carmarthenshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 8, \"record_number\": 49}, {\"column_name\": \"tf_birth_place\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 9, \"record_number\": 49}, {\"column_name\": \"occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"tf_occupation\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 11, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.40563779606856, \"bayes_factor\": 0.7549024867678091, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 12, \"record_number\": 49}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the false negatives will be because they weren't detected by the blocking rules\n",
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.5,\n",
    "    include_false_negatives=True,\n",
    "    include_false_positives=False,\n",
    ").as_record_dict(limit=50)\n",
    "\n",
    "linker.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
