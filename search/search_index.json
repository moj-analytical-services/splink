{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#fast-accurate-and-scalable-probabilistic-data-linkage","title":"Fast, accurate and scalable probabilistic data linkage","text":"<p>Splink is a Python package for probabilistic record linkage (entity resolution) that allows you to deduplicate and link records from datasets without unique identifiers.</p> <p>Get Started with Splink</p>"},{"location":"index.html#key-features","title":"Key Features","text":"<p>\u26a1 Speed: Capable of linking a million records on a laptop in approximately one minute. \ud83c\udfaf Accuracy: Full support for term frequency adjustments and user-defined fuzzy matching logic. \ud83c\udf10 Scalability: Execute linkage jobs in Python (using DuckDB) or big-data backends like AWS Athena or Spark for 100+ million records. \ud83c\udf93 Unsupervised Learning: No training data is required, as models can be trained using an unsupervised approach. \ud83d\udcca Interactive Outputs: Provides a wide range of interactive outputs to help users understand their model and diagnose linkage problems.</p> <p>Splink's core linkage algorithm is based on Fellegi-Sunter's model of record linkage, with various customizations to improve accuracy.</p>"},{"location":"index.html#what-does-splink-do","title":"What does Splink do?","text":"<p>Consider the following records that lack a unique person identifier:</p> <p></p> <p>Splink predicts which rows link together:</p> <p></p> <p>and clusters these links to produce an estimated person ID:</p> <p></p>"},{"location":"index.html#what-data-does-splink-work-best-with","title":"What data does Splink work best with?","text":"<p>Before using Splink, input data should be standardised, with consistent column names and formatting (e.g., lowercased, punctuation cleaned up, etc.).</p> <p>Splink performs best with input data containing multiple columns that are not highly correlated. For instance, if the entity type is persons, you may have columns for full name, date of birth, and city. If the entity type is companies, you could have columns for name, turnover, sector, and telephone number.</p> <p>High correlation occurs when the value of a column is highly constrained (predictable) from the value of another column. For example, a 'city' field is almost perfectly correlated with 'postcode'. Gender is highly correlated with 'first name'. Correlation is particularly problematic if all of your input columns are highly correlated.</p> <p>Splink is not designed for linking a single column containing a 'bag of words'. For example, a table with a single 'company name' column, and no other details.</p>"},{"location":"index.html#videos","title":"Videos","text":"<p>Our PyData Global 2024 talk provides a brief introduction to Splink and is available on YouTube here.</p>"},{"location":"index.html#support","title":"Support","text":"<p>If after reading the documentatation you still have questions, please feel free to post on our discussion forum.</p>"},{"location":"index.html#use-cases","title":"Use Cases","text":"<p>Here is a list of some of our known users and their use cases:</p> Public Sector (UK)Public Sector (International)AcademiaOther <ul> <li>Office for National Statistics's Business Index (formerly the Inter Departmental Business Register), Demographic Index and the 2021 Census.  See also this article and 2021 Census to PDS linkage report.</li> <li>NHS England is working on developing an alternative data linkage model using splink as the core engine for a new probabilistic data linkage service. This is in order to improve linkage and linkage explainability across NHS datasets. Code now available on github.</li> <li>Ministry of Defence launched their Veteran's Card system which uses Splink to verify applicants against historic records. This project was shortlisted for the Civil Service Awards</li> <li>Ministry of Justice created linked datasets (combining courts, prisons and probation data) for use by researchers as part of the Data First programme</li> <li>UK Health Security Agency used Splink to link HIV testing data to national health records to evaluate the impact of emergency department opt-out bloodborne virus testing.</li> <li>The Department for Education uses Splink to match records from certain data providers to existing learners and reduce the volume of clerical work required for corrections</li> <li>SAIL Databank, in collaboration with Secure eResearch Platform (SeRP), uses Splink to produce linked cohorts for a wide range of population-level research applications</li> <li>Lewisham Council (London) identified and auto-enrolled over 500 additional eligible families to receive Free School Meals</li> <li>Leicestershire County Council use Splink to match individuals across their Education and Social Care systems.  This ensures triage and front-line practitioners have a complete picture of those individuals.</li> <li>Integrated Corporate Services have used Splink to match address data in historical datasets, substantially improving match rates.</li> <li>London Office of Technology and Innovation created a dashboard to help better measure and reduce rough sleeping across London</li> <li>Competition and Markets Authority identified 'Persons with Significant Control' and estimated ownership groups across companies</li> <li>Office for Health Improvement and Disparities linked Health and Justice data to assess the pathways between probation and specialist alcohol and drug treatment services as part of the Better Outcomes through Linked Data programme</li> <li>Gateshead Council, in partnership with the National Innovation Centre for Data are creating a single view of debt</li> <li>Homes England has been working with the new developed Splink address matching version. We have succesfully tested and checked the linkage between Land Registry Price Paid dataset and the new Ordnance Survey National Geographical Dataset (NGD) but adddresses. The current linkage performs around 30 Million records in less than 5 hours with a high accuracy in a Databricks environment. This is helping Homes England with a vital component to identify and monitor new builds that will contribute to the 1.5 M homes mandate.</li> <li>The Department for Business and Trade plans to use Splink as part of Matchbox to reconcile business and product data for both analytical and operational use</li> <li>The Welsh Revenue Authority uses Splink in multiple linkage workflows to identify links in their own data, as well as to third party data for operational support in ensuring a fair tax system for Wales.</li> <li>Richmond Council and Wandsworth Council are using Splink to match residents\u2019 records across systems to create unified records and a single view of debt.</li> <li>Westmorland &amp; Furness Council used Splink to matched and de-duplicated Special Educational Needs and Disability (SEND) records across systems.  This provided a \u201csingle view of the child\u201d, improved data quality and automation, and laid the foundation for a wider \u201cSingle View of the Customer\u201d initiative.</li> </ul> <ul> <li>\ud83c\udde6\ud83c\uddfa The Australian Bureau of Statistics (ABS) used Splink to build the 2024 National Linkage Spine underpinning the National Disability Data Asset and will use Splink for the 2025 Person Linkage Spine build. They are also planning to use Splink for the Post Enumeration Survey as part of the 2026 Census quality assurance process.</li> <li>\ud83c\udde9\ud83c\uddea The German Federal Statistical Office (Destatis) uses Splink to conduct projects in linking register-based census data.</li> <li>\ud83c\uddea\ud83c\uddfa The European Medicines Agency uses Splink to detect duplicate adverse event reports for veterinary medicines</li> <li>\ud83c\uddfa\ud83c\uddf8 The Defense Health Agency (US Department of Defense) used Splink to identify duplicated hospital records across over 200 million data points in the military hospital data system</li> <li>\ud83c\udf10 UNHCR uses Splink to analyse and enhance the quality of datasets by identifying and addressing potential duplicates.</li> <li>\ud83c\udde8\ud83c\udde6 The Data Integration Unit at the Ontario Ministry of Children, Community, and Social Services are using Splink as their main data-integration tool for all intra- and inter-ministerial data-linking projects.</li> <li>\ud83c\uddec\ud83c\uddf2 Splink has been used to support the 2024 Gambian census by analysing and linking data from the census and the post-enumeration survey.</li> <li>\ud83c\udde8\ud83c\udde6 Environment and Climate Change Canada is a user of Splink to connect datasets from various administrative and reporting programs.</li> <li>\ud83c\udde8\ud83c\uddf1\ud83c\uddec\ud83c\udde7 Chilean Ministry of Health and University College London have assessed the access to immunisation programs among the migrant population</li> <li>\ud83c\uddfa\ud83c\uddf8 Florida Cancer Registry, published a feasibility study which showed Splink was faster and more accurate than alternatives</li> <li>\ud83c\uddfa\ud83c\uddf8 Catalyst Cooperative's Public Utility Data Liberation Project links public financial and operational data from electric utilities for use by US climate advocates, policymakers, and researchers seeking to accelerate the transition away from fossil fuels.</li> </ul> <ul> <li>Stanford University investigated the impact of receiving government assistance has on political attitudes</li> <li>Researchers from Harvard Medical School, Vanderbilt University Medical Center and Brigham and Women's Hospital published a study on augmenting death ascertainment in electronic health records using publicly available internet media sources.</li> <li>Bern University researched how Active Learning can be applied to Biomedical Record Linkage</li> <li>University of Pennsylvania, Princeton, and UC Berkeley researchers used Splink to link property data, voter files, and campaign donations, creating a dataset of 108M individuals to study the American voter base - see here.</li> <li>\ud83c\uddf1\ud83c\udde6 The Shared Child Health Record project in Lao PDR used Splink to de-duplicate pediatric records in a non-Latin script context</li> </ul> <ul> <li>Marie Curie have used Splink to build a single customer view on fundraising data which has been a \"huge success [...] the tooling is just so much better. [...] The power of being able to select, plug in, configure and train a tool versus writing code. It's just mind boggling actually.\"  Amongst other benefits, the system is expected to \"dramatically reduce manual reporting efforts previously required\". See also the blog post here.</li> <li>Club Brugge uses Splink to link football players from different data providers to their own database, simplifying and reducing the need for manual linkage labor.</li> <li>GN Group use Splink to deduplicate large volumes of customer records</li> </ul> <p>Sadly, we don't hear about the majority of our users or what they are working on. If you have a use case and it is not shown here please add it to the list!</p>"},{"location":"index.html#awards","title":"Awards","text":"<p>\ud83e\udd48 Civil Service Awards 2023: Best Use of Data, Science, and Technology - Runner up</p> <p>\ud83e\udd47 Analysis in Government Awards 2022: People's Choice Award - Winner</p> <p>\ud83e\udd48 Analysis in Government Awards 2022: Innovative Methods - Runner up</p> <p>\ud83e\udd47 Analysis in Government Awards 2020: Innovative Methods - Winner</p> <p>\ud83e\udd47 Ministry of Justice Data and Analytical Services Directorate (DASD) Awards 2020: Innovation and Impact - Winner</p>"},{"location":"index.html#citation","title":"Citation","text":"<p>If you use Splink in your research, we'd be grateful for a citation as follows:</p> <pre><code>@article{Linacre_Lindsay_Manassis_Slade_Hepworth_2022,\n    title        = {Splink: Free software for probabilistic record linkage at scale.},\n    author       = {Linacre, Robin and Lindsay, Sam and Manassis, Theodore and Slade, Zoe and Hepworth, Tom and Kennedy, Ross and Bond, Andrew},\n    year         = 2022,\n    month        = {Aug.},\n    journal      = {International Journal of Population Data Science},\n    volume       = 7,\n    number       = 3,\n    doi          = {10.23889/ijpds.v7i3.1794},\n    url          = {https://ijpds.org/article/view/1794},\n}\n</code></pre>"},{"location":"index.html#acknowledgements","title":"Acknowledgements","text":"<p>We are very grateful to ADR UK (Administrative Data Research UK) for providing the initial funding for this work as part of the Data First project.</p> <p>We are extremely grateful to professors Katie Harron, James Doidge and Peter Christen for their expert advice and guidance in the development of Splink. We are also very grateful to colleagues at the UK's Office for National Statistics for their expert advice and peer review of this work. Any errors remain our own.</p>"},{"location":"getting_started.html","title":"Getting Started","text":""},{"location":"getting_started.html#getting-started","title":"Getting Started","text":""},{"location":"getting_started.html#install","title":"Install","text":"<p>Splink supports python 3.8+.</p> <p>To obtain the latest released version of Splink you can install from PyPI using pip: </p><pre><code>pip install splink\n</code></pre> <p>or if you prefer, you can instead install Splink using conda: </p><pre><code>conda install -c conda-forge splink\n</code></pre> Backend Specific Installs"},{"location":"getting_started.html#backend-specific-installs","title":"Backend Specific Installs","text":"<p>From Splink v3.9.7, packages required by specific Splink backends can be optionally installed by adding the <code>[&lt;backend&gt;]</code> suffix to the end of your pip install.</p> <p>Note that SQLite and DuckDB come packaged with Splink and do not need to be optionally installed.</p> <p>The following backends are supported:</p>  Spark Athena PostgreSQL <pre><code>pip install 'splink[spark]'\n</code></pre> <pre><code>pip install 'splink[athena]'\n</code></pre> <pre><code>pip install 'splink[postgres]'\n</code></pre>"},{"location":"getting_started.html#quickstart","title":"Quickstart","text":"<p>To get a basic Splink model up and running, use the following code. It demonstrates how to:</p> <ol> <li>Estimate the parameters of a deduplication model</li> <li>Use the parameter estimates to identify duplicate records</li> <li>Use clustering to generate an estimated unique person ID.</li> </ol> Simple Splink Model Example <pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.JaroAtThresholds(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"surname\"),\n    ]\n)\n\nlinker = Linker(df, settings, db_api)\n\nlinker.training.estimate_probability_two_random_records_match(\n    [block_on(\"first_name\", \"surname\")],\n    recall=0.7,\n)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"first_name\", \"surname\")\n)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"email\"))\n\npairwise_predictions = linker.inference.predict(threshold_match_weight=-5)\n\nclusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    pairwise_predictions, 0.95\n)\n\ndf_clusters = clusters.as_pandas_dataframe(limit=5)\n</code></pre> <p>If you're using an LLM to suggest Splink code, see here for suggested prompts and context.</p>"},{"location":"getting_started.html#tutorials","title":"Tutorials","text":"<p>You can learn more about Splink in the step-by-step tutorial. Each has a corresponding Google Colab link to run the notebook in your browser.</p>"},{"location":"getting_started.html#example-notebooks","title":"Example Notebooks","text":"<p>You can see end-to-end example of several use cases in the example notebooks. Each has a corresponding Google Colab link to run the notebook in your browser.</p>"},{"location":"getting_started.html#getting-help","title":"Getting help","text":"<p>If after reading the documentatation you still have questions, please feel free to post on our discussion forum.</p>"},{"location":"api_docs/api_docs_index.html","title":"Introduction","text":""},{"location":"api_docs/api_docs_index.html#api-documentation","title":"API Documentation","text":"<p>This section contains reference material for the modules and functions within Splink.</p>"},{"location":"api_docs/api_docs_index.html#api","title":"API","text":""},{"location":"api_docs/api_docs_index.html#linker","title":"Linker","text":"<ul> <li>Training</li> <li>Visualisations</li> <li>Inference</li> <li>Clustering</li> <li>Evaluation</li> <li>Table Management</li> <li>Miscellaneous functions</li> </ul>"},{"location":"api_docs/api_docs_index.html#comparisons","title":"Comparisons","text":"<ul> <li>Comparison Library</li> <li>Comparison Level Library</li> </ul>"},{"location":"api_docs/api_docs_index.html#other","title":"Other","text":"<ul> <li>Exploratory</li> <li>Blocking Analysis</li> <li>Blocking</li> <li>Clustering</li> <li>SplinkDataFrame</li> <li>EM Training Session API</li> <li>Column Expression API</li> </ul>"},{"location":"api_docs/api_docs_index.html#in-built-datasets","title":"In-built datasets","text":"<p>Information on pre-made data tables available within Splink suitable for linking, to get up-and-running or to try out ideas.</p> <ul> <li>In-built datasets - information on included datasets, as well as how to use them, and methods for managing them.</li> </ul>"},{"location":"api_docs/api_docs_index.html#splink-settings","title":"Splink Settings","text":"<p>Reference materials for the Splink Settings dictionary:</p> <ul> <li>Settings Dictionary Reference - for reference material on the parameters available within a Splink Settings dictionary.</li> </ul>"},{"location":"api_docs/blocking.html","title":"Blocking","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking.html#documentation-for-the-blocking_rule_library","title":"Documentation for the <code>blocking_rule_library</code>","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking.html#splink.blocking_rule_library.CustomRule","title":"<code>CustomRule(blocking_rule, sql_dialect=None, salting_partitions=None, arrays_to_explode=None)</code>","text":"<p>               Bases: <code>BlockingRuleCreator</code></p> <p>Represents a custom blocking rule using a user-defined SQL condition.  To refer to the left hand side and the right hand side of the pairwise record comparison, use <code>l</code> and <code>r</code> respectively, e.g. <code>l.first_name = r.first_name and len(l.first_name) &lt;2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>blocking_rule</code> <code>str</code> <p>A SQL condition string representing the custom blocking rule.</p> required <code>sql_dialect</code> <code>str</code> <p>The SQL dialect of the provided blocking rule. If specified, Splink will attempt to translate the rule to the appropriate dialect.</p> <code>None</code> <code>salting_partitions</code> <code>int</code> <p>The number of partitions to use for salting. If provided, enables salting for this blocking rule.</p> <code>None</code> <code>arrays_to_explode</code> <code>list[str]</code> <p>A list of array column names to explode before applying the blocking rule.</p> <code>None</code> <p>Examples:</p> <pre><code>from splink.blocking_rule_library import CustomRule\n\n# Simple custom rule\nrule_1 = CustomRule(\"l.postcode = r.postcode\")\n\n# Custom rule with dialect translation\nrule_2 = CustomRule(\n    \"SUBSTR(l.surname, 1, 3) = SUBSTR(r.surname, 1, 3)\",\n    sql_dialect=\"sqlite\"\n)\n\n# Custom rule with salting\nrule_3 = CustomRule(\n    \"l.city = r.city\",\n    salting_partitions=10\n)\n</code></pre>","tags":["API","blocking"]},{"location":"api_docs/blocking.html#splink.blocking_rule_library.block_on","title":"<code>block_on(*col_names_or_exprs, salting_partitions=None, arrays_to_explode=None)</code>","text":"<p>Generates blocking rules of equality conditions  based on the columns or SQL expressions specified.</p> <p>When multiple columns or SQL snippets are provided, the function generates a compound blocking rule, connecting individual match conditions with \"AND\" clauses.</p> <p>Further information on equi-join conditions can be found here</p> <p>Parameters:</p> Name Type Description Default <code>col_names_or_exprs</code> <code>Union[str, ColumnExpression]</code> <p>A list of input columns or SQL conditions you wish to create blocks on.</p> <code>()</code> <code>salting_partitions</code> <code>(optional, int)</code> <p>Whether to add salting to the blocking rule. More information on salting can be found within the docs.</p> <code>None</code> <code>arrays_to_explode</code> <code>(optional, List[str])</code> <p>List of arrays to explode before applying the blocking rule.</p> <code>None</code> <p>Examples:</p> <pre><code>from splink import block_on\nbr_1 = block_on(\"first_name\")\nbr_2 = block_on(\"substr(surname,1,2)\", \"surname\")\n</code></pre>","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html","title":"Blocking analysis","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html#documentation-forsplinkblocking_analysis","title":"Documentation for<code>splink.blocking_analysis</code>","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html#splink.blocking_analysis.count_comparisons_from_blocking_rule","title":"<code>count_comparisons_from_blocking_rule(*, table_or_tables, blocking_rule, link_type, db_api, unique_id_column_name='unique_id', source_dataset_column_name=None, compute_post_filter_count=True, max_rows_limit=int(1000000000.0))</code>","text":"<p>Analyse a blocking rule to understand the number of comparisons it will generate.</p> <p>Read more about the definition of pre and post filter conditions here</p> <p>Parameters:</p> Name Type Description Default <code>table_or_tables</code> <code>(dataframe, str)</code> <p>Input data</p> required <code>blocking_rule</code> <code>Union[BlockingRuleCreator, str, Dict[str, Any]]</code> <p>The blocking rule to analyse</p> required <code>link_type</code> <code>user_input_link_type_options</code> <p>The link type - \"link_only\", \"dedupe_only\" or \"link_and_dedupe\"</p> required <code>db_api</code> <code>DatabaseAPISubClass</code> <p>Database API</p> required <code>unique_id_column_name</code> <code>str</code> <p>Defaults to \"unique_id\".</p> <code>'unique_id'</code> <code>source_dataset_column_name</code> <code>Optional[str]</code> <p>Defaults to None.</p> <code>None</code> <code>compute_post_filter_count</code> <code>bool</code> <p>Whether to use a slower methodology to calculate how many comparisons will be generated post filter conditions. Defaults to True.</p> <code>True</code> <code>max_rows_limit</code> <code>int</code> <p>Calculation of post filter counts will only proceed if the fast method returns a value below this limit. Defaults to int(1e9).</p> <code>int(1000000000.0)</code> <p>Returns:</p> Type Description <code>dict[str, Union[int, str]]</code> <p>dict[str, Union[int, str]]: A dictionary containing the results</p>","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html#splink.blocking_analysis.cumulative_comparisons_to_be_scored_from_blocking_rules_chart","title":"<code>cumulative_comparisons_to_be_scored_from_blocking_rules_chart(*, table_or_tables, blocking_rules, link_type, db_api, unique_id_column_name='unique_id', max_rows_limit=int(1000000000.0), source_dataset_column_name=None)</code>","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html#splink.blocking_analysis.cumulative_comparisons_to_be_scored_from_blocking_rules_data","title":"<code>cumulative_comparisons_to_be_scored_from_blocking_rules_data(*, table_or_tables, blocking_rules, link_type, db_api, unique_id_column_name='unique_id', max_rows_limit=int(1000000000.0), source_dataset_column_name=None)</code>","text":"","tags":["API","blocking"]},{"location":"api_docs/blocking_analysis.html#splink.blocking_analysis.n_largest_blocks","title":"<code>n_largest_blocks(*, table_or_tables, blocking_rule, link_type, db_api, n_largest=5)</code>","text":"<p>Find the values responsible for creating the largest blocks of records.</p> <p>For example, when blocking on first name and surname, the 'John Smith' block might be the largest block of records.  In cases where values are highly skewed a few values may be resonsible for generating a large proportion of all comparisons. This function helps you find the culprit values.</p> <p>The analysis is performed pre filter conditions, read more about what this means here</p> <p>Parameters:</p> Name Type Description Default <code>table_or_tables</code> <code>(dataframe, str)</code> <p>Input data</p> required <code>blocking_rule</code> <code>Union[BlockingRuleCreator, str, Dict[str, Any]]</code> <p>The blocking rule to analyse</p> required <code>link_type</code> <code>user_input_link_type_options</code> <p>The link type - \"link_only\", \"dedupe_only\" or \"link_and_dedupe\"</p> required <code>db_api</code> <code>DatabaseAPISubClass</code> <p>Database API</p> required <code>n_largest</code> <code>int</code> <p>How many rows to return. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>'SplinkDataFrame'</code> <p>A dataframe containing the n_largest blocks</p>","tags":["API","blocking"]},{"location":"api_docs/clustering.html","title":"Clustering","text":"","tags":["API","clustering"]},{"location":"api_docs/clustering.html#documentation-for-splinkclustering","title":"Documentation for <code>splink.clustering</code>","text":"","tags":["API","clustering"]},{"location":"api_docs/clustering.html#splink.clustering.cluster_pairwise_predictions_at_threshold","title":"<code>cluster_pairwise_predictions_at_threshold(nodes, edges, db_api, node_id_column_name, edge_id_column_name_left=None, edge_id_column_name_right=None, threshold_match_probability=None, threshold_match_weight=None)</code>","text":"<p>Clusters the pairwise match predictions into groups of connected records using the connected components graph clustering algorithm.</p> <p>Records with an estimated match probability at or above threshold_match_probability are considered to be a match (i.e. they represent the same entity).</p> <p>If no match probability or match weight is provided, it is assumed that all edges (comparison) are a match.</p> <p>If your node and edge column names follow Splink naming conventions, then you can omit edge_id_column_name_left and edge_id_column_name_right. For example, if you have a table of nodes with a column <code>unique_id</code>, it would be assumed that the edge table has columns <code>unique_id_l</code> and <code>unique_id_r</code>.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>AcceptableInputTableType</code> <p>The table containing node information</p> required <code>edges</code> <code>AcceptableInputTableType</code> <p>The table containing edge information</p> required <code>db_api</code> <code>DatabaseAPISubClass</code> <p>The database API to use for querying</p> required <code>node_id_column_name</code> <code>str</code> <p>The name of the column containing node IDs</p> required <code>edge_id_column_name_left</code> <code>Optional[str]</code> <p>The name of the column containing left edge IDs. If not provided, assumed to be f\"{node_id_column_name}_l\"</p> <code>None</code> <code>edge_id_column_name_right</code> <code>Optional[str]</code> <p>The name of the column containing right edge IDs. If not provided, assumed to be f\"{node_id_column_name}_r\"</p> <code>None</code> <code>threshold_match_probability</code> <code>Optional[float]</code> <p>Pairwise comparisons with a match_probability at or above this threshold are matched</p> <code>None</code> <code>threshold_match_weight</code> <code>Optional[float]</code> <p>Pairwise comparisons with a match_weight at or above this threshold are matched</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold.</p> <p>Examples:</p> <pre><code>from splink import DuckDBAPI\nfrom splink.clustering import cluster_pairwise_predictions_at_threshold\n\ndb_api = DuckDBAPI()\n\nnodes = [\n    {\"my_id\": 1},\n    {\"my_id\": 2},\n    {\"my_id\": 3},\n    {\"my_id\": 4},\n    {\"my_id\": 5},\n    {\"my_id\": 6},\n]\n\nedges = [\n    {\"n_1\": 1, \"n_2\": 2, \"match_probability\": 0.8},\n    {\"n_1\": 3, \"n_2\": 2, \"match_probability\": 0.9},\n    {\"n_1\": 4, \"n_2\": 5, \"match_probability\": 0.99},\n]\n\ncc = cluster_pairwise_predictions_at_threshold(\n    nodes,\n    edges,\n    node_id_column_name=\"my_id\",\n    edge_id_column_name_left=\"n_1\",\n    edge_id_column_name_right=\"n_2\",\n    db_api=db_api,\n    threshold_match_probability=0.5,\n)\n\ncc.as_duckdbpyrelation()\n</code></pre>","tags":["API","clustering"]},{"location":"api_docs/column_expression.html","title":"Column Expressions","text":"","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#column-expressions","title":"Column Expressions","text":"<p>In comparisons, you may wish to consider expressions which are not simply columns of your input table. For instance you may have a <code>forename</code> column in your data, but when comparing records you may wish to also use the values in this column transformed all to lowercase, or just the first three letters of the name, or perhaps both of these transformations taken together.</p> <p>If it is feasible to do so, then it may be best to derive a new column containing the transformed data. Particularly if it is an expensive calculation, or you wish to refer to it many times, deriving the column once on your input data may well be preferable, as it is cheaper than doing so directly in comparisons where each input record may need to be processed many times. However, there may be situations where you don't wish to derive a new column, perhaps for large data where you have many such transformations, or when you are experimenting with different models.</p> <p>This is where a <code>ColumnExpression</code> may be used. It represents some SQL expression, which may be a column, or some more complicated construct, to which you can also apply zero or more transformations. These are lazily evaluated, and in particular will not be tied to a specific SQL dialect until they are put (via settings into a linker). This can be particularly useful if you want to write code that can easily be switched between different backends.</p> Term frequency adjustments <p>One caveat to using a <code>ColumnExpression</code> is that it cannot be combined with term frequency adjustments. Term frequency adjustments can only be computed on the raw values in a column prior to any function transforms.</p> <p>If you wish to use term frequencies with transformations of an input column, you must pre-compute a new column in your input data with the transforms applied, instead of a <code>ColumnExpression</code>.</p> <pre><code>from splink import ColumnExpression\n\nemail_lowercase = ColumnExpression(\"email\").lower()\ndob_as_string = ColumnExpression(\"dob\").cast_to_string()\nsurname_initial_lowercase = ColumnExpression(\"surname\").substr(1, 1).lower()\nentry_date = ColumnExpression(\"entry_date_str\").try_parse_date(date_format=\"YYYY-MM-DD\")\nfull_name_lowercase = ColumnExpression(\"first_name || ' ' || surname\").lower()\n</code></pre> <p>You can use a <code>ColumnExpression</code> in most places where you might also use a simple column name, such as in a library comparison, a library comparison level, or in a blocking rule:</p> <pre><code>from splink import block_on\nimport splink.comparison_library as cl\nimport splink.comparison_level_library as cll\n\nfull_name_lower_br = block_on(full_name_lowercase)\n\nemail_comparison = cl.DamerauLevenshteinAtThresholds(email_lowercase, distance_threshold_or_thresholds=[1, 3])\nentry_date_comparison = cl.AbsoluteTimeDifferenceAtThresholds(\n    entry_date,\n    input_is_string=False,\n    metrics=[\"day\", \"day\"],\n    thresholds=[1, 10],\n)\nname_comparison = cl.CustomComparison(\n    comparison_levels=[\n        cll.NullLevel(full_name_lowercase),\n        cll.ExactMatch(full_name_lowercase),\n        cll.ExactMatch(\"surname\")\n        cll.ExactMatch(\"first_name\"),\n        cll.ExactMatch(surname_initial_lowercase),\n        cll.ElseLevel()\n    ],\n    output_column_name=\"name\",\n)\n</code></pre>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#columnexpression","title":"<code>ColumnExpression</code>","text":"<p>Enables transforms to be applied to a column before it's passed into a comparison level.</p> <p>Dialect agnostic.  Execution is delayed until the dialect is known.</p> For example <pre><code>from splink.column_expression import ColumnExpression\ncol = (\n    ColumnExpression(\"first_name\")\n    .lower()\n    .regex_extract(\"^[A-Z]{1,4}\")\n)\n\nExactMatchLevel(col)\n</code></pre> <p>Note that this will typically be created without a dialect, and the dialect will later be populated when the <code>ColumnExpression</code> is passed via a comparison level creator into a <code>Linker</code>.</p>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.lower","title":"<code>lower()</code>","text":"<p>Applies a lowercase transform to the input expression.</p>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.substr","title":"<code>substr(start, length)</code>","text":"<p>Applies a substring transform to the input expression of a given length starting from a specified index.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int</code> <p>The starting index of the substring.</p> required <code>length</code> <code>int</code> <p>The length of the substring.</p> required","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.cast_to_string","title":"<code>cast_to_string()</code>","text":"<p>Applies a cast to string transform to the input expression.</p>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.regex_extract","title":"<code>regex_extract(pattern, capture_group=0)</code>","text":"<p>Applies a regex extract transform to the input expression.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>The regex pattern to match.</p> required <code>capture_group</code> <code>int</code> <p>The capture group to extract from the matched pattern. Defaults to 0, meaning the full pattern is extracted</p> <code>0</code>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.nullif","title":"<code>nullif(null_value)</code>","text":"<p>Applies a nullif transform to the input expression, with the specified string value that should be converted to NULL.</p> <p>Parameters:</p> Name Type Description Default <code>null_value</code> <code>str</code> <p>The string literal that should be converted to NULL.</p> required","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.try_parse_date","title":"<code>try_parse_date(date_format=None)</code>","text":"<p>Applies a 'try parse date' transform to the input expression.</p> <p>Parameters:</p> Name Type Description Default <code>date_format</code> <code>str</code> <p>The date format to attempt to parse. Defaults to None, meaning the dialect-specific default format is used.</p> <code>None</code>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.try_parse_timestamp","title":"<code>try_parse_timestamp(timestamp_format=None)</code>","text":"<p>Applies a 'try parse timestamp' transform to the input expression.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp_format</code> <code>str</code> <p>The timestamp format to attempt to parse. Defaults to None, meaning the dialect-specific default format is used.</p> <code>None</code>","tags":["API","comparisons","blocking"]},{"location":"api_docs/column_expression.html#splink.internals.column_expression.ColumnExpression.access_extreme_array_element","title":"<code>access_extreme_array_element(first_or_last)</code>","text":"<p>Applies a transformation to access either the first or the last element of an array</p> <p>Parameters:</p> Name Type Description Default <code>first_or_last</code> <code>str</code> <p>'first' for returning the first elemen of the array, 'last' for the last element</p> required","tags":["API","comparisons","blocking"]},{"location":"api_docs/comparison_level_library.html","title":"Comparison Level Library","text":"","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#documentation-for-the-comparison_level_library","title":"Documentation for the <code>comparison_level_library</code>","text":"","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.AbsoluteDifferenceLevel","title":"<code>AbsoluteDifferenceLevel(col_name, difference_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where the absolute difference between two numerical values is within a specified threshold.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str | ColumnExpression</code> <p>Input column name or ColumnExpression.</p> required <code>difference_threshold</code> <code>int | float</code> <p>The maximum allowed absolute difference between the two values.</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.AbsoluteTimeDifferenceLevel","title":"<code>AbsoluteTimeDifferenceLevel(col_name, *, input_is_string, threshold, metric, datetime_format=None)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Computes the absolute elapsed time between two dates (total duration).</p> <p>This function computes the amount of time that has passed between two dates, in contrast to functions like <code>date_diff</code> found in some SQL backends, which count the number of full calendar intervals (e.g., months, years) crossed.</p> <p>For instance, the difference between January 29th and March 2nd would be less than two months in terms of elapsed time, unlike a <code>date_diff</code> calculation that would give an answer of 2 calendar intervals crossed.</p> <p>That the thresold is inclusive e.g. a level with a 10 day threshold will include difference in date of 10 days.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the input column containing the dates to compare</p> required <code>input_is_string</code> <code>bool</code> <p>Indicates if the input date/times are in string format, requiring parsing according to <code>datetime_format</code>.</p> required <code>threshold</code> <code>int</code> <p>The maximum allowed difference between the two dates, in units specified by <code>date_metric</code>.</p> required <code>metric</code> <code>str</code> <p>The unit of time to use when comparing the dates. Can be 'second', 'minute', 'hour', 'day', 'month', or 'year'.</p> required <code>datetime_format</code> <code>str</code> <p>The format string for parsing dates. ISO 8601 format used if not provided.</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.And","title":"<code>And(*comparison_levels)</code>","text":"<p>               Bases: <code>_Merge</code></p> <p>Represents a comparison level that is an 'AND' of other comparison levels</p> <p>Merge multiple ComparisonLevelCreators into a single ComparisonLevelCreator by merging their SQL conditions using a logical \"AND\".</p> <p>Parameters:</p> Name Type Description Default <code>*comparison_levels</code> <code>ComparisonLevelCreator | dict</code> <p>These represent the comparison levels you wish to combine via 'AND'</p> <code>()</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.ArrayIntersectLevel","title":"<code>ArrayIntersectLevel(col_name, min_intersection=1)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level based around the size of an intersection of arrays</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>min_intersection</code> <code>int</code> <p>The minimum cardinality of the intersection of arrays for this comparison level. Defaults to 1</p> <code>1</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.ArraySubsetLevel","title":"<code>ArraySubsetLevel(col_name, empty_is_subset=False)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where the smaller array is an exact subset of the larger array. If arrays are equal length, they must have the same elements</p> <p>The order of items in the arrays does not matter for this comparison.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str | ColumnExpression</code> <p>Input column name or ColumnExpression</p> required <code>empty_is_subset</code> <code>bool</code> <p>If True, an empty array is considered a subset of any array (including another empty array). Default is False.</p> <code>False</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.ColumnsReversedLevel","title":"<code>ColumnsReversedLevel(col_name_1, col_name_2, symmetrical=False)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where the columns are reversed. For example, if surname is in the forename field and vice versa</p> <p>By default, col_l = col_r.  If the symmetrical argument is True, then col_l = col_r AND col_r = col_l.</p> <p>Parameters:</p> Name Type Description Default <code>col_name_1</code> <code>str</code> <p>First column, e.g. forename</p> required <code>col_name_2</code> <code>str</code> <p>Second column, e.g. surname</p> required <code>symmetrical</code> <code>bool</code> <p>If True, equality is required in in both directions. Default is False.</p> <code>False</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.CosineSimilarityLevel","title":"<code>CosineSimilarityLevel(col_name, similarity_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a cosine similarity function</p> <p>e.g. array_cosine_similarity(val_l, val_r) &gt;= similarity_threshold</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>similarity_threshold</code> <code>float</code> <p>The threshold to use to assess similarity. Should be between 0 and 1.</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.CustomLevel","title":"<code>CustomLevel(sql_condition, label_for_charts=None, base_dialect_str=None)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level with a custom sql expression</p> <p>Must be in a form suitable for use in a SQL CASE WHEN expression e.g. \"substr(name_l, 1, 1) = substr(name_r, 1, 1)\"</p> <p>Parameters:</p> Name Type Description Default <code>sql_condition</code> <code>str</code> <p>SQL condition to assess similarity</p> required <code>label_for_charts</code> <code>str</code> <p>A label for this level to be used in charts. Default None, so that <code>sql_condition</code> is used</p> <code>None</code> <code>base_dialect_str</code> <code>str</code> <p>If specified, the SQL dialect that this expression will parsed as when attempting to translate to other backends</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.DamerauLevenshteinLevel","title":"<code>DamerauLevenshteinLevel(col_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a Damerau-Levenshtein distance function</p> <p>e.g. damerau_levenshtein(val_l, val_r) &lt;= distance_threshold</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>distance_threshold</code> <code>int</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.DistanceFunctionLevel","title":"<code>DistanceFunctionLevel(col_name, distance_function_name, distance_threshold, higher_is_more_similar=True)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using an arbitrary distance function</p> <p>e.g. <code>custom_distance(val_l, val_r) &gt;= (&lt;=) distance_threshold</code></p> <p>The function given by <code>distance_function_name</code> must exist in the SQL backend you use, and must take two parameters of the type in `col_name, returning a numeric type</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str | ColumnExpression</code> <p>Input column name</p> required <code>distance_function_name</code> <code>str</code> <p>the name of the SQL distance function</p> required <code>distance_threshold</code> <code>Union[int, float]</code> <p>The threshold to use to assess similarity</p> required <code>higher_is_more_similar</code> <code>bool</code> <p>Are higher values of the distance function more similar? (e.g. True for Jaro-Winkler, False for Levenshtein) Default is True</p> <code>True</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.DistanceInKMLevel","title":"<code>DistanceInKMLevel(lat_col, long_col, km_threshold, not_null=False)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Use the haversine formula to transform comparisons of lat,lngs into distances measured in kilometers</p> <p>Parameters:</p> Name Type Description Default <code>lat_col</code> <code>str</code> <p>The name of a latitude column or the respective array or struct column column containing the information For example: long_lat['lat'] or long_lat[0]</p> required <code>long_col</code> <code>str</code> <p>The name of a longitudinal column or the respective array or struct column column containing the information, plus an index. For example: long_lat['long'] or long_lat[1]</p> required <code>km_threshold</code> <code>int</code> <p>The total distance in kilometers to evaluate your comparisons against</p> required <code>not_null</code> <code>bool</code> <p>If true, ensure no attempt is made to compute this if any inputs are null. This is only necessary if you are not capturing nulls elsewhere in your comparison level.</p> <code>False</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.ElseLevel","title":"<code>ElseLevel</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>This level is used to capture all comparisons that do not match any other specified levels. It corresponds to the ELSE clause in a SQL CASE statement.</p>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.ExactMatchLevel","title":"<code>ExactMatchLevel(col_name, term_frequency_adjustments=False)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where there is an exact match</p> <p>e.g. val_l = val_r</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>term_frequency_adjustments</code> <code>bool</code> <p>If True, apply term frequency adjustments to the exact match level. Defaults to False.</p> <code>False</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.JaccardLevel","title":"<code>JaccardLevel(col_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a Jaccard distance function</p> <p>e.g. <code>jaccard(val_l, val_r) &gt;= distance_threshold</code></p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>distance_threshold</code> <code>Union[int, float]</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.JaroLevel","title":"<code>JaroLevel(col_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a Jaro distance function</p> <p>e.g. <code>jaro(val_l, val_r) &gt;= distance_threshold</code></p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>distance_threshold</code> <code>Union[int, float]</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.JaroWinklerLevel","title":"<code>JaroWinklerLevel(col_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a Jaro-Winkler distance function</p> <p>e.g. <code>jaro_winkler(val_l, val_r) &gt;= distance_threshold</code></p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>distance_threshold</code> <code>Union[int, float]</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.LevenshteinLevel","title":"<code>LevenshteinLevel(col_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using a sqlglot_dialect_name distance function</p> <p>e.g. levenshtein(val_l, val_r) &lt;= distance_threshold</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name</p> required <code>distance_threshold</code> <code>int</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.LiteralMatchLevel","title":"<code>LiteralMatchLevel(col_name, literal_value, literal_datatype, side_of_comparison='both')</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where a column matches a literal value</p> <p>e.g. val_l = 'literal' AND/OR val_r = 'literal'</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>Input column name or ColumnExpression</p> required <code>literal_value</code> <code>str</code> <p>The literal value to compare against e.g. 'male'</p> required <code>literal_datatype</code> <code>str</code> <p>The datatype of the literal value. Must be one of: \"string\", \"int\", \"float\", \"date\"</p> required <code>side_of_comparison</code> <code>str</code> <p>Which side(s) of the comparison to apply. Must be one of: \"left\", \"right\", \"both\". Defaults to \"both\".</p> <code>'both'</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.Not","title":"<code>Not(comparison_level)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level that is the negation of another comparison level</p> <p>Resulting ComparisonLevelCreator is equivalent to the passed ComparisonLevelCreator but with SQL conditions negated with logical \"NOY\".</p> <p>Parameters:</p> Name Type Description Default <code>*comparison_level</code> <code>ComparisonLevelCreator | dict</code> <p>This represents the comparison level you wish to negate with 'NOT'</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.NullLevel","title":"<code>NullLevel(col_name, valid_string_pattern=None)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where either or both values are NULL</p> <p>e.g. val_l IS NULL OR val_r IS NULL</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>Input column name or ColumnExpression</p> required <code>valid_string_pattern</code> <code>str</code> <p>If provided, a regex pattern to extract a valid substring from the column before checking for NULL. Default is None.</p> <code>None</code> Note <p>If a valid_string_pattern is provided, the NULL check will be performed on the extracted substring rather than the original column value.</p>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.Or","title":"<code>Or(*comparison_levels)</code>","text":"<p>               Bases: <code>_Merge</code></p> <p>Represents a comparison level that is an 'OR' of other comparison levels</p> <p>Merge multiple ComparisonLevelCreators into a single ComparisonLevelCreator by merging their SQL conditions using a logical \"OR\".</p> <p>Parameters:</p> Name Type Description Default <code>*comparison_levels</code> <code>ComparisonLevelCreator | dict</code> <p>These represent the comparison levels you wish to combine via 'OR'</p> <code>()</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.PairwiseStringDistanceFunctionLevel","title":"<code>PairwiseStringDistanceFunctionLevel(col_name, distance_function_name, distance_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>A comparison level using the most similar string distance between any pair of values between arrays in an array column.</p> <p>The function given by <code>distance_function_name</code> must be one of \"levenshtein,\" \"damera_levenshtein,\" \"jaro_winkler,\" or \"jaro.\"</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str | ColumnExpression</code> <p>Input column name</p> required <code>distance_function_name</code> <code>str</code> <p>the name of the string distance function</p> required <code>distance_threshold</code> <code>Union[int, float]</code> <p>The threshold to use to assess similarity</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#splink.comparison_level_library.PercentageDifferenceLevel","title":"<code>PercentageDifferenceLevel(col_name, percentage_threshold)</code>","text":"<p>               Bases: <code>ComparisonLevelCreator</code></p> <p>Represents a comparison level where the difference between two numerical values is within a specified percentage threshold.</p> <p>The percentage difference is calculated as the absolute difference between the two values divided by the greater of the two values.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Input column name.</p> required <code>percentage_threshold</code> <code>float</code> <p>The threshold percentage to use to assess similarity e.g. 0.1 for 10%.</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#absolutedatedifferencelevel","title":"AbsoluteDateDifferenceLevel","text":"<p>An alias of AbsoluteTimeDifferenceLevel.</p>","tags":["API","comparisons"]},{"location":"api_docs/comparison_level_library.html#configuring-comparisons","title":"Configuring comparisons","text":"<p>Note that all comparison levels have a <code>.configure()</code> method as follows:</p> <p>Configure the comparison level with options which are common to all comparison levels.  The options align to the keys in the json specification of a comparison level.  These options are usually not needed, but are available for advanced users.</p> <p>All options have default options set initially. Any call to <code>.configure()</code> will set any options that are supplied. Any subsequent calls to <code>.configure()</code> will not override these values with defaults; to override values you must must explicitly provide a value corresponding to the default.</p> <p>Generally speaking only a single call (at most) to <code>.configure()</code> should be required.</p> <p>Parameters:</p> Name Type Description Default <code>m_probability</code> <code>float</code> <p>The m probability for this comparison level. Default is equivalent to None, in which case a default initial value will be provided for this level.</p> <code>unsupplied_option</code> <code>u_probability</code> <code>float</code> <p>The u probability for this comparison level. Default is equivalent to None, in which case a default initial value will be provided for this level.</p> <code>unsupplied_option</code> <code>tf_adjustment_column</code> <code>str</code> <p>Make term frequency adjustments for this comparison level using this input column. Default is equivalent to None, meaning that term-frequency adjustments will not be applied for this level.</p> <code>unsupplied_option</code> <code>tf_adjustment_weight</code> <code>float</code> <p>Make term frequency adjustments for this comparison level using this weight. Default is equivalent to None, meaning term-frequency adjustments are fully-weighted if turned on.</p> <code>unsupplied_option</code> <code>tf_minimum_u_value</code> <code>float</code> <p>When term frequency adjustments are turned on, where the term frequency adjustment implies a u value below this value, use this minimum value instead. Defaults is equivalent to None, meaning no minimum value.</p> <code>unsupplied_option</code> <code>is_null_level</code> <code>bool</code> <p>If true, m and u values will not be estimated and instead the match weight will be zero for this column. Default is equivalent to False.</p> <code>unsupplied_option</code> <code>label_for_charts</code> <code>str</code> <p>If provided, a custom label that will be used for this level in any charts. Default is equivalent to None, in which case a default label will be provided for this level.</p> <code>unsupplied_option</code> <code>disable_tf_exact_match_detection</code> <code>bool</code> <p>If true, if term frequency adjustments are set, the corresponding adjustment will be made using the u-value for this level, rather than the usual case where it is the u-value of the exact match level in the same comparison. Default is equivalent to False.</p> <code>unsupplied_option</code> <code>fix_m_probability</code> <code>bool</code> <p>If true, the m probability for this level will be fixed and not estimated during training. Default is equivalent to False.</p> <code>unsupplied_option</code> <code>fix_u_probability</code> <code>bool</code> <p>If true, the u probability for this level will be fixed and not estimated during training. Default is equivalent to False.</p> <code>unsupplied_option</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html","title":"Comparison Library","text":"","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#documentation-for-the-comparison_library","title":"Documentation for the <code>comparison_library</code>","text":"","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.AbsoluteTimeDifferenceAtThresholds","title":"<code>AbsoluteTimeDifferenceAtThresholds(col_name, *, input_is_string, metrics, thresholds, datetime_format=None, term_frequency_adjustments=False, invalid_dates_as_null=True)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with multiple levels based on absolute time differences:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Absolute time difference levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with metrics = ['day', 'month'] and thresholds = [1, 3] the levels are:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Absolute time difference in <code>col_name</code> &lt;= 1 day</li> <li>Absolute time difference in <code>col_name</code> &lt;= 3 months</li> <li>Anything else</li> </ul> <p>This comparison uses the AbsoluteTimeDifferenceLevel, which computes the total elapsed time between two dates, rather than counting calendar intervals.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>input_is_string</code> <code>bool</code> <p>If True, the input dates are treated as strings and parsed according to <code>datetime_format</code>.</p> required <code>metrics</code> <code>Union[DateMetricType, List[DateMetricType]]</code> <p>The unit(s) of time to use when comparing dates. Can be 'second', 'minute', 'hour', 'day', 'month', or 'year'.</p> required <code>thresholds</code> <code>Union[int, float, List[Union[int, float]]]</code> <p>The threshold(s) to use for the time difference level(s).</p> required <code>datetime_format</code> <code>str</code> <p>The format string for parsing dates if <code>input_is_string</code> is True. ISO 8601 format used if not provided.</p> <code>None</code> <code>term_frequency_adjustments</code> <code>bool</code> <p>Whether to apply term frequency adjustments. Defaults to False.</p> <code>False</code> <code>invalid_dates_as_null</code> <code>bool</code> <p>If True and <code>input_is_string</code> is True, treat invalid dates as null. Defaults to True.</p> <code>True</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.ArrayIntersectAtSizes","title":"<code>ArrayIntersectAtSizes(col_name, size_threshold_or_thresholds=[1])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with multiple levels based on the intersection sizes of array elements:</p> <ul> <li>Intersection at specified size thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with size_threshold_or_thresholds = [3, 1], the levels are:</p> <ul> <li>Intersection of arrays in <code>col_name</code> has at least 3 elements</li> <li>Intersection of arrays in <code>col_name</code> has at least 1 element</li> <li>Anything else (e.g., empty intersection)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>size_threshold_or_thresholds</code> <code>Union[int, list[int]]</code> <p>The size threshold(s) for the intersection levels. Defaults to [1].</p> <code>[1]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.CosineSimilarityAtThresholds","title":"<code>CosineSimilarityAtThresholds(col_name, score_threshold_or_thresholds=[0.9, 0.8, 0.7])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with two or more levels:</p> <ul> <li>Cosine similarity levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with score_threshold_or_thresholds = [0.9, 0.7] the levels are:</p> <ul> <li>Cosine similarity in <code>col_name</code> &gt;= 0.9</li> <li>Cosine similarity in <code>col_name</code> &gt;= 0.7</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>score_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the cosine similarity level(s). Defaults to [0.9, 0.7].</p> <code>[0.9, 0.8, 0.7]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.CustomComparison","title":"<code>CustomComparison(comparison_levels, output_column_name=None, comparison_description=None)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data with custom supplied levels.</p> <p>Parameters:</p> Name Type Description Default <code>output_column_name</code> <code>str</code> <p>The column name to use to refer to this comparison</p> <code>None</code> <code>comparison_levels</code> <code>list</code> <p>A list of some combination of <code>ComparisonLevelCreator</code> objects, or dicts. These represent the similarity levels assessed by the comparison, in order of decreasing specificity</p> required <code>comparison_description</code> <code>str</code> <p>An optional description of the comparison</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.DamerauLevenshteinAtThresholds","title":"<code>DamerauLevenshteinAtThresholds(col_name, distance_threshold_or_thresholds=[1, 2])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Damerau-Levenshtein levels at specified distance thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with distance_threshold_or_thresholds = [1, 3] the levels are</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Damerau-Levenshtein distance in <code>col_name</code> &lt;= 1</li> <li>Damerau-Levenshtein distance in <code>col_name</code> &lt;= 3</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>distance_threshold_or_thresholds</code> <code>Union[int, list]</code> <p>The threshold(s) to use for the Damerau-Levenshtein similarity level(s). Defaults to [1, 2].</p> <code>[1, 2]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.DateOfBirthComparison","title":"<code>DateOfBirthComparison(col_name, *, input_is_string, datetime_thresholds=[1, 1, 10], datetime_metrics=['month', 'year', 'year'], datetime_format=None, invalid_dates_as_null=True)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Generate an 'out of the box' comparison for a date of birth column in the <code>col_name</code> provided.</p> <p>Note that <code>input_is_string</code> is a required argument: you must denote whether the <code>col_name</code> contains if of type date/dattime or string.</p> <p>The default arguments will give a comparison with comparison levels:</p> <ul> <li>Exact match (all other dates)</li> <li>Damerau-Levenshtein distance &lt;= 1</li> <li>Date difference &lt;= 1 month</li> <li>Date difference &lt;= 1 year</li> <li>Date difference &lt;= 10 years</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name</p> required <code>input_is_string</code> <code>bool</code> <p>If True, the provided <code>col_name</code> must be of type string.  If False, it must be a date or datetime.</p> required <code>datetime_thresholds</code> <code>Union[int, float, List[Union[int, float]]]</code> <p>Numeric thresholds for date differences. Defaults to [1, 1, 10].</p> <code>[1, 1, 10]</code> <code>datetime_metrics</code> <code>Union[DateMetricType, List[DateMetricType]]</code> <p>Metrics for date differences. Defaults to [\"month\", \"year\", \"year\"].</p> <code>['month', 'year', 'year']</code> <code>datetime_format</code> <code>str</code> <p>The datetime format used to cast strings to dates.  Only used if input is a string.</p> <code>None</code> <code>invalid_dates_as_null</code> <code>bool</code> <p>If True, treat invalid dates as null as opposed to allowing e.g. an exact or levenshtein match where one side or both are an invalid date.  Only used if input is a string.  Defaults to True.</p> <code>True</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.DistanceFunctionAtThresholds","title":"<code>DistanceFunctionAtThresholds(col_name, distance_function_name, distance_threshold_or_thresholds, higher_is_more_similar=True)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Custom distance function levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with distance_threshold_or_thresholds = [1, 3] and distance_function 'hamming', with higher_is_more_similar False the levels are:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Hamming distance of <code>col_name</code> &lt;= 1</li> <li>Hamming distance of <code>col_name</code> &lt;= 3</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>distance_function_name</code> <code>str</code> <p>the name of the SQL distance function</p> required <code>distance_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the distance function level(s).</p> required <code>higher_is_more_similar</code> <code>bool</code> <p>Are higher values of the distance function more similar? (e.g. True for Jaro-Winkler, False for Levenshtein) Default is True</p> <code>True</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.DistanceInKMAtThresholds","title":"<code>DistanceInKMAtThresholds(lat_col, long_col, km_thresholds)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>A comparison of the latitude, longitude coordinates defined in 'lat_col' and 'long col' giving the great circle distance between them in km.</p> <p>An example of the output with km_thresholds = [1, 10] would be:</p> <ul> <li>The two coordinates are within 1 km of one another</li> <li>The two coordinates are within 10 km of one another</li> <li>Anything else (i.e. the distance between coordinates are &gt; 10km apart)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>lat_col</code> <code>str</code> <p>The name of the latitude column to compare.</p> required <code>long_col</code> <code>str</code> <p>The name of the longitude column to compare.</p> required <code>km_thresholds</code> <code>iterable[float] | float</code> <p>The km threshold(s) for the distance levels.</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.EmailComparison","title":"<code>EmailComparison(col_name)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Generate an 'out of the box' comparison for an email address column with the in the <code>col_name</code> provided.</p> <p>The default comparison levels are:</p> <ul> <li>Null comparison: e.g., one email is missing or invalid.</li> <li>Exact match on full email: e.g., <code>john@smith.com</code> vs. <code>john@smith.com</code>.</li> <li>Exact match on username part of email: e.g., <code>john@company.com</code> vs. <code>john@other.com</code>.</li> <li>Jaro-Winkler similarity &gt; 0.88 on full email: e.g., <code>john.smith@company.com</code> vs. <code>john.smyth@company.com</code>.</li> <li>Jaro-Winkler similarity &gt; 0.88 on username part of email: e.g., <code>john.smith@company.com</code> vs. <code>john.smyth@other.com</code>.</li> <li>Anything else: e.g., <code>john@company.com</code> vs. <code>rebecca@other.com</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for the email addresses to be compared.</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.ExactMatch","title":"<code>ExactMatch(col_name)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with two levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.ForenameSurnameComparison","title":"<code>ForenameSurnameComparison(forename_col_name, surname_col_name, *, jaro_winkler_thresholds=[0.92, 0.88], forename_surname_concat_col_name=None)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Generate an 'out of the box' comparison for forename and surname columns in the <code>forename_col_name</code> and <code>surname_col_name</code> provided.</p> <p>It's recommended to derive an additional column containing a concatenated forename and surname column so that term frequencies can be applied to the full name.  If you have derived a column, provide it at <code>forename_surname_concat_col_name</code>.</p> <p>The default comparison levels are:</p> <ul> <li>Null comparison on both forename and surname</li> <li>Exact match on both forename and surname</li> <li>Columns reversed comparison (forename and surname swapped)</li> <li>Jaro-Winkler similarity &gt; 0.92 on both forename and surname</li> <li>Jaro-Winkler similarity &gt; 0.88 on both forename and surname</li> <li>Exact match on surname</li> <li>Exact match on forename</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>forename_col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for the forenames to be compared.</p> required <code>surname_col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for the surnames to be compared.</p> required <code>jaro_winkler_thresholds</code> <code>Union[float, list[float]]</code> <p>Thresholds for Jaro-Winkler similarity. Defaults to [0.92, 0.88].</p> <code>[0.92, 0.88]</code> <code>forename_surname_concat_col_name</code> <code>str</code> <p>The column name for concatenated forename and surname values. If provided, term frequencies are applied on the exact match using this column</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.JaccardAtThresholds","title":"<code>JaccardAtThresholds(col_name, score_threshold_or_thresholds=[0.9, 0.7])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaccard score levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with score_threshold_or_thresholds = [0.9, 0.7] the levels are:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaccard score in <code>col_name</code> &gt;= 0.9</li> <li>Jaccard score in <code>col_name</code> &gt;= 0.7</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>score_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the Jaccard similarity level(s). Defaults to [0.9, 0.7].</p> <code>[0.9, 0.7]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.JaroAtThresholds","title":"<code>JaroAtThresholds(col_name, score_threshold_or_thresholds=[0.9, 0.7])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaro score levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with score_threshold_or_thresholds = [0.9, 0.7] the levels are:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaro score in <code>col_name</code> &gt;= 0.9</li> <li>Jaro score in <code>col_name</code> &gt;= 0.7</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>score_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the Jaro similarity level(s). Defaults to [0.9, 0.7].</p> <code>[0.9, 0.7]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.JaroWinklerAtThresholds","title":"<code>JaroWinklerAtThresholds(col_name, score_threshold_or_thresholds=[0.9, 0.7])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaro-Winkler score levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with score_threshold_or_thresholds = [0.9, 0.7] the levels are:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Jaro-Winkler score in <code>col_name</code> &gt;= 0.9</li> <li>Jaro-Winkler score in <code>col_name</code> &gt;= 0.7</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>score_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the Jaro-Winkler similarity level(s). Defaults to [0.9, 0.7].</p> <code>[0.9, 0.7]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.LevenshteinAtThresholds","title":"<code>LevenshteinAtThresholds(col_name, distance_threshold_or_thresholds=[1, 2])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the data in <code>col_name</code> with three or more levels:</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Levenshtein levels at specified distance thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with distance_threshold_or_thresholds = [1, 3] the levels are</p> <ul> <li>Exact match in <code>col_name</code></li> <li>Levenshtein distance in <code>col_name</code> &lt;= 1</li> <li>Levenshtein distance in <code>col_name</code> &lt;= 3</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare</p> required <code>distance_threshold_or_thresholds</code> <code>Union[int, list]</code> <p>The threshold(s) to use for the levenshtein similarity level(s). Defaults to [1, 2].</p> <code>[1, 2]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.NameComparison","title":"<code>NameComparison(col_name, *, jaro_winkler_thresholds=[0.92, 0.88, 0.7], dmeta_col_name=None)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Generate an 'out of the box' comparison for a name column in the <code>col_name</code> provided.</p> <p>It's also possible to include a level for a dmetaphone match, but this requires you to derive a dmetaphone column prior to importing it into Splink. Note this is expected to be a column containing arrays of dmetaphone values, which are of length 1 or 2.</p> <p>The default comparison levels are:</p> <ul> <li>Null comparison</li> <li>Exact match</li> <li>Jaro-Winkler similarity &gt; 0.92</li> <li>Jaro-Winkler similarity &gt; 0.88</li> <li>Jaro-Winkler similarity &gt; 0.70</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for the names to be compared.</p> required <code>jaro_winkler_thresholds</code> <code>Union[float, list[float]]</code> <p>Thresholds for Jaro-Winkler similarity. Defaults to [0.92, 0.88, 0.7].</p> <code>[0.92, 0.88, 0.7]</code> <code>dmeta_col_name</code> <code>str</code> <p>The column name for dmetaphone values. If provided, array intersection level is included. This column must contain arrays of dmetaphone values, which are of length 1 or 2.</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.PairwiseStringDistanceFunctionAtThresholds","title":"<code>PairwiseStringDistanceFunctionAtThresholds(col_name, distance_function_name, distance_threshold_or_thresholds)</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Represents a comparison of the most similar pair of values where the first value is in the array data in <code>col_name</code> for the first record and the second value is in the array data in <code>col_name</code> for the second record. The comparison has three or more levels:</p> <ul> <li>Exact match between any pair of values</li> <li>User-selected string distance function levels at specified thresholds</li> <li>...</li> <li>Anything else</li> </ul> <p>For example, with distance_threshold_or_thresholds = [1, 3] and distance_function 'levenshtein' the levels are:</p> <ul> <li>Exact match between any pair of values</li> <li>Levenshtein distance between the most similar pair of values &lt;= 1</li> <li>Levenshtein distance between the most similar pair of values &lt;= 3</li> <li>Anything else</li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>The name of the column to compare.</p> required <code>distance_function_name</code> <code>str</code> <p>the name of the string distance function. Must be one of \"levenshtein,\" \"damera_levenshtein,\" \"jaro_winkler,\" or \"jaro.\"</p> required <code>distance_threshold_or_thresholds</code> <code>Union[float, list]</code> <p>The threshold(s) to use for the distance function level(s).</p> required","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#splink.comparison_library.PostcodeComparison","title":"<code>PostcodeComparison(col_name, *, invalid_postcodes_as_null=False, lat_col=None, long_col=None, km_thresholds=[1, 10, 100])</code>","text":"<p>               Bases: <code>ComparisonCreator</code></p> <p>Generate an 'out of the box' comparison for a postcode column with the in the <code>col_name</code> provided.</p> <p>The default comparison levels are:</p> <ul> <li>Null comparison</li> <li>Exact match on full postcode</li> <li>Exact match on sector</li> <li>Exact match on district</li> <li>Exact match on area</li> <li>Distance in km (if lat_col and long_col are provided)</li> </ul> <p>It's also possible to include levels for distance in km, but this requires you to have geocoded your postcodes prior to importing them into Splink. Use the <code>lat_col</code> and <code>long_col</code> arguments to tell Splink where to find the latitude and longitude columns.</p> <p>See https://ideal-postcodes.co.uk/guides/uk-postcode-format for definitions</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for the postcodes to be compared.</p> required <code>invalid_postcodes_as_null</code> <code>bool</code> <p>If True, treat invalid postcodes as null. Defaults to False.</p> <code>False</code> <code>lat_col</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for latitude. Required if <code>km_thresholds</code> is provided.</p> <code>None</code> <code>long_col</code> <code>Union[str, ColumnExpression]</code> <p>The column name or expression for longitude. Required if <code>km_thresholds</code> is provided.</p> <code>None</code> <code>km_thresholds</code> <code>Union[float, List[float]]</code> <p>Thresholds for distance in kilometers. If provided, <code>lat_col</code> and <code>long_col</code> must also be provided.</p> <code>[1, 10, 100]</code>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#absolutedatedifferenceatthresholds","title":"AbsoluteDateDifferenceAtThresholds","text":"<p>An alias of AbsoluteTimeDifferenceAtThresholds.</p>","tags":["API","comparisons"]},{"location":"api_docs/comparison_library.html#configuring-comparisons","title":"Configuring comparisons","text":"<p>Note that all comparisons have a <code>.configure()</code> method as follows:</p> <p>Configure the comparison creator with options that are common to all comparisons.</p> <p>For m and u probabilities, the first element in the list corresponds to the first comparison level, usually an exact match level. Subsequent elements correspond comparison to levels in sequential order, through to the last element which is usually the 'ELSE' level.</p> <p>All options have default options set initially. Any call to <code>.configure()</code> will set any options that are supplied. Any subsequent calls to <code>.configure()</code> will not override these values with defaults; to override values you must explicitly provide a value corresponding to the default.</p> <p>Generally speaking only a single call (at most) to <code>.configure()</code> should be required.</p> <p>Parameters:</p> Name Type Description Default <code>term_frequency_adjustments</code> <code>bool</code> <p>Whether term frequency adjustments are switched on for this comparison. Only applied to exact match levels. Default corresponds to False.</p> <code>unsupplied_option</code> <code>m_probabilities</code> <code>list</code> <p>List of m probabilities Default corresponds to None.</p> <code>unsupplied_option</code> <code>u_probabilities</code> <code>list</code> <p>List of u probabilities Default corresponds to None.</p> <code>unsupplied_option</code> Example <pre><code>cc = LevenshteinAtThresholds(\"name\", 2)\ncc.configure(\n    m_probabilities=[0.9, 0.08, 0.02],\n    u_probabilities=[0.01, 0.05, 0.94]\n    # probabilities for exact match level, levenshtein &lt;= 2, and else\n    # in that order\n)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/datasets.html","title":"SplinkDatasets","text":"","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#in-built-datasets","title":"In-built datasets","text":"<p>Splink has some datasets available for use to help you get up and running, test ideas, or explore Splink features. To use, simply import <code>splink_datasets</code>: </p><pre><code>from splink import splink_datasets\n\ndf = splink_datasets.fake_1000\n</code></pre> which you can then use to set up a linker: <pre><code>from splink splink_datasets, Linker, DuckDBAPI, SettingsCreator\n\ndf = splink_datasets.fake_1000\nlinker = Linker(\n    df,\n    SettingsCreator(\n        link_type=\"dedupe_only\",\n        comparisons=[\n            cl.exact_match(\"first_name\"),\n            cl.exact_match(\"surname\"),\n        ],\n    ),\n    db_api=DuckDBAPI()\n)\n</code></pre> Troubleshooting <p>If you get a <code>SSLCertVerificationError</code> when trying to use the inbuilt datasets, this can be fixed with the <code>ssl</code> package by running:</p> <p><code>ssl._create_default_https_context = ssl._create_unverified_context</code>.</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink_datasets","title":"<code>splink_datasets</code>","text":"<p>Each attribute of <code>splink_datasets</code> is a dataset available for use, which exists as a pandas <code>DataFrame</code>. These datasets are not packaged directly with Splink, but instead are downloaded only when they are requested. Once requested they are cached for future use. The cache can be cleared using <code>splink_dataset_utils</code> (see below), which also contains information on available datasets, and which have already been cached.</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#available-datasets","title":"Available datasets","text":"<p>The datasets available are listed below:</p> dataset name description rows unique entities link to source <code>fake_1000</code> Fake 1000 from splink demos.  Records are 250 simulated people, with different numbers of duplicates, labelled. 1,000 250 source <code>historical_50k</code> The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors. 50,000 5,156 source <code>febrl3</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL3 data set contains 5000 records (2000 originals and 3000 duplicates), with a maximum of 5 duplicates based on one original record. 5,000 2,000 source <code>febrl4a</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL4a contains 5000 original records. 5,000 5,000 source <code>febrl4b</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL4b contains 5000 duplicate records, one for each record in FEBRL4a. 5,000 5,000 source <code>transactions_origin</code> This data has been generated to resemble bank transactions leaving an account. There are no duplicates within the dataset and each transaction is designed to have a counterpart arriving in 'transactions_destination'. Memo is sometimes truncated or missing. 45,326 45,326 source <code>transactions_destination</code> This data has been generated to resemble bank transactions arriving in an account. There are no duplicates within the dataset and each transaction is designed to have a counterpart sent from 'transactions_origin'. There may be a delay between the source and destination account, and the amount may vary due to hidden fees and foreign exchange rates. Memo is sometimes truncated or missing. 45,326 45,326 source","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink_dataset_labels","title":"<code>splink_dataset_labels</code>","text":"<p>Some of the <code>splink_datasets</code> have corresponding clerical labels to help assess model performance. These are requested through the <code>splink_dataset_labels</code> module.</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#available-datasets_1","title":"Available datasets","text":"<p>The datasets available are listed below:</p> dataset name description rows unique entities link to source <code>fake_1000_labels</code> Clerical labels for fake_1000 3,176 NA source","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink_dataset_utils-api","title":"<code>splink_dataset_utils</code> API","text":"<p>In addition to <code>splink_datasets</code>, you can also import <code>splink_dataset_utils</code>, which has a few functions to help managing <code>splink_datasets</code>. This can be useful if you have limited internet connection and want to see what is already cached, or if you need to clear cache items (e.g. if datasets were to be updated, or if space is an issue).</p> <p>For example: </p><pre><code>from splink.datasets import splink_dataset_utils\n\nsplink_dataset_utils.show_downloaded_data()\nsplink_dataset_utils.clear_cache(['fake_1000'])\n</code></pre>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink.internals.datasets.utils.SplinkDataUtils.list_downloaded_datasets","title":"<code>list_downloaded_datasets()</code>","text":"<p>Return a list of datasets that have already been pre-downloaded</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink.internals.datasets.utils.SplinkDataUtils.list_all_datasets","title":"<code>list_all_datasets()</code>","text":"<p>Return a list of all available datasets, regardless of whether or not they have already been pre-downloaded</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink.internals.datasets.utils.SplinkDataUtils.show_downloaded_data","title":"<code>show_downloaded_data()</code>","text":"<p>Print a list of datasets that have already been pre-downloaded</p>","tags":["API","Datasets","Examples"]},{"location":"api_docs/datasets.html#splink.internals.datasets.utils.SplinkDataUtils.clear_downloaded_data","title":"<code>clear_downloaded_data(datasets=None)</code>","text":"<p>Delete any pre-downloaded data stored locally.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>list</code> <p>A list of dataset names (without any file suffix) to delete. If <code>None</code>, all datasets will be deleted. Default <code>None</code></p> <code>None</code>","tags":["API","Datasets","Examples"]},{"location":"api_docs/em_training_session.html","title":"EM Training Session API","text":"","tags":["API","training"]},{"location":"api_docs/em_training_session.html#documentation-foremtrainingsession","title":"Documentation for<code>EMTrainingSession</code>","text":"<p><code>linker.training.estimate_parameters_using_expectation_maximisation</code> returns an object of type <code>EMTrainingSession</code> which has the following methods:</p> <p>Manages training models using the Expectation Maximisation algorithm, and holds statistics on the evolution of parameter estimates.  Plots diagnostic charts</p>","tags":["API","training"]},{"location":"api_docs/em_training_session.html#splink.internals.em_training_session.EMTrainingSession.probability_two_random_records_match_iteration_chart","title":"<code>probability_two_random_records_match_iteration_chart()</code>","text":"<p>Display a chart showing the iteration history of the probability that two random records match.</p> <p>Returns:</p> Type Description <code>ChartReturnType</code> <p>An interactive Altair chart.</p>","tags":["API","training"]},{"location":"api_docs/em_training_session.html#splink.internals.em_training_session.EMTrainingSession.match_weights_interactive_history_chart","title":"<code>match_weights_interactive_history_chart()</code>","text":"<p>Display an interactive chart of the match weights history.</p> <p>Returns:</p> Type Description <code>ChartReturnType</code> <p>An interactive Altair chart.</p>","tags":["API","training"]},{"location":"api_docs/em_training_session.html#splink.internals.em_training_session.EMTrainingSession.m_u_values_interactive_history_chart","title":"<code>m_u_values_interactive_history_chart()</code>","text":"<p>Display an interactive chart of the m and u values.</p> <p>Returns:</p> Type Description <code>ChartReturnType</code> <p>An interactive Altair chart.</p>","tags":["API","training"]},{"location":"api_docs/evaluation.html","title":"Evaluation","text":"","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#methods-in-linkerevaluation","title":"Methods in Linker.evaluation","text":"<p>Evaluate the performance of a Splink model.  Accessed via <code>linker.evaluation</code></p>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.prediction_errors_from_labels_table","title":"<code>prediction_errors_from_labels_table(labels_splinkdataframe_or_table_name, include_false_positives=True, include_false_negatives=True, threshold_match_probability=0.5)</code>","text":"<p>Find false positives and false negatives based on the comparison between the <code>clerical_match_score</code> in the labels table compared with the splink predicted match probability</p> <p>The table of labels should be in the following format, and should be registered as a table with your database using</p> <p><code>labels_table = linker.table_management.register_labels_table(my_df)</code></p> source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 <p>Parameters:</p> Name Type Description Default <code>labels_splinkdataframe_or_table_name</code> <code>str | SplinkDataFrame</code> <p>Name of table containing labels in the database</p> required <code>include_false_positives</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>include_false_negatives</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>threshold_match_probability</code> <code>float</code> <p>Threshold probability above which a prediction considered to be a match. Defaults to 0.5.</p> <code>0.5</code> <p>Examples:</p> <pre><code>labels_table = linker.table_management.register_labels_table(df_labels)\n\nlinker.evaluation.prediction_errors_from_labels_table(\n   labels_table, include_false_negatives=True, include_false_positives=False\n).as_pandas_dataframe()\n</code></pre> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>Table containing false positives and negatives</p>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.accuracy_analysis_from_labels_column","title":"<code>accuracy_analysis_from_labels_column(labels_column_name, *, threshold_match_probability=0.5, match_weight_round_to_nearest=0.1, output_type='threshold_selection', add_metrics=[], positives_not_captured_by_blocking_rules_scored_as_zero=True)</code>","text":"<p>Generate an accuracy chart or table from ground truth data, where the ground truth is in a column in the input dataset called <code>labels_column_name</code></p> <p>Parameters:</p> Name Type Description Default <code>labels_column_name</code> <code>str</code> <p>Column name containing labels in the input table</p> required <code>threshold_match_probability</code> <code>float</code> <p>Where the <code>clerical_match_score</code> provided by the user is a probability rather than binary, this value is used as the threshold to classify <code>clerical_match_score</code>s as binary matches or non matches. Defaults to 0.5.</p> <code>0.5</code> <code>match_weight_round_to_nearest</code> <code>float</code> <p>When provided, thresholds are rounded.  When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the chart. Defaults to None.</p> <code>0.1</code> <code>add_metrics</code> <code>list(str)</code> <p>Precision and recall metrics are always included. Where provided, <code>add_metrics</code> specifies additional metrics to show, with the following options:</p> <ul> <li><code>\"specificity\"</code>: specificity, selectivity, true negative rate (TNR)</li> <li><code>\"npv\"</code>: negative predictive value (NPV)</li> <li><code>\"accuracy\"</code>: overall accuracy (TP+TN)/(P+N)</li> <li><code>\"f1\"</code>/<code>\"f2\"</code>/<code>\"f0_5\"</code>: F-scores for \u03b2=1 (balanced), \u03b2=2 (emphasis on recall) and \u03b2=0.5 (emphasis on precision)</li> <li><code>\"p4\"</code> -  an extended F1 score with specificity and NPV included</li> <li><code>\"phi\"</code> - \u03c6 coefficient or Matthews correlation coefficient (MCC)</li> </ul> <code>[]</code> <p>Examples:</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\"ground_truth\", add_metrics=[\"f1\"])\n</code></pre> <p>Returns:</p> Name Type Description <code>chart</code> <code>Union[ChartReturnType, SplinkDataFrame]</code> <p>An altair chart</p>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.accuracy_analysis_from_labels_table","title":"<code>accuracy_analysis_from_labels_table(labels_splinkdataframe_or_table_name, *, threshold_match_probability=0.5, match_weight_round_to_nearest=0.1, output_type='threshold_selection', add_metrics=[])</code>","text":"<p>Generate an accuracy chart or table from labelled (ground truth) data.</p> <p>The table of labels should be in the following format, and should be registered as a table with your database using <code>labels_table = linker.table_management.register_labels_table(my_df)</code></p> source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 <p>Note that <code>source_dataset</code> and <code>unique_id</code> should correspond to the values specified in the settings dict, and the <code>input_table_aliases</code> passed to the <code>linker</code> object.</p> <p>For <code>dedupe_only</code> links, the <code>source_dataset</code> columns can be ommitted.</p> <p>Parameters:</p> Name Type Description Default <code>labels_splinkdataframe_or_table_name</code> <code>str | SplinkDataFrame</code> <p>Name of table containing labels in the database</p> required <code>threshold_match_probability</code> <code>float</code> <p>Where the <code>clerical_match_score</code> provided by the user is a probability rather than binary, this value is used as the threshold to classify <code>clerical_match_score</code>s as binary matches or non matches. Defaults to 0.5.</p> <code>0.5</code> <code>match_weight_round_to_nearest</code> <code>float</code> <p>When provided, thresholds are rounded.  When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the chart. Defaults to None.</p> <code>0.1</code> <code>add_metrics</code> <code>list(str)</code> <p>Precision and recall metrics are always included. Where provided, <code>add_metrics</code> specifies additional metrics to show, with the following options:</p> <ul> <li><code>\"specificity\"</code>: specificity, selectivity, true negative rate (TNR)</li> <li><code>\"npv\"</code>: negative predictive value (NPV)</li> <li><code>\"accuracy\"</code>: overall accuracy (TP+TN)/(P+N)</li> <li><code>\"f1\"</code>/<code>\"f2\"</code>/<code>\"f0_5\"</code>: F-scores for \u03b2=1 (balanced), \u03b2=2 (emphasis on recall) and \u03b2=0.5 (emphasis on precision)</li> <li><code>\"p4\"</code> -  an extended F1 score with specificity and NPV included</li> <li><code>\"phi\"</code> - \u03c6 coefficient or Matthews correlation coefficient (MCC)</li> </ul> <code>[]</code> <p>Returns:</p> Type Description <code>Union[ChartReturnType, SplinkDataFrame]</code> <p>altair.Chart: An altair chart</p> <p>Examples:</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(\"ground_truth\", add_metrics=[\"f1\"])\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.prediction_errors_from_labels_column","title":"<code>prediction_errors_from_labels_column(label_colname, include_false_positives=True, include_false_negatives=True, threshold_match_probability=0.5)</code>","text":"<p>Generate a dataframe containing false positives and false negatives based on the comparison between the splink match probability and the labels column.  A label column is a column in the input dataset that contains the 'ground truth' cluster to which the record belongs</p> <p>Parameters:</p> Name Type Description Default <code>label_colname</code> <code>str</code> <p>Name of labels column in input data</p> required <code>include_false_positives</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>include_false_negatives</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>threshold_match_probability</code> <code>float</code> <p>Threshold above which a score is considered to be a match. Defaults to 0.5.</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>Table containing false positives and negatives</p> <p>Examples:</p> <pre><code>linker.evaluation.prediction_errors_from_labels_column(\n    \"ground_truth_cluster\",\n    include_false_negatives=True,\n    include_false_positives=False\n).as_pandas_dataframe()\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.unlinkables_chart","title":"<code>unlinkables_chart(x_col='match_weight', name_of_data_in_title=None, as_dict=False)</code>","text":"<p>Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters.</p> <p>Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match.</p> <p>Parameters:</p> Name Type Description Default <code>x_col</code> <code>str</code> <p>Column to use for the x-axis. Defaults to \"match_weight\".</p> <code>'match_weight'</code> <code>name_of_data_in_title</code> <code>str</code> <p>Name of the source dataset to use for the title of the output chart.</p> <code>None</code> <code>as_dict</code> <code>bool</code> <p>If True, return a dict version of the chart.</p> <code>False</code> <p>Returns:</p> Type Description <code>ChartReturnType</code> <p>altair.Chart: An altair chart</p> <p>Examples:</p> <p>After estimating the parameters of the model, run:</p> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/evaluation.html#splink.internals.linker_components.evaluation.LinkerEvalution.labelling_tool_for_specific_record","title":"<code>labelling_tool_for_specific_record(unique_id, source_dataset=None, out_path='labelling_tool.html', overwrite=False, match_weight_threshold=-4, view_in_jupyter=False, show_splink_predictions_in_interface=True)</code>","text":"<p>Create a standalone, offline labelling dashboard for a specific record as identified by its unique id</p> <p>Parameters:</p> Name Type Description Default <code>unique_id</code> <code>str</code> <p>The unique id of the record for which to create the labelling tool</p> required <code>source_dataset</code> <code>str</code> <p>If there are multiple datasets, to identify the record you must also specify the source_dataset. Defaults to None.</p> <code>None</code> <code>out_path</code> <code>str</code> <p>The output path for the labelling tool. Defaults to \"labelling_tool.html\".</p> <code>'labelling_tool.html'</code> <code>overwrite</code> <code>bool</code> <p>If true, overwrite files at the output path if they exist. Defaults to False.</p> <code>False</code> <code>match_weight_threshold</code> <code>int</code> <p>Include possible matches in the output which score above this threshold. Defaults to -4.</p> <code>-4</code> <code>view_in_jupyter</code> <code>bool</code> <p>If you're viewing in the Jupyter html viewer, set this to True to extract your labels. Defaults to False.</p> <code>False</code> <code>show_splink_predictions_in_interface</code> <code>bool</code> <p>Whether to show information about the Splink model's predictions that could potentially bias the decision of the clerical labeller. Defaults to True.</p> <code>True</code>","tags":["API","Clustering"]},{"location":"api_docs/exploratory.html","title":"Exploratory","text":"","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#documentation-forsplinkexploratory","title":"Documentation for<code>splink.exploratory</code>","text":"","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.completeness_chart","title":"<code>completeness_chart(table_or_tables, db_api, cols=None, table_names_for_chart=None)</code>","text":"<p>Generate a summary chart of data completeness (proportion of non-nulls) of columns in each of the input table or tables. By default, completeness is assessed for all columns in the input data.</p> <p>Parameters:</p> Name Type Description Default <code>table_or_tables</code> <code>Sequence[AcceptableInputTableType]</code> <p>A single table or a list of tables of data</p> required <code>db_api</code> <code>DatabaseAPISubClass</code> <p>The backend database API to use</p> required <code>cols</code> <code>List[str]</code> <p>List of column names to calculate completeness. If none, all columns will be computed. Default to None.</p> <code>None</code> <code>table_names_for_chart</code> <code>List[str]</code> <p>A list of names.  Must be the same length as table_or_tables.</p> <code>None</code>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.profile_columns","title":"<code>profile_columns(table_or_tables, db_api, column_expressions=None, top_n=10, bottom_n=10)</code>","text":"<p>Profiles the specified columns of the dataframe initiated with the linker.</p> <p>This can be computationally expensive if the dataframe is large.</p> <p>For the provided columns with column_expressions (or for all columns if left empty) calculate: - A distribution plot that shows the count of values at each percentile. - A top n chart, that produces a chart showing the count of the top n values within the column - A bottom n chart, that produces a chart showing the count of the bottom n values within the column</p> <p>This should be used to explore the dataframe, determine if columns have sufficient completeness for linking, analyse the cardinality of columns, and identify the need for standardisation within a given column.</p> <p>Args:</p> <pre><code>column_expressions (list, optional): A list of strings containing the\n    specified column names.\n    If left empty this will default to all columns.\ntop_n (int, optional): The number of top n values to plot.\nbottom_n (int, optional): The number of bottom n values to plot.\n</code></pre> <p>Returns:</p> Type Description <code>Optional[ChartReturnType]</code> <p>altair.Chart or dict: A visualization or JSON specification describing the</p> <code>Optional[ChartReturnType]</code> <p>profiling charts.</p> Note <ul> <li>The <code>linker</code> object should be an instance of the initiated linker.</li> <li>The provided <code>column_expressions</code> can be a list of column names to profile.     If left empty, all columns will be profiled.</li> <li>The <code>top_n</code> and <code>bottom_n</code> parameters determine the number of top and bottom     values to display in the respective charts.</li> </ul>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#documentation-forsplinkexploratorysimilarity_analysis","title":"Documentation for<code>splink.exploratory.similarity_analysis</code>","text":"","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.comparator_score","title":"<code>comparator_score(str1, str2, decimal_places=2)</code>","text":"<p>Helper function to give the similarity between two strings for the string comparators in splink.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nsa.comparator_score(\"Richard\", \"iRchard\")\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.comparator_score_chart","title":"<code>comparator_score_chart(list, col1, col2)</code>","text":"<p>Helper function returning a heatmap showing the sting similarity scores and string distances for a list of strings.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nlist = {\n        \"string1\": [\"Stephen\", \"Stephen\", \"Stephen\"],\n        \"string2\": [\"Stephen\", \"Steven\", \"Stephan\"],\n        }\n\nsa.comparator_score_chart(list, \"string1\", \"string2\")\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.comparator_score_df","title":"<code>comparator_score_df(list, col1, col2, decimal_places=2)</code>","text":"<p>Helper function returning a dataframe showing the string similarity scores and string distances for a list of strings.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nlist = {\n        \"string1\": [\"Stephen\", \"Stephen\",\"Stephen\"],\n        \"string2\": [\"Stephen\", \"Steven\", \"Stephan\"],\n        }\n\nsa.comparator_score_df(list, \"string1\", \"string2\")\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.comparator_score_threshold_chart","title":"<code>comparator_score_threshold_chart(list, col1, col2, similarity_threshold=None, distance_threshold=None)</code>","text":"<p>Helper function returning a heatmap showing the string similarity scores and string distances for a list of strings given a threshold.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nlist = {\n        \"string1\": [\"Stephen\", \"Stephen\",\"Stephen\"],\n        \"string2\": [\"Stephen\", \"Steven\", \"Stephan\"],\n        }\n\nsa.comparator_score_threshold_chart(data,\n                         \"string1\", \"string2\",\n                         similarity_threshold=0.8,\n                         distance_threshold=2)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.phonetic_match_chart","title":"<code>phonetic_match_chart(list, col1, col2)</code>","text":"<p>Helper function returning a heatmap showing the phonetic transform and matches for a list of strings given a threshold.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nlist = {\n        \"string1\": [\"Stephen\", \"Stephen\",\"Stephen\"],\n        \"string2\": [\"Stephen\", \"Steven\", \"Stephan\"],\n        }\n\nsa.comparator_score_threshold_chart(list,\n                         \"string1\", \"string2\",\n                         similarity_threshold=0.8,\n                         distance_threshold=2)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.phonetic_transform","title":"<code>phonetic_transform(string)</code>","text":"<p>Helper function to give the phonetic transformation of two strings with Soundex, Metaphone and Double Metaphone.</p> <p>Examples:</p> <pre><code>phonetic_transform(\"Richard\", \"iRchard\")\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/exploratory.html#splink.exploratory.similarity_analysis.phonetic_transform_df","title":"<code>phonetic_transform_df(list, col1, col2)</code>","text":"<p>Helper function returning a dataframe showing the phonetic transforms for a list of strings.</p> <p>Examples:</p> <pre><code>import splink.exploratory.similarity_analysis as sa\n\nlist = {\n        \"string1\": [\"Stephen\", \"Stephen\",\"Stephen\"],\n        \"string2\": [\"Stephen\", \"Steven\", \"Stephan\"],\n        }\n\nsa.phonetic_match_chart(list, \"string1\", \"string2\")\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/inference.html","title":"Inference","text":"","tags":["API","Inference"]},{"location":"api_docs/inference.html#methods-in-linkerinference","title":"Methods in Linker.inference","text":"<p>Use your Splink model to make predictions (perform inference). Accessed via <code>linker.inference</code>.</p>","tags":["API","Inference"]},{"location":"api_docs/inference.html#splink.internals.linker_components.inference.LinkerInference.deterministic_link","title":"<code>deterministic_link()</code>","text":"<p>Uses the blocking rules specified by <code>blocking_rules_to_generate_predictions</code> in your settings to generate pairwise record comparisons.</p> <p>For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links.</p> <p>Deterministic linkage, however, is likely to result in missed links (false negatives).</p> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>A SplinkDataFrame of the pairwise comparisons.</p> <pre><code>```py\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"dob\", \"first_name\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api=db_api)\nsplink_df = linker.inference.deterministic_link()\n```\n</code></pre>","tags":["API","Inference"]},{"location":"api_docs/inference.html#splink.internals.linker_components.inference.LinkerInference.predict","title":"<code>predict(threshold_match_probability=None, threshold_match_weight=None, materialise_after_computing_term_frequencies=True, materialise_blocked_pairs=True)</code>","text":"<p>Create a dataframe of scored pairwise comparisons using the parameters of the linkage model.</p> <p>Uses the blocking rules specified in the <code>blocking_rules_to_generate_predictions</code> key of the settings to generate the pairwise comparisons.</p> <p>Parameters:</p> Name Type Description Default <code>threshold_match_probability</code> <code>float</code> <p>If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None.</p> <code>None</code> <code>threshold_match_weight</code> <code>float</code> <p>If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None.</p> <code>None</code> <code>materialise_after_computing_term_frequencies</code> <code>bool</code> <p>If true, Splink will materialise the table containing the input nodes (rows) joined to any term frequencies which have been asked for in the settings object.  If False, this will be computed as part of a large CTE pipeline.   Defaults to True</p> <code>True</code> <code>materialise_blocked_pairs</code> <code>bool</code> <p>In the blocking phase, materialise the table of pairs of records that will be scored</p> <code>True</code> <p>Examples:</p> <pre><code>linker = linker(df, \"saved_settings.json\", db_api=db_api)\nsplink_df = linker.inference.predict(threshold_match_probability=0.95)\nsplink_df.as_pandas_dataframe(limit=5)\n</code></pre>","tags":["API","Inference"]},{"location":"api_docs/inference.html#splink.internals.linker_components.inference.LinkerInference.find_matches_to_new_records","title":"<code>find_matches_to_new_records(records_or_tablename, blocking_rules=[], match_weight_threshold=-4)</code>","text":"<p>Given one or more records, find records in the input dataset(s) which match and return in order of the Splink prediction score.</p> <p>This effectively provides a way of searching the input datasets for given record(s)</p> <p>Parameters:</p> Name Type Description Default <code>records_or_tablename</code> <code>List[dict]</code> <p>Input search record(s) as list of dict, or a table registered to the database.</p> required <code>blocking_rules</code> <code>list</code> <p>Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to [].</p> <code>[]</code> <code>match_weight_threshold</code> <code>int</code> <p>Return matches with a match weight above this threshold. Defaults to -4.</p> <code>-4</code> <p>Examples:</p> <pre><code>linker = Linker(df, \"saved_settings.json\", db_api=db_api)\n\n# You should load or pre-compute tf tables for any tables with\n# term frequency adjustments\nlinker.table_management.compute_tf_table(\"first_name\")\n# OR\nlinker.table_management.register_term_frequency_lookup(df, \"first_name\")\n\nrecord = {'unique_id': 1,\n    'first_name': \"John\",\n    'surname': \"Smith\",\n    'dob': \"1971-05-24\",\n    'city': \"London\",\n    'email': \"john@smith.net\"\n    }\ndf = linker.inference.find_matches_to_new_records(\n    [record], blocking_rules=[]\n)\n</code></pre> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>The pairwise comparisons.</p>","tags":["API","Inference"]},{"location":"api_docs/inference.html#splink.internals.linker_components.inference.LinkerInference.compare_two_records","title":"<code>compare_two_records(record_1, record_2, include_found_by_blocking_rules=False)</code>","text":"<p>Use the linkage model to compare and score a pairwise record comparison based on the two input records provided.</p> <p>If your inputs contain multiple rows, scores for the cartesian product of the two inputs will be returned.</p> <p>If your inputs contain hardcoded term frequency columns (e.g. a tf_first_name column), then these values will be used instead of any provided term frequency lookup tables. or term frequency values derived from the input data.</p> <p>Parameters:</p> Name Type Description Default <code>record_1</code> <code>dict</code> <p>dictionary representing the first record.  Columns names and data types must be the same as the columns in the settings object</p> required <code>record_2</code> <code>dict</code> <p>dictionary representing the second record.  Columns names and data types must be the same as the columns in the settings object</p> required <code>include_found_by_blocking_rules</code> <code>bool</code> <p>If True, outputs a column indicating whether the record pair would have been found by any of the blocking rules specified in settings.blocking_rules_to_generate_predictions. Defaults to False.</p> <code>False</code> <p>Examples:</p> <pre><code>linker = Linker(df, \"saved_settings.json\", db_api=db_api)\n\n# You should load or pre-compute tf tables for any tables with\n# term frequency adjustments\nlinker.table_management.compute_tf_table(\"first_name\")\n# OR\nlinker.table_management.register_term_frequency_lookup(df, \"first_name\")\n\nrecord_1 = {'unique_id': 1,\n    'first_name': \"John\",\n    'surname': \"Smith\",\n    'dob': \"1971-05-24\",\n    'city': \"London\",\n    'email': \"john@smith.net\"\n    }\n\nrecord_2 = {'unique_id': 1,\n    'first_name': \"Jon\",\n    'surname': \"Smith\",\n    'dob': \"1971-05-23\",\n    'city': \"London\",\n    'email': \"john@smith.net\"\n    }\ndf = linker.inference.compare_two_records(record_1, record_2)\n</code></pre> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>Pairwise comparison with scored prediction</p>","tags":["API","Inference"]},{"location":"api_docs/linker_clustering.html","title":"Clustering","text":"","tags":["API","Clustering"]},{"location":"api_docs/linker_clustering.html#methods-in-linkerclustering","title":"Methods in Linker.clustering","text":"<p>Cluster the results of the linkage model and analyse clusters, accessed via <code>linker.clustering</code>.</p>","tags":["API","Clustering"]},{"location":"api_docs/linker_clustering.html#splink.internals.linker_components.clustering.LinkerClustering.cluster_pairwise_predictions_at_threshold","title":"<code>cluster_pairwise_predictions_at_threshold(df_predict, threshold_match_probability=None, threshold_match_weight=None)</code>","text":"<p>Clusters the pairwise match predictions that result from <code>linker.inference.predict()</code> into groups of connected record using the connected components graph clustering algorithm</p> <p>Records with an estimated <code>match_probability</code> at or above <code>threshold_match_probability</code> (or records with a <code>match_weight</code> at or above <code>threshold_match_weight</code>) are considered to be a match (i.e. they represent the same entity).</p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The results of <code>linker.inference.predict()</code></p> required <code>threshold_match_probability</code> <code>float</code> <p>Pairwise comparisons with a <code>match_probability</code> at or above this threshold are matched</p> <code>None</code> <code>threshold_match_weight</code> <code>float</code> <p>Pairwise comparisons with a <code>match_weight</code> at or above this threshold are matched. Only one of threshold_match_probability or threshold_match_weight should be provided</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold.</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict(threshold_match_probability=0.5)\ndf_clustered = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict, threshold_match_probability=0.95\n)\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/linker_clustering.html#splink.internals.linker_components.clustering.LinkerClustering.cluster_using_single_best_links","title":"<code>cluster_using_single_best_links(df_predict, duplicate_free_datasets, threshold_match_probability=None, threshold_match_weight=None, ties_method='lowest_id')</code>","text":"<p>Clusters the pairwise match predictions that result from <code>linker.inference.predict()</code> into groups of connected records using a single best links method that restricts the clusters to have at most one record from each source dataset in the <code>duplicate_free_datasets</code> list.</p> <p>This method will include a record into a cluster if it is mutually the best match for the record and for the cluster, and if adding the record will not violate the criteria of having at most one record from each of the <code>duplicate_free_datasets</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The results of <code>linker.inference.predict()</code></p> required <code>duplicate_free_datasets</code> <code>List[str]</code> <p>(List[str]): The source datasets which should be treated as having no duplicates. Clusters will not form with more than one record from each of these datasets. This can be a subset of all of the source datasets in the input data.</p> required <code>threshold_match_probability</code> <code>float</code> <p>Pairwise comparisons with a <code>match_probability</code> at or above this threshold are matched</p> <code>None</code> <code>threshold_match_weight</code> <code>float</code> <p>Pairwise comparisons with a <code>match_weight</code> at or above this threshold are matched. Only one of threshold_match_probability or threshold_match_weight should be provided</p> <code>None</code> <code>ties_method</code> <code>str</code> <p>How the clustering method should deal with ties. There are two options: 'drop' and 'lowest_id'. After linking datasets A and B, if record A1 is tied between records B1 and B2 from dataset B, then the 'drop' option will drop both links, whereas the 'lowest_id' option will keep the link to record B1. If the links A1 to B1 and A1 to C1 are tied where each record is from a different source dataset then both links will be kept, even with the 'drop' option.</p> <code>'lowest_id'</code> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict(threshold_match_probability=0.5)\ndf_clustered = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict,\n    duplicate_free_datasets=[\"A\", \"B\"],\n    threshold_match_probability=0.95\n)\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/linker_clustering.html#splink.internals.linker_components.clustering.LinkerClustering.compute_graph_metrics","title":"<code>compute_graph_metrics(df_predict, df_clustered, *, threshold_match_probability=None)</code>","text":"<p>Generates tables containing graph metrics (for nodes, edges and clusters), and returns a data class of Splink dataframes</p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The results of <code>linker.inference.predict()</code></p> required <code>df_clustered</code> <code>SplinkDataFrame</code> <p>The outputs of <code>linker.clustering.cluster_pairwise_predictions_at_threshold()</code></p> required <code>threshold_match_probability</code> <code>float</code> <p>Filter the pairwise match predictions to include only pairwise comparisons with a match_probability at or above this threshold. If not provided, the value will be taken from metadata on <code>df_clustered</code>. If no such metadata is available, this value must be provided.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GraphMetricsResult</code> <code>GraphMetricsResults</code> <p>A data class containing SplinkDataFrames</p> <code>GraphMetricsResults</code> <p>of cluster IDs and selected node, edge or cluster metrics. attribute \"nodes\" for nodes metrics table attribute \"edges\" for edge metrics table attribute \"clusters\" for cluster metrics table</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict(threshold_match_probability=0.5)\ndf_clustered = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict, threshold_match_probability=0.95\n)\ngraph_metrics = linker.clustering.compute_graph_metrics(\n    df_predict, df_clustered, threshold_match_probability=0.95\n)\n\nnode_metrics = graph_metrics.nodes.as_pandas_dataframe()\nedge_metrics = graph_metrics.edges.as_pandas_dataframe()\ncluster_metrics = graph_metrics.clusters.as_pandas_dataframe()\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/misc.html","title":"Miscellaneous functions","text":"","tags":["API","Misc"]},{"location":"api_docs/misc.html#methods-in-linkermisc","title":"Methods in Linker.misc","text":"<p>Miscellaneous methods on the linker that don't fit into other categories. Accessed via <code>linker.misc</code>.</p>","tags":["API","Misc"]},{"location":"api_docs/misc.html#splink.internals.linker_components.misc.LinkerMisc.save_model_to_json","title":"<code>save_model_to_json(out_path=None, overwrite=False)</code>","text":"<p>Save the configuration and parameters of the linkage model to a <code>.json</code> file.</p> <p>The model can later be loaded into a new linker using `Linker(df, settings=\"path/to/model.json\", db_api=db_api).</p> <p>The settings dict is also returned in case you want to save it a different way.</p> <p>Examples:</p> <pre><code>linker.misc.save_model_to_json(\"my_settings.json\", overwrite=True)\n</code></pre> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>The settings as a dictionary.</p>","tags":["API","Misc"]},{"location":"api_docs/misc.html#splink.internals.linker_components.misc.LinkerMisc.query_sql","title":"<code>query_sql(sql, output_type='pandas')</code>","text":"<p>Run a SQL query against your backend database and return the resulting output.</p> <p>Examples:</p> <pre><code>linker = Linker(df, settings, db_api)\ndf_predict = linker.inference.predict()\nlinker.misc.query_sql(f\"select * from {df_predict.physical_name} limit 10\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL to be queried.</p> required <code>output_type</code> <code>str</code> <p>One of splink_df/splinkdf or pandas. This determines the type of table that your results are output in.</p> <code>'pandas'</code>","tags":["API","Misc"]},{"location":"api_docs/settings_dict_guide.html","title":"Settings Dict","text":"","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#guide-to-splink-settings","title":"Guide to Splink settings","text":"<p>This document enumerates all the settings and configuration options available when developing your data linkage model.</p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#link_type","title":"<code>link_type</code>","text":"<p>The type of data linking task.  Required.</p> <ul> <li> <p>When <code>dedupe_only</code>, <code>splink</code> find duplicates.  User expected to provide a single input dataset.</p> </li> <li> <p>When <code>link_and_dedupe</code>, <code>splink</code> finds links within and between input datasets.  User is expected to provide two or more input datasets.</p> </li> <li> <p>When <code>link_only</code>,  <code>splink</code> finds links between datasets, but does not attempt to deduplicate the datasets (it does not try and find links within each input dataset.) User is expected to provide two or more input datasets.</p> </li> </ul> <p>Examples: <code>['dedupe_only', 'link_only', 'link_and_dedupe']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#probability_two_random_records_match","title":"<code>probability_two_random_records_match</code>","text":"<p>The probability that two records chosen at random (with no blocking) are a match.  For example, if there are a million input records and each has on average one match, then this value should be 1/1,000,000.</p> <p>If you estimate parameters using expectation maximisation (EM), this provides an initial value (prior) from which the EM algorithm will start iterating.  EM will then estimate the true value of this parameter.</p> <p>Default value: <code>0.0001</code></p> <p>Examples: <code>[1e-05, 0.006]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#em_convergence","title":"<code>em_convergence</code>","text":"<p>Convergence tolerance for the Expectation Maximisation algorithm</p> <p>The algorithm will stop converging when the maximum of the change in model parameters between iterations is below this value</p> <p>Default value: <code>0.0001</code></p> <p>Examples: <code>[0.0001, 1e-05, 1e-06]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#max_iterations","title":"<code>max_iterations</code>","text":"<p>The maximum number of Expectation Maximisation iterations to run (even if convergence has not been reached)</p> <p>Default value: <code>25</code></p> <p>Examples: <code>[20, 150]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#unique_id_column_name","title":"<code>unique_id_column_name</code>","text":"<p>Splink requires that the input dataset has a column that uniquely identifies each record.  <code>unique_id_column_name</code> is the name of the column in the input dataset representing this unique id</p> <p>For linking tasks, ids must be unique within each dataset being linked, and do not need to be globally unique across input datasets</p> <p>Default value: <code>unique_id</code></p> <p>Examples: <code>['unique_id', 'id', 'pk']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#source_dataset_column_name","title":"<code>source_dataset_column_name</code>","text":"<p>The name of the column in the input dataset representing the source dataset</p> <p>Where we are linking datasets, we can't guarantee that the unique id column is globally unique across datasets, so we combine it with a source_dataset column.  Usually, this is created by Splink for the user</p> <p>Default value: <code>source_dataset</code></p> <p>Examples: <code>['source_dataset', 'dataset_name']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#retain_matching_columns","title":"<code>retain_matching_columns</code>","text":"<p>If set to true, each column used by the <code>comparisons</code> SQL expressions will be retained in output datasets</p> <p>This is helpful so that the user can inspect matches, but once the comparison vector (gamma) columns are computed, this information is not actually needed by the algorithm.  The algorithm will run faster and use less resources if this is set to false.</p> <p>Default value: <code>True</code></p> <p>Examples: <code>[False, True]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#retain_intermediate_calculation_columns","title":"<code>retain_intermediate_calculation_columns</code>","text":"<p>Retain intermediate calculation columns, such as the Bayes factors associated with each column in <code>comparisons</code></p> <p>The algorithm will run faster and use less resources if this is set to false.</p> <p>Default value: <code>False</code></p> <p>Examples: <code>[False, True]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#comparisons","title":"comparisons","text":"<p>A list specifying how records should be compared for probabilistic matching.  Each element is a dictionary</p> Settings keys nested within each member of <code>comparisons</code>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#output_column_name","title":"output_column_name","text":"<p>The name used to refer to this comparison in the output dataset.  By default, Splink will set this to the name(s) of any input columns used in the comparison.  This key is most useful to give a clearer description to comparisons that use multiple input columns.  e.g. a location column that uses postcode and town may be named location</p> <p>For a comparison column that uses a single input column, e.g. first_name, this will be set first_name. For comparison columns that use multiple columns, if left blank, this will be set to the concatenation of columns used.</p> <p>Examples: <code>['first_name', 'surname']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#comparison_description","title":"comparison_description","text":"<p>An optional label to describe this comparison, to be used in charting outputs.</p> <p>Examples: <code>['First name exact match', 'Surname with middle levenshtein level']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#comparison_levels","title":"comparison_levels","text":"<p>Comparison levels specify how input values should be compared.  Each level corresponds to an assessment of similarity, such as exact match, Jaro-Winkler match, one side of the match being null, etc</p> <p>Each comparison level represents a branch of a SQL case expression. They are specified in order of evaluation, each with a <code>sql_condition</code> that represents the branch of a case expression</p> <p>Example: </p><pre><code>[{\n    \"sql_condition\": \"first_name_l IS NULL OR first_name_r IS NULL\",\n    \"label_for_charts\": \"null\",\n    \"null_level\": True\n},\n{\n    \"sql_condition\": \"first_name_l = first_name_r\",\n    \"label_for_charts\": \"exact_match\",\n    \"tf_adjustment_column\": \"first_name\"\n},\n{\n    \"sql_condition\": \"ELSE\",\n    \"label_for_charts\": \"else\"\n}]\n</code></pre> Settings keys nested within each member of <code>comparison_levels</code>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#sql_condition","title":"<code>sql_condition</code>","text":"<p>A branch of a SQL case expression without WHEN and THEN e.g. <code>jaro_winkler_sim(surname_l, surname_r) &gt; 0.88</code></p> <p>Examples: <code>['forename_l = forename_r', 'jaro_winkler_sim(surname_l, surname_r) &gt; 0.88']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#label_for_charts","title":"label_for_charts","text":"<p>A label for this comparison level, which will appear on charts as a reminder of what the level represents</p> <p>Examples: <code>['exact', 'postcode exact']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#u_probability","title":"u_probability","text":"<p>the u probability for this comparison level - i.e. the proportion of records that match this level amongst truly non-matching records</p> <p>Examples: <code>[0.9]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#m_probability","title":"m_probability","text":"<p>the m probability for this comparison level - i.e. the proportion of records that match this level amongst truly matching records</p> <p>Examples: <code>[0.1]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#is_null_level","title":"is_null_level","text":"<p>If true, m and u values will not be estimated and instead the match weight will be zero for this column.  See treatment of nulls here on page 356, quote '. Under this MAR assumption, we can simply ignore missing data.': https://imai.fas.harvard.edu/research/files/linkage.pdf</p> <p>Default value: <code>False</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#tf_adjustment_column","title":"tf_adjustment_column","text":"<p>Make term frequency adjustments for this comparison level using this input column</p> <p>Default value: <code>None</code></p> <p>Examples: <code>['first_name', 'postcode']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#tf_adjustment_weight","title":"tf_adjustment_weight","text":"<p>Make term frequency adjustments using this weight. A weight of 1.0 is a full adjustment.  A weight of 0.0 is no adjustment.  A weight of 0.5 is a half adjustment</p> <p>Default value: <code>1.0</code></p> <p>Examples: <code>['first_name', 'postcode']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#tf_minimum_u_value","title":"tf_minimum_u_value","text":"<p>Where the term frequency adjustment implies a u value below this value, use this minimum value instead</p> <p>This prevents excessive weight being assigned to very unusual terms, such as a collision on a typo</p> <p>Default value: <code>0.0</code></p> <p>Examples: <code>[0.001, 1e-09]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#blocking_rules_to_generate_predictions","title":"<code>blocking_rules_to_generate_predictions</code>","text":"<p>A list of one or more blocking rules to apply. A Cartesian join is applied if <code>blocking_rules_to_generate_predictions</code> is empty or not supplied.</p> <p>Each rule is a SQL expression representing the blocking rule, which will be used to create a join.  The left table is aliased with <code>l</code> and the right table is aliased with <code>r</code>. For example, if you want to block on a <code>first_name</code> column, the blocking rule would be</p> <p><code>l.first_name = r.first_name</code>.</p> <p>To block on first name and the first letter of surname, it would be</p> <p><code>l.first_name = r.first_name and substr(l.surname,1,1) = substr(r.surname,1,1)</code>.</p> <p>Note that Splink deduplicates the comparisons generated by the blocking rules.</p> <p>If empty or not supplied, all comparisons between the input dataset(s) will be generated and blocking will not be used. For large input datasets, this will generally be computationally intractable because it will generate comparisons equal to the number of rows squared.</p> <p>Default value: <code>[]</code></p> <p>Examples: <code>[['l.first_name = r.first_name AND l.surname = r.surname', 'l.dob = r.dob']]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#additional_columns_to_retain","title":"<code>additional_columns_to_retain</code>","text":"<p>A list of columns not being used in the probabilistic matching comparisons that you want to include in your results.</p> <p>By default, Splink drops columns which are not used by any comparisons.  This gives you the option to retain columns which are not used by the model.  A common example is if the user has labelled data (training data) and wishes to retain the labels in the outputs</p> <p>Default value: <code>[]</code></p> <p>Examples: <code>[['cluster', 'col_2'], ['other_information']]</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#bayes_factor_column_prefix","title":"<code>bayes_factor_column_prefix</code>","text":"<p>The prefix to use for the columns that will be created to store the Bayes factors</p> <p>Default value: <code>bf_</code></p> <p>Examples: <code>['bf_', '__bf__']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#term_frequency_adjustment_column_prefix","title":"<code>term_frequency_adjustment_column_prefix</code>","text":"<p>The prefix to use for the columns that will be created to store the term frequency adjustments</p> <p>Default value: <code>tf_</code></p> <p>Examples: <code>['tf_', '__tf__']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#comparison_vector_value_column_prefix","title":"<code>comparison_vector_value_column_prefix</code>","text":"<p>The prefix to use for the columns that will be created to store the comparison vector values</p> <p>Default value: <code>gamma_</code></p> <p>Examples: <code>['gamma_', '__gamma__']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/settings_dict_guide.html#sql_dialect","title":"<code>sql_dialect</code>","text":"<p>The SQL dialect in which <code>sql_conditions</code> are written.  Must be a valid SQLGlot dialect</p> <p>Default value: <code>None</code></p> <p>Examples: <code>['spark', 'duckdb', 'presto', 'sqlite']</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Expectation Maximisation","Comparisons","Blocking Rules"]},{"location":"api_docs/splink_dataframe.html","title":"SplinkDataFrame","text":"","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#documentation-forsplinkdataframe","title":"Documentation for<code>SplinkDataFrame</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstraction over dataframe to handle basic operations like retrieving data and retrieving column names, which need different implementations depending on whether it's a spark dataframe, sqlite table etc. Uses methods like <code>as_pandas_dataframe()</code> and <code>as_record_dict()</code> to retrieve data</p>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.as_duckdbpyrelation","title":"<code>as_duckdbpyrelation(limit=None)</code>","text":"<p>Return the dataframe as a duckdbpyrelation.  Only available when using the DuckDB backend.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows</p> <code>None</code> <p>Returns:</p> Type Description <code>DuckDBPyRelation</code> <p>duckdb.DuckDBPyRelation: A DuckDBPyRelation object</p>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.as_pandas_dataframe","title":"<code>as_pandas_dataframe(limit=None)</code>","text":"<p>Return the dataframe as a pandas dataframe.</p> <p>This can be computationally expensive if the dataframe is large.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows</p> <code>None</code> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict()\ndf_ten_edges = df_predict.as_pandas_dataframe(10)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.as_record_dict","title":"<code>as_record_dict(limit=None)</code>","text":"<p>Return the dataframe as a list of record dictionaries.</p> <p>This can be computationally expensive if the dataframe is large.</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict()\nten_edges = df_predict.as_record_dict(10)\n</code></pre> <p>Returns:</p> Name Type Description <code>list</code> <code>list[dict[str, Any]]</code> <p>a list of records, each of which is a dictionary</p>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.as_spark_dataframe","title":"<code>as_spark_dataframe()</code>","text":"<p>Return the dataframe as a spark dataframe.  Only available when using the Spark backend.</p> <p>Returns:</p> Type Description <code>'SparkDataFrame'</code> <p>spark.DataFrame: A Spark DataFrame</p>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.drop_table_from_database_and_remove_from_cache","title":"<code>drop_table_from_database_and_remove_from_cache(force_non_splink_table=False)</code>","text":"<p>Drops the table from the underlying database, and removes it from the (linker) cache.</p> <p>By default this will fail if the table is not one created by Splink, but this check can be overriden</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict()\ndf_predict.drop_table_from_database_and_remove_from_cache()\n# predictions table no longer in the database / cache\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.to_csv","title":"<code>to_csv(filepath, overwrite=False)</code>","text":"<p>Save the dataframe in csv format.</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict()\ndf_predict.to_csv(\"model_predictions.csv\", overwrite=True)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/splink_dataframe.html#splink.internals.splink_dataframe.SplinkDataFrame.to_parquet","title":"<code>to_parquet(filepath, overwrite=False)</code>","text":"<p>Save the dataframe in parquet format.</p> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict()\ndf_predict.to_parquet(\"model_predictions.parquet\", overwrite=True)\n</code></pre>","tags":["API","comparisons"]},{"location":"api_docs/table_management.html","title":"Table Management","text":"","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#methods-in-linkertable_management","title":"Methods in Linker.table_management","text":"<p>Register Splink tables against your database backend and manage the Splink cache. Accessed via <code>linker.table_management</code>.</p>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.compute_tf_table","title":"<code>compute_tf_table(column_name)</code>","text":"<p>Compute a term frequency table for a given column and persist to the database</p> <p>This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time</p> <p>Examples:</p> <pre><code>Real time linkage\n```py\nlinker = Linker(df, settings=\"saved_settings.json\", db_api=db_api)\nlinker.table_management.compute_tf_table(\"surname\")\nlinker.inference.compare_two_records(record_left, record_right)\n```\nPre-computed term frequency tables\n```py\nlinker = Linker(df, db_api)\ndf_first_name_tf = linker.table_management.compute_tf_table(\"first_name\")\ndf_first_name_tf.write.parquet(\"folder/first_name_tf\")\n&gt;&gt;&gt;\n# On subsequent data linking job, read this table rather than recompute\ndf_first_name_tf = pd.read_parquet(\"folder/first_name_tf\")\nlinker.table_management.register_term_frequency_lookup(\n    df_first_name_tf, \"first_name\"\n)\n\n```\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>The column name in the input table</p> required <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>The resultant table as a splink data frame</p>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.invalidate_cache","title":"<code>invalidate_cache()</code>","text":"<p>Invalidate the Splink cache.  Any previously-computed tables will be recomputed. This is useful, for example, if the input data tables have changed.</p>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.register_table_input_nodes_concat_with_tf","title":"<code>register_table_input_nodes_concat_with_tf(input_data, overwrite=False)</code>","text":"<p>Register a pre-computed version of the input_nodes_concat_with_tf table that you want to re-use e.g. that you created in a previous run.</p> <p>This method allows you to register this table in the Splink cache so it will be used rather than Splink computing this table anew.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>AcceptableInputTableType</code> <p>The data you wish to register. This can be either a dictionary, pandas dataframe, pyarrow table or a spark dataframe.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the table in the underlying database if it exists.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>An abstraction representing the table created by the sql pipeline</p>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.register_table_predict","title":"<code>register_table_predict(input_data, overwrite=False)</code>","text":"<p>Register a pre-computed version of the prediction table for use in Splink.</p> <p>This method allows you to register a pre-computed prediction table in the Splink cache so it will be used rather than Splink computing the table anew.</p> <p>Examples:</p> <pre><code>predict_df = pd.read_parquet(\"path/to/predict_df.parquet\")\npredict_as_splinkdataframe = linker.table_management.register_table_predict(predict_df)\nclusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    predict_as_splinkdataframe, threshold_match_probability=0.75\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>AcceptableInputTableType</code> <p>The data you wish to register. This can be either a dictionary, pandas dataframe, pyarrow table, or a spark dataframe.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the table in the underlying database if it exists. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <p>An abstraction representing the table created by the SQL pipeline.</p>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.register_term_frequency_lookup","title":"<code>register_term_frequency_lookup(input_data, col_name, overwrite=False)</code>","text":"<p>Register a pre-computed term frequency lookup table for a given column.</p> <p>This method allows you to register a term frequency table in the Splink cache for a specific column. This table will then be used during linkage rather than computing the term frequency table anew from your input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>AcceptableInputTableType</code> <p>The data representing the term frequency table. This can be either a dictionary, pandas dataframe, pyarrow table, or a spark dataframe.</p> required <code>col_name</code> <code>str</code> <p>The name of the column for which the term frequency lookup table is being registered.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the table in the underlying database if it exists. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <p>An abstraction representing the registered term</p> <p>frequency table.</p> <p>Examples:</p> <pre><code>tf_table = [\n    {\"first_name\": \"theodore\", \"tf_first_name\": 0.012},\n    {\"first_name\": \"alfie\", \"tf_first_name\": 0.013},\n]\ntf_df = pd.DataFrame(tf_table)\nlinker.table_management.register_term_frequency_lookup(\n    tf_df,\n    \"first_name\"\n)\n</code></pre>","tags":["API","Clustering"]},{"location":"api_docs/table_management.html#splink.internals.linker_components.table_management.LinkerTableManagement.register_table","title":"<code>register_table(input_table, table_name, overwrite=False)</code>","text":"<p>Register a table to your backend database, to be used in one of the splink methods, or simply to allow querying.</p> <p>Tables can be of type: dictionary, record level dictionary, pandas dataframe, pyarrow table and in the spark case, a spark df.</p> <p>Examples:</p> <pre><code>test_dict = {\"a\": [666,777,888],\"b\": [4,5,6]}\nlinker.table_management.register_table(test_dict, \"test_dict\")\nlinker.misc.query_sql(\"select * from test_dict\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>input_table</code> <code>AcceptableInputTableType</code> <p>The data you wish to register. This can be either a dictionary, pandas dataframe, pyarrow table or a spark dataframe.</p> required <code>table_name</code> <code>str</code> <p>The name you wish to assign to the table.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the table in the underlying database if it exists</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SplinkDataFrame</code> <code>SplinkDataFrame</code> <p>An abstraction representing the table created by the sql pipeline</p>","tags":["API","Clustering"]},{"location":"api_docs/training.html","title":"Training","text":"","tags":["API","Training"]},{"location":"api_docs/training.html#methods-in-linkertraining","title":"Methods in Linker.training","text":"<p>Estimate the parameters of the linkage model, accessed via <code>linker.training</code>.</p>","tags":["API","Training"]},{"location":"api_docs/training.html#splink.internals.linker_components.training.LinkerTraining.estimate_probability_two_random_records_match","title":"<code>estimate_probability_two_random_records_match(deterministic_matching_rules, recall, max_rows_limit=int(1000000000.0))</code>","text":"<p>Estimate the model parameter <code>probability_two_random_records_match</code> using a direct estimation approach.</p> <p>This method counts the number of matches found using deterministic rules and divides by the total number of possible record comparisons. The recall of the deterministic rules is used to adjust this proportion up to reflect missed matches, providing an estimate of the probability that two random records from the input data are a match.</p> <p>Note that if more than one deterministic rule is provided, any duplicate pairs are automatically removed, so you do not need to worry about double counting.</p> <p>See here for discussion of methodology.</p> <p>Parameters:</p> Name Type Description Default <code>deterministic_matching_rules</code> <code>list</code> <p>A list of deterministic matching rules designed to admit very few (preferably no) false positives.</p> required <code>recall</code> <code>float</code> <p>An estimate of the recall the deterministic matching rules will achieve, i.e., the proportion of all true matches these rules will recover.</p> required <code>max_rows_limit</code> <code>int</code> <p>Maximum number of rows to consider during estimation. Defaults to 1e9.</p> <code>int(1000000000.0)</code> <p>Examples:</p> <pre><code>deterministic_rules = [\n    block_on(\"forename\", \"dob\"),\n    \"l.forename = r.forename and levenshtein(r.surname, l.surname) &lt;= 2\",\n    block_on(\"email\")\n]\nlinker.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.8\n)\n</code></pre>","tags":["API","Training"]},{"location":"api_docs/training.html#splink.internals.linker_components.training.LinkerTraining.estimate_u_using_random_sampling","title":"<code>estimate_u_using_random_sampling(max_pairs=1000000.0, seed=None)</code>","text":"<p>Estimate the u parameters of the linkage model using random sampling.</p> <p>The u parameters estimate the proportion of record comparisons that fall into each comparison level amongst truly non-matching records.</p> <p>This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true.</p> <p>The results of estimate_u_using_random_sampling, and therefore an entire splink model, can be made reproducible by setting the seed parameter. Setting the seed will have performance implications as additional processing is required.</p> <p>Parameters:</p> Name Type Description Default <code>max_pairs</code> <code>int</code> <p>The maximum number of pairwise record comparisons to sample. Larger will give more accurate estimates but lead to longer runtimes.  In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated.</p> <code>1000000.0</code> <code>seed</code> <code>int</code> <p>Seed for random sampling. Assign to get reproducible u probabilities. Note, seed for random sampling is only supported for DuckDB and Spark, for Athena and SQLite set to None.</p> <code>None</code> <p>Examples:</p> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e8)\n</code></pre> <p>Returns:</p> Name Type Description <code>Nothing</code> <code>None</code> <p>Updates the estimated u parameters within the linker object and returns nothing.</p>","tags":["API","Training"]},{"location":"api_docs/training.html#splink.internals.linker_components.training.LinkerTraining.estimate_parameters_using_expectation_maximisation","title":"<code>estimate_parameters_using_expectation_maximisation(blocking_rule, estimate_without_term_frequencies=False, fix_probability_two_random_records_match=False, fix_m_probabilities=False, fix_u_probabilities=True, populate_probability_two_random_records_match_from_trained_values=False)</code>","text":"<p>Estimate the parameters of the linkage model using expectation maximisation.</p> <p>By default, the m probabilities are estimated, but not the u probabilities, because good estimates for the u probabilities can be obtained from <code>linker.training.estimate_u_using_random_sampling()</code>.  You can change this by setting <code>fix_u_probabilities</code> to False.</p> <p>The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the blocked comparisons.</p> <p>By default, m parameters are estimated for all comparisons except those which are included in the blocking rule.</p> <p>For example, if the blocking rule is <code>block_on(\"first_name\")</code>, then parameter estimates will be made for all comparison except those which use <code>first_name</code> in their sql_condition</p> <p>By default, the probability two random records match is allowed to vary during EM estimation, but is not saved back to the model.  See this PR for the rationale.</p> <p>Parameters:</p> Name Type Description Default <code>blocking_rule</code> <code>BlockingRuleCreator | str</code> <p>The blocking rule used to generate pairwise record comparisons.</p> required <code>estimate_without_term_frequencies</code> <code>bool</code> <p>If True, the iterations of the EM algorithm ignore any term frequency adjustments and only depend on the comparison vectors. This allows the EM algorithm to run much faster, but the estimation of the parameters will change slightly.</p> <code>False</code> <code>fix_probability_two_random_records_match</code> <code>bool</code> <p>If True, do not update the probability two random records match after each iteration. Defaults to False.</p> <code>False</code> <code>fix_m_probabilities</code> <code>bool</code> <p>If True, do not update the m probabilities after each iteration. Defaults to False.</p> <code>False</code> <code>fix_u_probabilities</code> <code>bool</code> <p>If True, do not update the u probabilities after each iteration. Defaults to True.</p> <code>True</code> <code>populate_prob...</code> <code>(bool, optional)</code> <p>The full name of this parameter is populate_probability_two_random_records_match_from_trained_values. If True, derive this parameter from the blocked value. Defaults to False.</p> required <p>Examples:</p> <pre><code>br_training = block_on(\"first_name\", \"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    br_training\n)\n</code></pre> <p>Returns:</p> Name Type Description <code>EMTrainingSession</code> <code>EMTrainingSession</code> <p>An object containing information about the training session such as how parameters changed during the iteration history</p>","tags":["API","Training"]},{"location":"api_docs/training.html#splink.internals.linker_components.training.LinkerTraining.estimate_m_from_pairwise_labels","title":"<code>estimate_m_from_pairwise_labels(labels_splinkdataframe_or_table_name)</code>","text":"<p>Estimate the m probabilities of the linkage model from a dataframe of pairwise labels.</p> <p>The table of labels should be in the following format, and should be registered with your database:</p> source_dataset_l unique_id_l source_dataset_r unique_id_r df_1 1 df_2 2 df_1 1 df_2 3 <p>Note that <code>source_dataset</code> and <code>unique_id</code> should correspond to the values specified in the settings dict, and the <code>input_table_aliases</code> passed to the <code>linker</code> object. Note that at the moment, this method does not respect values in a <code>clerical_match_score</code> column.  If provided, these are ignored and it is assumed that every row in the table of labels is a score of 1, i.e. a perfect match.</p> <p>Parameters:</p> Name Type Description Default <code>labels_splinkdataframe_or_table_name</code> <code>str</code> <p>Name of table containing labels in the database or SplinkDataframe</p> required <p>Examples:</p> <pre><code>pairwise_labels = pd.read_csv(\"./data/pairwise_labels_to_estimate_m.csv\")\n\nlinker.table_management.register_table(\n    pairwise_labels, \"labels\", overwrite=True\n)\n\nlinker.training.estimate_m_from_pairwise_labels(\"labels\")\n</code></pre>","tags":["API","Training"]},{"location":"api_docs/training.html#splink.internals.linker_components.training.LinkerTraining.estimate_m_from_label_column","title":"<code>estimate_m_from_label_column(label_colname)</code>","text":"<p>Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s).</p> <p>The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records.</p> <p>The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches.</p> <p>For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model.</p> <p>Note that this column does not need to be fully populated.  A common case is where a unique identifier such as social security number is only partially populated.</p> <p>Parameters:</p> Name Type Description Default <code>label_colname</code> <code>str</code> <p>The name of the column containing the ground truth label in the input data.</p> required <p>Examples:</p> <pre><code>linker.training.estimate_m_from_label_column(\"social_security_number\")\n</code></pre> <p>Returns:</p> Name Type Description <code>Nothing</code> <code>None</code> <p>Updates the estimated m parameters within the linker object.</p>","tags":["API","Training"]},{"location":"api_docs/visualisations.html","title":"Visualisations","text":"","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#methods-in-linkervisualisations","title":"Methods in Linker.visualisations","text":"<p>Visualisations to help you understand and diagnose your linkage model. Accessed via <code>linker.visualisations</code>.</p> <p>Most of the visualisations return an altair.Chart object, meaning it can be saved an manipulated using Altair.</p> <p>For example:</p> <pre><code>altair_chart = linker.visualisations.match_weights_chart()\n\n# Save to various formats\naltair_chart.save(\"mychart.png\")\naltair_chart.save(\"mychart.html\")\naltair_chart.save(\"mychart.svg\")\naltair_chart.save(\"mychart.json\")\n\n# Get chart spec as dict\naltair_chart.to_dict()\n</code></pre> <p>To save the chart as a self-contained html file with all scripts inlined so it can be viewed offline:</p> <pre><code>from splink.internals.charts import save_offline_chart\nc = linker.visualisations.match_weights_chart()\nsave_offline_chart(c.to_dict(), \"test_chart.html\")\n</code></pre> <p>View resultant html file in Jupyter (or just load it in your browser)</p> <pre><code>from IPython.display import IFrame\nIFrame(src=\"./test_chart.html\", width=1000, height=500)\n</code></pre>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.match_weights_chart","title":"<code>match_weights_chart(as_dict=False)</code>","text":"<p>Display a chart of the (partial) match weights of the linkage model</p> <p>Parameters:</p> Name Type Description Default <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Examples:</p> <pre><code>altair_chart = linker.visualisations.match_weights_chart()\naltair_chart.save(\"mychart.png\")\n</code></pre>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.m_u_parameters_chart","title":"<code>m_u_parameters_chart(as_dict=False)</code>","text":"<p>Display a chart of the m and u parameters of the linkage model</p> <p>Parameters:</p> Name Type Description Default <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Examples:</p> <pre><code>altair_chart = linker.visualisations.m_u_parameters_chart()\naltair_chart.save(\"mychart.png\")\n</code></pre> <p>Returns:</p> Name Type Description <code>altair_chart</code> <code>ChartReturnType</code> <p>An altair chart</p>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.match_weights_histogram","title":"<code>match_weights_histogram(df_predict, target_bins=30, width=600, height=250, as_dict=False)</code>","text":"<p>Generate a histogram that shows the distribution of match weights in <code>df_predict</code></p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>Output of <code>linker.inference.predict()</code></p> required <code>target_bins</code> <code>int</code> <p>Target number of bins in histogram. Defaults to 30.</p> <code>30</code> <code>width</code> <code>int</code> <p>Width of output. Defaults to 600.</p> <code>600</code> <code>height</code> <code>int</code> <p>Height of output chart. Defaults to 250.</p> <code>250</code> <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Examples:</p> <pre><code>df_predict = linker.inference.predict(threshold_match_weight=-2)\nlinker.visualisations.match_weights_histogram(df_predict)\n</code></pre>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.parameter_estimate_comparisons_chart","title":"<code>parameter_estimate_comparisons_chart(include_m=True, include_u=False, as_dict=False)</code>","text":"<p>Show a chart that shows how parameter estimates have differed across the different estimation methods you have used.</p> <p>For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates</p> <p>Parameters:</p> Name Type Description Default <code>include_m</code> <code>bool</code> <p>Show different estimates of m values. Defaults to True.</p> <code>True</code> <code>include_u</code> <code>bool</code> <p>Show different estimates of u values. Defaults to False.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Examples:</p> <pre><code>linker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule=block_on(\"first_name\"),\n)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule=block_on(\"surname\"),\n)\n\nlinker.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <p>Returns:</p> Name Type Description <code>altair_chart</code> <code>ChartReturnType</code> <p>An Altair chart</p>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.tf_adjustment_chart","title":"<code>tf_adjustment_chart(output_column_name, n_most_freq=10, n_least_freq=10, vals_to_include=None, as_dict=False)</code>","text":"<p>Display a chart showing the impact of term frequency adjustments on a specific comparison level. Each value</p> <p>Parameters:</p> Name Type Description Default <code>output_column_name</code> <code>str</code> <p>Name of an output column for which term frequency  adjustment has been applied.</p> required <code>n_most_freq</code> <code>int</code> <p>Number of most frequent values to show. If this  or <code>n_least_freq</code> set to None, all values will be shown. Default to 10.</p> <code>10</code> <code>n_least_freq</code> <code>int</code> <p>Number of least frequent values to show. If this or <code>n_most_freq</code> set to None, all values will be shown. Default to 10.</p> <code>10</code> <code>vals_to_include</code> <code>list</code> <p>Specific values for which to show term frequency adjustments. Defaults to None.</p> <code>None</code> <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Examples:</p> <pre><code>linker.visualisations.tf_adjustment_chart(\"first_name\")\n</code></pre> <p>Returns:</p> Name Type Description <code>altair_chart</code> <code>ChartReturnType</code> <p>An Altair chart</p>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.waterfall_chart","title":"<code>waterfall_chart(records, filter_nulls=True, remove_sensitive_data=False, as_dict=False)</code>","text":"<p>Visualise how the final match weight is computed for the provided pairwise record comparisons.</p> <p>Records must be provided as a list of dictionaries. This would usually be obtained from <code>df.as_record_dict(limit=n)</code> where <code>df</code> is a SplinkDataFrame.</p> <p>Examples:</p> <pre><code>df = linker.inference.predict(threshold_match_weight=2)\nrecords = df.as_record_dict(limit=10)\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>List[dict]</code> <p>Usually be obtained from <code>df.as_record_dict(limit=n)</code> where <code>df</code> is a SplinkDataFrame.</p> required <code>filter_nulls</code> <code>bool</code> <p>Whether the visualisation shows null comparisons, which have no effect on final match weight. Defaults to True.</p> <code>True</code> <code>remove_sensitive_data</code> <code>bool</code> <p>When True, The waterfall chart will contain match weights only, and all of the (potentially sensitive) data from the input tables will be removed prior to the chart being created.</p> <code>False</code> <code>as_dict</code> <code>bool</code> <p>If True, return the chart as a dictionary.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>altair_chart</code> <code>ChartReturnType</code> <p>An Altair chart</p>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.comparison_viewer_dashboard","title":"<code>comparison_viewer_dashboard(df_predict, out_path, overwrite=False, num_example_rows=2, minimum_comparison_vector_count=0, return_html_as_string=False)</code>","text":"<p>Generate an interactive html visualization of the linker's predictions and save to <code>out_path</code>.  For more information see this video</p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The outputs of <code>linker.inference.predict()</code></p> required <code>out_path</code> <code>str</code> <p>The path (including filename) to save the html file to.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite the html file if it already exists? Defaults to False.</p> <code>False</code> <code>num_example_rows</code> <code>int</code> <p>Number of example rows per comparison vector. Defaults to 2.</p> <code>2</code> <code>minimum_comparison_vector_count</code> <code>int</code> <p>The minimum number of times that a comparison vector has to occur for it to be included in the dashboard. This can reduce the size of the produced html file by eliminating the rarest comparison vectors. Defaults to 0 (all comparison vectors are included).</p> <code>0</code> <code>return_html_as_string</code> <code>bool</code> <p>If True, return the html as a string</p> <code>False</code> <p>Examples:</p> <pre><code>df_predictions = linker.inference.predict()\nlinker.visualisations.comparison_viewer_dashboard(\n    df_predictions, \"scv.html\", True, 2\n)\n</code></pre> <p>Optionally, in Jupyter, you can display the results inline Otherwise you can just load the html file in your browser</p> <pre><code>from IPython.display import IFrame\nIFrame(src=\"./scv.html\", width=\"100%\", height=1200)\n</code></pre>","tags":["API","Visualisations"]},{"location":"api_docs/visualisations.html#splink.internals.linker_components.visualisations.LinkerVisualisations.cluster_studio_dashboard","title":"<code>cluster_studio_dashboard(df_predict, df_clustered, out_path, sampling_method='random', sample_size=10, cluster_ids=None, cluster_names=None, overwrite=False, return_html_as_string=False, _df_cluster_metrics=None)</code>","text":"<p>Generate an interactive html visualization of the predicted cluster and save to <code>out_path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The outputs of <code>linker.inference.predict()</code></p> required <code>df_clustered</code> <code>SplinkDataFrame</code> <p>The outputs of <code>linker.clustering.cluster_pairwise_predictions_at_threshold()</code></p> required <code>out_path</code> <code>str</code> <p>The path (including filename) to save the html file to.</p> required <code>sampling_method</code> <code>str</code> <p><code>random</code>, <code>by_cluster_size</code> or <code>lowest_density_clusters_by_size</code>. Defaults to <code>random</code>.</p> <code>'random'</code> <code>sample_size</code> <code>int</code> <p>Number of clusters to show in the dahboard. Defaults to 10.</p> <code>10</code> <code>cluster_ids</code> <code>list</code> <p>The IDs of the clusters that will be displayed in the dashboard.  If provided, ignore the <code>sampling_method</code> and <code>sample_size</code> arguments. Defaults to None.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the html file if it already exists? Defaults to False.</p> <code>False</code> <code>cluster_names</code> <code>list</code> <p>If provided, the dashboard will display these names in the selection box. Ony works in conjunction with <code>cluster_ids</code>.  Defaults to None.</p> <code>None</code> <code>return_html_as_string</code> <code>bool</code> <p>If True, return the html as a string</p> <code>False</code> <p>Examples:</p> <pre><code>df_p = linker.inference.predict()\ndf_c = linker.visualisations.cluster_pairwise_predictions_at_threshold(\n    df_p, 0.5\n)\n\nlinker.visualisations.cluster_studio_dashboard(\n    df_p, df_c, [0, 4, 7], \"cluster_studio.html\"\n)\n</code></pre> <p>Optionally, in Jupyter, you can display the results inline Otherwise you can just load the html file in your browser</p> <pre><code>from IPython.display import IFrame\nIFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200)\n</code></pre>","tags":["API","Visualisations"]},{"location":"blog/index.html","title":"Blog","text":"","tags":["Blog","News"]},{"location":"blog/2023/07/27/splink-updates---july-2023.html","title":"Splink Updates - July 2023","text":""},{"location":"blog/2023/07/27/splink-updates---july-2023.html#splink-updates-july-2023","title":"Splink Updates - July 2023","text":""},{"location":"blog/2023/07/27/splink-updates---july-2023.html#welcome-to-the-splink-blog","title":"Welcome to the Splink Blog!","text":"<p>Its hard to keep up to date with all of the new features being added to Splink, so we have launched this blog to share a round up of latest developments every few months.</p> <p>So, without further ado, here are some of the highlights from the first half of 2023!</p> <p>Latest Splink version: v3.9.4</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#massive-speed-gains-in-em-training","title":"Massive speed gains in EM training","text":"<p>There\u2019s now an option to make EM training much faster - in one example we\u2019ve seen at 1000x fold speedup.  Kudos to external contributor @aymonwuolanne from the Australian Bureau of Statistics!</p> <p>To make use of this, set the <code>estimate_without_term_frequencies</code> parameter to True; for example:</p> <pre><code>linker.estimate_parameters_using_expectation_maximisation(..., estimate_without_term_frequencies=True)\n</code></pre> <p>Note: If True, the EM algorithm ignores term frequency adjustments during the iterations. Instead, the adjustments are added once the EM algorithm has converged. This will result in slight difference in the final parameter estimations.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#out-of-the-box-comparisons","title":"Out-of-the-box Comparisons","text":"<p>Splink now contains lots of new out-of-the-box comparisons for dates, names, postcodes etc. The Comparison Template Library (CTL) provides suggested settings for common types of data used in linkage models.</p> <p>For example, a Comparison for <code>\"first_name\"</code> can now be written as:</p> <pre><code>import splink.duckdb.comparison_template_library as ctl\n\nfirst_name_comparison = ctl.name_comparison(\"first_name\")\n</code></pre> <p>Check out these new functions in the Topic Guide and Documentation.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#blocking-rule-library","title":"Blocking Rule Library","text":"<p>Blocking has, historically, been a point of confusion for users so we have been working behind the scenes to make that easier! The recently launched Blocking Rules Library (BRL) provides a set of functions for defining Blocking Rules (similar to the Comparison Library functions).</p> <p>For example, a Blocking Rule for <code>\"date_of_birth\"</code> can now be written as:</p> <pre><code>import splink.duckdb.blocking_rule_library as brl\n\nbrl.exact_match_rule(\"date_of_birth\")\n</code></pre> <p>Note: from Splink v3.9.6, <code>exact_match_rule</code> has been superseded by <code>block_on</code>. We advise using this going forward.</p> <p>Check out these new functions in the BRL Documentation as well as some new Blocking Topic Guides to better explain what Blocking Rules are, how they are used in Splink, and how to choose them.</p> <p>Keep a look out, as there are more improvements in the pipeline for Blocking in the coming months!</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#postgres-support","title":"Postgres Support","text":"<p>With a massive thanks to external contributor @hanslemm, Splink now supports  Postgres. To get started, check out the Postgres Topic Guide.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#clerical-labelling-tool-beta","title":"Clerical Labelling Tool (beta)","text":"<p>Clerical labelling is an important tool for generating performance metrics for linkage models (False Positive Rate, Recall, Precision etc.).</p> <p>Splink now has a (beta) GUI for clerical labelling which produces labels in a form that can be easily ingested into Splink to generate these performance metrics. Check out the example tool, linked Pull Request, and some previous tweets:</p> <p>Draft new Splink tool to speed up manual labelling of record linkage data. Example dashboard: https://t.co/yc1yHpa90X Grateful for any feedback whilst I'm still working on this, on Twitter or the draft PR: https://t.co/eXSNHHe2kcFree and open source pic.twitter.com/MEo4DmaxO9</p>\u2014 Robin Linacre (@RobinLinacre) April 28, 2023 <p>This tool is still in the beta phase, so is a work in progress and subject to change based on feedback we get from users. As a result, it is not thoroughly documented at this stage. We recommend checking out the links above to see a ready-made example of the tool. However, if you would like to generate your own, this example is a good starting point.</p> <p>We would love any feedback from users, so please comment on the PR or open a discussion.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#charts-in-altair-5","title":"Charts in Altair 5","text":"<p>Charts are now all fully-fledged Altair charts, making them much easier to work with.</p> <p>For example, a chart <code>c</code> can now be saved with:</p> <pre><code>c.save(\u201cchart.png\u201d, scale_factor=2)\n</code></pre> <p>where <code>json</code>, <code>html</code>, <code>png</code>, <code>svg</code> and <code>pdf</code> are all supported.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#reduced-duplication-in-comparison-libraries","title":"Reduced duplication in Comparison libraries","text":"<p>Historically, importing of the comparison libraries has included declaring the backend twice. For example:</p> <p></p><pre><code>import splink.duckdb.duckdb_comparison_level_library as cll\n</code></pre> This repetition has now been removed <pre><code>import splink.duckdb.comparison_level_library as cll\n</code></pre> The original structure still works, but throws a warning to switch to the new version."},{"location":"blog/2023/07/27/splink-updates---july-2023.html#in-built-datasets","title":"In-built datasets","text":"<p>When following along with the tutorial or example notebooks, one issue can be references of paths to data that does not exists on users machines. To overcome this issue, Splink now has a <code>splink_datasets</code> module which will store these datasets and make sure any users can copy and paste working code without fear of path issues. For example:</p> <p></p><pre><code>from splink.datasets import splink_datasets\n\ndf = splink_datasets.fake_1000\n</code></pre> returns the fake 1000 row dataset that is used in the Splink tutorial. <p>For more information check out the in-built datasets Documentation.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#regular-expressions-in-comparisons","title":"Regular Expressions in Comparisons","text":"<p>When comparing records, some columns will have a particular structure (e.g. dates, postcodes, email addresses). It can be useful to compare sections of a column entry. Splink's string comparison level functions now include a <code>regex_extract</code> to extract a portion of strings to be compared. For example, an <code>exact_match</code> comparison that compares the first section of a postcode (outcode) can be written as:</p> <pre><code>import splink.duckdb.duckdb_comparison_library as cl\n\npc_comparison = cl.exact_match(\"postcode\", regex_extract=\"^[A-Z]{1,2}\")\n</code></pre> <p>Splink's string comparison level functions also now include a <code>valid_string_regex</code> parameter which sends any entries that do not conform to a specified structure to the null level. For example, a <code>levenshtein</code> comparison that ensures emails have an \"@\" symbol can be written as:</p> <pre><code>import splink.duckdb.duckdb_comparison_library as cl\n\nemail_comparison = cl.levenshtein_at_thresholds(\"email\", valid_string_regex=\"^[^@]+\")\n</code></pre> <p>For more on how Regular Expressions can be used in Splink, check out the Regex topic guide.</p> <p>Note: from Splink v3.9.6, <code>valid_string_regex</code> has been renamed as <code>valid_string_pattern</code>.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#documentation-improvements","title":"Documentation Improvements","text":"<p>We have been putting a lot of effort into improving our documentation site, including launching this blog!</p> <p>Some of the improvements include:</p> <ul> <li>More Topic Guides covering things such as Record Linkage Theory, Guidance on Splink's backends and String Fuzzy Matching.</li> <li>A Contributors Guide to make contributing to Splink even easier. If you are interested in getting involved in open source, check the guide out!</li> <li>Adding tables to the Comparison libraries documentation to show the functions available for each SQL backend.</li> </ul> <p>Thanks to everyone who filled out our feedback survey. If you have any more feedback or ideas for how we can make the docs better please do let us know by raising an issue, starting a discussion or filling out the survey.</p>"},{"location":"blog/2023/07/27/splink-updates---july-2023.html#whats-in-the-pipeline","title":"What's in the pipeline?","text":"<ul> <li>   More Blocking improvements</li> <li>   Settings dictionary improvements</li> <li>   More guidance on how to evaluate Splink models and linkages</li> </ul>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html","title":"Splink Updates - December 2023","text":""},{"location":"blog/2023/12/06/splink-updates---december-2023.html#splink-updates-december-2023","title":"Splink Updates - December 2023","text":"<p>Welcome to the second installment of the Splink Blog!</p> <p>Here are some of the highlights from the second half of 2023, and a taste of what is in store for 2024!</p> <p>Latest Splink version: v3.9.10</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#charts-gallery","title":"Charts Gallery","text":"<p>The Splink docs site now has a Charts Gallery to show off all of the charts that come out-of-the-box with Splink to make linking easier.</p> <p></p> <p>Each chart now has an explanation of:</p> <ol> <li>What the chart shows</li> <li>How to interpret it</li> <li>Actions to take as a result</li> </ol> <p>This is the first step on a longer term journey to provide more guidance on how to evaluate Splink models and linkages, so watch this space for more in the coming months!</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#new-charts","title":"New Charts","text":"<p>We are always adding more charts to Splink - to understand how these charts are built see our new Charts Developer Guide.</p> <p>Two of our latest additions are:</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#confusion-matrix","title":"Confusion Matrix","text":"<p>When evaluating any classification model, a confusion matrix is a useful tool for summarising performance by representing counts of true positive, true negative, false positive, and false negative predictions.</p> <p>Splink now has its own confusion matrix chart to show how model performance changes with a given match weight threshold.</p> <p></p> <p>Note, labelled data is required to generate this chart.</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#completeness-chart","title":"Completeness Chart","text":"<p>When linking multiple datasets together, one of the most important factors for a successful linkage is the number of common fields across the datasets.</p> <p>Splink now has the completeness chart which gives a simple view of how well populated fields are across datasets.</p> <p></p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#settings-validation","title":"Settings Validation","text":"<p>The Settings dictionary is central to everything in Splink. It defines everything from the SQL dialect of your backend to how features are compared in Splink model.</p> <p>A common sticking point with users is how easy it is to make small errors when defining the Settings dictionary, resulting in unhelpful error messages.</p> <p>To address this issue, the Settings Validator provides clear, user-friendly feedback on what the issue is and how to fix it.</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#blocking-rule-library-improved","title":"Blocking Rule Library (Improved)","text":"<p>In our previous blog we introduced the Blocking Rule Library (BRL) built upon the <code>exact_match_rule</code> function. When testing this functionality we found it pretty verbose, particularly when blocking on multiple columns, so figured we could do better. From Splink v3.9.6 we introduced the <code>block_on</code> function to supersede <code>exact_match_rule</code>.</p> <p>For example, a block on <code>first_name</code> and <code>surname</code> now looks like:</p> <pre><code>from splink.duckdb.blocking_rule_library import block_on\nblock_on([\"first_name\", \"surname\"])\n</code></pre> <p>as opposed to</p> <pre><code>import splink.duckdb.blocking_rule_library as brl\nbrl.and_(\n  brl.exact_match_rule(\"first_name\"),\n  brl.exact_match_rule(\"surname\")\n)\n</code></pre> <p>All of the tutorials, example notebooks and docs have been updated to use <code>block_on</code>.</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#backend-specific-installs","title":"Backend Specific Installs","text":"<p>Some users have had difficulties downloading Splink due to additional dependencies, some of which may not be relevant for the backend they are using. To solve this, you can now install a minimal version of Splink for your given SQL engine.</p> <p>For example, to install Splink purely for Spark use the command:</p> <pre><code>pip install 'splink[spark]'\n</code></pre> <p>See the Getting Started page for further guidance.</p>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#drop-support-for-python-37","title":"Drop support for python 3.7","text":"<p>From Splink 3.9.7, support has been dropped for python 3.7. This decision has been made to manage dependency clashes in the back end of Splink.</p> <p>If you are working with python 3.7, please revert to Splink 3.9.6.</p> <pre><code>pip install splink==3.9.6\n</code></pre>"},{"location":"blog/2023/12/06/splink-updates---december-2023.html#whats-in-the-pipeline","title":"What's in the pipeline?","text":"<ul> <li>   Work on Splink 4 is currently underway</li> <li>   More guidance on how to evaluate Splink models and linkages</li> </ul>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html","title":"Ethics in Data Linking","text":""},{"location":"blog/2024/01/23/ethics-in-data-linking.html#ethics-in-data-linking","title":"Ethics in Data Linking","text":"<p>Welcome to the next installment of the Splink Blog where we\u2019re talking about Data Ethics!</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#why-should-we-care-about-ethics","title":"Why should we care about ethics?","text":"<p>Splink was developed in-house at the UK Government\u2019s Ministry of Justice. As data scientists in government, we are accountable to the public and have a duty to maintain public trust. This includes upholding high standards of data ethics in our work.</p> <p>Furthermore, data linkage is generally used at the start of analytical projects so any design decisions that are made, or biases introduced, will have consequences for all downstream use cases of that data. With this in mind, it is important to try and address any potential ethical issues at the linking stage.</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#ethics-and-splink","title":"Ethics and Splink","text":""},{"location":"blog/2024/01/23/ethics-in-data-linking.html#what-do-we-already-have-in-place","title":"What do we already have in place?","text":"<p>Data ethics has been a foundational consideration throughout Splink\u2019s development. For example, the decision to make Splink open-source was motivated by an ambition to make our data linking software fully transparent, accessible and auditable to users both inside and outside of government. The fact that this also empowers external users to expand and improve upon Splink\u2019s functionality is another huge benefit!</p> <p>Another core principle guiding the development of Splink has been explainability. Under the hood we use the Fellegi-Sunter model which is an industry-standard, well-researched, explainable methodology. This, in combination with interactive charts such as the waterfall chart, where model results can be easily broken down and visualised for individual record pairs, make Splink predictions easily interrogatable and explainable. Being able to interrogate predictions is especially valuable when things go wrong - if an incorrect link has been made you can trace it back see exactly why the model made the decision.</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#what-else-should-we-be-considering","title":"What else should we be considering?","text":"<p>To continue our exploration of ethical issues, we recently had a team away day focused on data ethics. We aimed to better understand where ethical concerns (e.g. bias) could arise in our own Splink linkage pipelines and what further steps we could take to empower users to be able to better understand and possibly mitigate these issues within their own projects. </p> <p>We discussed a typical data linking pipeline, as used in the Ministry of Justice, from data collection at source through to the generation of Splink cluster IDs. It became clear that there are considerations to make at each stage of a pipeline that can have an ethical implications such as:</p> <p></p> <p>For example, a higher occurrence of misspellings for names of non-UK origin during data collection can impact the accuracy of links for certain groups.</p> <p>As you can see, the entire data linking process has many stages with lots of moving parts, resulting in numerous opportunities for ethical issues to arise. </p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#what-are-we-going-to-do-about-it","title":"What are we going to do about it?","text":"<p>Summarised below are the key areas of ethical concern we identified and how we plan to address them.</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#evaluation","title":"Evaluation","text":"<p>Splink is not plug and play. As a software, it provides many configuration options to support its users, from blocking rules to term frequency adjustments. However, with greater flexibility comes greater variation in model design. From an explainability and quality assurance perspective, it is important to understand how different choices on model build interact and can influence results.</p> <p>It isn\u2019t trivial to unpick the interplaying factors that affect Splink\u2019s outputs, but as a first step we are building a framework and guidance to demonstrate how changes to a model's settings can impact predictions. We hope this will give users a better understanding of model sensitivity and more confidence in explaining and justifying the results of their models. We also hope this will serve as a stepping stone to tools that help evaluate models in a production setting (e.g. model drift).</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#bias","title":"Bias","text":"<p>Bias is a key area of ethical concern within data linking and one that crops up at many stages during a typical linking pipeline; from data collection to downstream linking. It is important to identify, quantify and, where possible, mitigate bias in input sources, model building and outputs. However, sources of bias are specific to a given use-case, and therefore finding general solutions to mitigating bias is challenging.</p> <p>This year we are embarking on a collaboration with the Alan Turing Institute to get expert support on assessing bias in our linking pipelines. The long-term goal is to create general tooling to help Splink users gain a better understanding of how bias could be being introduced into their models. Improved model evaluation (see above) is a first step in the development of these tools.</p>"},{"location":"blog/2024/01/23/ethics-in-data-linking.html#communication","title":"Communication","text":"<p>Sharing both our current knowledge and future discoveries on the ethics of data linking with Splink is important to help support our users and the data linking community more broadly. This blog is the first step on that journey for us.</p> <p>As already mentioned, Splink comes with a variety of tools that support explainability. We will be updating the Splink documentation to convey the significance of these resources from a data ethics perspective to help give existing users, potential adopters and their customers greater confidence in building Splink models and model predictions.</p> <p>Please visit the Ethics in Data Linking discussion on Splink's GitHub repository to get involved in the conversation and share your thoughts - we'd love to hear them!</p> <p>If you want to stay up to date with the latest Splink blogs subscribe to our new  RSS feed! </p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html","title":"Splink 3 updates, and Splink 4 development announcement - April 2024","text":""},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#splink-3-updates-and-splink-4-development-announcement-april-2024","title":"Splink 3 updates, and Splink 4 development announcement - April 2024","text":"<p>This post describes significant updates to Splink since our previous post and details of development work taking place on the forthcoming release of Splink 4.</p> <p>Latest Splink version: v3.9.14</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#splink-3-updates","title":"Splink 3 Updates","text":"<p>Here are some highlights of Splink development since our last update in December 2023. As always, keep an eye on the changelog for more regular updates.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#graph-metrics","title":"Graph metrics","text":"<p>Linked data can be interpreted as graphs, as described in our graph definitions guide. Given this, graph metrics are useful in record linkage because they give insights into the quality of your final output (linked data) and, by extension, the linkage pipeline. They are particularly relevant for the analysis of clusters.</p> <p>For example, a cluster where all entities are connected to all others with high match weights is likely to be more reliable than a cluster where many of the entities connect to only a small proportion of the other entities in the cluster. This can be measured by a graph metric called density.</p> <p>Several graph metrics can now be computed using <code>linker.compute_graph_metrics</code>.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#duckdb-performance-improvements-and-benchmarking","title":"DuckDB Performance Improvements and Benchmarking","text":"<p>The DuckDB backend is now fully parallelised, resulting in large performance increases especially on high core count machines.</p> <p>We now recommend the DuckDB backend for most users. It is the fastest backend, and is capable of linking large datasets, especially if you have access to high-spec machines.</p> <p>For the first time, we have also conducted formal benchmarking of DuckDB on machines of different sizes. Check out our blog post outlining the results of this investigation.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#blocking-on-an-array-column","title":"Blocking on an array column","text":"<p>In some circumstances, it is useful to block on an array column. For example, if a persons have an array (list) of postcodes associated with each record, then we may wish to generate all record comparisons where there is a match of at least one postcode (the union of the arrays is of length 1 or more). This feature was added in PR 1692, with thanks to Github user <code>nerskin</code> for this external contribution!</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#more-documentation","title":"More Documentation","text":"<p>We have been building more guidance and documentation to make life as easy as possible for users, including:</p> <ul> <li>Topic Guides exploring Evaluation for different outputs of the linkage process, including the Linkage Model, the Edges (Links) and Clusters.</li> <li>Guidance on our strategy for Managing Dependencies within Splink.</li> <li>A Developer Quickstart guide to help contributors get up and running smoothly (with thanks to external contributor <code>zmbc</code> for putting this together).</li> </ul> <p>Warning</p> <p>Splink 3 has entered maintenance mode.  We will continue to apply bugfixes, but new features should be built on the splink4_dev branch.  We are no longer accepting new features on the master (Splink 3) branch.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#splink-4","title":"Splink 4","text":"<p>The team has been focussing development efforts on Splink 4, due to be released later this year.</p> <p>We\u2019re pleased to announce we\u2019ve recently reached an important milestone: all tests are passing, and all of the tutorial and examples notebooks have been updated and work successfully in the new version</p> <p>Development releases of Splink 4 have commenced, and you can try it out using <code>pip install --pre splink</code>, or try it out in your web browser using the Colab links at the top the tutorial and example notebooks.</p> <p>As a result, Splink 3 has entered maintenance mode. We will continue to apply bugfixes, but new features should be built on the splink4_dev branch. We are no longer accepting new features on the master (Splink 3) branch.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#aims-of-splink-4","title":"Aims of Splink 4","text":"<p>Splink 4 represents an incremental improvement to version 3 that makes Splink easier to use without making any major changes to workflows. The core functionality has not changed - the steps to train a model and predict results are the same, and models trained in Splink 3 will still work in Splink 4.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#improve-ease-of-use","title":"Improve ease of use","text":"<p>The primary aim is to improve the user-facing API so that:</p> <ul> <li>The user has to write less code to achieve the same result</li> <li>Function imports are simpler and grouped more intuitively</li> <li>Settings and configuration can now be constructed entirely using Python objects, meaning that the user can rely heavily on autocomplete, rather than needing to remember the names of settings.</li> <li>Less dialect-specific code</li> </ul> <p>You can see an example of how the code changes between version 3 and 4 in the screenshot below:</p> <p></p> <p>The corresponding code is here.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#improve-ease-of-development","title":"Improve ease of development","text":"<p>A second important aim of Splink 4 is to improve the internal codebase to make Splink easier to develop for the core team and external contributors. These changes don\u2019t affect the end user, but should enable a faster pace of development.</p> <p>A wide range of improvements have been made such as:</p> <ul> <li>Code quality: type hinting, mypy conformance etc.</li> <li>Making CI run much faster</li> <li>Reducing rigidities in dependencies</li> <li>Decoupling parts of the codebase and less mutable state</li> </ul>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#timelines","title":"Timelines","text":"<p>We expect to do regular beta releases to PyPI in the coming months. They can be found here, and you can install the latest version of Splink 4 using <code>pip install --pre splink</code></p> <p>Warning</p> <p>During this time, there may be further breaking changes to the public API so please use Splink 4 with caution. However, we think the new API is now relatively stable, and big changes are unlikely.</p> <p>We expect to bring Splink 4 out of beta, and do a first full release sometime in the autumn.</p>"},{"location":"blog/2024/04/02/splink-3-updates-and-splink-4-development-announcement---april-2024.html#feedback","title":"Feedback","text":"<p>We would love feedback on Splink 4, so please check it out and let us know what you think! The best way to get in contact is via our discussion forum.</p>"},{"location":"blog/2024/07/24/splink-400-released.html","title":"Splink 4.0.0 released","text":""},{"location":"blog/2024/07/24/splink-400-released.html#splink-400-released","title":"Splink 4.0.0 released","text":"<p>We're pleased to release Splink 4, which is more scalable and easier to use than Splink 3.</p> <p>For the uninitiated, Splink is a free and open source library for record linkage and deduplication at scale, capable of deduplicating 100 million records+, that is widely used and has been downloaded over 8 million times.</p> <p>Version 4 is recommended to all new users.   For existing users, there has been no change to the statistical methodology. Version 3 and 4 will give the same results, so there's no urgency to upgrade existing pipelines.</p> <p>The improvements we've made to the user experience mean that Splink 4 syntax is not backwards compatible, so Splink 3 scripts will need to be adjusted to work in Splink 4.  However, the model serialisation format is unchanged, so models saved from Splink 3 in <code>.json</code> format can be imported into Splink 4.</p> <p>To get started quickly with Splink 4, checkout the examples.  You can see how things have changed by comparing them to the Splink 3 examples, or see the screenshot at the bottom of this post.</p>"},{"location":"blog/2024/07/24/splink-400-released.html#main-enhancements","title":"Main enhancements","text":"<ul> <li> <p>User Experience:  We have revamped all aspects of the user-facing API.  Functionality is easier to find, better named and better organised.</p> </li> <li> <p>Faster and more scalable  Our testing suggests that the internal changes have made Splink 4 significantly more scalable. Our testing also suggests Splink 4 is faster than Splink 3 for many workloads.  This is in addition to dramatic speedups that were integrated into Splink 3 in January, meaning Splink is now 5x faster for a typical workload on a modern laptop than it was in November 2023.  We welcome any feedback from users about speed and scalability, as it's hard for us to test the full range of scenarios.</p> </li> <li> <p>Improved backend code quality The Splink 4 codebase represents a big refactor to focus on code quality.  It should now be easier to contribute, and quicker and easier for the team to fix bugs.</p> </li> <li> <p>Autocomplete everywhere: All functions, most notably the settings object, have been rewritten to ensure autocomplete (IntelliSense/code completion) works.  This means you no longer need to remember the specific name of the wide range of configuration options - a key like <code>blocking_rules_to_generate_predictions</code> will autocomplete.  Where settings such as <code>link_type</code> have a predefined list of valid options, these will also autocomplete.</p> </li> </ul> <p></p>"},{"location":"blog/2024/07/24/splink-400-released.html#smaller-enhancements","title":"Smaller enhancements","text":"<p>Some highlights of other smaller improvements:</p> <ul> <li> <p>Linker functionality is now organised into namespaces.  In Splink 3, a very large number of functions were available on the <code>linker</code> object, making it hard to find and remember what functionality exists.  In Splink 4, functions are available in namespaces such as <code>linker.training</code> and <code>linker.inference</code>.  Documentation here.</p> </li> <li> <p>Blocking analysis.  The new blocking functions at <code>splink.blocking</code> include routines to ensure users don't accidentally run code that generates so many comparisons it never completes.  Blocking analysis is also much faster.  See the blocking tutorial for more.</p> </li> <li> <p>Switch between dialects more easily.  The backend SQL dialect (DuckDB, Spark etc.) is now imported using the relevant database API.  This is passed into Splink functions (such as creation of the linker), meaning that switching between dialects is now a case of importing a different database API, no other code needs to change. For example, compare the DuckDB and SQLite examples.</p> </li> <li> <p>Exploratory analysis no longer needs a linker.  Exploratory analysis that is typically conducted before starting data linking can now be done in isolation, without the user needing to configure a linker. Exploratory analysis is now available at <code>splink.exploratory</code>.  Similarly, blocking can be done without a linker using the functions at <code>splink.blocking</code>.</p> </li> <li> <p>Enhancements to API documentation. Now that the codebase is better organised, it's made it much easier provide high quality API documentation - the new pages are here.</p> </li> </ul>"},{"location":"blog/2024/07/24/splink-400-released.html#updating-splink-3-code","title":"Updating Splink 3 code","text":"<p>Conceptually, there are no major changes in Splink 4. Splink 4 code follows the same steps as Splink 3.  The same core estimation and prediction routines are used.  Splink 4 code that uses the same settings will produce the same results (predictions) as Splink 3.</p> <p>That said, there have been significant changes to the syntax and a reorganisation of functions.</p> <p>For users wishing to familiarise themselves with Splink 4, we recommend the easiest way is to compare and contrast the new examples with their Splink 3 equivalents.</p> <p>You may also find the following screenshot useful, which shows the diff of a fairly standard Splink 3 workflow that has been rewritten in Splink 4.</p> <p></p> <p>You can find the corresponding code here.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html","title":"Bias in Data Linking","text":""},{"location":"blog/2024/08/19/bias-in-data-linking.html#bias-in-data-linking","title":"Bias in Data Linking","text":"<p>In March 2024, the Splink team launched a 6-month 'Bias in Data Linking' internship with the Alan Turing Institute. This installment of the Splink Blog is going to introduce the internship, its goals, and provide an update on what's happened so far.</p> <p>The internship is being undertaken by myself, Erica Kane. I am a PhD student based at the University of Leeds. My doctoral research is in Data Analytics, conducted in partnership with the Parole Board, and I have a background in quantitative research within Criminal Justice.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#background","title":"\ud83d\udcdd Background","text":"<p>The internship stemmed from the team's previous engagement with ethics, understanding that this complex yet inevitable aspect of data science has implications for data linking. </p> <p>Data science pipelines are intricate processes with lots of decision points. At each of these decision points bias can creep in. If it does, its impact on results can vary as it interacts with different parts of the pipeline. For example, two datasets might react differently to the same bias introduced by a model. Additionally, multiple biases can interact with each other, making it difficult to see their individual effects. Therefore, detecting, monitoring, quantifying, and mitigating bias in data science pipelines is extremely challenging.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#goals","title":"\ud83c\udfaf Goals","text":"<p>To set the direction for the internship, it was useful to first define what a successful outcome would look like. </p> <p>Many users and developers of data linking pipelines have ideas about where bias might be entering their pipeline, but they aren\u2019t always sure how to evaluate this bias or understand its impact. So, the goal was to create a standardised approach to evaluating bias that\u2019s adaptable to different use cases.</p> <p>Before developing this approach, it was useful to look at different types and sources of bias in data linking pipelines. This made sure that the development was grounded in real-life examples, which was crucial for assessing if an evaluation method was suitable.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#sources-of-bias","title":"\ud83d\udd0d Sources of bias","text":"<p>From talking with experts and reviewing relevant materials, it was clear that there were already hypotheses about where bias might enter a data linking pipeline. </p> <p>These hypotheses were reviewed and grouped into broad categories, highlighting the key areas for evaluation:</p> <p></p> <p>The input data can contain mistakes or legitimate qualities which make some records harder to link than others. Addressing these mistakes or qualities through data preparation techniques can have the same effect. If this impact is not random, this means the input data will introduce bias.</p> <p>Model design involves specifying settings that define which records to compare and how to compare them. If these design choices result in a better/worse performance for certain record types, bias will be introduced.</p> <p>Understanding these potential bias sources laid the groundwork for determining the most suitable evaluation method.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#evaluating-bias","title":"\ud83d\udcca Evaluating bias","text":"<p>There are many ways to evaluate performance in data science, and a common approach is to compare the output of a model with a ground truth. In data linking, this means manually labelling comparisons as \"link\" or \"non-link\", running them through the pipeline, and then comparing the predicted results to these labels. </p> <p>Since this method is commonly used to measure overall performance, labelled data may already exist. If this is the case, it's worth exploring how these labels could be repurposed to evaluate bias instead. This requires a more focussed approach, where it's necessary to pinpoint specific records that align with a defined hypothesis. These might include records that represent mistakes, qualities, or preparation of the input data, or those affected by model design settings.</p> <p>Assuming there's already a hypothesis in place, this approach involves a 3-step process: </p> <p></p> <p>Each step was reviewed to understand the considerations for evaluating bias...</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#step-1-hand-label-record-comparisons","title":"Step 1: Hand label record comparisons","text":"<p>Firstly, a sample of record pairs are labelled by human experts to decide if they relate to the same person. This sample provides the base from which performance is assessed.</p> <p>When working with real data, it's not always clear whether records relate to the same individual... </p> <p></p> <p>Even human evaluators can struggle, and individuals often disagree. In these uncertain cases, there is a risk of bias being introduced into the labels by the evaluators themselves. The lack of consistency or reliability of labels makes it hard to consider them a \"ground truth\" from which to assess bias.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#step-2-identify-records","title":"Step 2: Identify records","text":"<p>The second step is to focus the evaluation on bias by identifying records that represent the specific hypothesis. Issues with this process are demonstrated by the following example:</p> <p>Bias is suspected to enter a pipeline through data standardisation using an English phonetic algorithm (e.g. Metaphone). </p> <p>Records with non-English phonetic names must be identified for evaluation. There are two main options to identify these records, both with associated drawbacks.</p> <ol> <li> <p>Using variables as proxies</p> <ul> <li>Assumes a relationship between the variable and name phonetics (e.g. ethnicity/nationality)</li> <li>Relies on accurate recording of the variable </li> </ul> </li> <li> <p>Direct identification</p> <ul> <li>Requires a complex technical solution which would be difficult to develop and verify</li> </ul> </li> </ol> <p>These issues are applicable to most hypotheses, and both options are likely to introduce additional bias.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#step-3-assess-the-performance","title":"Step 3: Assess the performance","text":"<p>The final step is to assess performance outcomes by comparing the labelled data with the pipeline\u2019s predictions. In bias evaluation, understanding where the model goes wrong is of particular interest (false positives and false negatives). </p> <p>A high-level typical data linking performance may look like this:</p> <p></p> <p>This represents the reality of the dominant class (non-links) in data linking, as most records which are compared will not relate to the same individual. This leaves very few errors to evaluate within a large sample of labels. When analysing for bias, the focus would be on an even smaller subset of records of interest. </p> <p>A bias specific data linking performance may look like this:</p> <p></p> <p>This further reduces the absolute number of examples, making it difficult to quantify the impact of any bias. </p> <p>Getting enough useful examples is possible, but impractical. It would require either dedicating a lot of resources to labelling or using a sampling method that could introduce additional bias.</p>"},{"location":"blog/2024/08/19/bias-in-data-linking.html#conclusions","title":"\ud83d\udca1 Conclusions","text":"<p>The internship aims to develop an approach that helps users of data linking pipelines evaluate suspected bias. This first blog covers the initial steps taken to figure out what the evaluation process could look like.</p> <p>Looking into how a common performance evaluation strategy handles bias investigation in data linking uncovered three main issues:</p> <ol> <li>Manual labelling does not give a reliable \"ground truth\".</li> <li>Records of interest for a specific hypothesis are difficult to identify.</li> <li>Gathering large samples of FPs and FNs is impractical.</li> </ol> <p>These challenges stem from working with real data and make this approach unsuitable for bias evaluation. We\u2019re currently looking into alternative options \u2014 stay tuned for updates!</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html","title":"Bias in Data Linking, continued","text":""},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#bias-in-data-linking-continued","title":"Bias in Data Linking, continued","text":"<p>This blog is the second in our series dedicated to Bias in Data Linking. Here we wrap up work completed during the the six-month Alan Turing Institute internship on 'Bias in Data Linking', and share some final thoughts.</p> <p>In the previous blog post we concluded that assessing bias in a linkage pipeline using real data and clerical labels is possible to some degree, but has major shortcomings. Here we consider a different approach which aims to address some of these issues.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#a-different-approach","title":"A Different Approach","text":"<p>Previously we established that bias in a linkage pipeline stems from two main sources: the data being linked and the linkage model. Considering both of these factors at the same time is complex, making it difficult to reach solid conclusions. Here we will explore how bias can have an impact within the linkage model only.</p> <p>As before, we assume there is a hypothesis that we would like to explore. In order to target bias within the linkage model, we construct a synthetic dataset with combinations of records which reflect the hypothesis we wish to test.</p> <p>This approach can be broken down into 5 key steps:</p> <p></p> <p>Note</p> <p>The following steps are intentionally high-level, for a more hands-on application on fake data with Splink check out the accompanying example notebook.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#1-generate-synthetic-records","title":"1. Generate synthetic records","text":"<p>This process builds a neutral foundation for bias detection by creating specific records to evaluate a pre-trained model's results. While the process of generating these records can vary, it's crucial to keep it controlled. Automatically generating large amounts of data without understanding the content can lead to the same issues as real production data.</p> <p>Instead of focussing on the number of synthetic records, the key is ensuring each record has a clear purpose that is relevant to the hypothesis. For example, if the hypothesis is that misspellings of names lead to worse linkage, and you suspect that misspellings are more common for names of certain origins, your synthetic records might look like this:</p> <p></p> <p>This is a simplification, and a real generation would likely include more rows with various spelling error iterations. The final two records also consider the case of similarly spelled names relating to different individuals.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#2-investigate-model-parameters","title":"2. Investigate model parameters","text":"<p>The pre-trained model can be analysed specifically in relation to the hypothesis, rather than just generally. In Splink, one way to do this is by using a match weights chart:</p> <p></p> <p>Each of the bars represent the amount of evidence (match weights) that two records refer to the same individual, depending on how similar the features are. It's useful to start thinking about how this chart relates to the scenario represented by the synthetic records. For example, for the above model there is only a significant drop in match weight for first_name between the third and fourth comparison level. </p> <p>Given the final linkage score relies on the accumulation of these match weights, viewing the model parameters in isolation like this does not give the full picture - specific examples are required.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#3-perform-and-evaluate-linkage","title":"3. Perform and evaluate linkage","text":"<p>Now that you have records to compare and a trained model, the next stage is to generate match probabilities. If a threshold for a link has been chosen, this can be used to indicate which records would be considered to be a link in a linkage pipeline.</p> <p>It's also useful to examine each comparison to see which features impact the match probability the most. In Splink, you can use a waterfall chart for this. This will help you identify if any weights are too predictive or not predictive enough based on your hypothesis. </p> <p>Some match weights might seem off for your hypothesis but be reasonable for the overall model. They might not be wrong per se, but if they create issues in specific scenarios, they will introduce bias into the pipeline.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#4-identify-bias-mitigations","title":"4. Identify bias mitigations","text":"<p>If you detect bias in the pipeline, you'll need to decide whether or not to address it. Assessing the mitigation strategy in this controlled manner ensures it directly addresses the bias.</p> <p>Here's an example of how you could approach deciding whether to mitigate for bias or not:</p> <p></p> <p>In reality there will often be some negative impact on overall performance and/or further biases introduced by changing the model, so the decision is not straightfoward. It depends on the specific use case.</p> <p>If you choose to attempt a bias mitigation, repeat steps 1-3 before reassessing the results to determine if it was successful. Keep in mind, this attempt may only work partially - or not at all. </p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#5-make-a-statement-about-bias","title":"5. Make a statement about bias","text":"<p>As discussed, investigating bias should be anchored in specific hypotheses and examples and the reporting of bias within a model should follow the same structure. It is unrealistic to expect that there will be no bias at all, or that it is practical to be able to check enough hypotheses to make such a broad statement. Instead, it is recommended to report on each of the hypotheses that have been tested.</p> <p>The mitigation stage can lead to three potential outcomes, each shaping a different statement about the the specific bias from your hypothesis:</p> <ol> <li> <p>Bias was not detected You might disprove the hypothesis, though it's rare that there's no bias at all.</p> </li> <li> <p>Bias was detected - it has been fully mitigated It's unlikely, but possible. If this happens, ensure the impact on overall performance and any further bias is thoroughly investigated and clearly explained.</p> </li> <li> <p>Bias was detected - it has been partially/could not be mitigated This is the most likely scenario. If mitigation is partial, clearly explain where it falls short. If there's no mitigation, work to gain a more detailed understanding of the bias.</p> </li> </ol> <p>If you conclude that bias has been detected and it can only be partially mitigated or not mitigated, this is not a failure. It's a likely outcome when you're trying to standardise a pipeline that handles thousands of different scenarios with varying impacts on results.</p>"},{"location":"blog/2024/12/02/bias-in-data-linking-continued.html#final-thoughts","title":"\ud83d\udcad Final thoughts","text":"<p>This approach doesn\u2019t aim to make statements about the impact of the detected bias. In other words, detecting bias alone doesn\u2019t allow you to draw conclusions on how the resulting linked data will look. This is because many other unrelated factors in the pipeline will interact with the scenarios and affect whether records are linked or not.</p> <p>The goal here is to better understand bias. This is done by highlighting specific scenarios, examining how the model handles them, and introducing mitigations directly. This approach allows for more transparent statements about bias during the development of a linkage pipeline.</p> <p>If you have any ideas or feedback on this process or how it's working in the notebook - please let us know!</p>"},{"location":"charts/index.html","title":"Charts Gallery","text":""},{"location":"charts/index.html#charts-gallery","title":"Charts Gallery","text":""},{"location":"charts/index.html#exploratory-analysis","title":"Exploratory Analysis","text":"<p><code>profile columns</code></p> <p><code>completeness chart</code></p>"},{"location":"charts/index.html#blocking","title":"Blocking","text":"<p><code>cumulative comparisons to be scored from blocking rules chart</code></p>"},{"location":"charts/index.html#comparison-helpers","title":"Comparison Helpers","text":"<p><code>comparator score chart</code></p> <p><code>comparator score threshold chart</code></p> <p><code>phonetic match chart</code></p>"},{"location":"charts/index.html#evaluation","title":"Evaluation","text":""},{"location":"charts/index.html#model-evaluation","title":"Model Evaluation","text":"<p><code>match weights chart</code></p> <p><code>m u parameters chart</code></p> <p><code>parameter estimate comparisons chart</code></p> <p><code>tf adjustment chart</code></p> <p><code>unlinkables chart</code></p>"},{"location":"charts/index.html#edge-link-evaluation","title":"Edge (Link) Evaluation","text":""},{"location":"charts/index.html#overall","title":"Overall","text":"<p><code>accuracy chart from labels table</code></p> <p><code>threshold_selection_tool from labels table</code></p>"},{"location":"charts/index.html#spot-checking","title":"Spot Checking","text":"<p><code>comparison viewer dashboard</code></p> <p><code>waterfall chart</code></p>"},{"location":"charts/index.html#cluster-evaluation","title":"Cluster Evaluation","text":""},{"location":"charts/index.html#overall_1","title":"Overall","text":""},{"location":"charts/index.html#spot-checking_1","title":"Spot Checking","text":"<p><code>cluster studio dashboard</code></p>"},{"location":"charts/index.html#all-charts","title":"All Charts","text":"<p><code>accuracy chart from labels table</code></p> <p><code>cluster studio dashboard</code></p> <p><code>comparator score chart</code></p> <p><code>comparator score threshold chart</code></p> <p><code>comparison viewer dashboard</code></p> <p><code>completeness chart</code></p> <p><code>cumulative comparisons from blocking rules chart</code></p> <p><code>m u parameters chart</code></p> <p><code>match weights chart</code></p> <p><code>parameter estimate comparisons chart</code></p> <p><code>phonetic match chart</code></p> <p><code>profile columns</code></p> <p><code>tf adjustment chart</code></p> <p><code>unlinkables chart</code></p> <p><code>waterfall chart</code></p>"},{"location":"charts/accuracy_analysis_from_labels_table.html","title":"accuracy chart from labels table","text":""},{"location":"charts/accuracy_analysis_from_labels_table.html#accuracy_analysis_from_labels_table","title":"<code>accuracy_analysis_from_labels_table</code>","text":"<p>At a glance</p> <p>Useful for: Selecting an optimal match weight threshold for generating linked clusters.</p> <p>API Documentation: accuracy_chart_from_labels_table()</p> <p>What is needed to generate the chart? A <code>linker</code> with some data and a corresponding labelled dataset</p>"},{"location":"charts/accuracy_analysis_from_labels_table.html#what-the-chart-shows","title":"What the chart shows","text":"<p>For a given match weight threshold, a record pair with a score above this threshold will be labelled a match and below the threshold will be labelled a non-match. For all possible match weight thresholds, this chart shows various accuracy metrics comparing the Splink scores against clerical labels. </p> <p>Precision and recall are shown by default, but various additional metrics can be added: specificity, negative predictive value (NPV), accuracy, \\(F_1\\), \\(F_2\\), \\(F_{0.5}\\), \\(P_4\\) and \\(\\phi\\) (Matthews correlation coefficient).</p>"},{"location":"charts/accuracy_analysis_from_labels_table.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Precision can be maximised by increasing the match threshold (reducing false positives).</p> <p>Recall can be maximised by decreasing the match threshold (reducing false negatives). </p> <p>Additional metrics can be used to find the optimal compromise between these two, looking for the threshold at which peak accuracy is achieved. </p> <p>Confusion matrix</p> <p>See threshold_selection_tool_from_labels_table for a more complete visualisation of the impact of match threshold on false positives and false negatives, with reference to the confusion matrix.</p>"},{"location":"charts/accuracy_analysis_from_labels_table.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>Having identified an optimal match weight threshold, this can be applied when generating linked clusters using cluster_pairwise_predictions_at_thresholds().</p>"},{"location":"charts/accuracy_analysis_from_labels_table.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\nfrom splink.datasets import splink_dataset_labels\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"substr(first_name,1,1)\"),\n        block_on(\"substr(surname, 1,1)\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api)\n\nlinker.training.estimate_probability_two_random_records_match(\n    [block_on(\"first_name\", \"surname\")], recall=0.7\n)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\n\ndf_labels = splink_dataset_labels.fake_1000_labels\nlabels_table = linker.table_management.register_labels_table(df_labels)\n\nchart = linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"accuracy\", add_metrics=[\"f1\"]\n)\n</code></pre> <p>Note that you can also produce a ROC chart, a precision recall chart, or get the results as a table:</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"roc\", add_metrics=[\"f1\"]\n)\n</code></pre> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"precision_recall\", add_metrics=[\"f1\"]\n)\n</code></pre> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"table\", add_metrics=[\"f1\"]\n).as_pandas_dataframe()\n</code></pre> truth_threshold match_probability total_clerical_labels p n tp tn fp fn P_rate ... precision recall specificity npv accuracy f1 f2 f0_5 p4 phi 0 -23.8 6.846774e-08 3176.0 2031.0 1145.0 1446.0 1055.0 90.0 585.0 0.639484 ... 0.941406 0.711965 0.921397 0.643293 0.787469 0.810765 0.748447 0.884404 0.783298 0.608544 1 -22.7 1.467638e-07 3176.0 2031.0 1145.0 1446.0 1077.0 68.0 585.0 0.639484 ... 0.955086 0.711965 0.940611 0.648014 0.794395 0.815797 0.750156 0.894027 0.790841 0.627351 2 -21.7 2.935275e-07 3176.0 2031.0 1145.0 1446.0 1083.0 62.0 585.0 0.639484 ... 0.958886 0.711965 0.945852 0.649281 0.796285 0.817180 0.750623 0.896689 0.792887 0.632504 3 -21.6 3.145950e-07 3176.0 2031.0 1145.0 1446.0 1088.0 57.0 585.0 0.639484 ... 0.962076 0.711965 0.950218 0.650329 0.797859 0.818336 0.751013 0.898918 0.794588 0.636808 4 -20.6 6.291899e-07 3176.0 2031.0 1145.0 1446.0 1094.0 51.0 585.0 0.639484 ... 0.965932 0.711965 0.955459 0.651578 0.799748 0.819728 0.751481 0.901609 0.796624 0.641982 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 278 24.2 9.999999e-01 3176.0 2031.0 1145.0 5.0 1145.0 0.0 2026.0 0.639484 ... 1.000000 0.002462 1.000000 0.361085 0.362091 0.004912 0.003075 0.012189 0.009733 0.029815 279 24.3 1.000000e+00 3176.0 2031.0 1145.0 4.0 1145.0 0.0 2027.0 0.639484 ... 1.000000 0.001969 1.000000 0.360971 0.361776 0.003931 0.002461 0.009770 0.007805 0.026663 280 24.4 1.000000e+00 3176.0 2031.0 1145.0 3.0 1145.0 0.0 2028.0 0.639484 ... 1.000000 0.001477 1.000000 0.360857 0.361461 0.002950 0.001846 0.007342 0.005867 0.023087 281 24.6 1.000000e+00 3176.0 2031.0 1145.0 2.0 1145.0 0.0 2029.0 0.639484 ... 1.000000 0.000985 1.000000 0.360744 0.361146 0.001968 0.001231 0.004904 0.003921 0.018848 282 25.1 1.000000e+00 3176.0 2031.0 1145.0 1.0 1145.0 0.0 2030.0 0.639484 ... 1.000000 0.000492 1.000000 0.360630 0.360831 0.000984 0.000615 0.002457 0.001965 0.013325 <p>283 rows \u00d7 25 columns</p>"},{"location":"charts/cluster_studio_dashboard.html","title":"cluster studio dashboard","text":""},{"location":"charts/cluster_studio_dashboard.html#cluster_studio_dashboard","title":"<code>cluster_studio_dashboard</code>","text":"<p>At a glance</p> <p>API Documentation: cluster_studio_dashboard()</p>"},{"location":"charts/cluster_studio_dashboard.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"substr(first_name,1,1)\"),\n        block_on(\"substr(surname, 1,1)\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n    retain_matching_columns=True,\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\ndf_predictions = linker.inference.predict(threshold_match_probability=0.2)\ndf_clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predictions, threshold_match_probability=0.5\n)\n\nlinker.visualisations.cluster_studio_dashboard(\n    df_predictions, df_clusters, \"img/cluster_studio.html\",\n    sampling_method=\"by_cluster_size\", overwrite=True\n)\n\n# You can view the scv.html file in your browser, or inline in a notebook as follows\nfrom IPython.display import IFrame\nIFrame(src=\"./img/cluster_studio.html\", width=\"100%\", height=1200)\n</code></pre>"},{"location":"charts/cluster_studio_dashboard.html#what-the-chart-shows","title":"What the chart shows","text":"<p>See here for a video explanation of the chart.</p>"},{"location":"charts/comparison_viewer_dashboard.html","title":"comparison viewer dashboard","text":""},{"location":"charts/comparison_viewer_dashboard.html#comparison_viewer_dashboard","title":"<code>comparison_viewer_dashboard</code>","text":"<p>At a glance</p> <p>API Documentation: comparison_viewer_dashboard()</p>"},{"location":"charts/comparison_viewer_dashboard.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"substr(first_name,1,1)\"),\n        block_on(\"substr(surname, 1,1)\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n    retain_matching_columns=True,\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\ndf_predictions = linker.inference.predict(threshold_match_probability=0.2)\n\nlinker.visualisations.comparison_viewer_dashboard(\n    df_predictions, \"img/scv.html\", overwrite=True\n)\n\n# You can view the scv.html file in your browser, or inline in a notebook as follows\nfrom IPython.display import IFrame\nIFrame(\n    src=\"./img/scv.html\", width=\"100%\", height=1200\n)\n</code></pre>"},{"location":"charts/comparison_viewer_dashboard.html#what-the-chart-shows","title":"What the chart shows","text":"<p>See the following video: An introduction to the Splink Comparison Viewer dashboard</p>"},{"location":"charts/completeness_chart.html","title":"completeness chart","text":""},{"location":"charts/completeness_chart.html#completeness_chart","title":"<code>completeness_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at which columns are populated across datasets. </p> <p>API Documentation: completeness_chart()</p> <p>What is needed to generate the chart? A <code>linker</code> with some data.</p>"},{"location":"charts/completeness_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>completeness_chart</code> shows the proportion of populated (non-null) values in the columns of multiple datasets.</p> What the chart tooltip shows <p></p> <p>The tooltip shows a number of values based on the panel that the user is hovering over, including:</p> <ul> <li>The dataset and column name</li> <li>The count and percentage of non-null values in the column for the relelvant dataset.</li> </ul>"},{"location":"charts/completeness_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Each panel represents the percentage of non-null values in a given dataset-column combination. The darker the panel, the lower the percentage of non-null values.</p>"},{"location":"charts/completeness_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>Only choose features that are sufficiently populated across all datasets in a linkage model.</p>"},{"location":"charts/completeness_chart.html#worked-example","title":"Worked Example","text":"<pre><code>from splink import splink_datasets, DuckDBAPI\nfrom splink.exploratory import completeness_chart\n\ndf = splink_datasets.fake_1000\n\n# Split a simple dataset into two, separate datasets which can be linked together.\ndf_l = df.sample(frac=0.5)\ndf_r = df.drop(df_l.index)\n\n\nchart = completeness_chart([df_l, df_r], db_api=DuckDBAPI())\nchart\n</code></pre>"},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html","title":"cumulative num comparisons from blocking rules chart","text":""},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html#cumulative_comparisons_to_be_scored_from_blocking_rules_chart","title":"<code>cumulative_comparisons_to_be_scored_from_blocking_rules_chart</code>","text":"<p>At a glance</p> <p>Useful for: Counting the number of comparisons generated by Blocking Rules.</p> <p>API Documentation: cumulative_comparisons_to_be_scored_from_blocking_rules_chart()</p> <p>What is needed to generate the chart? A <code>linker</code> with some data and a settings dictionary defining some Blocking Rules.</p>"},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>cumulative_comparisons_to_be_scored_from_blocking_rules_chart</code> shows the count of pairwise comparisons generated by a set of blocking rules.</p> What the chart tooltip shows <p></p> <p>The tooltip shows a number of statistics based on the bar that the user is hovering over, including:</p> <ul> <li>The blocking rule as an SQL statement.</li> <li>The number of additional pairwise comparisons generated by the blocking rule.</li> <li>The cumulative number of pairwise comparisons generated by the blocking rule and the previous blocking rules.</li> <li>The total number of possible pariwise comparisons (i.e. the Cartesian product). This represents the number of comparisons which would need to be evaluated if no blocking was implemented.</li> <li>The percentage of possible pairwise comparisons excluded by the blocking rule and the previous blocking rules (i.e. the Reduction Ratio). This is calculated as \\(1-\\frac{\\textsf{cumulative comparisons}}{\\textsf{total possible comparisons}}\\).</li> </ul>"},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Blocking rules are order dependent, therefore each bar in this chart shows the additional comparisons generated ontop of the previous blocking rules.</p> <p>For example, the chart above shows an exact match on <code>surname</code> generates an additional 1351 comparisons. If we reverse the order of the <code>surname</code> and <code>first_name</code> blocking rules:</p> <pre><code>blocking_rules_for_analysis = [\n    block_on(\"surname\"),\n    block_on(\"first_name\"),\n    block_on(\"email\"),\n]\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules_for_analysis,\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n)\n</code></pre> <p>The total number of comparisons is the same (3,664), but now 1,638 have been generated by the <code>surname</code> blocking rule. This suggests that 287 record comparisons have the same <code>first_name</code> and <code>surname</code>.</p>"},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>The main aim of this chart is to understand how many comparisons are generated by blocking rules that the Splink model will consider. The number of comparisons is the main primary driver of the amount of computational resource required for Splink model training, predictions etc. (i.e. how long things will take to run).</p> <p>The number of comparisons that are appropriate for a model varies. In general, if a model is taking hours to run (unless you are working with 100+ million records), it could be helpful to reduce the number of comparisons by defining more restrictive blocking rules.</p> <p>For instance, there are many people who could share the same <code>first_name</code> in the example above you may want to add an additonal requirement for a match on <code>dob</code> as well to reduce the number of records the model needs to consider.</p> <pre><code>blocking_rules_for_analysis = [\n    block_on(\"first_name\", \"dob\"),\n    block_on(\"surname\"),\n    block_on(\"email\"),\n]\n\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules_for_analysis,\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n)\n</code></pre> <p>Here, the total number of records pairs considered by the model have been reduced from 3,664 to 2,213.</p> <p>Further Reading</p> <p> For a deeper dive on blocking, please refer to the Blocking Topic Guides.</p> <p> For more on the blocking tools in Splink, please refer to the Blocking API documentation.</p>"},{"location":"charts/cumulative_comparisons_to_be_scored_from_blocking_rules_chart.html#worked-example","title":"Worked Example","text":""},{"location":"charts/m_u_parameters_chart.html","title":"m u parameters chart","text":""},{"location":"charts/m_u_parameters_chart.html#m_u_parameters_chart","title":"<code>m_u_parameters_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the m and u values generated by a Splink model.</p> <p>API Documentation: m_u_parameters_chart()</p> <p>What is needed to generate the chart? A trained Splink model.</p>"},{"location":"charts/m_u_parameters_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>m_u_parameters_chart</code> shows the results of a trained Splink model:</p> <ul> <li>The left chart shows the estimated m probabilities from the Splink model </li> <li>The right chart shows the estimated u probabilities from the Splink model.</li> </ul> <p>Each comparison within a model is represented in trained m and u values that have been estimated during the Splink model training for each comparison level.</p> What the chart tooltip shows"},{"location":"charts/m_u_parameters_chart.html#estimated-m-probability-tooltip","title":"Estimated m probability tooltip","text":"<p>The tooltip of the left chart shows information based on the comparison level bar that the user is hovering over, including:</p> <ul> <li>An explanation of the m probability for the comparison level.</li> <li>The name of the comparison and comparison level.</li> <li>The comparison level condition as an SQL statement.</li> <li>The m and u proability for the comparison level.</li> <li>The resulting bayes factor and match weight for the comparison level.</li> </ul>"},{"location":"charts/m_u_parameters_chart.html#estimated-u-probability-tooltip","title":"Estimated u probability tooltip","text":"<p>The tooltip of the right chart shows information based on the comparison level bar that the user is hovering over, including:</p> <ul> <li>An explanation of the u probability from the comparison level.</li> <li>The name of the comparison and comparison level.</li> <li>The comparison level condition as an SQL statement.</li> <li>The m and u proability for the comparison level.</li> <li>The resulting bayes factor and match weight for the comparison level.</li> </ul>"},{"location":"charts/m_u_parameters_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Each bar of the left chart shows the probability of a given comparison level when two records are a match. This can also be interpreted as the proportion of matching records which are allocated to the comparison level (as stated in the x axis label).</p> <p>Similarly, each bar of the right chart shows the probability of a given comparison level when two records are not a match. This can also be interpreted as the proportion of non-matching records which are allocated to the comparison level (as stated in the x axis label).</p> <p>Further Reading</p> <p>For a more comprehensive introduction to m and u probabilities, check out the Fellegi Sunter model topic guide.</p>"},{"location":"charts/m_u_parameters_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>As with the <code>match_weights_chart</code>, one of the most effective methods to assess a Splink model is to walk through each of the comparison levels of the <code>m_u_parameters_chart</code> and sense check the m and u probabilities that have been allocated by the model.</p> <p>For example, for all non-matching pairwise comparisons (which form the vast majority of all pairwise comparisons), it makes sense that the exact match and fuzzy levels occur very rarely. Furthermore, <code>dob</code> and <code>city</code> are lower cardinality features (i.e. have fewer possible values) than names so \"All other comparisons\" is less likely.</p> <p>If there are any m or u values that appear unusual, check out the values generated for each training session in the <code>parameter_estimate_comparisons_chart</code>.</p>"},{"location":"charts/m_u_parameters_chart.html#related-charts","title":"Related Charts","text":"<p><code>match weights chart</code></p> <p><code>parameter estimate comparisons chart</code></p>"},{"location":"charts/m_u_parameters_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\n\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nchart = linker.visualisations.m_u_parameters_chart()\nchart\n</code></pre> <pre><code>\n</code></pre>"},{"location":"charts/match_weights_chart.html","title":"match weights chart","text":""},{"location":"charts/match_weights_chart.html#match_weights_chart","title":"<code>match_weights_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the whole Splink model definition.</p> <p>API Documentation: match_weights_chart()</p> <p>What is needed to generate the chart? A trained Splink model.</p>"},{"location":"charts/match_weights_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>match_weights_chart</code> show the results of a trained Splink model. Each comparison within a model is represented in a bar chart, with a bar showing the evidence for two records being a match (i.e. match weight) for each comparison level.</p> What the chart tooltip shows <p></p> <p>The tooltip shows information based on the comparison level bar that the user is hovering over, including:</p> <ul> <li>The name of the comparison and comaprison level.</li> <li>The comparison level condition as an SQL statement.</li> <li>The m and u proability for the comparison level.</li> <li>The resulting bayes factor and match weight for the comparison level.</li> </ul>"},{"location":"charts/match_weights_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Each bar in the <code>match_weights_chart</code> shows the evidence of a match provided by each level in a Splink model (i.e. match weight). As such, the match weight chart provides a summary for the entire Splink model, as it shows the match weights for every type of comparison defined within the model.</p> <p>Any Splink score generated to compare two records will add up the evidence (i.e. match weights) for each comparison to come up with a final match weight score, which can then be converted into a probability of a match.</p> <p>The first bar chart is the Prior Match Weight, which is the . This can be thought of in the same way as the y-intercept of a simple regression model</p> <p>This chart is an aggregation of the <code>m_u_parameters_chart</code>. The match weight for a comparison level is simply \\(log_2(\\frac{m}{u})\\).</p>"},{"location":"charts/match_weights_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>Some heuristics to help assess Splink models with the <code>match_weights_chart</code>:</p>"},{"location":"charts/match_weights_chart.html#match-weights-gradually-reducing-within-a-comparison","title":"Match weights gradually reducing within a comparison","text":"<p>Comparison levels are order dependent, therefore they are constructed that the most \"similar\" levels come first and get gradually less \"similar\". As a result, we would generally expect that match weight will reduce as we go down the levels in a comparison. </p>"},{"location":"charts/match_weights_chart.html#very-similar-comparison-levels","title":"Very similar comparison levels","text":"<p>Comparisons are broken up into comparison levels to show different levels of similarity between records. As these levels are associated with different levels of similarity, we expect the amount of evidence (i.e. match weight) to vary between comparison levels. Two levels with the same match weight does not provide the model with any additional information which could make it perform better. </p> <p>Therefore, if two levels of a comparison return the same match weight, these should be combined into a single level.</p>"},{"location":"charts/match_weights_chart.html#very-different-comparison-levels","title":"Very different comparison levels","text":"<p>Levels that have a large variation between comparison levels have a significant impact on the model results. For example, looking at the <code>email</code> comparison in the chart above, the difference in match weight between an exact/fuzzy match and \"All other comparisons\" is &gt; 13, which is quite extreme. This generally happens with highly predictive features (e.g. email, national insurance number, social security number).</p> <p>If there are a number of highly predictive features, it is worth looking at simplifying your model using these more predictive features. In some cases, similar results may be obtained with a deterministic rather than a probabilistic linkage model.</p>"},{"location":"charts/match_weights_chart.html#logical-walk-through","title":"Logical Walk-through","text":"<p>One of the most effective methods to assess a splink model is to walk through each of the comparison levels of the <code>match_weights_chart</code> and sense check the amount of evidence (i.e. match weight) that has been allocated by the model.</p> <p>For example, in the chart above, we would expect records with the same <code>dob</code> to provide more evidence of a match that <code>first_name</code> or <code>surname</code>. Conversely, given how people can move location, we would expect that <code>city</code> would be less predictive than people's fixed, personally identifying characteristics like <code>surname</code>, <code>dob</code> etc.</p>"},{"location":"charts/match_weights_chart.html#anything-look-strange","title":"Anything look strange?","text":"<p>If anything still looks unusual, check out:</p> <ul> <li>the underlying m and u values in the <code>m_u_parameters_chart</code></li> <li>the values from each training session in the <code>parameter_estimate_comparisons_chart</code></li> </ul>"},{"location":"charts/match_weights_chart.html#related-charts","title":"Related Charts","text":"<p><code>m u parameters chart</code></p> <p><code>parameter estimate comparisons chart</code></p>"},{"location":"charts/match_weights_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\n\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nchart = linker.visualisations.match_weights_chart()\nchart\n</code></pre> <pre><code>\n</code></pre>"},{"location":"charts/parameter_estimate_comparisons_chart.html","title":"parameter estimate comparisons chart","text":""},{"location":"charts/parameter_estimate_comparisons_chart.html#parameter_estimate_comparisons_chart","title":"<code>parameter_estimate_comparisons_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the m and u value estimates across multiple Splink model training sessions.</p> <p>API Documentation: parameter_estimate_comparisons_chart()</p> <p>What is needed to generate the chart? A trained Splink model.</p>"},{"location":"charts/parameter_estimate_comparisons_chart.html#related-charts","title":"Related Charts","text":"<p><code>m u parameters chart</code></p> <p><code>match weights chart</code></p>"},{"location":"charts/parameter_estimate_comparisons_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"email\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nchart = linker.visualisations.parameter_estimate_comparisons_chart()\nchart\n</code></pre> <pre><code>\n</code></pre>"},{"location":"charts/profile_columns.html","title":"profile columns","text":""},{"location":"charts/profile_columns.html#profile_columns","title":"<code>profile_columns</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the distribution of values in columns. </p> <p>API Documentation: profile_columns()</p> <p>What is needed to generate the chart?: A <code>linker</code> with some data.</p>"},{"location":"charts/profile_columns.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>profile_columns</code> chart shows 3 charts for each selected column:</p> <ul> <li>The left chart shows the distribution of all values in the column.  It is a summary of the skew of value frequencies. The width of each \"step\" represents the proportion of all (non-null) values with a given count while the height of each \"step\" gives the count of the same given value.  </li> <li>The middle chart shows the counts of the ten most common values in the column. These correspond to the 10 leftmost \"steps\" in the left chart.</li> <li>The right chart shows the counts of the ten least common values in the column. These correspond to the 10 rightmost \"steps\" in the left chart.</li> </ul> What the chart tooltip shows"},{"location":"charts/profile_columns.html#left-chart","title":"Left chart:","text":"<p>This tooltip shows a number of statistics based on the column value of the \"step\" that the user is hovering over, including:</p> <ul> <li>The number of occurances of the given value.</li> <li>The precentile of the column value (excluding and including null values).</li> <li>The total number of rows in the column (excluding and including null values).</li> </ul>"},{"location":"charts/profile_columns.html#middle-and-right-chart","title":"Middle and right chart:","text":"<p>This tooltip shows a number of statistics based on the column value of the bar that the user is hovering over, including:</p> <ul> <li>The column value</li> <li>The count of the column value.</li> <li>The total number of rows in the column (excluding and including null values).</li> </ul>"},{"location":"charts/profile_columns.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>The distribution of values in your data is important for two main reasons:</p> <ol> <li> <p>Columns with higher cardinality (number of distinct values) are usually more useful for data linking. For instance, date of birth is a much stronger linkage variable than gender.</p> </li> <li> <p>The skew of values is important. If you have a <code>birth_place</code> column that has 1,000 distinct values, but 75% of them are London, this is much less useful for linkage than if the 1,000 values were equally distributed</p> </li> </ol>"},{"location":"charts/profile_columns.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>In an ideal world, all of the columns in datasets used for linkage would be high cardinality with a low skew (i.e. many distinct values that are evenly distributed). This is rarely the case with real-life datasets, but there a number of steps to extract the most predictive value, particularly with skewed data.</p>"},{"location":"charts/profile_columns.html#skewed-string-columns","title":"Skewed String Columns","text":"<p>Consider the skew of <code>birth_place</code> in our example:</p> <pre><code>profile_columns(df, column_expressions=\"birth_place\", db_api=DuckDBAPI())\n</code></pre> <p>Here we can see that \"london\" is the most common value, with many multiples more entires than the other values. In this case two records both having a <code>birth_place</code> of \"london\" gives far less evidence for a match than both having a rarer <code>birth_place</code> (e.g. \"felthorpe\").</p> <p>To take this skew into account, we can build Splink models with Term Frequency Adjustments. These adjustments will increase the amount of evidence for rare matching values and reduce the amount of evidence for common matching values.</p> <p>To understand how these work in more detail, check out the Term Frequency Adjustments Topic Guide</p>"},{"location":"charts/profile_columns.html#skewed-date-columns","title":"Skewed Date Columns","text":"<p>Dates can also be skewed, but tend to be dealt with slightly differently.</p> <p>Consider the <code>dob</code> column from our example:</p> <pre><code>profile_columns(df, column_expressions=\"dob\", db_api=DuckDBAPI())\n</code></pre> <p>Here we can see a large skew towards dates which are the 1st January. We can narrow down the profiling to show the distribution of month and day to explore this further:</p> <pre><code>profile_columns(df, column_expressions=\"substr(dob, 6, 10)\", db_api=DuckDBAPI())\n</code></pre> <p>Here we can see that over 35% of all dates in this dataset are the 1st January. This is fairly common in manually entered datasets where if only the year of birth is known, people will generally enter the 1st January for that year.</p>"},{"location":"charts/profile_columns.html#low-cardinality-columns","title":"Low cardinality columns","text":"<p>Unfortunately, there is not much that can be done to improve low cardinality data. Ultimately, they will provide some evidence of a match between records, but need to be used in conjunction with some more predictive, higher cardinality fields.</p>"},{"location":"charts/profile_columns.html#worked-example","title":"Worked Example","text":"<pre><code>from splink import splink_datasets, DuckDBAPI\nfrom splink.exploratory import profile_columns\n\ndf = splink_datasets.historical_50k\nprofile_columns(df, db_api=DuckDBAPI())\n</code></pre>"},{"location":"charts/template.html","title":"XXXXX_chart","text":""},{"location":"charts/template.html#xxxxx_chart","title":"<code>XXXXX_chart</code>","text":"<p>At a glance</p> <p>Useful for: </p> <p>API Documentation: XXXXXX_chart()</p> <p>What is needed to generate the chart? </p>"},{"location":"charts/template.html#worked-example","title":"Worked Example","text":"<pre><code>from splink.duckdb.linker import DuckDBLinker\nimport splink.duckdb.comparison_library as cl\nimport splink.duckdb.comparison_template_library as ctl\nfrom splink.duckdb.blocking_rule_library import block_on\nfrom splink.datasets import splink_datasets\nimport logging, sys\nlogging.disable(sys.maxsize)\n\ndf = splink_datasets.fake_1000\n\nsettings = {\n    \"link_type\": \"dedupe_only\",\n    \"blocking_rules_to_generate_predictions\": [\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    \"comparisons\": [\n        ctl.name_comparison(\"first_name\"),\n        ctl.name_comparison(\"surname\"),\n        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n        cl.exact_match(\"city\", term_frequency_adjustments=True),\n        ctl.email_comparison(\"email\", include_username_fuzzy_level=False),\n    ],\n}\n\nlinker = DuckDBLinker(df, settings)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on([\"first_name\", \"surname\"])\n\nlinker.training.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n</code></pre>"},{"location":"charts/template.html#what-the-chart-shows","title":"What the chart shows","text":"What the chart tooltip shows"},{"location":"charts/template.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":""},{"location":"charts/template.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":""},{"location":"charts/tf_adjustment_chart.html","title":"tf adjustment chart","text":""},{"location":"charts/tf_adjustment_chart.html#tf_adjustment_chart","title":"<code>tf_adjustment_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the impact of Term Frequency Adjustments on Match Weights.</p> <p>API Documentation: tf_adjustment_chart()</p> <p>What is needed to generate the chart?: A trained Splink model, including comparisons with term frequency adjustments.</p>"},{"location":"charts/tf_adjustment_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>tf_adjustment_chart</code> shows the impact of Term Frequency Adjustments on the Match Weight of a comparison. It is made up of two charts for each selected comparison:</p> <ul> <li>The left chart shows the match weight for two records with a matching <code>first_name</code> including a term frequency adjustment. The black horizontal line represents the base match weight (i.e. with no term frequency adjustment applied). By default this chart contains the 10 most frequent and 10 least frequent values in a comparison as well as any values assigned in the <code>vals_to_include</code> parameter.</li> <li>The right chart shows the distribution of match weights across all of the values of <code>first_name</code>.</li> </ul> What the tooltip shows"},{"location":"charts/tf_adjustment_chart.html#left-chart","title":"Left chart","text":"<p>The tooltip shows a number of statistics based on the column value of the point theat the user is hovering over, including:</p> <ul> <li>The column value</li> <li>The base match weight (i.e. with no term frequency adjustment) for a match on the column.</li> <li>The term frequency adjustment for the column value.</li> <li>The final match weight (i.e. the combined base match weight and term frequency adjustment)</li> </ul>"},{"location":"charts/tf_adjustment_chart.html#right-chart","title":"Right chart","text":"<p>The tooltip shows a number of statistics based on the bar that the user is hovering over, including:</p> <ul> <li>The final match weight bucket (in steps of 0.5).</li> <li>The number of records with a final match weight in the final match weight bucket.</li> </ul>"},{"location":"charts/tf_adjustment_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>The most common terms (on the left of the first chart) will have a negative term frequency adjustment and the values on the chart and represent the lowest match weight for a match for the selected comparison. Conversely, the least common terms (on the right of the first chart) will have a positive term frequency adjustment and the values on the chart represent the highest match weight for a match for the selected comparison.</p> <p>Given that the first chart only shows the most and least frequently occuring values, the second chart is provided to show the distribution of final match weights (including term frequency adjustments) across all values in the dataset.</p>"},{"location":"charts/tf_adjustment_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>There are no direct actions that need to be taken as a result of this chart. It is intended to give the user an indication of the size of the impact of Term Frequency Adjustments on comparisons, as seen in the Waterfall Chart.</p>"},{"location":"charts/tf_adjustment_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]).configure(\n            term_frequency_adjustments=True\n        ),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nchart = linker.visualisations.tf_adjustment_chart(\n    \"first_name\", vals_to_include=[\"Robert\", \"Grace\"]\n)\nchart\n</code></pre>"},{"location":"charts/threshold_selection_tool_from_labels_table.html","title":"threshold selection tool","text":""},{"location":"charts/threshold_selection_tool_from_labels_table.html#threshold_selection_tool_from_labels_table","title":"<code>threshold_selection_tool_from_labels_table</code>","text":"<p>At a glance</p> <p>Useful for: Selecting an optimal match weight threshold for generating linked clusters.</p> <p>API Documentation: accuracy_chart_from_labels_table()</p> <p>What is needed to generate the chart? A <code>linker</code> with some data and a corresponding labelled dataset</p>"},{"location":"charts/threshold_selection_tool_from_labels_table.html#what-the-chart-shows","title":"What the chart shows","text":"<p>For a given match weight threshold, a record pair with a score above this threshold will be labelled a match and below the threshold will be labelled a non-match. Lowering the threshold to the extreme ensures many more matches are generated - this maximises the True Positives (high recall) but at the expense of some False Positives (low precision).</p> <p>You can then see the effect on the confusion matrix of raising the match threshold. As more predicted matches become non-matches at the higher threshold, True Positives become False Negatives, but False Positives become True Negatives.</p> <p>This demonstrates the trade-off between Type 1 (FP) and Type 2 (FN) errors when selecting a match threshold, or precision vs recall.</p> <p>This chart adds further context to accuracy_analysis_from_labels_table showing:</p> <ul> <li>the relationship between match weight and match probability</li> <li>various accuracy metrics comparing the Splink scores against clerical labels</li> <li>the confusion matrix of the predictions and the labels</li> </ul>"},{"location":"charts/threshold_selection_tool_from_labels_table.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>Precision can be maximised by increasing the match threshold (reducing false positives).</p> <p>Recall can be maximised by decreasing the match threshold (reducing false negatives). </p> <p>Additional metrics can be used to find the optimal compromise between these two, looking for the threshold at which peak accuracy is achieved. </p>"},{"location":"charts/threshold_selection_tool_from_labels_table.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>Having identified an optimal match weight threshold, this can be applied when generating linked clusters using cluster_pairwise_predictions_at_thresholds().</p>"},{"location":"charts/threshold_selection_tool_from_labels_table.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\nfrom splink.datasets import splink_dataset_labels\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"substr(first_name,1,1)\"),\n        block_on(\"substr(surname, 1,1)\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api)\n\nlinker.training.estimate_probability_two_random_records_match(\n    [block_on(\"first_name\", \"surname\")], recall=0.7\n)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\ndf_labels = splink_dataset_labels.fake_1000_labels\nlabels_table = linker.table_management.register_labels_table(df_labels)\n\nchart = linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"threshold_selection\", add_metrics=[\"f1\"]\n)\nchart\n</code></pre>"},{"location":"charts/unlinkables_chart.html","title":"unlinkables chart","text":""},{"location":"charts/unlinkables_chart.html#unlinkables_chart","title":"<code>unlinkables_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at how many records have insufficient information to be linked to themselves.</p> <p>API Documentation: unlinkables_chart()</p> <p>What is needed to generate the chart? A trained Splink model</p>"},{"location":"charts/unlinkables_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>unlinkables_chart</code> shows the proportion of records with insufficient information to be matched to themselves at differing match thresholds.</p> What the chart tooltip shows <p></p> <p>This tooltip shows a number of statistics based on the match weight of the selected point of the line, including:</p> <ul> <li>The chosen match weight and corresponding match probability.</li> <li>The proportion of records of records that cannot be linked to themselves given the chosen match weight threshold for a match.</li> </ul>"},{"location":"charts/unlinkables_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>This chart gives an indication of both data quality and/or model predictiveness within a Splink model. If a high proportion of records are not linkable to themselves at a low match threshold (e.g. 0 match weight/50% probability) we can conclude that either/or:</p> <ul> <li>the data quality is low enough such that a significant proportion of records are unable to be linked to themselves</li> <li>the parameters of the Splink model are such that features have not been assigned enough weight, and therefore will not perform well</li> </ul> <p>This chart also gives an indication of the number of False Negatives (i.e. missed links) at a given threshold, assuming sufficient data quality. For example:</p> <ul> <li>we know that a record should be linked to itself, so seeing that a match weight \\(\\approx\\) 10 gives 16% of records unable to link to themselves</li> <li>exact matches generally provide the strongest matches, therefore, we can expect that any \"fuzzy\" matches to have lower match scores. As a result, we can deduce that the propoertion of False Negatives will be higher than 16%.</li> </ul>"},{"location":"charts/unlinkables_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>If the level of unlinkable records is extremely high at low match weight thresholds, you have a poorly performing model. This may be an issue that can be resolved by tweaking the models comparisons, but if the poor performance is primarily down to poor data quality, there is very little that can be done to improve the model.</p> <p>When interpretted as an indicator of False Negatives, this chart can be used to establish an upper bound for match weight, depending on the propensity for False Negatives in the particular use case.</p>"},{"location":"charts/unlinkables_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.7]),\n        cl.JaroAtThresholds(\"surname\", [0.9, 0.7]),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nchart = linker.evaluation.unlinkables_chart()\nchart\n</code></pre>"},{"location":"charts/waterfall_chart.html","title":"waterfall chart","text":""},{"location":"charts/waterfall_chart.html#waterfall_chart","title":"<code>waterfall_chart</code>","text":"<p>At a glance</p> <p>Useful for: Looking at the breakdown of the match weight for a pair of records.</p> <p>API Documentation: waterfall_chart()</p> <p>What is needed to generate the chart? A trained Splink model</p>"},{"location":"charts/waterfall_chart.html#what-the-chart-shows","title":"What the chart shows","text":"<p>The <code>waterfall_chart</code> shows the amount of evidence of a match that is provided by each comparison for a pair of records. Each bar represents a comparison and the corresponding amount of evidence (i.e. match weight) of a match for the pair of values displayed above the bar.</p> What the chart tooltip shows <p></p> <p>The tooltip contains information based on the bar that the user is hovering over, including:</p> <ul> <li>The comparison column (or columns)</li> <li>The column values from the pair of records being compared</li> <li>The comparison level as a label, SQL statement and the corresponding comparison vector value</li> <li>The bayes factor (i.e. how many times more likely is a match based on this evidence)</li> <li>The match weight for the comparison level</li> <li>The cumulative match probability from the chosen comparison and all of the previous comparisons.</li> </ul>"},{"location":"charts/waterfall_chart.html#how-to-interpret-the-chart","title":"How to interpret the chart","text":"<p>The first bar (labelled \"Prior\") is the match weight if no additional knowledge of features is taken into account, and can be thought of as similar to the y-intercept in a simple regression.</p> <p>Each subsequent bar shows the match weight for a comparison. These bars can be positive or negative depending on whether the given comparison gives positive or negative evidence for the two records being a match.</p> <p>Additional bars are added for comparisons with term frequency adjustments. For example, the chart above has term frequency adjustments for <code>first_name</code> so there is an extra <code>tf_first_name</code> bar showing how the frequency of a given name impacts the amount of evidence for the two records being a match.</p> <p>The final bar represents total match weight for the pair of records. This match weight can also be translated into a final match probablility, and the corresponding match probability is shown on the right axis (note the logarithmic scale).</p>"},{"location":"charts/waterfall_chart.html#actions-to-take-as-a-result-of-the-chart","title":"Actions to take as a result of the chart","text":"<p>This chart is useful for spot checking pairs of records to see if the Splink model is behaving as expected.</p> <p>If a pair of records look like they are incorrectly being assigned as a match/non-match, it is a sign that the Splink model is not working optimally. If this is the case, it is worth revisiting the model training step. </p> <p>Some common scenarios include:</p> <ul> <li> <p>If a comparison isn't capturing a specific edge case (e.g. fuzzy match), add a comparison level to capture this case and retrain the model.</p> </li> <li> <p>If the match weight for a comparison is looking unusual, refer to the <code>match_weights_chart</code> to see the match weight in context with the rest of the comparison levels within that comparison. If it is still looking unusual, you can dig deeper with the <code>parameter_estimate_comparisons_chart</code> to see if the model training runs are consistent. If there is a lot of variation between model training sessions, this can suggest some instability in the model. In this case, try some different model training rules and/or comparison levels.</p> </li> <li> <p>If the \"Prior\" match weight is too small or large compared to the match weight provided by the comparisons, try some different determininstic rules and recall inputs to the <code>estimate_probability_two_records_match</code> function.</p> </li> <li> <p>If you are working with a model with term frequency adjustments and want to dig deeper into the impact of term frequency on the model as a whole (i.e. not just for a single pairwise comparison), check out the <code>tf_adjustment_chart</code>.</p> </li> </ul>"},{"location":"charts/waterfall_chart.html#worked-example","title":"Worked Example","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.NameComparison(\"first_name\").configure(term_frequency_adjustments=True),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"year\", \"month\"],\n            datetime_thresholds=[1, 1],\n        ),\n        cl.ExactMatch(\"city\"),\n        cl.EmailComparison(\"email\", include_username_fuzzy_level=False),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n    retain_matching_columns=True,\n)\n\nlinker = Linker(df, settings, DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n\ndf_predictions = linker.inference.predict(threshold_match_probability=0.2)\nrecords_to_view = df_predictions.as_record_dict(limit=5)\n\nchart = linker.visualisations.waterfall_chart(records_to_view, filter_nulls=False)\nchart\n</code></pre>"},{"location":"demos/demo_settings/model_create_h50k.html","title":"Model create h50k","text":"<pre><code>#!conda install -c conda-forge splink=4.0 --yes\n</code></pre> <pre><code>from splink import splink_datasets\n\ndf = splink_datasets.historical_50k\n</code></pre> <pre><code>from splink import DuckDBAPI\ndb_api = DuckDBAPI()\n</code></pre> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules = [\n    block_on(\"substr(first_name,1,3)\", \"substr(surname,1,4)\"),\n    block_on(\"surname\", \"dob\"),\n    block_on(\"first_name\", \"dob\"),\n    block_on(\"postcode_fake\", \"first_name\"),\n    block_on(\"postcode_fake\", \"surname\"),\n    block_on(\"dob\", \"birth_place\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"dob\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"first_name\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"surname\"),\n    block_on(\"substr(first_name,1,2)\", \"substr(surname,1,2)\", \"substr(dob,1,4)\"),\n]\n</code></pre> <pre><code>import splink.comparison_library as cl\n\nfrom splink import Linker, SettingsCreator\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.NameComparison(\"first_name\").configure(term_frequency_adjustments=False),\n        cl.NameComparison(\"surname\").configure(term_frequency_adjustments=False),\n        cl.DateOfBirthComparison(\"dob\", input_is_string=True),\n        cl.PostcodeComparison(\"postcode_fake\"),\n        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=False),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=False),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\nlinker = Linker(df, settings, db_api=db_api)\n</code></pre> <pre><code>linker.training.estimate_probability_two_random_records_match(\n    [\n        \"l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob\",\n        \"substr(l.first_name,1,2) = substr(r.first_name,1,2) and l.surname = r.surname and substr(l.postcode_fake,1,2) = substr(r.postcode_fake,1,2)\",\n        \"l.dob = r.dob and l.postcode_fake = r.postcode_fake\",\n    ],\n    recall=0.6,\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000136.\nThis means that amongst all possible pairwise record comparisons, one in 7,362.31 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 173,728.33 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=5e6)\n</code></pre> <pre><code>----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - dob (no m values are trained).\n    - postcode_fake (no m values are trained).\n    - birth_place (no m values are trained).\n    - occupation (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = block_on(\"first_name\", \"surname\")\ntraining_session_names = (\n    linker.training.estimate_parameters_using_expectation_maximisation(\n        training_blocking_rule, estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\n(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n    - surname\n\nIteration 1: Largest change in params was -0.515 in probability_two_random_records_match\nIteration 2: Largest change in params was -0.0362 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0135 in the m_probability of birth_place, level `Exact match on birth_place`\nIteration 4: Largest change in params was -0.00654 in the m_probability of birth_place, level `All other comparisons`\nIteration 5: Largest change in params was 0.00378 in the m_probability of birth_place, level `Exact match on birth_place`\nIteration 6: Largest change in params was -0.00234 in the m_probability of birth_place, level `All other comparisons`\nIteration 7: Largest change in params was -0.00148 in the m_probability of birth_place, level `All other comparisons`\nIteration 8: Largest change in params was -0.00095 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 9: Largest change in params was -0.000633 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 10: Largest change in params was -0.000419 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 11: Largest change in params was -0.000277 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 12: Largest change in params was -0.000183 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 13: Largest change in params was -0.00012 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 14: Largest change in params was -7.92e-05 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\n\nEM converged after 14 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = block_on(\"dob\")\ntraining_session_dob = (\n    linker.training.estimate_parameters_using_expectation_maximisation(\n        training_blocking_rule, estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nIteration 1: Largest change in params was -0.36 in the m_probability of first_name, level `Exact match on first_name`\nIteration 2: Largest change in params was 0.0382 in the m_probability of first_name, level `All other comparisons`\nIteration 3: Largest change in params was 0.00824 in the m_probability of surname, level `All other comparisons`\nIteration 4: Largest change in params was 0.00266 in the m_probability of surname, level `All other comparisons`\nIteration 5: Largest change in params was 0.000806 in the m_probability of surname, level `All other comparisons`\nIteration 6: Largest change in params was 0.00024 in the m_probability of surname, level `All other comparisons`\nIteration 7: Largest change in params was 7.1e-05 in the m_probability of surname, level `All other comparisons`\n\nEM converged after 7 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code>linker.misc.save_model_to_json(\"model_h50k.json\", overwrite=True)\n</code></pre> <pre><code>{'link_type': 'dedupe_only',\n 'probability_two_random_records_match': 0.00013582694460587586,\n 'retain_matching_columns': True,\n 'retain_intermediate_calculation_columns': True,\n 'additional_columns_to_retain': [],\n 'sql_dialect': 'duckdb',\n 'linker_uid': '66au8ius',\n 'em_convergence': 0.0001,\n 'max_iterations': 25,\n 'bayes_factor_column_prefix': 'bf_',\n 'term_frequency_adjustment_column_prefix': 'tf_',\n 'comparison_vector_value_column_prefix': 'gamma_',\n 'unique_id_column_name': 'unique_id',\n 'source_dataset_column_name': 'source_dataset',\n 'blocking_rules_to_generate_predictions': [{'blocking_rule': '(SUBSTR(l.first_name, 1, 3) = SUBSTR(r.first_name, 1, 3)) AND (SUBSTR(l.surname, 1, 4) = SUBSTR(r.surname, 1, 4))',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(l.\"surname\" = r.\"surname\") AND (l.\"dob\" = r.\"dob\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(l.\"first_name\" = r.\"first_name\") AND (l.\"dob\" = r.\"dob\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(l.\"postcode_fake\" = r.\"postcode_fake\") AND (l.\"first_name\" = r.\"first_name\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(l.\"postcode_fake\" = r.\"postcode_fake\") AND (l.\"surname\" = r.\"surname\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(l.\"dob\" = r.\"dob\") AND (l.\"birth_place\" = r.\"birth_place\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(SUBSTR(l.postcode_fake, 1, 3) = SUBSTR(r.postcode_fake, 1, 3)) AND (l.\"dob\" = r.\"dob\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(SUBSTR(l.postcode_fake, 1, 3) = SUBSTR(r.postcode_fake, 1, 3)) AND (l.\"first_name\" = r.\"first_name\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(SUBSTR(l.postcode_fake, 1, 3) = SUBSTR(r.postcode_fake, 1, 3)) AND (l.\"surname\" = r.\"surname\")',\n   'sql_dialect': 'duckdb'},\n  {'blocking_rule': '(SUBSTR(l.first_name, 1, 2) = SUBSTR(r.first_name, 1, 2)) AND (SUBSTR(l.surname, 1, 2) = SUBSTR(r.surname, 1, 2)) AND (SUBSTR(l.dob, 1, 4) = SUBSTR(r.dob, 1, 4))',\n   'sql_dialect': 'duckdb'}],\n 'comparisons': [{'output_column_name': 'first_name',\n   'comparison_levels': [{'sql_condition': '\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL',\n     'label_for_charts': 'first_name is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n     'label_for_charts': 'Exact match on first_name',\n     'm_probability': 0.5457057743059716,\n     'u_probability': 0.011951030823329812,\n     'tf_adjustment_column': 'first_name',\n     'tf_adjustment_weight': 1.0},\n    {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92',\n     'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.92',\n     'm_probability': 0.06098051520443211,\n     'u_probability': 0.0018262673367931644},\n    {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88',\n     'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.88',\n     'm_probability': 0.07502792175772721,\n     'u_probability': 0.003353844214458144},\n    {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.7',\n     'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.7',\n     'm_probability': 0.120309986619356,\n     'u_probability': 0.020885448595733304},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.19797580211251312,\n     'u_probability': 0.9619834090296856}],\n   'comparison_description': 'NameComparison'},\n  {'output_column_name': 'surname',\n   'comparison_levels': [{'sql_condition': '\"surname_l\" IS NULL OR \"surname_r\" IS NULL',\n     'label_for_charts': 'surname is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"surname_l\" = \"surname_r\"',\n     'label_for_charts': 'Exact match on surname',\n     'm_probability': 0.7714400787402513,\n     'u_probability': 0.0006788109515158729,\n     'tf_adjustment_column': 'surname',\n     'tf_adjustment_weight': 1.0},\n    {'sql_condition': 'jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.92',\n     'label_for_charts': 'Jaro-Winkler distance of surname &gt;= 0.92',\n     'm_probability': 0.09368190481882498,\n     'u_probability': 0.0002900130152182439},\n    {'sql_condition': 'jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.88',\n     'label_for_charts': 'Jaro-Winkler distance of surname &gt;= 0.88',\n     'm_probability': 0.039136395099805245,\n     'u_probability': 0.00048319241644015245},\n    {'sql_condition': 'jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.7',\n     'label_for_charts': 'Jaro-Winkler distance of surname &gt;= 0.7',\n     'm_probability': 0.023569512976655334,\n     'u_probability': 0.017232968503952374},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.07217210836446314,\n     'u_probability': 0.9813150151128733}],\n   'comparison_description': 'NameComparison'},\n  {'output_column_name': 'dob',\n   'comparison_levels': [{'sql_condition': 'try_strptime(\"dob_l\", \\'%Y-%m-%d\\') IS NULL OR try_strptime(\"dob_r\", \\'%Y-%m-%d\\') IS NULL',\n     'label_for_charts': 'transformed dob is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"dob_l\" = \"dob_r\"',\n     'label_for_charts': 'Exact match on date of birth',\n     'm_probability': 0.6796640528638345,\n     'u_probability': 0.0023542362733926883},\n    {'sql_condition': 'damerau_levenshtein(\"dob_l\", \"dob_r\") &lt;= 1',\n     'label_for_charts': 'DamerauLevenshtein distance &lt;= 1',\n     'm_probability': 0.2736730864202431,\n     'u_probability': 0.02425500685606134},\n    {'sql_condition': 'ABS(EPOCH(try_strptime(\"dob_l\", \\'%Y-%m-%d\\')) - EPOCH(try_strptime(\"dob_r\", \\'%Y-%m-%d\\'))) &lt;= 2629800.0',\n     'label_for_charts': 'Abs date difference &lt;= 1 month',\n     'm_probability': 0.002677966995147039,\n     'u_probability': 0.0023411035361826224},\n    {'sql_condition': 'ABS(EPOCH(try_strptime(\"dob_l\", \\'%Y-%m-%d\\')) - EPOCH(try_strptime(\"dob_r\", \\'%Y-%m-%d\\'))) &lt;= 31557600.0',\n     'label_for_charts': 'Abs date difference &lt;= 1 year',\n     'm_probability': 0.006199700352635373,\n     'u_probability': 0.03354178334846173},\n    {'sql_condition': 'ABS(EPOCH(try_strptime(\"dob_l\", \\'%Y-%m-%d\\')) - EPOCH(try_strptime(\"dob_r\", \\'%Y-%m-%d\\'))) &lt;= 315576000.0',\n     'label_for_charts': 'Abs date difference &lt;= 10 year',\n     'm_probability': 0.02726057331431288,\n     'u_probability': 0.25042855211572257},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.010524620053827111,\n     'u_probability': 0.6870793178701791}],\n   'comparison_description': 'DateOfBirthComparison'},\n  {'output_column_name': 'postcode_fake',\n   'comparison_levels': [{'sql_condition': '\"postcode_fake_l\" IS NULL OR \"postcode_fake_r\" IS NULL',\n     'label_for_charts': 'postcode_fake is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"postcode_fake_l\" = \"postcode_fake_r\"',\n     'label_for_charts': 'Exact match on full postcode',\n     'm_probability': 0.6753757141159644,\n     'u_probability': 0.00014903079407788038},\n    {'sql_condition': 'NULLIF(regexp_extract(\"postcode_fake_l\", \\'^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]\\', 0), \\'\\') = NULLIF(regexp_extract(\"postcode_fake_r\", \\'^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]\\', 0), \\'\\')',\n     'label_for_charts': 'Exact match on sector',\n     'm_probability': 0.09395110908506221,\n     'u_probability': 0.00028996941834157726},\n    {'sql_condition': 'NULLIF(regexp_extract(\"postcode_fake_l\", \\'^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?\\', 0), \\'\\') = NULLIF(regexp_extract(\"postcode_fake_r\", \\'^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?\\', 0), \\'\\')',\n     'label_for_charts': 'Exact match on district',\n     'm_probability': 0.04225883501370074,\n     'u_probability': 0.00048215845142843657},\n    {'sql_condition': 'NULLIF(regexp_extract(\"postcode_fake_l\", \\'^[A-Za-z]{1,2}\\', 0), \\'\\') = NULLIF(regexp_extract(\"postcode_fake_r\", \\'^[A-Za-z]{1,2}\\', 0), \\'\\')',\n     'label_for_charts': 'Exact match on area',\n     'm_probability': 0.09785854822786318,\n     'u_probability': 0.011052555271205699},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.09055579355740942,\n     'u_probability': 0.9880262860649464}],\n   'comparison_description': 'PostcodeComparison'},\n  {'output_column_name': 'birth_place',\n   'comparison_levels': [{'sql_condition': '\"birth_place_l\" IS NULL OR \"birth_place_r\" IS NULL',\n     'label_for_charts': 'birth_place is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"birth_place_l\" = \"birth_place_r\"',\n     'label_for_charts': 'Exact match on birth_place',\n     'm_probability': 0.8345399212327826,\n     'u_probability': 0.005228068621252938},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.1654600787672175,\n     'u_probability': 0.9947719313787471}],\n   'comparison_description': 'ExactMatch'},\n  {'output_column_name': 'occupation',\n   'comparison_levels': [{'sql_condition': '\"occupation_l\" IS NULL OR \"occupation_r\" IS NULL',\n     'label_for_charts': 'occupation is NULL',\n     'is_null_level': True},\n    {'sql_condition': '\"occupation_l\" = \"occupation_r\"',\n     'label_for_charts': 'Exact match on occupation',\n     'm_probability': 0.8982446653774181,\n     'u_probability': 0.037284666827814034},\n    {'sql_condition': 'ELSE',\n     'label_for_charts': 'All other comparisons',\n     'm_probability': 0.10175533462258204,\n     'u_probability': 0.9627153331721859}],\n   'comparison_description': 'ExactMatch'}]}\n</code></pre>"},{"location":"demos/examples/examples_index.html","title":"Introduction","text":"","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#example-notebooks","title":"Example Notebooks","text":"<p>This section provides a series of examples to help you get started with Splink. You can find the underlying notebooks in the demos folder of the Splink repository.</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#duckdb-examples","title":"DuckDB examples","text":"","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#entity-type-persons","title":"Entity type: Persons","text":"<p> Deduplicating 50,000 records of realistic data based on historical persons</p> <p> Using the <code>link_only</code> setting to link, but not dedupe, two datasets</p> <p> Real time record linkage</p> <p> Accuracy analysis and ROC charts using a ground truth (cluster) column</p> <p> Estimating m probabilities from pairwise labels</p> <p> Deduplicating 50,000 records with Deterministic Rules</p> <p> Deduplicating the febrl3 dataset. Note this dataset comes from febrl, as referenced in A.2 here and replicated here. </p> <p> Linking the febrl4 datasets. As above, these datasets are from febrl, replicated here. </p> <p> Cookbook of various Splink techniques</p> <p> Interactive comparison playground</p> <p> Investigating Bias in a Splink Model</p> <p> Linking the pseudopeople Census and ACS datasets. These datasets are generated using pseudopeople. </p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#entity-type-financial-transactions","title":"Entity type: Financial transactions","text":"<p> Linking financial transactions</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#entity-type-businesses","title":"Entity type: Businesses","text":"<p> Matching business rates data with Companies House data</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#pyspark-examples","title":"PySpark examples","text":"<p> Deduplication of a small dataset using PySpark. Entity type is persons.</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#athena-examples","title":"Athena examples","text":"<p> Deduplicating 50,000 records of realistic data based on historical persons</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/examples_index.html#sqlite-examples","title":"SQLite examples","text":"<p> Deduplicating 50,000 records of realistic data based on historical persons</p>","tags":["Examples","DuckDB","Spark","Athena"]},{"location":"demos/examples/athena/deduplicate_50k_synthetic.html","title":"Deduplicate 50k rows historical persons","text":""},{"location":"demos/examples/athena/deduplicate_50k_synthetic.html#linking-a-dataset-of-real-historical-persons","title":"Linking a dataset of real historical persons","text":"<p>In this example, we deduplicate a more realistic dataset. The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced.</p> <p>Create a boto3 session to be used within the linker</p> <pre><code>import boto3\n\nboto3_session = boto3.Session(region_name=\"eu-west-1\")\n</code></pre>"},{"location":"demos/examples/athena/deduplicate_50k_synthetic.html#athenalinker-setup","title":"AthenaLinker Setup","text":"<p>To work nicely with Athena, you need to outline various filepaths, buckets and the database(s) you wish to interact with.</p> <p>The AthenaLinker has three required inputs: * input_table_or_tables - the input table to use for linking. This can either be a table in a database or a pandas dataframe * output_database - the database to output all of your splink tables to. * output_bucket - the s3 bucket you wish any parquet files produced by splink to be output to.</p> <p>and two optional inputs: * output_filepath - the s3 filepath to output files to. This is an extension of output_bucket and dictate the full filepath your files will be output to. * input_table_aliases - the name of your table within your database, should you choose to use a pandas df as an input.</p> <pre><code># Set the output bucket and the additional filepath to write outputs to\n############################################\n# EDIT THESE BEFORE ATTEMPTING TO RUN THIS #\n############################################\n\nfrom splink.backends.athena import AthenaAPI\n\n\nbucket = \"MYTESTBUCKET\"\ndatabase = \"MYTESTDATABASE\"\nfilepath = \"MYTESTFILEPATH\"  # file path inside of your bucket\n\naws_filepath = f\"s3://{bucket}/{filepath}\"\ndb_api = AthenaAPI(\n    boto3_session,\n    output_bucket=bucket,\n    output_database=database,\n    output_filepath=filepath,\n)\n</code></pre> <pre><code>import splink.comparison_library as cl\nfrom splink import block_on\n\nfrom splink import Linker, SettingsCreator, splink_datasets\n\ndf = splink_datasets.historical_50k\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"surname\", \"dob\"),\n    ],\n    comparisons=[\n        cl.ExactMatch(\"first_name\").configure(term_frequency_adjustments=True),\n        cl.LevenshteinAtThresholds(\"surname\", [1, 3]),\n        cl.LevenshteinAtThresholds(\"dob\", [1, 2]),\n        cl.LevenshteinAtThresholds(\"postcode_fake\", [1, 2]),\n        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n</code></pre> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(df, db_api, column_expressions=[\"first_name\", \"substr(surname,1,2)\"])\n</code></pre> <pre><code>from splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\nfrom splink import block_on\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    db_api=db_api,\n    blocking_rules=[block_on(\"first_name\", \"surname\"), block_on(\"surname\", \"dob\")],\n    link_type=\"dedupe_only\",\n)\n</code></pre> <pre><code>import splink.comparison_library as cl\n\n\nfrom splink import Linker, SettingsCreator\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"surname\", \"dob\"),\n    ],\n    comparisons=[\n        cl.ExactMatch(\"first_name\").configure(term_frequency_adjustments=True),\n        cl.LevenshteinAtThresholds(\"surname\", [1, 3]),\n        cl.LevenshteinAtThresholds(\"dob\", [1, 2]),\n        cl.LevenshteinAtThresholds(\"postcode_fake\", [1, 2]),\n        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\nlinker = Linker(df, settings, db_api=db_api)\n</code></pre> <pre><code>linker.training.estimate_probability_two_random_records_match(\n    [\n        block_on(\"first_name\", \"surname\", \"dob\"),\n        block_on(\"substr(first_name,1,2)\", \"surname\", \"substr(postcode_fake, 1,2)\"),\n        block_on(\"dob\", \"postcode_fake\"),\n    ],\n    recall=0.6,\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000136.\nThis means that amongst all possible pairwise record comparisons, one in 7,362.31 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 173,728.33 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=5e6)\n</code></pre> <pre><code>----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - dob (no m values are trained).\n    - postcode_fake (no m values are trained).\n    - birth_place (no m values are trained).\n    - occupation (no m values are trained).\n</code></pre> <pre><code>blocking_rule = block_on(\"first_name\", \"surname\")\ntraining_session_names = (\n    linker.training.estimate_parameters_using_expectation_maximisation(blocking_rule)\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\n(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n    - surname\n\nIteration 1: Largest change in params was -0.526 in probability_two_random_records_match\nIteration 2: Largest change in params was -0.0321 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0109 in the m_probability of birth_place, level `Exact match on birth_place`\nIteration 4: Largest change in params was -0.00341 in the m_probability of birth_place, level `All other comparisons`\nIteration 5: Largest change in params was -0.00116 in the m_probability of dob, level `All other comparisons`\nIteration 6: Largest change in params was -0.000547 in the m_probability of dob, level `All other comparisons`\nIteration 7: Largest change in params was -0.00029 in the m_probability of dob, level `All other comparisons`\nIteration 8: Largest change in params was -0.000169 in the m_probability of dob, level `All other comparisons`\nIteration 9: Largest change in params was -0.000105 in the m_probability of dob, level `All other comparisons`\nIteration 10: Largest change in params was -6.87e-05 in the m_probability of dob, level `All other comparisons`\n\nEM converged after 10 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n</code></pre> <pre><code>blocking_rule = block_on(\"dob\")\ntraining_session_dob = (\n    linker.training.estimate_parameters_using_expectation_maximisation(blocking_rule)\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\n\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nIteration 1: Largest change in params was -0.355 in the m_probability of first_name, level `Exact match on first_name`\nIteration 2: Largest change in params was -0.0383 in the m_probability of first_name, level `Exact match on first_name`\nIteration 3: Largest change in params was 0.00531 in the m_probability of postcode_fake, level `All other comparisons`\nIteration 4: Largest change in params was 0.00129 in the m_probability of postcode_fake, level `All other comparisons`\nIteration 5: Largest change in params was 0.00034 in the m_probability of surname, level `All other comparisons`\nIteration 6: Largest change in params was 8.9e-05 in the m_probability of surname, level `All other comparisons`\n\nEM converged after 6 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre> <pre><code>df_predict = linker.inference.predict()\ndf_e = df_predict.as_pandas_dataframe(limit=5)\ndf_e\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name ... bf_birth_place bf_tf_adj_birth_place occupation_l occupation_r gamma_occupation tf_occupation_l tf_occupation_r bf_occupation bf_tf_adj_occupation match_key 0 27.149493 1.000000 Q2296770-1 Q2296770-12 thomas rhomas 0 0.028667 0.000059 0.455194 ... 160.713933 4.179108 politician politician 1 0.088932 0.088932 22.916859 0.441273 1 1 1.627242 0.755454 Q2296770-1 Q2296770-15 thomas clifford, 0 0.028667 0.000020 0.455194 ... 0.154550 1.000000 politician &lt;NA&gt; -1 0.088932 NaN 1.000000 1.000000 1 2 29.206505 1.000000 Q2296770-1 Q2296770-3 thomas tom 0 0.028667 0.012948 0.455194 ... 160.713933 4.179108 politician politician 1 0.088932 0.088932 22.916859 0.441273 1 3 13.783027 0.999929 Q2296770-1 Q2296770-7 thomas tom 0 0.028667 0.012948 0.455194 ... 0.154550 1.000000 politician &lt;NA&gt; -1 0.088932 NaN 1.000000 1.000000 1 4 29.206505 1.000000 Q2296770-2 Q2296770-3 thomas tom 0 0.028667 0.012948 0.455194 ... 160.713933 4.179108 politician politician 1 0.088932 0.088932 22.916859 0.441273 1 <p>5 rows \u00d7 38 columns</p> <p>You can also view rows in this dataset as a waterfall chart as follows:</p> <pre><code>records_to_plot = df_e.to_dict(orient=\"records\")\nlinker.visualisations.waterfall_chart(records_to_plot, filter_nulls=False)\n</code></pre> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict, threshold_match_probability=0.95\n)\n</code></pre> <pre><code>Completed iteration 1, root rows count 641\nCompleted iteration 2, root rows count 187\nCompleted iteration 3, root rows count 251\nCompleted iteration 4, root rows count 75\nCompleted iteration 5, root rows count 23\nCompleted iteration 6, root rows count 30\nCompleted iteration 7, root rows count 34\nCompleted iteration 8, root rows count 30\nCompleted iteration 9, root rows count 9\nCompleted iteration 10, root rows count 5\nCompleted iteration 11, root rows count 0\n</code></pre> <pre><code>linker.visualisations.cluster_studio_dashboard(\n    df_predict,\n    clusters,\n    \"dashboards/50k_cluster.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\nfrom IPython.display import IFrame\n\nIFrame(src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200)\n</code></pre> <p> </p>"},{"location":"demos/examples/duckdb/accuracy_analysis_from_labels_column.html","title":"Evaluation from ground truth column","text":""},{"location":"demos/examples/duckdb/accuracy_analysis_from_labels_column.html#evaluation-when-you-have-fully-labelled-data","title":"Evaluation when you have fully labelled data","text":"<p>In this example, our data contains a fully-populated ground-truth column called <code>cluster</code> that enables us to perform accuracy analysis of the final model</p> <p> </p> <pre><code>from splink import splink_datasets\n\ndf = splink_datasets.fake_1000\ndf.head(2)\n</code></pre> unique_id first_name surname dob city email cluster 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 1 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 <pre><code>from splink import SettingsCreator, Linker, block_on, DuckDBAPI\n\nimport splink.comparison_library as cl\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n        block_on(\"dob\"),\n        block_on(\"email\"),\n    ],\n    comparisons=[\n        cl.ForenameSurnameComparison(\"first_name\", \"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n</code></pre> <pre><code>db_api = DuckDBAPI()\nlinker = Linker(df, settings, db_api=db_api)\ndeterministic_rules = [\n    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.surname = r.surname and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n    \"l.email = r.email\",\n]\n\nlinker.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.7\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.00333.\nThis means that amongst all possible pairwise record comparisons, one in 300.13 are expected to match.  With 499,500 total possible comparisons, we expect a total of around 1,664.29 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6, seed=5)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name_surname (no m values are trained).\n    - dob (no m values are trained).\n    - city (no m values are trained).\n    - email (no m values are trained).\n</code></pre> <pre><code>session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"dob\"), estimate_without_term_frequencies=True\n)\nsession_email = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"email\"), estimate_without_term_frequencies=True\n)\nsession_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"first_name\", \"surname\"), estimate_without_term_frequencies=True\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name_surname\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nWARNING:\nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was -0.751 in the m_probability of first_name_surname, level `(Exact match on first_name) AND (Exact match on surname)`\nIteration 2: Largest change in params was 0.196 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0536 in probability_two_random_records_match\nIteration 4: Largest change in params was 0.0189 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.00731 in probability_two_random_records_match\nIteration 6: Largest change in params was 0.0029 in probability_two_random_records_match\nIteration 7: Largest change in params was 0.00116 in probability_two_random_records_match\nIteration 8: Largest change in params was 0.000469 in probability_two_random_records_match\nIteration 9: Largest change in params was 0.000189 in probability_two_random_records_match\nIteration 10: Largest change in params was 7.62e-05 in probability_two_random_records_match\n\nEM converged after 10 iterations\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - dob (no m values are trained).\n    - email (some m values are not trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"email\" = r.\"email\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name_surname\n    - dob\n    - city\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - email\n\nIteration 1: Largest change in params was -0.438 in the m_probability of dob, level `Exact match on dob`\nIteration 2: Largest change in params was 0.122 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0286 in probability_two_random_records_match\nIteration 4: Largest change in params was 0.01 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.00448 in probability_two_random_records_match\nIteration 6: Largest change in params was 0.00237 in probability_two_random_records_match\nIteration 7: Largest change in params was 0.0014 in probability_two_random_records_match\nIteration 8: Largest change in params was 0.000893 in probability_two_random_records_match\nIteration 9: Largest change in params was 0.000597 in probability_two_random_records_match\nIteration 10: Largest change in params was 0.000413 in probability_two_random_records_match\nIteration 11: Largest change in params was 0.000292 in probability_two_random_records_match\nIteration 12: Largest change in params was 0.000211 in probability_two_random_records_match\nIteration 13: Largest change in params was 0.000154 in probability_two_random_records_match\nIteration 14: Largest change in params was 0.000113 in probability_two_random_records_match\nIteration 15: Largest change in params was 8.4e-05 in probability_two_random_records_match\n\nEM converged after 15 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - email (some m values are not trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\n(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name_surname\n\nWARNING:\nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was 0.473 in probability_two_random_records_match\nIteration 2: Largest change in params was 0.0452 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.00766 in probability_two_random_records_match\nIteration 4: Largest change in params was 0.00135 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.00025 in probability_two_random_records_match\nIteration 6: Largest change in params was 0.000468 in the m_probability of email, level `All other comparisons`\nIteration 7: Largest change in params was 0.00776 in the m_probability of email, level `All other comparisons`\nIteration 8: Largest change in params was 0.00992 in the m_probability of email, level `All other comparisons`\nIteration 9: Largest change in params was 0.00277 in probability_two_random_records_match\nIteration 10: Largest change in params was 0.000972 in probability_two_random_records_match\nIteration 11: Largest change in params was 0.000337 in probability_two_random_records_match\nIteration 12: Largest change in params was 0.000118 in probability_two_random_records_match\nIteration 13: Largest change in params was 4.14e-05 in probability_two_random_records_match\n\nEM converged after 13 iterations\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - email (some m values are not trained).\n</code></pre> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\", output_type=\"table\"\n).as_pandas_dataframe(limit=5)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre> truth_threshold match_probability total_clerical_labels p n tp tn fp fn P_rate ... precision recall specificity npv accuracy f1 f2 f0_5 p4 phi 0 -17.8 0.000004 499500.0 2031.0 497469.0 1650.0 495130.0 2339.0 381.0 0.004066 ... 0.413638 0.812408 0.995298 0.999231 0.994555 0.548173 0.681086 0.458665 0.707466 0.577474 1 -17.7 0.000005 499500.0 2031.0 497469.0 1650.0 495225.0 2244.0 381.0 0.004066 ... 0.423729 0.812408 0.995489 0.999231 0.994745 0.556962 0.686470 0.468564 0.714769 0.584558 2 -17.1 0.000007 499500.0 2031.0 497469.0 1650.0 495311.0 2158.0 381.0 0.004066 ... 0.433298 0.812408 0.995662 0.999231 0.994917 0.565165 0.691418 0.477901 0.721512 0.591197 3 -17.0 0.000008 499500.0 2031.0 497469.0 1650.0 495354.0 2115.0 381.0 0.004066 ... 0.438247 0.812408 0.995748 0.999231 0.995003 0.569358 0.693919 0.482710 0.724931 0.594601 4 -16.9 0.000008 499500.0 2031.0 497469.0 1650.0 495386.0 2083.0 381.0 0.004066 ... 0.442004 0.812408 0.995813 0.999231 0.995067 0.572519 0.695792 0.486353 0.727497 0.597173 <p>5 rows \u00d7 25 columns</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\"cluster\", output_type=\"roc\")\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\",\n    output_type=\"threshold_selection\",\n    threshold_match_probability=0.5,\n    add_metrics=[\"f1\"],\n)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre> <pre><code># Plot some false positives\nlinker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\", include_false_negatives=True, include_false_positives=True\n).as_pandas_dataframe(limit=5)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre> clerical_match_score found_by_blocking_rules match_weight match_probability unique_id_l unique_id_r surname_l surname_r first_name_l first_name_r ... email_l email_r gamma_email tf_email_l tf_email_r bf_email bf_tf_adj_email cluster_l cluster_r match_key 0 1.0 False -15.568945 0.000021 452 454 Daves Reuben None Davies ... rd@lewis.com idlewrs.cocm 0 0.003802 0.001267 0.01099 1.0 115 115 4 1 1.0 False -14.884057 0.000033 715 717 Joes Jones None Mia ... None mia.j63@martinez.biz -1 NaN 0.005070 1.00000 1.0 182 182 4 2 1.0 False -14.884057 0.000033 626 628 Davidson None geeorGe Geeorge ... None gdavidson@johnson-brown.com -1 NaN 0.005070 1.00000 1.0 158 158 4 3 1.0 False -13.761589 0.000072 983 984 Milller Miller Jessica aessicJ ... None jessica.miller@johnson.com -1 NaN 0.007605 1.00000 1.0 246 246 4 4 1.0 True -11.637585 0.000314 594 595 Kik Kiirk Grace Grace ... gk@frey-robinson.org rgk@frey-robinon.org 0 0.001267 0.001267 0.01099 1.0 146 146 0 <p>5 rows \u00d7 38 columns</p> <pre><code>records = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\", include_false_negatives=True, include_false_positives=True\n).as_record_dict(limit=5)\n\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre>"},{"location":"demos/examples/duckdb/deduplicate_50k_synthetic.html","title":"Deduplicate 50k rows historical persons","text":""},{"location":"demos/examples/duckdb/deduplicate_50k_synthetic.html#linking-a-dataset-of-real-historical-persons","title":"Linking a dataset of real historical persons","text":"<p>In this example, we deduplicate a more realistic dataset. The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced.</p> <p> </p> <pre><code>from splink import splink_datasets\n\ndf = splink_datasets.historical_50k\n</code></pre> <pre><code>df.head()\n</code></pre> unique_id cluster full_name first_and_surname first_name surname dob birth_place postcode_fake gender occupation 0 Q2296770-1 Q2296770 thomas clifford, 1st baron clifford of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 1 Q2296770-2 Q2296770 thomas of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 2 Q2296770-3 Q2296770 tom 1st baron clifford of chudleigh tom chudleigh tom chudleigh 1630-08-01 devon tq13 8df male politician 3 Q2296770-4 Q2296770 thomas 1st chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8hu None politician 4 Q2296770-5 Q2296770 thomas clifford, 1st baron chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df None politician <pre><code>from splink import DuckDBAPI\nfrom splink.exploratory import profile_columns\n\ndb_api = DuckDBAPI()\nprofile_columns(df, db_api, column_expressions=[\"first_name\", \"substr(surname,1,2)\"])\n</code></pre> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules = [\n    block_on(\"substr(first_name,1,3)\", \"substr(surname,1,4)\"),\n    block_on(\"surname\", \"dob\"),\n    block_on(\"first_name\", \"dob\"),\n    block_on(\"postcode_fake\", \"first_name\"),\n    block_on(\"postcode_fake\", \"surname\"),\n    block_on(\"dob\", \"birth_place\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"dob\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"first_name\"),\n    block_on(\"substr(postcode_fake,1,3)\", \"surname\"),\n    block_on(\"substr(first_name,1,2)\", \"substr(surname,1,2)\", \"substr(dob,1,4)\"),\n]\n\ndb_api = DuckDBAPI()\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules,\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n)\n</code></pre> <pre><code>import splink.comparison_library as cl\n\nfrom splink import Linker, SettingsCreator\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.ForenameSurnameComparison(\n            \"first_name\",\n            \"surname\",\n            forename_surname_concat_col_name=\"first_name_surname_concat\",\n        ),\n        cl.DateOfBirthComparison(\n            \"dob\", input_is_string=True\n        ),\n        cl.PostcodeComparison(\"postcode_fake\"),\n        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n# Needed to apply term frequencies to first+surname comparison\ndf[\"first_name_surname_concat\"] = df[\"first_name\"] + \" \" + df[\"surname\"]\nlinker = Linker(df, settings, db_api=db_api)\n</code></pre> <pre><code>linker.training.estimate_probability_two_random_records_match(\n    [\n        block_on(\"first_name\", \"surname\", \"dob\"),\n        block_on(\"substr(first_name,1,2)\", \"surname\", \"substr(postcode_fake,1,2)\"),\n        block_on(\"dob\", \"postcode_fake\"),\n    ],\n    recall=0.6,\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000136.\nThis means that amongst all possible pairwise record comparisons, one in 7,362.31 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 173,728.33 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=5e6)\n</code></pre> <pre><code>----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name_surname (no m values are trained).\n    - dob (no m values are trained).\n    - postcode_fake (no m values are trained).\n    - birth_place (no m values are trained).\n    - occupation (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = block_on(\"first_name\", \"surname\")\ntraining_session_names = (\n    linker.training.estimate_parameters_using_expectation_maximisation(\n        training_blocking_rule, estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\n(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name_surname\n\nIteration 1: Largest change in params was 0.248 in probability_two_random_records_match\nIteration 2: Largest change in params was -0.0935 in the m_probability of postcode_fake, level `Exact match on full postcode`\nIteration 3: Largest change in params was -0.0239 in the m_probability of birth_place, level `Exact match on birth_place`\nIteration 4: Largest change in params was 0.00984 in the m_probability of birth_place, level `All other comparisons`\nIteration 5: Largest change in params was -0.00477 in the m_probability of birth_place, level `Exact match on birth_place`\nIteration 6: Largest change in params was 0.00274 in the m_probability of birth_place, level `All other comparisons`\nIteration 7: Largest change in params was 0.00189 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 8: Largest change in params was 0.00129 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 9: Largest change in params was 0.000863 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 10: Largest change in params was 0.000576 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 11: Largest change in params was 0.000383 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 12: Largest change in params was 0.000254 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 13: Largest change in params was 0.000169 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 14: Largest change in params was 0.000112 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\nIteration 15: Largest change in params was 7.43e-05 in the m_probability of dob, level `Abs date difference &lt;= 10 year`\n\nEM converged after 15 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name_surname (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = block_on(\"dob\")\ntraining_session_dob = (\n    linker.training.estimate_parameters_using_expectation_maximisation(\n        training_blocking_rule, estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name_surname\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nIteration 1: Largest change in params was -0.472 in the m_probability of first_name_surname, level `Exact match on first_name_surname_concat`\nIteration 2: Largest change in params was 0.0536 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 3: Largest change in params was 0.0179 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 4: Largest change in params was 0.00547 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 5: Largest change in params was 0.00169 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 6: Largest change in params was 0.00053 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 7: Largest change in params was 0.000168 in the m_probability of first_name_surname, level `All other comparisons`\nIteration 8: Largest change in params was 5.38e-05 in the m_probability of first_name_surname, level `All other comparisons`\n\nEM converged after 8 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <p>The final match weights can be viewed in the match weights chart:</p> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre> <pre><code>df_predict = linker.inference.predict()\ndf_e = df_predict.as_pandas_dataframe(limit=5)\ndf_e\n</code></pre> <pre><code>Blocking time: 0.66 seconds\nPredict time: 1.32 seconds\n</code></pre> match_weight match_probability unique_id_l unique_id_r surname_l surname_r first_name_l first_name_r first_name_surname_concat_l first_name_surname_concat_r ... bf_birth_place bf_tf_adj_birth_place occupation_l occupation_r gamma_occupation tf_occupation_l tf_occupation_r bf_occupation bf_tf_adj_occupation match_key 0 11.155625 0.999562 Q19654778-17 Q19654778-4 chattock chattock richard ritchie richard chattock ritchie chattock ... 0.164723 1.000000 photographer photographer 1 0.018862 0.018862 23.537422 2.020099 4 1 21.080818 1.000000 Q2331144-2 Q2331144-9 caine caine sir hall sir caine hall caine ... 165.631265 20.031894 novelist writer 0 0.007078 0.053264 0.107239 1.000000 4 2 20.499240 0.999999 Q3377781-1 Q3377781-4 meux meux hedworth admiral hedworth meux admiral meux ... 165.631265 0.094897 politician politician 1 0.088932 0.088932 23.537422 0.428451 4 3 20.499240 0.999999 Q3377781-2 Q3377781-4 meux meux hedworth admiral hedworth meux admiral meux ... 165.631265 0.094897 politician politician 1 0.088932 0.088932 23.537422 0.428451 4 4 20.499240 0.999999 Q3377781-3 Q3377781-4 meux meux hedworth admiral hedworth meux admiral meux ... 165.631265 0.094897 politician politician 1 0.088932 0.088932 23.537422 0.428451 4 <p>5 rows \u00d7 42 columns</p> <p>You can also view rows in this dataset as a waterfall chart as follows:</p> <pre><code>records_to_plot = df_e.to_dict(orient=\"records\")\nlinker.visualisations.waterfall_chart(records_to_plot, filter_nulls=False)\n</code></pre> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict, threshold_match_probability=0.95\n)\n</code></pre> <pre><code>Completed iteration 1, num representatives needing updating: 810\nCompleted iteration 2, num representatives needing updating: 183\nCompleted iteration 3, num representatives needing updating: 59\nCompleted iteration 4, num representatives needing updating: 6\nCompleted iteration 5, num representatives needing updating: 1\nCompleted iteration 6, num representatives needing updating: 0\n</code></pre> <pre><code>from IPython.display import IFrame\n\nlinker.visualisations.cluster_studio_dashboard(\n    df_predict,\n    clusters,\n    \"dashboards/50k_cluster.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\n\nIFrame(src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200)\n</code></pre> <p> </p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\", output_type=\"accuracy\", match_weight_round_to_nearest=0.02\n)\n</code></pre> <pre><code>Blocking time: 1.37 seconds\nPredict time: 1.38 seconds\n</code></pre> <pre><code>records = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\",\n    threshold_match_probability=0.999,\n    include_false_negatives=False,\n    include_false_positives=True,\n).as_record_dict()\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code>Blocking time: 1.80 seconds\nPredict time: 0.59 seconds\n</code></pre> <pre><code># Some of the false negatives will be because they weren't detected by the blocking rules\nrecords = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\",\n    threshold_match_probability=0.5,\n    include_false_negatives=True,\n    include_false_positives=False,\n).as_record_dict(limit=50)\n\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code>Blocking time: 1.08 seconds\nPredict time: 0.48 seconds\n</code></pre>"},{"location":"demos/examples/duckdb/deterministic_dedupe.html","title":"Deterministic dedupe","text":""},{"location":"demos/examples/duckdb/deterministic_dedupe.html#linking-a-dataset-of-real-historical-persons-with-deterrministic-rules","title":"Linking a dataset of real historical persons with Deterrministic Rules","text":"<p>While Splink is primarily a tool for probabilistic records linkage, it includes functionality to perform deterministic (i.e. rules based) linkage.</p> <p>Significant work has gone into optimising the performance of rules based matching, so Splink is likely to be significantly faster than writing the basic SQL by hand.</p> <p>In this example, we deduplicate a 50k row dataset based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced. The probabilistic dedupe of the same dataset can be found at <code>Deduplicate 50k rows historical persons</code>.</p> <p> </p> <pre><code># Uncomment and run this cell if you're running in Google Colab.\n# !pip install splink\n</code></pre> <pre><code>import pandas as pd\n\nfrom splink import splink_datasets\n\npd.options.display.max_rows = 1000\ndf = splink_datasets.historical_50k\ndf.head()\n</code></pre> unique_id cluster full_name first_and_surname first_name surname dob birth_place postcode_fake gender occupation 0 Q2296770-1 Q2296770 thomas clifford, 1st baron clifford of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 1 Q2296770-2 Q2296770 thomas of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 2 Q2296770-3 Q2296770 tom 1st baron clifford of chudleigh tom chudleigh tom chudleigh 1630-08-01 devon tq13 8df male politician 3 Q2296770-4 Q2296770 thomas 1st chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8hu None politician 4 Q2296770-5 Q2296770 thomas clifford, 1st baron chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df None politician <p>When defining the settings object, specity your deterministic rules in the <code>blocking_rules_to_generate_predictions</code> key.</p> <p>For a deterministic linkage, the linkage methodology is based solely on these rules, so there is no need to define <code>comparisons</code> nor any other parameters required for model training in a probabilistic model.</p> <p>Prior to running the linkage, it's usually a good idea to check how many record comparisons will be generated by your deterministic rules:</p> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\ndb_api = DuckDBAPI()\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=[\n        block_on(\"first_name\", \"surname\", \"dob\"),\n        block_on(\"surname\", \"dob\", \"postcode_fake\"),\n        block_on(\"first_name\", \"dob\", \"occupation\"),\n    ],\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n)\n</code></pre> <pre><code>from splink import Linker, SettingsCreator\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\", \"dob\"),\n        block_on(\"surname\", \"dob\", \"postcode_fake\"),\n        block_on(\"first_name\", \"dob\", \"occupation\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\nlinker = Linker(df, settings, db_api=db_api)\n</code></pre> <p>The results of the linkage can be viewed with the <code>deterministic_link</code> function.</p> <pre><code>df_predict = linker.inference.deterministic_link()\ndf_predict.as_pandas_dataframe().head()\n</code></pre> unique_id_l unique_id_r occupation_l occupation_r first_name_l first_name_r dob_l dob_r surname_l surname_r postcode_fake_l postcode_fake_r match_key 0 Q55455287-12 Q55455287-2 None writer jaido jaido 1836-01-01 1836-01-01 morata morata ta4 2ug ta4 2uu 0 1 Q55455287-12 Q55455287-3 None writer jaido jaido 1836-01-01 1836-01-01 morata morata ta4 2ug ta4 2uu 0 2 Q55455287-12 Q55455287-4 None writer jaido jaido 1836-01-01 1836-01-01 morata morata ta4 2ug ta4 2sz 0 3 Q55455287-12 Q55455287-5 None None jaido jaido 1836-01-01 1836-01-01 morata morata ta4 2ug ta4 2ug 0 4 Q55455287-12 Q55455287-6 None writer jaido jaido 1836-01-01 1836-01-01 morata morata ta4 2ug None 0 <p>Which can be used to generate clusters.</p> <p>Note, for deterministic linkage, each comparison has been assigned a match probability of 1, so to generate clusters, set <code>threshold_match_probability=1</code> in the <code>cluster_pairwise_predictions_at_threshold</code> function.</p> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict\n)\n</code></pre> <pre><code>Completed iteration 1, root rows count 94\n\n\nCompleted iteration 2, root rows count 10\n\n\nCompleted iteration 3, root rows count 0\n</code></pre> <pre><code>clusters.as_pandas_dataframe(limit=5)\n</code></pre> cluster_id unique_id cluster full_name first_and_surname first_name surname dob birth_place postcode_fake gender occupation __splink_salt 0 Q16025107-1 Q5497940-9 Q5497940 frederick hall frederick hall frederick hall 1855-01-01 bristol, city of bs11 9pn None None 0.002739 1 Q1149445-1 Q1149445-9 Q1149445 earl egerton earl egerton earl egerton 1800-01-01 westminster w1d 2hf None None 0.991459 2 Q20664532-1 Q21466387-2 Q21466387 harry brooker harry brooker harry brooker 1848-01-01 plymouth pl4 9hx male painter 0.506127 3 Q1124636-1 Q1124636-12 Q1124636 tom stapleton tom stapleton tom stapleton 1535-01-01 None bn6 9na male theologian 0.612694 4 Q18508292-1 Q21466711-4 Q21466711 harry s0ence harry s0ence harry s0ence 1860-01-01 london se1 7pb male painter 0.488917 <p>These results can then be passed into the <code>Cluster Studio Dashboard</code>.</p> <pre><code>linker.visualisations.cluster_studio_dashboard(\n    df_predict,\n    clusters,\n    \"dashboards/50k_deterministic_cluster.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\nfrom IPython.display import IFrame\n\nIFrame(src=\"./dashboards/50k_deterministic_cluster.html\", width=\"100%\", height=1200)\n</code></pre> <p> </p>"},{"location":"demos/examples/duckdb/febrl3.html","title":"Febrl3 Dedupe","text":""},{"location":"demos/examples/duckdb/febrl3.html#deduplicating-the-febrl3-dataset","title":"Deduplicating the febrl3 dataset","text":"<p>See A.2 here and here for the source of this data</p> <p> </p> <pre><code>from splink.datasets import splink_datasets\n\ndf = splink_datasets.febrl3\n</code></pre> <pre><code>df = df.rename(columns=lambda x: x.strip())\n\ndf[\"cluster\"] = df[\"rec_id\"].apply(lambda x: \"-\".join(x.split(\"-\")[:2]))\n\ndf[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\ndf[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()\n\ndf.head(2)\n</code></pre> rec_id given_name surname street_number address_1 address_2 suburb postcode state date_of_birth soc_sec_id cluster 0 rec-1496-org mitchell green 7 wallaby place delmar cleveland 2119 sa 19560409 1804974 rec-1496 1 rec-552-dup-3 harley mccarthy 177 pridhamstreet milton marsden 3165 nsw 19080419 6089216 rec-552 <pre><code>df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\ndf[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()\n</code></pre> <pre><code>df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\ndf[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()\n</code></pre> <pre><code>from splink import DuckDBAPI, Linker, SettingsCreator\n\n# TODO:  Allow missingness to be analysed without a linker\nsettings = SettingsCreator(\n    unique_id_column_name=\"rec_id\",\n    link_type=\"dedupe_only\",\n)\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\n</code></pre> <p>It's usually a good idea to perform exploratory analysis on your data so you understand what's in each column and how often it's missing:</p> <pre><code>from splink.exploratory import completeness_chart\n\ncompleteness_chart(df, db_api=DuckDBAPI())\n</code></pre> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(df, db_api=DuckDBAPI(), column_expressions=[\"given_name\", \"surname\"])\n</code></pre> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules = [\n    block_on(\"soc_sec_id\"),\n    block_on(\"given_name\"),\n    block_on(\"surname\"),\n    block_on(\"date_of_birth\"),\n    block_on(\"postcode\"),\n]\n\ndb_api = DuckDBAPI()\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules,\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n    unique_id_column_name=\"rec_id\",\n)\n</code></pre> <pre><code>import splink.comparison_library as cl\n\nfrom splink import Linker\n\nsettings = SettingsCreator(\n    unique_id_column_name=\"rec_id\",\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.NameComparison(\"given_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"date_of_birth\",\n            input_is_string=True,\n            datetime_format=\"%Y%m%d\",\n        ),\n        cl.DamerauLevenshteinAtThresholds(\"soc_sec_id\", [2]),\n        cl.ExactMatch(\"street_number\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"postcode\").configure(term_frequency_adjustments=True),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\n</code></pre> <pre><code>from splink import block_on\n\ndeterministic_rules = [\n    block_on(\"soc_sec_id\"),\n    block_on(\"given_name\", \"surname\", \"date_of_birth\"),\n    \"l.given_name = r.surname and l.surname = r.given_name and l.date_of_birth = r.date_of_birth\",\n]\n\nlinker.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.9\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000528.\nThis means that amongst all possible pairwise record comparisons, one in 1,893.56 are expected to match.  With 12,497,500 total possible comparisons, we expect a total of around 6,600.00 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\n\n\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - given_name (no m values are trained).\n    - surname (no m values are trained).\n    - date_of_birth (some u values are not trained, no m values are trained).\n    - soc_sec_id (no m values are trained).\n    - street_number (no m values are trained).\n    - postcode (no m values are trained).\n</code></pre> <pre><code>em_blocking_rule_1 = block_on(\"date_of_birth\")\nsession_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    em_blocking_rule_1\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"date_of_birth\" = r.\"date_of_birth\"\n\nParameter estimates will be made for the following comparison(s):\n    - given_name\n    - surname\n    - soc_sec_id\n    - street_number\n    - postcode\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - date_of_birth\n\nIteration 1: Largest change in params was -0.376 in the m_probability of surname, level `Exact match on surname`\nIteration 2: Largest change in params was 0.0156 in the m_probability of surname, level `All other comparisons`\nIteration 3: Largest change in params was 0.000699 in the m_probability of postcode, level `All other comparisons`\nIteration 4: Largest change in params was -3.77e-05 in the m_probability of postcode, level `Exact match on postcode`\n\nEM converged after 4 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - date_of_birth (some u values are not trained, no m values are trained).\n</code></pre> <pre><code>em_blocking_rule_2 = block_on(\"postcode\")\nsession_postcode = linker.training.estimate_parameters_using_expectation_maximisation(\n    em_blocking_rule_2\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"postcode\" = r.\"postcode\"\n\nParameter estimates will be made for the following comparison(s):\n    - given_name\n    - surname\n    - date_of_birth\n    - soc_sec_id\n    - street_number\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - postcode\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 month' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 10 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was 0.0681 in probability_two_random_records_match\nIteration 2: Largest change in params was -0.00185 in the m_probability of date_of_birth, level `Exact match on date_of_birth`\nIteration 3: Largest change in params was -5.7e-05 in the m_probability of date_of_birth, level `Exact match on date_of_birth`\n\nEM converged after 3 iterations\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - date_of_birth (some u values are not trained, some m values are not trained).\n</code></pre> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>results = linker.inference.predict(threshold_match_probability=0.2)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\", match_weight_round_to_nearest=0.1, output_type=\"accuracy\"\n)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre> <pre><code>pred_errors_df = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\"\n).as_pandas_dataframe()\nlen(pred_errors_df)\npred_errors_df.head()\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre> clerical_match_score found_by_blocking_rules match_weight match_probability rec_id_l rec_id_r given_name_l given_name_r gamma_given_name tf_given_name_l ... postcode_l postcode_r gamma_postcode tf_postcode_l tf_postcode_r bf_postcode bf_tf_adj_postcode cluster_l cluster_r match_key 0 1.0 False -27.805731 4.262268e-09 rec-993-dup-1 rec-993-dup-3 westbrook jake 0 0.0004 ... 2704 2074 0 0.0002 0.0014 0.230173 1.0 rec-993 rec-993 5 1 1.0 False -27.805731 4.262268e-09 rec-829-dup-0 rec-829-dup-2 wilde kyra 0 0.0002 ... 3859 3595 0 0.0004 0.0006 0.230173 1.0 rec-829 rec-829 5 2 1.0 False -19.717877 1.159651e-06 rec-829-dup-0 rec-829-dup-1 wilde kyra 0 0.0002 ... 3859 3889 0 0.0004 0.0002 0.230173 1.0 rec-829 rec-829 5 3 1.0 True -15.453190 2.229034e-05 rec-721-dup-0 rec-721-dup-1 mikhaili elly 0 0.0008 ... 4806 4860 0 0.0008 0.0014 0.230173 1.0 rec-721 rec-721 2 4 1.0 True -12.931781 1.279648e-04 rec-401-dup-1 rec-401-dup-3 whitbe alexa-ose 0 0.0002 ... 3040 3041 0 0.0020 0.0004 0.230173 1.0 rec-401 rec-401 0 <p>5 rows \u00d7 45 columns</p> <p>The following chart seems to suggest that, where the model is making errors, it's because the data is corrupted beyond recognition and no reasonable linkage model could find these matches</p> <pre><code>records = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\"\n).as_record_dict(limit=10)\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre>"},{"location":"demos/examples/duckdb/febrl4.html","title":"Febrl4 link-only","text":""},{"location":"demos/examples/duckdb/febrl4.html#linking-the-febrl4-datasets","title":"Linking the febrl4 datasets","text":"<p>See A.2 here and here for the source of this data.</p> <p>It consists of two datasets, A and B, of 5000 records each, with each record in dataset A having a corresponding record in dataset B. The aim will be to capture as many of those 5000 true links as possible, with minimal false linkages.</p> <p>It is worth noting that we should not necessarily expect to capture all links. There are some links that although we know they do correspond to the same person, the data is so mismatched between them that we would not reasonably expect a model to link them, and indeed should a model do so may indicate that we have overengineered things using our knowledge of true links, which will not be a helpful reference in situations where we attempt to link unlabelled data, as will usually be the case.</p> <p> </p>"},{"location":"demos/examples/duckdb/febrl4.html#exploring-data-and-defining-model","title":"Exploring data and defining model","text":"<p>Firstly let's read in the data and have a little look at it</p> <pre><code>from splink import splink_datasets\n\ndf_a = splink_datasets.febrl4a\ndf_b = splink_datasets.febrl4b\n\n\ndef prepare_data(data):\n    data = data.rename(columns=lambda x: x.strip())\n    data[\"cluster\"] = data[\"rec_id\"].apply(lambda x: \"-\".join(x.split(\"-\")[:2]))\n    data[\"date_of_birth\"] = data[\"date_of_birth\"].astype(str).str.strip()\n    data[\"soc_sec_id\"] = data[\"soc_sec_id\"].astype(str).str.strip()\n    data[\"postcode\"] = data[\"postcode\"].astype(str).str.strip()\n    return data\n\n\ndfs = [prepare_data(dataset) for dataset in [df_a, df_b]]\n\ndisplay(dfs[0].head(2))\ndisplay(dfs[1].head(2))\n</code></pre> rec_id given_name surname street_number address_1 address_2 suburb postcode state date_of_birth soc_sec_id cluster 0 rec-1070-org michaela neumann 8 stanley street miami winston hills 4223 nsw 19151111 5304218 rec-1070 1 rec-1016-org courtney painter 12 pinkerton circuit bega flats richlands 4560 vic 19161214 4066625 rec-1016 rec_id given_name surname street_number address_1 address_2 suburb postcode state date_of_birth soc_sec_id cluster 0 rec-561-dup-0 elton 3 light setreet pinehill windermere 3212 vic 19651013 1551941 rec-561 1 rec-2642-dup-0 mitchell maxon 47 edkins street lochaoair north ryde 3355 nsw 19390212 8859999 rec-2642 <p>Next, to better understand which variables will prove useful in linking, we have a look at how populated each column is, as well as the distribution of unique values within each</p> <pre><code>from splink import DuckDBAPI, Linker, SettingsCreator\n\nbasic_settings = SettingsCreator(\n    unique_id_column_name=\"rec_id\",\n    link_type=\"link_only\",\n    # NB as we are linking one-one, we know the probability that a random pair will be a match\n    # hence we could set:\n    # \"probability_two_random_records_match\": 1/5000,\n    # however we will not specify this here, as we will use this as a check that\n    # our estimation procedure returns something sensible\n)\n\nlinker = Linker(dfs, basic_settings, db_api=DuckDBAPI())\n</code></pre> <p>It's usually a good idea to perform exploratory analysis on your data so you understand what's in each column and how often it's missing</p> <pre><code>from splink.exploratory import completeness_chart\n\ncompleteness_chart(dfs, db_api=DuckDBAPI())\n</code></pre> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(dfs, db_api=DuckDBAPI(), column_expressions=[\"given_name\", \"surname\"])\n</code></pre> <p>Next let's come up with some candidate blocking rules, which define which record comparisons are generated, and have a look at how many comparisons each will generate.</p> <p>For blocking rules that we use in prediction, our aim is to have the union of all rules cover all true matches, whilst avoiding generating so many comparisons that it becomes computationally intractable - i.e. each true match should have at least one of the following conditions holding.</p> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules = [\n    block_on(\"given_name\", \"surname\"),\n    # A blocking rule can also be an aribtrary SQL expression\n    \"l.given_name = r.surname and l.surname = r.given_name\",\n    block_on(\"date_of_birth\"),\n    block_on(\"soc_sec_id\"),\n    block_on(\"state\", \"address_1\"),\n    block_on(\"street_number\", \"address_1\"),\n    block_on(\"postcode\"),\n]\n\n\ndb_api = DuckDBAPI()\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=dfs,\n    blocking_rules=blocking_rules,\n    db_api=db_api,\n    link_type=\"link_only\",\n    unique_id_column_name=\"rec_id\",\n    source_dataset_column_name=\"source_dataset\",\n)\n</code></pre> <p>The broadest rule, having a matching postcode, unsurpisingly gives the largest number of comparisons. For this small dataset we still have a very manageable number, but if it was larger we might have needed to include a further <code>AND</code> condition with it to break the number of comparisons further.</p> <p>Now we get the full settings by including the blocking rules, as well as deciding the actual comparisons we will be including in our model.</p> <p>We will define two models, each with a separate linker with different settings, so that we can compare performance. One will be a very basic model, whilst the other will include a lot more detail.</p> <pre><code>import splink.comparison_level_library as cll\nimport splink.comparison_library as cl\n\n\n# the simple model only considers a few columns, and only two comparison levels for each\nsimple_model_settings = SettingsCreator(\n    unique_id_column_name=\"rec_id\",\n    link_type=\"link_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.ExactMatch(\"given_name\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"surname\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"street_number\").configure(term_frequency_adjustments=True),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\n# the detailed model considers more columns, using the information we saw in the exploratory phase\n# we also include further comparison levels to account for typos and other differences\ndetailed_model_settings = SettingsCreator(\n    unique_id_column_name=\"rec_id\",\n    link_type=\"link_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.NameComparison(\"given_name\").configure(term_frequency_adjustments=True),\n        cl.NameComparison(\"surname\").configure(term_frequency_adjustments=True),\n        cl.DateOfBirthComparison(\n            \"date_of_birth\",\n            input_is_string=True,\n            datetime_format=\"%Y%m%d\",\n            invalid_dates_as_null=True,\n        ),\n        cl.DamerauLevenshteinAtThresholds(\"soc_sec_id\", [1, 2]),\n        cl.ExactMatch(\"street_number\").configure(term_frequency_adjustments=True),\n        cl.DamerauLevenshteinAtThresholds(\"postcode\", [1, 2]).configure(\n            term_frequency_adjustments=True\n        ),\n        # we don't consider further location columns as they will be strongly correlated with postcode\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\n\nlinker_simple = Linker(dfs, simple_model_settings, db_api=DuckDBAPI())\nlinker_detailed = Linker(dfs, detailed_model_settings, db_api=DuckDBAPI())\n</code></pre>"},{"location":"demos/examples/duckdb/febrl4.html#estimating-model-parameters","title":"Estimating model parameters","text":"<p>We need to furnish our models with parameter estimates so that we can generate results. We will focus on the detailed model, generating the values for the simple model at the end</p> <p>We can instead estimate the probability two random records match, and compare with the known value of 1/5000 = 0.0002, to see how well our estimation procedure works.</p> <p>To do this we come up with some deterministic rules - the aim here is that we generate very few false positives (i.e. we expect that the majority of records with at least one of these conditions holding are true matches), whilst also capturing the majority of matches - our guess here is that these two rules should capture 80% of all matches.</p> <pre><code>deterministic_rules = [\n    block_on(\"soc_sec_id\"),\n    block_on(\"given_name\", \"surname\", \"date_of_birth\"),\n]\n\nlinker_detailed.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.8\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000239.\nThis means that amongst all possible pairwise record comparisons, one in 4,185.85 are expected to match.  With 25,000,000 total possible comparisons, we expect a total of around 5,972.50 matching pairs\n</code></pre> <p>Even playing around with changing these deterministic rules, or the nominal recall leaves us with an answer which is pretty close to our known value</p> <p>Next we estimate <code>u</code> and <code>m</code> values for each comparison, so that we can move to generating predictions</p> <pre><code># We generally recommend setting max pairs higher (e.g. 1e7 or more)\n# But this will run faster for the purpose of this demo\nlinker_detailed.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\n\n\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - given_name (no m values are trained).\n    - surname (no m values are trained).\n    - date_of_birth (some u values are not trained, no m values are trained).\n    - soc_sec_id (no m values are trained).\n    - street_number (no m values are trained).\n    - postcode (no m values are trained).\n</code></pre> <p>When training the <code>m</code> values using expectation maximisation, we need somre more blocking rules to reduce the total number of comparisons. For each rule, we want to ensure that we have neither proportionally too many matches, or too few.</p> <p>We must run this multiple times using different rules so that we can obtain estimates for all comparisons - if we block on e.g. <code>date_of_birth</code>, then we cannot compute the <code>m</code> values for the <code>date_of_birth</code> comparison, as we have only looked at records where these match.</p> <pre><code>session_dob = (\n    linker_detailed.training.estimate_parameters_using_expectation_maximisation(\n        block_on(\"date_of_birth\"), estimate_without_term_frequencies=True\n    )\n)\nsession_pc = (\n    linker_detailed.training.estimate_parameters_using_expectation_maximisation(\n        block_on(\"postcode\"), estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"date_of_birth\" = r.\"date_of_birth\"\n\nParameter estimates will be made for the following comparison(s):\n    - given_name\n    - surname\n    - soc_sec_id\n    - street_number\n    - postcode\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - date_of_birth\n\nIteration 1: Largest change in params was -0.331 in probability_two_random_records_match\nIteration 2: Largest change in params was 0.00365 in the m_probability of given_name, level `All other comparisons`\nIteration 3: Largest change in params was 9.22e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n\nEM converged after 3 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - date_of_birth (some u values are not trained, no m values are trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"postcode\" = r.\"postcode\"\n\nParameter estimates will be made for the following comparison(s):\n    - given_name\n    - surname\n    - date_of_birth\n    - soc_sec_id\n    - street_number\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - postcode\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 month' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 10 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was 0.0374 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 2: Largest change in params was 0.000457 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 3: Largest change in params was 7.66e-06 in the m_probability of soc_sec_id, level `All other comparisons`\n\nEM converged after 3 iterations\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - date_of_birth (some u values are not trained, some m values are not trained).\n</code></pre> <p>If we wish we can have a look at how our parameter estimates changes over these training sessions</p> <pre><code>session_dob.m_u_values_interactive_history_chart()\n</code></pre> <p>For variables that aren't used in the <code>m</code>-training blocking rules, we have two estimates --- one from each of the training sessions (see for example <code>street_number</code>). We can have a look at how the values compare between them, to ensure that we don't have drastically different values, which may be indicative of an issue.</p> <pre><code>linker_detailed.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <p>We repeat our parameter estimations for the simple model in much the same fashion</p> <pre><code>linker_simple.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.8\n)\nlinker_simple.training.estimate_u_using_random_sampling(max_pairs=1e7)\nsession_ssid = (\n    linker_simple.training.estimate_parameters_using_expectation_maximisation(\n        block_on(\"given_name\"), estimate_without_term_frequencies=True\n    )\n)\nsession_pc = linker_simple.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"street_number\"), estimate_without_term_frequencies=True\n)\nlinker_simple.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000239.\nThis means that amongst all possible pairwise record comparisons, one in 4,185.85 are expected to match.  With 25,000,000 total possible comparisons, we expect a total of around 5,972.50 matching pairs\n----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - given_name (no m values are trained).\n    - surname (no m values are trained).\n    - street_number (no m values are trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"given_name\" = r.\"given_name\"\n\nParameter estimates will be made for the following comparison(s):\n    - surname\n    - street_number\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - given_name\n\nIteration 1: Largest change in params was 0.0812 in the m_probability of surname, level `All other comparisons`\nIteration 2: Largest change in params was -0.0261 in the m_probability of surname, level `Exact match on surname`\nIteration 3: Largest change in params was -0.0247 in the m_probability of surname, level `Exact match on surname`\nIteration 4: Largest change in params was 0.0227 in the m_probability of surname, level `All other comparisons`\nIteration 5: Largest change in params was -0.0198 in the m_probability of surname, level `Exact match on surname`\nIteration 6: Largest change in params was 0.0164 in the m_probability of surname, level `All other comparisons`\nIteration 7: Largest change in params was -0.0131 in the m_probability of surname, level `Exact match on surname`\nIteration 8: Largest change in params was 0.0101 in the m_probability of surname, level `All other comparisons`\nIteration 9: Largest change in params was -0.00769 in the m_probability of surname, level `Exact match on surname`\nIteration 10: Largest change in params was 0.00576 in the m_probability of surname, level `All other comparisons`\nIteration 11: Largest change in params was -0.00428 in the m_probability of surname, level `Exact match on surname`\nIteration 12: Largest change in params was 0.00316 in the m_probability of surname, level `All other comparisons`\nIteration 13: Largest change in params was -0.00234 in the m_probability of surname, level `Exact match on surname`\nIteration 14: Largest change in params was -0.00172 in the m_probability of surname, level `Exact match on surname`\nIteration 15: Largest change in params was 0.00127 in the m_probability of surname, level `All other comparisons`\nIteration 16: Largest change in params was -0.000939 in the m_probability of surname, level `Exact match on surname`\nIteration 17: Largest change in params was -0.000694 in the m_probability of surname, level `Exact match on surname`\nIteration 18: Largest change in params was -0.000514 in the m_probability of surname, level `Exact match on surname`\nIteration 19: Largest change in params was -0.000381 in the m_probability of surname, level `Exact match on surname`\nIteration 20: Largest change in params was -0.000282 in the m_probability of surname, level `Exact match on surname`\nIteration 21: Largest change in params was 0.00021 in the m_probability of surname, level `All other comparisons`\nIteration 22: Largest change in params was -0.000156 in the m_probability of surname, level `Exact match on surname`\nIteration 23: Largest change in params was 0.000116 in the m_probability of surname, level `All other comparisons`\nIteration 24: Largest change in params was 8.59e-05 in the m_probability of surname, level `All other comparisons`\n\nEM converged after 24 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - given_name (no m values are trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"street_number\" = r.\"street_number\"\n\nParameter estimates will be made for the following comparison(s):\n    - given_name\n    - surname\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - street_number\n\nIteration 1: Largest change in params was -0.0446 in the m_probability of surname, level `Exact match on surname`\nIteration 2: Largest change in params was -0.0285 in the m_probability of surname, level `All other comparisons`\nIteration 3: Largest change in params was -0.026 in the m_probability of given_name, level `Exact match on given_name`\nIteration 4: Largest change in params was 0.0252 in the m_probability of given_name, level `All other comparisons`\nIteration 5: Largest change in params was -0.0231 in the m_probability of given_name, level `Exact match on given_name`\nIteration 6: Largest change in params was -0.02 in the m_probability of given_name, level `Exact match on given_name`\nIteration 7: Largest change in params was -0.0164 in the m_probability of given_name, level `Exact match on given_name`\nIteration 8: Largest change in params was -0.013 in the m_probability of given_name, level `Exact match on given_name`\nIteration 9: Largest change in params was 0.01 in the m_probability of given_name, level `All other comparisons`\nIteration 10: Largest change in params was -0.00757 in the m_probability of given_name, level `Exact match on given_name`\nIteration 11: Largest change in params was 0.00564 in the m_probability of given_name, level `All other comparisons`\nIteration 12: Largest change in params was -0.00419 in the m_probability of given_name, level `Exact match on given_name`\nIteration 13: Largest change in params was 0.0031 in the m_probability of given_name, level `All other comparisons`\nIteration 14: Largest change in params was -0.00231 in the m_probability of given_name, level `Exact match on given_name`\nIteration 15: Largest change in params was -0.00173 in the m_probability of given_name, level `Exact match on given_name`\nIteration 16: Largest change in params was 0.0013 in the m_probability of given_name, level `All other comparisons`\nIteration 17: Largest change in params was 0.000988 in the m_probability of given_name, level `All other comparisons`\nIteration 18: Largest change in params was -0.000756 in the m_probability of given_name, level `Exact match on given_name`\nIteration 19: Largest change in params was -0.000584 in the m_probability of given_name, level `Exact match on given_name`\nIteration 20: Largest change in params was -0.000465 in the m_probability of surname, level `Exact match on surname`\nIteration 21: Largest change in params was -0.000388 in the m_probability of surname, level `Exact match on surname`\nIteration 22: Largest change in params was -0.000322 in the m_probability of surname, level `Exact match on surname`\nIteration 23: Largest change in params was 0.000266 in the m_probability of surname, level `All other comparisons`\nIteration 24: Largest change in params was -0.000219 in the m_probability of surname, level `Exact match on surname`\nIteration 25: Largest change in params was -0.00018 in the m_probability of surname, level `Exact match on surname`\n\nEM converged after 25 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code># import json\n# we can have a look at the full settings if we wish, including the values of our estimated parameters:\n# print(json.dumps(linker_detailed._settings_obj.as_dict(), indent=2))\n# we can also get a handy summary of of the model in an easily readable format if we wish:\n# print(linker_detailed._settings_obj.human_readable_description)\n# (we suppress output here for brevity)\n</code></pre> <p>We can now visualise some of the details of our models. We can look at the match weights, which tell us the relative importance for/against a match for each of our comparsion levels.</p> <p>Comparing the two models will show the added benefit we get in the more detailed model --- what in the simple model is classed as 'all other comparisons' is instead broken down further, and we can see that the detail of how this is broken down in fact gives us quite a bit of useful information about the likelihood of a match.</p> <pre><code>linker_simple.visualisations.match_weights_chart()\n</code></pre> <pre><code>linker_detailed.visualisations.match_weights_chart()\n</code></pre> <p>As well as the match weights, which give us an idea of the overall effect of each comparison level, we can also look at the individual <code>u</code> and <code>m</code> parameter estimates, which tells us about the prevalence of coincidences and mistakes (for further details/explanation about this see this article). We might want to revise aspects of our model based on the information we ascertain here.</p> <p>Note however that some of these values are very small, which is why the match weight chart is often more useful for getting a decent picture of things.</p> <pre><code># linker_simple.m_u_parameters_chart()\nlinker_detailed.visualisations.m_u_parameters_chart()\n</code></pre> <p>It is also useful to have a look at unlinkable records - these are records which do not contain enough information to be linked at some match probability threshold. We can figure this out be seeing whether records are able to be matched with themselves.</p> <p>This is of course relative to the information we have put into the model - we see that in our simple model, at a 99% match threshold nearly 10% of records are unlinkable, as we have not included enough information in the model for distinct records to be adequately distinguished; this is not an issue in our more detailed model.</p> <pre><code>linker_simple.evaluation.unlinkables_chart()\n</code></pre> <pre><code>linker_detailed.evaluation.unlinkables_chart()\n</code></pre> <p>Our simple model doesn't do terribly, but suffers if we want to have a high match probability --- to be 99% (match weight ~7) certain of matches we have ~10% of records that we will be unable to link.</p> <p>Our detailed model, however, has enough nuance that we can at least self-link records.</p>"},{"location":"demos/examples/duckdb/febrl4.html#predictions","title":"Predictions","text":"<p>Now that we have had a look into the details of the models, we will focus on only our more detailed model, which should be able to capture more of the genuine links in our data</p> <pre><code>predictions = linker_detailed.inference.predict(threshold_match_probability=0.2)\ndf_predictions = predictions.as_pandas_dataframe()\ndf_predictions.head(5)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre> match_weight match_probability source_dataset_l source_dataset_r rec_id_l rec_id_r given_name_l given_name_r gamma_given_name tf_given_name_l ... gamma_postcode tf_postcode_l tf_postcode_r bf_postcode bf_tf_adj_postcode address_1_l address_1_r state_l state_r match_key 0 -1.830001 0.219521 __splink__input_table_0 __splink__input_table_1 rec-760-org rec-3951-dup-0 lachlan lachlan 4 0.0113 ... 3 0.0007 0.0007 759.407155 1.583362 bushby close templestoew avenue nsw vic 0 1 -1.801736 0.222896 __splink__input_table_0 __splink__input_table_1 rec-4980-org rec-4980-dup-0 isabella ctercteko 0 0.0069 ... 3 0.0004 0.0004 759.407155 2.770884 sturt avenue sturta venue vic vic 2 2 -1.271794 0.292859 __splink__input_table_0 __splink__input_table_1 rec-585-org rec-585-dup-0 danny stephenson 0 0.0001 ... 2 0.0016 0.0012 11.264825 1.000000 o'shanassy street o'shanassy street tas tas 1 3 -1.213441 0.301305 __splink__input_table_0 __splink__input_table_1 rec-1250-org rec-1250-dup-0 luke gazzola 0 0.0055 ... 2 0.0015 0.0002 11.264825 1.000000 newman morris circuit newman morr is circuit nsw nsw 1 4 -0.380336 0.434472 __splink__input_table_0 __splink__input_table_1 rec-4763-org rec-4763-dup-0 max alisha 0 0.0021 ... 1 0.0004 0.0016 0.043565 1.000000 duffy street duffy s treet nsw nsw 2 <p>5 rows \u00d7 47 columns</p> <p>We can see how our model performs at different probability thresholds, with a couple of options depending on the space we wish to view things</p> <pre><code>linker_detailed.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\", output_type=\"accuracy\"\n)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\n</code></pre> <p>and we can easily see how many individuals we identify and link by looking at clusters generated at some threshold match probability of interest - in this example 99%</p> <pre><code>clusters = linker_detailed.clustering.cluster_pairwise_predictions_at_threshold(\n    predictions, threshold_match_probability=0.99\n)\ndf_clusters = clusters.as_pandas_dataframe().sort_values(\"cluster_id\")\ndf_clusters.groupby(\"cluster_id\").size().value_counts()\n</code></pre> <pre><code>Completed iteration 1, root rows count 0\n\n\n\n\n\n2    4959\n1      82\nName: count, dtype: int64\n</code></pre> <p>In this case, we happen to know what the true links are, so we can manually inspect the ones that are doing worst to see what our model is not capturing - i.e. where we have false negatives.</p> <p>Similarly, we can look at the non-links which are performing the best, to see whether we have an issue with false positives.</p> <p>Ordinarily we would not have this luxury, and so would need to dig a bit deeper for clues as to how to improve our model, such as manually inspecting records across threshold probabilities,</p> <pre><code>df_predictions[\"cluster_l\"] = df_predictions[\"rec_id_l\"].apply(\n    lambda x: \"-\".join(x.split(\"-\")[:2])\n)\ndf_predictions[\"cluster_r\"] = df_predictions[\"rec_id_r\"].apply(\n    lambda x: \"-\".join(x.split(\"-\")[:2])\n)\ndf_true_links = df_predictions[\n    df_predictions[\"cluster_l\"] == df_predictions[\"cluster_r\"]\n].sort_values(\"match_probability\")\n</code></pre> <pre><code>records_to_view = 3\nlinker_detailed.visualisations.waterfall_chart(\n    df_true_links.head(records_to_view).to_dict(orient=\"records\")\n)\n</code></pre> <pre><code>df_non_links = df_predictions[\n    df_predictions[\"cluster_l\"] != df_predictions[\"cluster_r\"]\n].sort_values(\"match_probability\", ascending=False)\nlinker_detailed.visualisations.waterfall_chart(\n    df_non_links.head(records_to_view).to_dict(orient=\"records\")\n)\n</code></pre>"},{"location":"demos/examples/duckdb/febrl4.html#further-refinements","title":"Further refinements","text":"<p>Looking at the non-links we have done well in having no false positives at any substantial match probability --- however looking at some of the true links we can see that there are a few that we are not capturing with sufficient match probability.</p> <p>We can see that there are a few features that we are not capturing/weighting appropriately</p> <ul> <li>single-character transpostions, particularly in postcode (which is being lumped in with more 'severe typos'/probable non-matches)</li> <li>given/sur-names being swapped with typos</li> <li>given/sur-names being cross-matches on one only, with no match on the other cross</li> </ul> <p>We will quickly see if we can incorporate these features into a new model. As we are now going into more detail with the inter-relationship between given name and surname, it is probably no longer sensible to model them as independent comparisons, and so we will need to switch to a combined comparison on full name.</p> <pre><code># we need to append a full name column to our source data frames\n# so that we can use it for term frequency adjustments\ndfs[0][\"full_name\"] = dfs[0][\"given_name\"] + \"_\" + dfs[0][\"surname\"]\ndfs[1][\"full_name\"] = dfs[1][\"given_name\"] + \"_\" + dfs[1][\"surname\"]\n\n\nextended_model_settings = {\n    \"unique_id_column_name\": \"rec_id\",\n    \"link_type\": \"link_only\",\n    \"blocking_rules_to_generate_predictions\": blocking_rules,\n    \"comparisons\": [\n        {\n            \"output_column_name\": \"Full name\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"(given_name_l IS NULL OR given_name_r IS NULL) and (surname_l IS NULL OR surname_r IS NULL)\",\n                    \"label_for_charts\": \"Null\",\n                    \"is_null_level\": True,\n                },\n                # full name match\n                cll.ExactMatchLevel(\"full_name\", term_frequency_adjustments=True),\n                # typos - keep levels across full name rather than scoring separately\n                cll.JaroWinklerLevel(\"full_name\", 0.9),\n                cll.JaroWinklerLevel(\"full_name\", 0.7),\n                # name switched\n                cll.ColumnsReversedLevel(\"given_name\", \"surname\"),\n                # name switched + typo\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(given_name_l, surname_r) + jaro_winkler_similarity(surname_l, given_name_r) &gt;= 1.8\",\n                    \"label_for_charts\": \"switched + jaro_winkler_similarity &gt;= 1.8\",\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(given_name_l, surname_r) + jaro_winkler_similarity(surname_l, given_name_r) &gt;= 1.4\",\n                    \"label_for_charts\": \"switched + jaro_winkler_similarity &gt;= 1.4\",\n                },\n                # single name match\n                cll.ExactMatchLevel(\"given_name\", term_frequency_adjustments=True),\n                cll.ExactMatchLevel(\"surname\", term_frequency_adjustments=True),\n                # single name cross-match\n                {\n                    \"sql_condition\": \"given_name_l = surname_r OR surname_l = given_name_r\",\n                    \"label_for_charts\": \"single name cross-matches\",\n                },  # single name typos\n                cll.JaroWinklerLevel(\"given_name\", 0.9),\n                cll.JaroWinklerLevel(\"surname\", 0.9),\n                # the rest\n                cll.ElseLevel(),\n            ],\n        },\n        cl.DateOfBirthComparison(\n            \"date_of_birth\",\n            input_is_string=True,\n            datetime_format=\"%Y%m%d\",\n            invalid_dates_as_null=True,\n        ),\n        {\n            \"output_column_name\": \"Social security ID\",\n            \"comparison_levels\": [\n                cll.NullLevel(\"soc_sec_id\"),\n                cll.ExactMatchLevel(\"soc_sec_id\", term_frequency_adjustments=True),\n                cll.DamerauLevenshteinLevel(\"soc_sec_id\", 1),\n                cll.DamerauLevenshteinLevel(\"soc_sec_id\", 2),\n                cll.ElseLevel(),\n            ],\n        },\n        {\n            \"output_column_name\": \"Street number\",\n            \"comparison_levels\": [\n                cll.NullLevel(\"street_number\"),\n                cll.ExactMatchLevel(\"street_number\", term_frequency_adjustments=True),\n                cll.DamerauLevenshteinLevel(\"street_number\", 1),\n                cll.ElseLevel(),\n            ],\n        },\n        {\n            \"output_column_name\": \"Postcode\",\n            \"comparison_levels\": [\n                cll.NullLevel(\"postcode\"),\n                cll.ExactMatchLevel(\"postcode\", term_frequency_adjustments=True),\n                cll.DamerauLevenshteinLevel(\"postcode\", 1),\n                cll.DamerauLevenshteinLevel(\"postcode\", 2),\n                cll.ElseLevel(),\n            ],\n        },\n        # we don't consider further location columns as they will be strongly correlated with postcode\n    ],\n    \"retain_intermediate_calculation_columns\": True,\n}\n</code></pre> <pre><code># train\nlinker_advanced = Linker(dfs, extended_model_settings, db_api=DuckDBAPI())\nlinker_advanced.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.8\n)\n# We recommend increasing target rows to 1e8 improve accuracy for u\n# values in full name comparison, as we have subdivided the data more finely\n\n# Here, 1e7 for speed\nlinker_advanced.training.estimate_u_using_random_sampling(max_pairs=1e7)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000239.\nThis means that amongst all possible pairwise record comparisons, one in 4,185.85 are expected to match.  With 25,000,000 total possible comparisons, we expect a total of around 5,972.50 matching pairs\n----- Estimating u probabilities using random sampling -----\n\n\n\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nu probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - Full name (no m values are trained).\n    - date_of_birth (some u values are not trained, no m values are trained).\n    - Social security ID (no m values are trained).\n    - Street number (no m values are trained).\n    - Postcode (no m values are trained).\n</code></pre> <pre><code>session_dob = (\n    linker_advanced.training.estimate_parameters_using_expectation_maximisation(\n        \"l.date_of_birth = r.date_of_birth\", estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.date_of_birth = r.date_of_birth\n\nParameter estimates will be made for the following comparison(s):\n    - Full name\n    - Social security ID\n    - Street number\n    - Postcode\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - date_of_birth\n\nWARNING:\nLevel single name cross-matches on comparison Full name not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was -0.465 in the m_probability of Full name, level `Exact match on full_name`\nIteration 2: Largest change in params was 0.00252 in the m_probability of Social security ID, level `All other comparisons`\nIteration 3: Largest change in params was 4.98e-05 in the m_probability of Social security ID, level `All other comparisons`\n\nEM converged after 3 iterations\nm probability not trained for Full name - single name cross-matches (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - Full name (some m values are not trained).\n    - date_of_birth (some u values are not trained, no m values are trained).\n</code></pre> <pre><code>session_pc = (\n    linker_advanced.training.estimate_parameters_using_expectation_maximisation(\n        \"l.postcode = r.postcode\", estimate_without_term_frequencies=True\n    )\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.postcode = r.postcode\n\nParameter estimates will be made for the following comparison(s):\n    - Full name\n    - date_of_birth\n    - Social security ID\n    - Street number\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - Postcode\n\nWARNING:\nLevel single name cross-matches on comparison Full name not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 month' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 1 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nWARNING:\nLevel Abs difference of 'transformed date_of_birth &lt;= 10 year' on comparison date_of_birth not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was 0.0374 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 2: Largest change in params was 0.000656 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 3: Largest change in params was 1.75e-05 in the m_probability of Social security ID, level `All other comparisons`\n\nEM converged after 3 iterations\nm probability not trained for Full name - single name cross-matches (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nm probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth &lt;= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - Full name (some m values are not trained).\n    - date_of_birth (some u values are not trained, some m values are not trained).\n</code></pre> <pre><code>linker_advanced.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <pre><code>linker_advanced.visualisations.match_weights_chart()\n</code></pre> <pre><code>predictions_adv = linker_advanced.inference.predict()\ndf_predictions_adv = predictions_adv.as_pandas_dataframe()\nclusters_adv = linker_advanced.clustering.cluster_pairwise_predictions_at_threshold(\n    predictions_adv, threshold_match_probability=0.99\n)\ndf_clusters_adv = clusters_adv.as_pandas_dataframe().sort_values(\"cluster_id\")\ndf_clusters_adv.groupby(\"cluster_id\").size().value_counts()\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'Full name':\n    m values not fully trained\nComparison: 'date_of_birth':\n    m values not fully trained\nComparison: 'date_of_birth':\n    u values not fully trained\nCompleted iteration 1, root rows count 0\n\n\n\n\n\n2    4960\n1      80\nName: count, dtype: int64\n</code></pre> <p>This is a pretty modest improvement on our previous model - however it is worth re-iterating that we should not necessarily expect to recover all matches, as in several cases it may be unreasonable for a model to have reasonable confidence that two records refer to the same entity.</p> <p>If we wished to improve matters we could iterate on this process - investigating where our model is not performing as we would hope, and seeing how we can adjust these areas to address these shortcomings.</p>"},{"location":"demos/examples/duckdb/link_only.html","title":"Linking two tables of persons","text":""},{"location":"demos/examples/duckdb/link_only.html#linking-without-deduplication","title":"Linking without deduplication","text":"<p>A simple record linkage model using the <code>link_only</code> link type.</p> <p>With <code>link_only</code>, only between-dataset record comparisons are generated. No within-dataset record comparisons are created, meaning that the model does not attempt to find within-dataset duplicates.</p> <p> </p> <pre><code>from splink import splink_datasets\n\ndf = splink_datasets.fake_1000\n\n# Split a simple dataset into two, separate datasets which can be linked together.\ndf_l = df.sample(frac=0.5)\ndf_r = df.drop(df_l.index)\n\ndf_l.head(2)\n</code></pre> unique_id first_name surname dob city email cluster 922 922 Evie Jones 2002-07-22 NaN eviejones@brewer-sparks.org 230 224 224 Logn Feeruson 2013-10-15 London l.fergson46@shah.com 58 <pre><code>import splink.comparison_library as cl\n\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on\n\nsettings = SettingsCreator(\n    link_type=\"link_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    comparisons=[\n        cl.NameComparison(\n            \"first_name\",\n        ),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            invalid_dates_as_null=True,\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n)\n\nlinker = Linker(\n    [df_l, df_r],\n    settings,\n    db_api=DuckDBAPI(),\n    input_table_aliases=[\"df_left\", \"df_right\"],\n)\n</code></pre> <pre><code>from splink.exploratory import completeness_chart\n\ncompleteness_chart(\n    [df_l, df_r],\n    cols=[\"first_name\", \"surname\", \"dob\", \"city\", \"email\"],\n    db_api=DuckDBAPI(),\n    table_names_for_chart=[\"df_left\", \"df_right\"],\n)\n</code></pre> <pre><code>deterministic_rules = [\n    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.surname = r.surname and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n    block_on(\"email\"),\n]\n\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.00338.\nThis means that amongst all possible pairwise record comparisons, one in 295.61 are expected to match.  With 250,000 total possible comparisons, we expect a total of around 845.71 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6, seed=1)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - dob (no m values are trained).\n    - city (no m values are trained).\n    - email (no m values are trained).\n</code></pre> <pre><code>session_dob = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\nsession_email = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"email\")\n)\nsession_first_name = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"first_name\")\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nWARNING:\nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was -0.418 in the m_probability of surname, level `Exact match on surname`\nIteration 2: Largest change in params was 0.104 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0711 in the m_probability of first_name, level `All other comparisons`\nIteration 4: Largest change in params was 0.0237 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.0093 in probability_two_random_records_match\nIteration 6: Largest change in params was 0.00407 in probability_two_random_records_match\nIteration 7: Largest change in params was 0.0019 in probability_two_random_records_match\nIteration 8: Largest change in params was 0.000916 in probability_two_random_records_match\nIteration 9: Largest change in params was 0.000449 in probability_two_random_records_match\nIteration 10: Largest change in params was 0.000222 in probability_two_random_records_match\nIteration 11: Largest change in params was 0.00011 in probability_two_random_records_match\nIteration 12: Largest change in params was 5.46e-05 in probability_two_random_records_match\n\nEM converged after 12 iterations\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - dob (no m values are trained).\n    - email (some m values are not trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"email\" = r.\"email\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - dob\n    - city\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - email\n\nIteration 1: Largest change in params was -0.483 in the m_probability of dob, level `Exact match on dob`\nIteration 2: Largest change in params was 0.0905 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.02 in probability_two_random_records_match\nIteration 4: Largest change in params was 0.00718 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.0031 in probability_two_random_records_match\nIteration 6: Largest change in params was 0.00148 in probability_two_random_records_match\nIteration 7: Largest change in params was 0.000737 in probability_two_random_records_match\nIteration 8: Largest change in params was 0.000377 in probability_two_random_records_match\nIteration 9: Largest change in params was 0.000196 in probability_two_random_records_match\nIteration 10: Largest change in params was 0.000102 in probability_two_random_records_match\nIteration 11: Largest change in params was 5.37e-05 in probability_two_random_records_match\n\nEM converged after 11 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - email (some m values are not trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"first_name\" = r.\"first_name\"\n\nParameter estimates will be made for the following comparison(s):\n    - surname\n    - dob\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n\nIteration 1: Largest change in params was -0.169 in the m_probability of surname, level `All other comparisons`\nIteration 2: Largest change in params was -0.0127 in the m_probability of surname, level `All other comparisons`\nIteration 3: Largest change in params was -0.00388 in the m_probability of surname, level `All other comparisons`\nIteration 4: Largest change in params was -0.00164 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\nIteration 5: Largest change in params was -0.00089 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\nIteration 6: Largest change in params was -0.000454 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\nIteration 7: Largest change in params was -0.000225 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\nIteration 8: Largest change in params was -0.00011 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\nIteration 9: Largest change in params was -5.31e-05 in the m_probability of email, level `Jaro-Winkler &gt;0.88 on username`\n\nEM converged after 9 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code>results = linker.inference.predict(threshold_match_probability=0.9)\n</code></pre> <pre><code>results.as_pandas_dataframe(limit=5)\n</code></pre> match_weight match_probability source_dataset_l source_dataset_r unique_id_l unique_id_r first_name_l first_name_r gamma_first_name surname_l ... dob_l dob_r gamma_dob city_l city_r gamma_city email_l email_r gamma_email match_key 0 3.180767 0.900674 df_left df_right 242 240 Freya Freya 4 Shah ... 1970-12-17 1970-12-16 4 Lonnod noLdon 0 None None -1 0 1 3.180767 0.900674 df_left df_right 241 240 Freya Freya 4 None ... 1970-12-17 1970-12-16 4 London noLdon 0 f.s@flynn.com None -1 0 2 3.212523 0.902626 df_left df_right 679 682 Elizabeth Elizabeth 4 Shaw ... 2006-04-21 2016-04-18 1 Cardiff Cardifrf 0 e.shaw@smith-hall.biz e.shaw@smith-hall.lbiz 3 0 3 3.224126 0.903331 df_left df_right 576 580 Jessica Jessica 4 None ... 1974-11-17 1974-12-17 4 None Walsall -1 jesscac.owen@elliott.org None -1 0 4 3.224126 0.903331 df_left df_right 577 580 Jessica Jessica 4 None ... 1974-11-17 1974-12-17 4 None Walsall -1 jessica.owen@elliott.org None -1 0 <p>5 rows \u00d7 22 columns</p>"},{"location":"demos/examples/duckdb/pairwise_labels.html","title":"Estimating m probabilities from labels","text":""},{"location":"demos/examples/duckdb/pairwise_labels.html#estimating-m-from-a-sample-of-pairwise-labels","title":"Estimating m from a sample of pairwise labels","text":"<p>In this example, we estimate the m probabilities of the model from a table containing pairwise record comparisons which we know are 'true' matches. For example, these may be the result of work by a clerical team who have manually labelled a sample of matches.</p> <p>The table must be in the following format:</p> source_dataset_l unique_id_l source_dataset_r unique_id_r df_1 1 df_2 2 df_1 1 df_2 3 <p>It is assumed that every record in the table represents a certain match.</p> <p>Note that the column names above are the defaults. They should correspond to the values you've set for <code>unique_id_column_name</code> and <code>source_dataset_column_name</code>, if you've chosen custom values.</p> <pre><code>from splink.datasets import splink_dataset_labels\n\npairwise_labels = splink_dataset_labels.fake_1000_labels\n\n# Choose labels indicating a match\npairwise_labels = pairwise_labels[pairwise_labels[\"clerical_match_score\"] == 1]\npairwise_labels\n</code></pre> unique_id_l source_dataset_l unique_id_r source_dataset_r clerical_match_score 0 0 fake_1000 1 fake_1000 1.0 1 0 fake_1000 2 fake_1000 1.0 2 0 fake_1000 3 fake_1000 1.0 49 1 fake_1000 2 fake_1000 1.0 50 1 fake_1000 3 fake_1000 1.0 ... ... ... ... ... ... 3171 994 fake_1000 996 fake_1000 1.0 3172 995 fake_1000 996 fake_1000 1.0 3173 997 fake_1000 998 fake_1000 1.0 3174 997 fake_1000 999 fake_1000 1.0 3175 998 fake_1000 999 fake_1000 1.0 <p>2031 rows \u00d7 5 columns</p> <p>We now proceed to estimate the Fellegi Sunter model:</p> <pre><code>from splink import splink_datasets\n\ndf = splink_datasets.fake_1000\ndf.head(2)\n</code></pre> unique_id first_name surname dob city email cluster 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 1 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 <pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n</code></pre> <pre><code>linker = Linker(df, settings, db_api=DuckDBAPI(), set_up_basic_logging=False)\ndeterministic_rules = [\n    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.surname = r.surname and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n    \"l.email = r.email\",\n]\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n</code></pre> <pre><code># Register the pairwise labels table with the database, and then use it to estimate the m values\nlabels_df = linker.table_management.register_labels_table(pairwise_labels, overwrite=True)\nlinker.training.estimate_m_from_pairwise_labels(labels_df)\n\n\n# If the labels table already existing in the dataset you could run\n# linker.training.estimate_m_from_pairwise_labels(\"labels_tablename_here\")\n</code></pre> <pre><code>training_blocking_rule = block_on(\"first_name\")\nlinker.training.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n</code></pre> <pre><code>&lt;EMTrainingSession, blocking on l.\"first_name\" = r.\"first_name\", deactivating comparisons first_name&gt;\n</code></pre> <pre><code>linker.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre>"},{"location":"demos/examples/duckdb/quick_and_dirty_persons.html","title":"Quick and dirty persons model","text":""},{"location":"demos/examples/duckdb/quick_and_dirty_persons.html#historical-people-quick-and-dirty","title":"Historical people: Quick and dirty","text":"<p>This example shows how to get some initial record linkage results as quickly as possible.</p> <p>There are many ways to improve the accuracy of this model. But this may be a good place to start if you just want to give Splink a try and see what it's capable of.</p> <p> </p> <pre><code>from splink.datasets import splink_datasets\n\ndf = splink_datasets.historical_50k\ndf.head(5)\n</code></pre> unique_id cluster full_name first_and_surname first_name surname dob birth_place postcode_fake gender occupation 0 Q2296770-1 Q2296770 thomas clifford, 1st baron clifford of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 1 Q2296770-2 Q2296770 thomas of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 2 Q2296770-3 Q2296770 tom 1st baron clifford of chudleigh tom chudleigh tom chudleigh 1630-08-01 devon tq13 8df male politician 3 Q2296770-4 Q2296770 thomas 1st chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8hu None politician 4 Q2296770-5 Q2296770 thomas clifford, 1st baron chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df None politician <pre><code>from splink import block_on, SettingsCreator\nimport splink.comparison_library as cl\n\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"full_name\"),\n        block_on(\"substr(full_name,1,6)\", \"dob\", \"birth_place\"),\n        block_on(\"dob\", \"birth_place\"),\n        block_on(\"postcode_fake\"),\n    ],\n    comparisons=[\n        cl.ForenameSurnameComparison(\n            \"first_name\",\n            \"surname\",\n            forename_surname_concat_col_name=\"first_and_surname\",\n        ),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n        ),\n        cl.LevenshteinAtThresholds(\"postcode_fake\", 2),\n        cl.JaroWinklerAtThresholds(\"birth_place\", 0.9).configure(\n            term_frequency_adjustments=True\n        ),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n    ],\n)\n</code></pre> <pre><code>from splink import Linker, DuckDBAPI\n\n\nlinker = Linker(df, settings, db_api=DuckDBAPI(), set_up_basic_logging=False)\ndeterministic_rules = [\n    \"l.full_name = r.full_name\",\n    \"l.postcode_fake = r.postcode_fake and l.dob = r.dob\",\n]\n\nlinker.training.estimate_probability_two_random_records_match(\n    deterministic_rules, recall=0.6\n)\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=2e6)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n</code></pre> <pre><code>results = linker.inference.predict(threshold_match_probability=0.9)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'first_name_surname':\n    m values not fully trained\nComparison: 'first_name_surname':\n    u values not fully trained\nComparison: 'dob':\n    m values not fully trained\nComparison: 'postcode_fake':\n    m values not fully trained\nComparison: 'birth_place':\n    m values not fully trained\nComparison: 'occupation':\n    m values not fully trained\n</code></pre> <pre><code>results.as_pandas_dataframe(limit=5)\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r surname_l surname_r first_and_surname_l first_and_surname_r ... gamma_postcode_fake birth_place_l birth_place_r gamma_birth_place occupation_l occupation_r gamma_occupation full_name_l full_name_r match_key 0 3.170005 0.900005 Q7412607-1 Q7412607-3 samuel samuel shelley shelley samuel shelley samuel shelley ... 0 whitechapel city of london 0 illuminator illuminator 1 samuel shelley samuel shelley 0 1 3.170695 0.900048 Q15997578-4 Q15997578-7 job wilding wilding None job wilding wilding ... -1 wrexham wrexham 2 association football player association football player 1 job wilding wilding 2 2 3.170695 0.900048 Q15997578-2 Q15997578-7 job wilding wilding None job wilding wilding ... -1 wrexham wrexham 2 association football player association football player 1 job wilding wilding 2 3 3.170695 0.900048 Q15997578-1 Q15997578-7 job wilding wilding None job wilding wilding ... -1 wrexham wrexham 2 association football player association football player 1 job wilding wilding 2 4 3.172553 0.900164 Q5726641-11 Q5726641-8 henry harry page paige henry page harry paige ... 2 staffordshire moorlands staffordshire moorlands 2 cricketer cricketer 1 henry page harry paige 3 <p>5 rows \u00d7 26 columns</p>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html","title":"Real time record linkage","text":""},{"location":"demos/examples/duckdb/real_time_record_linkage.html#real-time-linkage","title":"Real time linkage","text":"<p>In this notebook, we demonstrate splink's incremental and real time linkage capabilities - specifically:</p> <ul> <li>the <code>linker.inference.compare_two_records</code> function, that allows you to interactively explore the results of a linkage model; and</li> <li>the <code>linker.find_matches_to_new_records</code> that allows you to incrementally find matches to a small number of new records</li> </ul> <p> </p>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html#step-1-load-a-pre-trained-linkage-model","title":"Step 1: Load a pre-trained linkage model","text":"<pre><code>import urllib.request\nimport json\nfrom pathlib import Path\nfrom splink import Linker, DuckDBAPI, block_on, SettingsCreator, splink_datasets\n\ndf = splink_datasets.fake_1000\n\nurl = \"https://raw.githubusercontent.com/moj-analytical-services/splink_demos/master/demo_settings/real_time_settings.json\"\n\nwith urllib.request.urlopen(url) as u:\n    settings = json.loads(u.read().decode())\n\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\n</code></pre> <pre><code>linker.visualisations.waterfall_chart(\n    linker.inference.predict().as_record_dict(limit=2)\n)\n</code></pre>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html#step-comparing-two-records","title":"Step Comparing two records","text":"<p>It's now possible to compute a match weight for any two records using <code>linker.inference.compare_two_records()</code></p> <pre><code>record_1 = {\n    \"unique_id\": 1,\n    \"first_name\": \"Lucas\",\n    \"surname\": \"Smith\",\n    \"dob\": \"1984-01-02\",\n    \"city\": \"London\",\n    \"email\": \"lucas.smith@hotmail.com\",\n}\n\nrecord_2 = {\n    \"unique_id\": 2,\n    \"first_name\": \"Lucas\",\n    \"surname\": \"Smith\",\n    \"dob\": \"1983-02-12\",\n    \"city\": \"Machester\",\n    \"email\": \"lucas.smith@hotmail.com\",\n}\n\nlinker._settings_obj._retain_intermediate_calculation_columns = True\n\n\n# To `compare_two_records` the linker needs to compute term frequency tables\n# If you have precomputed tables, you can linker.table_management.register_term_frequency_lookup()\nlinker.table_management.compute_tf_table(\"first_name\")\nlinker.table_management.compute_tf_table(\"surname\")\nlinker.table_management.compute_tf_table(\"dob\")\nlinker.table_management.compute_tf_table(\"city\")\nlinker.table_management.compute_tf_table(\"email\")\n\n\ndf_two = linker.inference.compare_two_records(record_1, record_2)\ndf_two.as_pandas_dataframe()\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name ... bf_city bf_tf_adj_city email_l email_r gamma_email tf_email_l tf_email_r bf_email bf_tf_adj_email match_key 0 13.161672 0.999891 1 2 Lucas Lucas 2 0.001203 0.001203 87.571229 ... 0.446404 1.0 lucas.smith@hotmail.com lucas.smith@hotmail.com 1 NaN NaN 263.229168 1.0 0 <p>1 rows \u00d7 40 columns</p>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html#step-3-interactive-comparisons","title":"Step 3: Interactive comparisons","text":"<p>One interesting applicatin of <code>compare_two_records</code> is to create a simple interface that allows the user to input two records interactively, and get real time feedback.</p> <p>In the following cell we use <code>ipywidets</code> for this purpose. \u2728\u2728 Change the values in the text boxes to see the waterfall chart update in real time. \u2728\u2728</p> <pre><code>import ipywidgets as widgets\nfrom IPython.display import display\n\n\nfields = [\"unique_id\", \"first_name\", \"surname\", \"dob\", \"email\", \"city\"]\n\nleft_text_boxes = []\nright_text_boxes = []\n\ninputs_to_interactive_output = {}\n\nfor f in fields:\n    wl = widgets.Text(description=f, value=str(record_1[f]))\n    left_text_boxes.append(wl)\n    inputs_to_interactive_output[f\"{f}_l\"] = wl\n    wr = widgets.Text(description=f, value=str(record_2[f]))\n    right_text_boxes.append(wr)\n    inputs_to_interactive_output[f\"{f}_r\"] = wr\n\nb1 = widgets.VBox(left_text_boxes)\nb2 = widgets.VBox(right_text_boxes)\nui = widgets.HBox([b1, b2])\n\n\ndef myfn(**kwargs):\n    my_args = dict(kwargs)\n\n    record_left = {}\n    record_right = {}\n\n    for key, value in my_args.items():\n        if value == \"\":\n            value = None\n        if key.endswith(\"_l\"):\n            record_left[key[:-2]] = value\n        elif key.endswith(\"_r\"):\n            record_right[key[:-2]] = value\n\n    # Assuming 'linker' is defined earlier in your code\n    linker._settings_obj._retain_intermediate_calculation_columns = True\n\n    df_two = linker.inference.compare_two_records(record_left, record_right)\n\n    recs = df_two.as_pandas_dataframe().to_dict(orient=\"records\")\n\n    display(linker.visualisations.waterfall_chart(recs, filter_nulls=False))\n\n\nout = widgets.interactive_output(myfn, inputs_to_interactive_output)\n\ndisplay(ui, out)\n</code></pre> <pre><code>HBox(children=(VBox(children=(Text(value='1', description='unique_id'), Text(value='Lucas', description='first\u2026\n\n\n\nOutput()\n</code></pre>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html#finding-matching-records-interactively","title":"Finding matching records interactively","text":"<p>It is also possible to search the records in the input dataset rapidly using the <code>linker.find_matches_to_new_records()</code> function</p> <pre><code>record = {\n    \"unique_id\": 123987,\n    \"first_name\": \"Robert\",\n    \"surname\": \"Alan\",\n    \"dob\": \"1971-05-24\",\n    \"city\": \"London\",\n    \"email\": \"robert255@smith.net\",\n}\n\n\ndf_inc = linker.inference.find_matches_to_new_records(\n    [record], blocking_rules=[]\n).as_pandas_dataframe()\ndf_inc.sort_values(\"match_weight\", ascending=False)\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name ... tf_city_r bf_city bf_tf_adj_city email_l email_r gamma_email tf_email_l tf_email_r bf_email bf_tf_adj_email 6 23.531793 1.000000 0 123987 Robert Robert 2 0.003610 0.00361 87.571229 ... 0.212792 1.000000 1.000000 robert255@smith.net robert255@smith.net 1 0.001267 0.001267 263.229168 1.730964 5 14.550320 0.999958 1 123987 Robert Robert 2 0.003610 0.00361 87.571229 ... 0.212792 1.000000 1.000000 roberta25@smith.net robert255@smith.net 0 0.002535 0.001267 0.423438 1.000000 4 10.388623 0.999255 3 123987 Robert Robert 2 0.003610 0.00361 87.571229 ... 0.212792 0.446404 1.000000 None robert255@smith.net -1 NaN 0.001267 1.000000 1.000000 3 2.427256 0.843228 2 123987 Rob Robert 0 0.001203 0.00361 0.218767 ... 0.212792 10.484859 0.259162 roberta25@smith.net robert255@smith.net 0 0.002535 0.001267 0.423438 1.000000 2 -2.123090 0.186697 8 123987 None Robert -1 NaN 0.00361 1.000000 ... 0.212792 1.000000 1.000000 None robert255@smith.net -1 NaN 0.001267 1.000000 1.000000 1 -2.205894 0.178139 754 123987 None Robert -1 NaN 0.00361 1.000000 ... 0.212792 1.000000 1.000000 j.c@whige.wort robert255@smith.net 0 0.001267 0.001267 0.423438 1.000000 0 -2.802309 0.125383 750 123987 None Robert -1 NaN 0.00361 1.000000 ... 0.212792 10.484859 0.259162 j.c@white.org robert255@smith.net 0 0.002535 0.001267 0.423438 1.000000 <p>7 rows \u00d7 39 columns</p>"},{"location":"demos/examples/duckdb/real_time_record_linkage.html#interactive-interface-for-finding-records","title":"Interactive interface for finding records","text":"<p>Again, we can use <code>ipywidgets</code> to build an interactive interface for the <code>linker.find_matches_to_new_records</code> function</p> <pre><code>@widgets.interact(\n    first_name=\"Robert\",\n    surname=\"Alan\",\n    dob=\"1971-05-24\",\n    city=\"London\",\n    email=\"robert255@smith.net\",\n)\ndef interactive_link(first_name, surname, dob, city, email):\n    record = {\n        \"unique_id\": 123987,\n        \"first_name\": first_name,\n        \"surname\": surname,\n        \"dob\": dob,\n        \"city\": city,\n        \"email\": email,\n        \"group\": 0,\n    }\n\n    for key in record.keys():\n        if type(record[key]) == str:\n            if record[key].strip() == \"\":\n                record[key] = None\n\n    df_inc = linker.inference.find_matches_to_new_records(\n        [record], blocking_rules=[f\"(true)\"]\n    ).as_pandas_dataframe()\n    df_inc = df_inc.sort_values(\"match_weight\", ascending=False)\n    recs = df_inc.to_dict(orient=\"records\")\n\n    display(linker.visualisations.waterfall_chart(recs, filter_nulls=False))\n</code></pre> <pre><code>interactive(children=(Text(value='Robert', description='first_name'), Text(value='Alan', description='surname'\u2026\n</code></pre> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre>"},{"location":"demos/examples/duckdb/transactions.html","title":"Linking financial transactions","text":""},{"location":"demos/examples/duckdb/transactions.html#linking-banking-transactions","title":"Linking banking transactions","text":"<p>This example shows how to perform a one-to-one link on banking transactions.</p> <p>The data is fake data, and was generated has the following features:</p> <ul> <li>Money shows up in the destination account with some time delay</li> <li>The amount sent and the amount received are not always the same - there are hidden fees and foreign exchange effects</li> <li>The memo is sometimes truncated and content is sometimes missing</li> </ul> <p>Since each origin payment should end up in the destination account, the <code>probability_two_random_records_match</code> of the model is known.</p> <p> </p> <pre><code>from splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf_origin = splink_datasets.transactions_origin\ndf_destination = splink_datasets.transactions_destination\n\ndisplay(df_origin.head(2))\ndisplay(df_destination.head(2))\n</code></pre> ground_truth memo transaction_date amount unique_id 0 0 MATTHIAS C paym 2022-03-28 36.36 0 1 1 M CORVINUS dona 2022-02-14 221.91 1 ground_truth memo transaction_date amount unique_id 0 0 MATTHIAS C payment BGC 2022-03-29 36.36 0 1 1 M CORVINUS BGC 2022-02-16 221.91 1 <p>In the following chart, we can see this is a challenging dataset to link:</p> <ul> <li>There are only 151 distinct transaction dates, with strong skew</li> <li>Some 'memos' are used multiple times (up to 48 times)</li> <li>There is strong skew in the 'amount' column, with 1,400 transactions of around 60.00</li> </ul> <pre><code>from splink.exploratory import profile_columns\n\ndb_api = DuckDBAPI()\nprofile_columns(\n    [df_origin, df_destination],\n    db_api=db_api,\n    column_expressions=[\n        \"memo\",\n        \"transaction_date\",\n        \"amount\",\n    ],\n)\n</code></pre> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\n# Design blocking rules that allow for differences in transaction date and amounts\nblocking_rule_date_1 = \"\"\"\n    strftime(l.transaction_date, '%Y%m') = strftime(r.transaction_date, '%Y%m')\n    and substr(l.memo, 1,3) = substr(r.memo,1,3)\n    and l.amount/r.amount &gt; 0.7   and l.amount/r.amount &lt; 1.3\n\"\"\"\n\n# Offset by half a month to ensure we capture case when the dates are e.g. 31st Jan and 1st Feb\nblocking_rule_date_2 = \"\"\"\n    strftime(l.transaction_date+15, '%Y%m') = strftime(r.transaction_date, '%Y%m')\n    and substr(l.memo, 1,3) = substr(r.memo,1,3)\n    and l.amount/r.amount &gt; 0.7   and l.amount/r.amount &lt; 1.3\n\"\"\"\n\nblocking_rule_memo = block_on(\"substr(memo,1,9)\")\n\nblocking_rule_amount_1 = \"\"\"\nround(l.amount/2,0)*2 = round(r.amount/2,0)*2 and yearweek(r.transaction_date) = yearweek(l.transaction_date)\n\"\"\"\n\nblocking_rule_amount_2 = \"\"\"\nround(l.amount/2,0)*2 = round((r.amount+1)/2,0)*2 and yearweek(r.transaction_date) = yearweek(l.transaction_date + 4)\n\"\"\"\n\nblocking_rule_cheat = block_on(\"unique_id\")\n\n\nbrs = [\n    blocking_rule_date_1,\n    blocking_rule_date_2,\n    blocking_rule_memo,\n    blocking_rule_amount_1,\n    blocking_rule_amount_2,\n    blocking_rule_cheat,\n]\n\n\ndb_api = DuckDBAPI()\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=[df_origin, df_destination],\n    blocking_rules=brs,\n    db_api=db_api,\n    link_type=\"link_only\"\n)\n</code></pre> <pre><code># Full settings for linking model\nimport splink.comparison_level_library as cll\nimport splink.comparison_library as cl\n\ncomparison_amount = {\n    \"output_column_name\": \"amount\",\n    \"comparison_levels\": [\n        cll.NullLevel(\"amount\"),\n        cll.ExactMatchLevel(\"amount\"),\n        cll.PercentageDifferenceLevel(\"amount\", 0.01),\n        cll.PercentageDifferenceLevel(\"amount\", 0.03),\n        cll.PercentageDifferenceLevel(\"amount\", 0.1),\n        cll.PercentageDifferenceLevel(\"amount\", 0.3),\n        cll.ElseLevel(),\n    ],\n    \"comparison_description\": \"Amount percentage difference\",\n}\n\n# The date distance is one sided becaause transactions should only arrive after they've left\n# As a result, the comparison_template_library date difference functions are not appropriate\nwithin_n_days_template = \"transaction_date_r - transaction_date_l &lt;= {n} and transaction_date_r &gt;= transaction_date_l\"\n\ncomparison_date = {\n    \"output_column_name\": \"transaction_date\",\n    \"comparison_levels\": [\n        cll.NullLevel(\"transaction_date\"),\n        {\n            \"sql_condition\": within_n_days_template.format(n=1),\n            \"label_for_charts\": \"1 day\",\n        },\n        {\n            \"sql_condition\": within_n_days_template.format(n=4),\n            \"label_for_charts\": \"&lt;=4 days\",\n        },\n        {\n            \"sql_condition\": within_n_days_template.format(n=10),\n            \"label_for_charts\": \"&lt;=10 days\",\n        },\n        {\n            \"sql_condition\": within_n_days_template.format(n=30),\n            \"label_for_charts\": \"&lt;=30 days\",\n        },\n        cll.ElseLevel(),\n    ],\n    \"comparison_description\": \"Transaction date days apart\",\n}\n\n\nsettings = SettingsCreator(\n    link_type=\"link_only\",\n    probability_two_random_records_match=1 / len(df_origin),\n    blocking_rules_to_generate_predictions=[\n        blocking_rule_date_1,\n        blocking_rule_date_2,\n        blocking_rule_memo,\n        blocking_rule_amount_1,\n        blocking_rule_amount_2,\n        blocking_rule_cheat,\n    ],\n    comparisons=[\n        comparison_amount,\n        cl.LevenshteinAtThresholds(\"memo\", [2, 6, 10]),\n        comparison_date,\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n</code></pre> <pre><code>linker = Linker(\n    [df_origin, df_destination],\n    settings,\n    input_table_aliases=[\"__ori\", \"_dest\"],\n    db_api=db_api,\n)\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - amount (no m values are trained).\n    - memo (no m values are trained).\n    - transaction_date (no m values are trained).\n</code></pre> <pre><code>linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"memo\"))\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"memo\" = r.\"memo\"\n\nParameter estimates will be made for the following comparison(s):\n    - amount\n    - transaction_date\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - memo\n\nIteration 1: Largest change in params was -0.588 in the m_probability of amount, level `Exact match on amount`\nIteration 2: Largest change in params was -0.176 in the m_probability of transaction_date, level `1 day`\nIteration 3: Largest change in params was 0.00996 in the m_probability of amount, level `Percentage difference of 'amount' within 10.00%`\nIteration 4: Largest change in params was 0.0022 in the m_probability of transaction_date, level `&lt;=30 days`\nIteration 5: Largest change in params was 0.000385 in the m_probability of transaction_date, level `&lt;=30 days`\nIteration 6: Largest change in params was -0.000255 in the m_probability of amount, level `All other comparisons`\nIteration 7: Largest change in params was -0.000229 in the m_probability of amount, level `All other comparisons`\nIteration 8: Largest change in params was -0.000208 in the m_probability of amount, level `All other comparisons`\nIteration 9: Largest change in params was -0.00019 in the m_probability of amount, level `All other comparisons`\nIteration 10: Largest change in params was -0.000173 in the m_probability of amount, level `All other comparisons`\nIteration 11: Largest change in params was -0.000159 in the m_probability of amount, level `All other comparisons`\nIteration 12: Largest change in params was -0.000146 in the m_probability of amount, level `All other comparisons`\nIteration 13: Largest change in params was -0.000135 in the m_probability of amount, level `All other comparisons`\nIteration 14: Largest change in params was -0.000124 in the m_probability of amount, level `All other comparisons`\nIteration 15: Largest change in params was -0.000115 in the m_probability of amount, level `All other comparisons`\nIteration 16: Largest change in params was -0.000107 in the m_probability of amount, level `All other comparisons`\nIteration 17: Largest change in params was -9.92e-05 in the m_probability of amount, level `All other comparisons`\n\nEM converged after 17 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - memo (no m values are trained).\n\n\n\n\n\n&lt;EMTrainingSession, blocking on l.\"memo\" = r.\"memo\", deactivating comparisons memo&gt;\n</code></pre> <pre><code>session = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"amount\"))\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"amount\" = r.\"amount\"\n\nParameter estimates will be made for the following comparison(s):\n    - memo\n    - transaction_date\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - amount\n\nIteration 1: Largest change in params was -0.373 in the m_probability of memo, level `Exact match on memo`\nIteration 2: Largest change in params was -0.108 in the m_probability of memo, level `Exact match on memo`\nIteration 3: Largest change in params was 0.0202 in the m_probability of memo, level `Levenshtein distance of memo &lt;= 10`\nIteration 4: Largest change in params was -0.00538 in the m_probability of memo, level `Exact match on memo`\nIteration 5: Largest change in params was 0.00482 in the m_probability of memo, level `All other comparisons`\nIteration 6: Largest change in params was 0.00508 in the m_probability of memo, level `All other comparisons`\nIteration 7: Largest change in params was 0.00502 in the m_probability of memo, level `All other comparisons`\nIteration 8: Largest change in params was 0.00466 in the m_probability of memo, level `All other comparisons`\nIteration 9: Largest change in params was 0.00409 in the m_probability of memo, level `All other comparisons`\nIteration 10: Largest change in params was 0.00343 in the m_probability of memo, level `All other comparisons`\nIteration 11: Largest change in params was 0.00276 in the m_probability of memo, level `All other comparisons`\nIteration 12: Largest change in params was 0.00216 in the m_probability of memo, level `All other comparisons`\nIteration 13: Largest change in params was 0.00165 in the m_probability of memo, level `All other comparisons`\nIteration 14: Largest change in params was 0.00124 in the m_probability of memo, level `All other comparisons`\nIteration 15: Largest change in params was 0.000915 in the m_probability of memo, level `All other comparisons`\nIteration 16: Largest change in params was 0.000671 in the m_probability of memo, level `All other comparisons`\nIteration 17: Largest change in params was 0.000488 in the m_probability of memo, level `All other comparisons`\nIteration 18: Largest change in params was 0.000353 in the m_probability of memo, level `All other comparisons`\nIteration 19: Largest change in params was 0.000255 in the m_probability of memo, level `All other comparisons`\nIteration 20: Largest change in params was 0.000183 in the m_probability of memo, level `All other comparisons`\nIteration 21: Largest change in params was 0.000132 in the m_probability of memo, level `All other comparisons`\nIteration 22: Largest change in params was 9.45e-05 in the m_probability of memo, level `All other comparisons`\n\nEM converged after 22 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>df_predict = linker.inference.predict(threshold_match_probability=0.001)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n</code></pre> <pre><code>linker.visualisations.comparison_viewer_dashboard(\n    df_predict, \"dashboards/comparison_viewer_transactions.html\", overwrite=True\n)\nfrom IPython.display import IFrame\n\nIFrame(\n    src=\"./dashboards/comparison_viewer_transactions.html\", width=\"100%\", height=1200\n)\n</code></pre> <p> </p> <pre><code>pred_errors = linker.evaluation.prediction_errors_from_labels_column(\n    \"ground_truth\", include_false_positives=True, include_false_negatives=False\n)\nlinker.visualisations.waterfall_chart(pred_errors.as_record_dict(limit=5))\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n</code></pre> <pre><code>pred_errors = linker.evaluation.prediction_errors_from_labels_column(\n    \"ground_truth\", include_false_positives=False, include_false_negatives=True\n)\nlinker.visualisations.waterfall_chart(pred_errors.as_record_dict(limit=5))\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html","title":"Investigating Bias in a Splink Model","text":"<p>Note</p> <p>This notebook is intended for usage alongside the second Bias in Data Linking blog.</p> <p>This notebook will guide you through a 5-step process for evaluating bias in a data linking pipeline. It offers an isolated approach to bias detection, exploring potential mitigation options, before drawing conclusions about the existence of bias in the pipeline.</p> <p>This approach depends on users having pre-developed hypotheses about bias, based on a thorough understanding of the input data and model design. We\u2019ll illustrate the approach with an example hypothesis, using Splink to show how each step can be practically applied.</p> <p>Consider this hypothesis:</p> <p>I\u2019m working with a 50,000-row dataset in which people appear multiple times over their lives. Because their information changes over time, records relating to the same individuals may not always be identical. I suspect that these changes could negatively impact linkage performance for those who update their details. Since women in this dataset are more likely to change their surname and postcode than men, this negative impact would disproportionately affect women, leading to a gender bias.</p>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html#1-generate-synthetic-data","title":"1. Generate synthetic data","text":"<p>Since the hypothesis deals with changes in surnames and addresses, the synthetic data should include multiple records for the same person with these variations:</p> <p>The synthetic data should also match the structure and format of the production data used to train the model.</p> <pre><code>import pandas as pd\n\nsynthetic_base_raw = [\n    {\"unique_id\": 1, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"brown\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"ba12 0ay\", \"gender\": \"female\", \"occupation\": \"politician\"}\n]\n\nsynthetic_comparison_raw = [\n    {\"unique_id\": 2, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"brown\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"ba12 0ay\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 3, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"doyle\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"ba12 0ay\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 4, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"brown\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"tf3 2ng\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 5, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"doyle\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"tf3 2ng\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 6, \"person_id\": 2, \"first_name\": \"jane\", \"surname\": \"brown\", \"dob\": \"1860-01-01\", \"birth_place\": \"london\", \"postcode_fake\": \"ba12 0ay\", \"gender\": \"female\", \"occupation\": \"artist\"}\n]\n\nsynthetic_base_df = pd.DataFrame(synthetic_base_raw)\nsynthetic_comparison_df = pd.DataFrame(synthetic_comparison_raw)\n</code></pre> <pre><code>synthetic_base_df\n</code></pre> unique_id person_id first_name surname dob birth_place postcode_fake gender occupation 0 1 1 sarah brown 1862-07-11 london ba12 0ay female politician <pre><code>synthetic_comparison_df\n</code></pre> unique_id person_id first_name surname dob birth_place postcode_fake gender occupation 0 2 1 sarah brown 1862-07-11 london ba12 0ay female politician 1 3 1 sarah doyle 1862-07-11 london ba12 0ay female politician 2 4 1 sarah brown 1862-07-11 london tf3 2ng female politician 3 5 1 sarah doyle 1862-07-11 london tf3 2ng female politician 4 6 2 jane brown 1860-01-01 london ba12 0ay female artist <p>The first row is the base individual, with each subsequent row representing a different comparison related to the hypothesis. The first comparison is a self-link to serve as a baseline. Next, rows represent isolated surname changes and postcode changes, and finally a combination of both. </p> <p>Since this hypothesis relates to the linkage of records that look different but are for the same person, it\u2019s helpful to include a record that looks similar but is for a different person (like a sibling or partner). This will help account for the downstream effects of any mitigation option (Step 4).</p>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html#2-train-and-investigate-model","title":"2. Train and investigate model","text":"<p>Train the model on the real production data (this Splink model is trained in 'model_create_h50k.ipynb' and saved as a json file). You can refer to the Splink tutorial if you need any further explanation on how to prepare the data and define the model settings. </p> <pre><code>from splink import DuckDBAPI\nfrom splink import Linker, SettingsCreator\nfrom splink import splink_datasets\n\ndb_api = DuckDBAPI()\n\nproduction_df = splink_datasets.historical_50k\n</code></pre> <pre><code>linker = Linker(production_df, settings='../../demo_settings/model_h50k.json', db_api=db_api)\n</code></pre> <p>It's useful to visualise the model parameters to learn the relative importance of different parts of your data for linking.</p> <p>You can do this in Splink by using a match weights chart:</p> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <p>When developing this model, it's essential to evaluate the parameter weights to ensure they align with the pipeline's goals. However, this approach requires considering the bias hypothesis.</p> <p>At first glance, the model appears normal, but a few key points stand out regarding the hypothesis (focussed on surname and postcode changes):</p> <ul> <li>A non-match on the surname is more predictive than a non-match on the first name.</li> <li>A postcode match has the highest predictive weight.</li> </ul> <p>The cumulative effect of these weights makes it difficult to fully understand their impact without generating comparisons.</p>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html#3-perform-and-evaluate-linkage","title":"3. Perform and evaluate linkage","text":"<p>In a standard linkage with Splink, all records which meet the criteria of the blocking rules would be compared against each other. However, in bias detection we may not be interested in a lot of the comparisons this process will generate match probabilities for. It can be easier to manually generate the comparisons that are relevant to the hypothesis. </p> <pre><code>def compare_records(base_records, comparison_records, linker):\n    results = []\n    for record_1 in base_records:\n        results.extend(\n            linker.inference.compare_two_records(record_1, record_2).as_pandas_dataframe()\n            for record_2 in comparison_records\n        )\n    all_comparisons_df = pd.concat(results, ignore_index=True)\n    return all_comparisons_df\n</code></pre> <pre><code>comparisons = compare_records(synthetic_base_raw, synthetic_comparison_raw, linker)\n</code></pre> <pre><code>No term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\n</code></pre> <p>Look at the resulting match probabilities in terms of the threshold of your pipeline. This pipeline has a high match threshold of 0.999, medium of 0.99, and low of 0.95.</p> <pre><code>def highlight_cells(val):\n    if val &gt;= 0.999:\n        color = '#c4f5bf'  # High threshold, green\n    elif val &gt;= 0.99:\n        color = '#faf9c0'  # Medium threshold, yellow\n    elif val &gt;= 0.95:\n        color = '#f5e1bf'  # Low threshold, orange\n    else:\n        color = '#f5c8bf'  # Below threshold, red\n    return f'background-color: {color}'\n</code></pre> <pre><code>columns_of_interest = ['match_weight', 'match_probability', 'unique_id_l', 'unique_id_r', 'first_name_l', 'first_name_r', 'surname_l','surname_r', 'dob_l', 'dob_r','postcode_fake_l', 'postcode_fake_r','birth_place_l', 'birth_place_r', 'occupation_l', 'occupation_r']\ncomparisons[columns_of_interest].style.map(highlight_cells, subset=['match_probability'])\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r surname_l surname_r dob_l dob_r postcode_fake_l postcode_fake_r birth_place_l birth_place_r occupation_l occupation_r 0 35.045794 1.000000 1 2 sarah sarah brown brown 1862-07-11 1862-07-11 ba12 0ay ba12 0ay london london politician politician 1 21.130263 1.000000 1 3 sarah sarah brown doyle 1862-07-11 1862-07-11 ba12 0ay ba12 0ay london london politician politician 2 19.452260 0.999999 1 4 sarah sarah brown brown 1862-07-11 1862-07-11 ba12 0ay tf3 2ng london london politician politician 3 5.536728 0.978913 1 5 sarah sarah brown doyle 1862-07-11 1862-07-11 ba12 0ay tf3 2ng london london politician politician 4 8.046801 0.996233 1 6 sarah jane brown brown 1862-07-11 1860-01-01 ba12 0ay ba12 0ay london london politician artist <p>The first three comparisons show high match probabilities. A surname change or postcode change alone allow for a linkage at a high match threshold. However, when combined they lower the match probability to 0.9781 - which could only be linked at a low threshold in the example pipeline. </p> <p>Additionally, it is useful to note that the sibling scenario has a a higher match probability than the surname and postcode change scenario, and it can be matched at a medium threshold. </p> <p>It\u2019s helpful to break these results down further to understand how the individual model parameters are combining to result in these final probabilities. This can be done in Splink using the waterfall chart:</p> <pre><code>records_to_plot = comparisons.to_dict(orient=\"records\")\nlinker.visualisations.waterfall_chart(records_to_plot)\n</code></pre> <p>Taking a closer look at each comparison helps reveal which features have the most impact in terms of the hypothesis. Some key takeaways are:</p> <ul> <li> <p>Matching on postcode and surname are the strongest indicators of a link. Therefore, when both surname and postcode change, you lose that strong link advantage. It's not that a non-match on surname or postcode is overly detrimental to the records being linked, but without the boost from a surname or postcode match, they only meet the low linkage threshold. </p> </li> <li> <p>In the sibling scenario, you can see the impact of one or two strong predictors in a model can have. Even with three non-matches (first name, DOB, and occupation), matching on both postcode and surname links the records at a medium threshold. </p> </li> <li> <p>As first name matches are less predictive than surname matches the sibling scenario has a more predictive name match than the same person changing their information. </p> </li> <li> <p>Due to the way individual factors are weighted, the combination of non-matches in this scenario means that people who change both their postcode and surname won't be linked at higher thresholds. Given this affects women more than men in our data, it leads to a gender bias in the pipeline.</p> </li> </ul>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html#4-identify-mitigations","title":"4. Identify mitigations","text":"<p>Now that bias has been detected, it's time to explore potential mitigation strategies:</p> <p>Are there viable technical solutions?</p> <p>In our example, a change in surname and postcode allows records to be linked at a low threshold. We should consider what can be done in the pipeline to ensure these comparisons are linked.</p> <p>Any technical solution should align with the hypothesis, as opposed to just pushing comparisons randomly over/under a threshold. Different elements of the pipeline can be altered to address the bias. </p> <ul> <li>Altering the input data - there's likely no potential solution here, as the bias stems from legitimate data qualities, not errors. </li> <li>Updating the model design - a TF adjustment might alter results, but this would be random so wouldn't address the hypothesis. However, adjusting comparison levels might help. </li> <li>Adjusting the output data - since the records link at a low threshold, lowering the threshold across the model would result in a link.</li> </ul> <p>Could they negatively impact overall performance?</p> <p>Lowering the threshold</p> <p>This could link records with surname and postcode changes but might also increase false positives, impacting overall performance. This trade-off needs careful consideration. In synthetic data, for instance, siblings would link at low thresholds. This is just one scenario, and there are most likely others. Given these potential issues, we\u2019re not pursuing a lower threshold.</p> <p>Adjusting comparison levels</p> <p>We'd need to decide that a factor\u2019s predictive power doesn't fit our hypothesis - but also make sure this applies across the whole model. There are lots of options, like making surname or postcode less predictive, or boosting factors like occupation, first name, DOB, or birthplace. We'll focus on one example to demonstrate the necessary considerations. </p> <p>Say we decide to manually make first name as predictive as surname, and we find that this change won\u2019t impact overall performance. Therefore, we can take this technical solution to the next consideration.</p> <p>Could they introduce further bias?</p> <p>It's important to think about other groups that this decision could impact. </p> <p>In this dataset, there's records relating to a community of Vietnamese people. They share similar postcodes and often list the same birthplace (because the dataset defaults to the country of birth if they were born outside the UK). Many families in this community have the same surname, as do many unrelated individuals (due to less variation in Vietnamese surnames). Additionally, because Vietnamese naming conventions differ from Western ones, surnames are often incorrectly recorded as first names in this dataset. </p> <p>Therefore, increasing the predictive power of first name matches will likely lead to more false positives for this community, introducing bias against the Vietnamese population in the dataset. The decision is made to not attempt bias mitigation.</p>"},{"location":"demos/examples/duckdb_no_test/bias_eval.html#5-make-a-statement-about-bias","title":"5. Make a statement about bias","text":"<p>When a bias is detected but not mitigated, it\u2019s crucial to explore it further to gain more insight. This helps refine the understanding of the bias and lays the groundwork for impact assessment.</p> <p>In our example, we can dig deeper into how the link fails with postcode and surname changes. To do this, we\u2019ll create some more synthetic data with partial changes in surname and postcode:</p> <pre><code>synthetic_comparison_partial_raw = [\n    {\"unique_id\": 2, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"brown-doyle\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"tf3 2ng\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 3, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"doyle\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"ba13 2ng\", \"gender\": \"female\", \"occupation\": \"politician\"},\n    {\"unique_id\": 4, \"person_id\": 1, \"first_name\": \"sarah\", \"surname\": \"brown-doyle\", \"dob\": \"1862-07-11\", \"birth_place\": \"london\", \"postcode_fake\": \"ba13 2ng\", \"gender\": \"female\", \"occupation\": \"politician\"}\n]\n\nsynthetic_comparison_partial_df = pd.DataFrame(synthetic_comparison_partial_raw)\n</code></pre> <p>In this scenario, we generate new records to be compared to the base. These represent a partial surname change (double-barrel) and a full postcode change, a partial postcode change (same area, different district) with a full surname change, and a combination of partial postcode and partial surname changes.</p> <p>We can then use the same model to link these records and examine the resulting match probabilities. </p> <pre><code>comparisons_partial = compare_records(synthetic_base_raw, synthetic_comparison_partial_raw, linker)\n\ncomparisons_partial[columns_of_interest].style.map(highlight_cells, subset=['match_probability'])\n</code></pre> <pre><code>No term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"first_name\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\nNo term frequencies found for column \"surname\".\nTo apply term frequency adjustments, you need to register a lookup using `linker.table_management.register_term_frequency_lookup`.\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r surname_l surname_r dob_l dob_r postcode_fake_l postcode_fake_r birth_place_l birth_place_r occupation_l occupation_r 0 15.641700 0.999980 1 2 sarah sarah brown brown-doyle 1862-07-11 1862-07-11 ba12 0ay tf3 2ng london london politician politician 1 12.130717 0.999777 1 3 sarah sarah brown doyle 1862-07-11 1862-07-11 ba12 0ay ba13 2ng london london politician politician 2 22.235689 1.000000 1 4 sarah sarah brown brown-doyle 1862-07-11 1862-07-11 ba12 0ay ba13 2ng london london politician politician <p>In all three cases, the records will remain linked at a high threshold. This insight can help make the final bias statement:</p> <p>Given how the model weighs the different parameters to produce match probabilities, a full change in both surname and postcode will lead to a non-link. As women are more likely than men to make these changes in the input data, this will introduce a gender bias in the pipeline.</p> <p>Now that this bias has been detected, it's important to note that we can't yet determine its exact impact on the linked data. This is because the final results are influenced by many other factors in the pipeline, which were intentionally excluded from this process to isolate the bias. </p> <p>Further investigation is needed to understand impact \u2014 such as understanding how many records in the input data undergo these changes, or how many records with a full surname and postcode change end up linked or not linked in the final data. </p>"},{"location":"demos/examples/duckdb_no_test/business_rates_match.html","title":"Linking businesses","text":""},{"location":"demos/examples/duckdb_no_test/business_rates_match.html#matching-businesses","title":"Matching businesses","text":"<p>In this example we attempt to match open business rates data from Stockport (source) with Companies House data (source).</p> <p>This is quite a challenging scenario because the data is not initially well suited for Splink.</p> <p>First, there are only three columns to match on:</p> <ul> <li>The business name</li> <li>The address</li> <li>The business postcode</li> </ul> <p>Second, the data itself is quite different to many other applications: the business name is an ordered 'bag of words'.</p> <p>We will therefore need to use a few preprocessing tricks to build a successful matching model/</p> <p>Let's start by taking a look at the data. To make the size of these files manageable, I have selected only rows from the companies house data where <code>substr(postcode, 1,4)</code> matches at least one postcode in the Stockport data, resulting in:</p> <ul> <li>Companies house data is around 1 million records</li> <li>Stockport data has 4,540 records</li> </ul> <p>In this example, to make it easy to understand, I break the calculation into multiple steps.  Many calculations can be combined into single steps - you can see a more condensed version here.</p> <p>First, let's take a look at the data:</p> <pre><code>import duckdb\nimport altair as alt\n\ndf_companies_house = duckdb.read_parquet(\"https://github.com/RobinL/company_matching_example/raw/refs/heads/main/companies_house.parquet\")\ndf_companies_house.sort(\"company_name\").show(max_rows=5)\n\ndf_stockport_business_rates = duckdb.read_parquet(\"https://github.com/RobinL/company_matching_example/raw/refs/heads/main/stockport_business_rates.parquet\")\ndf_stockport_business_rates.sort(\"company_name\").show(max_rows=5)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         company_name         \u2502 company_number \u2502             address_concat              \u2502 postcode \u2502\n\u2502           varchar            \u2502    varchar     \u2502                 varchar                 \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ! LTD                        \u2502 08209948       \u2502 9 PRINCES SQUARE                        \u2502 HG1 1ND  \u2502\n\u2502 !BIG IMPACT GRAPHICS LIMITED \u2502 11743365       \u2502 372 OLD STREET 335 ROSDEN HOUSE         \u2502 EC1V 9LT \u2502\n\u2502 !NFOGENIE LTD                \u2502 13522064       \u2502 71-75 SHELTON STREET                    \u2502 WC2H 9JQ \u2502\n\u2502       \u00b7                      \u2502    \u00b7           \u2502       \u00b7                                 \u2502    \u00b7     \u2502\n\u2502       \u00b7                      \u2502    \u00b7           \u2502       \u00b7                                 \u2502    \u00b7     \u2502\n\u2502       \u00b7                      \u2502    \u00b7           \u2502       \u00b7                                 \u2502    \u00b7     \u2502\n\u2502 4TECH MOTO LIMITED           \u2502 05583123       \u2502 1 BOND STREET                           \u2502 BB8 9DG  \u2502\n\u2502 4TECH SOFTWARE LIMITED       \u2502 07415956       \u2502 ELEVEN BRINDLEYPLACE 2 BRUNSWICK SQUARE \u2502 B1 2LP   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 5 shown)                                                             4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            company_name             \u2502 company_number \u2502                              address_concat                              \u2502 postcode \u2502\n\u2502               varchar               \u2502    varchar     \u2502                                 varchar                                  \u2502 varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 08 UK LTD                           \u2502 NULL           \u2502 15 MADOC STREET LLANDUDNO CONWY WALES                                    \u2502 LL30 2TL \u2502\n\u2502 1 GR LTD                            \u2502 NULL           \u2502 296-296A GORTON ROAD REDDISH STOCKPORT                                   \u2502 SK5 6RN  \u2502\n\u2502 101 CANVAS PRINTS LTD               \u2502 NULL           \u2502 SUITE 44 4TH FLOOR HOULDSWORTH MILL HOULDSWORTH STREET REDDISH STOCKPORT \u2502 SK5 6DA  \u2502\n\u2502           \u00b7                         \u2502  \u00b7             \u2502                           \u00b7                                              \u2502    \u00b7     \u2502\n\u2502           \u00b7                         \u2502  \u00b7             \u2502                           \u00b7                                              \u2502    \u00b7     \u2502\n\u2502           \u00b7                         \u2502  \u00b7             \u2502                           \u00b7                                              \u2502    \u00b7     \u2502\n\u2502 ZYGOCITY LTD T/A CRAFTSTAR STENCILS \u2502 NULL           \u2502 UNIT 46 GOYT MILL UPPER HIBBERT LANE MARPLE STOCKPORT                    \u2502 SK6 7HX  \u2502\n\u2502 ZYNC GROUP LTD IN LIQUIDATION       \u2502 NULL           \u2502 C/O COWGILLS LIMITED FOURTH FLOOR UNIT 5B THE PARKLANDS BOLTON           \u2502 BL6 4SD  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 4540 rows (5 shown)                                                                                                              4 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/business_rates_match.html#feature-engineering","title":"Feature engineering","text":"<p>We will do some feature engineering to make this data more amenable to matching:</p> <ul> <li>To match companies, we will tokenise the company name and compute the term frequencies of each token.  This will allow us to more accurately quantify how closely two business names match</li> <li>We will also pick out a subset of tokens to give us access to new blocking strategies</li> <li>To match addresses, we will use the first number in the address and the postcode only.  This is simplistic - for a more advanced approach to address matching in Splink see here </li> </ul> <p>We'll perform this featuring on both datasets simultaneously to ensure the token frequencies are representative of all the data</p> <pre><code># Start by creating a table with the data vertically concatenated\nsql = \"\"\"\ncreate or replace table all_input_data as\nwith concat_data as (\n    select *, 'stockport' as source_dataset\n\nfrom df_stockport_business_rates\nunion all\nselect *, 'z_all_companies' as source_dataset\nfrom df_companies_house\n)\nselect ROW_NUMBER() OVER () as unique_id, *\nfrom concat_data\n\"\"\"\n\nduckdb.execute(sql)\n\nduckdb.table(\"all_input_data\").show(max_rows=10, max_width=100000)\n</code></pre> <pre><code>FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 unique_id \u2502         company_name         \u2502 company_number \u2502                              address_concat                              \u2502 postcode \u2502 source_dataset  \u2502\n\u2502   int64   \u2502           varchar            \u2502    varchar     \u2502                                 varchar                                  \u2502 varchar  \u2502     varchar     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 08 UK LTD                    \u2502 NULL           \u2502 15 MADOC STREET LLANDUDNO CONWY WALES                                    \u2502 LL30 2TL \u2502 stockport       \u2502\n\u2502         2 \u2502 1 GR LTD                     \u2502 NULL           \u2502 296-296A GORTON ROAD REDDISH STOCKPORT                                   \u2502 SK5 6RN  \u2502 stockport       \u2502\n\u2502         3 \u2502 101 CANVAS PRINTS LTD        \u2502 NULL           \u2502 SUITE 44 4TH FLOOR HOULDSWORTH MILL HOULDSWORTH STREET REDDISH STOCKPORT \u2502 SK5 6DA  \u2502 stockport       \u2502\n\u2502         4 \u2502 121 DIRECT MAIL LTD          \u2502 NULL           \u2502 UNIT 18 CHARTER HOUSE LATHAM CLOSE BREDBURY STOCKPORT                    \u2502 SK6 2SD  \u2502 stockport       \u2502\n\u2502         5 \u2502 121 PERSONAL TRAINING LTD    \u2502 NULL           \u2502 198 WILMSLOW ROAD HEALD GREEN STOCKPORT                                  \u2502 SK8 3BH  \u2502 stockport       \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502\n\u2502      9996 \u2502 AL-MAALIK LOCUM SERVICES LTD \u2502 14351700       \u2502 239 MOSELEY ROAD LEVENSHULME                                             \u2502 M19 2LJ  \u2502 z_all_companies \u2502\n\u2502      9997 \u2502 AL-MAALIK PHARMACIES LTD     \u2502 14421852       \u2502 239 MOSELEY ROAD LEVENSHULME                                             \u2502 M19 2LJ  \u2502 z_all_companies \u2502\n\u2502      9998 \u2502 AL-MAALIK PROPERTIES LTD     \u2502 14412454       \u2502 1041 STOCKPORT ROAD                                                      \u2502 M19 2TF  \u2502 z_all_companies \u2502\n\u2502      9999 \u2502 AL-MADAD OUTREACH LTD        \u2502 14827390       \u2502 124-128 CITY ROAD                                                        \u2502 EC1V 2NX \u2502 z_all_companies \u2502\n\u2502     10000 \u2502 AL-MADANI LTD                \u2502 14415359       \u2502 71-75 SHELTON STREET COVENT GARDEN                                       \u2502 WC2H 9JQ \u2502 z_all_companies \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 10 shown)                                                                                                                           6 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Tokenize company names, and explode tokens across rows\n# The tokenisation approach here is simplistic, more advanced strategies could be used\n# in a more fully-fledged application\n\n\nsql = \"\"\"\nCREATE OR REPLACE TABLE unnested AS\nSELECT\n    unique_id,\n    unnest(regexp_split_to_array(upper(trim(company_name)), '\\\\s+')) as name_token,\n    generate_subscripts(regexp_split_to_array(upper(trim(company_name)), '\\\\s+'), 1) as token_position_in_name\nFROM all_input_data\n\"\"\"\n\nunnested = duckdb.execute(sql)\nduckdb.table(\"unnested\").show(max_rows=10, max_width=100000)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 unique_id \u2502 name_token \u2502 token_position_in_name \u2502\n\u2502   int64   \u2502  varchar   \u2502         int64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 08         \u2502                      1 \u2502\n\u2502         1 \u2502 UK         \u2502                      2 \u2502\n\u2502         1 \u2502 LTD        \u2502                      3 \u2502\n\u2502         2 \u2502 1          \u2502                      1 \u2502\n\u2502         2 \u2502 GR         \u2502                      2 \u2502\n\u2502         \u00b7 \u2502 \u00b7          \u2502                      \u00b7 \u2502\n\u2502         \u00b7 \u2502 \u00b7          \u2502                      \u00b7 \u2502\n\u2502         \u00b7 \u2502 \u00b7          \u2502                      \u00b7 \u2502\n\u2502      2619 \u2502 MEDATECH   \u2502                      1 \u2502\n\u2502      2619 \u2502 UK         \u2502                      2 \u2502\n\u2502      2619 \u2502 LTD        \u2502                      3 \u2502\n\u2502      2620 \u2502 MEDIA      \u2502                      1 \u2502\n\u2502      2620 \u2502 +          \u2502                      2 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 10 shown)         3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Compute token relative frequencies\nsql = \"\"\"\nCREATE OR REPLACE TABLE token_frequencies AS\nSELECT\n    name_token as token,\n    count(*)::float/(select count(*) from unnested) as rel_freq\nFROM unnested\nGROUP BY token\nORDER BY rel_freq DESC\n\n\"\"\"\n\n# Execute and show results\ntoken_frequencies = duckdb.execute(sql)\nduckdb.table(\"token_frequencies\").show(max_rows=10, max_width=100000)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   token    \u2502   rel_freq    \u2502\n\u2502  varchar   \u2502     float     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LTD        \u2502    0.14284134 \u2502\n\u2502 LIMITED    \u2502    0.13450336 \u2502\n\u2502 SERVICES   \u2502   0.012372046 \u2502\n\u2502 &amp;          \u2502    0.01089211 \u2502\n\u2502 MANAGEMENT \u2502  0.0076835644 \u2502\n\u2502   \u00b7        \u2502        \u00b7      \u2502\n\u2502   \u00b7        \u2502        \u00b7      \u2502\n\u2502   \u00b7        \u2502        \u00b7      \u2502\n\u2502 MENDIP     \u2502 6.0517837e-06 \u2502\n\u2502 MVP        \u2502 6.0517837e-06 \u2502\n\u2502 FINGERS    \u2502 6.0517837e-06 \u2502\n\u2502 GRADUATE   \u2502 6.0517837e-06 \u2502\n\u2502 REACT      \u2502 6.0517837e-06 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows           2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Reconstruct the company name as a list of tokens with their relative frequency\n# This creates a new column called name_tokens_with_freq\n# Example: 101 CANVAS PRINTS LTD  becomes\n# [\n#  {'token': 101, 'rel_freq': 3.19e-05},\n#  {'token': CANVAS, 'rel_freq': 2.20e-05},\n#  {'token': PRINTS, 'rel_freq': 3.16e-05},\n#  {'token': LTD, 'rel_freq': 0.142}\n# ]\nsql = \"\"\"\nCREATE OR REPLACE TABLE input_data_with_tokens AS\nWITH\ntokens_with_freq AS (\n    SELECT\n        m.unique_id,\n        -- Create a list of structs containing each token and its frequency\n        list_transform(\n            list_zip(\n                array_agg(u.name_token ORDER BY u.token_position_in_name),\n                array_agg(COALESCE(tf.rel_freq, 0.0) ORDER BY u.token_position_in_name)\n            ),\n            x -&gt; struct_pack(token := x[1], rel_freq := x[2])\n        ) as name_tokens_with_freq\n    FROM all_input_data m\n    JOIN unnested u ON m.unique_id = u.unique_id\n    LEFT JOIN token_frequencies tf ON u.name_token = tf.token\n    GROUP BY m.unique_id\n)\nSELECT\n    m.*,\n    t.name_tokens_with_freq\nFROM all_input_data m\nLEFT JOIN tokens_with_freq t ON m.unique_id = t.unique_id\norder by m.unique_id\n\"\"\"\n\n# Execute and show results\nduckdb.execute(sql)\nduckdb.table(\"input_data_with_tokens\").show(max_rows=10, max_width=200)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 unique_id \u2502     company_name     \u2502 company_number \u2502    address_concat    \u2502 postcode \u2502 source_dataset  \u2502                                    name_tokens_with_freq                                     \u2502\n\u2502   int64   \u2502       varchar        \u2502    varchar     \u2502       varchar        \u2502 varchar  \u2502     varchar     \u2502                           struct(token varchar, rel_freq float)[]                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 08 UK LTD            \u2502 NULL           \u2502 15 MADOC STREET LL\u2026  \u2502 LL30 2TL \u2502 stockport       \u2502 [{'token': 08, 'rel_freq': 2.2006486e-06}, {'token': UK, 'rel_freq': 0.0059337737}, {'toke\u2026  \u2502\n\u2502         2 \u2502 1 GR LTD             \u2502 NULL           \u2502 296-296A GORTON RO\u2026  \u2502 SK5 6RN  \u2502 stockport       \u2502 [{'token': 1, 'rel_freq': 0.000688803}, {'token': GR, 'rel_freq': 2.3656972e-05}, {'token'\u2026  \u2502\n\u2502         3 \u2502 101 CANVAS PRINTS \u2026  \u2502 NULL           \u2502 SUITE 44 4TH FLOOR\u2026  \u2502 SK5 6DA  \u2502 stockport       \u2502 [{'token': 101, 'rel_freq': 3.1909403e-05}, {'token': CANVAS, 'rel_freq': 2.2006485e-05}, \u2026  \u2502\n\u2502         4 \u2502 121 DIRECT MAIL LTD  \u2502 NULL           \u2502 UNIT 18 CHARTER HO\u2026  \u2502 SK6 2SD  \u2502 stockport       \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': DIRECT, 'rel_freq': 0.00050367345}, \u2026  \u2502\n\u2502         5 \u2502 121 PERSONAL TRAIN\u2026  \u2502 NULL           \u2502 198 WILMSLOW ROAD \u2026  \u2502 SK8 3BH  \u2502 stockport       \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': PERSONAL, 'rel_freq': 8.8851186e-05}\u2026  \u2502\n\u2502         \u00b7 \u2502          \u00b7           \u2502  \u00b7             \u2502          \u00b7           \u2502    \u00b7     \u2502     \u00b7           \u2502                                              \u00b7                                               \u2502\n\u2502         \u00b7 \u2502          \u00b7           \u2502  \u00b7             \u2502          \u00b7           \u2502    \u00b7     \u2502     \u00b7           \u2502                                              \u00b7                                               \u2502\n\u2502         \u00b7 \u2502          \u00b7           \u2502  \u00b7             \u2502          \u00b7           \u2502    \u00b7     \u2502     \u00b7           \u2502                                              \u00b7                                               \u2502\n\u2502      9996 \u2502 AL-MAALIK LOCUM SE\u2026  \u2502 14351700       \u2502 239 MOSELEY ROAD L\u2026  \u2502 M19 2LJ  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': LOCUM, 'rel_freq': 6.6844696e-0\u2026  \u2502\n\u2502      9997 \u2502 AL-MAALIK PHARMACI\u2026  \u2502 14421852       \u2502 239 MOSELEY ROAD L\u2026  \u2502 M19 2LJ  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PHARMACIES, 'rel_freq': 4.67637\u2026  \u2502\n\u2502      9998 \u2502 AL-MAALIK PROPERTI\u2026  \u2502 14412454       \u2502 1041 STOCKPORT ROAD  \u2502 M19 2TF  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PROPERTIES, 'rel_freq': 0.00506\u2026  \u2502\n\u2502      9999 \u2502 AL-MADAD OUTREACH \u2026  \u2502 14827390       \u2502 124-128 CITY ROAD    \u2502 EC1V 2NX \u2502 z_all_companies \u2502 [{'token': AL-MADAD, 'rel_freq': 2.7508108e-07}, {'token': OUTREACH, 'rel_freq': 1.9530757\u2026  \u2502\n\u2502     10000 \u2502 AL-MADANI LTD        \u2502 14415359       \u2502 71-75 SHELTON STRE\u2026  \u2502 WC2H 9JQ \u2502 z_all_companies \u2502 [{'token': AL-MADANI, 'rel_freq': 2.7508108e-07}, {'token': LTD, 'rel_freq': 0.14284134}]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 10 shown)                                                                                                                                                              7 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Derive rarest tokens - these will be used for blocking\n# This would be simpler if Duckdb list sort supported a lambda function\n# but it doesn't, so we have to unnest the list and sort manually\n# https://duckdb.org/docs/sql/functions/list.html#sorting-lists\nsql = \"\"\"\nwith\ntokens_unnested as (\n    SELECT\n        unique_id,\n        unnest(name_tokens_with_freq) as token_info\n    FROM input_data_with_tokens\n),\nrare_tokens as (\n    SELECT\n        unique_id,\n        array_agg(token_info.token ORDER BY token_info.rel_freq ASC)[:2] as rarest_tokens\n    FROM tokens_unnested\n    WHERE token_info.rel_freq &lt; 0.01\n    GROUP BY unique_id\n)\nselect m.*, rarest_tokens\nfrom input_data_with_tokens as m\nleft join rare_tokens on m.unique_id = rare_tokens.unique_id\norder by m.unique_id\n\"\"\"\ninput_data_with_tokens_and_rarest_tokens = duckdb.sql(sql)\ninput_data_with_tokens_and_rarest_tokens.show(max_rows=10, max_width=1000)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 unique_id \u2502         company_name         \u2502 company_number \u2502                              address_concat                              \u2502 postcode \u2502 source_dataset  \u2502                                                                                name_tokens_with_freq                                                                                \u2502      rarest_tokens      \u2502\n\u2502   int64   \u2502           varchar            \u2502    varchar     \u2502                                 varchar                                  \u2502 varchar  \u2502     varchar     \u2502                                                                       struct(token varchar, rel_freq float)[]                                                                       \u2502        varchar[]        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 08 UK LTD                    \u2502 NULL           \u2502 15 MADOC STREET LLANDUDNO CONWY WALES                                    \u2502 LL30 2TL \u2502 stockport       \u2502 [{'token': 08, 'rel_freq': 2.2006486e-06}, {'token': UK, 'rel_freq': 0.0059337737}, {'token': LTD, 'rel_freq': 0.14284134}]                                                         \u2502 [08, UK]                \u2502\n\u2502         2 \u2502 1 GR LTD                     \u2502 NULL           \u2502 296-296A GORTON ROAD REDDISH STOCKPORT                                   \u2502 SK5 6RN  \u2502 stockport       \u2502 [{'token': 1, 'rel_freq': 0.000688803}, {'token': GR, 'rel_freq': 2.3656972e-05}, {'token': LTD, 'rel_freq': 0.14284134}]                                                           \u2502 [GR, 1]                 \u2502\n\u2502         3 \u2502 101 CANVAS PRINTS LTD        \u2502 NULL           \u2502 SUITE 44 4TH FLOOR HOULDSWORTH MILL HOULDSWORTH STREET REDDISH STOCKPORT \u2502 SK5 6DA  \u2502 stockport       \u2502 [{'token': 101, 'rel_freq': 3.1909403e-05}, {'token': CANVAS, 'rel_freq': 2.2006485e-05}, {'token': PRINTS, 'rel_freq': 3.163432e-05}, {'token': LTD, 'rel_freq': 0.14284134}]      \u2502 [CANVAS, PRINTS]        \u2502\n\u2502         4 \u2502 121 DIRECT MAIL LTD          \u2502 NULL           \u2502 UNIT 18 CHARTER HOUSE LATHAM CLOSE BREDBURY STOCKPORT                    \u2502 SK6 2SD  \u2502 stockport       \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': DIRECT, 'rel_freq': 0.00050367345}, {'token': MAIL, 'rel_freq': 1.5679621e-05}, {'token': LTD, 'rel_freq': 0.14284134}]       \u2502 [MAIL, 121]             \u2502\n\u2502         5 \u2502 121 PERSONAL TRAINING LTD    \u2502 NULL           \u2502 198 WILMSLOW ROAD HEALD GREEN STOCKPORT                                  \u2502 SK8 3BH  \u2502 stockport       \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': PERSONAL, 'rel_freq': 8.8851186e-05}, {'token': TRAINING, 'rel_freq': 0.00092289696}, {'token': LTD, 'rel_freq': 0.14284134}] \u2502 [121, PERSONAL]         \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502         \u00b7 \u2502             \u00b7                \u2502  \u00b7             \u2502              \u00b7                                                           \u2502    \u00b7     \u2502     \u00b7           \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502      9996 \u2502 AL-MAALIK LOCUM SERVICES LTD \u2502 14351700       \u2502 239 MOSELEY ROAD LEVENSHULME                                             \u2502 M19 2LJ  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': LOCUM, 'rel_freq': 6.6844696e-05}, {'token': SERVICES, 'rel_freq': 0.012372046}, {'token': LTD, 'rel_freq': 0.14284134}] \u2502 [AL-MAALIK, LOCUM]      \u2502\n\u2502      9997 \u2502 AL-MAALIK PHARMACIES LTD     \u2502 14421852       \u2502 239 MOSELEY ROAD LEVENSHULME                                             \u2502 M19 2LJ  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PHARMACIES, 'rel_freq': 4.676378e-06}, {'token': LTD, 'rel_freq': 0.14284134}]                                           \u2502 [AL-MAALIK, PHARMACIES] \u2502\n\u2502      9998 \u2502 AL-MAALIK PROPERTIES LTD     \u2502 14412454       \u2502 1041 STOCKPORT ROAD                                                      \u2502 M19 2TF  \u2502 z_all_companies \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PROPERTIES, 'rel_freq': 0.005062042}, {'token': LTD, 'rel_freq': 0.14284134}]                                            \u2502 [AL-MAALIK, PROPERTIES] \u2502\n\u2502      9999 \u2502 AL-MADAD OUTREACH LTD        \u2502 14827390       \u2502 124-128 CITY ROAD                                                        \u2502 EC1V 2NX \u2502 z_all_companies \u2502 [{'token': AL-MADAD, 'rel_freq': 2.7508108e-07}, {'token': OUTREACH, 'rel_freq': 1.9530757e-05}, {'token': LTD, 'rel_freq': 0.14284134}]                                            \u2502 [AL-MADAD, OUTREACH]    \u2502\n\u2502     10000 \u2502 AL-MADANI LTD                \u2502 14415359       \u2502 71-75 SHELTON STREET COVENT GARDEN                                       \u2502 WC2H 9JQ \u2502 z_all_companies \u2502 [{'token': AL-MADANI, 'rel_freq': 2.7508108e-07}, {'token': LTD, 'rel_freq': 0.14284134}]                                                                                           \u2502 [AL-MADANI]             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 10 shown)                                                                                                                                                                                                                                                                                                                                           8 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Finally we're going to extract the 'house number' from the address, which, combined with the postcode will be used for matching\n\nsql = \"\"\"\nCREATE OR REPLACE TABLE data_for_matching AS\nselect\n    unique_id,\n    source_dataset,\n    company_name,\n    company_number,\n    COALESCE(\n        REGEXP_EXTRACT(address_concat, '(\\\\d+[A-Z]?)'),\n        REGEXP_EXTRACT(address_concat, '(\\\\S+)(?=\\\\s+HOUSE)')\n    ) AS first_num_in_address,\n    postcode,\n    name_tokens_with_freq,\n    rarest_tokens\nfrom input_data_with_tokens_and_rarest_tokens\n\n\"\"\"\nduckdb.execute(sql)\nduckdb.table(\"data_for_matching\").show(max_rows=10, max_width=400)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 unique_id \u2502 source_dataset  \u2502         company_name         \u2502 company_number \u2502 first_num_in_address \u2502 postcode \u2502                                                                                name_tokens_with_freq                                                                                \u2502      rarest_tokens      \u2502\n\u2502   int64   \u2502     varchar     \u2502           varchar            \u2502    varchar     \u2502       varchar        \u2502 varchar  \u2502                                                                       struct(token varchar, rel_freq float)[]                                                                       \u2502        varchar[]        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         1 \u2502 stockport       \u2502 08 UK LTD                    \u2502 NULL           \u2502 15                   \u2502 LL30 2TL \u2502 [{'token': 08, 'rel_freq': 2.2006486e-06}, {'token': UK, 'rel_freq': 0.0059337737}, {'token': LTD, 'rel_freq': 0.14284134}]                                                         \u2502 [08, UK]                \u2502\n\u2502         2 \u2502 stockport       \u2502 1 GR LTD                     \u2502 NULL           \u2502 296                  \u2502 SK5 6RN  \u2502 [{'token': 1, 'rel_freq': 0.000688803}, {'token': GR, 'rel_freq': 2.3656972e-05}, {'token': LTD, 'rel_freq': 0.14284134}]                                                           \u2502 [GR, 1]                 \u2502\n\u2502         3 \u2502 stockport       \u2502 101 CANVAS PRINTS LTD        \u2502 NULL           \u2502 44                   \u2502 SK5 6DA  \u2502 [{'token': 101, 'rel_freq': 3.1909403e-05}, {'token': CANVAS, 'rel_freq': 2.2006485e-05}, {'token': PRINTS, 'rel_freq': 3.163432e-05}, {'token': LTD, 'rel_freq': 0.14284134}]      \u2502 [CANVAS, PRINTS]        \u2502\n\u2502         4 \u2502 stockport       \u2502 121 DIRECT MAIL LTD          \u2502 NULL           \u2502 18                   \u2502 SK6 2SD  \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': DIRECT, 'rel_freq': 0.00050367345}, {'token': MAIL, 'rel_freq': 1.5679621e-05}, {'token': LTD, 'rel_freq': 0.14284134}]       \u2502 [MAIL, 121]             \u2502\n\u2502         5 \u2502 stockport       \u2502 121 PERSONAL TRAINING LTD    \u2502 NULL           \u2502 198                  \u2502 SK8 3BH  \u2502 [{'token': 121, 'rel_freq': 1.7055027e-05}, {'token': PERSONAL, 'rel_freq': 8.8851186e-05}, {'token': TRAINING, 'rel_freq': 0.00092289696}, {'token': LTD, 'rel_freq': 0.14284134}] \u2502 [121, PERSONAL]         \u2502\n\u2502         \u00b7 \u2502     \u00b7           \u2502             \u00b7                \u2502  \u00b7             \u2502  \u00b7                   \u2502    \u00b7     \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502         \u00b7 \u2502     \u00b7           \u2502             \u00b7                \u2502  \u00b7             \u2502  \u00b7                   \u2502    \u00b7     \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502         \u00b7 \u2502     \u00b7           \u2502             \u00b7                \u2502  \u00b7             \u2502  \u00b7                   \u2502    \u00b7     \u2502                                                                                          \u00b7                                                                                          \u2502        \u00b7                \u2502\n\u2502      9996 \u2502 z_all_companies \u2502 AL-MAALIK LOCUM SERVICES LTD \u2502 14351700       \u2502 239                  \u2502 M19 2LJ  \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': LOCUM, 'rel_freq': 6.6844696e-05}, {'token': SERVICES, 'rel_freq': 0.012372046}, {'token': LTD, 'rel_freq': 0.14284134}] \u2502 [AL-MAALIK, LOCUM]      \u2502\n\u2502      9997 \u2502 z_all_companies \u2502 AL-MAALIK PHARMACIES LTD     \u2502 14421852       \u2502 239                  \u2502 M19 2LJ  \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PHARMACIES, 'rel_freq': 4.676378e-06}, {'token': LTD, 'rel_freq': 0.14284134}]                                           \u2502 [AL-MAALIK, PHARMACIES] \u2502\n\u2502      9998 \u2502 z_all_companies \u2502 AL-MAALIK PROPERTIES LTD     \u2502 14412454       \u2502 1041                 \u2502 M19 2TF  \u2502 [{'token': AL-MAALIK, 'rel_freq': 8.252432e-07}, {'token': PROPERTIES, 'rel_freq': 0.005062042}, {'token': LTD, 'rel_freq': 0.14284134}]                                            \u2502 [AL-MAALIK, PROPERTIES] \u2502\n\u2502      9999 \u2502 z_all_companies \u2502 AL-MADAD OUTREACH LTD        \u2502 14827390       \u2502 124                  \u2502 EC1V 2NX \u2502 [{'token': AL-MADAD, 'rel_freq': 2.7508108e-07}, {'token': OUTREACH, 'rel_freq': 1.9530757e-05}, {'token': LTD, 'rel_freq': 0.14284134}]                                            \u2502 [AL-MADAD, OUTREACH]    \u2502\n\u2502     10000 \u2502 z_all_companies \u2502 AL-MADANI LTD                \u2502 14415359       \u2502 71                   \u2502 WC2H 9JQ \u2502 [{'token': AL-MADANI, 'rel_freq': 2.7508108e-07}, {'token': LTD, 'rel_freq': 0.14284134}]                                                                                           \u2502 [AL-MADANI]             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 10 shown)                                                                                                                                                                                                                                                                                       8 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/business_rates_match.html#splink-model","title":"Splink model","text":"<p>We've now prepared our data for matching.  We'll use a fairly straightforward matching model with one innovation: we need to define a comparison that is able to exploit the information in <code>name_tokens_with_freq</code>  effectively.</p> <p>The approach we're going to take is to define similarity as the number of tokens in common between two business names, adjusting for term frequency.  This can be computed by multiplying together the token frequencies of the matching tokens.</p> <p>We will create a comparison level for different thresholds of this value.</p> <pre><code>def calculate_tf_product_array_sql(token_rel_freq_array_name):\n\n    return f\"\"\"\n    list_intersect({token_rel_freq_array_name}_l, {token_rel_freq_array_name}_r)\n        .list_transform(x -&gt; x.rel_freq::float)\n        .list_concat([1.0::FLOAT]) -- in case there are no matches\n        .list_reduce((p, q) -&gt; p * q)\n    \"\"\"\n</code></pre> <pre><code># Prepare our two input datasets\n\ndf_stockport = duckdb.sql(\n    \"select * from data_for_matching where source_dataset = 'stockport'\"\n)\n\ndf_all_companies = duckdb.sql(\n    \"select * from data_for_matching where source_dataset = 'z_all_companies'\"\n)\n</code></pre> <pre><code>from splink import DuckDBAPI, Linker, SettingsCreator, block_on\nimport splink.comparison_library as cl\ncon = duckdb.connect(\":default:\")\ndb_api = DuckDBAPI(connection=con)\n\n\nsettings = SettingsCreator(\n    link_type=\"link_only\",\n    unique_id_column_name=\"unique_id\",\n    probability_two_random_records_match=1/1e6,\n    comparisons=[\n        {\n            \"output_column_name\": \"name_tokens_with_freq\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": '\"name_tokens_with_freq_l\" IS NULL OR \"name_tokens_with_freq_r\" IS NULL',\n                    \"label_for_charts\": \"name_tokens_with_freq is NULL\",\n                    \"is_null_level\": True,\n                },\n                {\n                    \"sql_condition\": f\"\"\"\n                    {calculate_tf_product_array_sql(\"name_tokens_with_freq\")} &lt; 1e-12\n                    \"\"\",\n                    \"label_for_charts\": \"Array product is less than 1e-10\",\n                },\n                {\n                    \"sql_condition\": f\"\"\"\n                    {calculate_tf_product_array_sql(\"name_tokens_with_freq\")} &lt; 1e-10\n                    \"\"\",\n                    \"label_for_charts\": \"Array product is less than 1e-10\",\n                },\n                {\n                    \"sql_condition\": f\"\"\"\n                    {calculate_tf_product_array_sql(\"name_tokens_with_freq\")} &lt; 1e-8\n                    \"\"\",\n                    \"label_for_charts\": \"Array product is less than 1e-8\",\n                },\n                {\n                    \"sql_condition\": f\"\"\"\n                    {calculate_tf_product_array_sql(\"name_tokens_with_freq\")} &lt; 1e-6\n                    \"\"\",\n                    \"label_for_charts\": \"Array product is less than 1e-6\",\n                },\n                {\n                    \"sql_condition\": f\"\"\"\n                    {calculate_tf_product_array_sql(\"name_tokens_with_freq\")} &lt; 1e-4\n                    \"\"\",\n                    \"label_for_charts\": \"Array product is less than 1e-4\",\n                },\n                {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\"},\n            ],\n            \"comparison_description\": \"ExactMatch\",\n        },\n        cl.PostcodeComparison(\"postcode\"),\n        cl.ExactMatch(\"first_num_in_address\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"postcode\"),\n        block_on(\"rarest_tokens\", \"substr(postcode,1,3)\"),\n        \"l.rarest_tokens[1] = r.rarest_tokens[2] and substr(l.company_name,1,3) = substr(r.company_name,1,3)\",\n        \"l.rarest_tokens[2] = r.rarest_tokens[1] and substr(l.company_name,1,3) = substr(r.company_name,1,3)\",\n        block_on(\"company_name\"),\n    ],\n    additional_columns_to_retain=[\"company_name\"],\n    retain_intermediate_calculation_columns=True,\n    retain_matching_columns=True,\n)\n\nlinker = Linker([df_stockport, df_all_companies], settings, db_api)\n</code></pre> <pre><code># Probably not worth training m values given how few columns we have;\n# by not training them we'll be using the defaults\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e7)\nlinker.visualisations.match_weights_chart()\n</code></pre> <pre><code>----- Estimating u probabilities using random sampling -----\n\n\n\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - name_tokens_with_freq (no m values are trained).\n    - postcode (no m values are trained).\n    - first_num_in_address (no m values are trained).\n</code></pre> <p></p> <pre><code># Get some results\n\ndf_predictions = linker.inference.predict(threshold_match_weight=-5)\n\n\n\n# Since the companies house data is a canonical list, here we're taking the\n# best matching company for each Stockport business\nsql = f\"\"\"\nWITH ranked_matches AS (\n    SELECT *,\n           ROW_NUMBER() OVER (PARTITION BY unique_id_l ORDER BY match_weight DESC) as rank\n    FROM {df_predictions.physical_name}\n),\nbest_match as (\n    select * from ranked_matches\n    where rank = 1\n    order by match_weight desc\n),\nmatched_stockport_ids as (\n    select distinct unique_id_l\n    from best_match\n)\nselect * from best_match\n\norder by match_probability desc\n\"\"\"\n\nranked_matches = con.sql(sql)\nranked_matches.show(max_rows=10, max_width=400)\n</code></pre> <pre><code>Blocking time: 0.18 seconds\n\n\n\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n\n\nPredict time: 3.65 seconds\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'name_tokens_with_freq':\n    m values not fully trained\nComparison: 'postcode':\n    m values not fully trained\nComparison: 'first_num_in_address':\n    m values not fully trained\n\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    match_weight     \u2502  match_probability  \u2502 source_dataset_l \u2502 source_dataset_r \u2502 unique_id_l \u2502 unique_id_r \u2502 name_tokens_with_f\u2026  \u2502 name_tokens_with_f\u2026  \u2502 gamma_name_tokens_\u2026  \u2502 bf_name_tokens_wit\u2026  \u2502 \u2026 \u2502 first_num_in_addre\u2026  \u2502 gamma_first_num_in\u2026  \u2502 bf_first_num_in_ad\u2026  \u2502    company_name_l    \u2502    company_name_r    \u2502   rarest_tokens_l    \u2502   rarest_tokens_r    \u2502 match_key \u2502 rank  \u2502\n\u2502       double        \u2502       double        \u2502     varchar      \u2502     varchar      \u2502    int64    \u2502    int64    \u2502 struct(token varch\u2026  \u2502 struct(token varch\u2026  \u2502        int32         \u2502        double        \u2502   \u2502       varchar        \u2502        int32         \u2502        double        \u2502       varchar        \u2502       varchar        \u2502      varchar[]       \u2502      varchar[]       \u2502  varchar  \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  21.416127918577743 \u2502  0.9999996426424596 \u2502 stockport        \u2502 z_all_companies  \u2502          80 \u2502      828925 \u2502 [{'token': ACOUSTI\u2026  \u2502 [{'token': ACOUSTI\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502 316                  \u2502                    1 \u2502   31.128138879477106 \u2502 ACOUSTIC AND ENGIN\u2026  \u2502 ACOUSTIC AND ENGIN\u2026  \u2502 [ACOUSTIC, CONSULT\u2026  \u2502 [ACOUSTIC, CONSULT\u2026  \u2502 0         \u2502     1 \u2502\n\u2502  21.416127918577743 \u2502  0.9999996426424596 \u2502 stockport        \u2502 z_all_companies  \u2502        2323 \u2502      487414 \u2502 [{'token': LA, 're\u2026  \u2502 [{'token': LA, 're\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502 29                   \u2502                    1 \u2502   31.128138879477106 \u2502 LA BELLE PRESTIGE \u2026  \u2502 LA BELLE PRESTIGE \u2026  \u2502 [BELLE, LA]          \u2502 [BELLE, LA]          \u2502 0         \u2502     1 \u2502\n\u2502  21.416127918577743 \u2502  0.9999996426424596 \u2502 stockport        \u2502 z_all_companies  \u2502        1928 \u2502       33589 \u2502 [{'token': HM, 're\u2026  \u2502 [{'token': HM, 're\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502 27                   \u2502                    1 \u2502   31.128138879477106 \u2502 HM ATKINS CLOTHING\u2026  \u2502 HM ATKINS CLOTHING\u2026  \u2502 [ATKINS, HM]         \u2502 [ATKINS, HM]         \u2502 0         \u2502     1 \u2502\n\u2502  21.416127918577743 \u2502  0.9999996426424596 \u2502 stockport        \u2502 z_all_companies  \u2502         643 \u2502      686474 \u2502 [{'token': BURTON,\u2026  \u2502 [{'token': BURTON,\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502                      \u2502                    1 \u2502   31.128138879477106 \u2502 BURTON ROOFING MER\u2026  \u2502 BURTON ROOFING MER\u2026  \u2502 [MERCHANTS, BURTON]  \u2502 [MERCHANTS, BURTON]  \u2502 0         \u2502     1 \u2502\n\u2502  21.416127918577743 \u2502  0.9999996426424596 \u2502 stockport        \u2502 z_all_companies  \u2502          58 \u2502      599776 \u2502 [{'token': ABCETA,\u2026  \u2502 [{'token': ABCETA,\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502 19                   \u2502                    1 \u2502   31.128138879477106 \u2502 ABCETA PLAYTHINGS \u2026  \u2502 ABCETA PLAYTHINGS \u2026  \u2502 [ABCETA, PLAYTHINGS] \u2502 [ABCETA, PLAYTHINGS] \u2502 0         \u2502     1 \u2502\n\u2502           \u00b7         \u2502           \u00b7         \u2502     \u00b7            \u2502        \u00b7         \u2502           \u00b7 \u2502         \u00b7   \u2502          \u00b7           \u2502          \u00b7           \u2502                    \u00b7 \u2502            \u00b7         \u2502 \u00b7 \u2502 \u00b7                    \u2502                    \u00b7 \u2502            \u00b7         \u2502          \u00b7           \u2502          \u00b7           \u2502         \u00b7            \u2502         \u00b7            \u2502 \u00b7         \u2502     \u00b7 \u2502\n\u2502           \u00b7         \u2502           \u00b7         \u2502     \u00b7            \u2502        \u00b7         \u2502           \u00b7 \u2502         \u00b7   \u2502          \u00b7           \u2502          \u00b7           \u2502                    \u00b7 \u2502            \u00b7         \u2502 \u00b7 \u2502 \u00b7                    \u2502                    \u00b7 \u2502            \u00b7         \u2502          \u00b7           \u2502          \u00b7           \u2502         \u00b7            \u2502         \u00b7            \u2502 \u00b7         \u2502     \u00b7 \u2502\n\u2502           \u00b7         \u2502           \u00b7         \u2502     \u00b7            \u2502        \u00b7         \u2502           \u00b7 \u2502         \u00b7   \u2502          \u00b7           \u2502          \u00b7           \u2502                    \u00b7 \u2502            \u00b7         \u2502 \u00b7 \u2502 \u00b7                    \u2502                    \u00b7 \u2502            \u00b7         \u2502          \u00b7           \u2502          \u00b7           \u2502         \u00b7            \u2502         \u00b7            \u2502 \u00b7         \u2502     \u00b7 \u2502\n\u2502 -3.4705625254057795 \u2502 0.08274585730410321 \u2502 stockport        \u2502 z_all_companies  \u2502        3079 \u2502      355661 \u2502 [{'token': PERPETU\u2026  \u2502 [{'token': PERPETU\u2026  \u2502                    5 \u2502    5881782.930380143 \u2502 \u2026 \u2502                      \u2502                    0 \u2502  0.05157398705697865 \u2502 PERPETUAL WATCH SE\u2026  \u2502 PERPETUAL WATCH SE\u2026  \u2502 [PERPETUAL, WATCH]   \u2502 [PERPETUAL, WATCH]   \u2502 4         \u2502     1 \u2502\n\u2502  -4.644182870808291 \u2502 0.03845316514889586 \u2502 stockport        \u2502 z_all_companies  \u2502        2140 \u2502      634191 \u2502 [{'token': JAMES, \u2026  \u2502 [{'token': JAMES, \u2026  \u2502                    2 \u2502   270.89098005456975 \u2502 \u2026 \u2502 4                    \u2502                    1 \u2502   31.128138879477106 \u2502 JAMES RETAIL LIMITED \u2502 JAMES RETAIL SOHAM\u2026  \u2502 [JAMES, RETAIL]      \u2502 [SOHAM, JAMES]       \u2502 2         \u2502     1 \u2502\n\u2502  -4.644182870808291 \u2502 0.03845316514889586 \u2502 stockport        \u2502 z_all_companies  \u2502        3986 \u2502     1036621 \u2502 [{'token': TGL, 'r\u2026  \u2502 [{'token': TGL, 'r\u2026  \u2502                    2 \u2502   270.89098005456975 \u2502 \u2026 \u2502                      \u2502                    1 \u2502   31.128138879477106 \u2502 TGL SOLUTIONS LTD    \u2502 TGL SOLUTIONS LIMI\u2026  \u2502 [TGL, SOLUTIONS]     \u2502 [TGL, SOLUTIONS]     \u2502 1         \u2502     1 \u2502\n\u2502  -4.644182870808291 \u2502 0.03845316514889586 \u2502 stockport        \u2502 z_all_companies  \u2502        1230 \u2502      617874 \u2502 [{'token': DOM, 'r\u2026  \u2502 [{'token': DOM, 'r\u2026  \u2502                    2 \u2502   270.89098005456975 \u2502 \u2026 \u2502 26                   \u2502                    1 \u2502   31.128138879477106 \u2502 DOM PROPERTIES LTD   \u2502 DOM PROPERTIES LIM\u2026  \u2502 [DOM, PROPERTIES]    \u2502 [DOM, PROPERTIES]    \u2502 1         \u2502     1 \u2502\n\u2502  -4.644182870808291 \u2502 0.03845316514889586 \u2502 stockport        \u2502 z_all_companies  \u2502        3657 \u2502      508179 \u2502 [{'token': SIMULAT\u2026  \u2502 [{'token': SIMULAT\u2026  \u2502                    2 \u2502   270.89098005456975 \u2502 \u2026 \u2502 10                   \u2502                    1 \u2502   31.128138879477106 \u2502 SIMULATION SOLUTIO\u2026  \u2502 SIMULATION SOLUTIO\u2026  \u2502 [SIMULATION, SOLUT\u2026  \u2502 [SIMULATION, SOLUT\u2026  \u2502 1         \u2502     1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2757 rows (10 shown)                                                                                                                                                                                                                                                                                                                                                       24 columns (19 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>sql = \"\"\"\nCREATE OR REPLACE TABLE comparison AS\nselect * from ranked_matches\nwhere company_name_l != company_name_r\norder by random()\nlimit 1\n\"\"\"\nduckdb.execute(sql)\n\n\nsql = \"\"\"\nSELECT match_probability, COLUMNS('^(t[^f_].*|b[^f_].*|[^tb].*_l)$') AS '\\\\1'\nFROM comparison\nUNION ALL\nSELECT match_probability, COLUMNS('^(t[^f_].*|b[^f_].*|[^tb].*_r)$') AS '\\\\1'\nFROM comparison;\n\"\"\"\nduckdb.sql(sql).show(max_rows=10, max_width=200)\n\nrecs = duckdb.table(\"comparison\").df().to_dict(orient=\"records\")\nlinker.visualisations.waterfall_chart(recs)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 match_probability  \u2502 source_dataset_l \u2502 unique_id_l \u2502             name_tokens_with_freq_l             \u2502 postcode_l \u2502 first_num_in_address_l \u2502         company_name_l         \u2502    rarest_tokens_l    \u2502\n\u2502       double       \u2502     varchar      \u2502    int64    \u2502     struct(token varchar, rel_freq float)[]     \u2502  varchar   \u2502        varchar         \u2502            varchar             \u2502       varchar[]       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0.9998652868923441 \u2502 stockport        \u2502         872 \u2502 [{'token': CLARITAS, 'rel_freq': 1.9255674e-0\u2026  \u2502 SK4 4DT    \u2502 10                     \u2502 CLARITAS WEALTH MANAGMENT LTD  \u2502 [CLARITAS, MANAGMENT] \u2502\n\u2502 0.9998652868923441 \u2502 z_all_companies  \u2502      537567 \u2502 [{'token': CLARITAS, 'rel_freq': 1.9255674e-0\u2026  \u2502 SK4 4DT    \u2502 10                     \u2502 CLARITAS WEALTH MANAGEMENT LTD \u2502 [CLARITAS, WEALTH]    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p></p> <pre><code>import altair as alt\n# Plot histogram of match weights\n\n# This list does not include any stockport records where no comparison pairs were made\n# because blocking rules did not find any potential matches\n\n# Add in unmatched records\nsql = \"\"\"\nWITH matched_stockport_ids as (\n    select distinct unique_id_l\n    from ranked_matches\n)\nselect\n    -10 as match_weight,\n    0.0 as match_probability,\nfrom data_for_matching t\nwhere t.source_dataset = 'stockport'\nand t.unique_id not in (select unique_id_l from matched_stockport_ids)\n\"\"\"\n\nunmatched_records = duckdb.sql(sql)\nunmatched_records.show(max_rows=10, max_width=400)\n\n\nsql = \"\"\"\nselect match_probability, match_weight from ranked_matches\nunion all\nselect match_probability, match_weight from unmatched_records\norder by match_probability desc\n\"\"\"\n\nall_records = con.sql(sql)\n\n# Create the histogram\nchart = (\n    alt.Chart(all_records.df())\n    .mark_bar()\n    .encode(\n        alt.X(\"match_weight:Q\", bin=alt.Bin(maxbins=50), title=\"Match Weight\"),\n        alt.Y(\"count():Q\", title=\"Count\"),\n    )\n    .properties(title=\"Distribution of Match Probabilities\", width=600, height=400)\n)\n\n# Save the chart\nchart\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 match_weight \u2502 match_probability \u2502\n\u2502    int32     \u2502   decimal(2,1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502           \u00b7  \u2502                \u00b7  \u2502\n\u2502           \u00b7  \u2502                \u00b7  \u2502\n\u2502           \u00b7  \u2502                \u00b7  \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u2502          -10 \u2502               0.0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1783 rows (10 shown)   2 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p></p>"},{"location":"demos/examples/duckdb_no_test/business_rates_match.html#extensions-and-final-notes","title":"Extensions and final notes","text":"<p>When running this against the full companies house data rather than the small subset here, the number of unmatched records (the bar on the left hand side of the histogram) reduces to about 890 records.</p> <p>There are a number of ways the accuracy of this example could be improved:</p> <ul> <li>Additional data cleaning, e.g. dealing better with company names like A B C Engineering vs ABC engineering, or translating word aliases like LTD to LIMITED</li> <li>A more sophisticated approach to tokenisation</li> <li>Blocking could be improved in various ways, e.g. by blocking on address tokens, using more 'rare' tokens, using partial postcodes better and so on</li> <li>Allowing fuzzy matching on tokens in the company name, not just full token matching</li> </ul>"},{"location":"demos/examples/duckdb_no_test/comparison_playground.html","title":"Comparison playground","text":""},{"location":"demos/examples/duckdb_no_test/comparison_playground.html#comparison-values","title":"Comparison values","text":"<p>Run the following cell to get an interactive interface for trying out comparisons from the <code>comparison_library</code>.</p> <p>The interface uses the default arguments for each comparison, and can only be used for comparisons that refer to a single column</p> <p>In the following cells, you can get similar results for custom comparisons with an arbitrary number of input columns.</p> <pre><code>import splink.comparison_library as cl\nfrom splink.internals.testing import comparison_vector_value, is_in_level\nfrom splink import DuckDBAPI\nimport ipywidgets as widgets\nfrom IPython.display import Markdown\n\n\ndef report_comparison_levels(comparison, values_dict, column_name):\n    db_api = DuckDBAPI()\n    levels = comparison.create_comparison_levels()\n    comparison_dict = comparison.get_comparison(\"duckdb\").as_dict()\n\n    table_rows = []\n    table_rows.append(\"| Match | Level | Description | SQL Condition |\")\n    table_rows.append(\"|-------|-------|-------------|---------------|\")\n\n    total_levels = len(levels)\n    matched_level = None\n    for i, level in enumerate(levels):\n        level_number = total_levels - i - 1\n        label = level.create_label_for_charts()\n        sql_condition = comparison_dict['comparison_levels'][i]['sql_condition']\n\n        is_match = is_in_level(level, values_dict, db_api)\n\n        if is_match and matched_level is None:\n            matched_level = level_number\n            match_indicator = \"\u2713\"\n            row = f\"| {match_indicator} | **{level_number}** | **{label}** | `{sql_condition}` |\"\n        else:\n            match_indicator = \"\"\n            row = f\"| {match_indicator} | {level_number} | {label} | `{sql_condition}` |\"\n\n        table_rows.append(row)\n\n    markdown_output = \"\\n\".join(table_rows)\n    return markdown_output\n\ndef create_comparison_playground(column_name):\n\n    comparison_types = [\n        'ExactMatch', 'LevenshteinAtThresholds', 'JaroAtThresholds',\n        'JaroWinklerAtThresholds', 'DamerauLevenshteinAtThresholds',\n        'JaccardAtThresholds',\n        'AbsoluteDateDifferenceAtThresholds',\n        'ArrayIntersectAtSizes', 'DateOfBirthComparison',\n         'EmailComparison',\n        'NameComparison', 'PostcodeComparison'\n    ]\n\n    default_values = {\n        'ExactMatch': ('john', 'jon'),\n        'LevenshteinAtThresholds': ('smith', 'smyth'),\n        'JaroAtThresholds': ('martha', 'matha'),\n        'JaroWinklerAtThresholds': ('williams', 'willaims'),\n        'DamerauLevenshteinAtThresholds': ('receive', 'recieve'),\n        'CosineSimilarityAtThresholds': ('data science', 'science data'),\n        'JaccardAtThresholds': ('0123456789', '012345678'),\n        'AbsoluteDateDifferenceAtThresholds': ('2023-01-01', '2023-01-15'),\n        'ArrayIntersectAtSizes': ('apple,banana,cherry', 'banana,cherry,date'),\n        'DateOfBirthComparison': ('1990-05-15', '1990-05-16'),\n        'EmailComparison': ('john.doe@example.com', 'john.doe@other.com'),\n        'NameComparison': ('Elizabeth', 'Elisabeth'),\n        'PostcodeComparison': ('SW1A 1AA', 'SW1A 1AB')\n    }\n\n    db_api = DuckDBAPI()\n\n    docstrings = {}\n    for comp_type in comparison_types:\n        class_obj = getattr(cl, comp_type)\n        init_doc = getattr(class_obj.__init__, '__doc__', None)\n        docstrings[comp_type] = init_doc if init_doc else class_obj.__doc__\n\n\n    def get_comparison(comp_type):\n        if comp_type in ['DateOfBirthComparison']:\n\n            return getattr(cl, comp_type)(column_name, input_is_string=True)\n        if comp_type == 'AbsoluteDateDifferenceAtThresholds':\n            return getattr(cl, comp_type)(column_name, input_is_string=True, metrics=[\"day\", \"month\"], thresholds=[1, 1])\n        elif comp_type in ['EmailComparison', 'ForenameSurnameComparison', 'NameComparison', 'PostcodeComparison', 'ArrayIntersectAtSizes']:\n            return getattr(cl, comp_type)(column_name)\n        else:\n            return getattr(cl, comp_type)(column_name)\n\n    def run_comparison(change):\n        left_value = left_input.value if left_input.value != \"\" else None\n        right_value = right_input.value if right_input.value != \"\" else None\n        comparison = get_comparison(comparison_select.value)\n\n        if comparison_select.value == 'ArrayIntersectAtSizes':\n            left_value = left_value.split(',') if left_value else None\n            right_value = right_value.split(',') if right_value else None\n\n        values_dict = {f\"{column_name}_l\": left_value, f\"{column_name}_r\": right_value}\n\n        output.clear_output()\n        markdown_output = report_comparison_levels(comparison, values_dict, column_name)\n        with output:\n            display(Markdown(\"### Comparison levels:\"))\n            display(Markdown(markdown_output))\n\n            docstring = docstrings.get(comparison_select.value, \"No docstring available\")\n            processed_docstring = \"\\n\".join(line.strip() for line in docstring.split(\"\\n\"))\n            display(Markdown(\"### Comparison Function Docstring:\"))\n            display(Markdown(processed_docstring))\n\n\n        # Store the markdown output for later use\n        playground.markdown_output = markdown_output\n\n\n\n    def on_comparison_change(change):\n        new_value = change['new']\n        left_value, right_value = default_values.get(new_value, ('', ''))\n\n        # Temporarily unobserve the input widgets\n        left_input.unobserve(run_comparison, names='value')\n        right_input.unobserve(run_comparison, names='value')\n\n        # Update the values\n        left_input.value = left_value\n        right_input.value = right_value\n\n        # Re-observe the input widgets\n        left_input.observe(run_comparison, names='value')\n        right_input.observe(run_comparison, names='value')\n\n        # Run the comparison once after updating both inputs\n        run_comparison(None)\n\n\n    comparison_select = widgets.Dropdown(\n        options=comparison_types,\n        value='ExactMatch',\n        description='Comparison:',\n    )\n    left_input = widgets.Text(description=f\"{column_name} Left:\", value=default_values['ExactMatch'][0])\n    right_input = widgets.Text(description=f\"{column_name} Right:\", value=default_values['ExactMatch'][1])\n    output = widgets.Output()\n\n    comparison_select.observe(on_comparison_change, names='value')\n    for widget in (comparison_select, left_input, right_input):\n        widget.observe(run_comparison, names='value')\n\n    # Call run_comparison immediately to compute initial output\n    playground = widgets.VBox([comparison_select, left_input, right_input, output])\n\n    run_comparison(None)\n\n    return playground\n\nplayground = create_comparison_playground(\"column\")\ndisplay(playground)\n</code></pre> <pre><code>VBox(children=(Dropdown(description='Comparison:', options=('ExactMatch', 'LevenshteinAtThresholds', 'JaroAtTh\u2026\n</code></pre> <pre><code>import splink.comparison_level_library as cll\n\nfirst_name_comparison = cl.CustomComparison(\n    comparison_levels=[\n        cll.NullLevel(\"first_name\"),\n        cll.ExactMatchLevel(\"first_name\"),\n        {\n            \"sql_condition\": \"first_name_l = surname_r\",\n            \"label_for_charts\": \"Match on reversed cols: first_name and surname\",\n        },\n        cll.JaroWinklerLevel(\"first_name\", 0.8),\n        cll.ElseLevel(),\n    ]\n)\n# Need to be able to pass values in as a dict {\"first_name_l\": \"Robin\", \"first_name_r\": \"Robyn\", \"surname_l\": \"Linacre\", \"surname_r\": \"Linacre\"}\nvalues = {\n    \"first_name_l\": \"Robin\",\n    \"first_name_r\": \"Linacre\",\n    \"surname_l\": \"Linacre\",\n    \"surname_r\": \"Robin\",\n}\ndisplay(Markdown(report_comparison_levels(first_name_comparison, values, \"first_name\")))\n</code></pre> Match Level Description SQL Condition 4 first_name is NULL <code>\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL</code> 3 Exact match on first_name <code>\"first_name_l\" = \"first_name_r\"</code> \u2713 2 Match on reversed cols: first_name and surname <code>first_name_l = surname_r</code> 1 Jaro-Winkler distance of first_name &gt;= 0.8 <code>jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.8</code> 0 All other comparisons <code>ELSE</code>"},{"location":"demos/examples/duckdb_no_test/cookbook.html","title":"Cookbook","text":""},{"location":"demos/examples/duckdb_no_test/cookbook.html#cookbook","title":"Cookbook","text":"<p>This notebook contains a miscellaneous collection of runnable examples illustrating various Splink techniques.</p>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#array-columns","title":"Array columns","text":""},{"location":"demos/examples/duckdb_no_test/cookbook.html#comparing-array-columns","title":"Comparing array columns","text":"<p>This example shows how we can use use <code>ArrayIntersectAtSizes</code> to assess the similarity of columns containing arrays.</p> <pre><code>import pandas as pd\n\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on\n\n\ndata = [\n    {\"unique_id\": 1, \"first_name\": \"John\", \"postcode\": [\"A\", \"B\"]},\n    {\"unique_id\": 2, \"first_name\": \"John\", \"postcode\": [\"B\"]},\n    {\"unique_id\": 3, \"first_name\": \"John\", \"postcode\": [\"A\"]},\n    {\"unique_id\": 4, \"first_name\": \"John\", \"postcode\": [\"A\", \"B\"]},\n    {\"unique_id\": 5, \"first_name\": \"John\", \"postcode\": [\"C\"]},\n]\n\ndf = pd.DataFrame(data)\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n    ],\n    comparisons=[\n        cl.ArrayIntersectAtSizes(\"postcode\", [2, 1]),\n        cl.ExactMatch(\"first_name\"),\n    ]\n)\n\n\nlinker = Linker(df, settings, DuckDBAPI(), set_up_basic_logging=False)\n\nlinker.inference.predict().as_pandas_dataframe()\n</code></pre> match_weight match_probability unique_id_l unique_id_r postcode_l postcode_r gamma_postcode first_name_l first_name_r gamma_first_name 0 -8.287568 0.003190 4 5 [A, B] [C] 0 John John 1 1 -0.287568 0.450333 3 4 [A] [A, B] 1 John John 1 2 -8.287568 0.003190 3 5 [A] [C] 0 John John 1 3 -8.287568 0.003190 2 3 [B] [A] 0 John John 1 4 -0.287568 0.450333 2 4 [B] [A, B] 1 John John 1 5 -8.287568 0.003190 2 5 [B] [C] 0 John John 1 6 -0.287568 0.450333 1 2 [A, B] [B] 1 John John 1 7 -0.287568 0.450333 1 3 [A, B] [A] 1 John John 1 8 6.712432 0.990554 1 4 [A, B] [A, B] 2 John John 1 9 -8.287568 0.003190 1 5 [A, B] [C] 0 John John 1"},{"location":"demos/examples/duckdb_no_test/cookbook.html#blocking-on-array-columns","title":"Blocking on array columns","text":"<p>This example shows how we can use <code>block_on</code> to block on the individual elements of an array column - that is, pairwise comaprisons are created for pairs or records where any of the elements in the array columns match.</p> <pre><code>import pandas as pd\n\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on\n\n\ndata = [\n    {\"unique_id\": 1, \"first_name\": \"John\", \"postcode\": [\"A\", \"B\"]},\n    {\"unique_id\": 2, \"first_name\": \"John\", \"postcode\": [\"B\"]},\n    {\"unique_id\": 3, \"first_name\": \"John\", \"postcode\": [\"C\"]},\n\n]\n\ndf = pd.DataFrame(data)\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"postcode\", arrays_to_explode=[\"postcode\"]),\n    ],\n    comparisons=[\n        cl.ArrayIntersectAtSizes(\"postcode\", [2, 1]),\n        cl.ExactMatch(\"first_name\"),\n    ]\n)\n\n\nlinker = Linker(df, settings, DuckDBAPI(), set_up_basic_logging=False)\n\nlinker.inference.predict().as_pandas_dataframe()\n</code></pre> match_weight match_probability unique_id_l unique_id_r postcode_l postcode_r gamma_postcode first_name_l first_name_r gamma_first_name 0 -0.287568 0.450333 1 2 [A, B] [B] 1 John John 1"},{"location":"demos/examples/duckdb_no_test/cookbook.html#other","title":"Other","text":""},{"location":"demos/examples/duckdb_no_test/cookbook.html#using-duckdb-without-pandas","title":"Using DuckDB without pandas","text":"<p>In this example, we read data directly using DuckDB and obtain results in native DuckDB <code>DuckDBPyRelation</code> format.</p> <pre><code>import duckdb\nimport tempfile\nimport os\n\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\n# Create a parquet file on disk to demontrate native DuckDB parquet reading\ndf = splink_datasets.fake_1000\ntemp_file = tempfile.NamedTemporaryFile(delete=True, suffix=\".parquet\")\ntemp_file_path = temp_file.name\ndf.to_parquet(temp_file_path)\n\n# Example would start here if you already had a parquet file\nduckdb_df = duckdb.read_parquet(temp_file_path)\n\ndb_api = DuckDBAPI(\":default:\")\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.JaroAtThresholds(\"surname\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"surname\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n\nresult = linker.inference.predict().as_duckdbpyrelation()\n\n# Since result is a DuckDBPyRelation, we can use all the usual DuckDB API\n# functions on it.\n\n# For example, we can use the `sort` function to sort the results,\n# or could use result.to_parquet() to write to a parquet file.\nresult.sort(\"match_weight\")\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    match_weight     \u2502  match_probability   \u2502 unique_id_l \u2502 \u2026 \u2502 gamma_surname \u2502   dob_l    \u2502   dob_r    \u2502 match_key \u2502\n\u2502       double        \u2502        double        \u2502    int64    \u2502   \u2502     int32     \u2502  varchar   \u2502  varchar   \u2502  varchar  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  -11.83278901894715 \u2502 0.000274066864295451 \u2502         758 \u2502 \u2026 \u2502             0 \u2502 2002-09-15 \u2502 2002-09-15 \u2502 0         \u2502\n\u2502 -10.247826518225994 \u2502  0.0008217501639050\u2026 \u2502         670 \u2502 \u2026 \u2502             0 \u2502 2006-12-05 \u2502 2006-12-05 \u2502 0         \u2502\n\u2502  -9.662864017504837 \u2502  0.0012321189988629\u2026 \u2502         558 \u2502 \u2026 \u2502             0 \u2502 2020-02-11 \u2502 2020-02-11 \u2502 0         \u2502\n\u2502  -9.470218939562441 \u2502  0.0014078881864458\u2026 \u2502         259 \u2502 \u2026 \u2502             1 \u2502 1983-03-07 \u2502 1983-03-07 \u2502 0         \u2502\n\u2502  -8.470218939562441 \u2502 0.002811817648042493 \u2502         644 \u2502 \u2026 \u2502            -1 \u2502 1992-02-06 \u2502 1992-02-06 \u2502 0         \u2502\n\u2502  -8.287568102831404 \u2502  0.0031901106569634\u2026 \u2502         393 \u2502 \u2026 \u2502             3 \u2502 1991-05-06 \u2502 1991-04-12 \u2502 1         \u2502\n\u2502  -8.287568102831404 \u2502  0.0031901106569634\u2026 \u2502         282 \u2502 \u2026 \u2502             3 \u2502 2004-12-02 \u2502 2002-02-25 \u2502 1         \u2502\n\u2502  -8.287568102831404 \u2502  0.0031901106569634\u2026 \u2502         282 \u2502 \u2026 \u2502             3 \u2502 2004-12-02 \u2502 1993-03-01 \u2502 1         \u2502\n\u2502  -8.287568102831404 \u2502  0.0031901106569634\u2026 \u2502         531 \u2502 \u2026 \u2502             3 \u2502 1987-09-11 \u2502 2000-09-03 \u2502 1         \u2502\n\u2502  -8.287568102831404 \u2502  0.0031901106569634\u2026 \u2502         531 \u2502 \u2026 \u2502             3 \u2502 1987-09-11 \u2502 1990-10-06 \u2502 1         \u2502\n\u2502           \u00b7         \u2502            \u00b7         \u2502          \u00b7  \u2502 \u00b7 \u2502             \u00b7 \u2502     \u00b7      \u2502     \u00b7      \u2502 \u00b7         \u2502\n\u2502           \u00b7         \u2502            \u00b7         \u2502          \u00b7  \u2502 \u00b7 \u2502             \u00b7 \u2502     \u00b7      \u2502     \u00b7      \u2502 \u00b7         \u2502\n\u2502           \u00b7         \u2502            \u00b7         \u2502          \u00b7  \u2502 \u00b7 \u2502             \u00b7 \u2502     \u00b7      \u2502     \u00b7      \u2502 \u00b7         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         554 \u2502 \u2026 \u2502             3 \u2502 2020-02-11 \u2502 2030-02-08 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         774 \u2502 \u2026 \u2502             3 \u2502 2027-04-21 \u2502 2017-04-23 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         874 \u2502 \u2026 \u2502             3 \u2502 2020-06-23 \u2502 2019-05-23 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         409 \u2502 \u2026 \u2502             3 \u2502 2017-05-03 \u2502 2008-05-05 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         415 \u2502 \u2026 \u2502             3 \u2502 2002-02-25 \u2502 1993-03-01 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         740 \u2502 \u2026 \u2502             3 \u2502 2005-09-18 \u2502 2006-09-14 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         417 \u2502 \u2026 \u2502             3 \u2502 2002-02-24 \u2502 1992-02-28 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         534 \u2502 \u2026 \u2502             3 \u2502 1974-02-28 \u2502 1975-03-31 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         286 \u2502 \u2026 \u2502             3 \u2502 1985-01-05 \u2502 1986-02-04 \u2502 1         \u2502\n\u2502   5.337135982495163 \u2502   0.9758593366351407 \u2502         172 \u2502 \u2026 \u2502             3 \u2502 2012-07-06 \u2502 2012-07-09 \u2502 1         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1800 rows (20 shown)                                                                          13 columns (7 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#fixing-m-or-u-probabilities-during-training","title":"Fixing <code>m</code> or <code>u</code> probabilities during training","text":"<pre><code>import splink.comparison_level_library as cll\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\n\ndb_api = DuckDBAPI()\n\nfirst_name_comparison = cl.CustomComparison(\n    comparison_levels=[\n        cll.NullLevel(\"first_name\"),\n        cll.ExactMatchLevel(\"first_name\").configure(\n            m_probability=0.9999,\n            fix_m_probability=True,\n            u_probability=0.7,\n            fix_u_probability=True,\n        ),\n        cll.ElseLevel(),\n    ]\n)\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        first_name_comparison,\n        cl.ExactMatch(\"surname\"),\n        cl.ExactMatch(\"dob\"),\n        cl.ExactMatch(\"city\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"dob\"),\n    ],\n    additional_columns_to_retain=[\"cluster\"],\n)\n\ndf = splink_datasets.fake_1000\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n\nlinker.visualisations.m_u_parameters_chart()\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#manually-altering-m-and-u-probabilities-post-training","title":"Manually altering <code>m</code> and <code>u</code> probabilities post-training","text":"<p>This is not officially supported, but can be useful for ad-hoc alterations to trained models.</p> <pre><code>import splink.comparison_level_library as cll\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\nfrom splink.datasets import splink_dataset_labels\n\nlabels = splink_dataset_labels.fake_1000_labels\n\ndb_api = DuckDBAPI()\n\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.ExactMatch(\"first_name\"),\n        cl.ExactMatch(\"surname\"),\n        cl.ExactMatch(\"dob\"),\n        cl.ExactMatch(\"city\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"dob\"),\n    ],\n)\ndf = splink_datasets.fake_1000\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n\n\nsurname_comparison = linker._settings_obj._get_comparison_by_output_column_name(\n    \"surname\"\n)\nelse_comparison_level = (\n    surname_comparison._get_comparison_level_by_comparison_vector_value(0)\n)\nelse_comparison_level._m_probability = 0.1\n\n\nlinker.visualisations.m_u_parameters_chart()\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#generate-the-beta-labelling-tool","title":"Generate the (beta) labelling tool","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.ExactMatch(\"first_name\"),\n        cl.ExactMatch(\"surname\"),\n        cl.ExactMatch(\"dob\"),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    max_iterations=2,\n)\n\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n\nlinker.training.estimate_probability_two_random_records_match(\n    [block_on(\"first_name\", \"surname\")], recall=0.7\n)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n\npairwise_predictions = linker.inference.predict(threshold_match_weight=-10)\n\nfirst_unique_id = df.iloc[0].unique_id\nlinker.evaluation.labelling_tool_for_specific_record(unique_id=first_unique_id, overwrite=True)\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#modifying-settings-after-loading-from-a-serialised-json-model","title":"Modifying settings after loading from a serialised <code>.json</code> model","text":"<pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\n# setup to create a model\n\ndb_api = DuckDBAPI()\n\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.LevenshteinAtThresholds(\"first_name\"),\n        cl.LevenshteinAtThresholds(\"surname\"),\n\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"surname\"),\n    ]\n)\n\nlinker = Linker(df, settings, db_api)\n\n\nlinker.misc.save_model_to_json(\"mod.json\", overwrite=True)\n\nnew_settings = SettingsCreator.from_path_or_dict(\"mod.json\")\n\nnew_settings.retain_intermediate_calculation_columns = True\nnew_settings.blocking_rules_to_generate_predictions = [\"1=1\"]\nnew_settings.additional_columns_to_retain = [\"cluster\"]\n\nlinker = Linker(df, new_settings, DuckDBAPI())\n\nlinker.inference.predict().as_duckdbpyrelation().show()\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#using-a-duckdb-udf-in-a-comparison-level","title":"Using a DuckDB UDF in a comparison level","text":"<pre><code>import difflib\n\nimport duckdb\n\nimport splink.comparison_level_library as cll\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\n\ndef custom_partial_ratio(s1, s2):\n    \"\"\"Custom function to compute partial ratio similarity between two strings.\"\"\"\n    s1, s2 = str(s1), str(s2)\n    matcher = difflib.SequenceMatcher(None, s1, s2)\n    return matcher.ratio()\n\n\ndf = splink_datasets.fake_1000\n\ncon = duckdb.connect()\ncon.create_function(\n    \"custom_partial_ratio\",\n    custom_partial_ratio,\n    [duckdb.typing.VARCHAR, duckdb.typing.VARCHAR],\n    duckdb.typing.DOUBLE,\n)\ndb_api = DuckDBAPI(connection=con)\n\n\nfuzzy_email_comparison = {\n    \"output_column_name\": \"email_fuzzy\",\n    \"comparison_levels\": [\n        cll.NullLevel(\"email\"),\n        cll.ExactMatchLevel(\"email\"),\n        {\n            \"sql_condition\": \"custom_partial_ratio(email_l, email_r) &gt; 0.8\",\n            \"label_for_charts\": \"Fuzzy match (\u2265 0.8)\",\n        },\n        cll.ElseLevel(),\n    ],\n}\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.ExactMatch(\"first_name\"),\n        cl.ExactMatch(\"surname\"),\n        cl.ExactMatch(\"dob\"),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        fuzzy_email_comparison,\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    max_iterations=2,\n)\n\nlinker = Linker(df, settings, db_api)\n\nlinker.training.estimate_probability_two_random_records_match(\n    [block_on(\"first_name\", \"surname\")], recall=0.7\n)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e5)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n\npairwise_predictions = linker.inference.predict(threshold_match_weight=-10)\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#nested-linkage","title":"Nested linkage","text":"<p>In this example, we want to deduplicate persons but only within each company.</p> <p>The problem is that the companies themselves may be duplicates, so we proceed by deduplicating the companies first and then deduplicating persons nested within each company we resolved in step 1.</p> <p>Note I do not include full model training code here, just a simple/illustrative model spec.  The example is more about demonstrating the nested linkage process.</p> <pre><code>import duckdb\nimport pandas as pd\nimport os\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on\nfrom splink.clustering import cluster_pairwise_predictions_at_threshold\n\n# Example data with companies and persons\ncompany_person_records_list = [\n    {\n        \"unique_id\": 1001,\n        \"client_id\": \"GGN1\",\n        \"company_name\": \"Green Garden Nurseries Ltd\",\n        \"postcode\": \"NR1 1AB\",\n        \"person_firstname\": \"John\",\n        \"person_surname\": \"Smith\",\n    },\n    {\n        \"unique_id\": 1002,\n        \"client_id\": \"GGN1\",\n        \"company_name\": \"Green Gardens Ltd\",\n        \"postcode\": \"NR1 1AB\",\n        \"person_firstname\": \"Sarah\",\n        \"person_surname\": \"Jones\",\n    },\n    {\n        \"unique_id\": 1003,\n        \"client_id\": \"GGN2\",\n        \"company_name\": \"Green Garden Nurseries Ltd\",\n        \"postcode\": \"NR1 1AB\",\n        \"person_firstname\": \"John\",\n        \"person_surname\": \"Smith\",\n    },\n    {\n        \"unique_id\": 3001,\n        \"client_id\": \"GW1\",\n        \"company_name\": \"Garden World\",\n        \"postcode\": \"LS2 3EF\",\n        \"person_firstname\": \"Emma\",\n        \"person_surname\": \"Wilson\",\n    },\n    {\n        \"unique_id\": 3002,\n        \"client_id\": \"GW1\",\n        \"company_name\": \"Garden World UK\",\n        \"postcode\": \"LS2 3EF\",\n        \"person_firstname\": \"Emma\",\n        \"person_surname\": \"Wilson\",\n    },\n    {\n        \"unique_id\": 3003,\n        \"client_id\": \"GW2\",\n        \"company_name\": \"Garden World\",\n        \"postcode\": \"LS2 3EF\",\n        \"person_firstname\": \"Emma\",\n        \"person_surname\": \"Wilson\",\n    },\n    {\n        \"unique_id\": 3004,\n        \"client_id\": \"GW2\",\n        \"company_name\": \"Garden World\",\n        \"postcode\": \"LS2 3EF\",\n        \"person_firstname\": \"James\",\n        \"person_surname\": \"Taylor\",\n    },\n]\ncompany_person_records = pd.DataFrame(company_person_records_list)\ncompany_person_records\nprint(\"========== NESTED COMPANY-PERSON LINKAGE EXAMPLE ==========\")\nprint(\"This example demonstrates a two-phase linkage process:\")\nprint(\"1. First, link and cluster to find duplicate companies (client_id)\")\nprint(\"2. Then, deduplicate persons ONLY within each company cluster\")\n\n# Initialize database\nif os.path.exists(\"nested_linkage.ddb\"):\n    os.remove(\"nested_linkage.ddb\")\ncon = duckdb.connect(\"nested_linkage.ddb\")\n\n# Load data into DuckDB\ncon.execute(\n    \"CREATE OR REPLACE TABLE company_person_records AS \"\n    \"SELECT * FROM company_person_records\"\n)\n\n\nprint(\"\\n--- PHASE 1: COMPANY LINKAGE ---\")\nprint(\"Company records to be linked:\")\ncon.table(\"company_person_records\").show()\n\n# STEP 1: Find duplicate client_ids\n\n\n# Configure company linkage\n# We match on person name because if we have duplicate client_ids,\n# it's likely that they may share the same contact\n# Note though, at this stage the entity is client not a person\ncompany_settings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    unique_id_column_name=\"unique_id\",\n    probability_two_random_records_match=0.001,\n    comparisons=[\n        cl.ExactMatch(\"client_id\"),\n        cl.JaroWinklerAtThresholds(\"person_firstname\"),\n        cl.JaroWinklerAtThresholds(\"person_surname\"),\n        cl.JaroWinklerAtThresholds(\"company_name\"),\n        cl.ExactMatch(\"postcode\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"postcode\"),\n        block_on(\"company_name\"),\n    ],\n    retain_matching_columns=True,\n)\n\ndb_api = DuckDBAPI(connection=con)\ncompany_linker = Linker(\"company_person_records\", company_settings, db_api)\ncompany_predictions = company_linker.inference.predict(threshold_match_probability=0.5)\n\nprint(\"\\nCompany pairwise matches:\")\ncompany_predictions.as_duckdbpyrelation().show()\n\n# Cluster companies\ncompany_nodes = con.sql(\"SELECT DISTINCT client_id FROM company_person_records\")\ncompany_edges = con.sql(f\"\"\"\n    SELECT\n        client_id_l as n_1,\n        client_id_r as n_2,\n        match_probability\n    FROM {company_predictions.physical_name}\n\"\"\")\n\n# Perform company clustering\ncompany_clusters = cluster_pairwise_predictions_at_threshold(\n    company_nodes,\n    company_edges,\n    node_id_column_name=\"client_id\",\n    edge_id_column_name_left=\"n_1\",\n    edge_id_column_name_right=\"n_2\",\n    db_api=db_api,\n    threshold_match_probability=0.5,\n)\n\n# Add company cluster IDs to original records\ncompany_clusters_ddb = company_clusters.as_duckdbpyrelation()\ncon.register(\"company_clusters_ddb\", company_clusters_ddb)\n\n\nsql = \"\"\"\nCREATE TABLE records_with_company_cluster AS\nSELECT cr.*,\n       cc.cluster_id as company_cluster_id\nFROM company_person_records cr\nLEFT JOIN company_clusters_ddb cc\nON cr.client_id = cc.client_id\n\"\"\"\ncon.execute(sql)\nprint(\"Records with company cluster:\")\ncon.table(\"records_with_company_cluster\").show()\n\n# Not needed, just to see what's happening\nprint(\"\\nCompany clustering results:\")\ncon.sql(\"\"\"\nSELECT\n    company_cluster_id,\n    array_agg(DISTINCT client_id) as client_ids,\n    array_agg(DISTINCT company_name) as company_names\nFROM records_with_company_cluster\nGROUP BY company_cluster_id\n\"\"\").show()\n\nprint(\"\\n--- PHASE 2: PERSON LINKAGE WITHIN COMPANIES ---\")\nprint(\"Now linking persons, but only within their company clusters\")\n\n# STEP 2: Link persons within company clusters\n# Create a new connection to isolate this step\ncon2 = duckdb.connect()\ncon2.sql(\"attach 'nested_linkage.ddb' as linkage_db\")\ncon2.execute(\n    \"create table records_with_company_cluster as select * from linkage_db.records_with_company_cluster\"\n)\ndb_api2 = DuckDBAPI(connection=con2)\n\n# Configure person linkage within company clusters\n# Simple linking model just distinguishes between people within a client_id\n# There shouldn't be many so this model can be straightforward\nperson_settings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    probability_two_random_records_match=0.01,\n    comparisons=[\n        cl.JaroWinklerAtThresholds(\"person_firstname\"),\n        cl.JaroWinklerAtThresholds(\"person_surname\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        # Critical: Block on company_cluster_id to only compare within company\n        block_on(\"company_cluster_id\"),\n    ],\n    retain_matching_columns=True,\n)\n\n# Link persons within company clusters\nperson_linker = Linker(\"records_with_company_cluster\", person_settings, db_api2)\nperson_predictions = person_linker.inference.predict(threshold_match_probability=0.5)\n\nprint(\"\\nPerson pairwise matches (within company clusters):\")\nperson_predictions.as_duckdbpyrelation().show(max_width=1000)\n\nperson_clusters = person_linker.clustering.cluster_pairwise_predictions_at_threshold(\n    person_predictions, threshold_match_probability=0.5\n)\n\nperson_clusters.as_duckdbpyrelation().sort(\"cluster_id\").show(max_width=1000)\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/cookbook.html#comparing-a-list-of-values-with-fuzzy-matching-and-term-frequency-adjustments","title":"Comparing a list of values with fuzzy matching and term frequency adjustments","text":"<p>See here for a description of this approach</p> <pre><code>import duckdb\n\nimport splink.comparison_level_library as cll\nimport splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator\n\ncon = duckdb.connect(database=\":memory:\")\n\nleft_records = [\n    {\n        \"unique_id\": 1,\n        \"primary_forename\": \"Alisha\",\n        \"all_forenames\": [\"Alisha\", \"Alisha Louise\", \"Ali\"],\n    },\n    {\n        \"unique_id\": 2,\n        \"primary_forename\": \"Michael\",\n        \"all_forenames\": [\"Michael\", \"Mike\"],\n    },\n]\n\nright_records = [\n    {\"unique_id\": 1, \"primary_forename\": \"Alisha\", \"all_forenames\": [\"Alisha\", \"Ali\"]},\n    {\"unique_id\": 3, \"primary_forename\": \"Alysha\", \"all_forenames\": [\"Alysha\"]},\n    {\"unique_id\": 9, \"primary_forename\": \"Michelle\", \"all_forenames\": [\"Michelle\"]},\n]\n\n\ndef make_table(name, recs):\n    con.execute(f\"drop table if exists {name}\")\n    con.execute(\n        f\"\"\"\n        create table {name} (\n            unique_id integer,\n            primary_forename varchar,\n            all_forenames varchar[]\n        )\n    \"\"\"\n    )\n    for r in recs:\n        arr = \"[\" + \", \".join(f\"'{v}'\" for v in r[\"all_forenames\"]) + \"]\"\n        con.execute(\n            f\"\"\"\n            insert into {name} values\n                ({r[\"unique_id\"]}, '{r[\"primary_forename\"]}', {arr})\n        \"\"\"\n        )\n\n\nmake_table(\"df_left\", left_records)\nmake_table(\"df_right\", right_records)\ncon.table(\"df_left\").show()\ncon.table(\"df_right\").show()\n\n\nforename_comparison = cl.CustomComparison(\n    output_column_name=\"forename\",\n    comparison_levels=[\n        cll.NullLevel(\"primary_forename\"),\n        # 1. exact with term-frequency adjustment\n        cll.ExactMatchLevel(\"primary_forename\", term_frequency_adjustments=True),\n        # 2. any overlap between arrays\n        cll.ArrayIntersectLevel(\"all_forenames\", min_intersection=1),\n        # 3. tight fuzzy\n        cll.JaroWinklerLevel(\"primary_forename\", distance_threshold=0.9),\n        # 4. looser fuzzy\n        cll.JaroWinklerLevel(\"primary_forename\", distance_threshold=0.7),\n        # 5. fuzzy anywhere in arrays\n        cll.PairwiseStringDistanceFunctionLevel(\n            col_name=\"all_forenames\",\n            distance_function_name=\"jaro_winkler\",\n            distance_threshold=0.85,\n        ),\n        cll.ElseLevel(),\n    ],\n    comparison_description=\"Forename comparison combining exact, array overlap and fuzzy logic\",\n)\n\n\nsettings = SettingsCreator(\n    link_type=\"link_only\",\n    unique_id_column_name=\"unique_id\",\n    blocking_rules_to_generate_predictions=[\n        # create all comparisons for demo\n        \"1=1\"\n    ],\n    comparisons=[forename_comparison],\n    retain_intermediate_calculation_columns=True,\n    retain_matching_columns=True,\n)\nlinker = Linker(\n    [\"df_left\", \"df_right\"],\n    settings,\n    db_api=DuckDBAPI(con),\n)\n\n# Skip training for demo purposes, just demonstrate that predict() works\n\ndf_predict = linker.inference.predict()\ndf_predict.as_duckdbpyrelation()\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html","title":"Pseudopeople Census to ACS link","text":""},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#linking-the-pseudopeople-census-and-acs-datasets","title":"Linking the pseudopeople Census and ACS datasets","text":"<p>In this tutorial we will configure and link two realistic, simulated datasets generated by the pseudopeople Python package. These datasets reflect a fictional sample population of ~10,000 simulants living in Anytown, Washington, USA, but pseudopeople can also generate datasets about two larger fictional populations, one simulating the state of Rhode Island, and the other simulating the entire United States.</p> <p>Here we will link Anytown's 2020 Decennial Census dataset to all years of its American Community Survey (ACS) dataset. Some people surveyed in the ACS, particularly in years other than 2020, will not be represented in the 2020 Census because they did not live in Anytown, or were not alive, when the 2020 Census was conducted - pseudopeople simulates people moving residence, being born and dying. So, our aim will be to link as many as possible of the ACS respondents which are reflected in the 2020 Census.</p> <p>This tutorial is adapted from the Febrl4 linking example.</p> <p> </p>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#configuring-pseudopeople","title":"Configuring pseudopeople","text":"<p>pseudopeople is designed to generate realistic datasets which are challenging to link to one another in many of the same ways that actual datasets are challenging to link. This requires adding noise to the data in the form of various types of errors that occur in real data collection and entry. The frequencies of each type of noise in the dataset can be configured for each column.</p> <p>Because the ACS dataset is small and therefore has less opportunities for noise to create linkage challenges,  let's increase the noise for the <code>date_of_birth</code> and <code>last_name</code> columns in both datasets from their default values. For <code>date_of_birth</code> we increase the frequency with which respondents swap the month and day when answering that survey question, and for <code>last_name</code> we increase both the frequency of respondents typing their last names carelessly, and the probability of a mistake on each character when typing carelessly. See here and here for more details.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport pseudopeople as psp\n\npd.set_option(\"display.max_columns\", 7)\n</code></pre> <pre><code>config_census = {\n    \"decennial_census\": {  # Dataset\n        # \"Swap month and day\" and \"Make typos\" are in the\n        # column-based noise category\n        \"column_noise\": {\n            \"date_of_birth\": {  # Column\n                \"swap_month_and_day\": {  # Noise type\n                    \"cell_probability\": 0.15,  # Default = .01\n                },\n            },\n            \"last_name\": {  # Column\n                \"make_typos\": {  # Noise type\n                    \"cell_probability\": 0.1,  # Default = .01\n                    \"token_probability\": 0.15,  # Default = .10\n                },\n            },\n        },\n    },\n}\nconfig_acs = {\n    \"american_community_survey\": {  # Dataset\n        # \"Swap month and day\" and \"Make typos\" are in the\n        # column-based noise category\n        \"column_noise\": {\n            \"date_of_birth\": {  # Column\n                \"swap_month_and_day\": {  # Noise type\n                    \"cell_probability\": 0.15,  # Default = .01\n                },\n            },\n            \"last_name\": {  # Column\n                \"make_typos\": {  # Noise type\n                    \"cell_probability\": 0.1,  # Default = .01\n                    \"token_probability\": 0.15,  # Default = .10\n                },\n            },\n        },\n    },\n}\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#exploring-the-data","title":"Exploring the data","text":"<p>Next, let's get the data ready for Splink. The Census data has about 10,000 rows, while the ACS data only has around 200. Note that each dataset has a column called <code>simulant_id</code>, which uniquely identifies a simulated person in our fictional population. The <code>simulant_id</code> is consistent across datasets, and can be used to check the accuracy of our model. Because it represents the truth, and we wouldn't have it in a real-life linkage task, we will not use it for blocking, comparisons, or any other part of our model, except to check the accuracy of our predictions at the end.</p> <pre><code>census = psp.generate_decennial_census(config=config_census)\nacs = psp.generate_american_community_survey(\n    config=config_acs, year=None\n)  # generate all years data with year=None\n\n# Make a year column for ACS so we can combine it with the Census column\n#  for exploratory analysis charts\nacs[\"year\"] = acs.survey_date.dt.year\nacs = acs.drop(\"survey_date\", axis=1)\n\n# uniquely identify each row in the datasets (regardless of simulant_id)\ncensus[\"id\"] = census.index\nacs[\"id\"] = len(census) + acs.index\n\n# calculate age_in_2020 since the ACS data contains surveys from different years\ncensus[\"age_in_2020\"] = pd.to_numeric(census.age, errors=\"coerce\")\nacs[\"age_in_2020\"] = pd.to_numeric(acs.age, errors=\"coerce\") - (acs.year - 2020)\n\n# create row ID to simulant_id lookup table\ncensus_ids = census[[\"id\", \"simulant_id\"]]\nacs_ids = acs[[\"id\", \"simulant_id\"]]\nsimulant_lookup = pd.concat([census_ids, acs_ids]).set_index(\"id\")\n\n\ndef prepare_data(data):\n    # concatenate address fields, setting the new field to NaN\n    # if any address fields besides unit number are missing\n    unit_number_no_na = data.unit_number.fillna(\"\")\n\n    columns_to_concat = [\n        \"street_number\",\n        \"street_name\",\n        \"city\",\n        \"state\",\n        \"zipcode\",\n    ]\n\n    has_addr_nan = data[columns_to_concat].isna().any(axis=1)\n\n    address_data = data[columns_to_concat].astype(str)\n    address_data[\"unit_number\"] = unit_number_no_na\n    data[\"address\"] = address_data.agg(\" \".join, axis=1).str.strip()\n    data.loc[has_addr_nan, \"address\"] = np.nan\n\n    return data\n\n\ndfs = [prepare_data(dataset) for dataset in [census, acs]]\n\ndfs[0]  # Census\n</code></pre> simulant_id household_id first_name ... id age_in_2020 address 0 0_2 0_7 Diana ... 0 25.0 5112 145th st Anytown WA 00000 1 0_3 0_7 Anna ... 1 25.0 5112 145th st Anytown WA 00000 2 0_923 0_8033 Gerald ... 2 76.0 1130 mallory ln Anytown WA 00000 3 0_2641 0_1066 Loretta ... 3 61.0 NaN 4 0_2801 0_1138 Richard ... 4 73.0 950 caribou lane Anytown WA 00000 ... ... ... ... ... ... ... ... 10226 0_11994 0_8051 Lauren ... 10226 17.0 3304 ethan allen way Anytown WA 00000 unit 200 10227 0_19693 0_6152 Johana ... 10227 20.0 1095 ernst st Anytown WA 00000 10228 0_19556 0_2064 Benjamin ... 10228 19.0 2002 203rd pl se Anytown WA 00000 10229 0_19579 0_1802 Brielle ... 10229 19.0 233 saint peters road Anytown WA 00000 10230 0_19666 0_881 Kyle ... 10230 19.0 224 s moraine st Anytown WA 00000 <p>10231 rows \u00d7 21 columns</p> <pre><code>dfs[1]  # ACS\n</code></pre> simulant_id household_id first_name ... id age_in_2020 address 0 0_10873 0_4411 Betty ... 10231 87.0 2403 magnolia park rd Anytown WA 00000 1 0_10344 0_4207 Dina ... 10232 47.0 4826 stone ridge ln Anytown WA 00000 2 0_10345 0_4207 Fiona ... 10233 13.0 4826 stone ridge ln Anytown WA 00000 3 0_10346 0_4207 Molly ... 10234 9.0 4826 stone ridge ln Anytown WA 00000 4 0_10347 0_4207 Daniel ... 10235 19.0 4826 stone ridge ln Anytown WA 00000 ... ... ... ... ... ... ... ... 206 0_18143 0_14148 Bentley ... 10437 7.0 2040 magnolia court Anytown WA 00000 207 0_24866 0_14148 Jordan ... 10438 25.0 2040 magnolia court Anytown WA 00000 208 0_18238 0_14832 Sarah ... 10439 32.0 NaN 209 0_9712 0_15932 Mom ... 10440 65.0 3619 hanging moss loop Anytown WA 00000 210 0_12239 0_14049 Sherry ... 10441 48.0 212a apple blossom dr Anytown WA 00000 <p>211 rows \u00d7 21 columns</p> <p>Because we are using all years of ACS surveys, and only the 2020 Decennial Census, there will be respondents to ACS surveys which were not in the 2020 Census because they moved away from Anytown before the 2020 Census was conducted, moved to Anytown after the 2020 Census was conducted, or were not alive during the 2020 Census. Let's check how many of these there are and display some of them. </p> <p>Note that we cannot simply remove ACS respondents whose surveys indicated they were born after 2020, because their <code>age</code> response could be inaccurate. Also note that we are only able to count and display these simulants for the tutorial because we know the true identities of each simulant - in a real-record linkage scenario, we would not know this information.</p> <pre><code>not_in_census = acs[~acs.simulant_id.isin(census.simulant_id)]\ndisplay(f\"{len(not_in_census)} ACS simulants not in 2020 Census\")\nnot_in_census.head(5)\n</code></pre> <pre><code>'54 ACS simulants not in 2020 Census'\n</code></pre> simulant_id household_id first_name ... id age_in_2020 address 4 0_10347 0_4207 Daniel ... 10235 19.0 4826 stone ridge ln Anytown WA 00000 16 0_2713 0_14807 Kristi ... 10247 36.0 6045 s patterson pl Anytown WA 00000 73 0_19708 0_3 Ariana ... 10304 20.0 8203 west farwell avenue Anytown WA 00000 93 0_16379 0_2246 Gregory ... 10324 56.0 12679 kingston ave Anytown WA 00000 101 0_1251 0_9630 NaN ... 10332 16.0 17947 newman dr Anytown WA 00000 <p>5 rows \u00d7 21 columns</p> <p>Next, to better understand which variables will prove useful in linking, we have a look at how populated each column is, as well as the distribution of unique values within each.</p> <p>It's usually a good idea to perform exploratory analysis on your data so you understand what's in each column and how often it's missing.</p> <pre><code>from splink import DuckDBAPI\nfrom splink.exploratory import completeness_chart\n\ncompleteness_chart(\n    dfs,\n    db_api=DuckDBAPI(),\n    table_names_for_chart=[\"census\", \"acs\"],\n    cols=[\n        \"age_in_2020\",\n        \"last_name\",\n        \"sex\",\n        \"middle_initial\",\n        \"date_of_birth\",\n        \"race_ethnicity\",\n        \"first_name\",\n        \"address\",\n        \"street_number\",\n        \"street_name\",\n        \"unit_number\",\n        \"city\",\n        \"state\",\n        \"zipcode\",\n    ],\n)\n</code></pre> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(dfs, db_api=DuckDBAPI())\n</code></pre> <p>You will notice that six addresses have many more simulants living at them than the others. Simulants in our fictional population may live either in a residential household, or in group quarters (GQ), which models institutional and non-institutional GQ establishments: carceral, nursing homes, and other institutional, and college, military, and other non-institutional. Each of these addresses simulates one of these six types of GQ \"households\".</p> <p>In the ACS data there are 103 unique street names (including typos), with 58 residents of the West Farwell Avenue GQ represented.</p> <pre><code>acs.street_name.value_counts()\n</code></pre> <pre><code>street_name\nwest farwell avenue    58\ngrove street            6\nn holman st             4\nstone ridge ln          4\nglenview rd             3\n                       ..\nblack mountain rd       1\necton la                1\nw 47th st               1\nkelton ave              1\nb pl nw                 1\nName: count, Length: 103, dtype: int64\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#defining-the-model","title":"Defining the model","text":"<p>Next let's come up with some candidate blocking rules, which define the record comparisons to generate, and have a look at how many comparisons each rule will generate.</p> <p>For blocking rules that we use in prediction, our aim is to have the union of all rules cover all true matches, whilst avoiding generating so many comparisons that it becomes computationally intractable - i.e. each true match should have at least one of the following conditions holding.</p> <pre><code>from splink import DuckDBAPI, block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules = [\n    block_on(\"first_name\"),\n    block_on(\"last_name\"),\n    block_on(\"date_of_birth\"),\n    block_on(\"street_name\"),\n    block_on(\"age_in_2020\", \"sex\"),\n    block_on(\"age_in_2020\", \"race_ethnicity\"),\n    block_on(\"age_in_2020\", \"middle_initial\"),\n    block_on(\"street_number\"),\n    block_on(\"middle_initial\", \"sex\", \"race_ethnicity\"),\n]\n\n\ndb_api = DuckDBAPI()\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=dfs,\n    blocking_rules=blocking_rules,\n    db_api=db_api,\n    link_type=\"link_only\",\n    unique_id_column_name=\"id\",\n    source_dataset_column_name=\"source_dataset\",\n)\n</code></pre> <p>For columns like <code>age_in_2020</code> that would create too many comparisons, we combine them with one or more other columns which would also create too many comparisons if blocked on alone.</p> <p>Now we get our model's settings by including the blocking rules, as well as deciding the actual comparisons we will be including in our model.</p> <p>To estimate <code>probability_two_random_records_match</code>, we will make the assumption that everyone in the ACS is also in the Census - we know from our check using the \"true\" simulant IDs above that this is not the case, but it is a good approximation. Depending on our knowledge of the dataset, we might be able to get a more accurate value by defining a set of deterministic matching rules and a guess of the number of matches reflected in those rules.</p> <pre><code>import splink.comparison_library as cl\nfrom splink import Linker, SettingsCreator\n\nsettings = SettingsCreator(\n    unique_id_column_name=\"id\",\n    link_type=\"link_only\",\n    blocking_rules_to_generate_predictions=blocking_rules,\n    comparisons=[\n        cl.NameComparison(\"first_name\", jaro_winkler_thresholds=[0.9]).configure(\n            term_frequency_adjustments=True\n        ),\n        cl.ExactMatch(\"middle_initial\").configure(term_frequency_adjustments=True),\n        cl.NameComparison(\"last_name\", jaro_winkler_thresholds=[0.9]).configure(\n            term_frequency_adjustments=True\n        ),\n        cl.DamerauLevenshteinAtThresholds(\n            \"date_of_birth\", distance_threshold_or_thresholds=[1]\n        ),\n        cl.DamerauLevenshteinAtThresholds(\"address\").configure(\n            term_frequency_adjustments=True\n        ),\n        cl.ExactMatch(\"sex\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n    probability_two_random_records_match=len(dfs[1]) / (len(dfs[0]) * len(dfs[1])),\n)\n\nlinker = Linker(\n    dfs, settings, db_api=DuckDBAPI(), input_table_aliases=[\"census\", \"acs\"]\n)\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#estimating-model-parameters","title":"Estimating model parameters","text":"<p>Next we estimate <code>u</code> and <code>m</code> values for each comparison, so that we can move to generating predictions.</p> <pre><code># We generally recommend setting max pairs higher (e.g. 1e7 or more)\n# But this will run faster for the purpose of this demo\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - middle_initial (no m values are trained).\n    - last_name (no m values are trained).\n    - date_of_birth (no m values are trained).\n    - address (no m values are trained).\n    - sex (no m values are trained).\n</code></pre> <p>When training the <code>m</code> values using expectation maximisation, we need some more blocking rules to reduce the total number of comparisons. For each rule, we want to ensure that we have neither proportionally too many matches, or too few.</p> <p>We must run this multiple times using different rules so that we can obtain estimates for all comparisons - if we block on e.g. <code>date_of_birth</code>, then we cannot compute the <code>m</code> values for the <code>date_of_birth</code> comparison, as we have only looked at records where these match.</p> <pre><code>session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"date_of_birth\"), estimate_without_term_frequencies=True\n)\nsession_ln = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"last_name\"), estimate_without_term_frequencies=True\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"date_of_birth\" = r.\"date_of_birth\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - middle_initial\n    - last_name\n    - address\n    - sex\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - date_of_birth\n\nIteration 1: Largest change in params was -0.303 in the m_probability of address, level `Exact match on address`\nIteration 2: Largest change in params was 0.0023 in probability_two_random_records_match\nIteration 3: Largest change in params was 6.64e-05 in probability_two_random_records_match\n\nEM converged after 3 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - date_of_birth (no m values are trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.\"last_name\" = r.\"last_name\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - middle_initial\n    - date_of_birth\n    - address\n    - sex\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - last_name\n\nIteration 1: Largest change in params was 0.215 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 2: Largest change in params was 0.0221 in the m_probability of date_of_birth, level `All other comparisons`\nIteration 3: Largest change in params was 0.00939 in the m_probability of first_name, level `All other comparisons`\nIteration 4: Largest change in params was 0.00489 in the m_probability of first_name, level `All other comparisons`\nIteration 5: Largest change in params was 0.00269 in the m_probability of first_name, level `All other comparisons`\nIteration 6: Largest change in params was 0.00155 in the m_probability of first_name, level `All other comparisons`\nIteration 7: Largest change in params was 0.000924 in the m_probability of first_name, level `All other comparisons`\nIteration 8: Largest change in params was 0.000563 in the m_probability of first_name, level `All other comparisons`\nIteration 9: Largest change in params was 0.000348 in the m_probability of first_name, level `All other comparisons`\nIteration 10: Largest change in params was 0.000218 in the m_probability of first_name, level `All other comparisons`\nIteration 11: Largest change in params was 0.000137 in the m_probability of first_name, level `All other comparisons`\nIteration 12: Largest change in params was 8.61e-05 in the m_probability of first_name, level `All other comparisons`\n\nEM converged after 12 iterations\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <p>If we wish we can have a look at how our parameter estimates changes over these training sessions.</p> <pre><code>session_dob.m_u_values_interactive_history_chart()\n</code></pre> <pre><code>session_ln.m_u_values_interactive_history_chart()\n</code></pre> <p>For variables that aren't used in the <code>m</code>-training blocking rules, we have two estimates --- one from each of the training sessions (see for example <code>address</code>). We can have a look at how the values compare between them, to ensure that we don't have drastically different values, which may be indicative of an issue.</p> <pre><code>linker.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <p>We can now visualise some of the details of our model. We can look at the match weights, which tell us the relative importance for/against a match for each of our comparison levels.</p> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <p>As well as the match weights, which give us an idea of the overall effect of each comparison level, we can also look at the individual <code>u</code> and <code>m</code> parameter estimates, which tells us about the prevalence of coincidences and mistakes (for further details/explanation about this see this article). We might want to revise aspects of our model based on the information we ascertain here.</p> <p>Note however that some of these values are very small, which is why the match weight chart is often more useful for getting a decent picture of things.</p> <pre><code>linker.visualisations.m_u_parameters_chart()\n</code></pre> <p>It is also useful to have a look at unlinkable records - these are records which do not contain enough information to be linked at some match probability threshold. We can figure this out by seeing whether records are able to be matched with themselves.</p> <p>We have low column missingness, so almost all of our records are linkable for almost all match thresholds.</p> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre>"},{"location":"demos/examples/duckdb_no_test/pseudopeople-acs.html#making-predictions-and-evaluating-results","title":"Making predictions and evaluating results","text":"<pre><code>predictions = linker.inference.predict()  # include all match_probabilities\ndf_predictions = predictions.as_pandas_dataframe()\npd.set_option(\"display.max_columns\", None)\ncolumns_to_show = [\n    \"match_probability\",\n    \"first_name_l\",\n    \"first_name_r\",\n    \"last_name_l\",\n    \"last_name_r\",\n    \"date_of_birth_l\",\n    \"date_of_birth_r\",\n    \"address_l\",\n    \"address_r\",\n]\ndf_predictions[columns_to_show]\n</code></pre> <pre><code>Blocking time: 0.09 seconds\nPredict time: 2.18 seconds\n</code></pre> match_probability first_name_l first_name_r last_name_l last_name_r date_of_birth_l date_of_birth_r address_l address_r 0 9.606711e-06 Clarence Clarence Weinmann Carlson 31/12/1959 29/11/1942 2540 grand river boulevard east Anytown WA 00000 64-34 se 16th ave Anytown WA 00000 1 5.612029e-05 Mark Mark Witczak Leath 53/10/1954 12/11/1962 84 nichole dr Anytown WA 00000 2044 heyden Anytiwn WA 00000 2 1.049291e-04 Kristi Kristi Bajn Guidry 08/06/1984 10/22/1958 6045 s patterson pl Anytown WA 00000 None 3 5.063852e-05 Edward Edward Svenson None 12/23/1961 02/05/1957 20 oakbridge py Anytown WA 00000 1129 sanford ave Anytown WA 00000 4 9.606711e-06 Joyce Joyce Janz Kea 08/21/1944 12/12/1964 8203 west farwell avenue Anytown WA 00500 8603 nw 302nd st Anytown WA 00000 ... ... ... ... ... ... ... ... ... ... 65155 6.102902e-07 Karla Jessica Broughman Marrin 15/05/1973 10/05/1981 5101 garden st ext Anytown WA 00000 122 rue royale Anytown WA 00000 65156 6.102902e-07 Karla Ruth Broughman White 15/05/1973 01/18/1943 5101 garden st ext Anytown WA 00000 1231 riverside dr Anytown WA 00000 65157 6.102902e-07 Karla Lauren Broughman Jacinto 15/05/1973 06/15/1991 5101 garden st ext Anytown WA 00000 273 carolyn drive Anytown WA 00000 65158 6.102902e-07 Karla Jo Broughman Senseman 15/05/1973 06/25/1956 5101 garden st ext Anytown WA 00000 3425 red lane rd Anytown WA 00000 65159 4.225087e-07 Dominic Anita Broughman Conner 08/21/1973 04/28/1947 5101 garden st ext Anytown WA 00000 4000 nw skycrest pkwy Anytown WA 00000 <p>65160 rows \u00d7 9 columns</p> <p>We can see how our model performs at different probability thresholds, with a couple of options depending on the space we wish to view things. The chart below shows that for a match weight around 6.4, or probability around 99%, our model has 2 false positives and 12 false negatives.</p> <p>These false negatives make sense, since we added a high degree of noise to <code>date_of_birth</code>, a very important matching column.</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"simulant_id\", output_type=\"accuracy\"\n)\n</code></pre> <pre><code>Blocking time: 0.09 seconds\nPredict time: 2.21 seconds\n</code></pre> <p>And we can easily see how many individuals we identify and link by looking at clusters generated at some threshold match probability of interest - let's choose 99% again for this example.</p> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    predictions, threshold_match_probability=0.99\n)\ndf_clusters = clusters.as_pandas_dataframe().sort_values(\"cluster_id\")\ndf_clusters.groupby(\"cluster_id\").size().value_counts()\n</code></pre> <pre><code>Completed iteration 1, num representatives needing updating: 0\n\n\n\n\n\n1    10149\n2      142\n3        3\nName: count, dtype: int64\n</code></pre> <p>There are a couple of interactive visualizations which can be useful for understanding and evaluating results.</p> <pre><code>from IPython.display import IFrame\n\nlinker.visualisations.cluster_studio_dashboard(\n    predictions,\n    clusters,\n    \"./dashboards/pseudopeople_cluster_studio.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\n# You can view the cluster_studio.html file in your browser,\n# or inline in a notbook as follows\nIFrame(src=\"./dashboards/pseudopeople_cluster_studio.html\", width=\"100%\", height=1000)\n</code></pre> <p> </p> <pre><code>linker.visualisations.comparison_viewer_dashboard(\n    predictions, \"./dashboards/pseudopeople_scv.html\", overwrite=True\n)\nIFrame(src=\"./dashboards/pseudopeople_scv.html\", width=\"100%\", height=1000)\n</code></pre> <p> </p> <p>In this example we know what the true links are, so we can also manually inspect the ones with the lowest match weights to see what our model is not capturing - i.e. where we have false negatives.</p> <p>Similarly, we can look at the non-links with the highest match weights, to see whether we have an issue with false positives.</p> <p>Ordinarily we would not have this luxury, and so would need to dig a bit deeper for clues as to how to improve our model, such as manually inspecting records across threshold probabilities.</p> <pre><code># add simulant_id_l and simulant_id_r columns by looking up\n# id_l and id_r in the simulant id lookup table\ndf_predictions = pd.merge(\n    df_predictions, simulant_lookup, left_on=\"id_l\", right_on=\"id\", how=\"left\"\n)\ndf_predictions = df_predictions.rename(columns={\"simulant_id\": \"simulant_id_l\"})\ndf_predictions = pd.merge(\n    df_predictions, simulant_lookup, left_on=\"id_r\", right_on=\"id\", how=\"left\"\n)\ndf_predictions = df_predictions.rename(columns={\"simulant_id\": \"simulant_id_r\"})\n</code></pre> <pre><code># sort links by lowest match_probability to see if we missed any\nlinks = df_predictions[\n    df_predictions[\"simulant_id_l\"] == df_predictions[\"simulant_id_r\"]\n].sort_values(\"match_weight\")\n# sort nonlinks by highest match_probability to see if we matched any\nnonlinks = df_predictions[\n    df_predictions[\"simulant_id_l\"] != df_predictions[\"simulant_id_r\"]\n].sort_values(\"match_weight\", ascending=False)\nlinks[columns_to_show].head(15)\n</code></pre> match_probability first_name_l first_name_r last_name_l last_name_r date_of_birth_l date_of_birth_r address_l address_r 6265 0.002081 Fxigy Faigy Wallace Wqolace 05/18/1980 18/05/1980 12679 kingston ave Anytown WA 00000 12679 kingston ave Anytown WA 00000 907 0.008139 Antoinette Antoinette Strawn Sggawg 23/08/1997 08/23/1997 1700 north kilpatrick street Anytown WA 00000 510 holcomb ave Anytown WA 00000 1953 0.022306 Peter Peter Giahnoia Giajgnkla 12/31/1952 31/12/1952 None 7171 glenhaven circle Anytown WA 00000 338 0.025074 Bailey Bailey Lapolla KapklUa 09/12/2000 12/09/2000 8203 west farwell avenue Anytown WA 00000 8203 wrst farwell avenie Anytown WA 000o0 3626 0.085472 Elizabeth Elizabeth Four Frost 08/29/1996 29/08/1996 8203 west farwell avenue Anytown WA 00000 8203 west farwell avenue Anytown WA 00000 2238 0.180708 Zachary Zachary Coilier Colliwr 20/01/2003 01/20/2003 8203 west farwell avenue Anytown WA 00000 8203 west farwell avenue Anytown WA 00000 5051 0.507048 Rmily Emily Yancey Yancey 12/24/1992 12/24/1993 8 kline st Anytown WA 00000 ap # 97 610 n 54th ln Anytown WA 00000 8204 0.600260 Christy Boy Cornel Cognel 12/20/1964 20/12/1964 8203 west farwell avenue Anytown WA 00000 8203 west farwell avenue Anytown WA 00000 751 0.710312 Benjamin Benjamin Allen Allen 02/26/2001 02/26/z001 8203 west farwell avenue Anytown WA 00000 2002 203rd pl se Anytown WA 00000 2745 0.832138 Susan Susan Winchell Wknchell 05/18/1967 18/05/1967 301 downer st Anytown WA 00000 204 linden road Anytown WA 00000 2225 0.933467 Barbara Barbara Anderson Anderson 28/12/1964 12/28/1964 1471 south e pine street Anytown WA 00000 375 jefferson st Anytown WA 00000 2251 0.943923 Jessica Jessica Martin Marrin 05/10/1981 10/05/1981 152 glenview rd Anytown WA 00000 apt 226 122 rue royale Anytown WA 00000 121 0.987992 Brielle Brielle Gonzalez Gonzalez 27/11/2000 11/27/2000 8203 west farwell avenue Anytown WA 00000 233 saint peters road Anytown WA 00000 4736 0.993122 Karla Karla Broughman Bdoughkab 15/05/1973 05/15/1973 5101 garden st ext Anytown WA 00000 5101 garden st ext Anytown WA 00000 262 0.994191 Leonard Leonard Gimlin Nimlin 16/10/2007 16/10/2007 16 w ocotillo rd Anytown WA 00000 6117 granny smith court Anytown WA 00000 <p>As you can see, nearly all of the false negatives (links with match probabilities below our chosen 99% threshold) are due to month/day swaps.</p> <pre><code>nonlinks[columns_to_show].head(5)\n</code></pre> match_probability first_name_l first_name_r last_name_l last_name_r date_of_birth_l date_of_birth_r address_l address_r 4951 0.995158 Tonya Ryan Maiden Maiden 04/02/1975 03/01/2008 7214 wild plum ct Anytown WA 00000 7214 wild plum ct Anytown WA 00000 6060 0.991929 Francis Angela Turner Turner 05/12/1971 05/12/1971 1432 isaac place Anytown WA 00000 1432 isaac place Anytown WA 00000 4987 0.975487 David Alex Middleton Middleton 09/19/1967 29/03/2001 6634 beachplum way Anytown WA 00000 6634 beachplum way Anytown WA 00000 5094 0.975487 David Frederick Middleton Middleton 09/19/1967 07/23/1999 6634 beachplum way Anytown WA 00000 6634 beachplum way Anytown WA 00000 4928 0.970317 Charles Lorraine Estrada Canche Estrada Canche 01/06/1931 11/25/1934 1009 northwest topeka boulevard Anytown WA 000... 1009 northwest topeka boulevard Anytown WA 000... <p>Note that not all columns used for comparisons are displayed in the tables above due to space. The waterfall charts below show some of the lowest match weight true links and highest match weight true nonlinks in more detail.</p> <pre><code>records_to_view = 15\nlinker.visualisations.waterfall_chart(\n    links.head(records_to_view).to_dict(orient=\"records\")\n)\n</code></pre> <pre><code>records_to_view = 5\nlinker.visualisations.waterfall_chart(\n    nonlinks.head(records_to_view).to_dict(orient=\"records\")\n)\n</code></pre> <p>We may also wish to evaluate the effects of using term frequencies for some columns, such as <code>address</code>, by looking at examples of the values <code>tf_address</code> for both common and uncommon address values. Common addresses such as the GQ household, displayed first in the waterfall chart below, will have smaller (negative) values for <code>tf_address</code>, while uncommon addresses will have larger (positive) values.</p> <pre><code>linker.visualisations.waterfall_chart(\n    # choose comparisons that have a term frequency adjustment for address\n    df_predictions[df_predictions.bf_tf_adj_address != 1]\n    .head(10)  # only display some of the first such comparisons\n    .sort_values(\n        \"bf_tf_adj_address\"\n    )  # sort by lowest adjustment (common addresses) first\n    .to_dict(orient=\"records\")\n)\n</code></pre>"},{"location":"demos/examples/spark/deduplicate_1k_synthetic.html","title":"Deduplication using Pyspark","text":""},{"location":"demos/examples/spark/deduplicate_1k_synthetic.html#linking-in-spark","title":"Linking in Spark","text":"<pre><code>from pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession\n\nfrom splink.backends.spark import similarity_jar_location\n\nconf = SparkConf()\n# This parallelism setting is only suitable for a small toy example\nconf.set(\"spark.driver.memory\", \"12g\")\nconf.set(\"spark.default.parallelism\", \"8\")\nconf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n\n\n# Add custom similarity functions, which are bundled with Splink\n# documented here: https://github.com/moj-analytical-services/splink_scalaudfs\npath = similarity_jar_location()\nconf.set(\"spark.jars\", path)\n\nsc = SparkContext.getOrCreate(conf=conf)\n\nspark = SparkSession(sc)\nspark.sparkContext.setCheckpointDir(\"./tmp_checkpoints\")\n</code></pre> <pre><code>24/07/13 19:50:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n</code></pre> <pre><code>from splink import splink_datasets\n\npandas_df = splink_datasets.fake_1000\n\ndf = spark.createDataFrame(pandas_df)\n</code></pre> <pre><code>import splink.comparison_library as cl\nfrom splink import Linker, SettingsCreator, SparkAPI, block_on\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.LevenshteinAtThresholds(\n            \"dob\"\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        \"l.surname = r.surname\",  # alternatively, you can write BRs in their SQL form\n    ],\n    retain_intermediate_calculation_columns=True,\n    em_convergence=0.01,\n)\n</code></pre> <pre><code>linker = Linker(df, settings, db_api=SparkAPI(spark_session=spark))\ndeterministic_rules = [\n    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.surname = r.surname and levenshtein(r.dob, l.dob) &lt;= 1\",\n    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n    \"l.email = r.email\",\n]\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.6)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.0806.                \nThis means that amongst all possible pairwise record comparisons, one in 12.41 are expected to match.  With 499,500 total possible comparisons, we expect a total of around 40,246.67 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=5e5)\n</code></pre> <pre><code>----- Estimating u probabilities using random sampling -----\n\n\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - dob (no m values are trained).\n    - city (no m values are trained).\n    - email (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\ntraining_session_fname_sname = (\n    linker.training.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n)\n\ntraining_blocking_rule = \"l.dob = r.dob\"\ntraining_session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    training_blocking_rule\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.first_name = r.first_name and l.surname = r.surname\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n    - surname\n\nIteration 1: Largest change in params was -0.709 in probability_two_random_records_match\nIteration 2: Largest change in params was 0.0573 in the m_probability of email, level `All other comparisons`\nIteration 3: Largest change in params was 0.0215 in the m_probability of email, level `All other comparisons`\nIteration 4: Largest change in params was 0.00888 in the m_probability of email, level `All other comparisons`\n\nEM converged after 4 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n\n----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.dob = r.dob\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nWARNING:                                                                        \nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was -0.548 in the m_probability of surname, level `Exact match on surname`\nIteration 2: Largest change in params was 0.129 in probability_two_random_records_match\nIteration 3: Largest change in params was 0.0313 in probability_two_random_records_match\nIteration 4: Largest change in params was 0.0128 in probability_two_random_records_match\nIteration 5: Largest change in params was 0.00651 in probability_two_random_records_match\n\nEM converged after 5 iterations\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\nYour model is fully trained. All comparisons have at least one estimate for their m and u values\n</code></pre> <pre><code>results = linker.inference.predict(threshold_match_probability=0.9)\n</code></pre> <pre><code>Blocking time: 4.65 seconds                                                     \nPredict time: 82.92 seconds\n</code></pre> <pre><code>spark_df = results.as_spark_dataframe().show()\n</code></pre> <pre><code>+------------------+------------------+-----------+-----------+------------+------------+----------------+---------------+---------------+------------------+--------------------+---------+---------+-------------+------------+------------+-------------------+------------------+----------+----------+---------+------------------+----------+----------+----------+---------+---------+------------------+------------------+--------------------+--------------------+-----------+----------+----------+-------------------+-------------------+---------+\n|      match_weight| match_probability|unique_id_l|unique_id_r|first_name_l|first_name_r|gamma_first_name|tf_first_name_l|tf_first_name_r|     bf_first_name|bf_tf_adj_first_name|surname_l|surname_r|gamma_surname|tf_surname_l|tf_surname_r|         bf_surname| bf_tf_adj_surname|     dob_l|     dob_r|gamma_dob|            bf_dob|    city_l|    city_r|gamma_city|tf_city_l|tf_city_r|           bf_city|    bf_tf_adj_city|             email_l|             email_r|gamma_email|tf_email_l|tf_email_r|           bf_email|    bf_tf_adj_email|match_key|\n+------------------+------------------+-----------+-----------+------------+------------+----------------+---------------+---------------+------------------+--------------------+---------+---------+-------------+------------+------------+-------------------+------------------+----------+----------+---------+------------------+----------+----------+----------+---------+---------+------------------+------------------+--------------------+--------------------+-----------+----------+----------+-------------------+-------------------+---------+\n|15.131885475840011|0.9999721492762709|         51|         56|      Jayden|      Jayden|               4|          0.008|          0.008|11.371009132404957|  4.0525525525525525|  Bennett|  Bennett|            4|       0.006|       0.006|  9.113630950205666| 5.981981981981981|2017-01-11|2017-02-10|        1|14.373012181955707|   Swansea|   Swansea|         1|    0.013|    0.013|5.8704874944935215| 5.481481481481482|                 NaN|       jb88@king.com|          0|     0.211|     0.004|0.35260600559686806|                1.0|        0|\n|  7.86514930254232|0.9957293356289956|        575|        577|     Jessica|     Jessica|               4|          0.011|          0.011|11.371009132404957|  2.9473109473109473|     Owen|      NaN|            0|       0.006|       0.181|0.45554364195240765|               1.0|1974-11-17|1974-11-17|        3|220.92747883214062|       NaN|       NaN|         1|    0.187|    0.187|5.8704874944935215|0.3810655575361458|                 NaN|jessica.owen@elli...|          0|     0.211|     0.002|0.35260600559686806|                1.0|        0|\n| 5.951711022429932|0.9841000517299358|        171|        174|         NaN|        Leah|               0|          0.169|          0.002|0.4452000905514796|                 1.0|  Russell|  Russell|            4|        0.01|        0.01|  9.113630950205666| 3.589189189189189|2011-06-08|2012-07-09|        0|0.2607755750325071|    London|    London|         1|    0.173|    0.173|5.8704874944935215|0.4119032327124813|leahrussell@charl...|leahrussell@charl...|          4|     0.005|     0.005|  8.411105418567649|  9.143943943943944|        1|\n|21.650093935297473|0.9999996961409438|        518|        519|      Amelia|     Amlelia|               2|          0.009|          0.001| 47.10808446952784|                 1.0|   Morgan|   Morgan|            4|       0.012|       0.012|  9.113630950205666|2.9909909909909906|2011-05-26|2011-05-26|        3|220.92747883214062|   Swindno|   Swindon|         0|    0.001|     0.01|0.6263033203299755|               1.0|amelia.morgan92@d...|amelia.morgan92@d...|          3|     0.004|     0.001| 211.35554441198767|                1.0|        1|\n|11.456207518049865|0.9996442185022277|        752|        754|        Jaes|         NaN|               0|          0.001|          0.169|0.4452000905514796|                 1.0|      NaN|      NaN|            4|       0.181|       0.181|  9.113630950205666|0.1982977452590712|1972-07-20|1971-07-20|        2| 84.28155355946456|       NaN|       NaN|         1|    0.187|    0.187|5.8704874944935215|0.3810655575361458|       j.c@white.org|      j.c@whige.wort|          3|     0.002|     0.001| 211.35554441198767|                1.0|        1|\n|24.387299048327478|0.9999999544286963|        760|        761|       Henry|       Henry|               4|          0.009|          0.009|11.371009132404957|   3.602268935602269|      Day|      Day|            4|       0.004|       0.004|  9.113630950205666| 8.972972972972972|2002-09-15|2002-08-18|        1|14.373012181955707|     Leeds|     Leeds|         1|    0.017|    0.017|5.8704874944935215| 4.191721132897603|hday48@thomas-car...|hday48@thomas-car...|          3|     0.003|     0.001| 211.35554441198767|                1.0|        0|\n|12.076660303346712|0.9997685471829967|        920|        922|         Evi|        Evie|               3|          0.001|          0.007| 61.79623639995749|                 1.0|    Jones|    Jones|            4|       0.023|       0.023|  9.113630950205666|1.5605170387779081|2012-06-19|2002-07-22|        0|0.2607755750325071|       NaN|       NaN|         1|    0.187|    0.187|5.8704874944935215|0.3810655575361458|eviejones@brewer-...|eviejones@brewer-...|          4|     0.004|     0.004|  8.411105418567649|  11.42992992992993|        1|\n| 4.002786788974079|0.9412833223288347|        171|        175|         NaN|       Lheah|               0|          0.169|          0.001|0.4452000905514796|                 1.0|  Russell|  Russell|            4|        0.01|        0.01|  9.113630950205666| 3.589189189189189|2011-06-08|2011-07-10|        0|0.2607755750325071|    London|   Londoon|         0|    0.173|    0.002|0.6263033203299755|               1.0|leahrussell@charl...|leahrussell@charl...|          4|     0.005|     0.005|  8.411105418567649|  9.143943943943944|        1|\n|19.936162812706836|0.9999990031804153|        851|        853|    Mhichael|     Michael|               2|          0.001|          0.006| 47.10808446952784|                 1.0|      NaN|      NaN|            4|       0.181|       0.181|  9.113630950205666|0.1982977452590712|2000-04-03|2000-04-03|        3|220.92747883214062|    London|    London|         1|    0.173|    0.173|5.8704874944935215|0.4119032327124813|      m.w@cannon.com|      m@w.cannon.com|          2|     0.002|     0.001| 251.69908796212906|                1.0|        1|\n| 21.33290823458872|0.9999996214227064|        400|        402|       James|       James|               4|          0.013|          0.013|11.371009132404957|  2.4938784938784937|    Dixon|    Dixon|            4|       0.009|       0.009|  9.113630950205666| 3.987987987987988|1991-04-12|1991-04-12|        3|220.92747883214062|       NaN|   Loodnon|         0|    0.187|    0.001|0.6263033203299755|               1.0|james.d@merritot-...|james.d@merritt-s...|          3|     0.001|     0.005| 211.35554441198767|                1.0|        0|\n|22.169132705637786|0.9999997879560012|         81|         84|        Ryan|        Ryan|               4|          0.005|          0.005|11.371009132404957|   6.484084084084084|     Cole|     Cole|            4|       0.005|       0.005|  9.113630950205666| 7.178378378378378|1987-05-27|1988-05-27|        2| 84.28155355946456|       NaN|   Bristol|         0|    0.187|    0.016|0.6263033203299755|               1.0|r.cole1@ramirez-a...|r.cole1@ramtrez-a...|          3|     0.005|     0.001| 211.35554441198767|                1.0|        0|\n|6.1486678498977065|0.9861008615160808|        652|        654|         NaN|         NaN|               4|          0.169|          0.169|11.371009132404957| 0.19183680722142257|  Roberts|      NaN|            0|       0.006|       0.181|0.45554364195240765|               1.0|1990-10-26|1990-10-26|        3|220.92747883214062|Birmingham|Birmingham|         1|     0.04|     0.04|5.8704874944935215|1.7814814814814814|                 NaN|droberts73@taylor...|          0|     0.211|     0.003|0.35260600559686806|                1.0|        0|\n|17.935398542824068|0.9999960106207738|        582|        584|      ilivOa|      Olivia|               1|          0.001|          0.014| 3.944098136204933|                 1.0|  Edwards|  Edwards|            4|       0.008|       0.008|  9.113630950205666| 4.486486486486486|1988-12-27|1988-12-27|        3|220.92747883214062|    Dudley|   Duudley|         0|    0.006|    0.001|0.6263033203299755|               1.0|      oe56@lopez.net|      oe56@lopez.net|          4|     0.003|     0.003|  8.411105418567649| 15.239906573239907|        1|\n|21.036204363210302|0.9999995349803662|        978|        981|     Jessica|     Jessica|               4|          0.011|          0.011|11.371009132404957|  2.9473109473109473|   Miller|  Miiller|            3|       0.004|       0.001|  82.56312210691897|               1.0|2001-05-23|2001-05-23|        3|220.92747883214062|       NaN|  Coventry|         0|    0.187|    0.021|0.6263033203299755|               1.0|jessica.miller@jo...|jessica.miller@jo...|          4|     0.006|     0.006|  8.411105418567649|  7.619953286619953|        0|\n|13.095432674729635|0.9998857562788657|        684|        686|       Rosie|       Rosie|               4|          0.005|          0.005|11.371009132404957|   6.484084084084084|  Johnstn| Johnston|            3|       0.001|       0.002|  82.56312210691897|               1.0|1979-12-23|1978-11-23|        1|14.373012181955707|       NaN| Sheffield|         0|    0.187|    0.007|0.6263033203299755|               1.0|                 NaN|                 NaN|          4|     0.211|     0.211|  8.411105418567649|0.21668113611241574|        0|\n|25.252698357543103|0.9999999749861632|        279|        280|        Lola|        Lola|               4|          0.008|          0.008|11.371009132404957|  4.0525525525525525|   Taylor|   Taylor|            4|       0.014|       0.014|  9.113630950205666|2.5637065637065635|2017-11-20|2016-11-20|        2| 84.28155355946456|  Aberdeen|  Aberdeen|         1|    0.016|    0.016|5.8704874944935215| 4.453703703703703|lolat86@bishop-gi...|lolat86@bishop-gi...|          4|     0.002|     0.002|  8.411105418567649|  22.85985985985986|        0|\n| 9.711807138722323|0.9988089303569408|         42|         43|    Theodore|    Theodore|               4|           0.01|           0.01|11.371009132404957|   3.242042042042042|   Morris|   Morris|            4|       0.004|       0.004|  9.113630950205666| 8.972972972972972|1978-09-18|1978-08-19|        1|14.373012181955707|Birgmhniam|Birmingham|         0|    0.001|     0.04|0.6263033203299755|               1.0|                 NaN|t.m39@brooks-sawy...|          0|     0.211|     0.005|0.35260600559686806|                1.0|        0|\n| 5.951711022429932|0.9841000517299358|        173|        174|         NaN|        Leah|               0|          0.169|          0.002|0.4452000905514796|                 1.0|  Russell|  Russell|            4|        0.01|        0.01|  9.113630950205666| 3.589189189189189|2011-06-08|2012-07-09|        0|0.2607755750325071|    London|    London|         1|    0.173|    0.173|5.8704874944935215|0.4119032327124813|leahrussell@charl...|leahrussell@charl...|          4|     0.005|     0.005|  8.411105418567649|  9.143943943943944|        1|\n| 23.43211696288854|0.9999999116452517|         88|         89|        Lexi|        Lexi|               4|          0.003|          0.003|11.371009132404957|  10.806806806806806|      NaN|      NaN|            4|       0.181|       0.181|  9.113630950205666|0.1982977452590712|1994-09-02|1994-09-02|        3|220.92747883214062|Birmingham|Birmingham|         1|     0.04|     0.04|5.8704874944935215|1.7814814814814814|l.gordon34cfren@h...|l.gordon34@french...|          2|     0.001|     0.002| 251.69908796212906|                1.0|        0|\n|7.1659948250873144|0.9930847652376709|        391|        393|       Isaac|       Isaac|               4|          0.005|          0.005|11.371009132404957|   6.484084084084084|      NaN|    James|            0|       0.181|       0.007|0.45554364195240765|               1.0|1991-05-06|1991-05-06|        3|220.92747883214062|     Lodon|    London|         0|    0.008|    0.173|0.6263033203299755|               1.0|isaac.james@smich...|                 NaN|          0|     0.001|     0.211|0.35260600559686806|                1.0|        0|\n+------------------+------------------+-----------+-----------+------------+------------+----------------+---------------+---------------+------------------+--------------------+---------+---------+-------------+------------+------------+-------------------+------------------+----------+----------+---------+------------------+----------+----------+----------+---------+---------+------------------+------------------+--------------------+--------------------+-----------+----------+----------+-------------------+-------------------+---------+\nonly showing top 20 rows\n</code></pre>"},{"location":"demos/examples/sqlite/deduplicate_50k_synthetic.html","title":"Deduplicate 50k rows historical persons","text":""},{"location":"demos/examples/sqlite/deduplicate_50k_synthetic.html#linking-a-dataset-of-real-historical-persons","title":"Linking a dataset of real historical persons","text":"<p>In this example, we deduplicate a more realistic dataset. The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced.</p> <p>Note, as explained in the backends topic guide, SQLite does not natively support string fuzzy matching functions such as <code>damareau-levenshtein</code> and <code>jaro-winkler</code> (as used in this example). Instead, these have been imported as python User Defined Functions (UDFs). One drawback of python UDFs is that they are considerably slower than native-SQL comparisons. As such, if you are hitting issues with large run times, consider switching to DuckDB (or some other backend).</p> <p> </p> <pre><code># Uncomment and run this cell if you're running in Google Colab.\n# !pip install splink\n# !pip install rapidfuzz\n</code></pre> <pre><code>import pandas as pd\n\nfrom splink import splink_datasets\n\npd.options.display.max_rows = 1000\n# reduce size of dataset to make things run faster\ndf = splink_datasets.historical_50k.sample(5000)\n</code></pre> <pre><code>from splink.backends.sqlite import SQLiteAPI\nfrom splink.exploratory import profile_columns\n\ndb_api = SQLiteAPI()\nprofile_columns(\n    df, db_api, column_expressions=[\"first_name\", \"postcode_fake\", \"substr(dob, 1,4)\"]\n)\n</code></pre> <pre><code>from splink import block_on\nfrom splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules =  [block_on(\"first_name\", \"surname\"),\n        block_on(\"surname\", \"dob\"),\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"postcode_fake\", \"first_name\")]\n\ndb_api = SQLiteAPI()\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules,\n    db_api=db_api,\n    link_type=\"dedupe_only\"\n)\n</code></pre> <pre><code>import splink.comparison_library as cl\nfrom splink import Linker\n\nsettings = {\n    \"link_type\": \"dedupe_only\",\n    \"blocking_rules_to_generate_predictions\": [\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"surname\", \"dob\"),\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"postcode_fake\", \"first_name\"),\n\n    ],\n    \"comparisons\": [\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DamerauLevenshteinAtThresholds(\"dob\", [1, 2]).configure(\n            term_frequency_adjustments=True\n        ),\n        cl.DamerauLevenshteinAtThresholds(\"postcode_fake\", [1, 2]),\n        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\n            \"occupation\",\n        ).configure(term_frequency_adjustments=True),\n    ],\n    \"retain_matching_columns\": True,\n    \"retain_intermediate_calculation_columns\": True,\n    \"max_iterations\": 10,\n    \"em_convergence\": 0.01,\n}\n\nlinker = Linker(df, settings, db_api=db_api)\n</code></pre> <pre><code>linker.training.estimate_probability_two_random_records_match(\n    [\n        block_on(\"first_name\", \"surname\", \"dob\"),\n        block_on(\"substr(first_name,1,2)\", \"surname\", \"substr(postcode_fake,1,2)\"),\n        block_on(\"dob\", \"postcode_fake\"),\n    ],\n    recall=0.6,\n)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.000125.\nThis means that amongst all possible pairwise record comparisons, one in 7,985.62 are expected to match.  With 12,497,500 total possible comparisons, we expect a total of around 1,565.00 matching pairs\n</code></pre> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n----- Estimating u probabilities using random sampling -----\nu probability not trained for first_name - Jaro-Winkler distance of first_name &gt;= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nu probability not trained for surname - Jaro-Winkler distance of surname &gt;= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n\nEstimated u probabilities using random sampling\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (some u values are not trained, no m values are trained).\n    - surname (some u values are not trained, no m values are trained).\n    - dob (no m values are trained).\n    - postcode_fake (no m values are trained).\n    - birth_place (no m values are trained).\n    - occupation (no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\ntraining_session_names = linker.training.estimate_parameters_using_expectation_maximisation(\n    training_blocking_rule, estimate_without_term_frequencies=True\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.first_name = r.first_name and l.surname = r.surname\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n    - surname\n\nIteration 1: Largest change in params was -0.438 in probability_two_random_records_match\nIteration 2: Largest change in params was -0.0347 in probability_two_random_records_match\nIteration 3: Largest change in params was -0.0126 in the m_probability of birth_place, level `All other comparisons`\nIteration 4: Largest change in params was 0.00644 in the m_probability of birth_place, level `Exact match on birth_place`\n\nEM converged after 4 iterations\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (some u values are not trained, no m values are trained).\n    - surname (some u values are not trained, no m values are trained).\n</code></pre> <pre><code>training_blocking_rule = \"l.dob = r.dob\"\ntraining_session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    training_blocking_rule, estimate_without_term_frequencies=True\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\nEstimating the m probabilities of the model by blocking on:\nl.dob = r.dob\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - postcode_fake\n    - birth_place\n    - occupation\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\nWARNING:\nLevel Jaro-Winkler distance of first_name &gt;= 0.88 on comparison first_name not observed in dataset, unable to train m value\n\nWARNING:\nLevel Jaro-Winkler distance of surname &gt;= 0.88 on comparison surname not observed in dataset, unable to train m value\n\nIteration 1: Largest change in params was 0.327 in the m_probability of first_name, level `All other comparisons`\nIteration 2: Largest change in params was -0.0566 in the m_probability of surname, level `Exact match on surname`\nIteration 3: Largest change in params was -0.0184 in the m_probability of surname, level `Exact match on surname`\nIteration 4: Largest change in params was -0.006 in the m_probability of surname, level `Exact match on surname`\n\nEM converged after 4 iterations\nm probability not trained for first_name - Jaro-Winkler distance of first_name &gt;= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\nm probability not trained for surname - Jaro-Winkler distance of surname &gt;= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (some u values are not trained, some m values are not trained).\n    - surname (some u values are not trained, some m values are not trained).\n</code></pre> <p>The final match weights can be viewed in the match weights chart:</p> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre> <pre><code>df_predict = linker.inference.predict()\ndf_e = df_predict.as_pandas_dataframe(limit=5)\ndf_e\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'first_name':\n    m values not fully trained\nComparison: 'first_name':\n    u values not fully trained\nComparison: 'surname':\n    m values not fully trained\nComparison: 'surname':\n    u values not fully trained\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name ... bf_birth_place bf_tf_adj_birth_place occupation_l occupation_r gamma_occupation tf_occupation_l tf_occupation_r bf_occupation bf_tf_adj_occupation match_key 0 26.932083 1.000000 Q446382-1 Q446382-3 marianne marianne 4 0.000801 0.000801 51.871289 ... 0.162366 1.000000 None None -1 NaN NaN 1.000000 1.000000 0 1 30.788800 1.000000 Q2835078-1 Q2835078-2 alfred alfred 4 0.013622 0.013622 51.871289 ... 197.452526 0.607559 None None -1 NaN NaN 1.000000 1.000000 0 2 23.882340 1.000000 Q2835078-1 Q2835078-5 alfred alfred 4 0.013622 0.013622 51.871289 ... 1.000000 1.000000 None None -1 NaN NaN 1.000000 1.000000 0 3 39.932187 1.000000 Q80158702-1 Q80158702-4 john john 4 0.053085 0.053085 51.871289 ... 197.452526 2.025198 sculptor sculptor 1 0.002769 0.002769 23.836781 13.868019 0 4 17.042339 0.999993 Q18810722-3 Q18810722-6 frederick frederick 4 0.012220 0.012220 51.871289 ... 197.452526 0.607559 printer printer 1 0.000791 0.000791 23.836781 48.538067 0 <p>5 rows \u00d7 44 columns</p> <p>You can also view rows in this dataset as a waterfall chart as follows:</p> <pre><code>records_to_plot = df_e.to_dict(orient=\"records\")\nlinker.visualisations.waterfall_chart(records_to_plot, filter_nulls=False)\n</code></pre> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predict, threshold_match_probability=0.95\n)\n</code></pre> <pre><code>Completed iteration 1, root rows count 5\nCompleted iteration 2, root rows count 0\n</code></pre> <pre><code>linker.visualisations.cluster_studio_dashboard(\n    df_predict,\n    clusters,\n    \"dashboards/50k_cluster.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\nfrom IPython.display import IFrame\n\nIFrame(src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200)\n</code></pre> <p> </p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_column(\n    \"cluster\", output_type=\"roc\", match_weight_round_to_nearest=0.02\n)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'first_name':\n    m values not fully trained\nComparison: 'first_name':\n    u values not fully trained\nComparison: 'surname':\n    m values not fully trained\nComparison: 'surname':\n    u values not fully trained\n</code></pre> <pre><code>records = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\",\n    threshold_match_probability=0.999,\n    include_false_negatives=False,\n    include_false_positives=True,\n).as_record_dict()\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'first_name':\n    m values not fully trained\nComparison: 'first_name':\n    u values not fully trained\nComparison: 'surname':\n    m values not fully trained\nComparison: 'surname':\n    u values not fully trained\n</code></pre> <pre><code># Some of the false negatives will be because they weren't detected by the blocking rules\nrecords = linker.evaluation.prediction_errors_from_labels_column(\n    \"cluster\",\n    threshold_match_probability=0.5,\n    include_false_negatives=True,\n    include_false_positives=False,\n).as_record_dict(limit=50)\n\nlinker.visualisations.waterfall_chart(records)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'first_name':\n    m values not fully trained\nComparison: 'first_name':\n    u values not fully trained\nComparison: 'surname':\n    m values not fully trained\nComparison: 'surname':\n    u values not fully trained\n</code></pre>"},{"location":"demos/tutorials/00_Tutorial_Introduction.html","title":"Introduction","text":""},{"location":"demos/tutorials/00_Tutorial_Introduction.html#introductory-tutorial","title":"Introductory tutorial","text":"<p>This is the introduction to a seven part tutorial which demonstrates how to de-duplicate a small dataset using simple settings.</p> <p>The aim of the tutorial is to demonstrate core Splink functionality succinctly, rather that comprehensively document all configuration options.</p> <p>The seven parts are:</p> <ul> <li> <p>1. Data prep pre-requisites</p> </li> <li> <p>2. Exploratory analysis </p> </li> <li> <p>3. Choosing blocking rules to optimise runtimes </p> </li> <li> <p>4. Estimating model parameters </p> </li> <li> <p>5. Predicting results </p> </li> <li> <p>6. Visualising predictions </p> </li> <li> <p>7. Evaluation </p> </li> <li> <p>8. Building your own model </p> </li> </ul> <p>Throughout the tutorial, we use the duckdb backend, which is the recommended option for smaller datasets of up to around 1 million records on a normal laptop.</p> <p>You can find these tutorial notebooks in the <code>docs/demos/tutorials/</code> folder of the  splink repo, or click the Colab links to run in your browser.</p>"},{"location":"demos/tutorials/00_Tutorial_Introduction.html#end-to-end-demos","title":"End-to-end demos","text":"<p>After following the steps of the tutorial, it might prove useful to have a look at some of the example notebooks that show various use-case scenarios of Splink from start to finish.</p>"},{"location":"demos/tutorials/00_Tutorial_Introduction.html#interactive-introduction-to-record-linkage-theory","title":"Interactive Introduction to Record Linkage Theory","text":"<p>If you'd like to learn more about record linkage theory, an interactive introduction is available here.</p>"},{"location":"demos/tutorials/00_Tutorial_Introduction.html#llm-prompts","title":"LLM prompts","text":"<p>If you're using an LLM to suggest Splink code, see here for suggested prompts and context.</p>"},{"location":"demos/tutorials/01_Prerequisites.html","title":"1. Data prep prerequisites","text":""},{"location":"demos/tutorials/01_Prerequisites.html#data-prerequisites","title":"Data Prerequisites","text":"<p>Splink requires that you clean your data and assign unique IDs to rows before linking. </p> <p>This section outlines the additional data cleaning steps needed before loading data into Splink.</p>"},{"location":"demos/tutorials/01_Prerequisites.html#unique-ids","title":"Unique IDs","text":"<ul> <li>Each input dataset must have a unique ID column, which is unique within the dataset.  By default, Splink assumes this column will be called <code>unique_id</code>, but this can be changed with the <code>unique_id_column_name</code> key in your Splink settings.  The unique id is essential because it enables Splink to keep track each row correctly. </li> </ul>"},{"location":"demos/tutorials/01_Prerequisites.html#conformant-input-datasets","title":"Conformant input datasets","text":"<ul> <li>Input datasets must be conformant, meaning they share the same column names and data formats. For instance, if one dataset has a \"date of birth\" column and another has a \"dob\" column, rename them to match. Ensure data type and number formatting are consistent across both columns. The order of columns in input dataframes is not important.</li> </ul>"},{"location":"demos/tutorials/01_Prerequisites.html#cleaning","title":"Cleaning","text":"<ul> <li>Ensure data consistency by cleaning your data. This process includes standardizing date formats, matching text case, and handling invalid data. For example, if one dataset uses \"yyyy-mm-dd\" date format and another uses \"mm/dd/yyyy,\" convert them to the same format before using Splink.  Try also to identify and rectify any obvious data entry errors, such as removing values such as 'Mr' or 'Mrs' from a 'first name' column.</li> </ul>"},{"location":"demos/tutorials/01_Prerequisites.html#ensure-nulls-are-consistently-and-correctly-represented","title":"Ensure nulls are consistently and correctly represented","text":"<ul> <li>Ensure null values (or other 'not known' indicators) are represented as true nulls, not empty strings. Splink treats null values differently from empty strings, so using true nulls guarantees proper matching across datasets.</li> </ul>"},{"location":"demos/tutorials/01_Prerequisites.html#further-details-on-data-cleaning-and-standardisation","title":"Further details on data cleaning and standardisation","text":"<p>Splink performs optimally with cleaned and standardized data. Here is a non-exhaustive list of suggestions for data cleaning rules to enhance matching accuracy:</p> <ul> <li>Trim leading and trailing whitespace from string values (e.g., \" john smith \" becomes \"john smith\").</li> <li>Remove special characters from string values (e.g., \"O'Hara\" becomes \"Ohara\").</li> <li>Standardise date formats as strings in \"yyyy-mm-dd\" format.</li> <li>Replace abbreviations with full words (e.g., standardize \"St.\" and \"Street\" to \"Street\").</li> </ul>"},{"location":"demos/tutorials/02_Exploratory_analysis.html","title":"2. Exploratory analysis","text":""},{"location":"demos/tutorials/02_Exploratory_analysis.html#exploratory-analysis","title":"Exploratory analysis","text":"<p>Exploratory analysis helps you understand features of your data which are relevant linking or deduplicating your data.</p> <p>Splink includes a variety of charts to help with this, which are demonstrated in this notebook.</p>"},{"location":"demos/tutorials/02_Exploratory_analysis.html#read-in-the-data","title":"Read in the data","text":"<p>For the purpose of this tutorial we will use a 1,000 row synthetic dataset that contains duplicates.</p> <p>The first five rows of this dataset are printed below.</p> <p>Note that the cluster column represents the 'ground truth' - a column which tells us with which rows refer to the same person. In most real linkage scenarios, we wouldn't have this column (this is what Splink is trying to estimate.)</p> <pre><code>from splink import  splink_datasets\n\ndf = splink_datasets.fake_1000\ndf = df.drop(columns=[\"cluster\"])\ndf.head(5)\n</code></pre> unique_id first_name surname dob city email 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 1 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 2 2 Rob Allen 1971-06-24 London roberta25@smith.net 3 3 Robert Alen 1971-06-24 Lonon NaN 4 4 Grace NaN 1997-04-26 Hull grace.kelly52@jones.com"},{"location":"demos/tutorials/02_Exploratory_analysis.html#analyse-missingness","title":"Analyse missingness","text":"<p>It's important to understand the level of missingness in your data, because columns with higher levels of missingness are less useful for data linking.</p> <pre><code>from splink.exploratory import completeness_chart\nfrom splink import DuckDBAPI\ndb_api = DuckDBAPI()\ncompleteness_chart(df, db_api=db_api)\n</code></pre> <p>The above summary chart shows that in this dataset, the <code>email</code>, <code>city</code>, <code>surname</code> and <code>forename</code> columns contain nulls, but the level of missingness is relatively low (less than 22%).</p>"},{"location":"demos/tutorials/02_Exploratory_analysis.html#analyse-the-distribution-of-values-in-your-data","title":"Analyse the distribution of values in your data","text":"<p>The distribution of values in your data is important for two main reasons:</p> <ol> <li> <p>Columns with higher cardinality (number of distinct values) are usually more useful for data linking. For instance, date of birth is a much stronger linkage variable than gender.</p> </li> <li> <p>The skew of values is important. If you have a <code>city</code> column that has 1,000 distinct values, but 75% of them are <code>London</code>, this is much less useful for linkage than if the 1,000 values were equally distributed</p> </li> </ol> <p>The <code>profile_columns()</code> method creates summary charts to help you understand these aspects of your data.</p> <p>To profile all columns, leave the column_expressions argument empty.</p> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(df, db_api=DuckDBAPI(), top_n=10, bottom_n=5)\n</code></pre> <p>This chart is very information-dense, but here are some key takehomes relevant to our linkage:</p> <ul> <li> <p>There is strong skew in the <code>city</code> field with around 20% of the values being <code>London</code>. We therefore will probably want to use <code>term_frequency_adjustments</code> in our linkage model, so that it can weight a match on London differently to a match on, say, <code>Norwich</code>.</p> </li> <li> <p>Looking at the \"Bottom 5 values by value count\", we can see typos in the data in most fields. This tells us this information was possibly entered by hand, or using Optical Character Recognition, giving us an insight into the type of data entry errors we may see.</p> </li> <li> <p>Email is a much more uniquely-identifying field than any others, with a maximum value count of 6. It's likely to be a strong linking variable.</p> </li> </ul> <p>Further Reading</p> <p> For more on exploratory analysis tools in Splink, please refer to the Exploratory Analysis API documentation.</p> <p> For more on the charts used in this tutorial, please refer to the Charts Gallery.</p>"},{"location":"demos/tutorials/02_Exploratory_analysis.html#next-steps","title":"Next steps","text":"<p>At this point, we have begun to develop a strong understanding of our data. It's time to move on to estimating a linkage model</p>"},{"location":"demos/tutorials/03_Blocking.html","title":"3. Blocking","text":""},{"location":"demos/tutorials/03_Blocking.html#choosing-blocking-rules-to-optimise-runtime","title":"Choosing blocking rules to optimise runtime","text":"<p>To link records, we need to compare pairs of records and decide which pairs are matches.</p> <p>For example consider the following two records:</p> first_name surname dob city email Robert Allen 1971-05-24 nan roberta25@smith.net Rob Allen 1971-06-24 London roberta25@smith.net <p>These can be represented as a pairwise comparison as follows:</p> first_name_l first_name_r surname_l surname_r dob_l dob_r city_l city_r email_l email_r Robert Rob Allen Allen 1971-05-24 1971-06-24 nan London roberta25@smith.net roberta25@smith.net <p>For most large datasets, it is computationally intractable to compare every row with every other row, since the number of comparisons rises quadratically with the number of records.</p> <p>Instead we rely on blocking rules, which specify which pairwise comparisons to generate. For example, we could generate the subset of pairwise comparisons where either first name or surname matches.</p> <p>This is part of a two step process to link data:</p> <ol> <li> <p>Use blocking rules to generate candidate pairwise record comparisons</p> </li> <li> <p>Use a probabilistic linkage model to score these candidate pairs, to determine which ones should be linked</p> </li> </ol> <p>Blocking rules are the most important determinant of the performance of your linkage job.</p> <p>When deciding on your blocking rules, you're trading off accuracy for performance:</p> <ul> <li>If your rules are too loose, your linkage job may fail.</li> <li>If they're too tight, you may miss some valid links.</li> </ul> <p>This tutorial clarifies what blocking rules are, and how to choose good rules.</p>"},{"location":"demos/tutorials/03_Blocking.html#blocking-rules-in-splink","title":"Blocking rules in Splink","text":"<p>In Splink, blocking rules are specified as SQL expressions.</p> <p>For example, to generate the subset of record comparisons where the first name and surname matches, we can specify the following blocking rule:</p> <pre><code>from splink import block_on\nblock_on(\"first_name\", \"surname\")\n</code></pre> <p>When executed, this blocking rule will be converted to a SQL statement with the following form:</p> <pre><code>SELECT ...\nFROM input_tables as l\nINNER JOIN input_tables as r\nON l.first_name = r.first_name AND l.surname = r.surname\n</code></pre> <p>Since blocking rules are SQL expressions, they can be arbitrarily complex. For example, you could create record comparisons where the initial of the first name and the surname match with the following rule:</p> <pre><code>from splink import block_on\nblock_on(\"substr(first_name, 1, 2)\", \"surname\")\n</code></pre>"},{"location":"demos/tutorials/03_Blocking.html#devising-effective-blocking-rules-for-prediction","title":"Devising effective blocking rules for prediction","text":"<p>The aims of your blocking rules are twofold:</p> <ol> <li>Eliminate enough non-matching comparison pairs so your record linkage job is small enough to compute</li> <li>Eliminate as few truly matching pairs as possible (ideally none)</li> </ol> <p>It is usually impossible to find a single blocking rule which achieves both aims, so we recommend using multiple blocking rules.</p> <p>When we specify multiple blocking rules, Splink will generate all comparison pairs that meet any one of the rules.</p> <p>For example, consider the following blocking rule:</p> <p><code>block_on(\"first_name\", \"dob\")</code></p> <p>This rule is likely to be effective in reducing the number of comparison pairs. It will retain all truly matching pairs, except those with errors or nulls in either the <code>first_name</code> or <code>dob</code> fields.</p> <p>Now consider a second blocking rule:</p> <p><code>block_on(\"email\")</code>.</p> <p>This will retain all truly matching pairs, except those with errors or nulls in the <code>email</code> column.</p> <p>Individually, these blocking rules are problematic because they exclude true matches where the records contain typos of certain types. But between them, they might do quite a good job.</p> <p>For a true match to be eliminated by the use of these two blocking rules, it would have to have an error in both <code>email</code> AND (<code>first_name</code> or <code>dob</code>).</p> <p>This is not completely implausible, but it is significantly less likely than if we'd used a single rule.</p> <p>More generally, we can often specify multiple blocking rules such that it becomes highly implausible that a true match would not meet at least one of these blocking criteria. This is the recommended approach in Splink. Generally we would recommend between about 3 and 10, though even more is possible.</p> <p>The question then becomes how to choose what to put in this list.</p>"},{"location":"demos/tutorials/03_Blocking.html#splink-tools-to-help-choose-your-blocking-rules","title":"Splink tools to help choose your blocking rules","text":"<p>Splink contains a number of tools to help you choose effective blocking rules. Let's try them out, using our small test dataset:</p> <pre><code>from splink import DuckDBAPI, block_on, splink_datasets\n\ndf = splink_datasets.fake_1000\n</code></pre>"},{"location":"demos/tutorials/03_Blocking.html#counting-the-number-of-comparisons-created-by-a-single-blocking-rule","title":"Counting the number of comparisons created by a single blocking rule","text":"<p>On large datasets, some blocking rules imply the creation of trillions of record comparisons, which would cause a linkage job to fail.</p> <p>Before using a blocking rule in a linkage job, it's therefore a good idea to count the number of records it generates to ensure it is not too loose:</p> <pre><code>from splink.blocking_analysis import count_comparisons_from_blocking_rule\n\ndb_api = DuckDBAPI()\n\nbr = block_on(\"substr(first_name, 1,1)\", \"surname\")\n\ncounts = count_comparisons_from_blocking_rule(\n    table_or_tables=df,\n    blocking_rule=br,\n    link_type=\"dedupe_only\",\n    db_api=db_api,\n)\n\ncounts\n</code></pre> <pre><code>{'number_of_comparisons_generated_pre_filter_conditions': 1632,\n 'number_of_comparisons_to_be_scored_post_filter_conditions': 473,\n 'filter_conditions_identified': '',\n 'equi_join_conditions_identified': 'SUBSTR(l.first_name, 1, 1) = SUBSTR(r.first_name, 1, 1) AND l.\"surname\" = r.\"surname\"',\n 'link_type_join_condition': 'where l.\"unique_id\" &lt; r.\"unique_id\"'}\n</code></pre> <pre><code>br = \"l.first_name = r.first_name and levenshtein(l.surname, r.surname) &lt; 2\"\n\ncounts = count_comparisons_from_blocking_rule(\n    table_or_tables=df,\n    blocking_rule= br,\n    link_type=\"dedupe_only\",\n    db_api=db_api,\n)\ncounts\n</code></pre> <pre><code>{'number_of_comparisons_generated_pre_filter_conditions': 4827,\n 'number_of_comparisons_to_be_scored_post_filter_conditions': 372,\n 'filter_conditions_identified': 'LEVENSHTEIN(l.surname, r.surname) &lt; 2',\n 'equi_join_conditions_identified': 'l.first_name = r.first_name',\n 'link_type_join_condition': 'where l.\"unique_id\" &lt; r.\"unique_id\"'}\n</code></pre> <p>The maximum number of comparisons that you can compute will be affected by your choice of SQL backend, and how powerful your computer is.</p> <p>For linkages in DuckDB on a standard laptop, we suggest using blocking rules that create no more than about 20 million comparisons. For Spark and Athena, try starting with fewer than 100 million comparisons, before scaling up.</p>"},{"location":"demos/tutorials/03_Blocking.html#finding-worst-offending-values-for-your-blocking-rule","title":"Finding 'worst offending' values for your blocking rule","text":"<p>Blocking rules can be affected by skew:  some values of a field may be much more common than others, and this can lead to a disproportionate number of comparisons being generated.</p> <p>It can be useful to identify whether your data is afflicted by this problem. </p> <pre><code>from splink.blocking_analysis import n_largest_blocks\n\nresult = n_largest_blocks(    table_or_tables=df,\n    blocking_rule= block_on(\"city\", \"first_name\"),\n    link_type=\"dedupe_only\",\n    db_api=db_api,\n    n_largest=3\n    )\n\nresult.as_pandas_dataframe()\n</code></pre> key_0 key_1 count_l count_r block_count 0 Birmingham Theodore 7 7 49 1 London Oliver 7 7 49 2 London James 6 6 36 <p>In this case, we can see that <code>Oliver</code>s in <code>London</code> will result in 49 comparisons being generated.  This is acceptable on this small dataset, but on a larger dataset, <code>Oliver</code>s in <code>London</code> could be responsible for many million comparisons.</p>"},{"location":"demos/tutorials/03_Blocking.html#counting-the-number-of-comparisons-created-by-a-list-of-blocking-rules","title":"Counting the number of comparisons created by a list of blocking rules","text":"<p>As noted above, it's usually a good idea to use multiple blocking rules. It's therefore useful to know how many record comparisons will be generated when these rules are applied.</p> <p>Since the same record comparison may be created by several blocking rules, and Splink automatically deduplicates these comparisons, we cannot simply total the number of comparisons generated by each rule individually.</p> <p>Splink provides a chart that shows the marginal (additional) comparisons generated by each blocking rule, after deduplication:</p> <pre><code>from splink.blocking_analysis import (\n    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n)\n\nblocking_rules_for_analysis = [\n    block_on(\"substr(first_name, 1,1)\", \"surname\"),\n    block_on(\"surname\"),\n    block_on(\"email\"),\n    block_on(\"city\", \"first_name\"),\n    \"l.first_name = r.first_name and levenshtein(l.surname, r.surname) &lt; 2\",\n]\n\n\ncumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n    table_or_tables=df,\n    blocking_rules=blocking_rules_for_analysis,\n    db_api=db_api,\n    link_type=\"dedupe_only\",\n)\n</code></pre>"},{"location":"demos/tutorials/03_Blocking.html#digging-deeper-understanding-why-certain-blocking-rules-create-large-numbers-of-comparisons","title":"Digging deeper: Understanding why certain blocking rules create large numbers of comparisons","text":"<p>Finally, we can use the <code>profile_columns</code> function we saw in the previous tutorial to understand a specific blocking rule in more depth.</p> <p>Suppose we're interested in blocking on city and first initial.</p> <p>Within each distinct value of <code>(city, first initial)</code>, all possible pairwise comparisons will be generated.</p> <p>So for instance, if there are 15 distinct records with <code>London,J</code> then these records will result in <code>n(n-1)/2 = 105</code> pairwise comparisons being generated.</p> <p>In a larger dataset, we might observe 10,000 <code>London,J</code> records, which would then be responsible for <code>49,995,000</code> comparisons.</p> <p>These high-frequency values therefore have a disproportionate influence on the overall number of pairwise comparisons, and so it can be useful to analyse skew, as follows:</p> <pre><code>from splink.exploratory import profile_columns\n\nprofile_columns(df, column_expressions=[\"city || left(first_name,1)\"], db_api=db_api)\n</code></pre> <p>Further Reading</p> <p> For a deeper dive on blocking, please refer to the Blocking Topic Guides.</p> <p> For more on the blocking tools in Splink, please refer to the Blocking API documentation.</p> <p> For more on the charts used in this tutorial, please refer to the Charts Gallery.</p>"},{"location":"demos/tutorials/03_Blocking.html#next-steps","title":"Next steps","text":"<p>Now we have chosen which records to compare, we can use those records to train a linkage model.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html","title":"4. Estimating model parameters","text":""},{"location":"demos/tutorials/04_Estimating_model_parameters.html#specifying-and-estimating-a-linkage-model","title":"Specifying and estimating a linkage model","text":"<p>In the last tutorial we looked at how we can use blocking rules to generate pairwise record comparisons.</p> <p>Now it's time to estimate a probabilistic linkage model to score each of these comparisons. The resultant match score is a prediction of whether the two records represent the same entity (e.g. are the same person).</p> <p>The purpose of estimating the model is to learn the relative importance of different parts of your data for the purpose of data linking.</p> <p>For example, a match on date of birth is a much stronger indicator that two records refer to the same entity than a match on gender. A mismatch on gender may be a stronger indicate against two records referring than a mismatch on name, since names are more likely to be entered differently.</p> <p>The relative importance of different information is captured in the (partial) 'match weights', which can be learned from your data. These match weights are then added up to compute the overall match score.</p> <p>The match weights are are derived from the <code>m</code> and <code>u</code> parameters of the underlying Fellegi Sunter model. Splink uses various statistical routines to estimate these parameters. Further details of the underlying theory can be found here, which will help you understand this part of the tutorial.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#specifying-a-linkage-model","title":"Specifying a linkage model","text":"<p>To build a linkage model, the user defines the partial match weights that <code>splink</code> needs to estimate. This is done by defining how the information in the input records should be compared.</p> <p>To be concrete, here is an example comparison:</p> first_name_l first_name_r surname_l surname_r dob_l dob_r city_l city_r email_l email_r Robert Rob Allen Allen 1971-05-24 1971-06-24 nan London roberta25@smith.net roberta25@smith.net <p>What functions should we use to assess the similarity of <code>Rob</code> vs. <code>Robert</code> in the the <code>first_name</code> field?</p> <p>Should similarity in the <code>dob</code> field be computed in the same way, or a different way?</p> <p>Your job as the developer of a linkage model is to decide what comparisons are most appropriate for the types of data you have.</p> <p>Splink can then estimate how much weight to place on a fuzzy match of <code>Rob</code> vs. <code>Robert</code>, relative to an exact match on <code>Robert</code>, or a non-match.</p> <p>Defining these scenarios is done using <code>Comparison</code>s.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#comparisons","title":"Comparisons","text":"<p>The concept of a <code>Comparison</code> has a specific definition within Splink: it defines how data from one or more input columns is compared.</p> <p>For example, one <code>Comparison</code> may represent how similarity is assessed for a person's date of birth.</p> <p>Another <code>Comparison</code> may represent the comparison of a person's name or location.</p> <p>A model is composed of many <code>Comparison</code>s, which between them assess the similarity of all of the columns being used for data linking.</p> <p>Each <code>Comparison</code> contains two or more <code>ComparisonLevels</code> which define n discrete gradations of similarity between the input columns within the Comparison.</p> <p>As such <code>ComparisonLevels</code>are nested within <code>Comparisons</code> as follows:</p> <pre><code>Data Linking Model\n\u251c\u2500-- Comparison: Date of birth\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match\n\u2502    \u251c\u2500-- ComparisonLevel: One character difference\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n\u251c\u2500-- Comparison: Surname\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match on surname\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n\u2502    etc.\n</code></pre> <p>Our example data would therefore result in the following comparisons, for <code>dob</code> and <code>surname</code>:</p> dob_l dob_r comparison_level interpretation 1971-05-24 1971-05-24 Exact match great match 1971-05-24 1971-06-24 One character difference fuzzy match 1971-05-24 2000-01-02 All other bad match <p></p> surname_l surname_r comparison_level interpretation Rob Rob Exact match great match Rob Jane All other bad match Rob Robert All other bad match, this comparison has no notion of nicknames <p>More information about specifying comparisons can be found here and here.</p> <p>We will now use these concepts to build a data linking model.</p> <pre><code># Begin by reading in the tutorial data again\nfrom splink import splink_datasets\n\ndf = splink_datasets.fake_1000\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#specifying-the-model-using-comparisons","title":"Specifying the model using comparisons","text":"<p>Splink includes a library of comparison functions at <code>splink.comparison_library</code> to make it simple to get started. These are split into two categories:</p> <ol> <li>Generic <code>Comparison</code> functions which apply a particular fuzzy matching function. For example, levenshtein distance.</li> </ol> <pre><code>import splink.comparison_library as cl\n\ncity_comparison = cl.LevenshteinAtThresholds(\"city\", 2)\nprint(city_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'LevenshteinAtThresholds' of \"city\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'city is NULL' with SQL rule: \"city_l\" IS NULL OR \"city_r\" IS NULL\n    - 'Exact match on city' with SQL rule: \"city_l\" = \"city_r\"\n    - 'Levenshtein distance of city &lt;= 2' with SQL rule: levenshtein(\"city_l\", \"city_r\") &lt;= 2\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <ol> <li><code>Comparison</code> functions tailored for specific data types. For example, email.</li> </ol> <pre><code>email_comparison = cl.EmailComparison(\"email\")\nprint(email_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'EmailComparison' of \"email\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'email is NULL' with SQL rule: \"email_l\" IS NULL OR \"email_r\" IS NULL\n    - 'Exact match on email' with SQL rule: \"email_l\" = \"email_r\"\n    - 'Exact match on username' with SQL rule: NULLIF(regexp_extract(\"email_l\", '^[^@]+', 0), '') = NULLIF(regexp_extract(\"email_r\", '^[^@]+', 0), '')\n    - 'Jaro-Winkler distance of email &gt;= 0.88' with SQL rule: jaro_winkler_similarity(\"email_l\", \"email_r\") &gt;= 0.88\n    - 'Jaro-Winkler &gt;0.88 on username' with SQL rule: jaro_winkler_similarity(NULLIF(regexp_extract(\"email_l\", '^[^@]+', 0), ''), NULLIF(regexp_extract(\"email_r\", '^[^@]+', 0), '')) &gt;= 0.88\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#specifying-the-full-settings-dictionary","title":"Specifying the full settings dictionary","text":"<p><code>Comparisons</code> are specified as part of the Splink <code>settings</code>, a Python dictionary which controls all of the configuration of a Splink model:</p> <pre><code>from splink import Linker, SettingsCreator, block_on, DuckDBAPI\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.LevenshteinAtThresholds(\"dob\", 1),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"city\"),\n        block_on(\"surname\"),\n\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\n</code></pre> <p>In words, this setting dictionary says:</p> <ul> <li>We are performing a <code>dedupe_only</code> (the other options are <code>link_only</code>, or <code>link_and_dedupe</code>, which may be used if there are multiple input datasets).</li> <li>When comparing records, we will use information from the <code>first_name</code>, <code>surname</code>, <code>dob</code>, <code>city</code> and <code>email</code> columns to compute a match score.</li> <li>The <code>blocking_rules_to_generate_predictions</code> states that we will only check for duplicates amongst records where either the <code>first_name AND city</code> or <code>surname</code> is identical.</li> <li>We have enabled term frequency adjustments for the 'city' column, because some values (e.g. <code>London</code>) appear much more frequently than others.</li> <li>We have set <code>retain_intermediate_calculation_columns</code> and <code>additional_columns_to_retain</code> to <code>True</code> so that Splink outputs additional information that helps the user understand the calculations. If they were <code>False</code>, the computations would run faster.</li> </ul>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimate-the-parameters-of-the-model","title":"Estimate the parameters of the model","text":"<p>Now that we have specified our linkage model, we need to estimate the <code>probability_two_random_records_match</code>, <code>u</code>, and <code>m</code> parameters.</p> <ul> <li> <p>The <code>probability_two_random_records_match</code> parameter is the probability that two records taken at random from your input data represent a match (typically a very small number).</p> </li> <li> <p>The <code>u</code> values are the proportion of records falling into each <code>ComparisonLevel</code> amongst truly non-matching records.</p> </li> <li> <p>The <code>m</code> values are the proportion of records falling into each <code>ComparisonLevel</code> amongst truly matching records</p> </li> </ul> <p>You can read more about the theory of what these mean.</p> <p>We can estimate these parameters using unlabeled data. If we have labels, then we can estimate them even more accurately.</p> <p>The rationale for the approach recommended in this tutorial is documented here.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimation-of-probability_two_random_records_match","title":"Estimation of <code>probability_two_random_records_match</code>","text":"<p>In some cases, the <code>probability_two_random_records_match</code> will be known. For example, if you are linking two tables of 10,000 records and expect a one-to-one match, then you should set this value to <code>1/10_000</code> in your settings instead of estimating it.</p> <p>More generally, this parameter is unknown and needs to be estimated.</p> <p>It can be estimated accurately enough for most purposes by combining a series of deterministic matching rules and a guess of the recall corresponding to those rules. For further details of the rationale behind this appraoch see here.</p> <p>In this example, I guess that the following deterministic matching rules have a recall of about 70%. That means, between them, the rules recover 70% of all true matches.</p> <pre><code>deterministic_rules = [\n    block_on(\"first_name\", \"dob\"),\n    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n    block_on(\"email\")\n]\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)\n</code></pre> <pre><code>Probability two random records match is estimated to be  0.00298.\nThis means that amongst all possible pairwise record comparisons, one in 335.56 are expected to match.  With 499,500 total possible comparisons, we expect a total of around 1,488.57 matching pairs\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimation-of-u-probabilities","title":"Estimation of <code>u</code> probabilities","text":"<p>Once we have the <code>probability_two_random_records_match</code> parameter, we can estimate the <code>u</code> probabilities.</p> <p>We estimate <code>u</code> using the <code>estimate_u_using_random_sampling</code> method, which doesn't require any labels.</p> <p>It works by sampling random pairs of records, since most of these pairs are going to be non-matches. Over these non-matches we compute the distribution of <code>ComparisonLevel</code>s for each <code>Comparison</code>.</p> <p>For instance, for <code>gender</code>, we would find that the the gender matches 50% of the time, and mismatches 50% of the time.</p> <p>For <code>dob</code> on the other hand, we would find that the <code>dob</code> matches 1% of the time, has a \"one character difference\" 3% of the time, and everything else happens 96% of the time.</p> <p>The larger the random sample, the more accurate the predictions. You control this using the <code>max_pairs</code> parameter. For large datasets, we recommend using at least 10 million - but the higher the better and 1 billion is often appropriate for larger datasets.</p> <pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n</code></pre> <pre><code>You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n\n\n----- Estimating u probabilities using random sampling -----\n\n\n\nEstimated u probabilities using random sampling\n\n\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - dob (no m values are trained).\n    - city (no m values are trained).\n    - email (no m values are trained).\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimation-of-m-probabilities","title":"Estimation of <code>m</code> probabilities","text":"<p><code>m</code> is the trickiest of the parameters to estimate, because we have to have some idea of what the true matches are.</p> <p>If we have labels, we can directly estimate it.</p> <p>If we do not have labelled data, the <code>m</code> parameters can be estimated using an iterative maximum likelihood approach called Expectation Maximisation.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimating-directly","title":"Estimating directly","text":"<p>If we have labels, we can estimate <code>m</code> directly using the <code>estimate_m_from_label_column</code> method of the linker.</p> <p>For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model.</p> <p>Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated.</p> <p>For example (in this tutorial we don't have labels, so we're not actually going to use this):</p> <pre><code>linker.training.estimate_m_from_label_column(\"social_security_number\")\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#estimating-with-expectation-maximisation","title":"Estimating with Expectation Maximisation","text":"<p>This algorithm estimates the <code>m</code> values by generating pairwise record comparisons, and using them to maximise a likelihood function.</p> <p>Each estimation pass requires the user to configure an estimation blocking rule to reduce the number of record comparisons generated to a manageable level.</p> <p>In our first estimation pass, we block on <code>first_name</code> and <code>surname</code>, meaning we will generate all record comparisons that have <code>first_name</code> and <code>surname</code> exactly equal.</p> <p>Recall we are trying to estimate the <code>m</code> values of the model, i.e. proportion of records falling into each <code>ComparisonLevel</code> amongst truly matching records.</p> <p>This means that, in this training session, we cannot estimate parameter estimates for the <code>first_name</code> or <code>surname</code> columns, since they will be equal for all the comparisons we do.</p> <p>We can, however, estimate parameter estimates for all of the other columns. The output messages produced by Splink confirm this.</p> <pre><code>training_blocking_rule = block_on(\"first_name\", \"surname\")\ntraining_session_fname_sname = (\n    linker.training.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\n\n\nEstimating the m probabilities of the model by blocking on:\n(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n\nParameter estimates will be made for the following comparison(s):\n    - dob\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - first_name\n    - surname\n\n\n\n\n\nWARNING:\nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\n\n\nIteration 1: Largest change in params was -0.521 in the m_probability of dob, level `Exact match on dob`\n\n\nIteration 2: Largest change in params was 0.0516 in probability_two_random_records_match\n\n\nIteration 3: Largest change in params was 0.0183 in probability_two_random_records_match\n\n\nIteration 4: Largest change in params was 0.00744 in probability_two_random_records_match\n\n\nIteration 5: Largest change in params was 0.00349 in probability_two_random_records_match\n\n\nIteration 6: Largest change in params was 0.00183 in probability_two_random_records_match\n\n\nIteration 7: Largest change in params was 0.00103 in probability_two_random_records_match\n\n\nIteration 8: Largest change in params was 0.000607 in probability_two_random_records_match\n\n\nIteration 9: Largest change in params was 0.000367 in probability_two_random_records_match\n\n\nIteration 10: Largest change in params was 0.000226 in probability_two_random_records_match\n\n\nIteration 11: Largest change in params was 0.00014 in probability_two_random_records_match\n\n\nIteration 12: Largest change in params was 8.73e-05 in probability_two_random_records_match\n\n\n\nEM converged after 12 iterations\n\n\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\n\n\nYour model is not yet fully trained. Missing estimates for:\n    - first_name (no m values are trained).\n    - surname (no m values are trained).\n    - email (some m values are not trained).\n</code></pre> <p>In a second estimation pass, we block on dob. This allows us to estimate parameters for the <code>first_name</code> and <code>surname</code> comparisons.</p> <p>Between the two estimation passes, we now have parameter estimates for all comparisons.</p> <pre><code>training_blocking_rule = block_on(\"dob\")\ntraining_session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n    training_blocking_rule\n)\n</code></pre> <pre><code>----- Starting EM training session -----\n\n\n\nEstimating the m probabilities of the model by blocking on:\nl.\"dob\" = r.\"dob\"\n\nParameter estimates will be made for the following comparison(s):\n    - first_name\n    - surname\n    - city\n    - email\n\nParameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n    - dob\n\n\n\n\n\nWARNING:\nLevel Jaro-Winkler &gt;0.88 on username on comparison email not observed in dataset, unable to train m value\n\n\n\nIteration 1: Largest change in params was -0.407 in the m_probability of surname, level `Exact match on surname`\n\n\nIteration 2: Largest change in params was 0.0929 in probability_two_random_records_match\n\n\nIteration 3: Largest change in params was 0.0548 in the m_probability of first_name, level `All other comparisons`\n\n\nIteration 4: Largest change in params was 0.0186 in probability_two_random_records_match\n\n\nIteration 5: Largest change in params was 0.00758 in probability_two_random_records_match\n\n\nIteration 6: Largest change in params was 0.00339 in probability_two_random_records_match\n\n\nIteration 7: Largest change in params was 0.0016 in probability_two_random_records_match\n\n\nIteration 8: Largest change in params was 0.000773 in probability_two_random_records_match\n\n\nIteration 9: Largest change in params was 0.000379 in probability_two_random_records_match\n\n\nIteration 10: Largest change in params was 0.000189 in probability_two_random_records_match\n\n\nIteration 11: Largest change in params was 9.68e-05 in probability_two_random_records_match\n\n\n\nEM converged after 11 iterations\n\n\nm probability not trained for email - Jaro-Winkler &gt;0.88 on username (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n\n\n\nYour model is not yet fully trained. Missing estimates for:\n    - email (some m values are not trained).\n</code></pre> <p>Note that Splink includes other algorithms for estimating m and u values, which are documented here.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#visualising-model-parameters","title":"Visualising model parameters","text":"<p>Splink can generate a number of charts to help you understand your model. For an introduction to these charts and how to interpret them, please see this video.</p> <p>The final estimated match weights can be viewed in the match weights chart:</p> <pre><code>linker.visualisations.match_weights_chart()\n</code></pre> <pre><code>linker.visualisations.m_u_parameters_chart()\n</code></pre> <p>We can also compare the estimates that were produced by the different EM training sessions</p> <pre><code>linker.visualisations.parameter_estimate_comparisons_chart()\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#saving-the-model","title":"Saving the model","text":"<p>We can save the model, including our estimated parameters, to a <code>.json</code> file, so we can use it in the next tutorial.</p> <pre><code>settings = linker.misc.save_model_to_json(\n    \"../demo_settings/saved_model_from_demo.json\", overwrite=True\n)\n</code></pre>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#detecting-unlinkable-records","title":"Detecting unlinkable records","text":"<p>An interesting application of our trained model that is useful to explore before making any predictions is to detect 'unlinkable' records.</p> <p>Unlinkable records are those which do not contain enough information to be linked. A simple example would be a record containing only 'John Smith', and null in all other fields. This record may link to other records, but we'll never know because there's not enough information to disambiguate any potential links. Unlinkable records can be found by linking records to themselves - if, even when matched to themselves, they don't meet the match threshold score, we can be sure they will never link to anything.</p> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre> <p>In the above chart, we can see that about 1.3% of records in the input dataset are unlinkable at a threshold match weight of 6.11 (correponding to a match probability of around 98.6%)</p> <p>Further Reading</p> <p> For more on the model estimation tools in Splink, please refer to the Model Training API documentation.</p> <p> For a deeper dive on:</p> <ul> <li>choosing comparisons, please refer to the Comparisons Topic Guides</li> <li>the underlying model theory, please refer to the Fellegi Sunter Topic Guide</li> <li>model training, please refer to the Model Training Topic Guides (Coming Soon).</li> </ul> <p> For more on the charts used in this tutorial, please refer to the Charts Gallery.</p>"},{"location":"demos/tutorials/04_Estimating_model_parameters.html#next-steps","title":"Next steps","text":"<p>Now we have trained a model, we can move on to using it predict matching records.</p>"},{"location":"demos/tutorials/05_Predicting_results.html","title":"5. Predicting results","text":""},{"location":"demos/tutorials/05_Predicting_results.html#predicting-which-records-match","title":"Predicting which records match","text":"<p>In the previous tutorial, we built and estimated a linkage model.</p> <p>In this tutorial, we will load the estimated model and use it to make predictions of which pairwise record comparisons match.</p> <pre><code>from splink import Linker, DuckDBAPI, splink_datasets\n\nimport pandas as pd\n\npd.options.display.max_columns = 1000\n\ndb_api = DuckDBAPI()\ndf = splink_datasets.fake_1000\n</code></pre>"},{"location":"demos/tutorials/05_Predicting_results.html#load-estimated-model-from-previous-tutorial","title":"Load estimated model from previous tutorial","text":"<pre><code>import json\nimport urllib\n\nurl = \"https://raw.githubusercontent.com/moj-analytical-services/splink/847e32508b1a9cdd7bcd2ca6c0a74e547fb69865/docs/demos/demo_settings/saved_model_from_demo.json\"\n\nwith urllib.request.urlopen(url) as u:\n    settings = json.loads(u.read().decode())\n\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\n</code></pre>"},{"location":"demos/tutorials/05_Predicting_results.html#predicting-match-weights-using-the-trained-model","title":"Predicting match weights using the trained model","text":"<p>We use <code>linker.inference.predict()</code> to run the model.</p> <p>Under the hood this will:</p> <ul> <li> <p>Generate all pairwise record comparisons that match at least one of the <code>blocking_rules_to_generate_predictions</code></p> </li> <li> <p>Use the rules specified in the <code>Comparisons</code> to evaluate the similarity of the input data</p> </li> <li> <p>Use the estimated match weights, applying term frequency adjustments where requested to produce the final <code>match_weight</code> and <code>match_probability</code> scores</p> </li> </ul> <p>Optionally, a <code>threshold_match_probability</code> or <code>threshold_match_weight</code> can be provided, which will drop any row where the predicted score is below the threshold.</p> <pre><code>df_predictions = linker.inference.predict(threshold_match_probability=0.2)\ndf_predictions.as_pandas_dataframe(limit=5)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name bf_tf_adj_first_name surname_l surname_r gamma_surname tf_surname_l tf_surname_r bf_surname bf_tf_adj_surname dob_l dob_r gamma_dob bf_dob city_l city_r gamma_city tf_city_l tf_city_r bf_city bf_tf_adj_city email_l email_r gamma_email tf_email_l tf_email_r bf_email bf_tf_adj_email match_key 0 -1.749664 0.229211 324 326 Kai Kai 4 0.006017 0.006017 84.821765 0.962892 None Turner -1 NaN 0.007326 1.000000 1.000000 2018-12-31 2009-11-03 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 k.t50eherand@z.ncom None -1 0.001267 NaN 1.0 1.0 0 1 -1.626076 0.244695 25 27 Gabriel None -1 0.001203 NaN 1.000000 1.000000 Thomas Thomas 4 0.004884 0.004884 88.870507 1.001222 1977-09-13 1977-10-17 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 gabriel.t54@nichols.info None -1 0.002535 NaN 1.0 1.0 1 2 -1.551265 0.254405 626 629 geeorGe George 1 0.001203 0.014440 4.176727 1.000000 Davidson Davidson 4 0.007326 0.007326 88.870507 0.667482 1999-05-07 2000-05-06 0 0.460743 Southamptn None -1 0.001230 NaN 1.00000 1.000000 None gdavidson@johnson-brown.com -1 NaN 0.00507 1.0 1.0 1 3 -1.427735 0.270985 600 602 Toby Toby 4 0.004813 0.004813 84.821765 1.203614 None None -1 NaN NaN 1.000000 1.000000 2003-04-23 2013-03-21 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 toby.d@menhez.com None -1 0.001267 NaN 1.0 1.0 0 4 -1.427735 0.270985 599 602 Toby Toby 4 0.004813 0.004813 84.821765 1.203614 Haall None -1 0.001221 NaN 1.000000 1.000000 2003-04-23 2013-03-21 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 None None -1 NaN NaN 1.0 1.0 0"},{"location":"demos/tutorials/05_Predicting_results.html#clustering","title":"Clustering","text":"<p>The result of <code>linker.inference.predict()</code> is a list of pairwise record comparisons and their associated scores. For instance, if we have input records A, B, C and D, it could be represented conceptually as:</p> <pre><code>A -&gt; B with score 0.9\nB -&gt; C with score 0.95\nC -&gt; D with score 0.1\nD -&gt; E with score 0.99\n</code></pre> <p>Often, an alternative representation of this result is more useful, where each row is an input record, and where records link, they are assigned to the same cluster.</p> <p>With a score threshold of 0.5, the above data could be represented conceptually as:</p> <pre><code>ID, Cluster ID\nA,  1\nB,  1\nC,  1\nD,  2\nE,  2\n</code></pre> <p>The algorithm that converts between the pairwise results and the clusters is called connected components, and it is included in Splink. You can use it as follows:</p> <pre><code>clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predictions, threshold_match_probability=0.5\n)\nclusters.as_pandas_dataframe(limit=10)\n</code></pre> <pre><code>Completed iteration 1, root rows count 2\n\n\nCompleted iteration 2, root rows count 0\n</code></pre> cluster_id unique_id first_name surname dob city email cluster __splink_salt tf_surname tf_email tf_city tf_first_name 0 0 0 Robert Alan 1971-06-24 None robert255@smith.net 0 0.012924 0.001221 0.001267 NaN 0.003610 1 1 1 Robert Allen 1971-05-24 None roberta25@smith.net 0 0.478756 0.002442 0.002535 NaN 0.003610 2 1 2 Rob Allen 1971-06-24 London roberta25@smith.net 0 0.409662 0.002442 0.002535 0.212792 0.001203 3 3 3 Robert Alen 1971-06-24 Lonon None 0 0.311029 0.001221 NaN 0.007380 0.003610 4 4 4 Grace None 1997-04-26 Hull grace.kelly52@jones.com 1 0.486141 NaN 0.002535 0.001230 0.006017 5 5 5 Grace Kelly 1991-04-26 None grace.kelly52@jones.com 1 0.434566 0.002442 0.002535 NaN 0.006017 6 6 6 Logan pMurphy 1973-08-01 None None 2 0.423760 0.001221 NaN NaN 0.012034 7 7 7 None None 2015-03-03 Portsmouth evied56@harris-bailey.net 3 0.683689 NaN 0.002535 0.017220 NaN 8 8 8 None Dean 2015-03-03 None None 3 0.553086 0.003663 NaN NaN NaN 9 8 9 Evie Dean 2015-03-03 Pootsmruth evihd56@earris-bailey.net 3 0.753070 0.003663 0.001267 0.001230 0.008424 <pre><code>sql = f\"\"\"\nselect *\nfrom {df_predictions.physical_name}\nlimit 2\n\"\"\"\nlinker.misc.query_sql(sql)\n</code></pre> match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name tf_first_name_l tf_first_name_r bf_first_name bf_tf_adj_first_name surname_l surname_r gamma_surname tf_surname_l tf_surname_r bf_surname bf_tf_adj_surname dob_l dob_r gamma_dob bf_dob city_l city_r gamma_city tf_city_l tf_city_r bf_city bf_tf_adj_city email_l email_r gamma_email tf_email_l tf_email_r bf_email bf_tf_adj_email match_key 0 -1.749664 0.229211 324 326 Kai Kai 4 0.006017 0.006017 84.821765 0.962892 None Turner -1 NaN 0.007326 1.000000 1.000000 2018-12-31 2009-11-03 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 k.t50eherand@z.ncom None -1 0.001267 NaN 1.0 1.0 0 1 -1.626076 0.244695 25 27 Gabriel None -1 0.001203 NaN 1.000000 1.000000 Thomas Thomas 4 0.004884 0.004884 88.870507 1.001222 1977-09-13 1977-10-17 0 0.460743 London London 1 0.212792 0.212792 10.20126 0.259162 gabriel.t54@nichols.info None -1 0.002535 NaN 1.0 1.0 1 <p>Further Reading</p> <p> For more on the prediction tools in Splink, please refer to the Prediction API documentation.</p>"},{"location":"demos/tutorials/05_Predicting_results.html#next-steps","title":"Next steps","text":"<p>Now we have made predictions with a model, we can move on to visualising it to understand how it is working.</p>"},{"location":"demos/tutorials/06_Visualising_predictions.html","title":"6. Visualising predictions","text":""},{"location":"demos/tutorials/06_Visualising_predictions.html#visualising-predictions","title":"Visualising predictions","text":"<p>Splink contains a variety of tools to help you visualise your predictions.</p> <p>The idea is that, by developing an understanding of how your model works, you can gain confidence that the predictions it makes are sensible, or alternatively find examples of where your model isn't working, which may help you improve the model specification and fix these problems.</p> <pre><code># Rerun our predictions to we're ready to view the charts\nfrom splink import Linker, DuckDBAPI, splink_datasets\n\nimport pandas as pd\n\npd.options.display.max_columns = 1000\n\ndb_api = DuckDBAPI()\ndf = splink_datasets.fake_1000\n</code></pre> <pre><code>import json\nimport urllib\n\nurl = \"https://raw.githubusercontent.com/moj-analytical-services/splink/847e32508b1a9cdd7bcd2ca6c0a74e547fb69865/docs/demos/demo_settings/saved_model_from_demo.json\"\n\nwith urllib.request.urlopen(url) as u:\n    settings = json.loads(u.read().decode())\n\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\ndf_predictions = linker.inference.predict(threshold_match_probability=0.2)\n</code></pre> <pre><code> -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre>"},{"location":"demos/tutorials/06_Visualising_predictions.html#waterfall-chart","title":"Waterfall chart","text":"<p>The waterfall chart provides a means of visualising individual predictions to understand how Splink computed the final matchweight for a particular pairwise record comparison.</p> <p>To plot a waterfall chart, the user chooses one or more records from the results of <code>linker.inference.predict()</code>, and provides these records to the <code>linker.visualisations.waterfall_chart()</code> function.</p> <p>For an introduction to waterfall charts and how to interpret them, please see this video.</p> <pre><code>records_to_view = df_predictions.as_record_dict(limit=5)\nlinker.visualisations.waterfall_chart(records_to_view, filter_nulls=False)\n</code></pre>"},{"location":"demos/tutorials/06_Visualising_predictions.html#comparison-viewer-dashboard","title":"Comparison viewer dashboard","text":"<p>The comparison viewer dashboard takes this one step further by producing an interactive dashboard that contains example predictions from across the spectrum of match scores.</p> <p>An in-depth video describing how to interpret the dashboard can be found here.</p> <pre><code>linker.visualisations.comparison_viewer_dashboard(df_predictions, \"scv.html\", overwrite=True)\n\n# You can view the scv.html file in your browser, or inline in a notbook as follows\nfrom IPython.display import IFrame\n\nIFrame(src=\"./scv.html\", width=\"100%\", height=1200)\n</code></pre> <p> </p>"},{"location":"demos/tutorials/06_Visualising_predictions.html#cluster-studio-dashboard","title":"Cluster studio dashboard","text":"<p>Cluster studio is an interactive dashboards that visualises the results of clustering your predictions.</p> <p>It provides examples of clusters of different sizes. The shape and size of clusters can be indicative of problems with record linkage, so it provides a tool to help you find potential false positive and negative links.</p> <pre><code>df_clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    df_predictions, threshold_match_probability=0.5\n)\n\nlinker.visualisations.cluster_studio_dashboard(\n    df_predictions,\n    df_clusters,\n    \"cluster_studio.html\",\n    sampling_method=\"by_cluster_size\",\n    overwrite=True,\n)\n\n# You can view the scv.html file in your browser, or inline in a notbook as follows\nfrom IPython.display import IFrame\n\nIFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1000)\n</code></pre> <pre><code>Completed iteration 1, root rows count 2\n\n\nCompleted iteration 2, root rows count 0\n</code></pre> <p> </p> <p>Further Reading</p> <p> For more on the visualisation tools in Splink, please refer to the Visualisation API documentation.</p> <p> For more on the charts used in this tutorial, please refer to the Charts Gallery</p>"},{"location":"demos/tutorials/06_Visualising_predictions.html#next-steps","title":"Next steps","text":"<p>Now we have visualised the results of a model, we can move on to some more formal Quality Assurance procedures using labelled data.</p>"},{"location":"demos/tutorials/07_Evaluation.html","title":"7. Evaluation","text":""},{"location":"demos/tutorials/07_Evaluation.html#evaluation-of-prediction-results","title":"Evaluation of prediction results","text":"<p>In the previous tutorial, we looked at various ways to visualise the results of our model. These are useful for evaluating a linkage pipeline because they allow us to understand how our model works and verify that it is doing something sensible. They can also be useful to identify examples where the model is not performing as expected.</p> <p>In addition to these spot checks, Splink also has functions to perform more formal accuracy analysis. These functions allow you to understand the likely prevalence of false positives and false negatives in your linkage models.</p> <p>They rely on the existence of a sample of labelled (ground truth) matches, which may have been produced (for example) by human beings. For the accuracy analysis to be unbiased, the sample should be representative of the overall dataset.</p> <pre><code># Rerun our predictions to we're ready to view the charts\nimport pandas as pd\n\nfrom splink import DuckDBAPI, Linker, splink_datasets\n\npd.options.display.max_columns = 1000\n\ndb_api = DuckDBAPI()\ndf = splink_datasets.fake_1000\n</code></pre> <pre><code>import json\nimport urllib\n\nfrom splink import block_on\n\nurl = \"https://raw.githubusercontent.com/moj-analytical-services/splink/847e32508b1a9cdd7bcd2ca6c0a74e547fb69865/docs/demos/demo_settings/saved_model_from_demo.json\"\n\nwith urllib.request.urlopen(url) as u:\n    settings = json.loads(u.read().decode())\n\n# The data quality is very poor in this dataset, so we need looser blocking rules\n# to achieve decent recall\nsettings[\"blocking_rules_to_generate_predictions\"] = [\n    block_on(\"first_name\"),\n    block_on(\"city\"),\n    block_on(\"email\"),\n    block_on(\"dob\"),\n]\n\nlinker = Linker(df, settings, db_api=DuckDBAPI())\ndf_predictions = linker.inference.predict(threshold_match_probability=0.01)\n</code></pre> <pre><code>Blocking time: 0.02 seconds\n\n\nPredict time: 0.80 seconds\n\n\n\n -- WARNING --\nYou have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\nComparison: 'email':\n    m values not fully trained\n</code></pre>"},{"location":"demos/tutorials/07_Evaluation.html#load-in-labels","title":"Load in labels","text":"<p>The labels file contains a list of pairwise comparisons which represent matches and non-matches.</p> <p>The required format of the labels file is described here.</p> <pre><code>from splink.datasets import splink_dataset_labels\n\ndf_labels = splink_dataset_labels.fake_1000_labels\nlabels_table = linker.table_management.register_labels_table(df_labels)\ndf_labels.head(5)\n</code></pre> unique_id_l source_dataset_l unique_id_r source_dataset_r clerical_match_score 0 0 fake_1000 1 fake_1000 1.0 1 0 fake_1000 2 fake_1000 1.0 2 0 fake_1000 3 fake_1000 1.0 3 0 fake_1000 4 fake_1000 0.0 4 0 fake_1000 5 fake_1000 0.0"},{"location":"demos/tutorials/07_Evaluation.html#view-examples-of-false-positives-and-false-negatives","title":"View examples of false positives and false negatives","text":"<pre><code>splink_df = linker.evaluation.prediction_errors_from_labels_table(\n    labels_table, include_false_negatives=True, include_false_positives=False\n)\nfalse_negatives = splink_df.as_record_dict(limit=5)\nlinker.visualisations.waterfall_chart(false_negatives)\n</code></pre>"},{"location":"demos/tutorials/07_Evaluation.html#false-positives","title":"False positives","text":"<pre><code># Note I've picked a threshold match probability of 0.01 here because otherwise\n# in this simple example there are no false positives\nsplink_df = linker.evaluation.prediction_errors_from_labels_table(\n    labels_table, include_false_negatives=False, include_false_positives=True, threshold_match_probability=0.01\n)\nfalse_postives = splink_df.as_record_dict(limit=5)\nlinker.visualisations.waterfall_chart(false_postives)\n</code></pre>"},{"location":"demos/tutorials/07_Evaluation.html#threshold-selection-chart","title":"Threshold Selection chart","text":"<p>Splink includes an interactive dashboard that shows key accuracy statistics:</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"threshold_selection\", add_metrics=[\"f1\"]\n)\n</code></pre>"},{"location":"demos/tutorials/07_Evaluation.html#receiver-operating-characteristic-curve","title":"Receiver operating characteristic curve","text":"<p>A ROC chart shows how the number of false positives and false negatives varies depending on the match threshold chosen. The match threshold is the match weight chosen as a cutoff for which pairwise comparisons to accept as matches.</p> <pre><code>linker.evaluation.accuracy_analysis_from_labels_table(labels_table, output_type=\"roc\")\n</code></pre>"},{"location":"demos/tutorials/07_Evaluation.html#truth-table","title":"Truth table","text":"<p>Finally, Splink can also report the underlying table used to construct the ROC and precision recall curves.</p> <pre><code>roc_table = linker.evaluation.accuracy_analysis_from_labels_table(\n    labels_table, output_type=\"table\"\n)\nroc_table.as_pandas_dataframe(limit=5)\n</code></pre> truth_threshold match_probability total_clerical_labels p n tp tn fp fn P_rate N_rate tp_rate tn_rate fp_rate fn_rate precision recall specificity npv accuracy f1 f2 f0_5 p4 phi 0 -18.9 0.000002 3176.0 2031.0 1145.0 1709.0 1103.0 42.0 322.0 0.639484 0.360516 0.841457 0.963319 0.036681 0.158543 0.976014 0.841457 0.963319 0.774035 0.885390 0.903755 0.865316 0.945766 0.880476 0.776931 1 -16.7 0.000009 3176.0 2031.0 1145.0 1709.0 1119.0 26.0 322.0 0.639484 0.360516 0.841457 0.977293 0.022707 0.158543 0.985014 0.841457 0.977293 0.776544 0.890428 0.907594 0.866721 0.952514 0.886010 0.789637 2 -12.8 0.000140 3176.0 2031.0 1145.0 1709.0 1125.0 20.0 322.0 0.639484 0.360516 0.841457 0.982533 0.017467 0.158543 0.988433 0.841457 0.982533 0.777471 0.892317 0.909043 0.867249 0.955069 0.888076 0.794416 3 -12.5 0.000173 3176.0 2031.0 1145.0 1708.0 1125.0 20.0 323.0 0.639484 0.360516 0.840965 0.982533 0.017467 0.159035 0.988426 0.840965 0.982533 0.776934 0.892003 0.908752 0.866829 0.954937 0.887763 0.793897 4 -12.4 0.000185 3176.0 2031.0 1145.0 1705.0 1132.0 13.0 326.0 0.639484 0.360516 0.839488 0.988646 0.011354 0.160512 0.992433 0.839488 0.988646 0.776406 0.893262 0.909576 0.866186 0.957542 0.889225 0.797936"},{"location":"demos/tutorials/07_Evaluation.html#unlinkables-chart","title":"Unlinkables chart","text":"<p>Finally, it can be interesting to analyse whether your dataset contains any 'unlinkable' records.</p> <p>'Unlinkable records' are records with such poor data quality they don't even link to themselves at a high enough probability to be accepted as matches</p> <p>For example, in a typical linkage problem, a 'John Smith' record with nulls for their address and postcode may be unlinkable.  By 'unlinkable' we don't mean there are no matches; rather, we mean it is not possible to determine whether there are matches.UnicodeTranslateError</p> <p>A high proportion of unlinkable records is an indication of poor quality in the input dataset</p> <pre><code>linker.evaluation.unlinkables_chart()\n</code></pre> <p>For this dataset and this trained model, we can see that most records are (theoretically) linkable:  At a match weight 6, around around 99% of records could be linked to themselves.</p> <p>Further Reading</p> <p> For more on the quality assurance tools in Splink, please refer to the Evaluation API documentation.</p> <p> For more on the charts used in this tutorial, please refer to the Charts Gallery.</p> <p> For more on the Evaluation Metrics used in this tutorial, please refer to the Edge Metrics guide.</p>"},{"location":"demos/tutorials/07_Evaluation.html#thats-it","title":"That's it!","text":"<p>That wraps up the Splink tutorial! Don't worry, there are still plenty of resources to help on the next steps of your Splink journey:</p> <p> For some end-to-end notebooks of Splink pipelines, check out our Examples</p> <p> For more deepdives into the different aspects of Splink, and record linkage more generally, check out our Topic Guides</p> <p> For a reference on all the functionality avalable in Splink, see our Documentation</p>"},{"location":"demos/tutorials/08_building_your_own_model.html","title":"8. Tips for building your own model","text":""},{"location":"demos/tutorials/08_building_your_own_model.html#next-steps-tips-for-building-your-own-model","title":"Next steps: Tips for Building your own model","text":"<p>Now that you've completed the tutorial, this page summarises some recommendations for how to approach building your own Splink models.</p> <p>These recommendations should help you create an accurate model as quickly as possible.  They're particularly applicable if you're working with large datasets, where you can get slowed down by long processing times.</p> <p>In a nutshell, we recommend beginning with a small sample and a basic model, then iteratively adding complexity to resolve issues and improve performance.</p>"},{"location":"demos/tutorials/08_building_your_own_model.html#general-workflow","title":"General workflow","text":"<ul> <li> <p>For large datasets, start by linking a small non-random sample of records. Building a model is an iterative process of writing data cleaning code, training models, finding issues, and circling back to fix them. You don't want long processing times slowing down this iteration cycle.</p> <p>Most of your code can be developed against a small sample of records, and only once that's working, re-run everything on the full dataset.</p> <p>You need a non-random sample of perhaps about 10,000 records. The same must be  non-random because it must retain lots of matches - for instance, retain all people aged over 70, or all people with a first name starting with the characters <code>pa</code>.  You should aim to be able to run your full training and prediction script in less than a minute.</p> <p>Remember to set a lower value (say <code>1e6</code>) of the <code>target_rows</code> when calling <code>estimate_u_using_random_sampling()</code> during this iteration process, but then increase in the final full-dataset run to a much higher value, maybe <code>1e8</code>, since large value of <code>target_rows</code> can cause long processing times even on relatively small datasets.</p> </li> <li> <p>Start with a simple model.  It's often tempting to start by designing a complex model, with many granular comparison levels in an attempt to reflect the real world closely.</p> <p>Instead, we recommend starting with with a simple, rough and ready model where most comparisons have 2-3 levels (exact match, possibly a fuzzy level, and everything else).  The idea is to get to the point of looking at prediction results as quickly as possible using e.g. the comparison viewer.  You can then start to look for where your simple model is getting it wrong, and use that as the basis for improving your model, and iterating until you're seeing good results.</p> </li> </ul>"},{"location":"demos/tutorials/08_building_your_own_model.html#blocking-rules-for-prediction","title":"Blocking rules for prediction","text":"<ul> <li> <p>Analyse the number of comparisons before running predict.  Use the tools in <code>splink.blocking_analysis</code> to validate that your rules aren't going to create a vast number of comparisons before asking Splink to create those comparisons.</p> </li> <li> <p>Many strict <code>blocking_rules_for_prediction</code> are generally better than few loose rules.  Whilst individually, strict blocking rules are likely to exclude many true matches, between them it should be implausible that a truly matching record 'falls through' all the rules.  Many strict rules often result in far fewer overall comparisons and a small number of loose rules.  In practice, many of our real-life models have between about 10-15 <code>blocking_rules_for_prediction</code>.</p> </li> </ul>"},{"location":"demos/tutorials/08_building_your_own_model.html#em-trainining","title":"EM trainining","text":"<ul> <li> <p>Predictions usually aren't very sensitive to <code>m</code> probabilities being a bit wrong.  The hardest model parameters to estimate are the <code>m</code> probabilities.  It's fairly common for Expectation Maximisation to yield 'bad' (implausble) values.  Luckily, the accuracy of your model is usually not particularly sensitive to the <code>m</code> probabilities - it usually the <code>u</code> probabilities driving the biggest match weights.  If you're having problems, consider fixing some <code>m</code> probabilities by expert judgement - see here for how.</p> </li> <li> <p>Convergence problems are often indicative of the need for further data cleaning.  Whilst predictions often aren't terribly sensitive to <code>m</code> probabilities, question why the estimation procedue is producing bad parameter estimates.  To do this, it's often enough to look at a variety of predictions to see if you can spot edge cases where the model is not doing what's expected.  For instance, we may find matches where the first name is <code>Mr</code>.  By fixing this and reestimating, the parameter estimates often make more sense.</p> </li> <li> <p>Blocking rules for EM training do not need high recall.  The purpose of blocking rules for EM training is to find a subset of records which include a reasonably balanced mix of matches and non matches.  There is no requirement that these records contain all, or even most of the matches.  For more see here  To double check that parameter estimates are a result of a biased sample of matches, you can use <code>linker.visualisations.parameter_estimate_comparisons_chart</code>.</p> </li> </ul>"},{"location":"demos/tutorials/08_building_your_own_model.html#working-with-large-datasets","title":"Working with large datasets","text":"<p>To optimise memory usage and performance:</p> <ul> <li> <p>Avoid pandas for input/output Whilst Splink supports inputs as pandas dataframes, and you can convert results to pandas using <code>.as_pandas_dataframe()</code>, we recommend against this for large datasets.  For large datasets, use the concept of a dataframe that's native to your database backend.  For example, if you're using Spark, it's best to read your files using Spark and pass Spark dataframes into Splink, and save any outputs using <code>splink_dataframe.as_spark_dataframe</code>.  With duckdb use the inbuilt duckdb csv/parquet reader, and output via <code>splinkdataframe.as_duckdbpyrelation</code>.</p> </li> <li> <p>Avoid pandas for data cleaning.  You will generally get substantially better performance by performing data cleaning in SQL using your chosen backend rather than using pandas.</p> </li> <li> <p>Turn off intermediate columns when calling <code>predict()</code>.  Whilst during the model development phase, it is useful to set <code>retain_intermediate_calculation_columns=True</code> and     <code>retain_intermediate_calculation_columns_for_prediction=True</code> in your settings, you should generally turn these off when calling <code>predict()</code>.  This will result in a much smaller table as your result set.  If you want waterfall charts for individual pairs, you can use <code>linker.inference.compare_two_records</code></p> </li> </ul>"},{"location":"dev_guides/index.html","title":"Contributing to Splink","text":""},{"location":"dev_guides/index.html#contributing-to-splink","title":"Contributing to Splink","text":"<p>Thank you for your interest in contributing to Splink! If this is your first time working with Splink, check our Contributors Guide.</p> <p>When making changes to Splink, there are a number of common operations that developers need to perform. The guides below lay out some of these common operations, and provides scripts to automate these processes. These include:</p> <ul> <li>Developer Quickstart - to get contributors up and running.</li> <li>Linting and Formatting - to ensure consistent code style and to reformat code, where possible.</li> <li>Testing - to ensure all of the codebase is performing as intended.</li> <li>Building the Documentation locally - to test any changes to the docs site render correctly.</li> <li>Releasing a new package version - to walk-through the release process for new versions of Splink. This generally happens every 2 weeks, or in the case of an urgent bug fix.</li> <li>Contributing to the Splink Blog - to walk through the process of adding a post to the Splink blog.</li> </ul>"},{"location":"dev_guides/index.html#how-splink-works","title":"How Splink works","text":"<p>Splink is quite a large, complex codebase. The guides in this section lay out some of the key structures and key areas within the Splink codebase. These include:</p> <ul> <li>Understanding and Debugging Splink - demonstrates several ways of understanding how Splink code is running under the hood. This includes Splink's debug mode and logging.</li> <li>Transpilation using SQLGlot - demonstrates how Splink translates SQL in order to be compatible with multiple SQL engines using the SQLGlot package.</li> <li>Performance and caching - demonstrates how pipelining and caching is used to make Splink run more efficiently.</li> <li>Charts - demonstrates how charts are built in Splink, including how to add new charts and edit existing charts.</li> <li>User-Defined Functions - demonstrates how User Defined Functions (UDFs) are used to provide functionality within Splink that is not native to a given SQL backend.</li> <li>Managing Splink's Dependencies - this section provides guidelines for managing our core dependencies and our strategy for phasing out Python versions that have reached their end-of-life.</li> </ul>"},{"location":"dev_guides/CONTRIBUTING.html","title":"Contributor Guide","text":""},{"location":"dev_guides/CONTRIBUTING.html#contributing-to-splink","title":"Contributing to Splink","text":"<p>Contributing to an open source project takes many forms. Below are some of the ways you can contribute to Splink!</p>"},{"location":"dev_guides/CONTRIBUTING.html#asking-questions","title":"Asking questions","text":"<p>If you have a question about Splink, we recommended asking on our GitHub discussion board. This means that other users can benefit from the answers too! On that note, it is always worth checking if a similar question has been asked (and answered) before.</p>"},{"location":"dev_guides/CONTRIBUTING.html#reporting-issues","title":"Reporting issues","text":"<p>Is something broken? Or not acting how you would expect? Are we missing a feature that would make your life easier? We want to know about it!</p> <p>When reporting issues please include as much detail as possible about your operating system, Splink version, python version and which SQL backend you are using. Whenever possible, please also include a brief, self-contained code example that demonstrates the problem. It is particularly helpful if you can look through the existing issues and provide links to any related issues.</p>"},{"location":"dev_guides/CONTRIBUTING.html#contributing-to-documentation","title":"Contributing to documentation","text":"<p>Contributions to Splink are not limited to the code. Feedback and input on our documentation from a user's perspective is extremely valuable - even something as small as fixing a typo. More generally, if you are interested in starting to work on Splink, documentation is a great way to get those first commits!</p> <p>The easiest way to contribute to the documentation is by clicking the pencil icon at the top right of the docs page you want to edit. This will automatically create a fork of the Splink repository on GitHub and make it easy to open a pull request with your changes, which one of the Splink dev team will review.</p> <p>If you need to make a larger change to the docs, this workflow might not be the best, since you won't get to see the effects of your changes before submitting them. To do this, you will need to create a fork of the Splink repo, then clone your fork to your computer. Then, you can edit the documentation in the docs folder (and API documentation, which can be found as docstrings in the code itself) locally. To see what the docs will look like with your changes, you can build the docs site locally. When you are happy with your changes, commit and push them to your fork, then create a Pull Request.</p> <p>We are trying to make our documentation as accessible to as many people as possible. If you find any problems with accessibility then please let us know by raising an issue, or feel free to put in a Pull Request with your suggested fixes.</p>"},{"location":"dev_guides/CONTRIBUTING.html#contributing-code","title":"Contributing code","text":"<p>Thanks for your interest in contributing code to Splink!</p> <p>There are a number of ways to get involved:</p> <ul> <li>Start work on an existing issue, there should be some with a <code>good first issue</code> flag which are a good place to start.</li> <li>Tackle a problem you have identified. If you have identified a feature or bug, the first step is to create a new issue to explain what you have identified and what you plan to implement, then you are free to fork the repository and get coding!</li> </ul> <p>In either case, we ask that you assign yourself to the relevant issue and open up a draft pull request (PR) while you are working on your feature/bug-fix. This helps the Splink dev team keep track of developments and means we can start supporting you sooner!</p> <p>You can always add further PRs to build extra functionality. Starting out with a minimum viable product and iterating makes for better software (in our opinion). It also helps get features out into the wild sooner.</p> <p>To get set up for development locally, see the development quickstart.</p>"},{"location":"dev_guides/CONTRIBUTING.html#best-practices","title":"Best practices","text":"<p>When making code changes, we recommend:</p> <ul> <li>Adding tests to ensure your code works as expected. These will be run through GitHub Actions when a PR is opened.</li> <li>Linting to ensure that code is styled consistently.</li> </ul>"},{"location":"dev_guides/CONTRIBUTING.html#branching-strategy","title":"Branching Strategy","text":"<p>All pull requests (PRs) should target the <code>master</code> branch.</p> <p>We believe that small Pull Requests make better code. They:</p> <ul> <li>are more focused</li> <li>increase understanding and clarity</li> <li>are easier (and quicker) to review</li> <li>get feedback quicker</li> </ul> <p>If you have a larger feature, please consider creating a simple minimum-viable feature and submit for review. Once this has been reviewed by the Splink dev team there are two options to consider:</p> <ol> <li>Merge minimal feature, then create a new branch with additional features.</li> <li>Do not merge the initial feature branch, create additional feature branches from the reviewed branch.</li> </ol> <p>The best solution often depends on the specific feature being created and any other development work happening in that area of the codebase. If you are unsure, please ask the dev team for advice on how to best structure your changes in your initial PR and we can come to a decision together.</p>"},{"location":"dev_guides/caching.html","title":"Caching and pipelining","text":""},{"location":"dev_guides/caching.html#caching-and-pipelining","title":"Caching and pipelining","text":"<p>Splink is able to run against multiple SQL backends because all of the core data linking calculations are implemented in SQL. This SQL can therefore be submitted to a chosen SQL backend for execution.</p> <p>Computations in Splink often take the form of a number of <code>select</code> statements run in sequence.</p> <p>For example, the <code>predict()</code> step:</p> <ul> <li>Inputs <code>__splink__df_concat_with_tf</code> and outputs <code>__splink__df_blocked</code></li> <li>Inputs <code>__splink__df_blocked</code> and outputs <code>__splink__df_comparison_vectors</code></li> <li>Inputs <code>__splink__df_comparison_vectors</code> and outputs <code>__splink__df_match_weight_parts</code></li> <li>Inputs <code>__splink__df_match_weight_parts</code> and outputs <code>__splink__df_predict</code></li> </ul> <p>To make this run faster, two key optimisations are implemented:</p> <ul> <li>Pipelining - combining multiple <code>select</code> statements into a single statement using <code>WITH</code>(CTE) queries</li> <li>Caching: saving the results of calculations so they don't need recalculating. This is especially useful because some intermediate calculations are reused multiple times during a typical Splink session</li> </ul> <p>This article discusses the general implementation of caching and pipelining. The implementation needs some alterations for certain backends like Spark, which lazily evaluate SQL by default.</p>"},{"location":"dev_guides/caching.html#implementation-pipelining","title":"Implementation: Pipelining","text":"<p>A <code>SQLPipeline</code> class manages SQL pipelining.</p> <p>A <code>SQLPipeline</code> is composed of a number of <code>SQLTask</code> objects, each of which represents a select statement.</p> <p>The code is fairly straightforward: Given a sequence of <code>select</code> statements, <code>[a,b,c]</code> they are combined into a single query as follows:</p> <pre><code>with\na as (a_sql),\nb as (b_sql),\nc_sql\n</code></pre> <p>To make this work, each statement (a,b,c) in the pipeline must refer to the previous step by name. For example, <code>b_sql</code> probably selects from the <code>a_sql</code> table, which has been aliased <code>a</code>. So <code>b_sql</code> must use the table name <code>a</code> to refer to the result of <code>a_sql</code>.</p> <p>To make this tractable, each <code>SQLTask</code> has an <code>output_table_name</code>. For example, the <code>output_table_name</code> for <code>a_sql</code> in the above example is <code>a</code>.</p> <p>For instance, in the <code>predict()</code> pipeline above, the first <code>output_table_name</code> is <code>__splink__df_blocked</code>. By giving each task a meaningful <code>output_table_name</code>, subsequent tasks can reference previous outputs in a way which is semantically clear.</p>"},{"location":"dev_guides/caching.html#implementation-caching","title":"Implementation: Caching","text":"<p>When a SQL pipeline is executed, it has two output names:</p> <ul> <li>A <code>physical_name</code>, which is the name of the materialised table in the output database e.g. <code>__splink__df_predict_cbc9833</code></li> <li>A <code>templated_name</code>, which is a descriptive name of what the table represents e.g. <code>__splink__df_predict</code></li> </ul> <p>Each time Splink runs a SQL pipeline, the SQL string is hashed. This creates a unique identifier for that particular SQL string, which serves to identify the output.</p> <p>When Splink is asked to execute a SQL string, before execution, it checks whether the resultant table already exists. If it does, it returns the table rather than recomputing it.</p> <p>For example, when we run <code>linker.inference.predict()</code>, Splink:</p> <ul> <li>Generates the SQL tasks</li> <li>Pipelines them into a single SQL statement</li> <li>Hashes the statement to create a physical name for the outputs <code>__splink__df_predict_cbc9833</code></li> <li>Checks whether a table with physical name <code>__splink__df_predict_cbc9833</code> already exists in the database</li> <li>If not, executes the SQL statement, creating table <code>__splink__df_predict_cbc9833</code> in the database.</li> </ul> <p>In terms of implementation, the following happens:</p> <ul> <li>SQL statements are generated an put in the queue - see here</li> <li>Once all the tasks have been added to the queue, we call <code>_execute_sql_pipeline()</code> see here</li> <li>The SQL is combined into a single pipelined statement here</li> <li>We call <code>_sql_to_splink_dataframe()</code> which returns the table (from the cache if it already exists, or it executes the SQL)</li> <li>The table is returned as a <code>SplinkDataframe</code>, an abstraction over a table in a database. See the API docs for SplinkDataFrame.</li> </ul>"},{"location":"dev_guides/caching.html#some-cached-tables-do-not-need-a-hash","title":"Some cached tables do not need a hash","text":"<p>A hash is required to uniquely identify some outputs. For example, blocking is used in several places in Splink, with different results. For example, the <code>__splink__df_blocked</code> needed to estimate parameters is different to the <code>__splink__df_blocked</code> needed in the <code>predict()</code> step.</p> <p>As a result, we cannot materialise a single table called <code>__splink__df_blocked</code> in the database and reuse it multiple times. This is why we append the hash of the SQL, so that we can uniquely identify the different versions of <code>__splink__df_blocked</code> which are needed in different contexts.</p> <p>There are, however, some tables which are globally unique. They only take a single form, and if they exist in the cache they never need recomputing.</p> <p>An example of this is <code>__splink__df_concat_with_tf</code>, which represents the concatenation of the input dataframes.</p> <p>To create this table, we can execute <code>_sql_to_splink_dataframe</code> with <code>materialise_as_hash</code> set to <code>False</code>. The resultant materialised table will not have a hash appended, and will simply be called <code>__splink__df_concat_with_tf</code>. This is useful, because when performing calculations Splink can now check the cache for <code>__splink__df_concat_with_tf</code> each time it is needed.</p> <p>In fact, many Splink pipelines begin with the assumption that this table exists in the database, because the first <code>SQLTask</code> in the pipeline refers to a table named <code>__splink__df_concat_with_tf</code>. To ensure this is the case, a function is used to create this table if it doesn't exist.</p>"},{"location":"dev_guides/caching.html#using-pipelining-to-optimise-splink-workloads","title":"Using pipelining to optimise Splink workloads","text":"<p>At what point should a pipeline of <code>SQLTask</code>s be executed (materialised into a physical table)?</p> <p>For any individual output, it will usually be fastest to pipeline the full linage of tasks, right from raw data through to the end result.</p> <p>However, there are many intermediate outputs which are used by many different Splink operations.</p> <p>Performance can therefore be improved by computing and saving these intermediate outputs to a cache, to ensure they don't need to be computed repeatedly.</p> <p>This is achieved by enqueueing SQL to a pipeline and strategically calling <code>execute_sql_pipeline</code> to materialise results that need to cached.</p>"},{"location":"dev_guides/debug_modes.html","title":"Understanding and debugging Splink","text":""},{"location":"dev_guides/debug_modes.html#understanding-and-debugging-splinks-computations","title":"Understanding and debugging Splink's computations","text":"<p>Splink contains tooling to help developers understand the underlying computations, how caching and pipelining is working, and debug problems.</p> <p>There are two main mechanisms: <code>_debug_mode</code>, and setting different logging levels</p>"},{"location":"dev_guides/debug_modes.html#debug-mode","title":"Debug mode","text":"<p>You can turn on debug mode by setting <code>linker._debug_mode = True</code>.</p> <p>This has the following effects:</p> <ul> <li>Each step of Splink's calculations are executed in turn. That is, pipelining is switched off.</li> <li>The SQL statements being executed by Splink are displayed</li> <li>The results of the SQL statements are displayed in tabular format</li> </ul> <p>This is probably the best way to understand each step of the calculations being performed by Splink - because a lot of the implementation gets 'hidden' within pipelines for performance reasons.</p> <p>Note that enabling debug mode will dramatically reduce Splink's performance!</p>"},{"location":"dev_guides/debug_modes.html#logging","title":"Logging","text":"<p>Splink has a range of logging modes that output information about what Splink is doing at different levels of verbosity.</p> <p>Unlike debug mode, logging doesn't affect the performance of Splink.</p>"},{"location":"dev_guides/debug_modes.html#logging-levels","title":"Logging levels","text":"<p>You can set the logging level with code like <code>logging.getLogger(\"splink\").setLevel(desired_level)</code> although see notes below about gotchas.</p> <p>The logging levels in Splink are:</p> <ul> <li><code>logging.INFO</code> (<code>20</code>): This outputs user facing messages about the training status of Splink models</li> <li><code>15</code>: Outputs additional information about time taken and parameter estimation</li> <li><code>logging.DEBUG</code> (<code>10</code>): Outputs information about the names of the SQL statements executed</li> <li><code>logging.DEBUG</code> (<code>7</code>): Outputs information about the names of the components of the SQL pipelines</li> <li><code>logging.DEBUG</code> (<code>5</code>): Outputs the SQL statements themselves</li> </ul>"},{"location":"dev_guides/debug_modes.html#how-to-control-logging","title":"How to control logging","text":"<p>Note that by default Splink sets the logging level to <code>INFO</code> on initialisation</p>"},{"location":"dev_guides/debug_modes.html#with-basic-logging","title":"With basic logging","text":"<pre><code>import logging\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n\n# This must come AFTER the linker is intialised, because the logging level\n# will be set to INFO\nlogging.getLogger(\"splink\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"dev_guides/debug_modes.html#without-basic-logging","title":"Without basic logging","text":"<pre><code># This code can be anywhere since set_up_basic_logging is False\nimport logging\nlogging.basicConfig(format=\"%(message)s\")\nsplink_logger = logging.getLogger(\"splink\")\nsplink_logger.setLevel(logging.INFO)\n\nlinker = Linker(df, settings, db_api, set_up_basic_logging=False)\n</code></pre>"},{"location":"dev_guides/dependency_compatibility_policy.html","title":"Dependency Compatibility Policy","text":"<p>This page highlights the importance of package versioning and proposes that we use a \"sunsetting\" strategy for updating our support python and dependency versions as they reach end-of-life.</p> <p>Additionally, it lays out some rough guidelines for us to follow when addresses future package conflicts and issues arises from antiquated dependency versions.</p>"},{"location":"dev_guides/dependency_compatibility_policy.html#package-versioning-policy","title":"Package Versioning Policy","text":"<p>Monitoring package versioning within Splink is important. It ensures that the project can be used by as wide a group of individuals as possible, without wreaking havoc on our issues log.</p> <p>Below is a rough summary of versioning and some complimentary guidelines detailing how we should look to deal with dependency management going forward.</p>"},{"location":"dev_guides/dependency_compatibility_policy.html#benefits-to-effective-versioning","title":"Benefits to Effective Versioning","text":"<p>Effective versioning is crucial for ensuring Splink's compatibility across diverse technical ecosystems and seamless integration with various Python versions and cloud tools. Key advantages include:</p> <ul> <li>Faster dependency resolution with <code>uv lock</code>.</li> <li>Reduces dependency conflicts across systems.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#versioning-guidance","title":"Versioning Guidance","text":""},{"location":"dev_guides/dependency_compatibility_policy.html#establish-minimum-supported-versions","title":"Establish Minimum Supported Versions","text":"<ul> <li>Align with Python Versions: Select the minimum required versions for dependencies based on the earliest version of Python we plan to support. This approach is aligned with our policy on Sunsetting End-of-Life Python Versions, ensuring Splink remains compatible across a broad spectrum of environments.</li> <li>Document Reasons:  Where appropriate, clearly document why specific versions are chosen as minimums, including any critical features or bug fixes that dictate these choices. We should look to do this in pull requests implementing the change and as comments in <code>pyproject.toml</code>. Doing so allows us to easily track versioning decisions.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#prefer-open-version-constraints","title":"Prefer Open Version Constraints","text":"<ul> <li>Use Open Upper Bounds: Wherever feasible, avoid setting an upper version limit for a dependency. This reduces compatibility conflicts with external packages and allows the user to decide their versioning strategy at the application level.</li> <li>Monitor Compatibility: Actively monitor the development of our core dependencies to anticipate significant updates (such as new major versions) that might necessitate code changes. Within Splink, this is particularly relevant for both SQLGlot and  DuckDB, that (semi)frequently release new, breaking changes.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#compatibility-checks","title":"Compatibility Checks","text":"<ul> <li>Automated Testing: Use Continuous Integration (CI) to help test the latest python and package versions. This helps identify compatibility issues early.</li> <li>Matrix Testing: Test against a matrix of dependencies or python versions to ensure broad compatibility. pytest_run_tests_with_cache.yml is currently our broad compatibility check for supported versions of python.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#handling-breaking-changes","title":"Handling Breaking Changes","text":"<ul> <li>Temporary Version Pinning for Major Changes: In cases where a dependency introduces breaking changes that we cannot immediately accommodate, we should look to temporarily pin to a specific version or version range until we have an opportunity to update Splink.</li> <li>Adaptive Code Changes: When feasible, adapt code to be compatible with new major versions of dependencies. This may include conditional logic to handle differences across versions. An example of this can be found within <code>input_column.py</code>, where we adjust how column identifiers are extracted from SQLGlot based on its version.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#documentation-and-communication","title":"Documentation and Communication","text":"<ul> <li>Clear Documentation: Clearly log installation instructions within the Getting Started section of our documentation. This should cover not only standard installation procedures but also specialised instructions, for instance, installing a -less version of Splink, for locked down environments.</li> <li>Log Dependency Changes in the CHANGELOG: Where dependencies are adjusted, ensure that changes are logged within <code>CHANGELOG.md</code>. This can help simplify debugging and creates a guide that can be easily referenced.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#user-support-and-feedback","title":"User Support and Feedback","text":"<ul> <li>Issue Tracking: Actively track and address issues related to dependency compatibility. Where users are having issues, have them report their package versions through either <code>pip freeze</code> or <code>pip-chill</code>, so we can more easily identify what may have caused the problem.</li> <li>Feedback Loops: Encourage feedback from users regarding compatibility and dependency issues. Streamline the reporting process in our issues log.</li> </ul>"},{"location":"dev_guides/dependency_compatibility_policy.html#sunsetting-end-of-life-python-versions","title":"Sunsetting End-of-Life Python Versions","text":"<p>In alignment with the Python community's practices, we are phasing out support for Python versions that have hit end-of-life and are no longer maintained by the core Python development team. This decision ensures that Splink remains secure, efficient, and up-to-date with the latest Python features and improvements.</p> <p>Our approach mirrors that of key package maintainers, such as the developers behind NumPy. The NumPy developers have kindly pulled together NEP 29, their guidelines for python version support. This outlines a recommended framework for the deprecation of outdated Python versions.</p>"},{"location":"dev_guides/dependency_compatibility_policy.html#benefits-of-discontinuing-support-for-older-python-versions","title":"Benefits of Discontinuing Support for Older Python Versions:","text":"<ul> <li>Enhanced Tooling: Embracing newer versions enables the use of advanced Python features, as we no longer need to use only features available in outdated python versions. See the new features in 3.9 that we can use after dropping support for 3.8.</li> <li>Fewer Dependabot Alerts: Transitioning away from older Python versions reduces the volume of alerts associated with legacy package dependencies.</li> <li>Minimised Package Conflicts: Updating python decreases the necessity for makeshift solutions to resolve dependency issues with our core dependencies, fostering a smoother integration with tools like Poetry.</li> </ul> <p>For a comprehensive rationale behind upgrading, the article \"It's time to stop using python 3.8\" offers an insightful summary.</p>"},{"location":"dev_guides/dependency_compatibility_policy.html#implementation-timeline","title":"Implementation Timeline:","text":"<p>The cessation of support for major Python versions post-end-of-life will not be immediate but will instead be phased in gradually over the months following their official end-of-life designation.</p> <p>Proposed Workflow for Sunsetting Major Python Versions:</p> <ol> <li>Initial Grace Period: We propose a waiting period of approximately six months post-end-of-life before initiating the upgrade process. This interval:<ul> <li>Mitigates potential complications arising from system-wide Python updates across major cloud distributors and network administrators.</li> <li>Provides a window to inform users about the impending deprecation of older versions.</li> </ul> </li> <li>Following the Grace Period:<ul> <li>Ensure the upgrade process is seamless and devoid of critical issues, leveraging the backward compatibility strengths of newer Python versions.</li> <li>Address any bugs discovered during the upgrade process.</li> <li>Update <code>pyproject.toml</code> accordingly. Pull requests updating our supported versions should be clearly marked with the <code>[DEPENDENCIES]</code> tag and <code>python_version_update</code> label for straightforward tracking.</li> </ul> </li> </ol>"},{"location":"dev_guides/dependency_compatibility_policy.html#pythons-development-cycle","title":"Python's Development Cycle:","text":"<p>A comprehensive summary of Python's development cycle is available on the Python Developer's Guide. This includes a chart outlining the full release cycle up to 2029:</p> <p></p> <p>As it stands, support for Python 3.9 will officially end in October of 2025. Following an initial grace period of around six months, we will then look to phase out support.</p> <p>We will look to regularly review this page and update Splink's dependencies accordingly.</p>"},{"location":"dev_guides/spark_pipelining_and_caching.html","title":"Spark caching","text":""},{"location":"dev_guides/spark_pipelining_and_caching.html#caching-and-pipelining-in-spark","title":"Caching and pipelining in Spark","text":"<p>This article assumes you've read the general guide to caching and pipelining.</p> <p>In Spark, some additions have to be made to this general pattern because all transformation in Spark are lazy.</p> <p>That is, when we call <code>df = spark.sql(sql)</code>, the <code>df</code> is not immediately computed.</p> <p>Furthermore, even when an action is called, the results aren't automatically persisted by Spark to disk. This differs from other backends, which execute SQL as a <code>create table</code> statement, meaning that the result is automatically saved.</p> <p>This interferes with caching, because Splink assumes that when the the function <code>_execute_sql_against_backend()</code> is called, this will be evaluated greedily (immediately evaluated) AND the results will be saved to the 'database'.</p> <p>Another quirk of Spark is that it chunks work up into tasks. This is relevant for two reasons:</p> <ul> <li>Tasks can suffer from skew, meaning some take longer than others, which can be bad from a performance point of view.</li> <li>The number of tasks and how data is partitioned controls how many files are output when results are saved. Some Splink operations results in a very large number of small files which can take a long time to read and write, relative to the same data stored in fewer files.</li> </ul> <p>Repartitioning can be used to rebalance workloads (reduce skew) and to avoid the 'many small files' problem.</p>"},{"location":"dev_guides/spark_pipelining_and_caching.html#spark-specific-modifications","title":"Spark-specific modifications","text":"<p>The logic for Spark is captured in the implementation of <code>_execute_sql_against_backend()</code> in the spark_linker.py.</p> <p>This has three roles:</p> <ul> <li>It determines how to save result - using either <code>persist</code>, <code>checkpoint</code> or saving to <code>.parquet</code>, with <code>.parquet</code> being the default.</li> <li>It determines which results to save. Some small results such <code>__splink__m_u_counts</code> are immediately converted using <code>toPandas()</code> rather than being saved. This is because saving to disk and reloading is expensive and unnecessary.</li> <li>It chooses which Spark dataframes to repartition to reduce the number of files which are written/read</li> </ul> <p>Note that repartitioning and saving is independent. Some dataframes are saved without repartitioning. Some dataframes are repartitioned without being saved.</p>"},{"location":"dev_guides/transpilation.html","title":"Transpilation using sqlglot","text":""},{"location":"dev_guides/transpilation.html#sql-transpilation-in-splink-and-how-we-support-multiple-sql-backends","title":"SQL Transpilation in Splink, and how we support multiple SQL backends","text":"<p>In Splink, all the core data linking algorithms are implemented in SQL. This allows computation to be offloaded to a SQL backend of the users choice.</p> <p>One difficulty with this paradigm is that SQL implementations differ - the functions available in (say) the Spark dialect of SQL differ from those available in DuckDB SQL. And to make matters worse, functions with the same name may behave differently (e.g. different arguments, arguments in different orders, etc.).</p> <p>Splink therefore needs a mechanism of writing SQL statements that are able to run against all the target SQL backends (engines).</p> <p>Details are as follows:</p>"},{"location":"dev_guides/transpilation.html#1-core-data-linking-algorithms-are-splink","title":"1. Core data linking algorithms are Splink","text":"<p>Core data linking algorithms are implemented in 'backend agnostic' SQL. So they're written using basic SQL functions that are common across the available in all the target backends, and don't need any translation.</p> <p>It has been possible to write all of the core Splink logic in SQL that is consistent between dialects.</p> <p>However, this is not the case with <code>Comparisons</code>, which tend to use backend specific SQL functions like <code>jaro_winker</code>, whose function names and signatures differ between backends.</p>"},{"location":"dev_guides/transpilation.html#2-user-provided-sql-is-interpolated-into-these-dialect-agnostic-sql-statements","title":"2. User-provided SQL is interpolated into these dialect-agnostic SQL statements","text":"<p>The user provides custom SQL is two places in Splink:</p> <ol> <li>Blocking rules</li> <li>The <code>sql_condition</code> (see here) provided as part of a <code>Comparison</code></li> </ol> <p>The user is free to write this SQL however they want.</p> <p>It's up to the user to ensure the SQL they provide will execute successfully in their chosen backend. So the <code>sql_condition</code> must use functions that exist in the target execution engine</p>"},{"location":"dev_guides/transpilation.html#3-backends-can-implement-transpilation-and-or-dialect-steps-to-further-transform-the-sql-if-needed","title":"3. Backends can implement transpilation and or dialect steps to further transform the SQL if needed","text":"<p>Occasionally some modifications are needed to the SQL to ensure it executes against the target backend.</p> <p><code>sqlglot</code> is used for this purpose. For instance, a custom dialect is implemented in the Spark linker.</p> <p>A transformer is implemented in the Athena linker.</p>"},{"location":"dev_guides/udfs.html","title":"User-Defined Functions","text":""},{"location":"dev_guides/udfs.html#user-defined-functions","title":"User Defined Functions","text":"<p>User Defined Functions (UDFs) are functions that can be created to add functionality to a given SQL backend that does not already exist. These are particularly useful within Splink as it supports multiple SQL engines each with different inherent functionality. UDFs are an important tool for creating consistent functionality across backends.</p> <p>For example, DuckDB has an in-built string comparison function for Jaccard similarity whereas Spark SQL doesn't have an equivalent function. Therefore, a UDF is required to use functions like <code>JaccardAtThresholds()</code> and <code>JaccardLevel()</code> with a Spark backend.</p>"},{"location":"dev_guides/udfs.html#spark","title":"Spark","text":"<p>Spark supports UDFs written in Scala and Java.</p> <p>Splink currently uses UDFs written in Scala and are implemented as follows:</p> <ul> <li>The UDFs are created in a separate repository, <code>splink_scalaudfs</code>, with the Scala functions being defined in <code>Similarity.scala</code>.</li> <li>The functions are then stored in a Java Archive (JAR) file - for more on JAR files, see the Java documentation.</li> <li>Once the JAR file containing the UDFs has been created, it is copied across to the spark_jars folder in Splink.</li> <li>Specify the the correct jar location within Splink.</li> <li>UDFS are then registered within the Spark Linker.</li> </ul> <p>Now the Spark UDFs have been successfully registered, they can be used in Spark SQL. For example,</p> <pre><code>jaccard(\"name_column_1\", \"name_column_2\") &gt;= 0.9\n</code></pre> <p>which provides the basis for functions such as <code>JaccardAtThresholds()</code> and <code>JaccardLevel()</code>.</p>"},{"location":"dev_guides/udfs.html#duckdb","title":"DuckDB","text":"<p>Python UDFs can be registered to a DuckDB connection from version 0.8.0 onwards.</p> <p>The documentation is here, an examples are here.  Note that these functions should be registered against the DuckDB connection provided to the linker using <code>connection.create_function</code>.</p> <p>Note that performance will generally be substantially slower than using native DuckDB functions.  Consider using vectorised UDFs were possible - see here.</p>"},{"location":"dev_guides/udfs.html#athena","title":"Athena","text":"<p>Athena supports UDFs written in Java, however these have not yet been implemented in Splink.</p>"},{"location":"dev_guides/udfs.html#sqlite","title":"SQLite","text":"<p>Python UDFs can be registered to a SQLite connection using the <code>create_function</code> function.  An example is as follows:</p> <pre><code>from rapidfuzz.distance.Levenshtein import distance\nconn = sqlite3.connect(\":memory:\")\nconn.create_function(\"levenshtein\", 2, distance)\n</code></pre> <p>The function <code>levenshtein</code> is now available to use as a Python function</p>"},{"location":"dev_guides/changing_splink/blog_posts.html","title":"Contributing to the Splink Blog","text":""},{"location":"dev_guides/changing_splink/blog_posts.html#contributing-to-the-splink-blog","title":"Contributing to the Splink Blog","text":"<p>Thanks for considering making a contribution to the Splink Blog! We are keen to use this blog as a forum all things data linking and Splink!</p> <p>This blog, and the docs as a whole, are built using the fantastic MkDocs material, to understand more about how the blog works under the hood checkout out the MkDocs material blog documentation.</p> <p>For more general guidance for contributing to Splink, check out our Contributor Guide.</p>"},{"location":"dev_guides/changing_splink/blog_posts.html#adding-a-blog-post","title":"Adding a blog post","text":"<p>The easiest way to get started with a blog post is to make a copy of one of the pre-existing blog posts and make edits from there. There is a metadata in the section at the top of each post which should be updated with the post date, authors and the category of the post (this is a tag system to make posts easier to find).</p> <p>Blog posts are ordered by date, so change the name of your post markdown file to be a recent date (YYYY-MM-DD format) to make sure it appears at the top of the blog.</p> <p>Note</p> <p>In this blog we want to make content as easily digestible as possible. We encourage breaking up and big blocks of text into sections and using visuals/emojis/gifs to bring your post to life!</p>"},{"location":"dev_guides/changing_splink/blog_posts.html#adding-a-new-author-to-the-blogs","title":"Adding a new author to the blogs","text":"<p>If you are a new author, you will need to add yourself to the .authors.yml file.</p>"},{"location":"dev_guides/changing_splink/blog_posts.html#testing-your-changes","title":"Testing your changes","text":"<p>Once you have made a first draft, check out how the deployed blog will look by building the docs locally.</p>"},{"location":"dev_guides/changing_splink/contributing_to_docs.html","title":"Contributing to Documentation","text":""},{"location":"dev_guides/changing_splink/contributing_to_docs.html#building-docs-locally","title":"Building docs locally","text":"<p>Before building the docs locally, you will need to follow the development quickstart to set up the necessary environment. You cannot skip this step, because some Splink docs Markdown is auto-generated using the Splink development environment.</p> <p>Once you've done that, to rapidly build the documentation and immediately see changes you've made you can use this script outside your Poetry virtual environment:</p> <pre><code>source scripts/make_docs_locally.sh\n</code></pre> <p>This is much faster than waiting for GitHub actions to run if you're trying to make fiddly changes to formatting etc.</p> <p>Once you've finished updating Splink documentation we ask that you run our spellchecker. Instructions on how to do this are given below.</p>"},{"location":"dev_guides/changing_splink/contributing_to_docs.html#quick-builds-for-rapidly-authoring-new-content","title":"Quick builds for rapidly authoring new content","text":"<p>When you <code>mkdocs serve -v --dirtyreload</code> or <code>mkdocs build</code> the documentation, the <code>mkdocs</code> command will rebuild the entire site. This can be slow if you're just making small changes to a single page.</p> <p>To speed up the process, you can temporarily tell <code>mkdocs</code> to ignore content by modifying <code>mkdocs.yml</code>, for example by adding:</p> <pre><code>exclude_docs: |\n  dev_guides/**\n  charts/**\n  topic_guides/**\n  demos/**\n  blog/**\n</code></pre>"},{"location":"dev_guides/changing_splink/contributing_to_docs.html#spellchecking-docs","title":"Spellchecking docs","text":"<p>When updating Splink documentation, we ask that you run our spellchecker before submitting a pull request. This is to help ensure quality and consistency across the documentation. If for whatever reason you can't run the spellchecker on your system, please don't let this prevent you from contributing to the documentation. Please note, the spellchecker only works on markdown files.</p> <p>If you are a Mac user with the <code>Homebrew</code> package manager installed, the script below will automatically install the required system dependency, <code>aspell</code>. If you've created your development environment using conda, <code>aspell</code> will have been installed as part of that process. Instructions for installing <code>aspell</code> through other means may be added here in the future.</p> <p>To run the spellchecker on either a single markdown file or folder of markdown files, you can run the following bash script:</p> <pre><code>./scripts/pyspelling/spellchecker.sh &lt;path_to_file_or_folder&gt;\n</code></pre> <p>Omitting the file/folder path will run the spellchecker on all markdown files contained in the <code>docs</code> folder. We recommend running the spellchecker only on files that you have created or edited.</p> <p>The spellchecker uses the Python package PySpelling and its underlying spellchecking tool, Aspell. Running the above script will automatically install these packages along with any other necessary dependencies.</p> <p>The spellchecker compares words to a standard British English dictionary and a custom dictionary (<code>scripts/pyspelling/custom_dictionary.txt</code>) of words. If no spelling mistakes are found, you will see the following terminal printout:</p> <pre><code>Spelling check passed :)\n</code></pre> <p>otherwise, PySpelling will printout the spelling mistakes found in each file.</p> <p>Correct spellings of words not found in a standard dictionary (e.g. \"Splink\") can be recorded as such by adding them to <code>scripts/pyspelling/custom_dictionary.txt</code>.</p> <p>Please correct any mistakes found or update the custom dictionary to ensure the spellchecker passes before putting in a pull request containing updates to the documentation.</p> <p>Note</p> <p>The spellchecker is configured (via <code>pyspelling.yml</code>) to ignore text between certain delimiters to minimise picking up Splink/programming-specific terms. If there are additional patterns that you think should be excepted then please let us know in your pull request.</p> <p>The custom dictionary deliberately contains a small number of misspelled words (e.g. \u201cSiohban\u201d). These are sometimes necessary where we are explaining how Splink handles typos in data records.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html","title":"Development Quickstart","text":"<p>Splink is a complex project with many dependencies. This page provides step-by-step instructions for getting set up to develop Splink. Once you have followed these instructions, you should be all set to start making changes.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-0-unix-like-operating-system","title":"Step 0: Unix-like operating system","text":"<p>We highly recommend developing Splink on a Unix-like operating system, such as MacOS or Linux. While it is possible to develop on another operating system such as Windows, we do not provide instructions for how to do so.</p> <p>Luckily, Windows users can easily fulfil this requirement by installing the Windows Subsystem for Linux (WSL):</p> <ul> <li>Open PowerShell as Administrator: Right-click the Start button, select \u201cWindows Terminal (Admin)\u201d, and ensure PowerShell is the selected shell.</li> <li>Run the command <code>wsl --install</code>.</li> <li>You can find more guidance on setting up WSL on the Microsoft website   but you don't need to do anything additional.</li> <li>Open the Windows Terminal again (does not need to be Admin) and select the Ubuntu shell.   Follow the rest of these instructions in that shell.</li> </ul>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-1-clone-splink","title":"Step 1: Clone Splink","text":"<p>If you haven't already, create a fork of the Splink repository. You can find the Splink repository here, or click here to go directly to making a fork. Clone your fork to whatever directory you want to work in with <code>git clone https://github.com/&lt;YOUR_USERNAME&gt;/splink.git</code>.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-2-choose-how-to-install-system-dependencies","title":"Step 2: Choose how to install system dependencies","text":"<p>Developing Splink requires Python, as well as uv (the package manager we use to install Python package dependencies). Python can be installed using uv, so does not need to be installed independently (although it can be). Running Spark or PostgreSQL on your computer to test those backends requires additional dependencies. Athena only runs in the AWS cloud, so to locally run the tests for that backend you will need to create an AWS account and configure Splink to use it.</p> <p>There are two ways to install these system dependencies: globally on your computer, or in an isolated conda environment.</p> <p>The decision of which approach to take is subjective.</p> <p>If you already have uv installed (plus Java and PostgreSQL if you want to run the Spark and PostgreSQL backends locally), there is probably little advantage to using <code>conda</code>.</p> <p>On the other hand, <code>conda</code> is particularly suitable if:</p> <ul> <li>You're already a <code>conda</code> user, and/or</li> <li>You're working in an environment where security policies prevent the installation of system level packages like Java</li> <li>You don't want to do global installs of some of the requirements like Java</li> </ul>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-3-manual-install-option-install-system-dependencies","title":"Step 3, Manual install option: Install system dependencies","text":""},{"location":"dev_guides/changing_splink/development_quickstart.html#uv","title":"uv","text":"<p>To install uv follow the installation guide in their docs.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#python","title":"Python","text":"<p>Once uv is installed, Python can be installed using uv, as outlined in the uv page on installing python.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#java","title":"Java","text":"<p>The instructions to install Java globally depend on your operating system. Generally, some version of Java will be available from your operating system's package manager. Note that you must install a version of Java earlier than Java 18 because Splink currently uses an older version of Spark.</p> <p>As an example, you could run this on Ubuntu:</p> <pre><code>sudo apt install openjdk-11-jre-headless\n</code></pre>"},{"location":"dev_guides/changing_splink/development_quickstart.html#postgresql-optional","title":"PostgreSQL (optional)","text":"<p>Follow the instructions on the PostgreSQL website to install it on your computer.</p> <p>Then, we will need to set up a database for Splink. You can achieve that with the following commands:</p> <pre><code>initdb splink_db\npg_ctl -D splink_db start --wait -l ./splink_db_log\ncreatedb splink_db # The inner database\npsql -d splink_db &lt;&lt;SQL\n  CREATE USER splinkognito CREATEDB CREATEROLE password 'splink123!' ;\nSQL\n</code></pre> <p>Most of these commands are one-time setup, but the <code>pg_ctl -D splink_db start --wait -l ./splink_db_log</code> command will need to be run each time you want to start PostgreSQL (after rebooting, for example).</p> <p>Alternatively, you can run PostgreSQL using Docker. First, install Docker Desktop.</p> <p>Then run the setup script (a thin wrapper around <code>docker-compose</code>) each time you want to start your PostgreSQL server:</p> <pre><code>./scripts/postgres_docker/setup.sh\n</code></pre> <p>and the teardown script each time you want to stop it:</p> <pre><code>./scripts/postgres_docker/teardown.sh\n</code></pre> <p>Included in the docker-compose file is a pgAdmin container to allow easy exploration of the database as you work, which can be accessed in-browser on the default port. The default username is <code>a@b.com</code> with password <code>b</code>.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-3-conda-install-option-install-system-dependencies","title":"Step 3, Conda install option: Install system dependencies","text":"<p>These instructions are the same no matter what operating system you are using. As an added benefit, these installations will be specific to the conda environment you create for Splink, so they will not interfere with other projects.</p> <p>For convenience, we have created an automatic installation script that will install all dependencies for you. It will create an isolated conda environment called <code>splink</code>.</p> <p>From the directory where you have cloned the Splink repository, simply run:</p> <pre><code>./scripts/conda/development_setup_with_conda.sh\n</code></pre> <p>If you use a shell besides bash, add the <code>mamba</code> CLI to your PATH by running <code>~/miniforge3/bin/mamba init &lt;your_shell&gt;</code> -- e.g. <code>~/miniforge3/bin/mamba init zsh</code> for zsh.</p> <p>If you've run this successfully, restart your terminal and skip to the \"Step 5: Activating your environment(s)\" section.</p> <p>If you would prefer to manually go through the steps to have a better understanding of what you are installing, continue to the next section.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#install-conda-itself","title":"Install Conda itself","text":"<p>First, we need to install a conda CLI. Any will do, but we recommend Miniforge, which can be installed like so:</p> <pre><code>curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh -b\n</code></pre> <p>Miniforge is great because it defaults to the community-curated conda-forge channel, and it installs the <code>mamba</code> CLI by default, which is generally faster than the <code>conda</code> CLI.</p> <p>Before you'll be able to run the <code>mamba</code> command, you need to run <code>~/miniforge3/bin/mamba init</code> for your shell -- e.g. <code>~/miniforge3/bin/mamba init</code> for Bash or <code>~/miniforge3/bin/mamba init zsh</code> for zsh.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#install-conda-packages","title":"Install Conda packages","text":"<p>The rest is easy, because all the other dependencies can be installed as conda packages. Simply run:</p> <pre><code>mamba env create -n splink --file ./scripts/conda/development_environment.yaml\n</code></pre> <p>Now run <code>mamba activate splink</code> to enter your newly created conda environment -- you will need to do this again each time you open a new terminal. Run the rest of the steps in this guide inside this environment. <code>mamba deactivate</code> leaves the environment.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-4-python-package-dependencies","title":"Step 4: Python package dependencies","text":"<p>Splink manages the other Python packages it depends on using uv. Simply run <code>uv sync</code> in the Splink directory to install them. You can find more options for this command (such as how to install optional dependencies) on the managing dependencies with uv page.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-5-activating-your-environments","title":"Step 5: Activating your environment(s)","text":"<p>Depending on the options you chose in this document, you now have either:</p> <ul> <li>Only a uv virtual environment.</li> <li>Both a conda environment and a uv virtual environment.</li> </ul> <p>If you did use conda, then each time you open a terminal to develop Splink, after navigating to the repository directory, run <code>mamba activate splink</code>.</p> <p>In either case, relevant python commands (such as running tests, scripts, or using the REPL) can now be run using <code>uv run ...</code>.</p>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-6-checking-that-it-worked","title":"Step 6: Checking that it worked","text":"<p>If you have installed all the dependencies, including PostgreSQL, you should be able to run the following command without error (will take about 10 minutes):</p> <pre><code>uv run pytest tests/\n</code></pre> <p>This runs all the Splink tests across the default DuckDB and Spark backends.</p> <p>For a quicker, but less comprehensive check, try testing that you can import Splink without error:</p> <pre><code>uv run python -c \"import splink\"\n</code></pre>"},{"location":"dev_guides/changing_splink/development_quickstart.html#step-7-visual-studio-code-optional","title":"Step 7: Visual Studio Code (optional)","text":"<p>You're now all set to develop Splink. If you have a text editor/IDE you are comfortable with for working on Python packages, you can use that. If you don't, we recommend Visual Studio Code. Here are some tips on how to get started:</p> <ul> <li>Install Visual Studio Code</li> <li>If you are using WSL on Windows, install the WSL extension.   You will want to do all development inside a WSL \"remote.\"</li> <li>Install the Python extension.</li> <li>Use the Python extension's pytest functionality to run the tests within your IDE.</li> <li>Use the interactive window to run code snippets.</li> </ul>"},{"location":"dev_guides/changing_splink/lint_and_format.html","title":"Linting and Formatting","text":""},{"location":"dev_guides/changing_splink/lint_and_format.html#linting-your-code","title":"Linting your code","text":"<p>We use ruff for linting and formatting.</p> <p>To quickly run both the linter and formatter, you can source the linting bash script (shown below). The -f flag can be called to run automatic fixes with ruff. If you simply wish for ruff to print the errors it finds to the console, remove this flag.</p> <pre><code>uv run ruff format\nuv run ruff check .\n</code></pre>"},{"location":"dev_guides/changing_splink/lint_and_format.html#additional-rules","title":"Additional Rules","text":"<p><code>ruff</code> contains an extensive arsenal of linting rules and techniques that can be applied.</p> <p>If you wish to add an addition rule, do so in the <code>pyproject.toml</code> file in the root of the project.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html","title":"Managing Environment and Dependencies","text":"<p>Splink utilises <code>uv</code> for managing its core dependencies, offering a clean and effective solution for tracking and resolving any ensuing package and version conflicts.</p> <p>You can find a list of Splink's core dependencies within the pyproject.toml file.</p> <p>A comprehensive list of uv commands is available in the uv documentation.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#fundamental-commands-in-uv","title":"Fundamental Commands in uv","text":"<p>Below are some useful commands to help in the maintenance and upkeep of the pyproject.toml file.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#adding-packages","title":"Adding Packages","text":"<p>To incorporate a new package into Splink: </p><pre><code>uv add &lt;package-name&gt;\n</code></pre> <p>To specify a version when adding a new package: </p><pre><code>uv add &lt;package-name&gt;==&lt;version&gt;\n# Add quotes if you want to use other equality calls\nuv add \"&lt;package-name&gt; &gt;= &lt;version&gt;\"\n</code></pre> <p>For non-dev dependencies, you should generally only use the <code>&gt;=</code> form so as not to be overly restrictive for users.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#modifying-packages","title":"Modifying Packages","text":"<p>To remove a package from the project:</p> <pre><code>uv remove &lt;package-name&gt;\n</code></pre> <p>Updating an existing package to a specific version:</p> <pre><code>uv add &lt;package-name&gt;==&lt;version&gt;\nuv add \"&lt;package-name&gt; &gt;= &lt;version&gt;\"\n</code></pre> <p>To update an existing package to the latest version leave out the version specification:</p> <pre><code>uv add &lt;package-name&gt;\n</code></pre> <p>Note: Direct updates can also be performed within the pyproject.toml file.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#locking-the-project","title":"Locking the Project","text":"<p>To update the existing <code>uv.lock</code> file, thereby locking the project to ensure consistent dependency installation across different environments:</p> <pre><code>uv lock\n</code></pre>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#installing-dependencies","title":"Installing Dependencies","text":"<p>To install project dependencies as per the lock file:</p> <pre><code>uv sync\n</code></pre> <p>For optional dependencies, additional flags are required. For instance, to install dependencies along with Spark support:</p> <pre><code>uv sync --extra spark\n</code></pre> <p>To install everything:</p> <pre><code>uv sync --group dev --group linting --group testing --group typechecking --group docs --all-extras\n</code></pre> <p>See pyproject.toml for details of dependency groups and available extras.</p>"},{"location":"dev_guides/changing_splink/managing_dependencies_with_uv.html#running-commands","title":"Running commands","text":"<p>You can run commands from your shell with <code>uv run</code>, e.g.</p> <pre><code>uv run pytest tests\n</code></pre> <p>You can specify a python version with <code>--python</code> or <code>-p</code>:</p> <pre><code>uv run -p 3.12 pytest tests\n</code></pre> <p>When using <code>uv run</code>, <code>uv</code> will automatically sync your project before running the command.</p>"},{"location":"dev_guides/changing_splink/releases.html","title":"Releasing a Package Version","text":""},{"location":"dev_guides/changing_splink/releases.html#releasing-a-new-version-of-splink","title":"Releasing a new version of Splink","text":"<p>Splink is regularly updated with releases to add new features or bug fixes to the package.</p> <p>Below are the steps for releasing a new version of Splink:</p> <ol> <li>On a new branch, update pyproject.toml and init.py with the latest version.</li> <li>Update CHANGELOG.md. This consists of adding a heading for the new release below the 'Unreleased' heading, with the new version and date. Additionally the links at the bottom of the file for 'unreleased' and the new version should be updated.</li> <li>Open a pull request to merge the new branch with the master branch (the base branch).</li> <li> <p>Once the pull request has been approved, merge the changes and generate a new release in the releases section of the repo, including:</p> </li> <li> <p>Choosing a new release tag (which matches your updates to pyproject.toml and init.py). Ensure that your release tag follows semantic versioning. The target branch should be set to master.</p> </li> </ol> <p>)</p> <ul> <li>Generating release notes. This can be done automatically by pressing the   button. </li> </ul> <p>This will give you release notes based off the Pull Requests which have been merged since the last release.</p> <p>For example </p> <ul> <li>Publish as the latest release</li> </ul> <p></p> <p>Now your release should be published to PyPI.</p>"},{"location":"dev_guides/changing_splink/testing.html","title":"Testing","text":"","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#testing-in-splink","title":"Testing in Splink","text":"<p>Tests in Splink make use of the pytest framework. You can find the tests themselves in the tests folder.</p> <p>Splink tests can be broadly categorised into three sets:</p> <ul> <li>'Core' tests - these are tests which test some specific bit of functionality which does not depend on any specific SQL dialect. They are usually unit tests - examples are testing <code>InputColumn</code> and testing the latitude-longitude distance calculation.</li> <li>Backend-agnostic tests - these are tests which run against some SQL backend, but which are written in such a way that they can run against many backends by making use of the backend-agnostic testing framework. The majority of tests are of this type.</li> <li>Backend-specific tests - these are tests which run against a specific SQL backend, and test some feature particular to this backend. There are not many of these, as Splink is designed to run very similarly independent of the backend used.</li> </ul>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#running-tests","title":"Running tests","text":"","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#running-tests-locally","title":"Running tests locally","text":"<p>To run tests locally against duckdb only (the default) run: </p><pre><code>uv run pytest tests/\n</code></pre> <p>To run a single test file, append the filename to the <code>tests/</code> folder call, for example:</p> <pre><code>uv run pytest tests/test_u_train.py\n</code></pre> <p>or for a single test, additionally append the test name after a pair of colons, as:</p> <pre><code>uv run pytest tests/test_u_train.py::test_u_train_multilink\n</code></pre> Further useful pytest options <p>There may be many warnings emitted, for instance by library dependencies, cluttering your output in which case you can use <code>--disable-pytest-warnings</code> or <code>-W ignore</code> so that these will not be displayed. Some additional command-line options that may be useful:</p> <ul> <li><code>-s</code> to disable output capture, so that test output is displayed in the terminal in all cases</li> <li><code>-v</code> for verbose mode, where each test instance will be displayed on a separate line with status</li> <li><code>-q</code> for quiet mode, where output is extremely minimal</li> <li><code>-x</code> to fail on first error/failure rather than continuing to run all selected tests     *</li> <li><code>-m some_mark</code> run only those tests marked with <code>some_mark</code> - see below for useful options here</li> </ul> <p>For instance usage might be: </p><pre><code># ignore warnings, display output\npytest -W ignore -s tests/\n</code></pre> <p>or </p><pre><code># ignore warnings, verbose output, fail on first error/failure\npytest -W ignore -v -x tests/\n</code></pre> <p>You can find a host of other available options using pytest's in-built help: </p><pre><code>pytest -h\n</code></pre>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#running-tests-for-specific-backends-or-backend-groups","title":"Running tests for specific backends or backend groups","text":"<p>You may wish to run tests relating to to specific backends, tests which are backend-independent, or any combinations of these. Splink allows for various combinations by making use of <code>pytest</code>'s <code>mark</code> feature.</p> <p>If when you invoke pytest you pass no marks explicitly, there will be an implicit mark of <code>default</code>, as per the pyproject.toml pytest.ini configuration, and see also the decorator.py file.</p> <p>The available options are:</p>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#run-core-tests","title":"Run core tests","text":"<p>Option for running only the backend-independent 'core' tests:</p> <ul> <li><code>uv run pytest tests/ -m core</code> - run only the 'core' tests, meaning those without dialect-dependence. In practice this means any test that hasn't been decorated using <code>mark_with_dialects_excluding</code> or <code>mark_with_dialects_including</code>.</li> </ul>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#run-tests-on-a-specific-backend","title":"Run tests on a specific backend","text":"<p>Options for running tests on one backend only - this includes tests written specifically for that backend, as well as backend-agnostic tests supported for that backend.</p> <ul> <li><code>uv run pytest tests/ -m duckdb</code> - run all <code>duckdb</code> tests, and all <code>core</code> tests<ul> <li>&amp; similarly for other dialects</li> </ul> </li> <li><code>uv run pytest tests/ -m duckdb_only</code> - run all <code>duckdb</code> tests only, and not the <code>core</code> tests<ul> <li>&amp; similarly for other dialects</li> </ul> </li> </ul>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#run-tests-across-multiple-backends","title":"Run tests across multiple backends","text":"<p>Options for running tests on multiple backends (including all backends) - this includes tests written specifically for those backends, as well as backend-agnostic tests supported for those backends.</p> <ul> <li><code>pytest tests/ -m default</code> or equivalently <code>pytest tests/</code> - run all tests in the <code>default</code> group. The <code>default</code> group consists of the <code>core</code> tests, and those dialects in the <code>default</code> group - currently <code>spark</code> and <code>duckdb</code>.<ul> <li>Other groups of dialects can be added and will similarly run with <code>pytest tests/ -m new_dialect_group</code>. Dialects within the current scope of testing and the groups they belong to are defined in the <code>dialect_groups</code> dictionary in tests/decorator.py</li> </ul> </li> <li><code>pytest tests/ -m all</code> run all tests for all available dialects</li> </ul> <p>These all work alongside all the other pytest options, so for instance to run the tests for training <code>probability_two_random_records_match</code> for only <code>duckdb</code>, ignoring warnings, with quiet output, and exiting on the first failure/error: </p><pre><code>pytest -W ignore -q -x -m duckdb tests/test_estimate_prob_two_rr_match.py\n</code></pre> Running tests against a specific version of Python <p>Testing Splink against a specific version of Python, especially newer versions not included in our GitHub Actions, is vital for identifying compatibility issues early and reviewing errors reported by users.</p> <p>If you're a conda user, you can create a isolated environment according to the instructions in the development quickstart.</p> <p>Another method is to utilise docker \ud83d\udc33.</p> <p>A pre-built Dockerfile for running tests against python version 3.9.10 can be located within scripts/run_tests.Dockerfile.</p> <p>To run, simply use the following docker command from within a terminal and the root folder of a Splink clone: </p><pre><code>docker build -t run_tests:testing -f scripts/run_tests.Dockerfile . &amp;&amp; docker run --rm --name splink-test run_tests:testing\n</code></pre> <p>This will both build and run the tests library.</p> <p>Feel free to replace <code>run_tests:testing</code> with an image name and tag you're happy with.</p> <p>Reusing the same image and tag will overwrite your existing image.</p> <p>You can also overwrite the default <code>CMD</code> if you want a different set of <code>pytest</code> command-line options, for example </p><pre><code>docker run --rm --name splink-test run_tests:testing pytest -W ignore -m spark tests/test_u_train.py\n</code></pre>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#running-with-a-pre-existing-postgres-database","title":"Running with a pre-existing Postgres database","text":"<p>If you have a pre-existing Postgres server you wish to use to run the tests against, you will need to specify environment variables for the credentials where they differ from default (in parentheses):</p> <ul> <li><code>SPLINKTEST_PG_USER</code> (<code>splinkognito</code>)</li> <li><code>SPLINKTEST_PG_PASSWORD</code> (<code>splink123!</code>)</li> <li><code>SPLINKTEST_PG_HOST</code> (<code>localhost</code>)</li> <li><code>SPLINKTEST_PG_PORT</code> (<code>5432</code>)</li> <li><code>SPLINKTEST_PG_DB</code> (<code>splink_db</code>) - tests will not actually run against this, but it is from a connection to this that the temporary test database + user will be created</li> </ul> <p>While care has been taken to ensure that tests are run using minimal permissions, and are cleaned up after, it is probably wise to run tests connected to a non-important database, in case anything goes wrong. In addition to the standard privileges for Splink usage, in order to run the tests you will need:</p> <ul> <li><code>CREATE DATABASE</code> to create a temporary testing database</li> <li><code>CREATEROLE</code> to create a temporary user role with limited privileges, which will be actually used for all the SQL execution in the tests</li> </ul>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#tests-in-ci","title":"Tests in CI","text":"<p>Splink utilises GitHub actions to run tests for each pull request. This consists of a few independent checks:</p> <ul> <li>The full test suite is run separately against several different python versions</li> <li>The example notebooks are checked to ensure they run without error</li> <li>The tutorial notebooks are checked to ensure they run without error</li> </ul>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#writing-tests","title":"Writing tests","text":"","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#core-tests","title":"Core tests","text":"<p>Core tests are treated the same way as ordinary pytest tests. Any test is marked as <code>core</code> by default, and will only be excluded from being a core test if it is decorated using either:</p> <ul> <li><code>@mark_with_dialects_excluding</code> for backend-agnostic tests, or</li> <li><code>@mark_with_dialects_including</code> for backend-specific tests</li> </ul> <p>from the test decorator file.</p>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#backend-agnostic-testing","title":"Backend-agnostic testing","text":"<p>The majority of tests should be written using the backend-agnostic testing framework. This just provides some small tools which allow tests to be written in a backend-independent way. This means the tests can then by run against all available SQL backends (or a subset, if some lack necessary features for the test).</p> <p>As an example, let's consider a test that will run on all dialects, and then break down the various parts to see what each is doing.</p> <pre><code>from tests.decorator import mark_with_dialects_excluding\n\n@mark_with_dialects_excluding()\ndef test_feature_that_works_for_all_backends(test_helpers, dialect, some_other_test_fixture):\n    helper = test_helpers[dialect]\n\n    df = helper.load_frame_from_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\")\n    settings = SettingsCreator(\n        link_type=\"dedupe_only\",\n        comparisons=[\n            cl.ExactMatch(\"first_name\"),\n            cl.ExactMatch(\"surname\"),\n        ],\n        blocking_rules_to_generate_predictions=[\n            block_on(\"first_name\"),\n        ],\n    )\n    linker = helper.Linker(\n        df,\n        settings,\n        **helper.extra_linker_args(),\n    )\n\n\n    # and then some actual testing logic\n</code></pre> <p>Firstly you should import the decorator-factory <code>mark_with_dialects_excluding</code>, which will decorate each test function:</p> <pre><code>from tests.decorator import mark_with_dialects_excluding\n</code></pre> <p>Then we define the function, and pass parameters:</p> <pre><code>@mark_with_dialects_excluding()\ndef test_feature_that_works_for_all_backends(test_helpers, dialect, some_other_test_fixture):\n</code></pre> <p>The decorator <code>@mark_with_dialects_excluding()</code> will do two things:</p> <ul> <li>marks the test it decorates with the appropriate custom <code>pytest</code> marks. This ensures that it will be run with tests for each dialect, excluding any that are passed as arguments; in this case it will be run for all dialects, as we have passed no arguments.</li> <li>parameterises the test with a string parameter <code>dialect</code>, which will be used to configure the test for that dialect. The test will run for each value of <code>dialect</code> possible, excluding any passed to the decorator (none in this case).</li> </ul> <p>You should aim to exclude as few dialects as possible - consider if you really need to exclude any. Dialects should only be excluded if the test doesn't make sense for them due to features they lack. The default choice should be the decorator with no arguments <code>@mark_with_dialects_excluding()</code>, meaning the test runs for all dialects.</p> <pre><code>@mark_with_dialects_excluding()\ndef test_feature_that_works_for_all_backends(test_helpers, dialect, some_other_test_fixture):\n</code></pre> <p>As well as the parameter <code>dialect</code> (which is provided by the decorator), we must also pass the helper-factory fixture <code>test_helpers</code>. We can additionally pass further fixtures if needed - in this case <code>some_other_test_fixture</code>. We could similarly provide an explicit parameterisation to the test, in which case we would also pass these parameters - see the pytest docs on parameterisation for more information.</p> <pre><code>    helper = test_helpers[dialect]\n</code></pre> <p>The fixture <code>test_helpers</code> is simply a dictionary of the specific-dialect test helpers - here we pick the appropriate one for our test.</p> <p>Each helper has the same set of methods and properties, which encapsulate all of the dialect-dependencies. You can find the full set of properties and methods by examining the source for the base class <code>TestHelper</code>.</p> <pre><code>    df = helper.load_frame_from_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\")\n</code></pre> <p>Here we are now actually using a method of the test helper - in this case we are loading a table from a csv to the database and returning it in a form suitable for passing to a Splink linker.</p> <p>Finally we instantiate the linker, passing any default set of extra arguments provided by the helper, which some dialects require. </p><pre><code>    linker = helper.Linker(df, settings_dict, **helper.extra_linker_args())\n</code></pre> <p>From this point onwards we will be working with the instantiated <code>linker</code>, and so will not need to refer to <code>helper</code> any more - the rest of the test can be written as usual.</p>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#excluding-some-backends","title":"Excluding some backends","text":"<p>Now let's consider an example in which we wanted to test a <code>ComparisonLevel</code> that included the <code>split_part</code> function which does not exist in the <code>sqlite</code> dialect. We assume that this particular comparison level is crucial for the test to make sense, otherwise we would rewrite this line to make it run universally. When you come to run the tests, this test will not run on the <code>sqlite</code> backend.</p> <pre><code>{\n    \"sql_condition\": \"split_part(email_l, '@', 1) = split_part(email_r, '@', 1)\",\n    \"label_for_charts\": \"email local-part matches\",\n}\n</code></pre> <p>Warning</p> <p>Tests should be made available to the widest range of backends possible. Only exclude backends if features not shared by all backends are crucial to the test-logic - otherwise consider rewriting things so that all backends are covered.</p> <p>We therefore want to exclude <code>sqlite</code> backend, as the test relies on features not directly available for that backend, which we can do as follows:</p> <pre><code>from tests.decorator import mark_with_dialects_excluding\n\n@mark_with_dialects_excluding(\"sqlite\")\ndef test_feature_that_doesnt_work_with_sqlite(test_helpers, dialect, some_other_test_fixture):\n    helper = test_helpers[dialect]\n\n    df = helper.load_frame_from_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\")\n\n    # and then some actual testing logic\n</code></pre> <p>The key difference is the argument we pass to the decorator: </p><pre><code>@mark_with_dialects_excluding(\"sqlite\")\ndef test_feature_that_doesnt_work_with_sqlite(test_helpers, dialect, some_other_test_fixture):\n</code></pre> As above this marks the test it decorates with the appropriate custom <code>pytest</code> marks, but in this case it ensures that it will be run with tests for each dialect excluding <code>sqlite</code>. Again <code>dialect</code> is passed as a parameter, and the test will run in turn for each value of <code>dialect</code> except for <code>sqlite</code>. <p>If you need to exclude multiple dialects this is also possible - just pass each as an argument. For example, to decorate a test that is not supported on <code>spark</code> or <code>sqlite</code>, use the decorator <code>@mark_with_dialects_excluding(\"sqlite\", \"spark\")</code>.</p>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/changing_splink/testing.html#backend-specific-tests","title":"Backend-specific tests","text":"<p>If you intend to write a test for a specific backend, first consider whether it is definitely specific to that backend - if not then a backend-agnostic test would be preferable, as then your test will be run against many backends. If you really do need to test features peculiar to one backend, then you can write it simply as you would an ordinary <code>pytest</code> test. The only difference is that you should decorate it with <code>@mark_with_dialects_including</code> (from tests/decorator.py) - for example:</p>  DuckDB Spark SQLite <pre><code>@mark_with_dialects_including(\"duckdb\")\ndef test_some_specific_duckdb_feature():\n    ...\n</code></pre> <pre><code>@mark_with_dialects_including(\"spark\")\ndef test_some_specific_spark_feature():\n    ...\n</code></pre> <pre><code>@mark_with_dialects_including(\"sqlite\")\ndef test_some_specific_sqlite_feature():\n    ...\n</code></pre> <p>This ensures that the test gets marked appropriately for running when the <code>Spark</code> tests should be run, and excludes it from the set of <code>core</code> tests.</p> <p>Note that unlike the exclusive <code>mark_with_dialects_excluding</code>, this decorator will not parameterise the test with the <code>dialect</code> argument. This is because usage of the inclusive form is largely designed for single-dialect tests. If you wish to override this behaviour and parameterise the test you can use the argument <code>pass_dialect</code>, for example <code>@mark_with_dialects_including(\"spark\", \"sqlite\", pass_dialect=True)</code>, in which case you would need to write the test in a backend-independent manner.</p>","tags":["Testing","Pytest","Backends"]},{"location":"dev_guides/charts/building_charts.html","title":"Building new charts","text":""},{"location":"dev_guides/charts/building_charts.html#building-a-new-chart-in-splink","title":"Building a new chart in Splink","text":"<p>As mentioned in the Understanding Splink Charts topic guide, splink charts are made up of three distinct parts:</p> <ol> <li>A function to create the dataset for the chart </li> <li>A template chart definition (in a json file)</li> <li>A function to read the chart definition, add the data to it, and return the chart itself </li> </ol>"},{"location":"dev_guides/charts/building_charts.html#worked-example","title":"Worked Example","text":"<p>Below is a worked example of how to create a new chart that shows all comparisons levels ordered by match weight:</p> <pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n      cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\"dob\", input_is_string=True),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.LevenshteinAtThresholds(\"email\", 2),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"surname\"),\n    ]\n)\n\nlinker = Linker(df, settings,DuckDBAPI())\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\nfor rule in [block_on(\"first_name\"), block_on(\"dob\")]:\n    linker.training.estimate_parameters_using_expectation_maximisation(rule)\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#generate-data-for-chart","title":"Generate data for chart","text":"<pre><code># Take linker object and extract complete settings dict\nrecords = linker._settings_obj._parameters_as_detailed_records\n\ncols_to_keep = [\n    \"comparison_name\",\n    \"sql_condition\",\n    \"label_for_charts\",\n    \"m_probability\",\n    \"u_probability\",\n    \"bayes_factor\",\n    \"log2_bayes_factor\",\n    \"comparison_vector_value\"\n]\n\n# Keep useful information for a match weights chart\nrecords = [{k: r[k] for k in cols_to_keep}\n           for r in records\n           if r[\"comparison_vector_value\"] != -1 and r[\"comparison_sort_order\"] != -1]\n\nrecords[:3]\n</code></pre> <pre><code>[{'comparison_name': 'first_name',\n  'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n  'label_for_charts': 'Exact match on first_name',\n  'm_probability': 0.5009783629340309,\n  'u_probability': 0.0057935713975033705,\n  'bayes_factor': 86.4714229896119,\n  'log2_bayes_factor': 6.434151525637829,\n  'comparison_vector_value': 4},\n {'comparison_name': 'first_name',\n  'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92',\n  'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.92',\n  'm_probability': 0.15450921411813767,\n  'u_probability': 0.0023429457903817435,\n  'bayes_factor': 65.9465595629351,\n  'log2_bayes_factor': 6.043225490816602,\n  'comparison_vector_value': 3},\n {'comparison_name': 'first_name',\n  'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88',\n  'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.88',\n  'm_probability': 0.07548037415770431,\n  'u_probability': 0.0015484319951285285,\n  'bayes_factor': 48.7463281533646,\n  'log2_bayes_factor': 5.607221645966225,\n  'comparison_vector_value': 2}]\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#create-a-chart-template","title":"Create a chart template","text":""},{"location":"dev_guides/charts/building_charts.html#build-prototype-chart-in-altair","title":"Build prototype chart in Altair","text":"<pre><code>import pandas as pd\nimport altair as alt\n\ndf = pd.DataFrame(records)\n\n# Need a unique name for each comparison level - easier to create in pandas than altair\ndf[\"cl_id\"] = df[\"comparison_name\"] + \"_\" + \\\n    df[\"comparison_vector_value\"].astype(\"str\")\n\n# Simple start - bar chart with x, y and color encodings\nalt.Chart(df).mark_bar().encode(\n    y=\"cl_id\",\n    x=\"log2_bayes_factor\",\n    color=\"comparison_name\"\n)\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#sort-bars-edit-axestitles","title":"Sort bars, edit axes/titles","text":"<pre><code>alt.Chart(df).mark_bar().encode(\n    y=alt.Y(\"cl_id\",\n        sort=\"-x\",\n        title=\"Comparison level\"\n    ),\n    x=alt.X(\"log2_bayes_factor\",\n        title=\"Comparison level match weight = log2(m/u)\",\n        scale=alt.Scale(domain=[-10,10])\n    ),\n    color=\"comparison_name\"\n).properties(\n    title=\"New Chart - WOO!\"\n).configure_view(\n    step=15\n)\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#add-tooltip","title":"Add tooltip","text":"<pre><code>alt.Chart(df).mark_bar().encode(\n    y=alt.Y(\"cl_id\",\n            sort=\"-x\",\n            title=\"Comparison level\"\n            ),\n    x=alt.X(\"log2_bayes_factor\",\n            title=\"Comparison level match weight = log2(m/u)\",\n            scale=alt.Scale(domain=[-10, 10])\n            ),\n    color=\"comparison_name\",\n    tooltip=[\n        \"comparison_name\",\n        \"label_for_charts\",\n        \"sql_condition\",\n        \"m_probability\",\n        \"u_probability\",\n        \"bayes_factor\",\n        \"log2_bayes_factor\"\n        ]\n).properties(\n    title=\"New Chart - WOO!\"\n).configure_view(\n    step=15\n)\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#add-text-layer","title":"Add text layer","text":"<pre><code># Create base chart with shared data and encodings (mark type not specified)\nbase = alt.Chart(df).encode(\n    y=alt.Y(\"cl_id\",\n            sort=\"-x\",\n            title=\"Comparison level\"\n            ),\n    x=alt.X(\"log2_bayes_factor\",\n            title=\"Comparison level match weight = log2(m/u)\",\n            scale=alt.Scale(domain=[-10, 10])\n            ),\n    tooltip=[\n        \"comparison_name\",\n        \"label_for_charts\",\n        \"sql_condition\",\n        \"m_probability\",\n        \"u_probability\",\n        \"bayes_factor\",\n        \"log2_bayes_factor\"\n    ]\n)\n\n# Build bar chart from base (color legend made redundant by text labels)\nbar = base.mark_bar().encode(\n    color=alt.Color(\"comparison_name\", legend=None)\n)\n\n# Build text layer from base\ntext = base.mark_text(dx=0, align=\"right\").encode(\n    text=\"comparison_name\"\n)\n\n# Final layered chart\nchart = bar + text\n\n# Add global config\nchart.resolve_axis(\n    y=\"shared\",\n    x=\"shared\"\n).properties(\n    title=\"New Chart - WOO!\"\n).configure_view(\n    step=15\n)\n</code></pre> <p>Sometimes things go wrong in Altair and it's not clear why or how to fix it. If the docs and Stack Overflow don't have a solution, the answer is usually that Altair is making decisions under the hood about the Vega-Lite schema that are out of your control.</p> <p>In this example, the sorting of the y-axis is broken when layering charts. If we show <code>bar</code> and <code>text</code> side-by-side, you can see they work as expected, but the sorting is broken in the layering process.</p> <pre><code>bar | text\n</code></pre> <p>Once we get to this stage (or whenever you're comfortable), we can switch to Vega-Lite by exporting the JSON from our <code>chart</code> object, or opening the chart in the Vega-Lite editor.</p> <pre><code>chart.to_json()\n</code></pre> Chart JSON <pre><code>  {\n  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\",\n  \"config\": {\n    \"view\": {\n      \"continuousHeight\": 300,\n      \"continuousWidth\": 300\n    }\n  },\n  \"data\": {\n    \"name\": \"data-3901c03d78701611834aa82ab7374cce\"\n  },\n  \"datasets\": {\n    \"data-3901c03d78701611834aa82ab7374cce\": [\n      {\n        \"bayes_factor\": 86.62949969575988,\n        \"cl_id\": \"first_name_4\",\n        \"comparison_name\": \"first_name\",\n        \"comparison_vector_value\": 4,\n        \"label_for_charts\": \"Exact match first_name\",\n        \"log2_bayes_factor\": 6.436786480320881,\n        \"m_probability\": 0.5018941916173814,\n        \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\",\n        \"u_probability\": 0.0057935713975033705\n      },\n      {\n        \"bayes_factor\": 82.81743551783742,\n        \"cl_id\": \"first_name_3\",\n        \"comparison_name\": \"first_name\",\n        \"comparison_vector_value\": 3,\n        \"label_for_charts\": \"Damerau_levenshtein &lt;= 1\",\n        \"log2_bayes_factor\": 6.371862624533329,\n        \"m_probability\": 0.19595791797531015,\n        \"sql_condition\": \"damerau_levenshtein(\\\"first_name_l\\\", \\\"first_name_r\\\") &lt;= 1\",\n        \"u_probability\": 0.00236614327345483\n      },\n      {\n        \"bayes_factor\": 35.47812468678278,\n        \"cl_id\": \"first_name_2\",\n        \"comparison_name\": \"first_name\",\n        \"comparison_vector_value\": 2,\n        \"label_for_charts\": \"Jaro_winkler_similarity &gt;= 0.9\",\n        \"log2_bayes_factor\": 5.148857848140163,\n        \"m_probability\": 0.045985303626033085,\n        \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") &gt;= 0.9\",\n        \"u_probability\": 0.001296159366708712\n      },\n      {\n        \"bayes_factor\": 11.266641370022352,\n        \"cl_id\": \"first_name_1\",\n        \"comparison_name\": \"first_name\",\n        \"comparison_vector_value\": 1,\n        \"label_for_charts\": \"Jaro_winkler_similarity &gt;= 0.8\",\n        \"log2_bayes_factor\": 3.493985601438375,\n        \"m_probability\": 0.06396730257493154,\n        \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") &gt;= 0.8\",\n        \"u_probability\": 0.005677583982137938\n      },\n      {\n        \"bayes_factor\": 0.19514855669673956,\n        \"cl_id\": \"first_name_0\",\n        \"comparison_name\": \"first_name\",\n        \"comparison_vector_value\": 0,\n        \"label_for_charts\": \"All other comparisons\",\n        \"log2_bayes_factor\": -2.357355302129234,\n        \"m_probability\": 0.19219528420634394,\n        \"sql_condition\": \"ELSE\",\n        \"u_probability\": 0.9848665419801952\n      },\n      {\n        \"bayes_factor\": 113.02818119005431,\n        \"cl_id\": \"surname_4\",\n        \"comparison_name\": \"surname\",\n        \"comparison_vector_value\": 4,\n        \"label_for_charts\": \"Exact match surname\",\n        \"log2_bayes_factor\": 6.820538712806792,\n        \"m_probability\": 0.5527050424941531,\n        \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\",\n        \"u_probability\": 0.004889975550122249\n      },\n      {\n        \"bayes_factor\": 80.61351958508214,\n        \"cl_id\": \"surname_3\",\n        \"comparison_name\": \"surname\",\n        \"comparison_vector_value\": 3,\n        \"label_for_charts\": \"Damerau_levenshtein &lt;= 1\",\n        \"log2_bayes_factor\": 6.332949906378981,\n        \"m_probability\": 0.22212752320956386,\n        \"sql_condition\": \"damerau_levenshtein(\\\"surname_l\\\", \\\"surname_r\\\") &lt;= 1\",\n        \"u_probability\": 0.0027554624131641246\n      },\n      {\n        \"bayes_factor\": 48.57568460485815,\n        \"cl_id\": \"surname_2\",\n        \"comparison_name\": \"surname\",\n        \"comparison_vector_value\": 2,\n        \"label_for_charts\": \"Jaro_winkler_similarity &gt;= 0.9\",\n        \"log2_bayes_factor\": 5.602162423566203,\n        \"m_probability\": 0.0490149338194711,\n        \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") &gt;= 0.9\",\n        \"u_probability\": 0.0010090425738347498\n      },\n      {\n        \"bayes_factor\": 13.478820689774516,\n        \"cl_id\": \"surname_1\",\n        \"comparison_name\": \"surname\",\n        \"comparison_vector_value\": 1,\n        \"label_for_charts\": \"Jaro_winkler_similarity &gt;= 0.8\",\n        \"log2_bayes_factor\": 3.752622370380284,\n        \"m_probability\": 0.05001678986356945,\n        \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") &gt;= 0.8\",\n        \"u_probability\": 0.003710768991942586\n      },\n      {\n        \"bayes_factor\": 0.1277149376863226,\n        \"cl_id\": \"surname_0\",\n        \"comparison_name\": \"surname\",\n        \"comparison_vector_value\": 0,\n        \"label_for_charts\": \"All other comparisons\",\n        \"log2_bayes_factor\": -2.969000820703079,\n        \"m_probability\": 0.1261357106132424,\n        \"sql_condition\": \"ELSE\",\n        \"u_probability\": 0.9876347504709363\n      },\n      {\n        \"bayes_factor\": 236.78351486807742,\n        \"cl_id\": \"dob_5\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 5,\n        \"label_for_charts\": \"Exact match\",\n        \"log2_bayes_factor\": 7.887424832202931,\n        \"m_probability\": 0.41383785481447766,\n        \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\",\n        \"u_probability\": 0.0017477477477477479\n      },\n      {\n        \"bayes_factor\": 65.74625268345359,\n        \"cl_id\": \"dob_4\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 4,\n        \"label_for_charts\": \"Damerau_levenshtein &lt;= 1\",\n        \"log2_bayes_factor\": 6.038836762842662,\n        \"m_probability\": 0.10806341031654734,\n        \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") &lt;= 1\",\n        \"u_probability\": 0.0016436436436436436\n      },\n      {\n        \"bayes_factor\": 29.476860590690453,\n        \"cl_id\": \"dob_3\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 3,\n        \"label_for_charts\": \"Within 1 month\",\n        \"log2_bayes_factor\": 4.881510974428093,\n        \"m_probability\": 0.11300938544779224,\n        \"sql_condition\": \"\\n            abs(date_diff('month',\\n                strptime(\\\"dob_l\\\", '%Y-%m-%d'),\\n                strptime(\\\"dob_r\\\", '%Y-%m-%d'))\\n                ) &lt;= 1\\n        \",\n        \"u_probability\": 0.003833833833833834\n      },\n      {\n        \"bayes_factor\": 3.397551460259144,\n        \"cl_id\": \"dob_2\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 2,\n        \"label_for_charts\": \"Within 1 year\",\n        \"log2_bayes_factor\": 1.7644954026183992,\n        \"m_probability\": 0.17200656922328977,\n        \"sql_condition\": \"\\n            abs(date_diff('year',\\n                strptime(\\\"dob_l\\\", '%Y-%m-%d'),\\n                strptime(\\\"dob_r\\\", '%Y-%m-%d'))\\n                ) &lt;= 1\\n        \",\n        \"u_probability\": 0.05062662662662663\n      },\n      {\n        \"bayes_factor\": 0.6267794172297388,\n        \"cl_id\": \"dob_1\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 1,\n        \"label_for_charts\": \"Within 10 years\",\n        \"log2_bayes_factor\": -0.6739702908716182,\n        \"m_probability\": 0.19035523041792068,\n        \"sql_condition\": \"\\n            abs(date_diff('year',\\n                strptime(\\\"dob_l\\\", '%Y-%m-%d'),\\n                strptime(\\\"dob_r\\\", '%Y-%m-%d'))\\n                ) &lt;= 10\\n        \",\n        \"u_probability\": 0.3037037037037037\n      },\n      {\n        \"bayes_factor\": 0.004272180302776005,\n        \"cl_id\": \"dob_0\",\n        \"comparison_name\": \"dob\",\n        \"comparison_vector_value\": 0,\n        \"label_for_charts\": \"All other comparisons\",\n        \"log2_bayes_factor\": -7.870811748958801,\n        \"m_probability\": 0.002727549779972325,\n        \"sql_condition\": \"ELSE\",\n        \"u_probability\": 0.6384444444444445\n      },\n      {\n        \"bayes_factor\": 10.904938885948333,\n        \"cl_id\": \"city_1\",\n        \"comparison_name\": \"city\",\n        \"comparison_vector_value\": 1,\n        \"label_for_charts\": \"Exact match\",\n        \"log2_bayes_factor\": 3.4469097796586596,\n        \"m_probability\": 0.6013808934279701,\n        \"sql_condition\": \"\\\"city_l\\\" = \\\"city_r\\\"\",\n        \"u_probability\": 0.0551475711801453\n      },\n      {\n        \"bayes_factor\": 0.42188504195296994,\n        \"cl_id\": \"city_0\",\n        \"comparison_name\": \"city\",\n        \"comparison_vector_value\": 0,\n        \"label_for_charts\": \"All other comparisons\",\n        \"log2_bayes_factor\": -1.2450781575619725,\n        \"m_probability\": 0.3986191065720299,\n        \"sql_condition\": \"ELSE\",\n        \"u_probability\": 0.9448524288198547\n      },\n      {\n        \"bayes_factor\": 269.6074384240141,\n        \"cl_id\": \"email_2\",\n        \"comparison_name\": \"email\",\n        \"comparison_vector_value\": 2,\n        \"label_for_charts\": \"Exact match\",\n        \"log2_bayes_factor\": 8.07471649055784,\n        \"m_probability\": 0.5914840252879943,\n        \"sql_condition\": \"\\\"email_l\\\" = \\\"email_r\\\"\",\n        \"u_probability\": 0.0021938713143283602\n      },\n      {\n        \"bayes_factor\": 222.9721189153553,\n        \"cl_id\": \"email_1\",\n        \"comparison_name\": \"email\",\n        \"comparison_vector_value\": 1,\n        \"label_for_charts\": \"Levenshtein &lt;= 2\",\n        \"log2_bayes_factor\": 7.800719512398763,\n        \"m_probability\": 0.3019669634613132,\n        \"sql_condition\": \"levenshtein(\\\"email_l\\\", \\\"email_r\\\") &lt;= 2\",\n        \"u_probability\": 0.0013542812658830492\n      },\n      {\n        \"bayes_factor\": 0.10692840956298139,\n        \"cl_id\": \"email_0\",\n        \"comparison_name\": \"email\",\n        \"comparison_vector_value\": 0,\n        \"label_for_charts\": \"All other comparisons\",\n        \"log2_bayes_factor\": -3.225282884575804,\n        \"m_probability\": 0.10654901125069259,\n        \"sql_condition\": \"ELSE\",\n        \"u_probability\": 0.9964518474197885\n      }\n    ]\n  },\n  \"layer\": [\n    {\n      \"encoding\": {\n        \"color\": {\n          \"field\": \"comparison_name\",\n          \"legend\": null,\n          \"type\": \"nominal\"\n        },\n        \"tooltip\": [\n          {\n            \"field\": \"comparison_name\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"label_for_charts\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"sql_condition\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"m_probability\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"u_probability\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"bayes_factor\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"log2_bayes_factor\",\n            \"type\": \"quantitative\"\n          }\n        ],\n        \"x\": {\n          \"field\": \"log2_bayes_factor\",\n          \"scale\": {\n            \"domain\": [\n              -10,\n              10\n            ]\n          },\n          \"title\": \"Comparison level match weight = log2(m/u)\",\n          \"type\": \"quantitative\"\n        },\n        \"y\": {\n          \"field\": \"cl_id\",\n          \"sort\": \"-x\",\n          \"title\": \"Comparison level\",\n          \"type\": \"nominal\"\n        }\n      },\n      \"mark\": {\n        \"type\": \"bar\"\n      }\n    },\n    {\n      \"encoding\": {\n        \"text\": {\n          \"field\": \"comparison_name\",\n          \"type\": \"nominal\"\n        },\n        \"tooltip\": [\n          {\n            \"field\": \"comparison_name\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"label_for_charts\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"sql_condition\",\n            \"type\": \"nominal\"\n          },\n          {\n            \"field\": \"m_probability\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"u_probability\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"bayes_factor\",\n            \"type\": \"quantitative\"\n          },\n          {\n            \"field\": \"log2_bayes_factor\",\n            \"type\": \"quantitative\"\n          }\n        ],\n        \"x\": {\n          \"field\": \"log2_bayes_factor\",\n          \"scale\": {\n            \"domain\": [\n              -10,\n              10\n            ]\n          },\n          \"title\": \"Comparison level match weight = log2(m/u)\",\n          \"type\": \"quantitative\"\n        },\n        \"y\": {\n          \"field\": \"cl_id\",\n          \"sort\": \"-x\",\n          \"title\": \"Comparison level\",\n          \"type\": \"nominal\"\n        }\n      },\n      \"mark\": {\n        \"align\": \"right\",\n        \"dx\": 0,\n        \"type\": \"text\"\n      }\n    }\n  ]\n  }\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#edit-in-vega-lite","title":"Edit in Vega-Lite","text":"<p>Opening the JSON from the above chart in Vega-Lite editor, it is now behaving as intended, with both bar and text layers sorted by match weight.</p> <p>If the chart is working as intended, there is only one step required before saving the JSON file - removing data from the template schema.</p> <p>The data appears as follows with a dictionary of all included <code>datasets</code> by name, and then each chart referencing the <code>data</code> it uses by name:</p> <pre><code>\"data\": {\"name\": \"data-a6c84a9cf1a0c7a2cd30cc1a0e2c1185\"},\n\"datasets\": {\n  \"data-a6c84a9cf1a0c7a2cd30cc1a0e2c1185\": [\n\n    ...\n\n  ]\n},\n</code></pre> <p>Where only one dataset is required, this is equivalent to: </p><pre><code>\"data\": {\"values\": [...]}\n</code></pre> <p>After removing the data references, the template can be saved in Splink as <code>splink/files/chart_defs/my_new_chart.json</code></p>"},{"location":"dev_guides/charts/building_charts.html#combine-the-chart-dataset-and-template","title":"Combine the chart dataset and template","text":"<p>Putting all of the above together, Splink needs definitions for the methods that generate the chart and the data behind it (these can be separate or performed by the same function if relatively simple).</p>"},{"location":"dev_guides/charts/building_charts.html#chart-definition","title":"Chart definition","text":"<p>In <code>splink/charts.py</code> we can add a new function to populate the chart definition with the provided data:</p> <pre><code>def my_new_chart(records, as_dict=False):\n    chart_path = \"my_new_chart.json\"\n    chart = load_chart_definition(chart_path)\n\n    chart[\"data\"][\"values\"] = records\n    return altair_or_json(chart, as_dict=as_dict)\n</code></pre> <p>Note - only the data is being added to a fixed chart definition here. Other elements of the chart spec can be changed by editing the <code>chart</code> dictionary in the same way. </p> <p>For example, if you wanted to add a <code>color_scheme</code> argument to replace the default scheme (\"tableau10\"), this function could include the line: <code>chart[\"layer\"][0][\"encoding\"][\"color\"][\"scale\"][\"scheme\"] = color_scheme</code></p>"},{"location":"dev_guides/charts/building_charts.html#chart-method","title":"Chart method","text":"<p>Then we can add a method to the linker in <code>splink/linker.py</code> so the chart can be generated by <code>linker.my_new_chart()</code>:</p> <pre><code>from .charts import my_new_chart\n\n...\n\nclass Linker:\n\n    ...\n\n    def my_new_chart(self):\n\n        # Take linker object and extract complete settings dict\n        records = self._settings_obj._parameters_as_detailed_records\n\n        cols_to_keep = [\n            \"comparison_name\",\n            \"sql_condition\",\n            \"label_for_charts\",\n            \"m_probability\",\n            \"u_probability\",\n            \"bayes_factor\",\n            \"log2_bayes_factor\",\n            \"comparison_vector_value\"\n        ]\n\n        # Keep useful information for a match weights chart\n        records = [{k: r[k] for k in cols_to_keep}\n                   for r in records \n                   if r[\"comparison_vector_value\"] != -1 and r[\"comparison_sort_order\"] != -1]\n\n        return my_new_chart(records)\n</code></pre>"},{"location":"dev_guides/charts/building_charts.html#previous-new-chart-prs","title":"Previous new chart PRs","text":"<p>Real-life Splink chart additions, for reference:</p> <ul> <li>Term frequency adjustment chart</li> <li>Completeness (multi-dataset) chart</li> <li>Cumulative blocking rule chart</li> <li>Unlinkables chart</li> <li>Missingness chart</li> <li>Waterfall chart</li> </ul>"},{"location":"dev_guides/charts/understanding_and_editing_charts.html","title":"Understanding and editing charts","text":""},{"location":"dev_guides/charts/understanding_and_editing_charts.html#charts-in-splink","title":"Charts in Splink","text":"<p>Interactive charts are a key tool when linking data with Splink. To see all of the charts available, check out the Splink Charts Gallery.</p>"},{"location":"dev_guides/charts/understanding_and_editing_charts.html#how-do-charts-work-in-splink","title":"How do charts work in Splink?","text":"<p>Charts in Splink are built with Altair.</p> <p>For a given chart, there is usually:</p> <ul> <li>A template chart definition (e.g. <code>match_weights_waterfall.json</code>)</li> <li>A function to create the dataset for the chart (e.g. <code>records_to_waterfall_data</code>)</li> <li>A function to read the chart definition, add the data to it, and return the chart itself (e.g. <code>waterfall_chart</code>)</li> </ul> The Vega-Lite Editor <p>By far the best feature of Vega-Lite is the online editor where the JSON schema and the chart are shown side-by-side, showing changes in real time as the editor helps you to navigate the API.</p> <p></p>"},{"location":"dev_guides/charts/understanding_and_editing_charts.html#editing-existing-charts","title":"Editing existing charts","text":"<p>If you take any Altair chart in HTML format, you should be able to make changes pretty easily with the Vega-Lite Editor.</p> <p>For example, consider the <code>comparator_score_chart</code> from the <code>similarity analysis library</code>:</p> Before After <p>Desired changes</p> <ul> <li>Titles (shared title)</li> <li>Axis titles</li> <li>Shared y-axis</li> <li>Colour scales!! \ud83e\udd2e (see the Vega colour schemes docs)</li> <li>red-green is an accessibility no-no</li> <li>shared colour scheme for different metrics</li> <li>unpleasant and unclear to look at</li> <li>legends not necessary (especially when using text labels)</li> <li>Text size encoding (larger text for similar strings)</li> <li>Remove \"_similarity\" and \"_distance\" from column labels</li> <li>Fixed column width (rather than chart width)</li> <li>Row highlighting (on click/hover)</li> </ul> <p>The old spec can be pasted into the Vega Lite editorand edited as shown in the video below:</p> <p></p> <p>Check out the final, improved version chart specification.</p> Before-After diff <pre><code>@@ -1,9 +1,8 @@\n{\n-  \"config\": {\n-    \"view\": {\n-      \"continuousWidth\": 400,\n-      \"continuousHeight\": 300\n-    }\n+  \"title\": {\n+    \"text\": \"Heatmaps of string comparison metrics\",\n+    \"anchor\": \"middle\",\n+    \"fontSize\": 16\n  },\n  \"hconcat\": [\n    {\n@@ -18,25 +17,32 @@\n                  0,\n                  1\n                ],\n-                \"range\": [\n-                  \"red\",\n-                  \"green\"\n-                ]\n+                \"scheme\": \"greenblue\"\n              },\n-              \"type\": \"quantitative\"\n+              \"type\": \"quantitative\",\n+              \"legend\": null\n            },\n            \"x\": {\n              \"field\": \"comparator\",\n-              \"type\": \"ordinal\"\n+              \"type\": \"ordinal\",\n+              \"title\": null\n            },\n            \"y\": {\n              \"field\": \"strings_to_compare\",\n-              \"type\": \"ordinal\"\n+              \"type\": \"ordinal\",\n+              \"title\": \"String comparison\",\n+              \"axis\": {\n+                \"titleFontSize\": 14\n+              }\n            }\n          },\n-          \"height\": 300,\n-          \"title\": \"Heatmap of Similarity Scores\",\n-          \"width\": 300\n+          \"title\": \"Similarity\",\n+          \"width\": {\n+            \"step\": 40\n+          },\n+          \"height\": {\n+            \"step\": 30\n+          }\n        },\n        {\n          \"mark\": {\n@@ -44,6 +50,16 @@\n            \"baseline\": \"middle\"\n          },\n          \"encoding\": {\n+            \"size\": {\n+              \"field\": \"score\",\n+              \"scale\": {\n+                \"range\": [\n+                  8,\n+                  14\n+                ]\n+              },\n+              \"legend\": null\n+            },\n            \"text\": {\n              \"field\": \"score\",\n              \"format\": \".2f\",\n@@ -51,7 +67,10 @@\n            },\n            \"x\": {\n              \"field\": \"comparator\",\n-              \"type\": \"ordinal\"\n+              \"type\": \"ordinal\",\n+              \"axis\": {\n+                \"labelFontSize\": 12\n+              }\n            },\n            \"y\": {\n              \"field\": \"strings_to_compare\",\n@@ -72,29 +91,33 @@\n            \"color\": {\n              \"field\": \"score\",\n              \"scale\": {\n-                \"domain\": [\n-                  0,\n-                  5\n-                ],\n-                \"range\": [\n-                  \"green\",\n-                  \"red\"\n-                ]\n+                \"scheme\": \"yelloworangered\",\n+                \"reverse\": true\n              },\n-              \"type\": \"quantitative\"\n+              \"type\": \"quantitative\",\n+              \"legend\": null\n            },\n            \"x\": {\n              \"field\": \"comparator\",\n-              \"type\": \"ordinal\"\n+              \"type\": \"ordinal\",\n+              \"title\": null,\n+              \"axis\": {\n+                \"labelFontSize\": 12\n+              }\n            },\n            \"y\": {\n              \"field\": \"strings_to_compare\",\n-              \"type\": \"ordinal\"\n+              \"type\": \"ordinal\",\n+              \"axis\": null\n            }\n          },\n-          \"height\": 300,\n-          \"title\": \"Heatmap of Distance Scores\",\n-          \"width\": 200\n+          \"title\": \"Distance\",\n+          \"width\": {\n+            \"step\": 40\n+          },\n+          \"height\": {\n+            \"step\": 30\n+          }\n        },\n        {\n          \"mark\": {\n@@ -102,6 +125,17 @@\n            \"baseline\": \"middle\"\n          },\n          \"encoding\": {\n+            \"size\": {\n+              \"field\": \"score\",\n+              \"scale\": {\n+                \"range\": [\n+                  8,\n+                  14\n+                ],\n+                \"reverse\": true\n+              },\n+              \"legend\": null\n+            },\n            \"text\": {\n              \"field\": \"score\",\n              \"type\": \"quantitative\"\n@@ -124,7 +158,9 @@\n  ],\n  \"resolve\": {\n    \"scale\": {\n-      \"color\": \"independent\"\n+      \"color\": \"independent\",\n+      \"y\": \"shared\",\n+      \"size\": \"independent\"\n    }\n  },\n  \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\",\n</code></pre>"},{"location":"includes/tags.html","title":"Tags","text":""},{"location":"includes/tags.html#tags","title":"Tags","text":"<p>Following is a list of relevant tags:</p> <p>[TAGS]</p>"},{"location":"includes/generated_files/dataset_labels_table.html","title":"Dataset labels table","text":"dataset name description rows unique entities link to source <code>fake_1000_labels</code> Clerical labels for fake_1000 3,176 NA source"},{"location":"includes/generated_files/datasets_table.html","title":"Datasets table","text":"dataset name description rows unique entities link to source <code>fake_1000</code> Fake 1000 from splink demos.  Records are 250 simulated people, with different numbers of duplicates, labelled. 1,000 250 source <code>historical_50k</code> The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors. 50,000 5,156 source <code>febrl3</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL3 data set contains 5000 records (2000 originals and 3000 duplicates), with a maximum of 5 duplicates based on one original record. 5,000 2,000 source <code>febrl4a</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL4a contains 5000 original records. 5,000 5,000 source <code>febrl4b</code> The Freely Extensible Biomedical Record Linkage (FEBRL) datasets consist of comparison patterns from an epidemiological cancer study in Germany.FEBRL4b contains 5000 duplicate records, one for each record in FEBRL4a. 5,000 5,000 source <code>transactions_origin</code> This data has been generated to resemble bank transactions leaving an account. There are no duplicates within the dataset and each transaction is designed to have a counterpart arriving in 'transactions_destination'. Memo is sometimes truncated or missing. 45,326 45,326 source <code>transactions_destination</code> This data has been generated to resemble bank transactions arriving in an account. There are no duplicates within the dataset and each transaction is designed to have a counterpart sent from 'transactions_origin'. There may be a delay between the source and destination account, and the amount may vary due to hidden fees and foreign exchange rates. Memo is sometimes truncated or missing. 45,326 45,326 source"},{"location":"topic_guides/topic_guides_index.html","title":"Introduction","text":""},{"location":"topic_guides/topic_guides_index.html#user-guide","title":"User Guide","text":"<p>This section contains in-depth guides on a variety of topics and concepts within Splink, as well as data linking more generally. These are intended to provide an extra layer of detail on top of the Splink tutorial and examples.</p> <p>The user guide is broken up into the following categories:</p> <ol> <li>Record Linkage Theory - for an introduction to data linkage from a theoretical perspective, and to help build some intuition around the parameters being estimated in Splink models.</li> <li>Linkage Models in Splink - for an introduction to the building blocks of a Splink model. Including the supported SQL Backends and how to define a model with a Splink Settings dictionary.</li> <li>Data Preparation - for guidance on preparing your data for linkage. Including guidance on feature engineering to help improve Splink models.</li> <li>Blocking - for an introduction to Blocking Rules and their purpose within record linkage. Including how blocking rules are used in different contexts within Splink.</li> <li>Comparing Records - for guidance on defining <code>Comparison</code>s withing a Splink model. Including how comparing records are structured within <code>Comparison</code>s, how to utilise string comparators for fuzzy matching and how deal with skewed data with Term Frequency Adjustments.</li> <li>Model Training - for guidance on the methods for training a Splink model, and how to choose them for specific use cases. (Coming soon)</li> <li>Clustering - for guidance on how records are clustered together. (Coming Soon)</li> <li>Evaluation - for guidance on how to evaluate Splink models, links and clusters (including Clerical Labelling).</li> <li>Performance - for guidance on how to make Splink models run more efficiently.</li> </ol>"},{"location":"topic_guides/blocking/blocking_rules.html","title":"What are Blocking Rules?","text":"","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#what-are-blocking-rules","title":"What are Blocking Rules?","text":"<p>The primary driver of Splink's run time is the number of record pairs that the Splink model has to process.  This is controlled by the blocking rules.</p> <p>This guide explains what blocking rules are, and how they can be used.</p>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#introduction","title":"Introduction","text":"<p>One of the main challenges to overcome in record linkage is the scale of the problem.</p> <p>The number of pairs of records to compare grows using the formula \\(\\frac{n\\left(n-1\\right)}2\\), i.e. with (approximately) the square of the number of records, as shown in the following chart:</p> <p></p> <p>For example, a dataset of 1 million input records would generate around 500 billion pairwise record comparisons.</p> <p>So, when datasets get bigger the computation could get infeasibly large. We use blocking to reduce the scale of the computation to something more tractible.</p>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#blocking","title":"Blocking","text":"<p>Blocking is a technique for reducing the number of record pairs that are considered by a model.</p> <p>Considering a dataset of 1 million records, comparing each record against all of the other records in the dataset generates ~500 billion pairwise comparisons. However, we know the vast majority of these record comparisons won't be matches, so processing the full ~500 billion comparisons would be largely pointless (as well as costly and time-consuming).</p> <p>Instead, we can define a subset of potential comparisons using Blocking Rules. These are rules that define \"blocks\" of comparisons that should be considered. For example, the blocking rule:</p> <p><code>\"block_on(\"first_name\", \"surname\")</code></p> <p>will generate only those pairwise record comparisons where first name and surname match.  That is, is equivalent to joining input records the SQL condition  <code>l.first_name = r.first_name and l.surname = r.surname</code></p> <p>Within a Splink model, you can specify multiple Blocking Rules to ensure all potential matches are considered.  These are provided as a list.  Splink will then produce all record comparisons that satisfy at least one of your blocking rules.</p> Further Reading <p>For more information on blocking, please refer to this article</p>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#blocking-in-splink","title":"Blocking in Splink","text":"<p>There are two areas in Splink where blocking is used:</p> <ul> <li> <p>The first is to generate pairwise comparisons when finding links (running <code>predict()</code>). This is the sense in which 'blocking' is usually understood in the context of record linkage.  These blocking rules are provided in the model settings using <code>blocking_rules_to_generate_predictions</code>.</p> </li> <li> <p>The second is a less familiar application of blocking: using it for model training. This is a more advanced topic, and is covered in the model training topic guide.</p> </li> </ul>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#choosing-blocking_rules_to_generate_predictions","title":"Choosing <code>blocking_rules_to_generate_predictions</code>","text":"<p>The blocking rules specified in your settings at <code>blocking_rules_to_generate_predictions</code> are the single most important determinant of how quickly your linkage runs.  This is because the number of comparisons generated is usually many multiple times higher than the number of input records.</p> <p>How can we choose a good set of blocking rules? It's usually better to use a longer list of strict blocking rules, than a short list of loose blocking rules.  Let's see why:</p> <p>The aim of our blocking rules are to:</p> <ul> <li>Capture as many true matches as possible</li> <li>Reduce the total number of comparisons being generated</li> </ul> <p>There is a tension between these aims, because by choosing loose blocking rules which generate more comparisons, you have a greater chance of capturing all true matches.</p> <p>A single rule is unlikely to be able to achieve both aims.</p> <p>For example, consider:</p> <p></p><pre><code>SettingsCreator(\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\")\n    ]\n)\n</code></pre> This will generate comparisons for all true matches where names match. But it would miss a true match where there was a typo in the name. <p>This is why <code>blocking_rules_to_generate_predictions</code> is a list.</p> <p>Suppose we also block on <code>postcode</code>:</p> <pre><code>SettingsCreator(\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"postcode\")\n    ]\n)\n</code></pre> <p>Now it doesn't matter if there's a typo in the name so long as postcode matches (and vice versa).</p> <p>We could take this further and block on, say, <code>date_of_birth</code> as well.</p> <p>By specifying a variety of <code>blocking_rules_to_generate_predictions</code>, even if each rule on its own is relatively tight, it becomes implausible that a truly matching record would not be captured by at least one of the rules.</p>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#tightening-blocking-rules-for-linking-larger-datasets","title":"Tightening blocking rules for linking larger datasets","text":"<p>As the size of your input data grows, tighter blocking rules may be needed.  Blocking on, say <code>first_name</code> and <code>surname</code> may be insufficiently tight to reduce the number of comparisons down to a computationally tractable number.</p> <p>In this situation, it's often best to use an even larger list of tighter blocking rules.</p> <p>An example could be something like: </p><pre><code>SettingsCreator(\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\", \"surname\", \"substr(postcode,1,3)\"),\n        block_on(\"surname\", \"dob\"),\n        block_on(\"first_name\", \"dob\"),\n        block_on(\"dob\", \"postcode\")\n        block_on(\"first_name\", \"postcode\")\n        block_on(\"surname\", \"postcode\")\n    ]\n)\n</code></pre>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#analysing-blocking_rules_to_generate_predictions","title":"Analysing <code>blocking_rules_to_generate_predictions</code>","text":"<p>It's generally a good idea to analyse the number of comparisons generated by your blocking rules before trying to use them to make predictions, to make sure you don't accidentally generate trillions of pairs.  You can use the following function to do this:</p> <pre><code>from splink.blocking_analysis import count_comparisons_from_blocking_rule\n\nbr = block_on(\"substr(first_name, 1,1)\", \"surname\")\n\ncount_comparisons_from_blocking_rule(\n        table_or_tables=df,\n        blocking_rule=br,\n        link_type=\"dedupe_only\",\n        db_api=db_api,\n    )\n</code></pre>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/blocking_rules.html#more-complex-blocking-rules","title":"More complex blocking rules","text":"<p>It is possible to use more complex blocking rules that use non-equijoin conditions.  For example, you could use a blocking rule that uses a fuzzy matching function:</p> <pre><code>l.first_name and r.first_name and levenshtein(l.surname, r.surname) &lt; 3\n</code></pre> <p>However, this will not be executed very efficiently, for reasons described in this page.</p>","tags":["Blocking","Performance"]},{"location":"topic_guides/blocking/model_training.html","title":"Model Training Blocking Rules","text":""},{"location":"topic_guides/blocking/model_training.html#blocking-for-model-training","title":"Blocking for Model Training","text":"<p>Model Training Blocking Rules choose which record pairs from a dataset get considered when training a Splink model. These are used during Expectation Maximisation (EM), where we estimate the m probability (in most cases).</p> <p>The aim of Model Training Blocking Rules is to reduce the number of record pairs considered when training a Splink model in order to reduce the computational resource required. Each Training Blocking Rule define a training \"block\" of records which have a combination of matches and non-matches that are considered by Splink's Expectation Maximisation algorithm.</p> <p>The Expectation Maximisation algorithm seems to work best when the pairwise record comparisons are a mix of anywhere between around 0.1% and 99.9% true matches. It works less efficiently if there is a huge imbalance between the two (e.g. a billion non matches and only a hundred matches).</p> <p>Note</p> <p>Unlike blocking rules for prediction, it does not matter if Training Rules excludes some true matches - it just needs to generate examples of matches and non-matches.</p>"},{"location":"topic_guides/blocking/model_training.html#using-training-rules-in-splink","title":"Using Training Rules in Splink","text":"<p>Blocking Rules for Model Training are used as a parameter in the <code>estimate_parameters_using_expectation_maximisation</code> function. After a <code>linker</code> object has been instantiated, you can estimate <code>m probability</code> with training sessions such as:</p> <pre><code>from splink import block_on\n\nblocking_rule_for_training = block_on(\"first_name\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n)\n</code></pre> <p>Here, we have defined a \"block\" of records where <code>first_name</code> are the same. As names are not unique, we can be pretty sure that there will be a combination of matches and non-matches in this \"block\" which is what is required for the EM algorithm.</p> <p>Matching only on <code>first_name</code> will likely generate a large \"block\" of pairwise comparisons which will take longer to run. In this case it may be worthwhile applying a stricter blocking rule to reduce runtime. For example, a match on <code>first_name</code> and <code>surname</code>:</p> <pre><code>from splink import block_on\nblocking_rule = block_on(\"first_name\", \"surname\")\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    blocking_rule_for_training\n    )\n</code></pre> <p>which will still have a combination of matches and non-matches, but fewer record pairs to consider.</p>"},{"location":"topic_guides/blocking/model_training.html#choosing-training-rules","title":"Choosing Training Rules","text":"<p>The idea behind Training Rules is to consider \"blocks\" of record pairs with a mixture of matches and non-matches. In practice, most blocking rules have a mixture of matches and non-matches so the primary consideration should be to reduce the runtime of model training by choosing Training Rules that reduce the number of record pairs in the training set.</p> <p>There are some tools within Splink to help choosing these rules. For example, the <code>count_comparisons_from_blocking_rule</code> gives the number of records pairs generated by a blocking rule:</p> <pre><code>from splink import block_on, DuckDBAPI\nfrom splink.blocking_analysis import count_comparisons_from_blocking_rule\n\ndb_api = DuckDBAPI()\n\nbr = block_on(\"first_name\", \"surname\")\n\ncount_comparisons_from_blocking_rule(\n    table_or_tables=df,\n    blocking_rule=br,\n    link_type=\"dedupe_only\",\n    db_api=db_api,\n)\n</code></pre> <p>1056</p> <p>It is recommended that you run this function to check how many comparisons are generated before training a model so that you do not needlessly run a training session on billions of comparisons.</p> <p>Note</p> <p>Unlike blocking rules for prediction, Training Rules are treated separately for each EM training session therefore the total number of comparisons for Model Training is simply the sum of <code>count_comparisons_from_blocking_rule</code> across all Blocking Rules (as opposed to the result of <code>cumulative_comparisons_from_blocking_rules_records</code>).</p>"},{"location":"topic_guides/blocking/performance.html","title":"Computational Performance","text":""},{"location":"topic_guides/blocking/performance.html#blocking-rule-performance","title":"Blocking Rule Performance","text":"<p>When considering computational performance of blocking rules, there are two main drivers to address:</p> <ul> <li>How may pairwise comparisons are generated</li> <li>How quickly each pairwise comparison takes to run</li> </ul> <p>Below we run through an example of how to address each of these drivers.</p>"},{"location":"topic_guides/blocking/performance.html#strict-vs-lenient-blocking-rules","title":"Strict vs lenient Blocking Rules","text":"<p>One way to reduce the number of comparisons being considered within a model is to apply strict blocking rules. However, this can have a significant impact on the how well the Splink model works.</p> <p>In reality, we recommend getting a model up and running with strict Blocking Rules and incrementally loosening them to see the impact on the runtime and quality of the results. By starting with strict blocking rules, the linking process will run faster which means you can iterate through model versions more quickly.</p> Example - Incrementally loosening Prediction Blocking Rules <p>When choosing Prediction Blocking Rules, consider how <code>blocking_rules_to_generate_predictions</code> may be made incrementally less strict. We may start with the following rule:</p> <p><code>l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob</code>.</p> <p>This is a very strict rule, and will only create comparisons where full name and date of birth match. This has the advantage of creating few record comparisons, but the disadvantage that the rule will miss true matches where there are typos or nulls in any of these three fields.</p> <p>This blocking rule could be loosened to:</p> <p><code>substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname and l.year_of_birth = r.year_of_birth</code></p> <p>Now it allows for typos or aliases in the first name, so long as the first letter is the same, and errors in month or day of birth.</p> <p>Depending on the side of your input data, the rule could be further loosened to</p> <p><code>substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname</code></p> <p>or even</p> <p><code>l.surname = r.surname</code></p> <p>The user could use the <code>count_comparisons_from_blocking_rule()</code> function to select which rule is appropriate for their data.</p>"},{"location":"topic_guides/blocking/performance.html#efficient-blocking-rules","title":"Efficient Blocking Rules","text":"<p>While the number of pairwise comparisons is important for reducing the computation, it is also helpful to consider the efficiency of the Blocking Rules. There are a number of ways to define subsets of records (i.e. \"blocks\"), but they are not all computationally efficient.</p> <p>From a performance perspective, here we consider two classes of blocking rule:</p> <ul> <li>Equi-join conditions</li> <li>Filter conditions</li> </ul>"},{"location":"topic_guides/blocking/performance.html#equi-join-conditions","title":"Equi-join Conditions","text":"<p>Equi-joins are simply equality conditions between records, e.g.</p> <p><code>l.first_name = r.first_name</code></p> <p>Equality-based blocking rules can be executed efficiently by SQL engines in the sense that the engine is able to create only the record pairs that satisfy the blocking rule. The engine does not have to create all possible record pairs and then filter out the pairs that do not satisfy the blocking rule.  This is in contrast to filter conditions (see below), where the engine has to create a larger set of comparisons and then filter it down.</p> <p>Due to this efficiency advantage, equality-based blocking rules should be considered the default method for defining blocking rules. For example, the above example can be written as:</p> <pre><code>from splink import block_on\nblock_on(\"first_name\")\n</code></pre>"},{"location":"topic_guides/blocking/performance.html#filter-conditions","title":"Filter Conditions","text":"<p>Filter conditions refer to any Blocking Rule that isn't a simple equality between columns. E.g.</p> <p><code>levenshtein(l.surname, r.surname) &lt; 3</code></p> <p>Blocking rules which use similarity or distance functions, such as the example above, are inefficient as the <code>levenshtein</code> function needs to be evaluated for all possible record comparisons before filtering out the pairs that do not satisfy the filter condition.</p>"},{"location":"topic_guides/blocking/performance.html#combining-blocking-rules-efficiently","title":"Combining Blocking Rules Efficiently","text":"<p>Just as how Blocking Rules can impact on performance, so can how they are combined. The most efficient Blocking Rules combinations are \"AND\" statements. E.g.</p> <p><code>block_on(\"first_name\", \"surname\")</code></p> <p>which is equivalent to</p> <p><code>l.first_name = r.first_name AND l.surname = r.surname</code></p> <p>\"OR\" statements are extremely inefficient and should almost never be used. E.g.</p> <p><code>l.first_name = r.first_name OR l.surname = r.surname</code></p> <p>In most SQL engines, an <code>OR</code> condition within a blocking rule will result in all possible record comparisons being generated.  That is, the whole blocking rule becomes a filter condition rather than an equi-join condition, so these should be avoided.  For further information, see here.</p> <p>Instead of the <code>OR</code> condition being included in the blocking rule, instead, provide two blocking rules to Splink.  This will achieve the desired outcome of generating all comparisons where either the first name or surname match.</p> <pre><code>SettingsCreator(\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\")\n    ]\n)\n</code></pre> Spark-specific Further Reading <p>Given the ability to parallelise operations in Spark, there are some additional configuration options which can improve performance of blocking. Please refer to the Spark Performance Topic Guides for more information.</p> <p>Note: In Spark Equi-joins are implemented using hash partitioning, which facilitates splitting the workload across multiple machines.</p>"},{"location":"topic_guides/comparisons/choosing_comparators.html","title":"Choosing string comparators","text":""},{"location":"topic_guides/comparisons/choosing_comparators.html#choosing-string-comparators","title":"Choosing String Comparators","text":"<p>When building a Splink model, one of the most important aspects is defining the <code>Comparisons</code> and <code>Comparison Levels</code> that the model will train on. Each <code>Comparison Level</code> within a <code>Comparison</code> should contain a different amount of evidence that two records are a match, to which the model can assign a match weight. When considering different amounts of evidence for the model, it is helpful to explore fuzzy matching as a way of distinguishing strings that are similar, but not the same, as one another.</p> <p>This guide is intended to show how Splink's string comparators perform in different situations in order to help choosing the most appropriate comparator for a given column as well as the most appropriate threshold (or thresholds). For descriptions and examples of each string comparators available in Splink, see the dedicated topic guide.</p>"},{"location":"topic_guides/comparisons/choosing_comparators.html#what-options-are-available-when-comparing-strings","title":"What options are available when comparing strings?","text":"<p>There are three main classes of string comparator that are considered within Splink:</p> <ol> <li>String Similarity Scores </li> <li>String Distance Scores </li> <li>Phonetic Matching </li> </ol> <p>where  </p> <p>String Similarity Scores are scores between 0 and 1 indicating how similar two strings are. 0 represents two completely dissimilar strings and 1 represents identical strings. E.g. Jaro-Winkler Similarity.  </p> <p>String Distance Scores are integer distances, counting the number of operations to convert one string into another. A lower string distance indicates more similar strings. E.g. Levenshtein Distance.  </p> <p>Phonetic Matching is whether two strings are phonetically similar. The two strings are passed through a phonetic transformation algorithm and then the resulting phonetic codes are matched. E.g. Double Metaphone.</p>"},{"location":"topic_guides/comparisons/choosing_comparators.html#comparing-string-similarity-and-distance-scores","title":"Comparing String Similarity and Distance Scores","text":"<p>Splink contains a <code>comparison_helpers</code> module which includes some helper functions for comparing the string similarity and distance scores that can help when choosing the most appropriate fuzzy matching function.</p> <p>For comparing two strings the <code>comparator_score</code> function returns the scores for all of the available comparators. E.g. consider a simple inversion \"Richard\" vs \"iRchard\":</p> <pre><code>from splink.exploratory import similarity_analysis as sa\n\nsa.comparator_score(\"Richard\", \"iRchard\")\n</code></pre> string1 string2 levenshtein_distance damerau_levenshtein_distance jaro_similarity jaro_winkler_similarity jaccard_similarity 0 Richard iRchard 2 1 0.95 0.95 1.0 <p>Now consider a collection of common variations of the name \"Richard\" - which comparators will consider these variations as sufficiently similar to \"Richard\"?</p> <pre><code>import pandas as pd\n\ndata = [\n    {\"string1\": \"Richard\", \"string2\": \"Richard\", \"error_type\": \"None\"},\n    {\"string1\": \"Richard\", \"string2\": \"ichard\", \"error_type\": \"Deletion\"},\n    {\"string1\": \"Richard\", \"string2\": \"Richar\", \"error_type\": \"Deletion\"},\n    {\"string1\": \"Richard\", \"string2\": \"iRchard\", \"error_type\": \"Transposition\"},\n    {\"string1\": \"Richard\", \"string2\": \"Richadr\", \"error_type\": \"Transposition\"},\n    {\"string1\": \"Richard\", \"string2\": \"Rich\", \"error_type\": \"Shortening\"},\n    {\"string1\": \"Richard\", \"string2\": \"Rick\", \"error_type\": \"Nickname/Alias\"},\n    {\"string1\": \"Richard\", \"string2\": \"Ricky\", \"error_type\": \"Nickname/Alias\"},\n    {\"string1\": \"Richard\", \"string2\": \"Dick\", \"error_type\": \"Nickname/Alias\"},\n    {\"string1\": \"Richard\", \"string2\": \"Rico\", \"error_type\": \"Nickname/Alias\"},\n    {\"string1\": \"Richard\", \"string2\": \"Rachael\", \"error_type\": \"Different Name\"},\n    {\"string1\": \"Richard\", \"string2\": \"Stephen\", \"error_type\": \"Different Name\"},\n]\n\ndf = pd.DataFrame(data)\ndf\n</code></pre> string1 string2 error_type 0 Richard Richard None 1 Richard ichard Deletion 2 Richard Richar Deletion 3 Richard iRchard Transposition 4 Richard Richadr Transposition 5 Richard Rich Shortening 6 Richard Rick Nickname/Alias 7 Richard Ricky Nickname/Alias 8 Richard Dick Nickname/Alias 9 Richard Rico Nickname/Alias 10 Richard Rachael Different Name 11 Richard Stephen Different Name <p>The <code>comparator_score_chart</code> function allows you to compare two lists of strings and how similar the elements are according to the available string similarity and distance metrics.</p> <pre><code>sa.comparator_score_chart(data, \"string1\", \"string2\")\n</code></pre> <p>Here we can see that all of the metrics are fairly sensitive to transcriptions errors (\"Richadr\", \"Richar\", \"iRchard\"). However, considering nicknames/aliases (\"Rick\", \"Ricky\", \"Rico\"), simple metrics such as Jaccard, Levenshtein and Damerau-Levenshtein tend to be less useful. The same can be said for name shortenings (\"Rich\"), but to a lesser extent than more complex nicknames. However, even more subtle metrics like Jaro and Jaro-Winkler still struggle to identify less obvious nicknames/aliases such as \"Dick\". </p> <p>If you would prefer the underlying dataframe instead of the chart, there is the <code>comparator_score_df</code> function.</p> <pre><code>sa.comparator_score_df(data, \"string1\", \"string2\")\n</code></pre> string1 string2 levenshtein_distance damerau_levenshtein_distance jaro_similarity jaro_winkler_similarity jaccard_similarity 0 Richard Richard 0 0 1.00 1.00 1.00 1 Richard ichard 1 1 0.95 0.95 0.86 2 Richard Richar 1 1 0.95 0.97 0.86 3 Richard iRchard 2 1 0.95 0.95 1.00 4 Richard Richadr 2 1 0.95 0.97 1.00 5 Richard Rich 3 3 0.86 0.91 0.57 6 Richard Rick 4 4 0.73 0.81 0.38 7 Richard Ricky 4 4 0.68 0.68 0.33 8 Richard Dick 5 5 0.60 0.60 0.22 9 Richard Rico 4 4 0.73 0.81 0.38 10 Richard Rachael 3 3 0.71 0.74 0.44 11 Richard Stephen 7 7 0.43 0.43 0.08"},{"location":"topic_guides/comparisons/choosing_comparators.html#choosing-thresholds","title":"Choosing thresholds","text":"<p>We can add distance and similarity thresholds to the comparators to see what strings would be included in a given comparison level:</p> <pre><code>sa.comparator_score_threshold_chart(\n    data, \"string1\", \"string2\", distance_threshold=2, similarity_threshold=0.8\n)\n</code></pre> <p>To class our variations on \"Richard\" in the same <code>Comparison Level</code>, a good choice of metric could be Jaro-Winkler with a threshold of 0.8. Lowering the threshold any more could increase the chances for false positives. </p> <p>For example, consider a single Jaro-Winkler <code>Comparison Level</code> threshold of 0.7 would lead to \"Rachael\" being considered as providing the same amount evidence for a record matching as \"iRchard\".</p> <p>An alternative way around this is to construct a <code>Comparison</code> with multiple levels, each corresponding to a different threshold of Jaro-Winkler similarity. For example, below we construct a <code>Comparison</code> using the <code>Comparison Library</code> function JaroWinklerAtThresholds with multiple levels for different match thresholds.:</p> <pre><code>import splink.comparison_library as cl\n\nfirst_name_comparison = cl.JaroWinklerAtThresholds(\"first_name\", [0.9, 0.8, 0.7])\n</code></pre> <p>If we print this comparison as a dictionary we can see the underlying SQL.</p> <pre><code>first_name_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <pre><code>{'output_column_name': 'first_name',\n 'comparison_levels': [{'sql_condition': '\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL',\n   'label_for_charts': 'first_name is NULL',\n   'is_null_level': True},\n  {'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n   'label_for_charts': 'Exact match on first_name'},\n  {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.9',\n   'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.9'},\n  {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.8',\n   'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.8'},\n  {'sql_condition': 'jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.7',\n   'label_for_charts': 'Jaro-Winkler distance of first_name &gt;= 0.7'},\n  {'sql_condition': 'ELSE', 'label_for_charts': 'All other comparisons'}],\n 'comparison_description': 'JaroWinklerAtThresholds'}\n</code></pre> <p>Where:  </p> <ul> <li>Exact Match level will catch perfect matches (\"Richard\").  </li> <li>The 0.9 threshold will catch Shortenings and Typos (\"ichard\", \"Richar\", \"iRchard\", \"Richadr\",  \"Rich\").  </li> <li>The 0.8 threshold will catch simple Nicknames/Aliases (\"Rick\", \"Rico\").  </li> <li>The 0.7 threshold will catch more complex Nicknames/Aliases (\"Ricky\"), but will also include less relevant names (e.g. \"Rachael\"). However, this should not be a concern as the model should give less predictive power (i.e. Match Weight) to this level of evidence.  </li> <li>All other comparisons will end up in the \"Else\" level  </li> </ul>"},{"location":"topic_guides/comparisons/choosing_comparators.html#phonetic-matching","title":"Phonetic Matching","text":"<p>There are similar functions available within splink to help users get familiar with phonetic transformations. You can create similar visualisations to string comparators.</p> <p>To see the phonetic transformations for a single string, there is the <code>phonetic_transform</code> function:</p> <pre><code>sa.phonetic_transform(\"Richard\")\n</code></pre> <pre><code>{'soundex': 'R02063', 'metaphone': 'RXRT', 'dmetaphone': ('RXRT', 'RKRT')}\n</code></pre> <pre><code>sa.phonetic_transform(\"Steven\")\n</code></pre> <pre><code>{'soundex': 'S30105', 'metaphone': 'STFN', 'dmetaphone': ('STFN', '')}\n</code></pre> <p>Now consider a collection of common variations of the name \"Stephen\". Which phonetic transforms will consider these as sufficiently similar to \"Stephen\"?</p> <pre><code>data = [\n    {\"string1\": \"Stephen\", \"string2\": \"Stephen\", \"error_type\": \"None\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Steven\", \"error_type\": \"Spelling Variation\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stephan\", \"error_type\": \"Spelling Variation/Similar Name\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Steve\", \"error_type\": \"Nickname/Alias\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stehpen\", \"error_type\": \"Transposition\"},\n    {\"string1\": \"Stephen\", \"string2\": \"tSephen\", \"error_type\": \"Transposition\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stephne\", \"error_type\": \"Transposition\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stphen\", \"error_type\": \"Deletion\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stepheb\", \"error_type\": \"Replacement\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Stephanie\", \"error_type\": \"Different Name\"},\n    {\"string1\": \"Stephen\", \"string2\": \"Richard\", \"error_type\": \"Different Name\"},\n]\n\n\ndf = pd.DataFrame(data)\ndf\n</code></pre> string1 string2 error_type 0 Stephen Stephen None 1 Stephen Steven Spelling Variation 2 Stephen Stephan Spelling Variation/Similar Name 3 Stephen Steve Nickname/Alias 4 Stephen Stehpen Transposition 5 Stephen tSephen Transposition 6 Stephen Stephne Transposition 7 Stephen Stphen Deletion 8 Stephen Stepheb Replacement 9 Stephen Stephanie Different Name 10 Stephen Richard Different Name <p>The <code>phonetic_match_chart</code> function allows you to compare two lists of strings and how similar the elements are according to the available string similarity and distance metrics.</p> <pre><code>sa.phonetic_match_chart(data, \"string1\", \"string2\")\n</code></pre> <p>Here we can see that all of the algorithms recognise simple phonetically similar names (\"Stephen\", \"Steven\"). However, there is some variation when it comes to transposition errors (\"Stehpen\", \"Stephne\") with soundex and metaphone-esque giving different results. There is also different behaviour considering different names (\"Stephanie\").</p> <p>Given there is no clear winner that captures all of the similar names, it is recommended that phonetic matches are used as a single <code>Comparison Level</code> within in a <code>Comparison</code> which also includes string comparators in the other levels. To see an example of this, see the Combining String scores and Phonetic matching section of this topic guide.</p> <p>If you would prefer the underlying dataframe instead of the chart, there is the <code>phonetic_transform_df</code> function.</p> <pre><code>sa.phonetic_transform_df(data, \"string1\", \"string2\")\n</code></pre> string1 string2 soundex metaphone dmetaphone 0 Stephen Stephen [S30105, S30105] [STFN, STFN] [(STFN, ), (STFN, )] 1 Stephen Steven [S30105, S30105] [STFN, STFN] [(STFN, ), (STFN, )] 2 Stephen Stephan [S30105, S30105] [STFN, STFN] [(STFN, ), (STFN, )] 3 Stephen Steve [S30105, S3010] [STFN, STF] [(STFN, ), (STF, )] 4 Stephen Stehpen [S30105, S30105] [STFN, STPN] [(STFN, ), (STPN, )] 5 Stephen tSephen [S30105, t50105] [STFN, TSFN] [(STFN, ), (TSFN, )] 6 Stephen Stephne [S30105, S301050] [STFN, STFN] [(STFN, ), (STFN, )] 7 Stephen Stphen [S30105, S3105] [STFN, STFN] [(STFN, ), (STFN, )] 8 Stephen Stepheb [S30105, S30101] [STFN, STFP] [(STFN, ), (STFP, )] 9 Stephen Stephanie [S30105, S301050] [STFN, STFN] [(STFN, ), (STFN, )] 10 Stephen Richard [S30105, R02063] [STFN, RXRT] [(STFN, ), (RXRT, RKRT)]"},{"location":"topic_guides/comparisons/choosing_comparators.html#combining-string-scores-and-phonetic-matching","title":"Combining String scores and Phonetic matching","text":"<p>Once you have considered all of the string comparators and phonetic transforms for a given column, you may decide that you would like to have multiple comparison levels including a combination of options.</p> <p>For this you can construct a custom comparison to catch all of the edge cases you want. For example, if you decide that the comparison for <code>first_name</code> in the model should consider:</p> <ol> <li>A <code>Dmetaphone</code> level for phonetic similarity</li> <li>A <code>Levenshtein</code> level with distance of 2 for typos</li> <li>A <code>Jaro-Winkler</code> level with similarity 0.8 for fuzzy matching</li> </ol> <pre><code>import splink.comparison_library as cl\nimport splink.comparison_level_library as cll\nfirst_name_comparison = cl.CustomComparison(\n    output_column_name=\"first_name\",\n    comparison_levels=[\n        cll.NullLevel(\"first_name\"),\n        cll.ExactMatchLevel(\"first_name\"),\n        cll.JaroWinklerLevel(\"first_name\", 0.9),\n        cll.LevenshteinLevel(\"first_name\", 0.8),\n        cll.ArrayIntersectLevel(\"first_name_dm\", 1),\n        cll.ElseLevel()\n    ]\n)\n\nprint(first_name_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'CustomComparison' of \"first_name\" and \"first_name_dm\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'Jaro-Winkler distance of first_name &gt;= 0.9' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.9\n    - 'Levenshtein distance of first_name &lt;= 0.8' with SQL rule: levenshtein(\"first_name_l\", \"first_name_r\") &lt;= 0.8\n    - 'Array intersection size &gt;= 1' with SQL rule: array_length(list_intersect(\"first_name_dm_l\", \"first_name_dm_r\")) &gt;= 1\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>where <code>first_name_dm</code> refers to a column in the dataset which has been created during the feature engineering step to give the <code>Dmetaphone</code> transform of <code>first_name</code>.</p>"},{"location":"topic_guides/comparisons/comparators.html","title":"String comparators","text":"","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#string-comparators","title":"String Comparators","text":"<p>There are a number of string comparator functions available in Splink that allow fuzzy matching for strings within <code>Comparisons</code> and <code>Comparison Levels</code>. For each of these fuzzy matching functions, below you will find explanations of how they work, worked examples and recommendations for the types of data they are useful for.</p> <p>For guidance on how to choose the most suitable string comparator, and associated threshold, see the dedicated topic guide.</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#levenshtein-distance","title":"Levenshtein Distance","text":"<p>At a glance</p> <p>Useful for: Data entry errors e.g. character miskeys. Splink comparison functions: levenshtein_level() and levenshtein_at_thresholds() Returns: An integer (lower is more similar).</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#description","title":"Description","text":"<p>Levenshtein distance, also known as edit distance, is a measure of the difference between two strings. It represents the minimum number of insertions, deletions, or substitutions of characters required to transform one string into the other.</p> <p>Or, as a formula,</p> \\[\\textsf{Levenshtein}(s_1, s_2) = \\min \\lbrace \\begin{array}{l} \\text{insertion , } \\text{deletion , } \\text{substitution} \\end{array} \\rbrace \\]","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#examples","title":"Examples","text":"\"KITTEN\" vs \"SITTING\" <p>The minimum number of operations to convert \"KITTEN\" into \"SITTING\" are:</p> <ul> <li>Substitute \"K\" in \"KITTEN\" with \"S\" to get \"SITTEN.\"</li> <li>Substitute \"E\" in \"SITTEN\" with \"I\" to get \"SITTIN.\"</li> <li>Insert \"G\" after \"N\" in \"SITTIN\" to get \"SITTING.\"</li> </ul> <p>Therefore,</p> \\[\\textsf{Levenshtein}(\\texttt{KITTEN}, \\texttt{SITTING}) = 3\\] \"CAKE\" vs \"ACKE\" <p>The minimum number of operations to convert \"CAKE\" into \"ACKE\" are:</p> <ul> <li>Substitute \"C\" in \"CAKE\" with \"A\" to get \"AAKE.\"</li> <li>substitute the second \"A\" in \"AAKE\" with \"C\" to get \"ACKE.\"</li> </ul> <p>Therefore,</p> \\[\\textsf{Levenshtein}(\\texttt{CAKE}, \\texttt{ACKE}) = 2\\]","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#sample-code","title":"Sample code","text":"<p>You can test out the Levenshtein distance as follows:</p> <pre><code>import duckdb\nduckdb.sql(\"SELECT levenshtein('CAKE', 'ACKE')\").df().iloc[0,0]\n</code></pre> <p>2</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#damerau-levenshtein-distance","title":"Damerau-Levenshtein Distance","text":"<p>At a glance</p> <p>Useful for: Data entry errors e.g. character transpositions and miskeys Splink comparison functions: damerau_levenshtein_level() and damerau_levenshtein_at_thresholds() Returns: An integer (lower is more similar).</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#description_1","title":"Description","text":"<p>Damerau-Levenshtein distance is a variation of Levenshtein distance that also includes transposition operations, which are the interchange of adjacent characters. This distance measures the minimum number of operations required to transform one string into another by allowing insertions, deletions, substitutions, and transpositions of characters.</p> <p>Or, as a formula,</p> \\[\\textsf{DamerauLevenshtein}(s_1, s_2) = \\min \\lbrace \\begin{array}{l} \\text{insertion , } \\text{deletion , } \\text{substitution , } \\text{transposition} \\end{array} \\rbrace \\]","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#examples_1","title":"Examples","text":"\"KITTEN\" vs \"SITTING\" <p>The minimum number of operations to convert \"KITTEN\" into \"SITTING\" are:</p> <ul> <li>Substitute \"K\" in \"KITTEN\" with \"S\" to get \"SITTEN\".</li> <li>Substitute \"E\" in \"SITTEN\" with \"I\" to get \"SITTIN\".</li> <li>Insert \"G\" after \"T\" in \"SITTIN\" to get \"SITTING\".</li> </ul> <p>Therefore,</p> \\[\\textsf{DamerauLevenshtein}(\\texttt{KITTEN}, \\texttt{SITTING}) = 3\\] \"CAKE\" vs \"ACKE\" <p>The minimum number of operations to convert \"CAKE\" into \"ACKE\" are:</p> <ul> <li>Transpose \"C\" and \"A\" in \"CAKE\" with \"A\" to get \"ACKE.\"</li> </ul> <p>Therefore,</p> \\[\\textsf{DamerauLevenshtein}(\\texttt{CAKE}, \\texttt{ACKE}) = 1\\]","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#sample-code_1","title":"Sample code","text":"<p>You can test out the Damerau-Levenshtein distance as follows:</p> <pre><code>import duckdb\nduckdb.sql(\"SELECT damerau_levenshtein('CAKE', 'ACKE')\").df().iloc[0,0]\n</code></pre> <p>1</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#jaro-similarity","title":"Jaro Similarity","text":"<p>At a glance</p> <p>Useful for:  Strings where all characters are considered equally important, regardless of order e.g. ID numbers Splink comparison functions: jaro_level() and jaro_at_thresholds() Returns:  A score between 0 and 1 (higher is more similar)</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#description_2","title":"Description","text":"<p>Jaro similarity is a measure of similarity between two strings. It takes into account the number and order of matching characters, as well as the number of transpositions needed to make the strings identical.</p> <p>Jaro similarity considers:</p> <ul> <li>The number of matching characters (characters in the same position in both strings).</li> <li>The number of transpositions (pairs of characters that are not in the same position in both strings).</li> </ul> <p>Or, as a formula:</p> \\[\\textsf{Jaro}(s_1, s_2) = \\frac{1}{3} \\left[ \\frac{m}{|s_1|} + \\frac{m}{|s_2|} + \\frac{m-t}{m} \\right]\\] <p>where:</p> <ul> <li>\\(s_1\\) and \\(s_2\\) are the two strings being compared</li> <li>\\(m\\) is the number of common characters (which are considered matching only if they are the same and not farther than \\(\\left\\lfloor \\frac{\\min(|s_1|,|s_2|)}{2} \\right\\rfloor - 1\\) characters apart)</li> <li>\\(t\\) is the number of transpositions (which is calculated as the number of matching characters that are not in the right order divided by two).</li> </ul>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#examples_2","title":"Examples","text":"\"MARTHA\" vs \"MARHTA\": <ul> <li>There are four matching characters: \"M\", \"A\", \"R\", and \"T\".</li> <li>There is one transposition: the fifth character in \"MARTHA\" (\"H\") is not in the same position as the fifth character in \"MARHTA\" (\"T\").</li> <li>We calculate the Jaro similarity using the formula:</li> </ul> \\[\\textsf{Jaro}(\\texttt{MARTHA}, \\texttt{MARHTA}) = \\frac{1}{3} \\left[ \\frac{4}{6} + \\frac{4}{6} + \\frac{4-1}{4} \\right] = 0.944\\] \"MARTHA\" vs \"AMRTHA\": <ul> <li>There are four matching characters: \"M\", \"A\", \"R\", and \"T\".</li> <li>There is one transposition: the first character in \"MARTHA\" (\"M\") is not in the same position as the first character in \"AMRTHA\" (\"T\").</li> <li>We calculate the Jaro similarity using the formula:</li> </ul> \\[\\textsf{Jaro}(\\texttt{MARTHA}, \\texttt{AMRTHA}) = \\frac{1}{3} \\left[ \\frac{4}{6} + \\frac{4}{6} + \\frac{4-1}{4} \\right] = 0.944\\] <p>Noting that transpositions of strings gives the same Jaro similarity regardless of order.</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#sample-code_2","title":"Sample code","text":"<p>You can test out the Jaro similarity as follows:</p> <pre><code>import duckdb\nduckdb.sql(\"SELECT jaro_similarity('MARTHA', 'MARHTA')\").df().iloc[0,0]\n</code></pre> <p>0.944</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#jaro-winkler-similarity","title":"Jaro-Winkler Similarity","text":"<p>At a glance</p> <p>Useful for: Strings where importance is weighted towards the first 4 characters e.g. Names Splink comparison functions: jaro_winkler_level() and jaro_winkler_at_thresholds() Returns:  A score between 0 and 1 (higher is more similar).</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#description_3","title":"Description","text":"<p>Jaro-Winkler similarity is a variation of Jaro similarity that gives extra weight to matching prefixes of the strings. It is particularly useful for names</p> <p>The Jaro-Winkler similarity is calculated as follows:</p> \\[\\textsf{JaroWinkler}(s_1, s_2) = \\textsf{Jaro}(s_1, s_2) + p \\cdot l \\cdot (1 - \\textsf{Jaro}(s_1, s_2))\\] <p>where: - \\(\\textsf{Jaro}(s_1, s_2)\\) is the Jaro similarity between the two strings - \\(l\\) is the length of the common prefix between the two strings, up to a maximum of four characters - \\(p\\) is a prefix scale factor, commonly set to 0.1.</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#examples_3","title":"Examples","text":"\"MARTHA\" vs \"MARHTA\" <p>The common prefix between the two strings is \"MAR\", which has a length of 3. We calculate the Jaro-Winkler similarity using the formula:</p> \\[\\textsf{Jaro-Winkler}(\\texttt{MARTHA}, \\texttt{MARHTA}) = 0.944 + 0.1 \\cdot 3 \\cdot (1 - 0.944) = 0.9612\\] <p>The Jaro-Winkler similarity is slightly higher than the Jaro similarity, due to the matching prefix.</p> \"MARTHA\" vs \"AMRTHA\": <p>There is no common prefix, so the Jaro-Winkler similarity formula gives:</p> \\[\\textsf{Jaro-Winkler}(\\texttt{MARTHA}, \\texttt{MARHTA}) = 0.944 + 0.1 \\cdot 0 \\cdot (1 - 0.944) = 0.944\\] <p>Which is the same as the Jaro score.</p> <p>Note that the Jaro-Winkler similarity should be used with caution, as it may not always provide better results than the standard Jaro similarity, especially when dealing with short strings or strings that have no common prefix.</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#sample-code_3","title":"Sample code","text":"<p>You can test out the Jaro similarity as follows:</p> <pre><code>import duckdb\nduckdb.sql(\"SELECT jaro_winkler_similarity('MARTHA', 'MARHTA')\").df().iloc[0,0]\n</code></pre> <p>0.9612</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#jaccard-similarity","title":"Jaccard Similarity","text":"<p>At a glance</p> <p>Useful for: Splink comparison functions: jaccard_level() and [jaccard_at_thresholds()](../../comparison_library.md#splink.comparison_library.JaccardAtThresholdsBase) Returns:  A score between 0 and 1 (higher is more similar).</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#description_4","title":"Description","text":"<p>Jaccard similarity is a measure of similarity between two sets of items, based on the size of their intersection (elements in common) and union (total elements across both sets). For strings, it considers the overlap of characters within each string. Mathematically, it can be represented as:</p> \\[\\textsf{Jaccard}=\\frac{|A \\cap B|}{|A \\cup B|}\\] <p>where A and B are two strings, and |A| and |B| represent their cardinalities (i.e., the number of elements in each set).</p> <p>In practice, Jaccard is more useful with strings that can be split up into multiple words as opposed to characters within a single word or string. E.g. tokens within addresses:</p> <p>Address 1: {\"flat\", \"2\", \"123\", \"high\", \"street\", \"london\", \"sw1\", \"1ab\"}</p> <p>Address 2: {\"2\", \"high\", \"street\", \"london\", \"sw1a\", \"1ab\"},</p> <p>where:</p> <ul> <li>there are 9 unique tokens across the addresses: \"flat\", \"2\", \"123\", \"high\", \"street\", \"london\", \"sw1\", \"sw1a\", \"1ab\"</li> <li>there are 5 tokens found in both addresses: \"2\", \"high\", \"street\", \"london\", \"1ab\"</li> </ul> <p>We calculate the Jaccard similarity using the formula:</p> \\[\\textsf{Jaccard}(\\textrm{Address1}, \\textrm{Address2})=\\frac{5}{9}=0.5556\\] <p>However, this functionality is not currently implemented within Splink</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#examples_4","title":"Examples","text":"\"DUCK\" vs \"LUCK\" <ul> <li>There are five unique characters across the strings: \"D\", \"U\", \"C\", \"K\", \"L\"</li> <li>Three are found in both strings: \"U\", \"C\", \"K\"</li> </ul> <p>We calculate the Jaccard similarity using the formula:</p> \\[\\textsf{Jaccard}(\\texttt{DUCK}, \\texttt{LUCK})=\\frac{3}{5}=0.6\\] \"MARTHA\" vs \"MARHTA\" <ul> <li>There are five unique characters across the strings: \"M\", \"A\", \"R\", \"T\", \"H\"</li> <li>Five are found in both strings: \"M\", \"A\", \"R\", \"T\", \"H\"</li> </ul> <p>We calculate the Jaccard similarity using the formula:</p> \\[\\textsf{Jaccard}(\\texttt{MARTHA}, \\texttt{MARHTA})=\\frac{5}{5}=1\\]","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparators.html#sample-code_4","title":"Sample code","text":"<p>You can test out the Jaccard similarity between two strings with the function below:</p> <pre><code>def jaccard_similarity(str1, str2):\n        set1 = set(str1)\n        set2 = set(str2)\n        return len(set1 &amp; set2) / len(set1 | set2)\n\njaccard_similarity(\"DUCK\", \"LUCK\")\n</code></pre> <p>0.6</p>","tags":["API","comparisons","Levenshtein","Damerau-Levenshtein","Jaro","Jaro-Winkler","Jaccard"]},{"location":"topic_guides/comparisons/comparisons_and_comparison_levels.html","title":"Comparisons and comparison levels","text":""},{"location":"topic_guides/comparisons/comparisons_and_comparison_levels.html#comparison-and-comparisonlevels","title":"Comparison and ComparisonLevels","text":""},{"location":"topic_guides/comparisons/comparisons_and_comparison_levels.html#comparing-information","title":"Comparing information","text":"<p>To find matching records, Splink creates pairwise record comparisons from the input records, and scores these comparisons.</p> <p>Suppose for instance your data contains <code>first_name</code> and <code>surname</code> and <code>dob</code>:</p> id first_name surname dob 1 john smith 1991-04-11 2 jon smith 1991-04-17 3 john smyth 1991-04-11 <p>To compare these records, at the blocking stage, Splink will set these records against each other in a table of pairwise record comparisons:</p> id_l id_r first_name_l first_name_r surname_l surname_r dob_l dob_r 1 2 john jon smith smith 1991-04-11 1991-04-17 1 3 john john smith smyth 1991-04-11 1991-04-11 2 3 jon john smith smyth 1991-04-17 1991-04-11 <p>When defining comparisons, we are defining rules that operate on each row of this latter table of pairwise comparisons</p>"},{"location":"topic_guides/comparisons/comparisons_and_comparison_levels.html#defining-similarity","title":"Defining similarity","text":"<p>How how should we assess similarity between the records?</p> <p>In Splink, we will use different measures of similarity for different columns in the data, and then combine these measures to get an overall similarity score.  But the most appropriate definition of similarity will differ between columns.</p> <p>For example, two surnames that differ by a single character would usually be considered to be similar.  But a one character difference in a 'gender' field encoded as <code>M</code> or <code>F</code> is not similar at all!</p> <p>To allow for this, Splink uses the concepts of <code>Comparison</code>s and <code>ComparisonLevel</code>s.  Each <code>Comparison</code> usually measures the similarity of a single column in the data, and each <code>Comparison</code> is made up of one or more <code>ComparisonLevel</code>s.</p> <p>Within each <code>Comparison</code> are n discrete <code>ComparisonLevel</code>s.  Each <code>ComparisonLevel</code> defines a discrete gradation (category) of similarity within a Comparison.  There can be as many <code>ComparisonLevels</code> as you want. For example:</p> <pre><code>Data Linking Model\n\u251c\u2500-- Comparison: Gender\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n\u251c\u2500-- Comparison: First name\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match on surname\n\u2502    \u251c\u2500-- ComparisonLevel: surnames have JaroWinklerSimilarity &gt; 0.95\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n</code></pre> <p>The categories are discrete rather than continuous for performance reasons - so for instance, a <code>ComparisonLevel</code> may be defined as <code>jaro winkler similarity between &gt; 0.95</code>, as opposed to using the Jaro-Winkler score as a continuous measure directly.</p> <p>It is up to the user to decide how best to define similarity for the different columns (fields) in their data, and this is a key part of modelling a record linkage problem.</p> <p>A much more detailed of how this works can be found in this series of interactive tutorials - refer in particular to computing the Fellegi Sunter model.</p>"},{"location":"topic_guides/comparisons/comparisons_and_comparison_levels.html#an-example","title":"An example:","text":"<p>The concepts of <code>Comparison</code>s and <code>ComparisonLevel</code>s are best explained using an example.</p> <p>Consider the following simple data linkage model with only two columns (in a real example there would usually be more):</p> <pre><code>Data Linking Model\n\u251c\u2500-- Comparison: Date of birth\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match\n\u2502    \u251c\u2500-- ComparisonLevel: One character difference\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n\u251c\u2500-- Comparison: First name\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match on first_name\n\u2502    \u251c\u2500-- ComparisonLevel: first_names have JaroWinklerSimilarity &gt; 0.95\n\u2502    \u251c\u2500-- ComparisonLevel: first_names have JaroWinklerSimilarity &gt; 0.8\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n</code></pre> <p>In this model we have two <code>Comparison</code>s: one for date of birth and one for first name:</p> <p>For date of birth, we have chosen three discrete <code>ComparisonLevel</code>s to measure similarity.  Either the dates of birth are an exact match, they differ by one character, or they are different in some other way.</p> <p>For first name, we have chosen four discrete <code>ComparisonLevel</code>s to measure similarity.  Either the first names are an exact match, they have a JaroWinkler similarity of greater than 0.95, they have a JaroWinkler similarity of greater than 0.8, or they are different in some other way.</p> <p>Note that these definitions are mutually exclusive, because they're implemented by Splink like an if statement.  For example, for first name, the <code>Comparison</code> is equivalent to the following pseudocode:</p> <pre><code>if first_name_l_ == first_name_r:\n    return \"Assign to category: Exact match\"\nelif JaroWinklerSimilarity(first_name_l_, first_name_r) &gt; 0.95:\n    return \"Assign to category: JaroWinklerSimilarity &gt; 0.95\"\nelif JaroWinklerSimilarity(first_name_l_, first_name_r) &gt; 0.8:\n    return \"Assign to category: JaroWinklerSimilarity &gt; 0.8\"\nelse:\n    return \"Assign to category: All other\"\n</code></pre> <p>In the next section, we will see how to define these <code>Comparison</code>s and <code>ComparisonLevel</code>s in Splink.</p>"},{"location":"topic_guides/comparisons/customising_comparisons.html","title":"Defining and customising comparisons","text":""},{"location":"topic_guides/comparisons/customising_comparisons.html#defining-and-customising-how-record-comparisons-are-made","title":"Defining and customising how record comparisons are made","text":"<p>A key feature of Splink is the ability to customise how record comparisons are made - that is, how similarity is defined for different data types.  For example, the definition of similarity that is appropriate for a date of birth field is different than for a first name field.</p> <p>By tailoring the definitions of similarity, linking models are more effectively able to distinguish between different gradations of similarity, leading to more accurate data linking models.</p>"},{"location":"topic_guides/comparisons/customising_comparisons.html#comparisons-and-comparisonlevels","title":"<code>Comparisons</code> and <code>ComparisonLevels</code>","text":"<p>Recall that a Splink model contains a collection of <code>Comparisons</code> and <code>ComparisonLevels</code> organised in a hierarchy.  </p> <p>Each <code>ComparisonLevel</code> defines the different gradations of similarity that make up a <code>Comparison</code>.</p> <p>An example is as follows:</p> <pre><code>Data Linking Model\n\u251c\u2500-- Comparison: Date of birth\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match\n\u2502    \u251c\u2500-- ComparisonLevel: Up to one character difference\n\u2502    \u251c\u2500-- ComparisonLevel: Up to three character difference\n\u2502    \u251c\u2500-- ComparisonLevel: All other\n\u251c\u2500-- Comparison: Name\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match on first name and surname\n\u2502    \u251c\u2500-- ComparisonLevel: Exact match on first name\n\u2502    \u251c\u2500-- etc.\n</code></pre>"},{"location":"topic_guides/comparisons/customising_comparisons.html#three-ways-of-specifying-comparisons","title":"Three ways of specifying Comparisons","text":"<p>In Splink, there are three ways of specifying <code>Comparisons</code>:</p> <ul> <li>Using 'out-of-the-box' <code>Comparison</code>s (Most simple/succinct)</li> <li>Composing pre-defined <code>ComparisonLevels</code> </li> <li>Writing a full dictionary spec of a <code>Comparison</code> by hand (most verbose/flexible)</li> </ul>"},{"location":"topic_guides/comparisons/customising_comparisons.html#method-1-using-the-comparisonlibrary","title":"Method 1: Using the <code>ComparisonLibrary</code>","text":"<p>The <code>ComparisonLibrary</code>  contains pre-baked similarity functions that cover many common use cases.</p> <p>These functions generate an entire <code>Comparison</code>, composed of several <code>ComparisonLevels</code>.</p> <p>You can find a listing of all available <code>Comparison</code>s at the page for its API documentation here</p> <p>The following provides an example of using the <code>ExactMatch</code> <code>Comparison</code>, and producing the description (with associated SQL) for the <code>duckdb</code> backend:</p> <pre><code>import splink.comparison_library as cl\n\nfirst_name_comparison = cl.ExactMatch(\"first_name\")\nprint(first_name_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'ExactMatch' of \"first_name\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>Note that, under the hood, these functions generate a Python dictionary, which conforms to the underlying <code>.json</code> specification of a model:</p> <pre><code>first_name_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <pre><code>{'output_column_name': 'first_name',\n 'comparison_levels': [{'sql_condition': '\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL',\n   'label_for_charts': 'first_name is NULL',\n   'is_null_level': True},\n  {'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n   'label_for_charts': 'Exact match on first_name'},\n  {'sql_condition': 'ELSE', 'label_for_charts': 'All other comparisons'}],\n 'comparison_description': 'ExactMatch'}\n</code></pre> <p>We can now generate a second, more complex comparison using one of our data-specific comparisons, the <code>PostcodeComparison</code>:</p> <pre><code>pc_comparison = cl.PostcodeComparison(\"postcode\")\nprint(pc_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'PostcodeComparison' of \"postcode\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on full postcode' with SQL rule: \"postcode_l\" = \"postcode_r\"\n    - 'Exact match on sector' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '')\n    - 'Exact match on district' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '')\n    - 'Exact match on area' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}', 0), '')\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>For a deep dive on out of the box comparisons, see the dedicated topic guide.</p> <p>Comparisons can be further configured using the <code>.configure()</code> method - full API docs here.</p>"},{"location":"topic_guides/comparisons/customising_comparisons.html#method-2-comparisonlevels","title":"Method 2: <code>ComparisonLevels</code>","text":"<p><code>ComparisonLevels</code> provide a lower-level API that allows you to compose your own comparisons.</p> <p>For example, the user may wish to specify a comparison that has levels for a match on soundex and jaro_winkler of the <code>first_name</code> field.  </p> <p>The below example assumes the user has derived a column <code>soundex_first_name</code> which contains the soundex of the first name.</p> <pre><code>from splink.comparison_library import CustomComparison\nimport splink.comparison_level_library as cll\n\ncustom_name_comparison = CustomComparison(\n    output_column_name=\"first_name\",\n    comparison_levels=[\n        cll.NullLevel(\"first_name\"),\n        cll.ExactMatchLevel(\"first_name\").configure(tf_adjustment_column=\"first_name\"),\n        cll.ExactMatchLevel(\"soundex_first_name\").configure(\n            tf_adjustment_column=\"soundex_first_name\"\n        ),\n        cll.ElseLevel(),\n    ],\n)\n\nprint(custom_name_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'CustomComparison' of \"first_name\" and \"soundex_first_name\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'Exact match on soundex_first_name' with SQL rule: \"soundex_first_name_l\" = \"soundex_first_name_r\"\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>This can now be specified in the settings dictionary as follows:</p> <pre><code>from splink import SettingsCreator, block_on\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    comparisons=[\n        custom_name_comparison,\n        cl.LevenshteinAtThresholds(\"dob\", [1, 2]),\n    ],\n)\n</code></pre> <p>To inspect the custom comparison as a dictionary, you can call <code>custom_name_comparison.get_comparison(\"duckdb\").as_dict()</code></p> <p>Note that <code>ComparisonLevels</code> can be further configured using the <code>.configure()</code> method - full API documentation here </p>"},{"location":"topic_guides/comparisons/customising_comparisons.html#method-3-providing-the-spec-as-a-dictionary","title":"Method 3: Providing the spec as a dictionary","text":"<p>Behind the scenes in Splink, all <code>Comparisons</code> are eventually turned into a dictionary which conforms to the formal <code>jsonschema</code> specification of the settings dictionary and here.</p> <p>The library functions described above are convenience functions that provide a shorthand way to produce valid dictionaries.</p> <p>For maximum control over your settings, you can specify your comparisons as a dictionary.</p> <pre><code>comparison_first_name = {\n    \"output_column_name\": \"first_name\",\n    \"comparison_levels\": [\n        {\n            \"sql_condition\": \"first_name_l IS NULL OR first_name_r IS NULL\",\n            \"label_for_charts\": \"Null\",\n            \"is_null_level\": True,\n        },\n        {\n            \"sql_condition\": \"first_name_l = first_name_r\",\n            \"label_for_charts\": \"Exact match\",\n            \"tf_adjustment_column\": \"first_name\",\n            \"tf_adjustment_weight\": 1.0,\n            \"tf_minimum_u_value\": 0.001,\n        },\n        {\n            \"sql_condition\": \"dmeta_first_name_l = dmeta_first_name_r\",\n            \"label_for_charts\": \"Exact match\",\n            \"tf_adjustment_column\": \"dmeta_first_name\",\n            \"tf_adjustment_weight\": 1.0,\n        },\n        {\n            \"sql_condition\": \"jaro_winkler_sim(first_name_l, first_name_r) &gt; 0.8\",\n            \"label_for_charts\": \"Exact match\",\n            \"tf_adjustment_column\": \"first_name\",\n            \"tf_adjustment_weight\": 0.5,\n            \"tf_minimum_u_value\": 0.001,\n        },\n        {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\"},\n    ],\n}\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    comparisons=[\n        comparison_first_name,\n        cl.LevenshteinAtThresholds(\"dob\", [1, 2]),\n    ],\n)\n</code></pre>"},{"location":"topic_guides/comparisons/customising_comparisons.html#examples","title":"Examples","text":"<p>Below are some examples of how you can define the same comparison, but through different methods.</p>"},{"location":"topic_guides/comparisons/customising_comparisons.html#exact-match-comparison-with-term-frequency-adjustments","title":"Exact match Comparison with Term-Frequency Adjustments","text":"Comparison LibraryComparison Level LibrarySettings Dictionary <pre><code>import splink.comparison_library as cl\n\nfirst_name_comparison = cl.ExactMatch(\"first_name\").configure(\n    term_frequency_adjustments=True\n)\n</code></pre> <pre><code>import splink.comparison_level_library as cll\n\nfirst_name_comparison = cl.CustomComparison(\n    output_column_name=\"first_name\",\n    comparison_description=\"Exact match vs. anything else\",\n    comparison_levels=[\n        cll.NullLevel(\"first_name\"),\n        cll.ExactMatchLevel(\"first_name\").configure(tf_adjustment_column=\"first_name\"),\n        cll.ElseLevel(),\n    ],\n)\n</code></pre> <pre><code>first_name_comparison = {\n    'output_column_name': 'first_name',\n    'comparison_levels': [\n        {\n            'sql_condition': '\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL',\n            'label_for_charts': 'Null',\n            'is_null_level': True\n        },\n        {\n            'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n            'label_for_charts': 'Exact match',\n            'tf_adjustment_column': 'first_name',\n            'tf_adjustment_weight': 1.0\n        },\n        {\n            'sql_condition': 'ELSE', \n            'label_for_charts': 'All other comparisons'\n        }],\n    'comparison_description': 'Exact match vs. anything else'\n}\n</code></pre> <p>Each of which gives</p> <p></p><pre><code>{\n    'output_column_name': 'first_name',\n    'comparison_levels': [\n        {\n            'sql_condition': '\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL',\n            'label_for_charts': 'Null',\n            'is_null_level': True\n        },\n        {\n            'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n            'label_for_charts': 'Exact match',\n            'tf_adjustment_column': 'first_name',\n            'tf_adjustment_weight': 1.0\n        },\n        {\n            'sql_condition': 'ELSE', \n            'label_for_charts': 'All other comparisons'\n        }],\n    'comparison_description': 'Exact match vs. anything else'\n}\n</code></pre> in your settings dictionary."},{"location":"topic_guides/comparisons/customising_comparisons.html#levenshtein-comparison","title":"Levenshtein Comparison","text":"Comparison LibraryComparison Level LibrarySettings Dictionary <pre><code>import splink.comparison_library as cl\n\nemail_comparison = cl.LevenshteinAtThresholds(\"email\", [2, 4])\n</code></pre> <pre><code>import splink.comparison_library as cl\nimport splink.comparison_level_library as cll\n\nemail_comparison = cl.CustomComparison(\n    output_column_name=\"email\",\n    comparison_description=\"Exact match vs. Email within levenshtein thresholds 2, 4 vs. anything else\",\n    comparison_levels=[\n        cll.NullLevel(\"email\"),\n        cll.LevenshteinLevel(\"email\", distance_threshold=2),\n        cll.LevenshteinLevel(\"email\", distance_threshold=4),\n        cll.ElseLevel(),\n    ],\n)\n</code></pre> <pre><code>email_comparison = {\n    'output_column_name': 'email',\n    'comparison_levels': [{'sql_condition': '\"email_l\" IS NULL OR \"email_r\" IS NULL',\n    'label_for_charts': 'Null',\n    'is_null_level': True},\n    {\n        'sql_condition': '\"email_l\" = \"email_r\"',\n        'label_for_charts': 'Exact match'\n    },\n    {\n        'sql_condition': 'levenshtein(\"email_l\", \"email_r\") &lt;= 2',\n        'label_for_charts': 'Levenshtein &lt;= 2'\n    },\n    {\n        'sql_condition': 'levenshtein(\"email_l\", \"email_r\") &lt;= 4',\n        'label_for_charts': 'Levenshtein &lt;= 4'\n    },\n    {\n        'sql_condition': 'ELSE', \n        'label_for_charts': 'All other comparisons'\n    }],\n    'comparison_description': 'Exact match vs. Email within levenshtein thresholds 2, 4 vs. anything else'}\n</code></pre> <p>Each of which gives</p> <pre><code>{\n    'output_column_name': 'email',\n    'comparison_levels': [\n        {\n            'sql_condition': '\"email_l\" IS NULL OR \"email_r\" IS NULL',\n            'label_for_charts': 'Null',\n            'is_null_level': True},\n        {\n            'sql_condition': '\"email_l\" = \"email_r\"',\n            'label_for_charts': 'Exact match'\n        },\n        {\n            'sql_condition': 'levenshtein(\"email_l\", \"email_r\") &lt;= 2',\n            'label_for_charts': 'Levenshtein &lt;= 2'\n        },\n        {\n            'sql_condition': 'levenshtein(\"email_l\", \"email_r\") &lt;= 4',\n            'label_for_charts': 'Levenshtein &lt;= 4'\n        },\n        {\n            'sql_condition': 'ELSE', \n            'label_for_charts': 'All other comparisons'\n        }],\n    'comparison_description': 'Exact match vs. Email within levenshtein thresholds 2, 4 vs. anything else'\n}\n</code></pre> <p>in your settings dictionary.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html","title":"Out-of-the-box comparisons","text":""},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#out-of-the-box-comparisons-for-specific-data-types","title":"Out-of-the-box <code>Comparisons</code> for specific data types","text":"<p>Splink has pre-defined <code>Comparison</code>s available for variety of data types.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#dateofbirthcomparison","title":"DateOfBirthComparison","text":"<p>You can find full API docs for <code>DateOfBirthComparison</code> here</p> <pre><code>import splink.comparison_library as cl\n\ndate_of_birth_comparison = cl.DateOfBirthComparison(\n    \"date_of_birth\",\n    input_is_string=True,\n)\n</code></pre> <p>You can view the structure of the comparison as follows:</p> <pre><code>print(date_of_birth_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'DateOfBirthComparison' of \"date_of_birth\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'transformed date_of_birth is NULL' with SQL rule: try_strptime(\"date_of_birth_l\", '%Y-%m-%d') IS NULL OR try_strptime(\"date_of_birth_r\", '%Y-%m-%d') IS NULL\n    - 'Exact match on date of birth' with SQL rule: \"date_of_birth_l\" = \"date_of_birth_r\"\n    - 'DamerauLevenshtein distance &lt;= 1' with SQL rule: damerau_levenshtein(\"date_of_birth_l\", \"date_of_birth_r\") &lt;= 1\n    - 'Abs date difference &lt;= 1 month' with SQL rule: ABS(EPOCH(try_strptime(\"date_of_birth_l\", '%Y-%m-%d')) - EPOCH(try_strptime(\"date_of_birth_r\", '%Y-%m-%d'))) &lt;= 2629800.0\n    - 'Abs date difference &lt;= 1 year' with SQL rule: ABS(EPOCH(try_strptime(\"date_of_birth_l\", '%Y-%m-%d')) - EPOCH(try_strptime(\"date_of_birth_r\", '%Y-%m-%d'))) &lt;= 31557600.0\n    - 'Abs date difference &lt;= 10 year' with SQL rule: ABS(EPOCH(try_strptime(\"date_of_birth_l\", '%Y-%m-%d')) - EPOCH(try_strptime(\"date_of_birth_r\", '%Y-%m-%d'))) &lt;= 315576000.0\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>To see this as a specifications dictionary you can use:</p> <pre><code>date_of_birth_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <p>which can be used as the basis for a more custom comparison, as shown in the Defining and Customising Comparisons topic guide , if desired.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#name-comparison","title":"Name Comparison","text":"<p>A Name comparison is intended for use on an individual name column (e.g. forename, surname) </p> <p>You can find full API docs for <code>NameComparison</code> here</p> <pre><code>import splink.comparison_library as cl\n\nfirst_name_comparison = cl.NameComparison(\"first_name\")\n</code></pre> <pre><code>print(first_name_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'NameComparison' of \"first_name\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'Jaro-Winkler distance of first_name &gt;= 0.92' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92\n    - 'Jaro-Winkler distance of first_name &gt;= 0.88' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88\n    - 'Jaro-Winkler distance of first_name &gt;= 0.7' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.7\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>The NameComparison  also allows flexibility to change the parameters and/or fuzzy matching comparison levels.</p> <p>For example:</p> <pre><code>surname_comparison = cl.NameComparison(\n    \"surname\",\n    jaro_winkler_thresholds=[0.95, 0.9],\n    dmeta_col_name=\"surname_dmeta\",\n)\nprint(surname_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'NameComparison' of \"surname\" and \"surname_dmeta\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'surname is NULL' with SQL rule: \"surname_l\" IS NULL OR \"surname_r\" IS NULL\n    - 'Exact match on surname' with SQL rule: \"surname_l\" = \"surname_r\"\n    - 'Jaro-Winkler distance of surname &gt;= 0.95' with SQL rule: jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.95\n    - 'Jaro-Winkler distance of surname &gt;= 0.9' with SQL rule: jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.9\n    - 'Array intersection size &gt;= 1' with SQL rule: array_length(list_intersect(\"surname_dmeta_l\", \"surname_dmeta_r\")) &gt;= 1\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>Where <code>surname_dm</code> refers to a column which has used the DoubleMetaphone algorithm on <code>surname</code> to give a phonetic spelling. This helps to catch names which sounds the same but have different spellings (e.g. Stephens vs Stevens). For more on Phonetic Transformations, see the topic guide.</p> <p>To see this as a specifications dictionary you can call</p> <pre><code>surname_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <p>which can be used as the basis for a more custom comparison, as shown in the Defining and Customising Comparisons topic guide , if desired.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#forename-and-surname-comparison","title":"Forename and Surname Comparison","text":"<p>It can be helpful to construct a single comparison for for comparing the forename and surname because:</p> <ol> <li> <p>The Fellegi-Sunter model assumes that columns are independent. We know that forename and surname are usually correlated given the regional variation of names etc, so considering then in a single comparison can help to create better models.</p> <p>As a result term-frequencies of individual forename and surname individually does not necessarily reflect how common the combination of forename and surname are.  For more information on term-frequencies, see the dedicated topic guide. Combining forename and surname in a single comparison can allows the model to consider the joint term-frequency as well as individual.</p> </li> <li> <p>It is common for some records to have swapped forename and surname by mistake. Addressing forename and surname in a single comparison can allows the model to consider these name inversions.</p> </li> </ol> <p>The <code>ForenameSurnameComparison</code> has been designed to accomodate this.</p> <p>You can find full API docs for <code>ForenameSurnameComparison</code> here</p> <pre><code>import splink.comparison_library as cl\n\nfull_name_comparison = cl.ForenameSurnameComparison(\"forename\", \"surname\")\n</code></pre> <pre><code>print(full_name_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'ForenameSurnameComparison' of \"forename\" and \"surname\".\nSimilarity is assessed using the following ComparisonLevels:\n    - '(forename is NULL) AND (surname is NULL)' with SQL rule: (\"forename_l\" IS NULL OR \"forename_r\" IS NULL) AND (\"surname_l\" IS NULL OR \"surname_r\" IS NULL)\n    - '(Exact match on forename) AND (Exact match on surname)' with SQL rule: (\"forename_l\" = \"forename_r\") AND (\"surname_l\" = \"surname_r\")\n    - 'Match on reversed cols: forename and surname' with SQL rule: \"forename_l\" = \"surname_r\" AND \"forename_r\" = \"surname_l\"\n    - '(Jaro-Winkler distance of forename &gt;= 0.92) AND (Jaro-Winkler distance of surname &gt;= 0.92)' with SQL rule: (jaro_winkler_similarity(\"forename_l\", \"forename_r\") &gt;= 0.92) AND (jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.92)\n    - '(Jaro-Winkler distance of forename &gt;= 0.88) AND (Jaro-Winkler distance of surname &gt;= 0.88)' with SQL rule: (jaro_winkler_similarity(\"forename_l\", \"forename_r\") &gt;= 0.88) AND (jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.88)\n    - 'Exact match on surname' with SQL rule: \"surname_l\" = \"surname_r\"\n    - 'Exact match on forename' with SQL rule: \"forename_l\" = \"forename_r\"\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>As noted in the feature engineering guide, to take advantage of term frequency adjustments on full name, you need to derive a full name column prior to importing data into Splink.  You then provide the column name using the <code>forename_surname_concat_col_name</code> argument:</p> <pre><code>full_name_comparison = cl.ForenameSurnameComparison(\"forename\", \"surname\", forename_surname_concat_col_name=\"first_and_last_name\")\n</code></pre> <p>To see this as a specifications dictionary you can call</p> <pre><code>full_name_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <p>Which can be used as the basis for a more custom comparison, as shown in the Defining and Customising Comparisons topic guide , if desired.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#postcode-comparisons","title":"Postcode Comparisons","text":"<p>See Feature Engineering for more details.</p> <pre><code>import splink.comparison_library as cl\n\npc_comparison = cl.PostcodeComparison(\"postcode\")\n</code></pre> <pre><code>print(pc_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'PostcodeComparison' of \"postcode\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on full postcode' with SQL rule: \"postcode_l\" = \"postcode_r\"\n    - 'Exact match on sector' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '')\n    - 'Exact match on district' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '')\n    - 'Exact match on area' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}', 0), '')\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>If you have derived lat long columns, you can model geographical distances.  </p> <pre><code>pc_comparison = cl.PostcodeComparison(\"postcode\", lat_col=\"lat\", long_col=\"long\", km_thresholds=[1,10,50])\nprint(pc_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'PostcodeComparison' of \"postcode\", \"long\" and \"lat\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on postcode' with SQL rule: \"postcode_l\" = \"postcode_r\"\n    - 'Exact match on transformed postcode' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '')\n    - 'Distance in km &lt;= 1' with SQL rule:  cast( acos( case when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &gt; 1 then 1 when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &lt; -1 then -1 else ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) end ) * 6371 as float ) &lt;= 1\n    - 'Distance in km &lt;= 10' with SQL rule:  cast( acos( case when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &gt; 1 then 1 when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &lt; -1 then -1 else ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) end ) * 6371 as float ) &lt;= 10\n    - 'Distance in km &lt;= 50' with SQL rule:  cast( acos( case when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &gt; 1 then 1 when ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) &lt; -1 then -1 else ( sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) + cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") ) * cos( radians(\"long_r\" - \"long_l\") ) ) end ) * 6371 as float ) &lt;= 50\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>To see this as a specifications dictionary you can call</p> <pre><code>pc_comparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> <p>which can be used as the basis for a more custom comparison, as shown in the Defining and Customising Comparisons topic guide , if desired.</p>"},{"location":"topic_guides/comparisons/out_of_the_box_comparisons.html#email-comparison","title":"Email Comparison","text":"<p>You can find full API docs for <code>EmailComparison</code> here</p> <pre><code>import splink.comparison_library as cl\n\nemail_comparison = cl.EmailComparison(\"email\")\n</code></pre> <pre><code>print(email_comparison.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'EmailComparison' of \"email\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'email is NULL' with SQL rule: \"email_l\" IS NULL OR \"email_r\" IS NULL\n    - 'Exact match on email' with SQL rule: \"email_l\" = \"email_r\"\n    - 'Exact match on username' with SQL rule: NULLIF(regexp_extract(\"email_l\", '^[^@]+', 0), '') = NULLIF(regexp_extract(\"email_r\", '^[^@]+', 0), '')\n    - 'Jaro-Winkler distance of email &gt;= 0.88' with SQL rule: jaro_winkler_similarity(\"email_l\", \"email_r\") &gt;= 0.88\n    - 'Jaro-Winkler &gt;0.88 on username' with SQL rule: jaro_winkler_similarity(NULLIF(regexp_extract(\"email_l\", '^[^@]+', 0), ''), NULLIF(regexp_extract(\"email_r\", '^[^@]+', 0), '')) &gt;= 0.88\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>To see this as a specifications dictionary you can call</p> <pre><code>email_comparison.as_dict()\n</code></pre> <p>which can be used as the basis for a more custom comparison, as shown in the Defining and Customising Comparisons topic guide , if desired.</p>"},{"location":"topic_guides/comparisons/phonetic.html","title":"Phonetic algorithms","text":"","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/phonetic.html#phonetic-transformation-algorithms","title":"Phonetic transformation algorithms","text":"<p>Phonetic transformation algorithms can be used to identify words that sound similar, even if they are spelled differently (e.g. \"Stephen\" vs \"Steven\"). These algorithms to give another type of fuzzy match and are often generated in the Feature Engineering step of record linkage.</p> <p>Once generated, phonetic matches can be used within comparisons &amp; comparison levels and blocking rules.</p> <pre><code>import splink.comparison_library as cl\n\nfirst_name_comparison = cl.NameComparison(\n                        \"first_name\",\n                        dmeta_col_name= \"first_name_dm\")\nprint(first_name_comparison.human_readable_description)\n</code></pre> <pre><code>Comparison 'NameComparison' of \"first_name\" and \"first_name_dm\".\nSimilarity is assessed using the following ComparisonLevels:\n\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'Jaro-Winkler distance of first_name &gt;= 0.92' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92\n    - 'Jaro-Winkler distance of first_name &gt;= 0.88' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88\n    - 'Array intersection size &gt;= 1' with SQL rule: array_length(list_intersect(\"first_name_dm_l\", \"first_name_dm_r\")) &gt;= 1\n    - 'Jaro-Winkler distance of first_name &gt;= 0.7' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.7\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre>","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/phonetic.html#algorithms","title":"Algorithms","text":"<p>Below are some examples of well known phonetic transformation algorithms.</p>","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/phonetic.html#soundex","title":"Soundex","text":"<p>Soundex is a phonetic algorithm that assigns a code to words based on their sound. The Soundex algorithm works by converting a word into a four-character code, where the first character is the first letter of the word, and the next three characters are numerical codes representing the word's remaining consonants. Vowels and some consonants, such as H, W, and Y, are ignored.</p> Algorithm Steps <p>The Soundex algorithm works by following these steps:</p> <ol> <li> <p>Retain the first letter of the word and remove all other vowels and the letters \"H\", \"W\", and \"Y\".</p> </li> <li> <p>Replace each remaining consonant (excluding the first letter) with a numerical code as follows:</p> <ol> <li>B, F, P, and V are replaced with \"1\"</li> <li>C, G, J, K, Q, S, X, and Z are replaced with \"2\"</li> <li>D and T are replaced with \"3\"</li> <li>L is replaced with \"4\"</li> <li>M and N are replaced with \"5\"</li> <li>R is replaced with \"6\"</li> </ol> </li> <li> <p>Combine the first letter and the numerical codes to form a four-character code. If there are fewer than four characters, pad the code with zeros.</p> </li> </ol> Example <p>You can test out the Soundex transformation between two strings through the phonetics package.</p> <pre><code>import phonetics\nprint(phonetics.soundex(\"Smith\"), phonetics.soundex(\"Smyth\"))\n</code></pre> <p>S5030 S5030</p>","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/phonetic.html#metaphone","title":"Metaphone","text":"<p>Metaphone is an improved version of the Soundex algorithm that was developed to handle a wider range of words and languages. The Metaphone algorithm assigns a code to a word based on its phonetic pronunciation, but it takes into account the sound of the entire word, rather than just its first letter and consonants. The Metaphone algorithm works by applying a set of rules to the word's pronunciation, such as converting the \"TH\" sound to a \"T\" sound, or removing silent letters. The resulting code is a variable-length string of letters that represents the word's pronunciation.</p> Algorithm Steps <p>The Metaphone algorithm works by following these steps:</p> <ol> <li> <p>Convert the word to uppercase and remove all non-alphabetic characters.</p> </li> <li> <p>Apply a set of pronunciation rules to the word, such as:</p> <ol> <li>Convert the letters \"C\" and \"K\" to \"K\"</li> <li>Convert the letters \"PH\" to \"F\"</li> <li>Convert the letters \"W\" and \"H\" to nothing if they are not at the beginning of the word</li> </ol> </li> <li> <p>Apply a set of replacement rules to the resulting word, such as:</p> <ol> <li>Replace the letter \"G\" with \"J\" if it is followed by an \"E\", \"I\", or \"Y\"</li> <li>Replace the letter \"C\" with \"S\" if it is followed by an \"E\", \"I\", or \"Y\"</li> <li>Replace the letter \"X\" with \"KS\"</li> </ol> </li> <li> <p>If the resulting word ends with \"S\", remove it.</p> </li> <li> <p>If the resulting word ends with \"ED\", \"ING\", or \"ES\", remove it.</p> </li> <li> <p>If the resulting word starts with \"KN\", \"GN\", \"PN\", \"AE\", \"WR\", or \"WH\", remove the first letter.</p> </li> <li> <p>If the resulting word starts with a vowel, retain the first letter.</p> </li> <li> <p>Retain the first four characters of the resulting word, or pad it with zeros if it has fewer than four characters.</p> </li> </ol> Example <p>You can test out the Metaphone transformation between two strings through the phonetics package.</p> <pre><code>import phonetics\nprint(phonetics.metaphone(\"Smith\"), phonetics.metaphone(\"Smyth\"))\n</code></pre> <p>SM0 SM0</p>","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/phonetic.html#double-metaphone","title":"Double Metaphone","text":"<p>Double Metaphone is an extension of the Metaphone algorithm that generates two codes for each word, one for the primary pronunciation and one for an alternate pronunciation. The Double Metaphone algorithm is designed to handle a wide range of languages and dialects, and it is more accurate than the original Metaphone algorithm.</p> <p>The Double Metaphone algorithm works by applying a set of rules to the word's pronunciation, similar to the Metaphone algorithm, but it generates two codes for each word. The primary code is the most likely pronunciation of the word, while the alternate code represents a less common pronunciation.</p> Algorithm Steps Standard Double MetaphoneAlternative Double Metaphone <p>The Double Metaphone algorithm works by following these steps:</p> <ol> <li> <p>Convert the word to uppercase and remove all non-alphabetic characters.</p> </li> <li> <p>Apply a set of pronunciation rules to the word, such as:</p> <ol> <li>Convert the letters \"C\" and \"K\" to \"K\"</li> <li>Convert the letters \"PH\" to \"F\"</li> <li>Convert the letters \"W\" and \"H\" to nothing if they are not at the beginning of the word</li> </ol> </li> <li> <p>Apply a set of replacement rules to the resulting word, such as:</p> <ol> <li>Replace the letter \"G\" with \"J\" if it is followed by an \"E\", \"I\", or \"Y\"</li> <li>Replace the letter \"C\" with \"S\" if it is followed by an \"E\", \"I\", or \"Y\"</li> <li>Replace the letter \"X\" with \"KS\"</li> </ol> </li> <li> <p>If the resulting word ends with \"S\", remove it.</p> </li> <li> <p>If the resulting word ends with \"ED\", \"ING\", or \"ES\", remove it.</p> </li> <li> <p>If the resulting word starts with \"KN\", \"GN\", \"PN\", \"AE\", \"WR\", or \"WH\", remove the first letter.</p> </li> <li> <p>If the resulting word starts with \"X\", \"Z\", \"GN\", or \"KN\", retain the first two characters.</p> </li> <li> <p>Apply a second set of rules to the resulting word to generate an alternative code.</p> </li> <li> <p>Return the primary and alternative codes as a tuple.</p> </li> </ol> <p>The Alternative Double Metaphone algorithm takes into account different contexts in the word and is generated by following these steps:</p> <ol> <li> <p>Apply a set of prefix rules, such as:</p> <ol> <li>Convert the letter \"G\" at the beginning of the word to \"K\" if it is followed by \"N\", \"NED\", or \"NER\"</li> <li>Convert the letter \"A\" at the beginning of the word to \"E\" if it is followed by \"SCH\"</li> </ol> </li> <li> <p>Apply a set of suffix rules, such as:</p> <ol> <li>Convert the letters \"E\" and \"I\" at the end of the word to \"Y\"</li> <li>Convert the letters \"S\" and \"Z\" at the end of the word to \"X\"</li> <li>Remove the letter \"D\" at the end of the word if it is preceded by \"N\"</li> </ol> </li> <li> <p>Apply a set of replacement rules, such as:</p> <ol> <li>Replace the letter \"C\" with \"X\" if it is followed by \"IA\" or \"H\"</li> <li>Replace the letter \"T\" with \"X\" if it is followed by \"IA\" or \"CH\"</li> </ol> </li> <li> <p>Retain the first four characters of the resulting word, or pad it with zeros if it has fewer than four characters.</p> </li> <li> <p>If the resulting word starts with \"X\", \"Z\", \"GN\", or \"KN\", retain the first two characters.</p> </li> <li> <p>Return the alternative code.</p> </li> </ol> Example <p>You can test out the Metaphone transformation between two strings through the phonetics package.</p> <pre><code>import phonetics\nprint(phonetics.dmetaphone(\"Smith\"), phonetics.dmetaphone(\"Smyth\"))\n</code></pre> <p>('SM0', 'XMT') ('SM0', 'XMT')</p>","tags":["API","Phonetic Transformations","Comparisons","Blocking","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/comparisons/regular_expressions.html","title":"Regular expressions","text":""},{"location":"topic_guides/comparisons/regular_expressions.html#extracting-partial-strings","title":"Extracting partial strings","text":"<p>It can sometimes be useful to make comparisons based on substrings or parts of column values. For example, one approach to comparing postcodes is to consider their constituent components, e.g. area, district, etc (see Featuring Engineering for more details).</p> <p>We can use functions such as substrings and regular expressions to enable users to compare strings without needing to engineer new features from source data.</p> <p>Splink supports this functionality via the use of the <code>ComparisonExpression</code>.</p>"},{"location":"topic_guides/comparisons/regular_expressions.html#examples","title":"Examples","text":""},{"location":"topic_guides/comparisons/regular_expressions.html#1-exact-match-on-postcode-area","title":"1. Exact match on postcode area","text":"<p>Suppose you wish to make comparisons on a postcode column in your data, however only care about finding links between people who share the same area code (given by the first 1 to 2 letters of the postcode). The regular expression to pick out the first two characters is <code>^[A-Z]{1,2}</code>:</p> <pre><code>import splink.comparison_level_library as cll\nfrom splink import ColumnExpression\n\npc_ce = ColumnExpression(\"postcode\").regex_extract(\"^[A-Z]{1,2}\")\nprint(cll.ExactMatchLevel(pc_ce).get_comparison_level(\"duckdb\").sql_condition)\n</code></pre> <pre><code>NULLIF(regexp_extract(\"postcode_l\", '^[A-Z]{1,2}', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Z]{1,2}', 0), '')\n</code></pre> <p>We may therefore configure a comparison as follows:</p> <pre><code>from splink.comparison_library import CustomComparison\n\ncc = CustomComparison(\n    output_column_name=\"postcode\",\n    comparison_levels=[\n        cll.NullLevel(\"postcode\"),\n        cll.ExactMatchLevel(pc_ce),\n        cll.ElseLevel()\n    ]\n\n)\nprint(cc.get_comparison(\"duckdb\").human_readable_description)\n</code></pre> <pre><code>Comparison 'CustomComparison' of \"postcode\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on transformed postcode' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Z]{1,2}', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Z]{1,2}', 0), '')\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> person_id_l person_id_r postcode_l postcode_r comparison_level 7 1 SE1P 0NY SE1P 0NY exact match 5 1 SE2 4UZ SE1P 0NY exact match 9 2 SW14 7PQ SW3 9JG exact match 4 8 N7 8RL EC2R 8AH else level 6 3 SE2 4UZ null level"},{"location":"topic_guides/comparisons/regular_expressions.html#2-exact-match-on-initial","title":"2. Exact match on initial","text":"<p>In this example we use the <code>.substr</code> function to create a comparison level based on the first letter of a column value. </p> <p>Note that the <code>substr</code> function is 1-indexed, so the first character is given by <code>substr(1, 1)</code>:  The first two characters would be given by <code>substr(1, 2)</code>.</p> <pre><code>import splink.comparison_level_library as cll\nfrom splink import ColumnExpression\n\ninitial = ColumnExpression(\"first_name\").substr(1,1)\nprint(cll.ExactMatchLevel(initial).get_comparison_level(\"duckdb\").sql_condition)\n</code></pre> <pre><code>SUBSTRING(\"first_name_l\", 1, 1) = SUBSTRING(\"first_name_r\", 1, 1)\n</code></pre>"},{"location":"topic_guides/comparisons/regular_expressions.html#additional-info","title":"Additional info","text":"<p>Regular expressions containing \u201c\\\u201d (the python escape character) are tricky to make work with the Spark linker due to escaping so consider using alternative syntax, for example replacing \u201c\\d\u201d with \u201c[0-9]\u201d.</p> <p>Different regex patterns can achieve the same result but with more or less efficiency. You might want to consider optimising your regular expressions to improve performance (see here, for example).</p>"},{"location":"topic_guides/comparisons/term-frequency.html","title":"Term frequency adjustments","text":"","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#term-frequency-adjustments","title":"Term-Frequency Adjustments","text":"","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#problem-statement","title":"Problem Statement","text":"<p>A shortcoming of the basic Fellegi-Sunter model is that it doesn\u2019t account for skew in the distributions of linking variables. A stark example is a binary variable such as gender in the prison population, where male offenders outnumber female offenders by 10:1.</p> <p></p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#how-does-this-affect-our-m-and-u-probabilities","title":"How does this affect our m and u probabilities?","text":"<ul> <li> <p>m probability is unaffected - given two records are a match, the gender field should also match with roughly the same probability for males and females</p> </li> <li> <p>Given two records are not a match, however, it is far more likely that both records will be male than that they will both be female - u probability is too low for the more common value (male) and too high otherwise.</p> </li> </ul> <p>In this example, one solution might be to create an extra comparison level for matches on gender:</p> <ul> <li> <p><code>l.gender = r.gender AND l.gender = 'Male'</code></p> </li> <li> <p><code>l.gender = r.gender AND l.gender = 'Female'</code></p> </li> </ul> <p>However, this complexity forces us to estimate two m probabilities when one would do, and it becomes impractical if we extend to higher-cardinality variables like surname, requiring thousands of additional comparison levels.</p> <p></p> <p>This problem used to be addressed with an ex-post (after the fact) solution - once the linking is done, we have a look at the average match probability for each value in a column to determine which values tend to be stronger indicators of a match. If the average match probability for records pairs that share a surname is 0.2 but the average for the specific surname Smith is 0.1 then we know that the match weight for name should be adjusted downwards for Smiths.</p> <p>The shortcoming of this option is that in practice, the model training is conducted on the assumption that all name matches are equally informative, and all of the underlying probabilities are evaluated accordingly. Ideally, we want to be able to account for term frequencies within the Fellegi-Sunter framework as trained by the EM algorithm.</p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#toy-example","title":"Toy Example","text":"<p>Below is an illustration of 2 datasets (10 records each) with skewed distributions of first name. A <code>link_and_dedupe</code> Splink model concatenates these two tables and deduplicates those 20 records.</p> <p></p> <p>In principle, u probabilities for a small dataset like this can be estimated directly - out of 190 possible pairwise comparisons, 77 of them have the same first name. Based on the assumption that matches are rare (i.e. the vast majority of these comparisons are non-matches), we use this as a direct estimate of u. Random sampling makes the same assumption, but by using a manageable-sized sample of a much larger dataset where it would be prohibitively costly to perform all possible comparisons (a Cartesian join).</p> <p>Once we have concatenated our input tables, it is useful to calculate the term frequencies (TF) of each value. Rather than keep a separate TF table, we can add a TF column to the concatenated table - this is what <code>df_concat_with_tf</code> refers to within Splink.</p> <p>Building on the example above, we can define the m and u probabilities for a specific first name value, and work out an expression for the resulting match weight.</p> <p></p> <p>Just as we can add independent match weights for name, DOB and other comparisons (as shown in the Splink waterfall charts), we can also add an independent TF adjustment term for each comparison. This is useful because:</p> <ul> <li> <p>The TF adjustment doesn't depend on m, and therefore does not have to be estimated by the EM algorithm - it is known already</p> </li> <li> <p>The EM algorithm benefits from the TF adjustment (rather than previous post hoc implementations)</p> </li> <li> <p>It is trivially easy to \u201cturn off\u201d TF adjustments in our final match weights if we wish</p> </li> <li> <p>We can easily disentangle and visualise the aggregate significance of a particular column, separately from the deviations within it (see charts below)</p> </li> </ul> <p></p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#visualising-tf-adjustments","title":"Visualising TF Adjustments","text":"<p>For an individual comparison of two records, we can see the impact of TF adjustments in the waterfall charts:</p> <p> </p> This example shows two records having a match weight of +15.69 due to a match on first name, surname and DOB. Due to relatively uncommon values for all 3 of these, they each have an additional term frequency adjustment contributing around +5 to the final match weight <p>We can also see these match weights and TF adjustments summarised using a chart like the below to highlight common and uncommon names. We do this already using the Splink linker's profile_columns method, but once we know the u probabilities for our comparison columns, we can show these outliers in terms of their impact on match weight:</p> <p> </p> In this example of names from FEBRL data used in the demo notebooks, we see that a match on first name has a match weight of +6. For an uncommon name like Portia this is increased, whereas a common name like Jack has a reduced match weight. This chart can be generated using `linker.visualisations.tf_adjustment_chart(\"name\")`","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#applying-tf-adjustments-in-splink","title":"Applying TF adjustments in Splink","text":"<p>Depending on how you compose your Splink settings, TF adjustments can be applied to a specific comparison level in different ways:</p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#comparisonlibrary-functions","title":"ComparisonLibrary functions","text":"<pre><code>import splink.comparison_library as cl\n\nsex_comparison = cl.ExactMatch(\"sex\").configure(term_frequency_adjustments=True)\n\nname_comparison = cl.JaroWinklerAtThresholds(\n    \"name\",\n    score_threshold_or_thresholds=[0.9, 0.8],\n).configure(term_frequency_adjustments=True)\n\nemail_comparison = cl.EmailComparison(\"email\").configure(\n    term_frequency_adjustments=True,\n)\n</code></pre>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#comparison-level-library-functions","title":"Comparison level library functions","text":"<pre><code>import splink.comparison_level_library as cll\n\nname_comparison = cl.CustomComparison(\n    output_column_name=\"name\",\n    comparison_description=\"Full name\",\n    comparison_levels=[\n        cll.NullLevel(\"full_name\"),\n        cll.ExactMatchLevel(\"full_name\").configure(tf_adjustment_column=\"full_name\"),\n        cll.ColumnsReversedLevel(\"first_name\", \"surname\").configure(\n            tf_adjustment_column=\"surname\"\n        ),\n        cll.else_level(),\n    ],\n)\n</code></pre>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#providing-a-detailed-spec-as-a-dictionary","title":"Providing a detailed spec as a dictionary","text":"<pre><code>comparison_first_name = {\n    \"output_column_name\": \"first_name\",\n    \"comparison_description\": \"First name jaro dmeta\",\n    \"comparison_levels\": [\n        {\n            \"sql_condition\": \"first_name_l IS NULL OR first_name_r IS NULL\",\n            \"label_for_charts\": \"Null\",\n            \"is_null_level\": True,\n        },\n        {\n            \"sql_condition\": \"first_name_l = first_name_r\",\n            \"label_for_charts\": \"Exact match\",\n            \"tf_adjustment_column\": \"first_name\",\n            \"tf_adjustment_weight\": 1.0,\n            \"tf_minimum_u_value\": 0.001,\n        },\n        {\n            \"sql_condition\": \"jaro_winkler_sim(first_name_l, first_name_r) &gt; 0.8\",\n            \"label_for_charts\": \"Exact match\",\n            \"tf_adjustment_column\": \"first_name\",\n            \"tf_adjustment_weight\": 0.5,\n            \"tf_minimum_u_value\": 0.001,\n        },\n        {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\"},\n    ],\n}\n</code></pre>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#more-advanced-applications","title":"More advanced applications","text":"<p>The code examples above show how we can use term frequencies for different columns for different comparison levels, and demonstrated a few other features of the TF adjustment implementation in Splink:</p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#multiple-columns","title":"Multiple columns","text":"<p>Each comparison level can be adjusted on the basis of a specified column. In the case of exact match levels, this is trivial but it allows some partial matches to be reframed as exact matches on a different derived column. One example could be ethnicity, often provided in codes as a letter (W/M/B/A/O - the ethnic group) and a number. Without TF adjustments, an ethnicity comparison might have 3 levels - exact match, match on ethnic group (<code>LEFT(ethnicity,1)</code>), no match. By creating a derived column <code>ethnic_group = LEFT(ethnicity,1)</code> we can apply TF adjustments to both levels.</p> <pre><code>ethnicity_comparison = cl.CustomComparison(\n    output_column_name=\"ethnicity\",\n    comparison_description=\"Self-defined ethnicity\",\n    comparison_levels=[\n        cll.NullLevel(\"ethnicity\"),\n        cll.ExactMatchLevel(\"ethnicity\").configure(tf_adjustment_column=\"ethnicity\"),\n        cll.ExactMatchLevel(\"ethnic_group\").configure(tf_adjustment_column=\"ethnic_group\"),\n        cll.else_level(),\n    ],\n)\n</code></pre> <p>A more critical example would be a full name comparison that uses separate first name and surname columns. Previous implementations would apply TF adjustments to each name component independently, so \u201cJohn Smith\u201d would be adjusted down for the common name \u201cJohn\u201d and then again for the common name \u201cSmith\u201d. However, the frequencies of names are not generally independent (e.g. \u201cMohammed Khan\u201d is a relatively common full name despite neither name occurring frequently). A simple full name comparison could therefore be structured as follows:</p> <pre><code>name_comparison = cl.CustomComparison(\n    output_column_name=\"name\",\n    comparison_description=\"Full name\",\n    comparison_levels=[\n        cll.NullLevel(\"full_name\"),\n        cll.ExactMatchLevel(\"full_name\").configure(tf_adjustment_column=\"full_name\"),\n        cll.ExactMatchLevel(\"first_name\").configure(tf_adjustment_column=\"first_name\"),\n        cll.ExactMatchLevel(\"surname\").configure(tf_adjustment_column=\"surname\"),\n        cll.else_level(),\n    ],\n)\n</code></pre>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#fuzzy-matches","title":"Fuzzy matches","text":"<p>All of the above discussion of TF adjustments has assumed an exact match on the column in question, but this need not be the case. Where we have a \u201cfuzzy\u201d match between string values, it is generally assumed that there has been some small corruption in the text, for a number of possible reasons. A trivial example could be <code>\"Smith\"</code> vs <code>\"Smith \"</code> which we know to be equivalent if not an exact string match.</p> <p>In the case of a fuzzy match, we may decide it is desirable to apply TF adjustments for the same reasons as an exact match, but given there are now two distinct sides to the comparison, there are also two different TF adjustments. Building on our assumption that one side is the \u201ccorrect\u201d or standard value and the other contains some mistake, Splink will simply use the greater of the two term frequencies. There should be more <code>\"Smith\"</code>s than <code>\"Smith \"</code>s, so the former provides the best estimate of the true prevalence of the name Smith in the data.</p> <p>In cases where this assumption might not hold and both values are valid and distinct (e.g. <code>\"Alex\"</code> v <code>\"Alexa\"</code>), this behaviour is still desirable. Taking the most common of the two ensures that we err on the side of lowering the match score for a more common name than increasing the score by assuming the less common name.</p> <p>TF adjustments will not be applied to any comparison level without explicitly being turned on, but to allow for some middle ground when applying them to fuzzy match column, there is a <code>tf_adjustment_weight</code> setting that can down-weight the TF adjustment. A weight of zero is equivalent to turning TF adjustments off, while a weight of 0.5 means the match weights are halved, mitigating their impact:</p> <pre><code>{\n  \"sql_condition\": \"jaro_winkler_sim(first_name_l, first_name_r) &gt; 0.8\",\n  \"label_for_charts\": \"Exact match\",\n  \"tf_adjustment_column\": \"first_name\",\n  \"tf_adjustment_weight\": 0.5\n}\n</code></pre>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/comparisons/term-frequency.html#low-frequency-outliers","title":"Low-frequency outliers","text":"<p>Another example of where you may wish to limit the impact of TF adjustments is for exceedingly rare values. As defined above, the TF-adjusted match weight, K is inversely proportional to the term frequency, allowing K to become very large in some cases.</p> <p>Let\u2019s say we have a handful of records with the misspelt first name \u201cSiohban\u201d (rather than \u201cSiobhan\u201d). Fuzzy matches between the two spellings will rightly be adjusted on the basis of the frequency of the correct spelling, but there will be a small number of cases where the misspellings match one another. Given we suspect these values are more likely to be misspellings of more common names, rather than a distinct and very rare name, we can mitigate this effect by imposing a minimum value on the term frequency used (equivalent to the u value). This can be added to your full settings dictionary as in the example above using <code>\"tf_minimum_u_value\": 0.001</code>. This means that for values with a frequency of &lt;1 in 1000, it will be set to 0.001.</p>","tags":["Term Frequency","Comparisons"]},{"location":"topic_guides/data_preparation/feature_engineering.html","title":"Feature Engineering","text":"","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#feature-engineering-for-data-linkage","title":"Feature Engineering for Data Linkage","text":"<p>During record linkage, the features in a given dataset are used to provide evidence as to whether two records are a match. Like any predictive model, the quality of a Splink model is dictated by the features provided.</p> <p>Below are some examples of features that be created from common columns, and how to create more detailed comparisons with them in a Splink model.</p>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#postcodes","title":"Postcodes","text":"<p>In this example, we derive latitude and longitude coordinates from a postcode column to create a more nuanced comparison. By doing so, we account for similarity not just in the string of the postcode, but in the geographical location it represents.  This could be useful if we believe, for instance, that people move house, but generally stay within the same geographical area.</p> <p>We start with a comparison that uses the postcode's components, For example, UK postcodes can be broken down into the following substrings:</p> <p> See image source for more details.</p> <p>The pre-built postcode comparison generates a comparison with levels for an exact match on full postcode, sector, district and area in turn.</p> <p>Code examples to use the comparison template:</p> <pre><code>import splink.comparison_library as cl\n\npc_comparison = ctl.PostcodeComparison(\"postcode\").get_comparison(\"duckdb\")\nprint(pc_comparison.human_readable_description)\n</code></pre> Output <pre><code>Comparison 'PostcodeComparison' of \"postcode\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on full postcode' with SQL rule: \"postcode_l\" = \"postcode_r\"\n    - 'Exact match on sector' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '')\n    - 'Exact match on district' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]?', 0), '')\n    - 'Exact match on area' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}', 0), '')\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>Note that this is not able to compute geographical distance by default, because it cannot assume that lat-long coordinates are available.</p> <p>We now proceed to derive <code>lat</code> and <code>long</code> columns so that we can take advantage of geographcial distance.  We will use the ONS Postcode Directory to look up the lat-long coordinates for each postcode.</p> <p>Read in a dataset with postcodes:</p> <pre><code>import duckdb\n\nfrom splink import splink_datasets\n\ndf = splink_datasets.historical_50k\n\ndf_with_pc = \"\"\"\nWITH postcode_lookup AS (\n    SELECT\n        pcd AS postcode,\n        lat,\n        long\n    FROM\n        read_csv_auto('./path/to/ONSPD_FEB_2023_UK.csv')\n)\nSELECT\n    df.*,\n    postcode_lookup.lat,\n    postcode_lookup.long\nFROM\n    df\nLEFT JOIN\n    postcode_lookup\nON\n    upper(df.postcode_fake) = postcode_lookup.postcode\n\"\"\"\n\ndf_with_postcode = duckdb.sql(df_with_pc)\n</code></pre> <p>Now that coordinates have been added, a more detailed postcode comparison can be produced using the <code>postcode_comparison</code>:</p> <pre><code>pc_comparison = cl.PostcodeComparison(\n    \"postcode\", lat_col=\"lat\", long_col=\"long\", km_thresholds=[1, 10]\n).get_comparison(\"duckdb\")\nprint(pc_comparison.human_readable_description)\n</code></pre> Output <pre><code>Comparison 'PostcodeComparison' of \"postcode\", \"lat\" and \"long\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'postcode is NULL' with SQL rule: \"postcode_l\" IS NULL OR \"postcode_r\" IS NULL\n    - 'Exact match on postcode' with SQL rule: \"postcode_l\" = \"postcode_r\"\n    - 'Exact match on transformed postcode' with SQL rule: NULLIF(regexp_extract(\"postcode_l\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '') = NULLIF(regexp_extract(\"postcode_r\", '^[A-Za-z]{1,2}[0-9][A-Za-z0-9]? [0-9]', 0), '')\n    - 'Distance less than 1km' with SQL rule:\n        cast(\n            acos(\n\n        case\n            when (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    ) &gt; 1 then 1\n            when (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    ) &lt; -1 then -1\n            else (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    )\n        end\n\n            ) * 6371\n            as float\n        )\n    &lt;= 1\n    - 'Distance less than 10km' with SQL rule:\n        cast(\n            acos(\n\n        case\n            when (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    ) &gt; 1 then 1\n            when (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    ) &lt; -1 then -1\n            else (\n        sin( radians(\"lat_l\") ) * sin( radians(\"lat_r\") ) +\n        cos( radians(\"lat_l\") ) * cos( radians(\"lat_r\") )\n            * cos( radians(\"long_r\" - \"long_l\") )\n    )\n        end\n\n            ) * 6371\n            as float\n        )\n    &lt;= 10\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre> <p>or by using <code>cll.distance_in_km_level()</code> in conjunction with other comparison levels:</p> <pre><code>import splink.comparison_level_library as cll\nimport splink.comparison_library as cl\n\ncustom_postcode_comparison = cl.CustomComparison(\n    output_column_name=\"postcode\",\n    comparison_description=\"Postcode\",\n    comparison_levels=[\n        cll.NullLevel(\"postcode\"),\n        cll.ExactMatchLevel(\"postcode\"),\n        cll.DistanceInKMLevel(\"lat\", \"long\", 1),\n        cll.DistanceInKMLevel(\"lat\", \"long\", 10),\n        cll.DistanceInKMLevel(\"lat\", \"long\", 50),\n        cll.ElseLevel(),\n    ],\n)\n</code></pre>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#phonetic-transformations","title":"Phonetic transformations","text":"<p>Phonetic transformation algorithms can be used to identify words that sound similar, even if they are spelled differently. These are particularly useful for names and can be used as an additional comparison level within name comparisons.</p> <p>For a more detailed explanation on phonetic transformation algorithms, see the topic guide.</p>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#example","title":"Example","text":"<p>There are a number of python packages which support phonetic transformations that can be applied to a pandas dataframe, which can then be loaded into the <code>Linker</code>. For example, creating a Double Metaphone column with the phonetics python library:</p> <pre><code>import pandas as pd\nimport phonetics\n\nfrom splink import splink_datasets\ndf = splink_datasets.fake_1000\n\n# Define a function to apply the dmetaphone phonetic algorithm to each name in the column\ndef dmetaphone_name(name):\n    if name is None:\n        pass\n    else:\n        return phonetics.dmetaphone(name)\n\n# Apply the function to the \"first_name\" and surname columns using the apply method\ndf['first_name_dm'] = df['first_name'].apply(dmetaphone_name)\ndf['surname_dm'] = df['surname'].apply(dmetaphone_name)\n\ndf.head()\n</code></pre> Output unique_id first_name surname dob city email group first_name_dm surname_dm 0 0 Julia 2015-10-29 London hannah88@powers.com 0 ('JL', 'AL') 1 1 Julia Taylor 2015-07-31 London hannah88@powers.com 0 ('JL', 'AL') ('TLR', '') 2 2 Julia Taylor 2016-01-27 London hannah88@powers.com 0 ('JL', 'AL') ('TLR', '') 3 3 Julia Taylor 2015-10-29 hannah88opowersc@m 0 ('JL', 'AL') ('TLR', '') 4 4 oNah Watson 2008-03-23 Bolton matthew78@ballard-mcdonald.net 1 ('AN', '') ('ATSN', 'FTSN') <p>Note: Soundex and Metaphone are also supported in phonetics</p> <p>Now that the dmetaphone columns have been added, they can be used within comparisons. For example, using the <code>NameComparison</code> function from the comparison library.</p> <pre><code>import splink.comparison_library as cl\n\ncomparison = cl.NameComparison(\"first_name\", dmeta_col_name=\"first_name_dm\").get_comparison(\"duckdb\")\ncomparison.human_readable_description\n</code></pre> Output <pre><code>Comparison 'NameComparison' of \"first_name\" and \"first_name_dm\".\nSimilarity is assessed using the following ComparisonLevels:\n    - 'first_name is NULL' with SQL rule: \"first_name_l\" IS NULL OR \"first_name_r\" IS NULL\n    - 'Exact match on first_name' with SQL rule: \"first_name_l\" = \"first_name_r\"\n    - 'Jaro-Winkler distance of first_name &gt;= 0.92' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92\n    - 'Jaro-Winkler distance of first_name &gt;= 0.88' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88\n    - 'Array intersection size &gt;= 1' with SQL rule: array_length(list_intersect(\"first_name_dm_l\", \"first_name_dm_r\")) &gt;= 1\n    - 'Jaro-Winkler distance of first_name &gt;= 0.7' with SQL rule: jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.7\n    - 'All other comparisons' with SQL rule: ELSE\n</code></pre>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#full-name","title":"Full name","text":"<p>If Splink has access to a combined full name column, it can use the term frequency of the full name, as opposed to treating forename and surname as independent.</p> <p>This can be important because correlations in names are common.  For example, in the UK, \u201cMohammed Khan\u201d is a more common full name than the individual frequencies of \"Mohammed\" or \"Khan\" would suggest.</p> <p>The following example shows how to do this.</p> <p>For more on term frequency, see the dedicated topic guide.</p>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/data_preparation/feature_engineering.html#example_1","title":"Example","text":"<p>Derive a full name column:</p> <pre><code>import pandas as pd\n\nfrom splink import splink_datasets\n\ndf = splink_datasets.fake_1000\n\ndf['full_name'] = df['first_name'] + ' ' + df['surname']\n\ndf.head()\n</code></pre> <p>Now that the <code>full_name</code> column has been added, it can be used within comparisons. For example, using the ForenameSurnameComparison function from the comparison library.</p> <pre><code>comparison = cl.ForenameSurnameComparison(\n    \"first_name\", \"surname\", forename_surname_concat_col_name=\"full_name\"\n)\ncomparison.get_comparison(\"duckdb\").as_dict()\n</code></pre> Output <pre><code>{'output_column_name': 'first_name_surname',\n'comparison_levels': [{'sql_condition': '(\"first_name_l\" IS NULL OR \"first_name_r\" IS NULL) AND (\"surname_l\" IS NULL OR \"surname_r\" IS NULL)',\n'label_for_charts': '(first_name is NULL) AND (surname is NULL)',\n'is_null_level': True},\n{'sql_condition': '\"full_name_l\" = \"full_name_r\"',\n'label_for_charts': 'Exact match on full_name',\n'tf_adjustment_column': 'full_name',\n'tf_adjustment_weight': 1.0},\n{'sql_condition': '\"first_name_l\" = \"surname_r\" AND \"first_name_r\" = \"surname_l\"',\n'label_for_charts': 'Match on reversed cols: first_name and surname'},\n{'sql_condition': '(jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.92) AND (jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.92)',\n'label_for_charts': '(Jaro-Winkler distance of first_name &gt;= 0.92) AND (Jaro-Winkler distance of surname &gt;= 0.92)'},\n{'sql_condition': '(jaro_winkler_similarity(\"first_name_l\", \"first_name_r\") &gt;= 0.88) AND (jaro_winkler_similarity(\"surname_l\", \"surname_r\") &gt;= 0.88)',\n'label_for_charts': '(Jaro-Winkler distance of first_name &gt;= 0.88) AND (Jaro-Winkler distance of surname &gt;= 0.88)'},\n{'sql_condition': '\"surname_l\" = \"surname_r\"',\n'label_for_charts': 'Exact match on surname',\n'tf_adjustment_column': 'surname',\n'tf_adjustment_weight': 1.0},\n{'sql_condition': '\"first_name_l\" = \"first_name_r\"',\n'label_for_charts': 'Exact match on first_name',\n'tf_adjustment_column': 'first_name',\n'tf_adjustment_weight': 1.0},\n{'sql_condition': 'ELSE', 'label_for_charts': 'All other comparisons'}],\n'comparison_description': 'ForenameSurnameComparison'}\n</code></pre> <p>Note that the first level is now :</p> <pre><code>{'sql_condition': '\"full_name_l\" = \"full_name_r\"',\n'label_for_charts': 'Exact match on full_name',\n'tf_adjustment_column': 'full_name',\n'tf_adjustment_weight': 1.0},\n</code></pre> <p>whereas without specifying <code>forename_surname_concat_col_name</code> we would have had:</p> <pre><code>{'sql_condition': '(\"first_name_l\" = \"first_name_r\") AND (\"surname_l\" = \"surname_r\")',\n'label_for_charts': '(Exact match on first_name) AND (Exact match on surname)'},\n</code></pre>","tags":["API","Feature Engineering","Comparisons","Postcode","Phonetic Transformations","Soundex","Metaphone","Double Metaphone"]},{"location":"topic_guides/evaluation/edge_metrics.html","title":"Edge Metrics","text":"<p>This guide is intended to be a reference guide for Edge Metrics used throughout Splink. It will build up from basic principles into more complex metrics.</p> <p>Note</p> <p>All of these metrics are dependent on having a \"ground truth\" to compare against. This is generally provided by Clerical Labelling (i.e. labels created by a human). For more on how to generate this ground truth (and the impact that can have on Edge Metrics), check out the Clerical Labelling Topic Guide.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#the-basics","title":"The Basics","text":"<p>Any Edge (Link) within a Splink model will fall into one of four categories:</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#true-positive","title":"True Positive","text":"<p>Also known as: True Link</p> <p>A True Positive is a case where a Splink model correctly predicts a match between two records.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#true-negative","title":"True Negative","text":"<p>Also known as: True Non-link</p> <p>A True Negative is a case where a Splink model correctly predicts a non-match between two records.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#false-positive","title":"False Positive","text":"<p>Also known as: False Link, Type I Error</p> <p>A False Positive is a case where a Splink model incorrectly predicts a match between two records, when they are actually a non-match.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#false-negative","title":"False Negative","text":"<p>Also known as: False Non-link, Missed Link, Type II Error</p> <p>A False Negative is a case where a Splink model incorrectly predicts a non-match between two records, when they are actually a match.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#confusion-matrix","title":"Confusion Matrix","text":"<p>These can be summarised in a Confusion Matrix</p> <p></p> <p>In a perfect model there would be no False Positives or False Negatives (i.e. FP = 0 and FN = 0).</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#metrics-for-linkage","title":"Metrics for Linkage","text":"<p>The confusion matrix shows counts of each link type, but we are generally more interested in proportions. I.e. what percentage of the time does the model get the answer right?</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#accuracy","title":"Accuracy","text":"<p>The simplest metric is</p> \\[\\textsf{Accuracy} = \\frac{\\textsf{True Positives}+\\textsf{True Negatives}}{\\textsf{All Predictions}}\\] <p>This measures the proportion of correct classifications (of any kind). This may be useful for balanced data but high accuracy can be achieved by simply assuming the majority class for highly imbalanced data (e.g. assuming non-matches).</p> Accuracy in Splink <ul> <li>Accuracy can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul> <p></p>"},{"location":"topic_guides/evaluation/edge_metrics.html#true-positive-rate-recall","title":"True Positive Rate (Recall)","text":"<p>Also known as: Sensitivity</p> <p>The True Positive Rate (Recall) is the proportion of matches that are correctly predicted by Splink.</p> \\[\\textsf{Recall} = \\frac{\\textsf{True Positives}}{\\textsf{All Positives}} = \\frac{\\textsf{True Positives}}{\\textsf{True Positives} + \\textsf{False Negatives}}\\] Recall in Splink <ul> <li>Recall can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul>"},{"location":"topic_guides/evaluation/edge_metrics.html#true-negative-rate-specificity","title":"True Negative Rate (Specificity)","text":"<p>Also known as: Selectivity</p> <p>The True Negative Rate (Specificity) is the proportion of non-matches that are correctly predicted by Splink.</p> \\[\\textsf{Specificity} = \\frac{\\textsf{True Negatives}}{\\textsf{All Negatives}} = \\frac{\\textsf{True Negatives}}{\\textsf{True Negatives} + \\textsf{False Positives}}\\] Specificity in Splink <ul> <li>Specificity can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul>"},{"location":"topic_guides/evaluation/edge_metrics.html#positive-predictive-value-precision","title":"Positive Predictive Value (Precision)","text":"<p>The Positive Predictive Value (Precision), is the proportion of predicted matches which are true matches.</p> \\[\\textsf{Precision} = \\frac{\\textsf{True Positives}}{\\textsf{All Predicted Positives}} = \\frac{\\textsf{True Positives}}{\\textsf{True Positives} + \\textsf{False Positives}}\\] Precision in Splink <ul> <li>Precision can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul>"},{"location":"topic_guides/evaluation/edge_metrics.html#negative-predictive-value","title":"Negative Predictive Value","text":"<p>The Negative Predictive Value is the proportion of predicted non-matches which are true non-matches.</p> \\[\\textsf{Negative Predictive Value} = \\frac{\\textsf{True Negatives}}{\\textsf{All Predicted Negatives}} = \\frac{\\textsf{True Negatives}}{\\textsf{True Negatives} + \\textsf{False Negatives}}\\] Negative Predictive Value in Splink <ul> <li>Negative predictive value can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul> <p>Warning</p> <p>Each of these metrics looks at just one row or column of the confusion matrix. A model cannot be meaningfully summarised by just one of these performance measures.</p> <p>\u201cPredicts cancer with 100% Precision\u201d - is true of a \u201cmodel\u201d that correctly identifies one known cancer patient, but misdiagnoses everyone else as cancer-free.</p> <p>\u201cAI judge\u2019s verdicts have Recall of 100%\u201d - is true for a power-mad AI judge that declares everyone guilty, regardless of any evidence to the contrary.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#composite-metrics-for-linkage","title":"Composite Metrics for Linkage","text":"<p>This section contains composite metrics i.e. combinations of metrics that can been derived from the confusion matrix (Precision, Recall, Specificity and Negative Predictive Value).</p> <p>Any comparison of two records has a number of possible outcomes (True Positives, False Positives etc.), each of which has a different impact on your specific use case. It is very rare that a single metric defines the desired behaviour of a model. Therefore, evaluating performance with a composite metric (or a combination of metrics) is advised.</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#f-score","title":"F Score","text":"<p>The F-Score is a weighted harmonic mean of Precision (Positive Predictive Value) and Recall (True Positive Rate). For a general weight \\(\\beta\\):</p> \\[F_{\\beta} = \\frac{(1 + \\beta^2) \\cdot \\textsf{Precision} \\cdot \\textsf{Recall}}{\\beta^2 \\cdot \\textsf{Precision} + \\textsf{Recall}}\\] <p>where Recall is \\(\\beta\\) times more important than Precision.</p> <p>For example, when Precision and Recall are equally weighted (\\(\\beta = 1\\)), we get:</p> \\[F_{1} = 2\\left[\\frac{1}{\\textsf{Precision}}+\\frac{1}{\\textsf{Recall}}\\right]^{-1} = \\frac{2 \\cdot \\textsf{Precision} \\cdot \\textsf{Recall}}{\\textsf{Precision} + \\textsf{Recall}}\\] <p>Other popular versions of the F score are \\(F_{2}\\) (Recall twice as important as Precision) and \\(F_{0.5}\\) (Precision twice as important as Recall)</p> F-Score in Splink <ul> <li>The F score can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul> <p>Warning</p> <p>F-score does not account for class imbalance in the data, and is asymmetric (i.e. it considers the prediction of matching records, but ignores how well the model correctly predicts non-matching records).</p>"},{"location":"topic_guides/evaluation/edge_metrics.html#p4-score","title":"P4 Score","text":"<p>The \\(P_{4}\\) Score is the harmonic mean of the 4 metrics that can be directly derived from the confusion matrix:</p> \\[ 4\\left[\\frac{1}{\\textsf{Recall}}+\\frac{1}{\\textsf{Specificity}}+\\frac{1}{\\textsf{Precision}}+\\frac{1}{\\textsf{Negative Predictive Value}}\\right]^{-1} \\] <p>This addresses one of the issues with the F-Score as it considers how well the model predicts non-matching records as well as matching records.</p> <p>Note: all metrics are given equal weighting.</p> \\(P_{4}\\) in Splink <ul> <li>\\(P_{4}\\) can be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul>"},{"location":"topic_guides/evaluation/edge_metrics.html#matthews-correlation-coefficient","title":"Matthews Correlation Coefficient","text":"<p>The Matthews Correlation Coefficient (\\(\\phi\\)) is a measure of how correlation between predictions and actual observations.</p> \\[ \\phi = \\sqrt{\\textsf{Recall} \\cdot \\textsf{Specificity} \\cdot \\textsf{Precision} \\cdot \\textsf{Negative Predictive Value}} - \\sqrt{(1 - \\textsf{Recall})(1 - \\textsf{Specificity})(1 - \\textsf{Precision})(1 - \\textsf{Negative Predictive Value})} \\] Matthews Correlation Coefficient (\\(\\phi\\)) in Splink <ul> <li>\\(\\phi\\) be calculated in Splink using the <code>accuracy_analysis_from_labels_column</code> and <code>accuracy_analysis_from_labels_table methods</code>. Checkout the <code>splink.evaluation</code> docs for more.</li> </ul> <p>Note</p> <p>Unlike the other metrics in this guide, \\(\\phi\\) is a correlation coefficient, so can range from -1 to 1 (as opposed to a range of 0 to 1).</p> <p>In reality, linkage models should never be negatively correlated with actual observations, so \\(\\phi\\) can be used in the same way as other metrics.</p>"},{"location":"topic_guides/evaluation/edge_overview.html","title":"Overview","text":""},{"location":"topic_guides/evaluation/edge_overview.html#edge-evaluation","title":"Edge Evaluation","text":"<p>Once you have a trained model, you use it to generate edges (links) between entities (nodes). These edges will have a Match Weight and corresponding Probability.</p> <p>There are several strategies for checking whether the links created in your pipeline perform as you want/expect.</p>"},{"location":"topic_guides/evaluation/edge_overview.html#consider-the-edge-metrics","title":"Consider the Edge Metrics","text":"<p>Edge Metrics measure how links perform at an overall level.</p> <p>First, consider how you would like your model to perform. What is important for your use case? Do you want to ensure that you capture all possible matches (i.e. high recall)? Or do you want to minimise the number of incorrectly predicted matches (i.e. high precision)? Perhaps a combination of both?</p> <p>For a summary of all the edge metrics available in Splink, check out the Edge Metrics guide.</p> <p>Note</p> <p>To produce Edge Metrics you will require a \"ground truth\" to compare your linkage results against (which can be achieved by Clerical Labelling).</p>"},{"location":"topic_guides/evaluation/edge_overview.html#spot-checking-pairs-of-records","title":"Spot Checking pairs of records","text":"<p>Spot Checking real examples of record pairs is helpful for confidence in linkage results. It is an effective way to build intuition for how the model works in practice and allows you to interrogate edge cases.</p> <p>Results of individual record pairs can be examined with the Waterfall Chart.</p> <p>Choosing which pairs of records to spot check can be done by either:</p> <ul> <li>Looking at all combinations of comparison levels and choosing which to examine in the Comparison Viewer Dashboard.</li> <li>Identifying and examining records which have been incorrectly predicted by your Splink model.</li> </ul> <p>As you are checking real examples, you will often come across cases that have not been accounted for by your model which you believe signify a match (e.g. a fuzzy match for names). We recommend using this feedback loop to help iterate and improve the definition of your model.</p>"},{"location":"topic_guides/evaluation/edge_overview.html#choosing-a-threshold","title":"Choosing a Threshold","text":"<p>Threshold selection is a key decision point within a linkage pipeline. One of the major benefits of probabilistic linkage versus a deterministic (i.e. rules-based) approach is the ability to choose the amount of evidence required for two records to be considered a match (i.e. a threshold).</p> <p>When you have decided on the metrics that are important for your use case, you can use the Threshold Selection Tool to get a first estimate for what your threshold should be.</p> <p>Note</p> <p>The Threshold Selection Tool requires labelled data to act as a \"ground truth\" to compare your linkage results against.</p> <p>Once you have an initial threshold, you can use Comparison Viewer Dashboard to look at records on either side of your threshold to check whether the threshold makes intuitive sense.</p> <p>From here, we recommend an iterative process of tweaking your threshold based on your spot checking then looking at the impact that this has on your overall edge metrics. Another tools that can be useful is spot checking where your model has gone wrong using <code>prediction_errors_from_labels_table</code> as demoed in the accuracy analysis demo.</p>"},{"location":"topic_guides/evaluation/edge_overview.html#in-summary","title":"In Summary","text":"<p>Evaluating the edges (links) of a linkage model depends on your use case. Defining what \"good\" looks like is a key step, which then allows you to choose a relevant metric (or metrics) for measuring success.</p> <p>Your desired metric should help give an initial estimation for a linkage threshold, then you can use spot checking to help settle on a final threshold.</p> <p>In general, the links between pairs of records are not the final output of linkage pipeline. Most use-cases use these links to group records together into clusters. In this instance, evaluating the links themselves is not sufficient, you have to evaluate the resulting clusters as well.</p>"},{"location":"topic_guides/evaluation/labelling.html","title":"Clerical Labelling","text":""},{"location":"topic_guides/evaluation/labelling.html#clerical-labelling","title":"Clerical Labelling","text":"<p>This page is under construction - check back soon!</p>"},{"location":"topic_guides/evaluation/model.html","title":"Model","text":""},{"location":"topic_guides/evaluation/model.html#model-evaluation","title":"Model Evaluation","text":"<p>The parameters in a trained Splink model determine the match probability (Splink score) assigned to pairwise record comparisons. Before scoring any pairs of records there are a number of ways to check whether your model will perform as you expect.</p>"},{"location":"topic_guides/evaluation/model.html#look-at-the-model-parameters","title":"Look at the model parameters","text":"<p>The final model is summarised in the match weights chart with each bar in the chart signifying the match weight (i.e. the amount of evidence for or against a match) for each comparison level in your model.</p> <p>If, after some investigation, you still can't make sense of some of the match weights, take a look at the corresponding \\(m\\) and \\(u\\) values generated to see if they themselves make sense. These can be viewed in the m u parameters chart.</p> <p>Remember that \\(\\textsf{Match Weight} = \\log_2 \\frac{m}{u}\\)</p>"},{"location":"topic_guides/evaluation/model.html#look-at-the-model-training","title":"Look at the model training","text":"<p>The behaviour of a model during training can offer some insight into its utility. The more stable a model is in the training process, the more reliable the outputs are.</p> <p>Stability of model training can be seen in the Expectation Maximisation stage (for \\(m\\) training):</p> <ul> <li> <p>Stability across EM training sessions can be seen through the parameter estimates chart</p> </li> <li> <p>Stability within each session is indicated by the speed of convergence of the algorithm. This is shown in the terminal output during training. In general, the fewer iterations required to converge the better.  You can also access convergence charts on the EM training session object</p> <pre><code>training_session = linker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"first_name\", \"surname\")\n)\ntraining_session.match_weights_interactive_history_chart()\n</code></pre> </li> </ul>"},{"location":"topic_guides/evaluation/model.html#in-summary","title":"In summary","text":"<p>Evaluating a trained model is not an exact science - there are no metrics which can definitively say whether a model is good or bad at this stage. In most cases, applying human logic and heuristics is the best you can do to establish whether the model is sensible. Given the variety of potential use cases of Splink, there is no perfect, universal model, just models that can be tuned to produce useful outputs for a given application.</p> <p>The tools within Splink are intended to help identify areas where your model may not be performing as expected. In future versions releases we hope to automatically flag where there are areas of a model that require further investigation to make this process easier for the user.</p>"},{"location":"topic_guides/evaluation/overview.html","title":"Overview","text":""},{"location":"topic_guides/evaluation/overview.html#evaluation-overview","title":"Evaluation Overview","text":"<p>Evaluation is a non-trivial, but crucial, task in data linkage. Linkage pipelines are complex and require many design decisions, each of which has an impact on the end result. </p> <p>This set of topic guides is intended to provide some structure and guidance on how to evaluate a Splink model alongside its resulting links and clusters.</p>"},{"location":"topic_guides/evaluation/overview.html#how-do-we-evaluate-different-stages-of-the-pipeline","title":"How do we evaluate different stages of the pipeline?","text":"<p>Evaluation in a data linking pipeline can be broken into 3 broad categories:</p>"},{"location":"topic_guides/evaluation/overview.html#model-evaluation","title":"Model Evaluation","text":"<p>After you have trained your model, you can start evaluating the parameters and overall design of the model. To see how, check out the Model Evaluation guide.</p>"},{"location":"topic_guides/evaluation/overview.html#edge-link-evaluation","title":"Edge (Link) Evaluation","text":"<p>Once you have trained a model, you will use it to predict the probability of links (edges) between entities (nodes). To see how to evaluate these links, check out the Edge Evaluation guide.</p>"},{"location":"topic_guides/evaluation/overview.html#cluster-evaluation","title":"Cluster Evaluation","text":"<p>Once you have chosen a linkage threshold, the edges are used to generate clusters of records. To see how to evaluate these clusters, check out the Cluster Evaluation guide.</p> <p>Note</p> <p>In reality, the development of a linkage pipeline involves iterating through multiple versions of models, links and clusters. For example, for each model version you will generally want to understand the downstream impact on the links and clusters generated. As such, you will likely revisit each stage of evaluation a number of times before settling on a final output.</p> <p>The aim of these guides, and the tools provided in Splink, is to ensure that you are able to extract enough information from each iteration to better understand how your pipeline is working and identify areas for improvement.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html","title":"Graph metrics","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#graph-metrics","title":"Graph metrics","text":"<p>Graph metrics quantify the characteristics of a graph. A simple example of a graph metric is cluster size, which is the number of nodes within a cluster.</p> <p>For data linking with Splink, it is useful to sort graph metrics into three categories:</p> <ul> <li>Node metrics</li> <li>Edge metrics</li> <li>Cluster metrics</li> </ul> <p>Each of these are defined below together with examples and explanations of how they can be applied to linked data to evaluate cluster quality. The examples cover all metrics currently available in Splink.</p> <p>Note</p> <p>It is important to bear in mind that whilst graph metrics can be very useful for assessing linkage quality, they are rarely definitive, especially when taken in isolation. A more comprehensive picture can be built by considering various metrics in conjunction with one another.</p> <p>It is also important to consider metrics within the context of their distribution and the underlying dataset. For example: a cluster density (see below) of 0.4 might seem low but could actually be above average for the dataset in question; a cluster of size 80 might be suspiciously large for one dataset but not for another.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#node-metrics","title":"Node metrics","text":"<p>Node metrics quantify the properties of the nodes which live within clusters.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#node-degree","title":"Node Degree","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition","title":"Definition","text":"<p>Node degree is the number of edges connected to a node.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example","title":"Example","text":"<p>In the cluster below A has a node degree of 1, whereas D has a node degree of 3.</p> <p></p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage","title":"Application in Data Linkage","text":"<p>High node degree is generally considered good as it means there are many edges in support of records in a cluster being linked. Nodes with low node degree could indicate links being missed (false negatives) or be the result of a small number of false links (false positives).</p> <p>However, erroneous links (false positives) could also be the reason for high node degree, so it can be useful to validate the edges of highly connected nodes.</p> <p>It is important to consider cluster size when looking at node degree. By definition, larger clusters contain more nodes to form links between, allowing nodes within them to attain higher degrees compared to those in smaller clusters. Consequently, low node degree within larger clusters can carry greater significance.</p> <p>Bear in mind, that the centrality of a single node in a cluster isn't necessarily representative of the overall connectedness of a cluster. This is where cluster centralisation can help.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#node-centrality","title":"Node Centrality","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition_1","title":"Definition","text":"<p>Node centrality is the proportion of all possible edges connected to a node. It can also be interpreted as a normalised node degree, or the proportion of other nodes in the cluster that are linked to. Centrality ranges from 0 to 1. A centrality of 1 means a node is connected to all other nodes in a cluster.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example_1","title":"Example","text":"<p>In the cluster below node B is connected to all nodes (giving a centrality of 1), whereas node A is connected to 1 out of 4 nodes (giving a centrality of 0.25).</p> <p></p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage_1","title":"Application in Data Linkage","text":"<p>High node centrality is generally considered good as it means the node is directly connected to many of the other nodes in a cluster. Low node centrality (particularly in relation to the rest of the nodes in the cluster) can be an indicative of a false link (false positive).</p> <p>Unlike node degree, centrality takes the cluster size into account and, being normalised, is more appropriate for comparing nodes across clusters.</p> <p>Node centrality can be useful as the node with the highest centrality in a cluster could be chosen to represent a cluster (sometimes know as a \"golden record\"). This is not appropriate in all cases, but the most connected node within a cluster will likely have much in common with other nodes.</p> <p>Bear in mind, that the degree of a single node in a cluster isn't necessarily representative of the overall connectedness of a cluster. This is where cluster centralisation can help.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#edge-metrics","title":"Edge metrics","text":"<p>Edge metrics quantify the properties of the edges within a cluster. </p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#is-bridge","title":"'is bridge'","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition_2","title":"Definition","text":"<p>An edge is classified as a 'bridge' if its removal splits a cluster into two smaller clusters.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example_2","title":"Example","text":"<p>For example, the removal of the link labelled \"Bridge\" below would break this cluster of 9 nodes into two clusters of 5 and 4 nodes, respectively.</p> <p></p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage_2","title":"Application in Data Linkage","text":"<p>Bridges can be signalers of false positives in linked data, especially when joining two highly connected sub-clusters. Examining bridges can shed light on issues with the linking process leading to the formation of false positive links.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#cluster-metrics","title":"Cluster metrics","text":"<p>Cluster metrics refer to the characteristics of a cluster as a whole, rather than the individual nodes and edges it contains.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#cluster-size","title":"Cluster Size","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition_3","title":"Definition","text":"<p>Cluster size refers to the number of nodes within a cluster.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example_3","title":"Example","text":"<p>The cluster below is of size 5.</p> <p></p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage_3","title":"Application in Data Linkage","text":"<p>When thinking about cluster size, it is often useful to consider the biggest clusters produced and ask yourself if the sizes seem reasonable for the dataset being linked. For example when linking people, does it make sense that an individual is appearing hundreds of times in the linked data resulting in a cluster of over 100 nodes? If the answer is no, then false positives links are probably being formed.</p> <p>If you don't have an intuition of what seems reasonable, then it is worth inspecting a sample of the largest clusters in Splink's Cluster Studio Dashboard to validate (or invalidate) links. From there you can develop an understanding of what maximum cluster size to expect for your linkage. Bear in mind that a large and highly dense cluster is usually less suspicious than a large low-density cluster.</p> <p>There also might be a lower bound on cluster size. For example, when linking two datasets in which you know people appear at least once in each, the minimum expected size of cluster will be 2. Clusters smaller than the minimum size indicate links have been missed.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#cluster-density","title":"Cluster Density","text":""},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition_4","title":"Definition","text":"<p>The density of a cluster is given by the number of edges it contains divided by the maximum possible number of edges. Density ranges from 0 to 1. A density of 1 means that all nodes are connected to all other nodes in a cluster.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example_4","title":"Example","text":"<p>The left cluster below has links between all nodes (giving a density of 1), whereas the right cluster has the minimum number of edges (4) to link 5 nodes together (giving a density of 0.4).</p> <p></p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage_4","title":"Application in Data Linkage","text":"<p>When evaluating clusters, a high density (closer to 1) is generally considered good as it means there are many edges in support of the records in a cluster being linked.</p> <p>A low density could indicate links being missed. This could happen, for example, if blocking rules are too tight or the clustering threshold is too high.</p> <p>A sample of low density clusters can be inspected in Splink's Cluster Studio Dashboard via the option <code>sampling_method = \"lowest_density_clusters_by_size\"</code>, which performs stratified sampling across different cluster sizes. When inspecting a cluster, ask yourself the question: why aren't more links being formed between record nodes?</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#cluster-centralisation","title":"Cluster Centralisation","text":"<p>Work in Progress</p> <p>We are still working out where Cluster Centralisation can be best used in the context of record linkage. At this stage, we do not have clear recommendations or guidance on the best places to use it - so if you have any expertise in this area we would love to hear from you!</p> <p>We will update this guidance as and when we have clearer strategies in this space.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#definition_5","title":"Definition","text":"<p>Cluster centralisation is defined as the deviation from maximum node degree normalised with respect to the maximum possible value. In other words, cluster centralisation tells us about the concentration of edges in a cluster. Centralisation ranges from 0 to 1.</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#example_5","title":"Example","text":"<p>Coming Soon</p>"},{"location":"topic_guides/evaluation/clusters/graph_metrics.html#application-in-data-linkage_5","title":"Application in Data Linkage","text":"<p>A high cluster centralisation (closer to 1) indicates that a few nodes are home to significantly more connections compared to the rest of the nodes in a cluster. This can help identify clusters containing nodes with a lower number of connections (low node degree) relative to what is possible for that cluster.</p> <p>Low centralisation suggests that edges are more evenly distributed amongst nodes in a cluster. This can be good if all nodes within a clusters enjoy many connections. However, low centralisation could also indicate that most nodes are not as highly connected as they could be. To check for this, look at low centralisation in conjunction with low density.</p> <p>A guide on how to compute graph metrics mentioned above with Splink is given in the next chapter.</p> <p>Please note, this topic guide is a work in progress and we welcome any feedback.</p>"},{"location":"topic_guides/evaluation/clusters/how_to_compute_metrics.html","title":"How to compute graph metrics","text":""},{"location":"topic_guides/evaluation/clusters/how_to_compute_metrics.html#how-to-compute-graph-metrics-with-splink","title":"How to compute graph metrics with Splink","text":""},{"location":"topic_guides/evaluation/clusters/how_to_compute_metrics.html#introduction-to-the-compute_graph_metrics-method","title":"Introduction to the <code>compute_graph_metrics()</code> method","text":"<p>To enable users to calculate a variety of graph metrics for their linked data, Splink provides the <code>compute_graph_metrics()</code> method.</p> <p>The method is called on the <code>linker</code> like so:</p> <pre><code>linker.clustering.compute_graph_metrics(df_predict, df_clustered, threshold_match_probability=0.95)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df_predict</code> <code>SplinkDataFrame</code> <p>The results of <code>linker.inference.predict()</code></p> required <code>df_clustered</code> <code>SplinkDataFrame</code> <p>The outputs of <code>linker.clustering.cluster_pairwise_predictions_at_threshold()</code></p> required <code>threshold_match_probability</code> <code>float</code> <p>Filter the pairwise match predictions to include only pairwise comparisons with a match_probability at or above this threshold. If not provided, the value will be taken from metadata on <code>df_clustered</code>. If no such metadata is available, this value must be provided.</p> <code>None</code> <p>Warning</p> <p><code>threshold_match_probability</code> should be the same as the clustering threshold passed to <code>cluster_pairwise_predictions_at_threshold()</code>. If this information is available to Splink then it will be passed automatically, otherwise the user will have to provide it themselves and take care to ensure that threshold values align.</p> <p>The method generates tables containing graph metrics (for nodes, edges and clusters), and returns a data class of Splink dataframes. The individual Splink dataframes containing node, edge and cluster metrics can be accessed as follows:</p> <pre><code>graph_metrics = linker.clustering.compute_graph_metrics(\n    pairwise_predictions, clusters\n)\n\ndf_edges = graph_metrics.edges.as_pandas_dataframe()\ndf_nodes = graph_metrics.nodes.as_pandas_dataframe()\ndf_clusters = graph_metrics.clusters.as_pandas_dataframe()\n</code></pre> <p>The metrics computed by <code>compute_graph_metrics()</code> include all those mentioned in the Graph metrics chapter, namely:</p> <ul> <li>Node degree</li> <li>Node centrality</li> <li>'Is bridge'</li> <li>Cluster size</li> <li>Cluster density</li> <li>Cluster centrality</li> </ul> <p>All of these metrics are calculated by default. If you are unable to install the <code>igraph</code> package required for 'is bridge', this metric won't be calculated, however all other metrics will still be generated.</p>"},{"location":"topic_guides/evaluation/clusters/how_to_compute_metrics.html#full-code-example","title":"Full code example","text":"<p>This code snippet computes graph metrics for a simple Splink dedupe model. A pandas dataframe of cluster metrics is displayed as the final output.</p> <pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndf = splink_datasets.historical_50k\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    comparisons=[\n        cl.ExactMatch(\n            \"first_name\",\n        ).configure(term_frequency_adjustments=True),\n        cl.JaroWinklerAtThresholds(\"surname\", score_threshold_or_thresholds=[0.9, 0.8]),\n        cl.LevenshteinAtThresholds(\n            \"postcode_fake\", distance_threshold_or_thresholds=[1, 2]\n        ),\n    ],\n    blocking_rules_to_generate_predictions=[\n        block_on(\"postcode_fake\", \"first_name\"),\n        block_on(\"first_name\", \"surname\"),\n        block_on(\"dob\", \"substr(postcode_fake,1,2)\"),\n        block_on(\"postcode_fake\", \"substr(dob,1,3)\"),\n        block_on(\"postcode_fake\", \"substr(dob,4,5)\"),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\ndb_api = DuckDBAPI()\nlinker = Linker(df, settings, db_api)\n\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"first_name\", \"surname\")\n)\n\nlinker.training.estimate_parameters_using_expectation_maximisation(\n    block_on(\"dob\", \"substr(postcode_fake, 1,3)\")\n)\n\npairwise_predictions = linker.inference.predict()\nclusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n    pairwise_predictions, 0.95\n)\n\ngraph_metrics = linker.clustering.compute_graph_metrics(pairwise_predictions, clusters)\n\ndf_clusters = graph_metrics.clusters.as_pandas_dataframe()\n</code></pre> <pre><code>df_clusters\n</code></pre> cluster_id n_nodes n_edges density cluster_centralisation 0 Q5076213-1 10 31.0 0.688889 0.250000 1 Q760788-1 9 30.0 0.833333 0.214286 2 Q88466525-10 3 3.0 1.000000 0.000000 3 Q88466525-1 10 37.0 0.822222 0.222222 4 Q1386511-1 13 47.0 0.602564 0.272727 ... ... ... ... ... ... 21346 Q1562561-16 1 0.0 NaN NaN 21347 Q15999964-5 1 0.0 NaN NaN 21348 Q5363139-12 1 0.0 NaN NaN 21349 Q4722328-5 1 0.0 NaN NaN 21350 Q7528564-13 1 0.0 NaN NaN <p>21351 rows \u00d7 5 columns</p>"},{"location":"topic_guides/evaluation/clusters/overview.html","title":"Overview","text":""},{"location":"topic_guides/evaluation/clusters/overview.html#cluster-evaluation","title":"Cluster Evaluation","text":"<p>Graphs provide a natural way to think about linked data (see the \"Linked data as graphs\" guide for a refresher). Visualising linked data as a graph and employing graph metrics are powerful ways to evaluate linkage quality.</p> <p></p> <p>Graph metrics help to give a big-picture view of the clusters generated by a Splink model. Through metric distributions and statistics, we can gauge the quality of clusters and monitor how adjustments to models impact results.</p> <p>Graph metrics can also help us home in on problematic clusters, such as those containing inaccurate links (false positives). Spot-checking can be performed with Splink\u2019s Cluster Studio Dashboard which enables users to visualise individual clusters and interrogate the links between their member records.</p>"},{"location":"topic_guides/evaluation/clusters/overview.html#evaluating-cluster-quality","title":"Evaluating cluster quality","text":""},{"location":"topic_guides/evaluation/clusters/overview.html#what-is-a-high-quality-cluster","title":"What is a high quality cluster?","text":"<p>When it comes to data linking, the highest quality clusters will be those containing all possible true matches (there will be no missed links a.k.a. false negatives) and no false matches (no false positives). In other words, clusters only containing precisely those nodes corresponding to records about the same entity.</p> <p>Generating clusters which all adhere to this ideal is rare in practice. For example,</p> <ul> <li>Blocking rules, necessary to make computations tractable, can prevent record comparisons between some true matches ever being made</li> <li>Data limitations can place an upper bound on the level of quality achievable</li> </ul> <p>Despite this, graph metrics can help us get closer to a satisfactory level of quality as well as monitor it going forward.</p>"},{"location":"topic_guides/evaluation/clusters/overview.html#what-does-cluster-quality-look-like-for-you","title":"What does cluster quality look like for you?","text":"<p>The extent of cluster evaluation efforts and what is considered 'good enough' will vary greatly with linkage use-case. You might already have labelled data or quality assured outputs from another model which define a clear benchmark for cluster quality.</p> <p>Domain knowledge can also set expectations of what is deemed reasonable or good. For example, you might already know that a large cluster (containing say 100 nodes) is suspicious for your deduplicated dataset.</p> <p>However, you may currently have little or no knowledge about the data or no a clear idea of what good quality clusters look like for your linkage.</p> <p>Whatever the starting point, this topic guide is designed to help users develop a better understanding of their clusters and help focus quality assurance efforts to get the best out of their linkage models.</p>"},{"location":"topic_guides/evaluation/clusters/overview.html#what-this-topic-guide-contains","title":"What this topic guide contains","text":"<ul> <li>An introduction to the graph metrics currently available in Splink and how to apply them to linked data</li> <li>Instructions on how to compute graph metrics with Splink</li> </ul> <p>Please note, this topic guide is a work in progress and we welcome any feedback.</p>"},{"location":"topic_guides/llms/prompting_llms.html","title":"LLM prompts","text":""},{"location":"topic_guides/llms/prompting_llms.html#using-llms-such-as-chatgpt-to-help-you-write-splink-code","title":"Using LLMs such as ChatGPT to help you write Splink code","text":"<p>We provide two files that summarise the Splink docs to help you use Splink with LLMs:</p> <p>Concise Splink Documentation Summary - around 25,000 tokens</p> <p>Comprehensive Splink Documentation Summary - around 90,000 tokens</p> <p>At present, only the concise one is short enough for the ChatGPT GUI. The longer one fits in the Claude long context (200k tokens) model.</p>"},{"location":"topic_guides/llms/prompting_llms.html#recommended-use","title":"Recommended use","text":"<p>To use these files, we suggest copying and pasing their contents into the LLM, and then appending your question.</p> <p>Alternative, if you're an OpenAI user, you can use the Splink 4 GPT, which includes these context files in their knowledge</p> <p>For instance, you may paste their contents and then ask:</p> <pre><code>I have a dataset I want to dedupe using duckdb\n\nIt has columns full_name, dob, occupation, zip\n\nDo some preparatory data cleaning and run a splink script to train a model and dedupe\n</code></pre> <p>Which results in (ChatGPT <code>o1</code> model)</p> Click to see example response <pre><code>import duckdb\nfrom splink import Linker, SettingsCreator, DuckDBAPI, block_on\nimport splink.comparison_library as cl\n\n# Load and clean data in DuckDB\ncon = duckdb.connect()\ncon.execute(\"\"\"\n    CREATE TABLE raw_data AS SELECT * FROM read_csv('your_data.csv', HEADER=TRUE)\n\"\"\")\n\n# Example cleaning steps: lowercasing fields, removing punctuation from full_name, standardizing dob format\ncon.execute(\"\"\"\n    CREATE TABLE cleaned AS\n    SELECT\n        regexp_replace(lower(full_name), '[^a-z ]', '', 'g') as full_name,\n        regexp_replace(dob, '[^0-9-]', '', 'g') as dob,\n        lower(occupation) as occupation,\n        regexp_replace(lower(zip), '[^a-z0-9 ]', '', 'g') as zip\n    FROM raw_data\n\"\"\")\n\ndf = con.table(\"cleaned\")\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"full_name\"),\n        block_on(\"dob\"),\n        block_on(\"zip\"),\n    ],\n    comparisons=[\n        cl.NameComparison(\"full_name\"),\n        cl.DateOfBirthComparison(\"dob\", input_is_string=True),\n        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n        cl.LevenshteinAtThresholds(\"zip\", 2),\n    ],\n    retain_intermediate_calculation_columns=True,\n)\n\ndb_api = DuckDBAPI()\nlinker = Linker(df, settings, db_api=db_api)\n\ndeterministic_rules = [\n    \"l.full_name = r.full_name and l.dob = r.dob\",\n    \"l.zip = r.zip and levenshtein(l.full_name, r.full_name) &lt; 2\"\n]\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"full_name\"))\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n\npredictions = linker.inference.predict(threshold_match_probability=0.9)\nclusters = linker.clustering.cluster_pairwise_predictions_at_threshold(predictions, threshold_match_probability=0.95)\n</code></pre> <p>Warning</p> <p>Whilst these prompts can be helpful to give you some initial code, there's no guarantees it will be correct.</p> <p>However, in many cases it can provide a useful starting point.</p> <p>You can also ask more theoretical questions such as:</p> <pre><code>Explain briefly how we can calculate the prior in Splink.  Given the number of matches is unknown, how can we calculate the probability two random records match?  Give a code example.\n</code></pre> Click to see example response <pre><code>Splink typically uses a set of deterministic rules that identify a subset of highly probable matches. By assuming these rules have a known \u201crecall\u201d (i.e. they capture a certain proportion of all true matches), Splink infers the total number of matches and, from that, calculates the probability that two random records match. In other words, you pick deterministic rules, count how many pairs they produce, estimate what fraction of all true matches they represent, and then scale up that count to the entire dataset, giving you an approximate prior probability.\n</code></pre>"},{"location":"topic_guides/llms/prompting_llms.html#how-these-prompts-are-generated","title":"How these prompts are generated","text":"<p>These files are generated with the following scripts, which you may wish to modify for your purposes:</p> <p>Create LLM Prompt Long Script</p> <p>Create LLM Prompt Short Script</p>"},{"location":"topic_guides/llms/prompting_llms.html#issues-and-discussions","title":"Issues and Discussions","text":"<p>I have also created a knowledgebase file by scraping all Github issues and discussions from the main Splink repo.</p> <p>I've found Gemini Pro 1.5 (2 million context length) is able to process these files effectively.</p> <p>Knowledgebase prompt - 1.6 million tokens</p> <p>Create knowledgebase script</p>"},{"location":"topic_guides/performance/drivers_of_performance.html","title":"Run times, performance and linking large data","text":"<p>This topic guide covers the fundamental drivers of the run time of Splink jobs.</p>","tags":["Performance"]},{"location":"topic_guides/performance/drivers_of_performance.html#blocking","title":"Blocking","text":"<p>The primary driver of run time is the number of record pairs that the Splink model has to process. In Splink, the number of pairs to consider is reduced using Blocking Rules which are covered in depth in their own set of topic guides.</p>","tags":["Performance"]},{"location":"topic_guides/performance/drivers_of_performance.html#complexity-of-comparisons","title":"Complexity of comparisons","text":"<p>The second most important driver of runtime is the complexity of comparisons, and the computional intensity of the fuzzy matching functions used.</p> <p>Complexity is added to comparisons in a number of ways, including:</p> <ul> <li>Increasing the number of comparison levels</li> <li>Using more computationally expensive comparison functions</li> <li>Adding Term Frequency Adjustments</li> </ul> <p>See performance of comparison functions for benchmarking results.</p>","tags":["Performance"]},{"location":"topic_guides/performance/drivers_of_performance.html#retaining-columns-through-the-linkage-process","title":"Retaining columns through the linkage process","text":"<p>The size your dataset has an impact on the performance of Splink. This is also applicable to the tables that Splink creates and uses under the hood. Some Splink functionality requires additional calculated columns to be stored. For example:</p> <ul> <li>The <code>comparison_viewer_dashboard</code> requires <code>retain_matching_columns</code> and <code>retain_intermediate_calculation_columns</code> to be set to <code>True</code> in the settings dictionary, but this makes some processes less performant.</li> </ul>","tags":["Performance"]},{"location":"topic_guides/performance/drivers_of_performance.html#filtering-out-pairwise-comparisons-in-the-predict-step","title":"Filtering out pairwise comparisons in the <code>predict()</code> step","text":"<p>Reducing the number of pairwise comparisons that need to be returned will make Splink perform faster. One way of doing this is to filter comparisons with a match score below a given threshold (using a <code>threshold_match_probability</code> or <code>threshold_match_weight</code>) when you call <code>predict()</code>.</p>","tags":["Performance"]},{"location":"topic_guides/performance/drivers_of_performance.html#model-training-without-term-frequency-adjustments","title":"Model training without term frequency adjustments","text":"<p>Model training with Term Frequency adjustments can be made more performant by setting <code>estimate_without_term_frequencies</code> parameter to <code>True</code> in <code>estimate_parameters_using_expectation_maximisation</code>.</p>","tags":["Performance"]},{"location":"topic_guides/performance/optimising_duckdb.html","title":"Optimising DuckDB performance","text":"","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#optimising-duckdb-jobs","title":"Optimising DuckDB jobs","text":"<p>This topic guide describes how to configure DuckDB to optimise performance</p> <p>It is assumed readers have already read the more general guide to linking big data, and have chosen appropriate blocking rules.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#summary","title":"Summary:","text":"<ul> <li>From <code>splink==3.9.11</code> onwards, DuckDB generally parallelises jobs well, so you should see 100% usage of all CPU cores for the main Splink operations (parameter estimation and prediction)</li> <li>In some cases <code>predict()</code> needs salting on <code>blocking_rules_to_generate_predictions</code> to achieve 100% CPU use. You're most likely to need this in the following scenarios:<ul> <li>Very high core count machines</li> <li>Splink models that contain a small number of <code>blocking_rules_to_generate_predictions</code></li> <li>Splink models that have a relatively small number of input rows (less than around 500k)</li> </ul> </li> <li>If you are facing memory issues with DuckDB, you have the option of using an on-disk database.</li> <li>Reducing the amount of parallelism by removing salting can also sometimes reduce memory usage</li> </ul> <p>You can find a blog post with formal benchmarks of DuckDB performance on a variety of machine types here.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#configuration","title":"Configuration","text":"","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#ensuring-100-cpu-usage-across-all-cores-on-predict","title":"Ensuring 100% CPU usage across all cores on <code>predict()</code>","text":"<p>The aim is for overall parallelism of the predict() step to closely align to the number of thread/vCPU cores you have: - If parallelism is too low, you won't use all your threads - If parallelism is too high, runtime will be longer.</p> <p>The number of CPU cores used is given by the following formula:</p> <p>\\(\\text{base parallelism} = \\frac{\\text{number of input rows}}{122,880}\\)</p> <p>\\(\\text{blocking rule parallelism}\\)</p> <p>\\(= \\text{count of blocking rules} \\times\\) \\(\\text{number of salting partitions per blocking rule}\\)</p> <p>\\(\\text{overall parallelism} = \\text{base parallelism} \\times \\text{blocking rule parallelism}\\)</p> <p>If overall parallelism is less than the total number of threads, then you won't achieve 100% CPU usage.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#example","title":"Example","text":"<p>Consider a deduplication job with 1,000,000 input rows, on a machine with 32 cores (64 threads)</p> <p>In our Splink suppose we set:</p> <pre><code>settings =  {\n    ...\n    \"blocking_rules_to_generate_predictions\" ; [\n        block_on(\"first_name\", salting_partitions=2),\n        block_on(\"dob\", salting_partitions=2),\n        block_on(\"surname\", salting_partitions=2),\n    ]\n    ...\n}\n</code></pre> <p>Then we have:</p> <ul> <li>Base parallelism of 9.</li> <li>3 blocking rules</li> <li>2 salting partitions per blocking rule</li> </ul> <p>We therefore have paralleism of \\(9 \\times 3 \\times 2 = 54\\), which is less than the 64 threads, and therefore we won't quite achieve full parallelism.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#generalisation","title":"Generalisation","text":"<p>The above formula for overall parallelism assumes all blocking rules have the same number of salting partitions, which is not necessarily the case. In the more general case of variable numbers of salting partitions, the formula becomes</p> \\[ \\text{overall parallelism} = \\text{base parallelism} \\times \\text{total number of salted blocking partitions across all blocking rules} \\] <p>So for example, with two blocking rules, if the first has 2 salting partitions, and the second has 10 salting partitions, when we would multiply base parallelism by 12.</p> <p>This may be useful in the case one of the blocking rules produces more comparisons than another: the 'bigger' blocking rule can be salted more.</p> <p>For further information about how parallelism works in DuckDB, including links to relevant DuckDB documentation and discussions, see here.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#running-out-of-memory","title":"Running out of memory","text":"<p>If your job is running out of memory, the first thing to consider is tightening your blocking rules, or running the workload on a larger machine.</p> <p>If these are not possible, the following config options may help reduce memory usage:</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#using-an-on-disk-database","title":"Using an on-disk database","text":"<p>DuckDB can spill to disk using several settings:</p> <p>Use the special <code>:temporary:</code> connection built into Splink that creates a temporary on disk database</p> <pre><code>linker = Linker(\n    df, settings, DuckDBAPI(connection=\":temporary:\")\n)\n</code></pre> <p>Use an on-disk database:</p> <pre><code>con = duckdb.connect(database='my-db.duckdb')\nlinker = Linker(\n    df, settings, DuckDBAPI(connection=con)\n)\n</code></pre> <p>Use an in-memory database, but ensure it can spill to disk:</p> <pre><code>con = duckdb.connect(\":memory:\")\n\ncon.execute(\"SET temp_directory='/path/to/temp';\")\nlinker = Linker(\n    df, settings, DuckDBAPI(connection=con)\n)\n</code></pre> <p>See also this section of the DuckDB docs</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_duckdb.html#reducing-salting","title":"Reducing salting","text":"<p>Empirically we have noticed that there is a tension between parallelism and total memory usage. If you're running out of memory, you could consider reducing parallelism.</p>","tags":["Performance","DuckDB","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html","title":"Optimising Spark performance","text":"","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#optimising-spark-jobs","title":"Optimising Spark jobs","text":"<p>This topic guide describes how to configure Spark to optimise performance - especially large linkage jobs which are slow or are not completing using default settings.</p> <p>It is assumed readers have already read the more general guide to linking big data, and blocking rules are proportionate to the size of the Spark cluster. As a very rough guide, on a small cluster of (say) 8 machines, we recommend starting with blocking rules that generate around 100 million comparisons. Once this is working, loosening the blocking rules to around 1 billion comparisons or more is often achievable.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#summary","title":"Summary:","text":"<ul> <li>Ensure blocking rules are not generating too many comparisons.</li> <li>We recommend setting the <code>break_lineage_method</code> to <code>\"parquet\"</code>, which is the default</li> <li><code>num_partitions_on_repartition</code> should be set so that each file in the output of <code>predict()</code> is roughly 100MB.</li> <li>Try setting <code>spark.default.parallelism</code> to around 5x the number of CPUs in your cluster</li> </ul> <p>For a cluster with 10 CPUs, that outputs about 8GB of data in parquet format, the following setup may be appropriate:</p> <pre><code>from splink import SparkAPI\n\nspark.conf.set(\"spark.default.parallelism\", \"50\")\nspark.conf.set(\"spark.sql.shuffle.partitions\", \"50\")\n\ndb_api = SparkAPI(\n    spark_session=spark,\n    break_lineage_method=\"parquet\",\n    num_partitions_on_repartition=80,\n)\n</code></pre>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#breaking-lineage","title":"Breaking lineage","text":"<p>Splink uses an iterative algorithm for model training, and more generally, lineage is long and complex. We have found that big jobs fail to complete without further optimisation. This is a well-known problem:</p> <p>Quote</p> <p>\"This long lineage bottleneck is widely known by sophisticated Spark application programmers. A common practice for dealing with long lineage is to have the application program strategically checkpoint RDDs at code locations that truncate much of the lineage for checkpointed data and resume computation immediately from the checkpoint.\"</p> <p>Splink will automatically break lineage in sensible places. We have found in practice that, when running Spark jobs backed by AWS S3, the fastest method of breaking lineage is persisting outputs to <code>.parquet</code> file.</p> <p>You can do this using the <code>break_lineage_method</code> parameter as follows:</p> <pre><code>from splink import SparkAPI\n\ndb_api = SparkAPI(\n    spark_session=spark,\n    break_lineage_method=\"parquet\",\n    num_partitions_on_repartition=80,\n)\n</code></pre> <p>Other options are <code>checkpoint</code> and <code>persist</code>, plus a few others for databricks. For different Spark setups, particularly if you have fast local storage, you may find these options perform better.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#spark-parallelism","title":"Spark Parallelism","text":"<p>We suggest setting default parallelism to roughly 5x the number of CPUs in your cluster. This is a very rough rule of thumb, and if you're encountering performance problems you may wish to experiment with different values.</p> <p>One way to set default parallelism is as follows:</p> <pre><code>from pyspark.context import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nconf = SparkConf()\n\nconf.set(\"spark.default.parallelism\", \"50\")\nconf.set(\"spark.sql.shuffle.partitions\", \"50\")\n\nsc = SparkContext.getOrCreate(conf=conf)\nspark = SparkSession(sc)\n</code></pre> <p>In general, increasing parallelism will make Spark 'chunk' your job into a larger amount of smaller tasks. This may solve memory issues. But note there is a tradeoff here: if you increase parallelism too high, Spark may take too much time scheduling large numbers of tasks, and may even run out of memory performing this work. See here. Also note that when blocking, jobs cannot be split into a large number of tasks than the cardinality of the blocking rule. For example, if you block on month of birth, this will be split into 12 tasks, irrespective of the parallelism setting. See here. You can use salting (below) to partially address this limitation.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#repartition-after-blocking","title":"Repartition after blocking","text":"<p>For some jobs, setting <code>repartition_after_blocking=True</code> when you initialise the <code>SparkAPI</code> may improve performance.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#salting","title":"Salting","text":"<p>For very large jobs, you may find that salting your blocking keys results in faster run times.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/optimising_spark.html#general-spark-config","title":"General Spark config","text":"<p>Splink generates large numbers of record comparisons from relatively small input datasets. This is an unusual type of workload, and so default Spark parameters are not always appropriate. Some of the issues encountered are similar to performance issues encountered with Cartesian joins - so some of the tips in relevant articles may help.</p>","tags":["Performance","Spark","Salting","Parallelism"]},{"location":"topic_guides/performance/performance_of_comparison_functions.html","title":"Performance of comparison functions","text":""},{"location":"topic_guides/performance/performance_of_comparison_functions.html#comparing-the-execution-speed-of-different-comparisons","title":"Comparing the execution speed of different comparisons","text":"<p>An important determinant of Splink performance is the computational complexity of any similarity or distance measures (fuzzy matching functions) used as part of your model config.</p> <p>For example, you may be considering using Jaro Winkler  or Levenshtein, and wish to know which will take longer to compute.</p> <p>This page contains summary statistics from performance benchmarking these functions.  The code used to generate these results can be found here, and raw results can be found here.</p> <p>The timings are based on making 10,000,000 comparisons of the named function.</p>"},{"location":"topic_guides/performance/performance_of_comparison_functions.html#duckdb","title":"DuckDB","text":"<p>The following chart shows the performance of different functions in DuckDB</p>"},{"location":"topic_guides/performance/performance_of_comparison_functions.html#spark","title":"Spark","text":"<p>The following chart shows the performance of different functions in Spark</p>"},{"location":"topic_guides/performance/performance_of_comparison_functions.html#caveats-and-notes","title":"Caveats and notes","text":"<p>These charts are intended to provide a rough, high level guide to performance.  Real world performance can be sensitive to a number of factors:</p> <ul> <li>For some functions such as Levenshtein, a longer input string will take longer to compute.</li> <li>For some functions, it may be simpler to compute the result when comparing two similar strings</li> <li>For the cosine similarity function, we used an embeddings length of 10.  This is far lower than many typical applications e.g. OpenAI's can have a length of 1,536.  The reason was that we were running out of memory (RAM) for longer lengths, causing spill to disk, which in turn prevented the test being a pure test of the function itself.</li> </ul> <p>If you wish to run your own benchmarks, head over to the splink_speed_testing repo, create tests like these and then run using the command </p> <pre><code>pytest benchmarks/\n</code></pre>"},{"location":"topic_guides/performance/salting.html","title":"Salting blocking rules","text":"","tags":["Performance","Salting","Spark"]},{"location":"topic_guides/performance/salting.html#salting-blocking-rules","title":"Salting blocking rules","text":"<p>For very large linkages using Apache Spark, Splink supports salting blocking rules.</p> <p>Under certain conditions, this can help Spark better parallelise workflows, leading to shorter run times, and avoiding out of memory errors. It is most likely to help where you have blocking rules that create very large numbers of comparisons (100m records+) and where there is skew in how record comparisons are made (e.g. blocking on full name creates more comparisons amongst 'John Smith's than many other names).</p> <p>Further information about the motivation for salting can be found here.</p> <p>Note that salting is only available for the Spark backend</p>","tags":["Performance","Salting","Spark"]},{"location":"topic_guides/performance/salting.html#how-to-use-salting","title":"How to use salting","text":"<p>To enable salting using the <code>Linker</code> with Spark, you provide some of your blocking rules as a dictionary rather than a string.</p> <p>This enables you to choose the number of salts for each blocking rule.</p> <p>Blocking rules provided as plain strings default to no salting (<code>salting_partitions = 1</code>)</p> <p>The following code snippet illustrates:</p> <pre><code>import logging\n\nfrom pyspark.context import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession\n\nimport splink.comparison_library as cl\nfrom splink import Linker, SparkAPI, splink_datasets\n\nconf = SparkConf()\nconf.set(\"spark.driver.memory\", \"12g\")\nconf.set(\"spark.sql.shuffle.partitions\", \"8\")\nconf.set(\"spark.default.parallelism\", \"8\")\n\nsc = SparkContext.getOrCreate(conf=conf)\nspark = SparkSession(sc)\nspark.sparkContext.setCheckpointDir(\"./tmp_checkpoints\")\n\nsettings = {\n    \"probability_two_random_records_match\": 0.01,\n    \"link_type\": \"dedupe_only\",\n    \"blocking_rules_to_generate_predictions\": [\n        \"l.dob = r.dob\",\n        {\"blocking_rule\": \"l.first_name = r.first_name\", \"salting_partitions\": 4},\n    ],\n    \"comparisons\": [\n        cl.LevenshteinAtThresholds(\"first_name\", 2),\n        cl.ExactMatch(\"surname\"),\n        cl.ExactMatch(\"dob\"),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.ExactMatch(\"email\"),\n    ],\n    \"retain_matching_columns\": True,\n    \"retain_intermediate_calculation_columns\": True,\n    \"additional_columns_to_retain\": [\"cluster\"],\n    \"max_iterations\": 1,\n    \"em_convergence\": 0.01,\n}\n\n\ndf = splink_datasets.fake_1000\n\nspark_api = SparkAPI(spark_session=spark)\nlinker = Linker(df, settings, db_api=spark_api)\nlogging.getLogger(\"splink\").setLevel(5)\n\nlinker.inference.deterministic_link()\n</code></pre> <p>And we can see that salting has been applied by looking at the SQL generated in the log:</p> <pre><code>SELECT\n  l.unique_id AS unique_id_l,\n  r.unique_id AS unique_id_r,\n  l.first_name AS first_name_l,\n  r.first_name AS first_name_r,\n  l.surname AS surname_l,\n  r.surname AS surname_r,\n  l.dob AS dob_l,\n  r.dob AS dob_r,\n  l.city AS city_l,\n  r.city AS city_r,\n  l.tf_city AS tf_city_l,\n  r.tf_city AS tf_city_r,\n  l.email AS email_l,\n  r.email AS email_r,\n  l.`group` AS `group_l`,\n  r.`group` AS `group_r`,\n  '0' AS match_key\nFROM __splink__df_concat_with_tf AS l\nINNER JOIN __splink__df_concat_with_tf AS r\n  ON l.dob = r.dob\nWHERE\n  l.unique_id &lt; r.unique_id\nUNION ALL\nSELECT\n  l.unique_id AS unique_id_l,\n  r.unique_id AS unique_id_r,\n  l.first_name AS first_name_l,\n  r.first_name AS first_name_r,\n  l.surname AS surname_l,\n  r.surname AS surname_r,\n  l.dob AS dob_l,\n  r.dob AS dob_r,\n  l.city AS city_l,\n  r.city AS city_r,\n  l.tf_city AS tf_city_l,\n  r.tf_city AS tf_city_r,\n  l.email AS email_l,\n  r.email AS email_r,\n  l.`group` AS `group_l`,\n  r.`group` AS `group_r`,\n  '1' AS match_key\nFROM __splink__df_concat_with_tf AS l\nINNER JOIN __splink__df_concat_with_tf AS r\n  ON l.first_name = r.first_name\n  AND CEIL(l.__splink_salt * 4) = 1\n  AND NOT (\n    COALESCE((\n        l.dob = r.dob\n    ), FALSE)\n  )\nWHERE\n  l.unique_id &lt; r.unique_id\nUNION ALL\nSELECT\n  l.unique_id AS unique_id_l,\n  r.unique_id AS unique_id_r,\n  l.first_name AS first_name_l,\n  r.first_name AS first_name_r,\n  l.surname AS surname_l,\n  r.surname AS surname_r,\n  l.dob AS dob_l,\n  r.dob AS dob_r,\n  l.city AS city_l,\n  r.city AS city_r,\n  l.tf_city AS tf_city_l,\n  r.tf_city AS tf_city_r,\n  l.email AS email_l,\n  r.email AS email_r,\n  l.`group` AS `group_l`,\n  r.`group` AS `group_r`,\n  '1' AS match_key\nFROM __splink__df_concat_with_tf AS l\nINNER JOIN __splink__df_concat_with_tf AS r\n  ON l.first_name = r.first_name\n  AND CEIL(l.__splink_salt * 4) = 2\n  AND NOT (\n    COALESCE((\n        l.dob = r.dob\n    ), FALSE)\n  )\nWHERE\n  l.unique_id &lt; r.unique_id\nUNION ALL\nSELECT\n  l.unique_id AS unique_id_l,\n  r.unique_id AS unique_id_r,\n  l.first_name AS first_name_l,\n  r.first_name AS first_name_r,\n  l.surname AS surname_l,\n  r.surname AS surname_r,\n  l.dob AS dob_l,\n  r.dob AS dob_r,\n  l.city AS city_l,\n  r.city AS city_r,\n  l.tf_city AS tf_city_l,\n  r.tf_city AS tf_city_r,\n  l.email AS email_l,\n  r.email AS email_r,\n  l.`group` AS `group_l`,\n  r.`group` AS `group_r`,\n  '1' AS match_key\nFROM __splink__df_concat_with_tf AS l\nINNER JOIN __splink__df_concat_with_tf AS r\n  ON l.first_name = r.first_name\n  AND CEIL(l.__splink_salt * 4) = 3\n  AND NOT (\n    COALESCE((\n        l.dob = r.dob\n    ), FALSE)\n  )\nWHERE\n  l.unique_id &lt; r.unique_id\nUNION ALL\nSELECT\n  l.unique_id AS unique_id_l,\n  r.unique_id AS unique_id_r,\n  l.first_name AS first_name_l,\n  r.first_name AS first_name_r,\n  l.surname AS surname_l,\n  r.surname AS surname_r,\n  l.dob AS dob_l,\n  r.dob AS dob_r,\n  l.city AS city_l,\n  r.city AS city_r,\n  l.tf_city AS tf_city_l,\n  r.tf_city AS tf_city_r,\n  l.email AS email_l,\n  r.email AS email_r,\n  l.`group` AS `group_l`,\n  r.`group` AS `group_r`,\n  '1' AS match_key\nFROM __splink__df_concat_with_tf AS l\nINNER JOIN __splink__df_concat_with_tf AS r\n  ON l.first_name = r.first_name\n  AND CEIL(l.__splink_salt * 4) = 4\n  AND NOT (\n    COALESCE((\n        l.dob = r.dob\n    ), FALSE)\n  )\nWHERE\n  l.unique_id &lt; r.unique_id\n</code></pre>","tags":["Performance","Salting","Spark"]},{"location":"topic_guides/splink_fundamentals/link_type.html","title":"Link type - linking vs deduping","text":"","tags":["Dedupe","Link","Link and Dedupe"]},{"location":"topic_guides/splink_fundamentals/link_type.html#link-type-linking-deduping-or-both","title":"Link type: Linking, Deduping or Both","text":"<p>Splink allows data to be linked, deduplicated or both.</p> <p>Linking refers to finding links between datasets, whereas deduplication finding links within datasets.</p> <p>Data linking is therefore only meaningful when more than one dataset is provided.</p> <p>This guide shows how to specify the settings dictionary and initialise the linker for the three link types.</p>","tags":["Dedupe","Link","Link and Dedupe"]},{"location":"topic_guides/splink_fundamentals/link_type.html#deduplication","title":"Deduplication","text":"<p>The <code>dedupe_only</code> link type expects the user to provide a single input table, and is specified as follows</p> <pre><code>from splink import SettingsCreator\n\nsettings = SettingsCreator(\n    link_type= \"dedupe_only\",\n)\n\nlinker = Linker(df, settings, db_api=dbapi, )\n</code></pre>","tags":["Dedupe","Link","Link and Dedupe"]},{"location":"topic_guides/splink_fundamentals/link_type.html#link-only","title":"Link only","text":"<p>The <code>link_only</code> link type expects the user to provide a list of input tables, and is specified as follows:</p> <pre><code>from splink import SettingsCreator\n\nsettings = SettingsCreator(\n    link_type= \"link_only\",\n)\n\nlinker = Linker(\n    [df_1, df_2, df_n],\n    settings,\n    db_api=dbapi,\n    input_table_aliases=[\"name1\", \"name2\", \"name3\"],\n)\n</code></pre> <p>The <code>input_table_aliases</code> argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink.</p>","tags":["Dedupe","Link","Link and Dedupe"]},{"location":"topic_guides/splink_fundamentals/link_type.html#link-and-dedupe","title":"Link and dedupe","text":"<p>The <code>link_and_dedupe</code> link type expects the user to provide a list of input tables, and is specified as follows:</p> <pre><code>from splink import SettingsCreator\n\nsettings = SettingsCreator(\n    link_type= \"link_and_dedupe\",\n)\n\nlinker = Linker(\n    [df_1, df_2, df_n],\n    settings,\n    db_api=dbapi,\n    input_table_aliases=[\"name1\", \"name2\", \"name3\"],\n)\n</code></pre> <p>The <code>input_table_aliases</code> argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink.</p>","tags":["Dedupe","Link","Link and Dedupe"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html","title":"Retrieving and querying Splink results","text":"","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html#retrieving-and-querying-splink-results","title":"Retrieving and Querying Splink Results","text":"<p>When Splink returns results, it does so in the format of a <code>SplinkDataFrame</code>.   This is needed to allow Splink to provide results in a uniform format across the different database backends</p> <p>For example, when you run <code>df_predict = linker.inference.predict()</code>, the result <code>df_predict</code> is a <code>SplinkDataFrame</code>.</p> <p>A <code>SplinkDataFrame</code> is an abstraction of a table in the underlying backend database, and provides several convenience methods for interacting with the underlying table. For detailed information check the full API.</p>","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html#converting-to-other-types","title":"Converting to other types","text":"<p>You can convert a <code>SplinkDataFrame</code> into a Pandas dataframe using <code>splink_df.as_pandas_dataframe()</code>.</p> <p>To view the first few records use a limit statement: <code>splink_df.as_pandas_dataframe(limit=10)</code>.</p> <p>For large linkages, it is not recommended to convert the whole <code>SplinkDataFrame</code> to pandas because Splink results can be very large, so converting them into pandas can be slow and result in out of memory errors. Usually it will be better to use SQL to query the tables directly.</p>","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html#querying-tables","title":"Querying tables","text":"<p>You can find out the name of the table in the underlying database using <code>splink_df.physical_name</code>. This enables you to run SQL queries directly against the results. You can execute queries using <code>linker.misc.query_sql</code> - this is the recommended approach as it's typically faster and more memory efficient than using pandas dataframes.</p> <p>The following is an example of this approach, in which we use SQL to find the best match to each input record in a <code>link_type=\"link_only\"</code> job (i.e remove duplicate matches):</p> <pre><code># linker is a Linker with link_type set to \"link_only\"\ndf_predict = linker.inference.predict(threshold_match_probability=0.75)\n\nsql = f\"\"\"\nwith ranked as\n(\nselect *,\nrow_number() OVER (\n    PARTITION BY unique_id_l order by match_weight desc\n    ) as row_number\nfrom {df_predict.physical_name}\n)\n\nselect *\nfrom ranked\nwhere row_number = 1\n\"\"\"\n\ndf_query_result = linker.misc.query_sql(sql)  # pandas dataframe\n</code></pre> <p>Note that <code>linker.misc.query_sql</code> will return a pandas dataframe by default, but you can instead return a <code>SplinkDataFrame</code> as follows: </p><pre><code>df_query_result = linker.misc.query_sql(sql, output_type='splink_df')\n</code></pre>","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html#saving-results","title":"Saving results","text":"<p>If you have a <code>SplinkDataFrame</code>, you may wish to store the results in some file outside of your database. As tables may be large, there are a couple of convenience methods for doing this directly without needing to load the table into memory. Currently Splink supports saving frames to either <code>csv</code> or <code>parquet</code> format. Of these we generally recommend the latter, as it is typed, compressed, column-oriented, and easily supports nested data.</p> <p>To save results, simply use the methods <code>to_csv()</code> or <code>to_parquet()</code> - for example: </p><pre><code>df_predict = linker.inference.predict()\ndf_predict.to_parquet(\"splink_predictions.parquet\", overwrite=True)\n# or alternatively:\ndf_predict.to_csv(\"splink_predictions.csv\", overwrite=True)\n</code></pre>","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/querying_splink_results.html#creating-a-splinkdataframe","title":"Creating a <code>SplinkDataFrame</code>","text":"<p>You can  create a <code>SplinkDataFrame</code> for any table in your database. You will need to already have a <code>linker</code> to manage interactions with the database: </p><pre><code>import pandas as pd\nimport duckdb\n\nfrom splink import Linker, SettingsCreator, DuckDBAPI\nfrom splink.datasets import splink_datasets\n\ncon = duckdb.connect()\ndf_numbers = pd.DataFrame({\"id\": [1, 2, 3], \"number\": [\"one\", \"two\", \"three\"]})\ncon.sql(\"CREATE TABLE number_table AS SELECT * FROM df_numbers\")\n\ndb_api = DuckDBAPI(connection=con)\ndf = splink_datasets.fake_1000\n\nlinker = Linker(df, settings=SettingsCreator(link_type=\"dedupe_only\"), db_api=db_api)\nsplink_df = linker.table_management.register_table(\"number_table\", \"a_templated_name\")\nsplink_df.as_pandas_dataframe()\n</code></pre> ```","tags":["SQL","Data Frames","SplinkDataFrame"]},{"location":"topic_guides/splink_fundamentals/settings.html","title":"Defining Splink models","text":"","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#defining-a-splink-model","title":"Defining a Splink Model","text":"","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#what-makes-a-splink-model","title":"What makes a Splink Model?","text":"<p>When building any linkage model in Splink, there are 3 key things which need to be defined:</p> <ol> <li>What type of linkage you want (defined by the link type)</li> <li>What pairs of records to consider (defined by blocking rules)</li> <li>What features to consider, and how they should be compared (defined by comparisons)</li> </ol>","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#defining-a-splink-model-with-a-settings-dictionary","title":"Defining a Splink model with a settings dictionary","text":"<p>All aspects of a Splink model are defined via the <code>SettingsCreator</code> object.</p> <p>For example, consider a simple model:</p> <pre><code>import splink.comparison_library as cl\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\", \"dob\"),\n    ],\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"month\", \"year\"],\n            datetime_thresholds=[\n                1,\n                1,\n            ],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n)\n</code></pre> <p>Where:</p> <p>1. Type of linkage</p> <p>The <code>\"link_type\"</code> is defined as a deduplication for a single dataset.</p> <pre><code>    link_type=\"dedupe_only\",\n</code></pre> <p>2. Pairs of records to consider</p> <p>The <code>\"blocking_rules_to_generate_predictions\"</code> define a subset of pairs of records for the model to be considered when making predictions. In this case, where there is a match on:</p> <ul> <li><code>first_name</code></li> <li>OR (<code>surname</code> AND <code>dob</code>).</li> </ul> <pre><code>    blocking_rules_to_generate_predictions=[\n            block_on(\"first_name\"),\n            block_on(\"surname\", \"dob\"),\n        ],\n</code></pre> <p>For more information on how blocking is used in Splink, see the dedicated topic guide.</p> <p>3. Features to consider, and how they should be compared</p> <p>The <code>\"comparisons\"</code> define the features to be compared between records: <code>\"first_name\"</code>, <code>\"surname\"</code>, <code>\"dob\"</code>, <code>\"city\"</code> and <code>\"email\"</code>.</p> <pre><code>    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"month\", \"year\"],\n            datetime_thresholds=[\n                1,\n                1,\n            ],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n</code></pre> <p>Using functions from the comparison library to define how these features should be compared.</p> <p>For more information on how comparisons are defined, see the dedicated topic guide.</p> <p>With our finalised settings object, we can train a Splink model using the following code:</p> Example model using the settings dictionary <pre><code>import splink.comparison_library as cl\nfrom splink import DuckDBAPI, Linker, SettingsCreator, block_on, splink_datasets\n\ndb_api = DuckDBAPI()\ndf = splink_datasets.fake_1000\n\nsettings = SettingsCreator(\n    link_type=\"dedupe_only\",\n    blocking_rules_to_generate_predictions=[\n        block_on(\"first_name\"),\n        block_on(\"surname\"),\n    ],\n    comparisons=[\n        cl.NameComparison(\"first_name\"),\n        cl.NameComparison(\"surname\"),\n        cl.DateOfBirthComparison(\n            \"dob\",\n            input_is_string=True,\n            datetime_metrics=[\"month\", \"year\"],\n            datetime_thresholds=[\n                1,\n                1,\n            ],\n        ),\n        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n        cl.EmailComparison(\"email\"),\n    ],\n)\n\nlinker = Linker(df, settings, db_api=db_api)\nlinker.training.estimate_u_using_random_sampling(max_pairs=1e6)\n\nblocking_rule_for_training = block_on(\"first_name\", \"surname\")\nlinker.training.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n\nblocking_rule_for_training = block_on(\"dob\")\nlinker.training.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n\npairwise_predictions = linker.inference.predict()\n\nclusters = linker.clustering.cluster_pairwise_predictions_at_threshold(pairwise_predictions, 0.95)\nclusters.as_pandas_dataframe(limit=5)\n</code></pre>","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#advanced-usage-of-the-settings-dictionary","title":"Advanced usage of the settings dictionary","text":"<p>The section above refers to the three key aspects of the Splink settings dictionary. There are a variety of other lesser used settings, which can be found as the arguments to the <code>SettingsCreator</code></p>","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#saving-a-trained-model","title":"Saving a trained model","text":"<p>Once you have have a trained Splink model, it is often helpful to save out the model. The <code>save_model_to_json</code> function allows the user to save out the specifications of their trained model.</p> <pre><code>linker.misc.save_model_to_json(\"model.json\")\n</code></pre> <p>which, using the example settings and model training from above, gives the following output:</p> Model JSON <p>When the splink model is saved to disk using <code>linker.misc.save_model_to_json(\"model.json\")</code> these settings become:</p> <pre><code>{\n    \"link_type\": \"dedupe_only\",\n    \"probability_two_random_records_match\": 0.0008208208208208208,\n    \"retain_matching_columns\": true,\n    \"retain_intermediate_calculation_columns\": false,\n    \"additional_columns_to_retain\": [],\n    \"sql_dialect\": \"duckdb\",\n    \"linker_uid\": \"29phy7op\",\n    \"em_convergence\": 0.0001,\n    \"max_iterations\": 25,\n    \"bayes_factor_column_prefix\": \"bf_\",\n    \"term_frequency_adjustment_column_prefix\": \"tf_\",\n    \"comparison_vector_value_column_prefix\": \"gamma_\",\n    \"unique_id_column_name\": \"unique_id\",\n    \"source_dataset_column_name\": \"source_dataset\",\n    \"blocking_rules_to_generate_predictions\": [\n        {\n            \"blocking_rule\": \"l.\\\"first_name\\\" = r.\\\"first_name\\\"\",\n            \"sql_dialect\": \"duckdb\"\n        },\n        {\n            \"blocking_rule\": \"l.\\\"surname\\\" = r.\\\"surname\\\"\",\n            \"sql_dialect\": \"duckdb\"\n        }\n    ],\n    \"comparisons\": [\n        {\n            \"output_column_name\": \"first_name\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"\\\"first_name_l\\\" IS NULL OR \\\"first_name_r\\\" IS NULL\",\n                    \"label_for_charts\": \"first_name is NULL\",\n                    \"is_null_level\": true\n                },\n                {\n                    \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\",\n                    \"label_for_charts\": \"Exact match on first_name\",\n                    \"m_probability\": 0.48854806009621365,\n                    \"u_probability\": 0.0056770619302010565\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") &gt;= 0.9\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of first_name &gt;= 0.9\",\n                    \"m_probability\": 0.1903763096120358,\n                    \"u_probability\": 0.003424501164330396\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") &gt;= 0.8\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of first_name &gt;= 0.8\",\n                    \"m_probability\": 0.08609678978546921,\n                    \"u_probability\": 0.006620702251038765\n                },\n                {\n                    \"sql_condition\": \"ELSE\",\n                    \"label_for_charts\": \"All other comparisons\",\n                    \"m_probability\": 0.23497884050628137,\n                    \"u_probability\": 0.9842777346544298\n                }\n            ],\n            \"comparison_description\": \"jaro_winkler at thresholds 0.9, 0.8 vs. anything else\"\n        },\n        {\n            \"output_column_name\": \"surname\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"\\\"surname_l\\\" IS NULL OR \\\"surname_r\\\" IS NULL\",\n                    \"label_for_charts\": \"surname is NULL\",\n                    \"is_null_level\": true\n                },\n                {\n                    \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\",\n                    \"label_for_charts\": \"Exact match on surname\",\n                    \"m_probability\": 0.43210610613512185,\n                    \"u_probability\": 0.004322481469643699\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") &gt;= 0.9\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of surname &gt;= 0.9\",\n                    \"m_probability\": 0.2514700606335103,\n                    \"u_probability\": 0.002907020988387136\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") &gt;= 0.8\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of surname &gt;= 0.8\",\n                    \"m_probability\": 0.0757748206402343,\n                    \"u_probability\": 0.0033636211436311888\n                },\n                {\n                    \"sql_condition\": \"ELSE\",\n                    \"label_for_charts\": \"All other comparisons\",\n                    \"m_probability\": 0.2406490125911336,\n                    \"u_probability\": 0.989406876398338\n                }\n            ],\n            \"comparison_description\": \"jaro_winkler at thresholds 0.9, 0.8 vs. anything else\"\n        },\n        {\n            \"output_column_name\": \"dob\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\",\n                    \"label_for_charts\": \"dob is NULL\",\n                    \"is_null_level\": true\n                },\n                {\n                    \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\",\n                    \"label_for_charts\": \"Exact match on dob\",\n                    \"m_probability\": 0.39025358731716286,\n                    \"u_probability\": 0.0016036280808555408\n                },\n                {\n                    \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") &lt;= 1\",\n                    \"label_for_charts\": \"Damerau-Levenshtein distance of dob &lt;= 1\",\n                    \"m_probability\": 0.1489444378965258,\n                    \"u_probability\": 0.0016546990388445707\n                },\n                {\n                    \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) &lt;= 2629800.0\",\n                    \"label_for_charts\": \"Abs difference of 'transformed dob &lt;= 1 month'\",\n                    \"m_probability\": 0.08866691175438302,\n                    \"u_probability\": 0.002594404665842722\n                },\n                {\n                    \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) &lt;= 31557600.0\",\n                    \"label_for_charts\": \"Abs difference of 'transformed dob &lt;= 1 year'\",\n                    \"m_probability\": 0.10518866178811104,\n                    \"u_probability\": 0.030622146410222362\n                },\n                {\n                    \"sql_condition\": \"ELSE\",\n                    \"label_for_charts\": \"All other comparisons\",\n                    \"m_probability\": 0.26694640124381713,\n                    \"u_probability\": 0.9635251218042348\n                }\n            ],\n            \"comparison_description\": \"Exact match vs. Damerau-Levenshtein distance &lt;= 1 vs. month difference &lt;= 1 vs. year difference &lt;= 1 vs. anything else\"\n        },\n        {\n            \"output_column_name\": \"city\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"\\\"city_l\\\" IS NULL OR \\\"city_r\\\" IS NULL\",\n                    \"label_for_charts\": \"city is NULL\",\n                    \"is_null_level\": true\n                },\n                {\n                    \"sql_condition\": \"\\\"city_l\\\" = \\\"city_r\\\"\",\n                    \"label_for_charts\": \"Exact match on city\",\n                    \"m_probability\": 0.561103053663773,\n                    \"u_probability\": 0.052019405886043986,\n                    \"tf_adjustment_column\": \"city\",\n                    \"tf_adjustment_weight\": 1.0\n                },\n                {\n                    \"sql_condition\": \"ELSE\",\n                    \"label_for_charts\": \"All other comparisons\",\n                    \"m_probability\": 0.438896946336227,\n                    \"u_probability\": 0.947980594113956\n                }\n            ],\n            \"comparison_description\": \"Exact match 'city' vs. anything else\"\n        },\n        {\n            \"output_column_name\": \"email\",\n            \"comparison_levels\": [\n                {\n                    \"sql_condition\": \"\\\"email_l\\\" IS NULL OR \\\"email_r\\\" IS NULL\",\n                    \"label_for_charts\": \"email is NULL\",\n                    \"is_null_level\": true\n                },\n                {\n                    \"sql_condition\": \"\\\"email_l\\\" = \\\"email_r\\\"\",\n                    \"label_for_charts\": \"Exact match on email\",\n                    \"m_probability\": 0.5521904988218763,\n                    \"u_probability\": 0.0023577568563241916\n                },\n                {\n                    \"sql_condition\": \"NULLIF(regexp_extract(\\\"email_l\\\", '^[^@]+', 0), '') = NULLIF(regexp_extract(\\\"email_r\\\", '^[^@]+', 0), '')\",\n                    \"label_for_charts\": \"Exact match on transformed email\",\n                    \"m_probability\": 0.22046667643566936,\n                    \"u_probability\": 0.0010970118706508391\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(\\\"email_l\\\", \\\"email_r\\\") &gt;= 0.88\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of email &gt;= 0.88\",\n                    \"m_probability\": 0.21374764835824084,\n                    \"u_probability\": 0.0007367990176013098\n                },\n                {\n                    \"sql_condition\": \"jaro_winkler_similarity(NULLIF(regexp_extract(\\\"email_l\\\", '^[^@]+', 0), ''), NULLIF(regexp_extract(\\\"email_r\\\", '^[^@]+', 0), '')) &gt;= 0.88\",\n                    \"label_for_charts\": \"Jaro-Winkler distance of transformed email &gt;= 0.88\",\n                    \"u_probability\": 0.00027834629553827263\n                },\n                {\n                    \"sql_condition\": \"ELSE\",\n                    \"label_for_charts\": \"All other comparisons\",\n                    \"m_probability\": 0.013595176384213488,\n                    \"u_probability\": 0.9955300859598853\n                }\n            ],\n            \"comparison_description\": \"jaro_winkler on username at threshold 0.88 vs. anything else\"\n        }\n    ]\n}\n</code></pre> <p>This is simply the settings dictionary with additional entries for <code>\"m_probability\"</code> and <code>\"u_probability\"</code> in each of the <code>\"comparison_levels\"</code>, which have estimated during model training.</p> <p>For example in the first name exact match level:</p> <pre><code>{\n    \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\",\n    \"label_for_charts\": \"Exact match on first_name\",\n    \"m_probability\": 0.48854806009621365,\n    \"u_probability\": 0.0056770619302010565\n},\n</code></pre> <p>where the <code>m_probability</code> and <code>u_probability</code> values here are then used to generate the match weight for an exact match on <code>\"first_name\"</code> between two records (i.e. the amount of evidence provided by records having the same first name) in model predictions.</p>","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/settings.html#loading-a-pre-trained-model","title":"Loading a pre-trained model","text":"<p>When using a pre-trained model, you can read in the model from a json and recreate the linker object to make new pairwise predictions. For example:</p> <pre><code>linker = Linker(\n    new_df,\n    settings=\"./path/to/model.json\",\n    db_api=db_api\n)\n</code></pre>","tags":["settings","Dedupe","Link","Link and Dedupe","Comparisons","Blocking Rules"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html","title":"Backends overview","text":"","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#splinks-sql-backends-spark-duckdb-etc","title":"Splink's SQL backends: Spark, DuckDB, etc","text":"<p>Splink is a Python library. However, it implements all data linking computations by generating SQL, and submitting the SQL statements to a backend of the user's choosing for execution.</p> <p>The Splink code you write is almost identical between backends, so it's straightforward to migrate between backends. Often, it's a good idea to start working using DuckDB on a sample of data, because it will produce results very quickly. When you're comfortable with your model, you may wish to migrate to a big data backend to estimate/predict on the full dataset.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#choosing-a-backend","title":"Choosing a backend","text":"","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#considerations-when-choosing-a-sql-backend-for-splink","title":"Considerations when choosing a SQL backend for Splink","text":"<p>When choosing which backend to use when getting started with Splink, there are a number of factors to consider:</p> <ul> <li>the size of the dataset(s)</li> <li>the amount of boilerplate code/configuration required</li> <li>access to specific (sometimes proprietary) platforms</li> <li>the backend-specific features offered by Splink</li> <li>the level of support and active development offered by Splink</li> </ul> <p>Below is a short summary of each of the backends available in Splink.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#duckdb","title":"DuckDB","text":"<p>DuckDB is recommended for most users for all but the largest linkages.</p> <p>It is the fastest backend, and is capable of linking large datasets, especially if you have access to high-spec machines.</p> <p>As a rough guide it can:</p> <ul> <li>Link up to around 5 million records on a modern laptop (4 core/16GB RAM)</li> <li>Link tens of millions of records on high spec cloud computers very fast.</li> </ul> <p>For further details, see the results of formal benchmarking here.</p> <p>DuckDB is also recommended because for many users its simplest to set up.</p> <p>It can be run on any device with python installed and it is installed automatically with Splink via <code>pip install splink</code>. DuckDB has complete coverage for the functions in the Splink comparison libraries.  Alongside the Spark linker, it receives most attention from the development team.</p> <p>See the DuckDB deduplication example notebook to get a better idea of how Splink works with DuckDB.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#spark","title":"Spark","text":"<p>Spark is recommended for:</p> <ul> <li>Very large linkages, especially where DuckDB is performing poorly or running out of memory, or</li> <li>Or have easier access to a Spark cluster than a single high-spec instance to run DuckDB</li> </ul> <p>It is not our default recommendation for most users because:</p> <ul> <li>It involves more configuration than users, such as registering UDFs and setting up a Spark cluster</li> <li>It is slower than DuckDB for many</li> </ul> <p>The Spark linker has complete coverage for the functions in the Splink comparison libraries.</p> <p>If working with Databricks note that the Splink development team does not have access to a Databricks environment so we can struggle help DataBricks-specific issues.</p> <p>See the Spark deduplication example notebook for an example of how Splink works with Spark.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#athena","title":"Athena","text":"<p>Athena is a big data SQL backend provided on AWS which is great for large datasets (10+ million records). It requires access to a live AWS account and as a persistent database, requires some additional management of the tables created by Splink. Athena has reasonable, but not complete, coverage for fuzzy matching functions, see Presto. At this time, the Athena backend is being used sparingly by the Splink development team so receives minimal levels of support.</p> <p>In addition, from a development perspective, the necessity for an AWS connection makes testing Athena code more difficult, so there may be occasional bugs that would normally be caught by our testing framework.</p> <p>See the Athena deduplication example notebook to get a better idea of how Splink works with Athena.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#sqlite","title":"SQLite","text":"<p>SQLite is similar to DuckDB in that it is, generally, more suited to smaller datasets. SQLite is simple to setup and can be run directly in a Jupyter notebook, but is not as performant as DuckDB. SQLite has reasonable, but not complete, coverage for the functions in the Splink comparison libraries, with gaps in array and date comparisons. String fuzzy matching, while not native to SQLite is available via python UDFs which has some performance implications. SQLite is not actively been used by the Splink team so receives minimal levels of support.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL is a relatively new linker, so we have not fully tested performance or what size of datasets can processed with Splink. The Postgres backend requires a Postgres database, so it is recommend to use this backend only if you are working with a pre-existing Postgres database. Postgres has reasonable, but not complete, coverage for the functions in the Splink comparison libraries, with gaps in string fuzzy matching functionality due to the lack of some string functions in Postgres. At this time, the Postgres backend is not being actively used by the Splink development team so receives minimal levels of support.</p> <p>More details on using Postgres as a Splink backend can be found on the Postgres page.</p>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#using-your-chosen-backend","title":"Using your chosen backend","text":"<p>Choose the relevant DBAPI:</p> <p>Once you have initialised the <code>linker</code> object, there is no difference in the subsequent code between backends.</p>  DuckDB Spark Athena SQLite PostgreSQL <pre><code>from splink import Linker, DuckDBAPI\n\nlinker = Linker(df, settings, db_api=DuckDBAPI(...))\n</code></pre> <pre><code>from splink import Linker, SparkAPI\n\nlinker = Linker(df, settings, db_api=SparkAPI(...))\n</code></pre> <pre><code>from splink import Linker, AthenaAPI\n\nlinker = Linker(df, settings, db_api=AthenaAPI(...))\n</code></pre> <pre><code>from splink import Linker, SQLiteAPI\n\nlinker = Linker(df, settings, db_api=SQLiteAPI(...))\n</code></pre> <pre><code>from splink import Linker, PostgresAPI\n\nlinker = Linker(df, settings, db_api=PostgresAPI(...))\n</code></pre>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#additional-information-for-specific-backends","title":"Additional Information for specific backends","text":"","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/backends.html#sqlite_1","title":"SQLite","text":"<p>SQLite does not have native support for fuzzy string-matching functions. However, the following are available for Splink users as python user-defined functions (UDFs)  which are automatically registered when calling <code>SQLiteAPI()</code></p> <ul> <li><code>levenshtein</code></li> <li><code>damerau_levenshtein</code></li> <li><code>jaro</code></li> <li><code>jaro_winkler</code></li> </ul> <p>However, there are a couple of points to note:</p> <ul> <li>These functions are implemented using the RapidFuzz package, which must be installed if you wish to make use of them, via e.g. <code>pip install rapidfuzz</code>. If you do not wish to do so you can disable the use of these functions when creating your linker: <pre><code>SQLiteAPI(register_udfs=False)\n</code></pre></li> <li>As these functions are implemented in python they will be considerably slower than any native-SQL comparisons. If you find that your model-training or predictions are taking a large time to run, you may wish to consider instead switching to DuckDB (or some other backend).</li> </ul>","tags":["Spark","DuckDB","Athena","SQLite","Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html","title":"PostgreSQL","text":"","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#using-postgresql-as-a-splink-backend","title":"Using PostgreSQL as a Splink backend","text":"<p>Splink is compatible with using PostgreSQL (or simply as Postgres) as a SQL backend - for other options have a look at the overview of Splink backends.</p>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#setup","title":"Setup","text":"<p>Splink makes use of SQLAlchemy for connecting to Postgres, and the default database adapter is <code>psycopg2</code>, but you should be able to use any other if you prefer. The <code>PostgresLinker</code> requires a valid engine upon creation to manage interactions with the database: </p><pre><code>from sqlalchemy import create_engine\n\nfrom splink.postgres.linker import PostgresLinker\nimport splink.postgres.comparison_library as cl\n\n# create a sqlalchemy engine to manage connecting to the database\nengine = create_engine(\"postgresql+psycopg2://USER:PASSWORD@HOST:PORT/DB_NAME\")\n\nsettings = SettingsCreator(\n    link_type= \"dedupe_only\",\n)\n</code></pre> <p>You can pass data to the linker in one of two ways:</p> <ul> <li> <p>use the name of a pre-existing table in your database </p><pre><code>dbapi = PostgresAPI(engine=engine)\nlinker = Linker(\n    \"my_data_table,\n    settings_dict,\n    db_api=db_api,\n)\n</code></pre> </li> <li> <p>or pass a pandas DataFrame directly, in which case the linker will create a corresponding table for you automatically in the database </p><pre><code>import pandas as pd\n\n# create pandas frame from csv\ndf = pd.read_csv(\"./my_data_table.csv\")\n\ndbapi = PostgresAPI(engine=engine)\nlinker = Linker(\n    df,\n    settings_dict,\n    db_api=db_api,\n)\n</code></pre> </li> </ul>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#permissions","title":"Permissions","text":"<p>When you connect to Postgres, you must do so with a role that has sufficient privileges for Splink to operate correctly. These are:</p> <ul> <li><code>CREATE ON DATABASE</code>, to allow Splink to create a schema for working, and install the <code>fuzzystrmatch</code> extension</li> <li><code>USAGE ON LANGUAGE SQL</code> and <code>USAGE ON TYPE float8</code> - these are required for creating the UDFs that Splink employs for calculations</li> </ul>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#things-to-know","title":"Things to know","text":"","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#schemas","title":"Schemas","text":"<p>When you create a <code>PostgresLinker</code>, Splink will create a new schema within the database you specify - by default this schema is called <code>splink</code>, but you can choose another name by passing the appropriate argument when creating the linker: </p><pre><code>dbapi = PostgresAPI(engine=engine, schema=\"another_splink_schema\")\n</code></pre> This schema is where all of Splink's work will be carried out, and where any tables created by Splink will live. <p>By default when looking for tables, Splink will check the schema it created, and the <code>public</code> schema; if you have tables in other schemas that you would like to be discoverable by Splink, you can use the parameter <code>other_schemas_to_search</code>: </p><pre><code>dbapi = PostgresAPI(engine=engine, other_schemas_to_search=[\"my_data_schema_1\", \"my_data_schema_2\"])\n</code></pre>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#user-defined-functions-udfs","title":"User-Defined Functions (UDFs)","text":"<p>Splink makes use of Postgres' user-defined functions in order to operate, which are defined in the schema created by Splink when you create the linker. These functions are all defined using SQL, and are:</p> <ul> <li><code>log2</code> - required for core Splink functionality</li> <li><code>datediff</code> - for the datediff comparison level</li> <li><code>ave_months_between</code> - for the datediff comparison level</li> <li><code>array_intersect</code> - for the array intersect comparison level</li> </ul> <p>Information</p> <p>The information below is only relevant if you are planning on making changes to Splink. If you are only intending to use Splink with Postgres, you do not need to read any further.</p>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#testing-splink-with-postgres","title":"Testing Splink with Postgres","text":"<p>To run only the Splink tests that run against Postgres, you can run simply: </p><pre><code>pytest -m postgres_only tests/\n</code></pre> For more information see the documentation page for testing in Splink. <p>The tests will are run using a temporary database and user that are created at the start of the test session, and destroyed at the end.</p>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#postgres-via-docker","title":"Postgres via docker","text":"<p>If you are trying to run tests with Splink on Postgres, or simply develop using Postgres, you may prefer to not actually install Postgres on you system, but to run it instead using Docker. In this case you can simply run the setup script (a thin wrapper around <code>docker-compose</code>): </p><pre><code>./scripts/postgres_docker/setup.sh\n</code></pre> Included in the docker-compose file is a pgAdmin container to allow easy exploration of the database as you work, which can be accessed in-browser on the default port. <p>When you are finished you can remove these resources: </p><pre><code>./scripts/postgres_docker/teardown.sh\n</code></pre>","tags":["Postgres","Backends"]},{"location":"topic_guides/splink_fundamentals/backends/postgres.html#running-with-a-pre-existing-database","title":"Running with a pre-existing database","text":"<p>If you have a pre-existing Postgres server you wish to use to run the tests against, you will need to specify environment variables for the credentials where they differ from default (in parentheses):</p> <ul> <li><code>SPLINKTEST_PG_USER</code> (<code>splinkognito</code>)</li> <li><code>SPLINKTEST_PG_PASSWORD</code> (<code>splink123!</code>)</li> <li><code>SPLINKTEST_PG_HOST</code> (<code>localhost</code>)</li> <li><code>SPLINKTEST_PG_PORT</code> (<code>5432</code>)</li> <li><code>SPLINKTEST_PG_DB</code> (<code>splink_db</code>) - tests will not actually run against this, but it is from a connection to this that the temporary test database + user will be created</li> </ul> <p>While care has been taken to ensure that tests are run using minimal permissions, and are cleaned up after, it is probably wise to run tests connected to a non-important database, in case anything goes wrong. In addition to the above privileges, in order to run the tests you will need:</p> <ul> <li><code>CREATE DATABASE</code> to create a temporary testing database</li> <li><code>CREATEROLE</code> to create a temporary user role with limited privileges, which will be actually used for all the SQL execution in the tests</li> </ul>","tags":["Postgres","Backends"]},{"location":"topic_guides/theory/fellegi_sunter.html","title":"The Fellegi-Sunter Model","text":""},{"location":"topic_guides/theory/fellegi_sunter.html#the-fellegi-sunter-model","title":"The Fellegi-Sunter model","text":"<p>This topic guide gives a high-level introduction to the Fellegi Sunter model, the statistical model that underlies Splink's methodology.</p> <p>For a more detailed interactive guide that aligns to Splink's methodology see Robin Linacre's interactive introduction to probabilistic linkage.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#parameters-of-the-fellegi-sunter-model","title":"Parameters of the Fellegi-Sunter model","text":"<p>The Fellegi-Sunter model has three main parameters that need to be considered to generate a match probability between two records:</p> <ul> <li>\\(\\lambda\\) - probability that any two records match</li> <li>\\(m\\) - probability of a given observation given the records are a match</li> <li>\\(u\\) - probability of a given observation given the records are not a match</li> </ul>"},{"location":"topic_guides/theory/fellegi_sunter.html#probability","title":"\u03bb probability","text":"<p>The lambda (\\(\\lambda\\)) parameter is the prior probability that any two records match. I.e. assuming no other knowledge of the data, how likely is a match? Or, as a formula:</p> \\[ \\lambda = Pr(\\textsf{Records match}) \\] <p>This is the same for all records comparisons, but is highly dependent on:</p> <ul> <li>The total number of records</li> <li>The number of duplicate records (more duplicates increases \\(\\lambda\\))</li> <li>The overlap between datasets<ul> <li>Two datasets covering the same cohort (high overlap, high \\(\\lambda\\))</li> <li>Two entirely independent datasets (low overlap, low \\(\\lambda\\))</li> </ul> </li> </ul>"},{"location":"topic_guides/theory/fellegi_sunter.html#m-probability","title":"m probability","text":"<p>The \\(m\\) probability is the probability of a given observation given the records are a match. Or, as a formula:</p> \\[ m = Pr(\\textsf{Observation | Records match}) \\] <p>For example, consider the the \\(m\\) probability of a match on Date of Birth (DOB). For two records that are a match, what is the probability that:</p> <ul> <li>DOB is the same:</li> <li>Almost 100%, say 98% \\(\\Longrightarrow m \\approx 0.98\\)</li> <li>DOB is different:</li> <li>Maybe a 2% chance of a data error? \\(\\Longrightarrow m \\approx 0.02\\)</li> </ul> <p>The \\(m\\) probability is largely a measure of data quality - if DOB is poorly collected, it may only match exactly for 50% of true matches.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#u-probability","title":"u probability","text":"<p>The \\(u\\) probability is the probability of a given observation given the records are not a match. Or, as a formula:</p> \\[ u = Pr(\\textsf{Observation | Records do not match}) \\] <p>For example, consider the the \\(u\\) probability of a match on Surname. For two records that are not a match, what is the probability that:</p> <ul> <li>Surname is the same:</li> <li>Depending on the surname, &lt;1%? \\(\\Longrightarrow u \\approx 0.005\\)</li> <li>Surname is different:</li> <li>Almost 100% \\(\\Longrightarrow u \\approx 0.995\\)</li> </ul> <p>The \\(u\\) probability is a measure of coincidence. As there are so many possible surnames, the chance of sharing the same surname with a randomly-selected person is small.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#interpreting-m-and-u","title":"Interpreting m and u","text":"<p>In the case of a perfect unique identifier:</p> <ul> <li>A person is only assigned one such value - \\(m = 1\\) (match) or \\(m=0\\) (non-match)</li> <li>A value is only ever assigned to one person - \\(u = 0\\) (match) or \\(u = 1\\) (non-match)</li> </ul> <p>Where \\(m\\) and \\(u\\) deviate from these ideals can usually be intuitively explained:</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#m-probability_1","title":"m probability","text":"<p>A measure of data quality/reliability.</p> <p>How often might a person's information change legitimately or through data error?</p> <ul> <li>Names: typos, aliases, nicknames, middle names, married names etc.</li> <li>DOB: typos, estimates (e.g. 1st Jan YYYY where date not known)</li> <li>Address: formatting issues, moving house, multiple addresses, temporary addresses</li> </ul>"},{"location":"topic_guides/theory/fellegi_sunter.html#u-probability_1","title":"u probability","text":"<p>A measure of coincidence/cardinality<sup>1</sup>.</p> <p>How many different people might share a given identifier?</p> <ul> <li>DOB (high cardinality) \u2013 for a flat age distribution spanning ~30 years, there are ~10,000 DOBs (0.01% chance of a match)</li> <li>Sex (low cardinality) \u2013 only 2 potential values (~50% chance of a match)</li> </ul>"},{"location":"topic_guides/theory/fellegi_sunter.html#match-weights","title":"Match Weights","text":"<p>One of the key measures of evidence of a match between records is the match weight.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#deriving-match-weights-from-m-and-u","title":"Deriving Match Weights from m and u","text":"<p>The match weight is a measure of the relative size of \\(m\\) and \\(u\\):</p> \\[ \\begin{equation} \\begin{aligned}     M &amp;= \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\log_2 K \\\\[10pt]     &amp;= \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\log_2 m - \\log_2 u \\end{aligned} \\end{equation} \\] <p>where \\(\\lambda\\) is the probability that two random records match and \\(K=m/u\\) is the Bayes factor.</p> <p>A key assumption of the Fellegi Sunter model is that observations from different column/comparisons are independent of one another. This means that the Bayes factor for two records is the products of the Bayes factor for each column/comparison:</p> \\[ K_\\textsf{features} = K_\\textsf{forename} \\cdot K_\\textsf{surname} \\cdot K_\\textsf{dob} \\cdot K_\\textsf{city} \\cdot K_\\textsf{email} \\] <p>This, in turn, means that match weights are additive:</p> \\[ M_\\textsf{obs} = M_\\textsf{prior} + M_\\textsf{features} \\] <p>where \\(M_\\textsf{prior} = \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right)\\) and \\(M_\\textsf{features} = M_\\textsf{forename} + M_\\textsf{surname} + M_\\textsf{dob} + M_\\textsf{city} + M_\\textsf{email}\\).</p> <p>So, considering these properties, the total match weight for two observed records can be rewritten as:</p> \\[ \\begin{equation} \\begin{aligned}     M_\\textsf{obs} &amp;= \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\sum_{i}^\\textsf{features}\\log_2(\\frac{m_i}{u_i}) \\\\[10pt]     &amp;= \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\log_2\\left(\\prod_i^\\textsf{features}\\frac{m_i}{u_i}\\right) \\end{aligned} \\end{equation} \\]"},{"location":"topic_guides/theory/fellegi_sunter.html#interpreting-match-weights","title":"Interpreting Match Weights","text":"<p>The match weight is the central metric showing the amount of evidence of a match is provided by each of the features in a model. The is most easily shown through Splink's Waterfall Chart:</p> <p></p> <ul> <li>1\ufe0f\u20e3 are the two records being compared</li> <li> <p>2\ufe0f\u20e3 is the match weight of the prior, \\(M_\\textsf{prior} = \\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right)\\).   This is the match weight if no additional knowledge of features is taken into account, and can be thought of as similar to the y-intercept in a simple regression.</p> </li> <li> <p>3\ufe0f\u20e3 are the match weights of each feature, \\(M_\\textsf{forename}\\), \\(M_\\textsf{surname}\\), \\(M_\\textsf{dob}\\), \\(M_\\textsf{city}\\) and \\(M_\\textsf{email}\\) respectively.</p> </li> <li> <p>4\ufe0f\u20e3 is the total match weight for two observed records, combining 2\ufe0f\u20e3 and 3\ufe0f\u20e3:</p> \\[ \\begin{equation} \\begin{aligned}     M_\\textsf{obs} &amp;= M_\\textsf{prior} + M_\\textsf{forename} + M_\\textsf{surname} + M_\\textsf{dob} + M_\\textsf{city} + M_\\textsf{email} \\\\[10pt]      &amp;= -6.67 + 4.74 + 6.49 - 1.97 - 1.12 + 8.00 \\\\[10pt]      &amp;= 9.48 \\end{aligned} \\end{equation} \\] </li> <li> <p>5\ufe0f\u20e3 is an axis representing the \\(\\textsf{match weight} = \\log_2(\\textsf{Bayes factor})\\))</p> </li> <li> <p>6\ufe0f\u20e3 is an axis representing the equivalent match probability (noting the non-linear scale). For more on the relationship between match weight and probability, see the sections below</p> </li> </ul>"},{"location":"topic_guides/theory/fellegi_sunter.html#match-probability","title":"Match Probability","text":"<p>Match probability is a more intuitive measure of similarity than match weight, and is, generally, used when choosing a similarity threshold for record matching.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#deriving-match-probability-from-match-weight","title":"Deriving Match Probability from Match Weight","text":"<p>Probability of two records being a match can be derived from the total match weight:</p> \\[ Pr(\\textsf{Match | Observation}) = \\frac{2^{M_\\textsf{obs}}}{1+2^{M_\\textsf{obs}}} \\] Example <p>Consider the example in the Interpreting Match Weights section. The total match weight, \\(M_\\textsf{obs} = 9.48\\). Therefore,</p> \\[ Pr(\\textsf{Match | Observation}) = \\frac{2^{9.48}}{1+2^{9.48}} \\approx 0.999 \\]"},{"location":"topic_guides/theory/fellegi_sunter.html#understanding-the-relationship-between-match-probability-and-match-weight","title":"Understanding the relationship between Match Probability and Match Weight","text":"<p>It can be helpful to build up some intuition for how match weight translates into match probability.</p> <p>Plotting match probability versus match weight gives the following chart:</p> <p></p> <p>Some observations from this chart:</p> <ul> <li>\\(\\textsf{Match weight} = 0 \\Longrightarrow \\textsf{Match probability} = 0.5\\)</li> <li>\\(\\textsf{Match weight} = 2 \\Longrightarrow \\textsf{Match probability} = 0.8\\)</li> <li>\\(\\textsf{Match weight} = 3 \\Longrightarrow \\textsf{Match probability} = 0.9\\)</li> <li>\\(\\textsf{Match weight} = 4 \\Longrightarrow \\textsf{Match probability} = 0.95\\)</li> <li>\\(\\textsf{Match weight} = 7 \\Longrightarrow \\textsf{Match probability} = 0.99\\)</li> </ul> <p>So, the impact of any additional match weight on match probability gets smaller as the total match weight increases. This makes intuitive sense as, when comparing two records, after you already have a lot of evidence/features indicating a match, adding more evidence/features will not have much of an impact on the probability of a match.</p> <p>Similarly, if you already have a lot of negative evidence/features indicating a match, adding more evidence/features will not have much of an impact on the probability of a match.</p>"},{"location":"topic_guides/theory/fellegi_sunter.html#deriving-match-probability-from-m-and-u","title":"Deriving Match Probability from m and u","text":"<p>Given the definitions for match probability and match weight above, we can rewrite the probability in terms of \\(m\\) and \\(u\\).</p> \\[ \\begin{equation} \\begin{aligned} Pr(\\textsf{Match | Observation}) &amp;= \\frac{2^{\\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\log_2\\left(\\prod_{i}^\\textsf{features}\\frac{m_{i}}{u_{i}}\\right)}}{1+2^{\\log_2\\left(\\frac{\\lambda}{1-\\lambda}\\right) + \\log_2\\left(\\prod_{i}^\\textsf{features}\\frac{m_{i}}{u_{i}}\\right)}} \\\\[20pt]  &amp;= \\frac{\\left(\\frac{\\lambda}{1-\\lambda}\\right)\\prod_{i}^\\textsf{features}\\frac{m_{i}}{u_{i}}}{1+\\left(\\frac{\\lambda}{1-\\lambda}\\right)\\prod_{i}^\\textsf{features}\\frac{m_{i}}{u_{i}}} \\\\[20pt]  &amp;= 1 - \\left[1+\\left(\\frac{\\lambda}{1-\\lambda}\\right)\\prod_{i}^\\textsf{features}\\frac{m_{i}}{u_{i}}\\right]^{-1} \\end{aligned} \\end{equation} \\]"},{"location":"topic_guides/theory/fellegi_sunter.html#further-reading","title":"Further Reading","text":"<p>This academic paper provides a detailed mathematical description of the model used by R fastLink package.  The mathematics used by Splink is very similar.</p> <ol> <li> <p>Cardinality is the the number of items in a set. In record linkage, cardinality refers to the number of possible values a feature could have. This is important in record linkage, as the number of possible options for e.g. date of birth has a significant impact on the amount of evidence that a match on date of birth provides for two records being a match.\u00a0\u21a9</p> </li> </ol>"},{"location":"topic_guides/theory/linked_data_as_graphs.html","title":"Linked Data as Graphs","text":""},{"location":"topic_guides/theory/linked_data_as_graphs.html#linked-data-as-graphs","title":"Linked data as graphs","text":"<p>When you link data, the results can be thought of as a graph, where each record (node) in your data is connected to other records by links (edges).  This guide discusses relevant graph theory.</p> <p>A graph is a collection of points (referred to in graph theory as nodes or vertices) connected by lines (referred to as edges).</p> <p></p> <p>Then a group of interconnected nodes is referred to as a cluster.</p> <p></p> <p>Graphs provide a natural way to represent linked data, where the nodes of a graph represent records being linked and the edges represent the links between them. So, if we have 5 records (A-E) in our dataset(s), with links between them, this can be represented as a graph like so:</p> <p></p> <p>When linking people together, a cluster represents the all of the records in our dataset(s) that refer to the same person. We can give this cluster a new identifier (F) as a way of referring to this single person.</p> <p></p> <p>Note</p> <p>For clusters produced with Splink, every edge comes with an associated Splink score (the probability of two records being a match). The clustering threshold (<code>match_probability_threshold</code>) supplied by the user determines which records are included in a cluster, as any links (edges) between records with a match probability below this threshold are excluded.</p> <p>Clusters, specifically cluster IDs, are the ultimate output of a Splink pipeline.</p>"},{"location":"topic_guides/theory/linked_data_as_graphs.html#probabilistic-data-linkage-and-graphs","title":"Probabilistic data linkage and graphs","text":"<p>When performing probabilistic linkage, each pair of records has a score indicating how similar they are. For example, consider a collection of records with pairwise similarity scores:</p> <p></p> <p>Having a score associated with each pair of records is the key benefit of probabilistic linkage, as we have a measure of similarity of the records (rather than a binary link/no-link). However, we need to choose a threshold at or above which links are considered valid in order to generate our final linked data (clusters).</p> <p>Let's consider a few different thresholds for the records above to see how the resulting clusters change. Setting a threshold of 0.95 keeps all links, so the records are all joined up into a single cluster.</p> <p></p> <p>Whereas if we increase the threshold to 0.99, one link is discarded. This breaks the records into two clusters.</p> <p></p> <p>Increasing the threshold further (to 0.999) breaks an additional two links, resulting in a total of three clusters.</p> <p></p> <p>This demonstrates that choice of threshold can have a significant impact on the final linked data produced (i.e. clusters). For more specific guidance on selecting linkage thresholds, check out the Evaluation Topic Guides.</p>"},{"location":"topic_guides/theory/probabilistic_vs_deterministic.html","title":"Probabilistic vs Deterministic linkage","text":""},{"location":"topic_guides/theory/probabilistic_vs_deterministic.html#types-of-record-linkage","title":"Types of Record Linkage","text":"<p>There are two main types of record linkage - Deterministic and Probabilistic.</p>"},{"location":"topic_guides/theory/probabilistic_vs_deterministic.html#deterministic-linkage","title":"Deterministic Linkage","text":"<p>Deterministic Linkage is a rules-based approach for joining records together.</p> <p>For example, consider a single table with duplicates:</p> AID Name DOB Postcode A00001 Bob Smith 1990-05-09 AB12 3CD A00002 Robert Smith 1990-05-09 AB12 3CD A00003 Robert \"Bobby\u201d Smith 1990-05-09 - <p>and some deterministic rules:</p> <pre><code>IF Name matches AND DOB matches (Rule 1)\nTHEN records are a match\n\nELSE\n\nIF Forename matches AND DOB matches AND Postcode match (Rule 2)\nTHEN records are a match\n\nELSE\n\nrecords do not match\n</code></pre> <p>Applying these rules to the table above leads to no matches:</p> <p>A0001-A0002 No match (different forename) A0001-A0003 No match (different forename) A0002-A0003 No match (missing postcode)</p> <p>So, even a relatively simple dataset, with duplicates that are obvious to a human, will require more complex rules.</p> <p>In general, Deterministic linkage is:</p>      \u2705 Computationally cheap       \u2705 Capable of achieving high precision (few False Positives)         \u274c Lacking in subtlety       \u274c Prone to Low recall (False Negatives)    Deterministic Linkage in Splink <p>While Splink is primarily a tool for Probabilistic linkage, Deterministic linkage is also supported (utilising blocking rules). See the example notebooks to see how this is Deterministic linkage is implemented in Splink.</p>"},{"location":"topic_guides/theory/probabilistic_vs_deterministic.html#probabilistic-linkage","title":"Probabilistic Linkage","text":"<p>Probabilistic Linkage is a evidence-based approach for joining records together.</p> <p>Linkage is probabilistic in the sense that it relies on the balance of evidence. In a large dataset, observing that two records match on the full name 'Robert Smith' provides some evidence that these two records may refer to the same person, but this evidence is inconclusive. However, the cumulative evidence from across multiple features within the dataset (e.g. date of birth, home address, email address) can provide conclusive evidence of a match. The evidence for a match is commonly represented as a probability.</p> <p>For example, putting the first 2 records of the table above through a probabilistic model gives a an overall probability that the records are a match: </p> <p>In addition, the breakdown of this probability by the evidence provided by each feature can be shown through a waterfall chart:</p> <p></p> <p>Given these probabilities, unlike (binary) Deterministic linkage, the user can choose an evidence threshold for what they consider a match before creating a new unique identifier.</p> <p>This is important, as it allows the linkage to be customised to best support the specific use case. For example, if it is important to:</p> <ul> <li>minimise False Positive matches (i.e. where False Negatives are less of a concern), a higher threshold for a match can be chosen.</li> <li>maximise True Positive matches (i.e. where False Positives are less of a concern), a lower threshold can be chosen.</li> </ul> <p>Further Reading</p> <p>For a more in-depth introduction to Probabilistic Data Linkage, including an interactive version of the waterfall chart above, see Robin Linacre's Blog.</p> Probabilistic Linkage in Splink <p>Splink is primarily a tool for Probabilistic linkage, and implements the Fellegi-Sunter model - the most common probabilistic record linkage model. See the Splink Tutorial for a step by step guide for Probabilistic linkage in Splink.</p> <p>A Topic Guide on the Fellegi-Sunter model is can be found here!</p>"},{"location":"topic_guides/theory/record_linkage.html","title":"Why do we need record linkage?","text":""},{"location":"topic_guides/theory/record_linkage.html#why-do-we-need-record-linkage","title":"Why do we need record linkage?","text":""},{"location":"topic_guides/theory/record_linkage.html#in-a-perfect-world","title":"In a perfect world","text":"<p>In a perfect world, everyone (and everything) would have a single, unique identifier. If this were the case, linking any datasets would be a simple inner join.</p> Example <p>Consider 2 tables of people A and B with no duplicates and each person has a unique id <code>UID</code>. To join these tables in SQL we would write:</p> <pre><code>SELECT *\nFROM A\nINNER JOIN B\nON A.UID = B.UID\n</code></pre>"},{"location":"topic_guides/theory/record_linkage.html#in-reality","title":"In reality","text":"<p>Real datasets often lack truly unique identifiers (both within and across datasets).</p> <p>The overall aim of record linkage is to generate a unique identifier to be used like <code>UID</code> to our \"perfect world\" scenario.</p> <p>Record linkage the process of using the information within records to assess whether records refer to the same entity.  For example, if records refer to people, factors such as names, date of birth, location etc can be used to link records together.</p> <p>Record linkage can be done within datasets (deduplication) or between datasets (linkage), or both.</p>"},{"location":"topic_guides/training/training_rationale.html","title":"Training rationale","text":"<p>In Splink, in most scenarios, we recommend a hybrid approach to training model parameters, whereby we use direct estimation techniques for the <code>probability_two_random_records_match</code> (\u03bb) parameter and the <code>u</code> probabilities, and then use EM training for the <code>m</code> probabilities.</p> <p>The overall rationale is that we found that whilst it's possible to train all parameters using EM, empirically we've found you get better parameter estimates, and fewer convergence problems using direct estimation of some parameters.</p> <p>In particular:</p> <ul> <li>You can precisely estimate the <code>u</code> probabilities in most cases, so there's no reason to use a less reliable unsupervised technique.</li> <li>With <code>probability_two_random_records_match</code>, we found that Expectation Maximisation often resulted in inaccurate results due to our 'blocking' methodology for training <code>m</code> values. In practice, the direct estimation technique gave better results, despite being somewhat imprecise.</li> </ul> <p>The recommended sequence for model training and associated rationale is as follows:</p>","tags":["Training"]},{"location":"topic_guides/training/training_rationale.html#1-use-linkertrainingestimate_probability_two_random_records_match-to-estimate-the-proportion-of-records","title":"1. Use linker.training.estimate_probability_two_random_records_match to estimate the proportion of records.","text":"<p>The <code>probability_two_random_records_match</code> is one of the harder parameters to estimate because there's a catch-22: to know its value, we need to know which records match, but that's the whole problem we're trying to solve.</p> <p>Luckily, in most cases it's relatively easy to come up with a good guess, within (say) half or double its true value. It turns out that this is good enough to get good estimates of the other parameters, and ultimatey to get good predictions.</p> <p>In our methodology,  the user specifies a list of deterministic matching rules that they believe represent true matches. These will be strict, and therefore will miss some fuzzy matches. For all but the most messy datasets, they should capture the majority of matches. A recall parameter is then provided by the user, which is the user's guess of how many matches are missed by these rules.</p> <p>In a typical case, the deterministic rules may capture (say) 80% of matches. If the user gets this wrong and provides recall of say 60% or 95%, the effect on <code>probability_two_random_records_match</code> is not huge.</p> <p>For example, a typical parameter estimate for <code>probability_two_random_records_match</code> when expressed as a match weight may be -14.  Assuming true recall of 80%, if the user guessed recall wrong at 60% or 95%, the parameter would be estimated at -13.75 or -14.42 respectively.</p> <p>In turn, so long as this parameter is roughly right, it serves as an 'anchor' to EM parameter estimation later, which prevents it iterating/converging to the 'wrong' place (there's no guarantee it converges to a global minimum, only a local one).</p> <p>Example: </p><pre><code>deterministic_rules = [\n    block_on(\"first_name\", \"surname\", \"dob\"),\n    block_on(\"email\")\"\n]\n\nlinker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)\n</code></pre>","tags":["Training"]},{"location":"topic_guides/training/training_rationale.html#2-use-linkertrainingestimate_u_using_random_sampling-to-train-u-probabilities","title":"2. Use linker.training.estimate_u_using_random_sampling to train <code>u</code> probabilities.","text":"<p>This one is easy to justify: On a sufficiently large dataset, if you take two random records, they will almost certainly not be a match. The <code>u</code> probabilities are calculated on the basis of truly non-matching records. So we can directly calculate them from random record comparisons. The only errors will be:</p> <ul> <li>Sampling error\u2014in which case we can increase our sample size.</li> <li>The small errors introduced by the fact that, occasionally, our sampled records will match. In practice, this rarely has a big effect.</li> </ul> <p>Example: </p><pre><code>linker.training.estimate_u_using_random_sampling(max_pairs=1e7)\n</code></pre> Increase <code>max_pairs</code> if you need more precision. This step is usually straightforward and reliable.","tags":["Training"]},{"location":"topic_guides/training/training_rationale.html#3-use-linkertrainingestimate_parameters_using_expectation_maximisation-to-estimate-m-probabilities","title":"3. Use linker.training.estimate_parameters_using_expectation_maximisation to estimate <code>m</code> probabilities.","text":"<p>The <code>m</code> probabilities have the same 'catch-22' problem as the <code>probability_two_random_records_match</code>. Luckily, the magic of EM is that it solves this problem.</p> <p>In the context of record linkage on large datsets, one problem is that we cannot easily run EM on random pairs of records, because they are almost all non-matches. It would work if we had infinite computing resources and could create unlimited numbers of comparisons. But in a typical case, even if we create 1 billion random comparisons, perhaps only 1000 are matches. Now we only have a sample size of 1,000 to estimate our <code>m</code> values, and their estimates may be imprecise. This contrasts to <code>u</code> estimation, where we have a sample size of <code>max_pair</code>s , often millions or even billions.</p> <p>To speed this up, we can use a trick. By blocking on some columns (e.g. first name and surname), we now restrict our record comparisons to a subset with a far higher proportion of matches than random comparisons.</p> <p>This trick is vulnerable to the criticism that we may get a biased selection of matching records. The Fellegi-Sunter model assumes columns are independent conditional on match status, which is rarely true in practice.</p> <p>But if this assumption holds then the selection of records is unbiased, and the parameter estimates are correct.</p>","tags":["Training"]},{"location":"topic_guides/training/training_rationale.html#the-round-robin","title":"The 'round robin'","text":"<p>One complexity of this approach is that when we block on first name and surname, we can't get parameter estimates for these two columns because we've forced all comparison to be equal.</p> <p>That's why we need multiple EM training passes: we need a second pass blocking on e.g. date_of_birth to get parameter estimates for first_name and surname.</p> <pre><code>linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\nlinker.training.estimate_parameters_using_expectation_maximisation(block_on(\"first_name\", \"surname\"))\n</code></pre> <p>At this point, we have:</p> <ul> <li>One estimate for the <code>m</code> values for first_name and surname</li> <li>One estimate for the <code>m</code> values for date_of_birth</li> <li>Two estimates for each <code>m</code> value for any other columns</li> </ul> <p>If we're worried about our estimates, we can run more training rounds to get more estimates, e.g. blocking on postcode. We can then use linker.visualisations.parameter_estimate_comparisons_chart to check that the various estimates are similar. Under the hood, Splink will take an average.</p> <pre><code>linker.visualisations.parameter_estimate_comparisons_chart()\n</code></pre> <p>Empirically, one of the nice things here is that, because we've fixed the <code>u</code> probabilities and the <code>probability_two_random_records_match</code> at sensible values, they anchor the EM training process and it turns out you don't get too many convergence problems.</p> <p>Finally, if the user is still having convergence problems, there are two options: 1. In practice, we have found these can be often due to data quality issues e.g. <code>mr</code> and <code>mrs</code> in <code>first_name</code>, so it's a good idea to go back to exploratory data analysis and understand if there's a root cause 2. If there's no obvious cause, the user can fix the m values, see here  and here</p>","tags":["Training"]},{"location":"blog/category/bias.html","title":"Bias","text":""},{"location":"blog/category/feature-updates.html","title":"Feature Updates","text":""},{"location":"blog/category/ethics.html","title":"Ethics","text":""}]}